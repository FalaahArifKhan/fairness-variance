{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a94715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba83a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@development\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c51a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5435244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install BlackBoxAuditing==0.1.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4739c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a7f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc41f3",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc54142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import LawSchoolDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "from configs.models_config_for_tuning import get_model_params_for_mult_repair_levels\n",
    "\n",
    "from source.preprocessing import get_simple_preprocessor\n",
    "from source.experiment_interface import run_exp_iter_with_disparate_impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa3c612",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOT_DIR = os.path.join(os.getcwd(), \"..\", \"..\")\n",
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'mult_repair_levels_law_school'\n",
    "DB_COLLECTION_NAME = 'exp_mult_repair_levels'\n",
    "DATASET_NAME = 'LawSchoolDataset'\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', EXPERIMENT_NAME)\n",
    "# FAIR_INTERVENTION_PARAMS_LST = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "FAIR_INTERVENTION_PARAMS_LST = [0.1, 0.9]\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', EXPERIMENT_NAME, 'law_school_2018_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0f124",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d10efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f663ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bfb80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': '9430484b-bec6-42a0-ac65-11c53446a61f',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ccac1d",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b11c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = LawSchoolDataset()\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6686bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.X_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.y_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f195891",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.X_data['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da16a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.X_data['male'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb95bb1",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c6af08",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7213ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned_params_filenames = ['tuning_results_Folktables_NY_2018_Employment_alpha_0.8_20230706__115508.csv']\n",
    "# tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', EXPERIMENT_NAME, tuned_params_filename)\n",
    "#                          for tuned_params_filename in tuned_params_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec922b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_model_params_for_mult_repair_levels(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "                                   with_tuning=True,\n",
    "                                   # with_tuning=False,\n",
    "                                   # tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   verbose=True, \n",
    "                                   dataset_name=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03d191",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627d2887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_alpha_0.1_20230806__195840.csv',\n",
    "    'tuning_results_Law_School_alpha_0.9_20230806__195951.csv',\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_model_params_for_mult_repair_levels(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "#                                    with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   verbose=True, \n",
    "                                   dataset_name=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f78bb9",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c504f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_alpha_0.1_20230806__195840.csv',\n",
    "    'tuning_results_Law_School_alpha_0.9_20230806__195951.csv',\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_model_params_for_mult_repair_levels(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "#                                    with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   verbose=True, \n",
    "                                   dataset_name=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd4bae",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_alpha_0.1_20230806__195840.csv',\n",
    "    'tuning_results_Law_School_alpha_0.9_20230806__195951.csv',\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_model_params_for_mult_repair_levels(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c24e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "#                                    with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   verbose=True, \n",
    "                                   dataset_name=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237328c1",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da1084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_alpha_0.1_20230806__195840.csv',\n",
    "    'tuning_results_Law_School_alpha_0.9_20230806__195951.csv',\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_model_params_for_mult_repair_levels(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addb3527",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "#                                    with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   verbose=True, \n",
    "                                   dataset_name=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdfa243",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22acf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_alpha_0.1_20230806__195840.csv',\n",
    "    'tuning_results_Law_School_alpha_0.9_20230806__195951.csv',\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_model_params_for_mult_repair_levels(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c01df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_disparate_impact(data_loader=exp_iter_data_loader,\n",
    "                                   experiment_seed=experiment_seed,\n",
    "                                   test_set_fraction=TEST_SET_FRACTION,\n",
    "                                   db_writer_func=db_writer_func,\n",
    "                                   fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                                   models_params_for_tuning=models_params_for_tuning,\n",
    "                                   metrics_computation_config=metrics_computation_config,\n",
    "                                   custom_table_fields_dct=custom_table_fields_dct,\n",
    "#                                    with_tuning=True,\n",
    "                                   with_tuning=False,\n",
    "                                   tuned_params_df_paths=tuned_params_df_paths,\n",
    "                                   save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                   verbose=True, \n",
    "                                   dataset_name=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb144c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
