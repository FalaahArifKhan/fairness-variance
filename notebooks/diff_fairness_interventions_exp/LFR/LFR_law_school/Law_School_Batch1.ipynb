{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de875131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_for_uncertainty_experiments\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_for_uncertainty_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55975050",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7757acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde677b6",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90397c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import LawSchoolDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "from configs.models_config_for_tuning import get_folktables_employment_models_params_for_tuning\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_LFR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fcd186",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'LFR_law_school'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIR_INTERVENTION_PARAMS_LST = [{'k': 5, 'Ax': 0.01, 'Ay': 1.0, 'Az': 50.0}]\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp', 'LFR', EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                'LFR', EXPERIMENT_NAME, 'law_school_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337574fe",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87800656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df97fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': 'a1345526-1623-4fc7-b1a4-2a7790c4eef5',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51ebaa8",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97525ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = LawSchoolDataset()\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d9fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a37ae",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41898df0",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91096f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned_params_filenames = ['tuning_results_Folktables_NY_2018_Employment_alpha_0.8_20230706__115508.csv']\n",
    "# tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', EXPERIMENT_NAME, tuned_params_filename)\n",
    "#                          for tuned_params_filename in tuned_params_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58267eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1974ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_LFR(data_loader=exp_iter_data_loader,\n",
    "                      experiment_seed=experiment_seed,\n",
    "                      test_set_fraction=TEST_SET_FRACTION,\n",
    "                      db_writer_func=db_writer_func,\n",
    "                      fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                      models_params_for_tuning=models_params_for_tuning,\n",
    "                      metrics_computation_config=metrics_computation_config,\n",
    "                      custom_table_fields_dct=custom_table_fields_dct,\n",
    "                      with_tuning=True,\n",
    "                      # with_tuning=False,\n",
    "                      # tuned_params_df_paths=tuned_params_df_paths,\n",
    "                      save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                      dataset_name='LawSchoolDataset',\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c1fe03",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_20240103__005319.csv'\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                      'LFR', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_LFR(data_loader=exp_iter_data_loader,\n",
    "                      experiment_seed=experiment_seed,\n",
    "                      test_set_fraction=TEST_SET_FRACTION,\n",
    "                      db_writer_func=db_writer_func,\n",
    "                      fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                      models_params_for_tuning=models_params_for_tuning,\n",
    "                      metrics_computation_config=metrics_computation_config,\n",
    "                      custom_table_fields_dct=custom_table_fields_dct,\n",
    "                      # with_tuning=True,\n",
    "                      with_tuning=False,\n",
    "                      tuned_params_df_paths=tuned_params_df_paths,\n",
    "                      save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                      dataset_name='LawSchoolDataset',\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e33aa",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e400e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_20240103__005319.csv'\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                      'LFR', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_LFR(data_loader=exp_iter_data_loader,\n",
    "                      experiment_seed=experiment_seed,\n",
    "                      test_set_fraction=TEST_SET_FRACTION,\n",
    "                      db_writer_func=db_writer_func,\n",
    "                      fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                      models_params_for_tuning=models_params_for_tuning,\n",
    "                      metrics_computation_config=metrics_computation_config,\n",
    "                      custom_table_fields_dct=custom_table_fields_dct,\n",
    "                      # with_tuning=True,\n",
    "                      with_tuning=False,\n",
    "                      tuned_params_df_paths=tuned_params_df_paths,\n",
    "                      save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                      dataset_name='LawSchoolDataset',\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6209c2",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_20240103__005319.csv'\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                      'LFR', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b601106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_LFR(data_loader=exp_iter_data_loader,\n",
    "                      experiment_seed=experiment_seed,\n",
    "                      test_set_fraction=TEST_SET_FRACTION,\n",
    "                      db_writer_func=db_writer_func,\n",
    "                      fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                      models_params_for_tuning=models_params_for_tuning,\n",
    "                      metrics_computation_config=metrics_computation_config,\n",
    "                      custom_table_fields_dct=custom_table_fields_dct,\n",
    "                      # with_tuning=True,\n",
    "                      with_tuning=False,\n",
    "                      tuned_params_df_paths=tuned_params_df_paths,\n",
    "                      save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                      dataset_name='LawSchoolDataset',\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2141de52",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b69f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_20240103__005319.csv'\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                      'LFR', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f66a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_LFR(data_loader=exp_iter_data_loader,\n",
    "                      experiment_seed=experiment_seed,\n",
    "                      test_set_fraction=TEST_SET_FRACTION,\n",
    "                      db_writer_func=db_writer_func,\n",
    "                      fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                      models_params_for_tuning=models_params_for_tuning,\n",
    "                      metrics_computation_config=metrics_computation_config,\n",
    "                      custom_table_fields_dct=custom_table_fields_dct,\n",
    "                      # with_tuning=True,\n",
    "                      with_tuning=False,\n",
    "                      tuned_params_df_paths=tuned_params_df_paths,\n",
    "                      save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                      dataset_name='LawSchoolDataset',\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f44a8",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "tuned_params_filenames = [\n",
    "    'tuning_results_Law_School_20240103__005319.csv'\n",
    "]\n",
    "tuned_params_df_paths = [os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                      'LFR', EXPERIMENT_NAME, tuned_params_filename)\n",
    "                         for tuned_params_filename in tuned_params_filenames]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage\n",
    "models_params_for_tuning = get_folktables_employment_models_params_for_tuning(experiment_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exp_iter_with_LFR(data_loader=exp_iter_data_loader,\n",
    "                      experiment_seed=experiment_seed,\n",
    "                      test_set_fraction=TEST_SET_FRACTION,\n",
    "                      db_writer_func=db_writer_func,\n",
    "                      fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                      models_params_for_tuning=models_params_for_tuning,\n",
    "                      metrics_computation_config=metrics_computation_config,\n",
    "                      custom_table_fields_dct=custom_table_fields_dct,\n",
    "                      # with_tuning=True,\n",
    "                      with_tuning=False,\n",
    "                      tuned_params_df_paths=tuned_params_df_paths,\n",
    "                      save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                      dataset_name='LawSchoolDataset',\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbca73b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
