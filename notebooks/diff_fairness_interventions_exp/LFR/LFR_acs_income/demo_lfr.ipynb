{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T13:07:31.253900Z",
     "start_time": "2023-12-30T13:07:30.250740Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T13:07:31.502693Z",
     "start_time": "2023-12-30T13:07:31.255074Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig = load_preproc_data_adult()\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T13:07:31.508900Z",
     "start_time": "2023-12-30T13:07:31.502272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Original training dataset"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.193662\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Original test dataset"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.196507\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "privileged_groups = [{'sex': 1.0}]\n",
    "unprivileged_groups = [{'sex': 0.0}]\n",
    "\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original test dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with and transform the original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T13:07:31.516675Z",
     "start_time": "2023-12-30T13:07:31.510905Z"
    }
   },
   "outputs": [],
   "source": [
    "scale_orig = StandardScaler()\n",
    "dataset_orig_train.features = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "dataset_orig_test.features = scale_orig.transform(dataset_orig_test.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T13:08:25.979813Z",
     "start_time": "2023-12-30T13:07:31.518170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.8248745006364724, L_x: 2.4562291653747206,  L_y: 0.556274147762223,  L_z: 0.01148871816838871\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          190     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.24875D-01    |proj g|=  1.70678D-02\n",
      "step: 250, loss: 0.8225663928658248, L_x: 2.4542585887813217,  L_y: 0.5551546650160966,  L_z: 0.01099293448579802\n",
      "\n",
      "At iterate    1    f=  8.22566D-01    |proj g|=  1.82058D-02\n",
      "step: 500, loss: 0.8010326580481005, L_x: 2.381059755824986,  L_y: 0.5402945693956658,  L_z: 0.01131605653496808\n",
      "\n",
      "At iterate    2    f=  8.01033D-01    |proj g|=  1.95040D-02\n",
      "step: 750, loss: 0.7842317548189357, L_x: 2.3602522698335915,  L_y: 0.5332522979837272,  L_z: 0.007477114925924687\n",
      "\n",
      "At iterate    3    f=  7.84232D-01    |proj g|=  1.80112D-02\n",
      "\n",
      "At iterate    4    f=  7.47652D-01    |proj g|=  2.33976D-02\n",
      "step: 1000, loss: 0.7149587539517059, L_x: 2.0770765868493277,  L_y: 0.4721795187898537,  L_z: 0.017535788238459697\n",
      "\n",
      "At iterate    5    f=  7.14959D-01    |proj g|=  2.36787D-02\n",
      "step: 1250, loss: 0.6894820302732023, L_x: 1.936847337206789,  L_y: 0.46119748469950056,  L_z: 0.01729990592651141\n",
      "\n",
      "At iterate    6    f=  6.89482D-01    |proj g|=  9.76565D-03\n",
      "step: 1500, loss: 0.677834420438133, L_x: 1.8436857150592398,  L_y: 0.463350297615972,  L_z: 0.015057775658118486\n",
      "\n",
      "At iterate    7    f=  6.77834D-01    |proj g|=  2.56375D-02\n",
      "\n",
      "At iterate    8    f=  6.71178D-01    |proj g|=  2.66404D-02\n",
      "step: 1750, loss: 0.6664343913037178, L_x: 1.8145774756594057,  L_y: 0.4602525491034171,  L_z: 0.01236204731718006\n",
      "\n",
      "At iterate    9    f=  6.66434D-01    |proj g|=  2.22585D-02\n",
      "step: 2000, loss: 0.6591126008340797, L_x: 1.79806532137401,  L_y: 0.4560344978228327,  L_z: 0.011635785436923023\n",
      "\n",
      "At iterate   10    f=  6.59113D-01    |proj g|=  1.82038D-02\n",
      "step: 2250, loss: 0.6554832244764826, L_x: 1.7782080877220348,  L_y: 0.4538467274207932,  L_z: 0.01190784414174294\n",
      "\n",
      "At iterate   11    f=  6.55483D-01    |proj g|=  1.87834D-02\n",
      "\n",
      "At iterate   12    f=  6.48867D-01    |proj g|=  2.49989D-02\n",
      "step: 2500, loss: 0.6507298838033911, L_x: 1.7325231722111663,  L_y: 0.45327013510381864,  L_z: 0.012103715739227904\n",
      "step: 2750, loss: 0.6465938116284387, L_x: 1.749697431582685,  L_y: 0.45302798796478855,  L_z: 0.009298040252690746\n",
      "\n",
      "At iterate   13    f=  6.46594D-01    |proj g|=  1.20750D-02\n",
      "step: 3000, loss: 0.6457089771426051, L_x: 1.7396851650374874,  L_y: 0.45234431135335906,  L_z: 0.009698074642748657\n",
      "\n",
      "At iterate   14    f=  6.45709D-01    |proj g|=  2.31072D-02\n",
      "\n",
      "At iterate   15    f=  6.42398D-01    |proj g|=  2.25726D-02\n",
      "step: 3250, loss: 0.6347297267400028, L_x: 1.6575108577045918,  L_y: 0.44913009491823336,  L_z: 0.00992427302565512\n",
      "\n",
      "At iterate   16    f=  6.34730D-01    |proj g|=  2.41000D-02\n",
      "step: 3500, loss: 0.6304566375782311, L_x: 1.6315448709736375,  L_y: 0.447893947010776,  L_z: 0.009704101735045644\n",
      "\n",
      "At iterate   17    f=  6.30457D-01    |proj g|=  1.70609D-02\n",
      "step: 3750, loss: 0.6290268387358225, L_x: 1.598971309446753,  L_y: 0.4476288068401413,  L_z: 0.010750450475502996\n",
      "\n",
      "At iterate   18    f=  6.29027D-01    |proj g|=  1.56193D-02\n",
      "step: 4000, loss: 0.6261160489782183, L_x: 1.6042202418379645,  L_y: 0.44703495205520494,  L_z: 0.009329536369608442\n",
      "\n",
      "At iterate   19    f=  6.26116D-01    |proj g|=  2.53771D-02\n",
      "\n",
      "At iterate   20    f=  6.22322D-01    |proj g|=  1.19678D-02\n",
      "step: 4250, loss: 0.6203559109429871, L_x: 1.5805503722670982,  L_y: 0.4444581392770754,  L_z: 0.008921367219600964\n",
      "\n",
      "At iterate   21    f=  6.20356D-01    |proj g|=  1.33240D-02\n",
      "step: 4500, loss: 0.6172115430990152, L_x: 1.549715842976287,  L_y: 0.4469807911353675,  L_z: 0.007629583833009504\n",
      "\n",
      "At iterate   22    f=  6.17212D-01    |proj g|=  1.60008D-02\n",
      "step: 4750, loss: 0.6163346883022027, L_x: 1.531678275177009,  L_y: 0.4484540936209299,  L_z: 0.007356383581785901\n",
      "\n",
      "At iterate   23    f=  6.16335D-01    |proj g|=  2.29546D-02\n",
      "\n",
      "At iterate   24    f=  6.13080D-01    |proj g|=  2.50956D-02\n",
      "step: 5000, loss: 0.6114231978878696, L_x: 1.5225722768406218,  L_y: 0.4468438720503764,  L_z: 0.006161049076715478\n",
      "\n",
      "At iterate   25    f=  6.11423D-01    |proj g|=  1.63981D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  190     25     27     31     0     8   1.640D-02   6.114D-01\n",
      "  F =  0.61142320251501292     \n",
      "\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT        \n"
     ]
    }
   ],
   "source": [
    "# Input recontruction quality - Ax\n",
    "# Fairness constraint - Az\n",
    "# Output prediction error - Ay\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "    \n",
    "TR = LFR(unprivileged_groups=unprivileged_groups,\n",
    "         privileged_groups=privileged_groups,\n",
    "         k=10, Ax=0.1, Ay=1.0, Az=2.0,\n",
    "         verbose=1\n",
    "        )\n",
    "TR = TR.fit(dataset_orig_train, maxiter=5000, maxfun=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T13:08:26.101345Z",
     "start_time": "2023-12-30T13:08:25.977847Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform training data and align features\n",
    "dataset_transf_train = TR.transform(dataset_orig_train)\n",
    "dataset_transf_test = TR.transform(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T13:08:26.140337Z",
     "start_time": "2023-12-30T13:08:26.098983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.91      0.87     11133\n",
      "         1.0       0.59      0.41      0.49      3520\n",
      "\n",
      "    accuracy                           0.79     14653\n",
      "   macro avg       0.71      0.66      0.68     14653\n",
      "weighted avg       0.77      0.79      0.78     14653\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dataset_orig_test.labels, dataset_transf_test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T13:09:20.687934Z",
     "start_time": "2023-12-30T13:09:20.680797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Training dataset"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed: Difference in mean outcomes between unprivileged and privileged groups = -0.072447\n",
      "Original: Difference in mean outcomes between unprivileged and privileged groups = -0.193662\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Test dataset"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed: Difference in mean outcomes between unprivileged and privileged groups = -0.079498\n",
      "Original: Difference in mean outcomes between unprivileged and privileged groups = -0.196507\n"
     ]
    }
   ],
   "source": [
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Training dataset\"))\n",
    "print(\"Transformed: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())\n",
    "print(\"Original: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "metric_transf_test = BinaryLabelDatasetMetric(dataset_transf_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Test dataset\"))\n",
    "print(\"Transformed: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_test.mean_difference())\n",
    "print(\"Original: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "abs(1-disparate impact) must be small (close to 0) for classifier predictions to be fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T13:08:36.829436Z",
     "start_time": "2023-12-30T13:08:26.161270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Individual fairness metrics"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency of labels in transformed training dataset= 1.000000\n",
      "Consistency of labels in original training dataset= 0.754225\n",
      "Consistency of labels in transformed test dataset= 1.000000\n",
      "Consistency of labels in original test dataset= 0.721545\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Individual fairness metrics\"))\n",
    "print(\"Consistency of labels in transformed training dataset= %f\" %metric_transf_train.consistency())\n",
    "print(\"Consistency of labels in original training dataset= %f\" %metric_orig_train.consistency())\n",
    "print(\"Consistency of labels in transformed test dataset= %f\" %metric_transf_test.consistency())\n",
    "print(\"Consistency of labels in original test dataset= %f\" %metric_orig_test.consistency())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T13:08:50.472785Z",
     "start_time": "2023-12-30T13:08:50.468311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "def check_algorithm_success():\n",
    "    \"\"\"Transformed dataset consistency should be greater than original dataset.\"\"\"\n",
    "    assert metric_transf_test.consistency() > metric_orig_test.consistency(),\\\n",
    "        \"Transformed dataset consistency should be greater than original dataset.\"\n",
    "    \n",
    "    print('Success!')\n",
    "\n",
    "check_algorithm_success()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T13:08:36.834934Z",
     "start_time": "2023-12-30T13:08:36.832102Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
