{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "579cdd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c496e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:55:54.052462Z",
     "start_time": "2024-01-06T10:55:54.038357Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fac979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:56:09.679156Z",
     "start_time": "2024-01-06T10:56:09.668186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efeb31c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.457257Z",
     "start_time": "2024-01-06T11:15:26.114625Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6f4b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.466361Z",
     "start_time": "2024-01-06T11:15:26.457627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b1bdfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.478005Z",
     "start_time": "2024-01-06T11:15:26.467253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/dh3553/projects/fairness-variance\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8ed6a4",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8603fd05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.734704Z",
     "start_time": "2024-01-06T11:15:28.036691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import ACSIncomeDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5e0b4",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486ff8f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.772286Z",
     "start_time": "2024-01-06T11:15:31.735883Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'ADB_acs_income'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION_NAME = 'ADB'\n",
    "FAIR_INTERVENTION_PARAMS_LST = ['debiased_classifier']\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                     FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, 'folk_GA_2018_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32687278",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9faff9a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.813421Z",
     "start_time": "2024-01-06T11:15:31.771935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairness_variance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9088d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.096974Z",
     "start_time": "2024-01-06T11:15:31.811395Z"
    }
   },
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5afdac96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.138747Z",
     "start_time": "2024-01-06T11:15:32.097343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  bbba3cc4-760b-4e93-bb97-3a2077202cce\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b9181",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db87d5d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:33.528732Z",
     "start_time": "2024-01-06T11:15:33.475702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL</th>\n",
       "      <th>COW</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WKHP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>230</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4110</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4130</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4020</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8300</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SCHL COW MAR  OCCP POBP RELP SEX RAC1P  AGEP  WKHP\n",
       "0   23   7   3   230   36    0   1     1    55  55.0\n",
       "1   16   1   5  4110   13    2   2     1    20  35.0\n",
       "2   16   4   3  4130   51    0   2     1    59  30.0\n",
       "3   18   4   1  4020   13    0   1     2    43  40.0\n",
       "4   14   1   1  8300   20    1   2     2    33  20.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = ACSIncomeDataset(state=['GA'], year=2018, with_nulls=False,\n",
    "                               subsample_size=15_000, subsample_seed=42)\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6071d717",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:34.580537Z",
     "start_time": "2024-01-06T11:15:34.538952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df18b61c",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca1b2e2",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a4ebb19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:37.135031Z",
     "start_time": "2024-01-06T11:15:37.105079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e0b90a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:44.618835Z",
     "start_time": "2024-01-06T11:15:43.745040Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:04:06 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 100,\n",
      " 'experiment_iteration': 'Exp_iter_1',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 100,\n",
      " 'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc38ee9c876469caefd18438ec5bf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:04:06 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=724)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0a941737a8417cb4f7946d88b35431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8c917d6c174359aff6c81106515faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.703511; batch adversarial loss: 0.868435\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433493; batch adversarial loss: 0.870017\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396227; batch adversarial loss: 0.863279\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393296; batch adversarial loss: 0.784595\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335170; batch adversarial loss: 0.729312\n",
      "epoch 5; iter: 0; batch classifier loss: 0.302273; batch adversarial loss: 0.718420\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340553; batch adversarial loss: 0.671042\n",
      "epoch 7; iter: 0; batch classifier loss: 0.317702; batch adversarial loss: 0.662751\n",
      "epoch 8; iter: 0; batch classifier loss: 0.252170; batch adversarial loss: 0.648393\n",
      "epoch 9; iter: 0; batch classifier loss: 0.292380; batch adversarial loss: 0.613334\n",
      "epoch 10; iter: 0; batch classifier loss: 0.278500; batch adversarial loss: 0.582467\n",
      "epoch 11; iter: 0; batch classifier loss: 0.315808; batch adversarial loss: 0.541661\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282857; batch adversarial loss: 0.547508\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245198; batch adversarial loss: 0.570313\n",
      "epoch 14; iter: 0; batch classifier loss: 0.295288; batch adversarial loss: 0.471533\n",
      "epoch 15; iter: 0; batch classifier loss: 0.255773; batch adversarial loss: 0.471669\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227866; batch adversarial loss: 0.459387\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265236; batch adversarial loss: 0.390383\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221451; batch adversarial loss: 0.492176\n",
      "epoch 19; iter: 0; batch classifier loss: 0.235272; batch adversarial loss: 0.424545\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222551; batch adversarial loss: 0.393122\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149757; batch adversarial loss: 0.495092\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181218; batch adversarial loss: 0.386822\n",
      "epoch 23; iter: 0; batch classifier loss: 0.139735; batch adversarial loss: 0.457702\n",
      "epoch 24; iter: 0; batch classifier loss: 0.153798; batch adversarial loss: 0.475582\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132027; batch adversarial loss: 0.444322\n",
      "epoch 26; iter: 0; batch classifier loss: 0.129947; batch adversarial loss: 0.370190\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140482; batch adversarial loss: 0.350910\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166366; batch adversarial loss: 0.481889\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178009; batch adversarial loss: 0.357132\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca8679",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc9ab2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EXPERIMENT_SEEDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configs for an experiment iteration\u001b[39;00m\n\u001b[1;32m      2\u001b[0m exp_iter_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 3\u001b[0m experiment_seed \u001b[38;5;241m=\u001b[39m \u001b[43mEXPERIMENT_SEEDS\u001b[49m[exp_iter_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m tuned_params_filenames \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      6\u001b[0m tuned_params_df_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_fairness_interventions_exp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                       FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, tuned_params_filename)\n\u001b[1;32m      8\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m tuned_params_filename \u001b[38;5;129;01min\u001b[39;00m tuned_params_filenames]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EXPERIMENT_SEEDS' is not defined"
     ]
    }
   ],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dcc6472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:56.249510Z",
     "start_time": "2024-01-04T20:53:56.233525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 200,\n",
      " 'experiment_iteration': 'Exp_iter_2',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 200,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5645c6009d3b48d29619a238bc476502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 200, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c0277603884950a0c35cc9dcc3f539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7137564e8e0d4fcbbbfaaf03d73e170a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa30ab3dbbfe4acb8557a8c1e2d6556b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a36e32d08b44c1b01ae496881c6b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05fef8a",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4d43b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bc8c9a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:46.750905Z",
     "start_time": "2024-01-04T20:53:46.744795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 300,\n",
      " 'experiment_iteration': 'Exp_iter_3',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 300,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b0aa26f024ad1b1089190e134193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 300, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddcae8f6fc4651885a3144088ae9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43ba8d965cc436a91f10cc39b3d5e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94495e7bec64c9ebf4c05cdd52e605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f7167dd20740a68f8f90158ec19560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cedda2b",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a938da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a36ab51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:37.675129Z",
     "start_time": "2024-01-04T20:53:37.670178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 400,\n",
      " 'experiment_iteration': 'Exp_iter_4',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 400,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5b534568b14897b8686d22a9c79d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 400, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42164aebf0d74a5992f0ca8075639200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a128a0a62f40fb9bd0b88e41d55103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6300cf6db9cc4bcf95389b1f6e9b8108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e75feb8b5c4e00a1fc551544462dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942818d6",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7814faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88928487",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:27.080554Z",
     "start_time": "2024-01-04T20:53:27.072313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 500,\n",
      " 'experiment_iteration': 'Exp_iter_5',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 500,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8257cfd4f743e8887bbc74613694af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 500, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2d40e5f54c4d67bf9f1e66289ae23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63535df3c576469e9e855b70194bc572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15688b8597f74cdaadb60cc93599720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165f4884fae4f29829de3acc475dac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc72a6",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "515ba279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18b17498",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:16.632770Z",
     "start_time": "2024-01-04T20:53:16.629083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:06:22 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 600,\n",
      " 'experiment_iteration': 'Exp_iter_6',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 600,\n",
      " 'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678a3617bca64492a9668df181b9b429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:06:23 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=731)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 2649,  1964, 14464,  4377, 14152,  5747,  1529, 10243, 12578,\n",
      "             9794,  7142, 14347,  6387,  2917,   317,  9085,  5821, 11007,\n",
      "             8142,  3719],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 2649,  1964, 14464,  4377, 14152,  5747,  1529, 10243, 12578,\n",
      "             9794,  7142, 14347,  6387,  2917,   317,  9085,  5821, 11007,\n",
      "             8142,  3719],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5a317f1d884457857dfde36074d5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885b9e078d41420a95aaf6c8fede4226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.719484; batch adversarial loss: 0.812822\n",
      "epoch 1; iter: 0; batch classifier loss: 0.404913; batch adversarial loss: 0.751535\n",
      "epoch 2; iter: 0; batch classifier loss: 0.441876; batch adversarial loss: 0.751648\n",
      "epoch 3; iter: 0; batch classifier loss: 0.378361; batch adversarial loss: 0.699692\n",
      "epoch 4; iter: 0; batch classifier loss: 0.304029; batch adversarial loss: 0.646867\n",
      "epoch 5; iter: 0; batch classifier loss: 0.338124; batch adversarial loss: 0.632146\n",
      "epoch 6; iter: 0; batch classifier loss: 0.313677; batch adversarial loss: 0.607706\n",
      "epoch 7; iter: 0; batch classifier loss: 0.345183; batch adversarial loss: 0.588510\n",
      "epoch 8; iter: 0; batch classifier loss: 0.292644; batch adversarial loss: 0.563213\n",
      "epoch 9; iter: 0; batch classifier loss: 0.333739; batch adversarial loss: 0.549269\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374007; batch adversarial loss: 0.539442\n",
      "epoch 11; iter: 0; batch classifier loss: 0.320962; batch adversarial loss: 0.484266\n",
      "epoch 12; iter: 0; batch classifier loss: 0.249758; batch adversarial loss: 0.496239\n",
      "epoch 13; iter: 0; batch classifier loss: 0.273880; batch adversarial loss: 0.493922\n",
      "epoch 14; iter: 0; batch classifier loss: 0.240745; batch adversarial loss: 0.431921\n",
      "epoch 15; iter: 0; batch classifier loss: 0.194272; batch adversarial loss: 0.465094\n",
      "epoch 16; iter: 0; batch classifier loss: 0.223312; batch adversarial loss: 0.471241\n",
      "epoch 17; iter: 0; batch classifier loss: 0.160105; batch adversarial loss: 0.483837\n",
      "epoch 18; iter: 0; batch classifier loss: 0.165455; batch adversarial loss: 0.464402\n",
      "epoch 19; iter: 0; batch classifier loss: 0.167185; batch adversarial loss: 0.465094\n",
      "epoch 20; iter: 0; batch classifier loss: 0.192965; batch adversarial loss: 0.470346\n",
      "epoch 21; iter: 0; batch classifier loss: 0.203387; batch adversarial loss: 0.421205\n",
      "epoch 22; iter: 0; batch classifier loss: 0.185642; batch adversarial loss: 0.423423\n",
      "epoch 23; iter: 0; batch classifier loss: 0.154293; batch adversarial loss: 0.339884\n",
      "epoch 24; iter: 0; batch classifier loss: 0.201483; batch adversarial loss: 0.365700\n",
      "epoch 25; iter: 0; batch classifier loss: 0.218797; batch adversarial loss: 0.458144\n",
      "epoch 26; iter: 0; batch classifier loss: 0.154479; batch adversarial loss: 0.411201\n",
      "epoch 27; iter: 0; batch classifier loss: 0.196358; batch adversarial loss: 0.436905\n",
      "epoch 28; iter: 0; batch classifier loss: 0.148912; batch adversarial loss: 0.381249\n",
      "epoch 29; iter: 0; batch classifier loss: 0.214337; batch adversarial loss: 0.415565\n",
      "epoch 30; iter: 0; batch classifier loss: 0.147717; batch adversarial loss: 0.357003\n",
      "epoch 31; iter: 0; batch classifier loss: 0.158004; batch adversarial loss: 0.446943\n",
      "epoch 32; iter: 0; batch classifier loss: 0.095905; batch adversarial loss: 0.331826\n",
      "epoch 33; iter: 0; batch classifier loss: 0.167978; batch adversarial loss: 0.427475\n",
      "epoch 34; iter: 0; batch classifier loss: 0.126581; batch adversarial loss: 0.423049\n",
      "epoch 35; iter: 0; batch classifier loss: 0.134975; batch adversarial loss: 0.440591\n",
      "epoch 36; iter: 0; batch classifier loss: 0.176881; batch adversarial loss: 0.399948\n",
      "epoch 37; iter: 0; batch classifier loss: 0.190058; batch adversarial loss: 0.470053\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127610; batch adversarial loss: 0.340689\n",
      "epoch 39; iter: 0; batch classifier loss: 0.171811; batch adversarial loss: 0.416110\n",
      "epoch 40; iter: 0; batch classifier loss: 0.131337; batch adversarial loss: 0.473636\n",
      "epoch 41; iter: 0; batch classifier loss: 0.091626; batch adversarial loss: 0.352899\n",
      "epoch 42; iter: 0; batch classifier loss: 0.170848; batch adversarial loss: 0.406540\n",
      "epoch 43; iter: 0; batch classifier loss: 0.096108; batch adversarial loss: 0.472537\n",
      "epoch 44; iter: 0; batch classifier loss: 0.128901; batch adversarial loss: 0.394900\n",
      "epoch 45; iter: 0; batch classifier loss: 0.109974; batch adversarial loss: 0.418651\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126015; batch adversarial loss: 0.466395\n",
      "epoch 47; iter: 0; batch classifier loss: 0.080218; batch adversarial loss: 0.395235\n",
      "epoch 48; iter: 0; batch classifier loss: 0.067626; batch adversarial loss: 0.433126\n",
      "epoch 49; iter: 0; batch classifier loss: 0.087776; batch adversarial loss: 0.388577\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098725; batch adversarial loss: 0.364973\n",
      "epoch 51; iter: 0; batch classifier loss: 0.118632; batch adversarial loss: 0.471899\n",
      "epoch 52; iter: 0; batch classifier loss: 0.118448; batch adversarial loss: 0.389624\n",
      "epoch 53; iter: 0; batch classifier loss: 0.110769; batch adversarial loss: 0.441326\n",
      "epoch 54; iter: 0; batch classifier loss: 0.107308; batch adversarial loss: 0.447404\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091676; batch adversarial loss: 0.481739\n",
      "epoch 56; iter: 0; batch classifier loss: 0.088376; batch adversarial loss: 0.428534\n",
      "epoch 57; iter: 0; batch classifier loss: 0.169032; batch adversarial loss: 0.396060\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078170; batch adversarial loss: 0.446825\n",
      "epoch 59; iter: 0; batch classifier loss: 0.106634; batch adversarial loss: 0.503207\n",
      "epoch 60; iter: 0; batch classifier loss: 0.103730; batch adversarial loss: 0.400669\n",
      "epoch 61; iter: 0; batch classifier loss: 0.096283; batch adversarial loss: 0.463074\n",
      "epoch 62; iter: 0; batch classifier loss: 0.074497; batch adversarial loss: 0.378635\n",
      "epoch 63; iter: 0; batch classifier loss: 0.060167; batch adversarial loss: 0.390916\n",
      "epoch 64; iter: 0; batch classifier loss: 0.115271; batch adversarial loss: 0.453574\n",
      "epoch 65; iter: 0; batch classifier loss: 0.066809; batch adversarial loss: 0.348407\n",
      "epoch 66; iter: 0; batch classifier loss: 0.076934; batch adversarial loss: 0.438343\n",
      "epoch 67; iter: 0; batch classifier loss: 0.138299; batch adversarial loss: 0.411659\n",
      "epoch 68; iter: 0; batch classifier loss: 0.101258; batch adversarial loss: 0.425201\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070279; batch adversarial loss: 0.418127\n",
      "epoch 70; iter: 0; batch classifier loss: 0.123310; batch adversarial loss: 0.395883\n",
      "epoch 71; iter: 0; batch classifier loss: 0.088728; batch adversarial loss: 0.427145\n",
      "epoch 72; iter: 0; batch classifier loss: 0.084791; batch adversarial loss: 0.432480\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065742; batch adversarial loss: 0.438406\n",
      "epoch 74; iter: 0; batch classifier loss: 0.092413; batch adversarial loss: 0.409501\n",
      "epoch 75; iter: 0; batch classifier loss: 0.118113; batch adversarial loss: 0.422621\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073902; batch adversarial loss: 0.435638\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076797; batch adversarial loss: 0.365898\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073761; batch adversarial loss: 0.457030\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071616; batch adversarial loss: 0.410211\n",
      "epoch 80; iter: 0; batch classifier loss: 0.096296; batch adversarial loss: 0.411224\n",
      "epoch 81; iter: 0; batch classifier loss: 0.105832; batch adversarial loss: 0.402158\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062384; batch adversarial loss: 0.449120\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070852; batch adversarial loss: 0.342986\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075320; batch adversarial loss: 0.360566\n",
      "epoch 85; iter: 0; batch classifier loss: 0.148606; batch adversarial loss: 0.455053\n",
      "epoch 86; iter: 0; batch classifier loss: 0.107352; batch adversarial loss: 0.399710\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057617; batch adversarial loss: 0.407248\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064341; batch adversarial loss: 0.451742\n",
      "epoch 89; iter: 0; batch classifier loss: 0.100986; batch adversarial loss: 0.352559\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061558; batch adversarial loss: 0.375156\n",
      "epoch 91; iter: 0; batch classifier loss: 0.101050; batch adversarial loss: 0.484352\n",
      "epoch 92; iter: 0; batch classifier loss: 0.081849; batch adversarial loss: 0.428867\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080215; batch adversarial loss: 0.449859\n",
      "epoch 94; iter: 0; batch classifier loss: 0.104360; batch adversarial loss: 0.410032\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052073; batch adversarial loss: 0.381307\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043717; batch adversarial loss: 0.437316\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069399; batch adversarial loss: 0.454289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.050438; batch adversarial loss: 0.372869\n",
      "epoch 99; iter: 0; batch classifier loss: 0.070677; batch adversarial loss: 0.459523\n",
      "epoch 100; iter: 0; batch classifier loss: 0.052630; batch adversarial loss: 0.430367\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070350; batch adversarial loss: 0.518998\n",
      "epoch 102; iter: 0; batch classifier loss: 0.074188; batch adversarial loss: 0.450733\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035929; batch adversarial loss: 0.468156\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066013; batch adversarial loss: 0.453549\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041895; batch adversarial loss: 0.353826\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071961; batch adversarial loss: 0.379452\n",
      "epoch 107; iter: 0; batch classifier loss: 0.060546; batch adversarial loss: 0.401504\n",
      "epoch 108; iter: 0; batch classifier loss: 0.103822; batch adversarial loss: 0.471504\n",
      "epoch 109; iter: 0; batch classifier loss: 0.069687; batch adversarial loss: 0.459308\n",
      "epoch 110; iter: 0; batch classifier loss: 0.074449; batch adversarial loss: 0.446432\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049547; batch adversarial loss: 0.448566\n",
      "epoch 112; iter: 0; batch classifier loss: 0.064165; batch adversarial loss: 0.436958\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071702; batch adversarial loss: 0.422845\n",
      "epoch 114; iter: 0; batch classifier loss: 0.070124; batch adversarial loss: 0.392779\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048909; batch adversarial loss: 0.380878\n",
      "epoch 116; iter: 0; batch classifier loss: 0.109063; batch adversarial loss: 0.566658\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052711; batch adversarial loss: 0.422536\n",
      "epoch 118; iter: 0; batch classifier loss: 0.066082; batch adversarial loss: 0.465861\n",
      "epoch 119; iter: 0; batch classifier loss: 0.084917; batch adversarial loss: 0.434448\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050741; batch adversarial loss: 0.385803\n",
      "epoch 121; iter: 0; batch classifier loss: 0.067000; batch adversarial loss: 0.383361\n",
      "epoch 122; iter: 0; batch classifier loss: 0.095307; batch adversarial loss: 0.462321\n",
      "epoch 123; iter: 0; batch classifier loss: 0.073411; batch adversarial loss: 0.468288\n",
      "epoch 124; iter: 0; batch classifier loss: 0.056187; batch adversarial loss: 0.390073\n",
      "epoch 125; iter: 0; batch classifier loss: 0.096196; batch adversarial loss: 0.481100\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039187; batch adversarial loss: 0.442359\n",
      "epoch 127; iter: 0; batch classifier loss: 0.086964; batch adversarial loss: 0.437607\n",
      "epoch 128; iter: 0; batch classifier loss: 0.083012; batch adversarial loss: 0.396716\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041173; batch adversarial loss: 0.436272\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047779; batch adversarial loss: 0.384653\n",
      "epoch 131; iter: 0; batch classifier loss: 0.067849; batch adversarial loss: 0.443423\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037622; batch adversarial loss: 0.480789\n",
      "epoch 133; iter: 0; batch classifier loss: 0.050526; batch adversarial loss: 0.464407\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049972; batch adversarial loss: 0.364485\n",
      "epoch 135; iter: 0; batch classifier loss: 0.066150; batch adversarial loss: 0.470169\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049727; batch adversarial loss: 0.416803\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040377; batch adversarial loss: 0.426893\n",
      "epoch 138; iter: 0; batch classifier loss: 0.067134; batch adversarial loss: 0.429020\n",
      "epoch 139; iter: 0; batch classifier loss: 0.056307; batch adversarial loss: 0.482363\n",
      "epoch 140; iter: 0; batch classifier loss: 0.056716; batch adversarial loss: 0.487966\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032366; batch adversarial loss: 0.515451\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025685; batch adversarial loss: 0.431421\n",
      "epoch 143; iter: 0; batch classifier loss: 0.048052; batch adversarial loss: 0.422006\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039299; batch adversarial loss: 0.498862\n",
      "epoch 145; iter: 0; batch classifier loss: 0.051891; batch adversarial loss: 0.469043\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042605; batch adversarial loss: 0.513714\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039068; batch adversarial loss: 0.311335\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017278; batch adversarial loss: 0.450375\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030744; batch adversarial loss: 0.469928\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032095; batch adversarial loss: 0.514786\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021557; batch adversarial loss: 0.412894\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036786; batch adversarial loss: 0.419075\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020137; batch adversarial loss: 0.371586\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033872; batch adversarial loss: 0.387024\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018073; batch adversarial loss: 0.438317\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045026; batch adversarial loss: 0.316621\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029482; batch adversarial loss: 0.489635\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019297; batch adversarial loss: 0.515138\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041219; batch adversarial loss: 0.486088\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031930; batch adversarial loss: 0.475611\n",
      "epoch 161; iter: 0; batch classifier loss: 0.076164; batch adversarial loss: 0.625182\n",
      "epoch 162; iter: 0; batch classifier loss: 0.059953; batch adversarial loss: 0.666079\n",
      "epoch 163; iter: 0; batch classifier loss: 0.092515; batch adversarial loss: 0.565940\n",
      "epoch 164; iter: 0; batch classifier loss: 0.065754; batch adversarial loss: 0.618935\n",
      "epoch 165; iter: 0; batch classifier loss: 0.111896; batch adversarial loss: 0.674200\n",
      "epoch 166; iter: 0; batch classifier loss: 0.120069; batch adversarial loss: 0.816741\n",
      "epoch 167; iter: 0; batch classifier loss: 0.183101; batch adversarial loss: 0.848812\n",
      "epoch 168; iter: 0; batch classifier loss: 0.102005; batch adversarial loss: 0.605230\n",
      "epoch 169; iter: 0; batch classifier loss: 0.179234; batch adversarial loss: 0.864820\n",
      "epoch 170; iter: 0; batch classifier loss: 0.128998; batch adversarial loss: 0.646396\n",
      "epoch 171; iter: 0; batch classifier loss: 0.123462; batch adversarial loss: 0.629250\n",
      "epoch 172; iter: 0; batch classifier loss: 0.205391; batch adversarial loss: 0.832505\n",
      "epoch 173; iter: 0; batch classifier loss: 0.134990; batch adversarial loss: 0.676084\n",
      "epoch 174; iter: 0; batch classifier loss: 0.111055; batch adversarial loss: 0.505221\n",
      "epoch 175; iter: 0; batch classifier loss: 0.116123; batch adversarial loss: 0.541409\n",
      "epoch 176; iter: 0; batch classifier loss: 0.162282; batch adversarial loss: 0.631971\n",
      "epoch 177; iter: 0; batch classifier loss: 0.151914; batch adversarial loss: 0.703883\n",
      "epoch 178; iter: 0; batch classifier loss: 0.171424; batch adversarial loss: 0.601356\n",
      "epoch 179; iter: 0; batch classifier loss: 0.192863; batch adversarial loss: 0.612355\n",
      "epoch 180; iter: 0; batch classifier loss: 0.186453; batch adversarial loss: 0.637872\n",
      "epoch 181; iter: 0; batch classifier loss: 0.215707; batch adversarial loss: 0.696135\n",
      "epoch 182; iter: 0; batch classifier loss: 0.161598; batch adversarial loss: 0.630181\n",
      "epoch 183; iter: 0; batch classifier loss: 0.232670; batch adversarial loss: 0.853670\n",
      "epoch 184; iter: 0; batch classifier loss: 0.165937; batch adversarial loss: 0.623678\n",
      "epoch 185; iter: 0; batch classifier loss: 0.169712; batch adversarial loss: 0.624297\n",
      "epoch 186; iter: 0; batch classifier loss: 0.183627; batch adversarial loss: 0.610918\n",
      "epoch 187; iter: 0; batch classifier loss: 0.171792; batch adversarial loss: 0.543290\n",
      "epoch 188; iter: 0; batch classifier loss: 0.256707; batch adversarial loss: 0.885408\n",
      "epoch 189; iter: 0; batch classifier loss: 0.156477; batch adversarial loss: 0.540169\n",
      "epoch 190; iter: 0; batch classifier loss: 0.174955; batch adversarial loss: 0.553225\n",
      "epoch 191; iter: 0; batch classifier loss: 0.149795; batch adversarial loss: 0.530015\n",
      "epoch 192; iter: 0; batch classifier loss: 0.150745; batch adversarial loss: 0.536024\n",
      "epoch 193; iter: 0; batch classifier loss: 0.213560; batch adversarial loss: 0.613018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.205202; batch adversarial loss: 0.608215\n",
      "epoch 195; iter: 0; batch classifier loss: 0.222477; batch adversarial loss: 0.663275\n",
      "epoch 196; iter: 0; batch classifier loss: 0.105342; batch adversarial loss: 0.501960\n",
      "epoch 197; iter: 0; batch classifier loss: 0.135464; batch adversarial loss: 0.571497\n",
      "epoch 198; iter: 0; batch classifier loss: 0.141394; batch adversarial loss: 0.523688\n",
      "epoch 199; iter: 0; batch classifier loss: 0.184964; batch adversarial loss: 0.601003\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685813; batch adversarial loss: 0.604207\n",
      "epoch 1; iter: 0; batch classifier loss: 0.457542; batch adversarial loss: 0.660954\n",
      "epoch 2; iter: 0; batch classifier loss: 0.368873; batch adversarial loss: 0.608523\n",
      "epoch 3; iter: 0; batch classifier loss: 0.448714; batch adversarial loss: 0.579148\n",
      "epoch 4; iter: 0; batch classifier loss: 0.345604; batch adversarial loss: 0.580691\n",
      "epoch 5; iter: 0; batch classifier loss: 0.482157; batch adversarial loss: 0.531517\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322077; batch adversarial loss: 0.558771\n",
      "epoch 7; iter: 0; batch classifier loss: 0.361624; batch adversarial loss: 0.522298\n",
      "epoch 8; iter: 0; batch classifier loss: 0.342982; batch adversarial loss: 0.510738\n",
      "epoch 9; iter: 0; batch classifier loss: 0.383779; batch adversarial loss: 0.561531\n",
      "epoch 10; iter: 0; batch classifier loss: 0.257021; batch adversarial loss: 0.514798\n",
      "epoch 11; iter: 0; batch classifier loss: 0.316351; batch adversarial loss: 0.514763\n",
      "epoch 12; iter: 0; batch classifier loss: 0.238797; batch adversarial loss: 0.487335\n",
      "epoch 13; iter: 0; batch classifier loss: 0.287052; batch adversarial loss: 0.512728\n",
      "epoch 14; iter: 0; batch classifier loss: 0.298090; batch adversarial loss: 0.479820\n",
      "epoch 15; iter: 0; batch classifier loss: 0.224248; batch adversarial loss: 0.536237\n",
      "epoch 16; iter: 0; batch classifier loss: 0.260085; batch adversarial loss: 0.582415\n",
      "epoch 17; iter: 0; batch classifier loss: 0.226652; batch adversarial loss: 0.538991\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237112; batch adversarial loss: 0.487536\n",
      "epoch 19; iter: 0; batch classifier loss: 0.216115; batch adversarial loss: 0.517745\n",
      "epoch 20; iter: 0; batch classifier loss: 0.247740; batch adversarial loss: 0.511930\n",
      "epoch 21; iter: 0; batch classifier loss: 0.221277; batch adversarial loss: 0.439679\n",
      "epoch 22; iter: 0; batch classifier loss: 0.180643; batch adversarial loss: 0.519355\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168203; batch adversarial loss: 0.458188\n",
      "epoch 24; iter: 0; batch classifier loss: 0.173105; batch adversarial loss: 0.499332\n",
      "epoch 25; iter: 0; batch classifier loss: 0.169064; batch adversarial loss: 0.454943\n",
      "epoch 26; iter: 0; batch classifier loss: 0.136278; batch adversarial loss: 0.551995\n",
      "epoch 27; iter: 0; batch classifier loss: 0.153567; batch adversarial loss: 0.524547\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217026; batch adversarial loss: 0.415217\n",
      "epoch 29; iter: 0; batch classifier loss: 0.216332; batch adversarial loss: 0.459794\n",
      "epoch 30; iter: 0; batch classifier loss: 0.177992; batch adversarial loss: 0.417588\n",
      "epoch 31; iter: 0; batch classifier loss: 0.205371; batch adversarial loss: 0.395196\n",
      "epoch 32; iter: 0; batch classifier loss: 0.185481; batch adversarial loss: 0.395220\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163374; batch adversarial loss: 0.445589\n",
      "epoch 34; iter: 0; batch classifier loss: 0.261646; batch adversarial loss: 0.422153\n",
      "epoch 35; iter: 0; batch classifier loss: 0.236250; batch adversarial loss: 0.498642\n",
      "epoch 36; iter: 0; batch classifier loss: 0.228810; batch adversarial loss: 0.475390\n",
      "epoch 37; iter: 0; batch classifier loss: 0.180652; batch adversarial loss: 0.463120\n",
      "epoch 38; iter: 0; batch classifier loss: 0.242721; batch adversarial loss: 0.497718\n",
      "epoch 39; iter: 0; batch classifier loss: 0.230251; batch adversarial loss: 0.489302\n",
      "epoch 40; iter: 0; batch classifier loss: 0.192754; batch adversarial loss: 0.486742\n",
      "epoch 41; iter: 0; batch classifier loss: 0.129063; batch adversarial loss: 0.564983\n",
      "epoch 42; iter: 0; batch classifier loss: 0.253006; batch adversarial loss: 0.473957\n",
      "epoch 43; iter: 0; batch classifier loss: 0.238520; batch adversarial loss: 0.452780\n",
      "epoch 44; iter: 0; batch classifier loss: 0.294039; batch adversarial loss: 0.488434\n",
      "epoch 45; iter: 0; batch classifier loss: 0.185716; batch adversarial loss: 0.495279\n",
      "epoch 46; iter: 0; batch classifier loss: 0.187931; batch adversarial loss: 0.436588\n",
      "epoch 47; iter: 0; batch classifier loss: 0.185238; batch adversarial loss: 0.450295\n",
      "epoch 48; iter: 0; batch classifier loss: 0.267853; batch adversarial loss: 0.385720\n",
      "epoch 49; iter: 0; batch classifier loss: 0.277662; batch adversarial loss: 0.462088\n",
      "epoch 50; iter: 0; batch classifier loss: 0.220078; batch adversarial loss: 0.472772\n",
      "epoch 51; iter: 0; batch classifier loss: 0.191056; batch adversarial loss: 0.458003\n",
      "epoch 52; iter: 0; batch classifier loss: 0.175461; batch adversarial loss: 0.445563\n",
      "epoch 53; iter: 0; batch classifier loss: 0.285256; batch adversarial loss: 0.494974\n",
      "epoch 54; iter: 0; batch classifier loss: 0.260980; batch adversarial loss: 0.411094\n",
      "epoch 55; iter: 0; batch classifier loss: 0.170635; batch adversarial loss: 0.459148\n",
      "epoch 56; iter: 0; batch classifier loss: 0.144632; batch adversarial loss: 0.409588\n",
      "epoch 57; iter: 0; batch classifier loss: 0.118924; batch adversarial loss: 0.470167\n",
      "epoch 58; iter: 0; batch classifier loss: 0.211750; batch adversarial loss: 0.499453\n",
      "epoch 59; iter: 0; batch classifier loss: 0.150307; batch adversarial loss: 0.496359\n",
      "epoch 60; iter: 0; batch classifier loss: 0.164814; batch adversarial loss: 0.395913\n",
      "epoch 61; iter: 0; batch classifier loss: 0.168534; batch adversarial loss: 0.447913\n",
      "epoch 62; iter: 0; batch classifier loss: 0.248963; batch adversarial loss: 0.559129\n",
      "epoch 63; iter: 0; batch classifier loss: 0.206815; batch adversarial loss: 0.433584\n",
      "epoch 64; iter: 0; batch classifier loss: 0.171217; batch adversarial loss: 0.496080\n",
      "epoch 65; iter: 0; batch classifier loss: 0.193265; batch adversarial loss: 0.446283\n",
      "epoch 66; iter: 0; batch classifier loss: 0.127565; batch adversarial loss: 0.421913\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059816; batch adversarial loss: 0.406906\n",
      "epoch 68; iter: 0; batch classifier loss: 0.067202; batch adversarial loss: 0.522899\n",
      "epoch 69; iter: 0; batch classifier loss: 0.055940; batch adversarial loss: 0.463756\n",
      "epoch 70; iter: 0; batch classifier loss: 0.057061; batch adversarial loss: 0.415845\n",
      "epoch 71; iter: 0; batch classifier loss: 0.062992; batch adversarial loss: 0.452031\n",
      "epoch 72; iter: 0; batch classifier loss: 0.063630; batch adversarial loss: 0.525748\n",
      "epoch 73; iter: 0; batch classifier loss: 0.115646; batch adversarial loss: 0.498927\n",
      "epoch 74; iter: 0; batch classifier loss: 0.074102; batch adversarial loss: 0.310210\n",
      "epoch 75; iter: 0; batch classifier loss: 0.093115; batch adversarial loss: 0.394390\n",
      "epoch 76; iter: 0; batch classifier loss: 0.133274; batch adversarial loss: 0.425897\n",
      "epoch 77; iter: 0; batch classifier loss: 0.077628; batch adversarial loss: 0.487923\n",
      "epoch 78; iter: 0; batch classifier loss: 0.099925; batch adversarial loss: 0.416721\n",
      "epoch 79; iter: 0; batch classifier loss: 0.109161; batch adversarial loss: 0.410866\n",
      "epoch 80; iter: 0; batch classifier loss: 0.103954; batch adversarial loss: 0.496098\n",
      "epoch 81; iter: 0; batch classifier loss: 0.109312; batch adversarial loss: 0.422515\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083688; batch adversarial loss: 0.432473\n",
      "epoch 83; iter: 0; batch classifier loss: 0.037199; batch adversarial loss: 0.370922\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064171; batch adversarial loss: 0.395880\n",
      "epoch 85; iter: 0; batch classifier loss: 0.062039; batch adversarial loss: 0.437448\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062054; batch adversarial loss: 0.456461\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071775; batch adversarial loss: 0.451000\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057102; batch adversarial loss: 0.441421\n",
      "epoch 89; iter: 0; batch classifier loss: 0.070399; batch adversarial loss: 0.441985\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054694; batch adversarial loss: 0.506078\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081994; batch adversarial loss: 0.403504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.059714; batch adversarial loss: 0.365830\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054383; batch adversarial loss: 0.543843\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039865; batch adversarial loss: 0.518749\n",
      "epoch 95; iter: 0; batch classifier loss: 0.108702; batch adversarial loss: 0.453624\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055689; batch adversarial loss: 0.471658\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062234; batch adversarial loss: 0.405495\n",
      "epoch 98; iter: 0; batch classifier loss: 0.075641; batch adversarial loss: 0.461259\n",
      "epoch 99; iter: 0; batch classifier loss: 0.075201; batch adversarial loss: 0.417785\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059887; batch adversarial loss: 0.430129\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051962; batch adversarial loss: 0.434018\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059046; batch adversarial loss: 0.437190\n",
      "epoch 103; iter: 0; batch classifier loss: 0.065359; batch adversarial loss: 0.344073\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065684; batch adversarial loss: 0.387821\n",
      "epoch 105; iter: 0; batch classifier loss: 0.070590; batch adversarial loss: 0.483102\n",
      "epoch 106; iter: 0; batch classifier loss: 0.087686; batch adversarial loss: 0.486248\n",
      "epoch 107; iter: 0; batch classifier loss: 0.054462; batch adversarial loss: 0.492463\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073181; batch adversarial loss: 0.442009\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046819; batch adversarial loss: 0.328745\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067439; batch adversarial loss: 0.455849\n",
      "epoch 111; iter: 0; batch classifier loss: 0.056848; batch adversarial loss: 0.437602\n",
      "epoch 112; iter: 0; batch classifier loss: 0.062967; batch adversarial loss: 0.401596\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046234; batch adversarial loss: 0.424909\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053717; batch adversarial loss: 0.439118\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048284; batch adversarial loss: 0.330846\n",
      "epoch 116; iter: 0; batch classifier loss: 0.072110; batch adversarial loss: 0.407276\n",
      "epoch 117; iter: 0; batch classifier loss: 0.066001; batch adversarial loss: 0.433524\n",
      "epoch 118; iter: 0; batch classifier loss: 0.072165; batch adversarial loss: 0.387208\n",
      "epoch 119; iter: 0; batch classifier loss: 0.093260; batch adversarial loss: 0.424239\n",
      "epoch 120; iter: 0; batch classifier loss: 0.068917; batch adversarial loss: 0.509848\n",
      "epoch 121; iter: 0; batch classifier loss: 0.082847; batch adversarial loss: 0.437164\n",
      "epoch 122; iter: 0; batch classifier loss: 0.064071; batch adversarial loss: 0.403591\n",
      "epoch 123; iter: 0; batch classifier loss: 0.091107; batch adversarial loss: 0.477905\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057519; batch adversarial loss: 0.437107\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041370; batch adversarial loss: 0.367097\n",
      "epoch 126; iter: 0; batch classifier loss: 0.069667; batch adversarial loss: 0.478308\n",
      "epoch 127; iter: 0; batch classifier loss: 0.062262; batch adversarial loss: 0.545927\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055354; batch adversarial loss: 0.333649\n",
      "epoch 129; iter: 0; batch classifier loss: 0.058246; batch adversarial loss: 0.399790\n",
      "epoch 130; iter: 0; batch classifier loss: 0.075992; batch adversarial loss: 0.412581\n",
      "epoch 131; iter: 0; batch classifier loss: 0.057973; batch adversarial loss: 0.454063\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050392; batch adversarial loss: 0.414200\n",
      "epoch 133; iter: 0; batch classifier loss: 0.058044; batch adversarial loss: 0.416800\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057033; batch adversarial loss: 0.337222\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049896; batch adversarial loss: 0.398701\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057136; batch adversarial loss: 0.348973\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042055; batch adversarial loss: 0.363559\n",
      "epoch 138; iter: 0; batch classifier loss: 0.079823; batch adversarial loss: 0.422540\n",
      "epoch 139; iter: 0; batch classifier loss: 0.075842; batch adversarial loss: 0.300291\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030146; batch adversarial loss: 0.459153\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031225; batch adversarial loss: 0.311850\n",
      "epoch 142; iter: 0; batch classifier loss: 0.070197; batch adversarial loss: 0.377858\n",
      "epoch 143; iter: 0; batch classifier loss: 0.054885; batch adversarial loss: 0.417309\n",
      "epoch 144; iter: 0; batch classifier loss: 0.089999; batch adversarial loss: 0.365607\n",
      "epoch 145; iter: 0; batch classifier loss: 0.064256; batch adversarial loss: 0.369112\n",
      "epoch 146; iter: 0; batch classifier loss: 0.046874; batch adversarial loss: 0.438939\n",
      "epoch 147; iter: 0; batch classifier loss: 0.051738; batch adversarial loss: 0.374471\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039507; batch adversarial loss: 0.402929\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039564; batch adversarial loss: 0.442721\n",
      "epoch 150; iter: 0; batch classifier loss: 0.046053; batch adversarial loss: 0.415372\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040021; batch adversarial loss: 0.444652\n",
      "epoch 152; iter: 0; batch classifier loss: 0.066267; batch adversarial loss: 0.440991\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035210; batch adversarial loss: 0.404439\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039659; batch adversarial loss: 0.482722\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023595; batch adversarial loss: 0.491329\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023102; batch adversarial loss: 0.432855\n",
      "epoch 157; iter: 0; batch classifier loss: 0.045210; batch adversarial loss: 0.403606\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021266; batch adversarial loss: 0.428430\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045670; batch adversarial loss: 0.336652\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036967; batch adversarial loss: 0.370905\n",
      "epoch 161; iter: 0; batch classifier loss: 0.046955; batch adversarial loss: 0.432054\n",
      "epoch 162; iter: 0; batch classifier loss: 0.056400; batch adversarial loss: 0.411902\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024722; batch adversarial loss: 0.364947\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037714; batch adversarial loss: 0.428898\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023255; batch adversarial loss: 0.377759\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035483; batch adversarial loss: 0.437437\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025212; batch adversarial loss: 0.473910\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033260; batch adversarial loss: 0.413460\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025930; batch adversarial loss: 0.401994\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025885; batch adversarial loss: 0.468646\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040953; batch adversarial loss: 0.387748\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028079; batch adversarial loss: 0.366737\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025305; batch adversarial loss: 0.413756\n",
      "epoch 174; iter: 0; batch classifier loss: 0.034942; batch adversarial loss: 0.460165\n",
      "epoch 175; iter: 0; batch classifier loss: 0.053243; batch adversarial loss: 0.432969\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023315; batch adversarial loss: 0.456279\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020913; batch adversarial loss: 0.450689\n",
      "epoch 178; iter: 0; batch classifier loss: 0.056710; batch adversarial loss: 0.398574\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044088; batch adversarial loss: 0.434389\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027916; batch adversarial loss: 0.491070\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025100; batch adversarial loss: 0.444368\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023387; batch adversarial loss: 0.451876\n",
      "epoch 183; iter: 0; batch classifier loss: 0.044040; batch adversarial loss: 0.452941\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028629; batch adversarial loss: 0.429957\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014531; batch adversarial loss: 0.446470\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028844; batch adversarial loss: 0.437809\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032168; batch adversarial loss: 0.422042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.020776; batch adversarial loss: 0.436269\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041168; batch adversarial loss: 0.488703\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017985; batch adversarial loss: 0.406437\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030442; batch adversarial loss: 0.472975\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040680; batch adversarial loss: 0.349820\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020550; batch adversarial loss: 0.391539\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035825; batch adversarial loss: 0.484912\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015332; batch adversarial loss: 0.446112\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037767; batch adversarial loss: 0.431508\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032949; batch adversarial loss: 0.436980\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027336; batch adversarial loss: 0.440712\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023204; batch adversarial loss: 0.315762\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671544; batch adversarial loss: 0.637421\n",
      "epoch 1; iter: 0; batch classifier loss: 0.498382; batch adversarial loss: 0.595345\n",
      "epoch 2; iter: 0; batch classifier loss: 0.521889; batch adversarial loss: 0.609273\n",
      "epoch 3; iter: 0; batch classifier loss: 0.367669; batch adversarial loss: 0.566759\n",
      "epoch 4; iter: 0; batch classifier loss: 0.313100; batch adversarial loss: 0.553273\n",
      "epoch 5; iter: 0; batch classifier loss: 0.311920; batch adversarial loss: 0.557805\n",
      "epoch 6; iter: 0; batch classifier loss: 0.348010; batch adversarial loss: 0.538301\n",
      "epoch 7; iter: 0; batch classifier loss: 0.294220; batch adversarial loss: 0.538484\n",
      "epoch 8; iter: 0; batch classifier loss: 0.324523; batch adversarial loss: 0.483401\n",
      "epoch 9; iter: 0; batch classifier loss: 0.319717; batch adversarial loss: 0.518125\n",
      "epoch 10; iter: 0; batch classifier loss: 0.336891; batch adversarial loss: 0.510385\n",
      "epoch 11; iter: 0; batch classifier loss: 0.210535; batch adversarial loss: 0.525762\n",
      "epoch 12; iter: 0; batch classifier loss: 0.252197; batch adversarial loss: 0.465703\n",
      "epoch 13; iter: 0; batch classifier loss: 0.249276; batch adversarial loss: 0.569364\n",
      "epoch 14; iter: 0; batch classifier loss: 0.260560; batch adversarial loss: 0.486466\n",
      "epoch 15; iter: 0; batch classifier loss: 0.242317; batch adversarial loss: 0.499852\n",
      "epoch 16; iter: 0; batch classifier loss: 0.221734; batch adversarial loss: 0.420843\n",
      "epoch 17; iter: 0; batch classifier loss: 0.197680; batch adversarial loss: 0.481918\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268925; batch adversarial loss: 0.485889\n",
      "epoch 19; iter: 0; batch classifier loss: 0.217525; batch adversarial loss: 0.488365\n",
      "epoch 20; iter: 0; batch classifier loss: 0.203700; batch adversarial loss: 0.485739\n",
      "epoch 21; iter: 0; batch classifier loss: 0.103066; batch adversarial loss: 0.523221\n",
      "epoch 22; iter: 0; batch classifier loss: 0.171318; batch adversarial loss: 0.500881\n",
      "epoch 23; iter: 0; batch classifier loss: 0.158790; batch adversarial loss: 0.430901\n",
      "epoch 24; iter: 0; batch classifier loss: 0.121828; batch adversarial loss: 0.426726\n",
      "epoch 25; iter: 0; batch classifier loss: 0.129699; batch adversarial loss: 0.487206\n",
      "epoch 26; iter: 0; batch classifier loss: 0.139485; batch adversarial loss: 0.475464\n",
      "epoch 27; iter: 0; batch classifier loss: 0.144748; batch adversarial loss: 0.449605\n",
      "epoch 28; iter: 0; batch classifier loss: 0.092371; batch adversarial loss: 0.568414\n",
      "epoch 29; iter: 0; batch classifier loss: 0.172808; batch adversarial loss: 0.466392\n",
      "epoch 30; iter: 0; batch classifier loss: 0.140122; batch adversarial loss: 0.512701\n",
      "epoch 31; iter: 0; batch classifier loss: 0.100121; batch adversarial loss: 0.415924\n",
      "epoch 32; iter: 0; batch classifier loss: 0.174109; batch adversarial loss: 0.482116\n",
      "epoch 33; iter: 0; batch classifier loss: 0.181738; batch adversarial loss: 0.433748\n",
      "epoch 34; iter: 0; batch classifier loss: 0.150858; batch adversarial loss: 0.457544\n",
      "epoch 35; iter: 0; batch classifier loss: 0.119471; batch adversarial loss: 0.416448\n",
      "epoch 36; iter: 0; batch classifier loss: 0.149700; batch adversarial loss: 0.489679\n",
      "epoch 37; iter: 0; batch classifier loss: 0.093133; batch adversarial loss: 0.435200\n",
      "epoch 38; iter: 0; batch classifier loss: 0.091602; batch adversarial loss: 0.669555\n",
      "epoch 39; iter: 0; batch classifier loss: 0.098421; batch adversarial loss: 0.488951\n",
      "epoch 40; iter: 0; batch classifier loss: 0.178514; batch adversarial loss: 0.504451\n",
      "epoch 41; iter: 0; batch classifier loss: 0.080044; batch adversarial loss: 0.445280\n",
      "epoch 42; iter: 0; batch classifier loss: 0.090794; batch adversarial loss: 0.586628\n",
      "epoch 43; iter: 0; batch classifier loss: 0.221149; batch adversarial loss: 0.465560\n",
      "epoch 44; iter: 0; batch classifier loss: 0.158168; batch adversarial loss: 0.402010\n",
      "epoch 45; iter: 0; batch classifier loss: 0.156978; batch adversarial loss: 0.497580\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127052; batch adversarial loss: 0.522595\n",
      "epoch 47; iter: 0; batch classifier loss: 0.211907; batch adversarial loss: 0.467971\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082288; batch adversarial loss: 0.529566\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107728; batch adversarial loss: 0.441318\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119141; batch adversarial loss: 0.449267\n",
      "epoch 51; iter: 0; batch classifier loss: 0.108138; batch adversarial loss: 0.459778\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111992; batch adversarial loss: 0.482723\n",
      "epoch 53; iter: 0; batch classifier loss: 0.222406; batch adversarial loss: 0.425199\n",
      "epoch 54; iter: 0; batch classifier loss: 0.150274; batch adversarial loss: 0.450133\n",
      "epoch 55; iter: 0; batch classifier loss: 0.134784; batch adversarial loss: 0.371000\n",
      "epoch 56; iter: 0; batch classifier loss: 0.118697; batch adversarial loss: 0.473893\n",
      "epoch 57; iter: 0; batch classifier loss: 0.125172; batch adversarial loss: 0.446386\n",
      "epoch 58; iter: 0; batch classifier loss: 0.107093; batch adversarial loss: 0.576902\n",
      "epoch 59; iter: 0; batch classifier loss: 0.117471; batch adversarial loss: 0.325576\n",
      "epoch 60; iter: 0; batch classifier loss: 0.134554; batch adversarial loss: 0.509943\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114675; batch adversarial loss: 0.487285\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101518; batch adversarial loss: 0.490327\n",
      "epoch 63; iter: 0; batch classifier loss: 0.158853; batch adversarial loss: 0.512921\n",
      "epoch 64; iter: 0; batch classifier loss: 0.140563; batch adversarial loss: 0.428748\n",
      "epoch 65; iter: 0; batch classifier loss: 0.142945; batch adversarial loss: 0.451578\n",
      "epoch 66; iter: 0; batch classifier loss: 0.169936; batch adversarial loss: 0.435929\n",
      "epoch 67; iter: 0; batch classifier loss: 0.117814; batch adversarial loss: 0.457412\n",
      "epoch 68; iter: 0; batch classifier loss: 0.153725; batch adversarial loss: 0.494311\n",
      "epoch 69; iter: 0; batch classifier loss: 0.140768; batch adversarial loss: 0.495598\n",
      "epoch 70; iter: 0; batch classifier loss: 0.126038; batch adversarial loss: 0.532947\n",
      "epoch 71; iter: 0; batch classifier loss: 0.116847; batch adversarial loss: 0.351820\n",
      "epoch 72; iter: 0; batch classifier loss: 0.125617; batch adversarial loss: 0.561463\n",
      "epoch 73; iter: 0; batch classifier loss: 0.158388; batch adversarial loss: 0.480657\n",
      "epoch 74; iter: 0; batch classifier loss: 0.130129; batch adversarial loss: 0.369423\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075756; batch adversarial loss: 0.379107\n",
      "epoch 76; iter: 0; batch classifier loss: 0.104953; batch adversarial loss: 0.456598\n",
      "epoch 77; iter: 0; batch classifier loss: 0.133047; batch adversarial loss: 0.471190\n",
      "epoch 78; iter: 0; batch classifier loss: 0.141558; batch adversarial loss: 0.468483\n",
      "epoch 79; iter: 0; batch classifier loss: 0.118255; batch adversarial loss: 0.492201\n",
      "epoch 80; iter: 0; batch classifier loss: 0.138068; batch adversarial loss: 0.426986\n",
      "epoch 81; iter: 0; batch classifier loss: 0.078082; batch adversarial loss: 0.517889\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072743; batch adversarial loss: 0.505998\n",
      "epoch 83; iter: 0; batch classifier loss: 0.122084; batch adversarial loss: 0.480892\n",
      "epoch 84; iter: 0; batch classifier loss: 0.172058; batch adversarial loss: 0.338439\n",
      "epoch 85; iter: 0; batch classifier loss: 0.082432; batch adversarial loss: 0.531554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.106103; batch adversarial loss: 0.455131\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068472; batch adversarial loss: 0.465249\n",
      "epoch 88; iter: 0; batch classifier loss: 0.081433; batch adversarial loss: 0.514102\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063835; batch adversarial loss: 0.520982\n",
      "epoch 90; iter: 0; batch classifier loss: 0.090432; batch adversarial loss: 0.451797\n",
      "epoch 91; iter: 0; batch classifier loss: 0.118753; batch adversarial loss: 0.456125\n",
      "epoch 92; iter: 0; batch classifier loss: 0.090040; batch adversarial loss: 0.540547\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071657; batch adversarial loss: 0.552854\n",
      "epoch 94; iter: 0; batch classifier loss: 0.059643; batch adversarial loss: 0.446016\n",
      "epoch 95; iter: 0; batch classifier loss: 0.067100; batch adversarial loss: 0.514593\n",
      "epoch 96; iter: 0; batch classifier loss: 0.079905; batch adversarial loss: 0.530430\n",
      "epoch 97; iter: 0; batch classifier loss: 0.089710; batch adversarial loss: 0.483442\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072496; batch adversarial loss: 0.551527\n",
      "epoch 99; iter: 0; batch classifier loss: 0.081765; batch adversarial loss: 0.501064\n",
      "epoch 100; iter: 0; batch classifier loss: 0.086824; batch adversarial loss: 0.474523\n",
      "epoch 101; iter: 0; batch classifier loss: 0.097797; batch adversarial loss: 0.421945\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079622; batch adversarial loss: 0.450779\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061709; batch adversarial loss: 0.408372\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044147; batch adversarial loss: 0.439335\n",
      "epoch 105; iter: 0; batch classifier loss: 0.073888; batch adversarial loss: 0.498661\n",
      "epoch 106; iter: 0; batch classifier loss: 0.070840; batch adversarial loss: 0.454363\n",
      "epoch 107; iter: 0; batch classifier loss: 0.022680; batch adversarial loss: 0.498374\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055430; batch adversarial loss: 0.410063\n",
      "epoch 109; iter: 0; batch classifier loss: 0.084178; batch adversarial loss: 0.455365\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058860; batch adversarial loss: 0.535405\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044560; batch adversarial loss: 0.488831\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047456; batch adversarial loss: 0.402985\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051178; batch adversarial loss: 0.463378\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072166; batch adversarial loss: 0.581045\n",
      "epoch 115; iter: 0; batch classifier loss: 0.067433; batch adversarial loss: 0.460737\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039960; batch adversarial loss: 0.393183\n",
      "epoch 117; iter: 0; batch classifier loss: 0.016556; batch adversarial loss: 0.532150\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042206; batch adversarial loss: 0.528225\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037755; batch adversarial loss: 0.486365\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040580; batch adversarial loss: 0.396442\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046388; batch adversarial loss: 0.389390\n",
      "epoch 122; iter: 0; batch classifier loss: 0.077551; batch adversarial loss: 0.551226\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036623; batch adversarial loss: 0.386533\n",
      "epoch 124; iter: 0; batch classifier loss: 0.045486; batch adversarial loss: 0.365296\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043246; batch adversarial loss: 0.448036\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049497; batch adversarial loss: 0.493520\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022699; batch adversarial loss: 0.505767\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036111; batch adversarial loss: 0.479280\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019839; batch adversarial loss: 0.448063\n",
      "epoch 130; iter: 0; batch classifier loss: 0.015987; batch adversarial loss: 0.441258\n",
      "epoch 131; iter: 0; batch classifier loss: 0.063462; batch adversarial loss: 0.424649\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015855; batch adversarial loss: 0.488412\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034385; batch adversarial loss: 0.479658\n",
      "epoch 134; iter: 0; batch classifier loss: 0.047385; batch adversarial loss: 0.430000\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025886; batch adversarial loss: 0.556259\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044252; batch adversarial loss: 0.463737\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015318; batch adversarial loss: 0.493008\n",
      "epoch 138; iter: 0; batch classifier loss: 0.012674; batch adversarial loss: 0.395737\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013621; batch adversarial loss: 0.505245\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030288; batch adversarial loss: 0.351009\n",
      "epoch 141; iter: 0; batch classifier loss: 0.047984; batch adversarial loss: 0.517247\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034974; batch adversarial loss: 0.516640\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013571; batch adversarial loss: 0.443831\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036952; batch adversarial loss: 0.340748\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024610; batch adversarial loss: 0.464415\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028728; batch adversarial loss: 0.494668\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018563; batch adversarial loss: 0.421309\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030541; batch adversarial loss: 0.483972\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011320; batch adversarial loss: 0.470019\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041086; batch adversarial loss: 0.441423\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038783; batch adversarial loss: 0.422265\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023617; batch adversarial loss: 0.441069\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018674; batch adversarial loss: 0.483202\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046381; batch adversarial loss: 0.431034\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030238; batch adversarial loss: 0.453482\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032333; batch adversarial loss: 0.477432\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042511; batch adversarial loss: 0.463370\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019810; batch adversarial loss: 0.364265\n",
      "epoch 159; iter: 0; batch classifier loss: 0.048951; batch adversarial loss: 0.455825\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008918; batch adversarial loss: 0.522547\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027821; batch adversarial loss: 0.475093\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018043; batch adversarial loss: 0.481658\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007702; batch adversarial loss: 0.497454\n",
      "epoch 164; iter: 0; batch classifier loss: 0.050941; batch adversarial loss: 0.473758\n",
      "epoch 165; iter: 0; batch classifier loss: 0.006978; batch adversarial loss: 0.399276\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013795; batch adversarial loss: 0.485190\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011794; batch adversarial loss: 0.469330\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036568; batch adversarial loss: 0.385594\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021924; batch adversarial loss: 0.439794\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039352; batch adversarial loss: 0.348406\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013972; batch adversarial loss: 0.428501\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007829; batch adversarial loss: 0.442742\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013157; batch adversarial loss: 0.348919\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007716; batch adversarial loss: 0.433249\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021166; batch adversarial loss: 0.469776\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020266; batch adversarial loss: 0.440510\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006954; batch adversarial loss: 0.469589\n",
      "epoch 178; iter: 0; batch classifier loss: 0.004498; batch adversarial loss: 0.479980\n",
      "epoch 179; iter: 0; batch classifier loss: 0.055478; batch adversarial loss: 0.448518\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012279; batch adversarial loss: 0.490920\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032773; batch adversarial loss: 0.487171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.030943; batch adversarial loss: 0.420755\n",
      "epoch 183; iter: 0; batch classifier loss: 0.040913; batch adversarial loss: 0.441099\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008807; batch adversarial loss: 0.528699\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028619; batch adversarial loss: 0.409387\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014650; batch adversarial loss: 0.373094\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012738; batch adversarial loss: 0.430365\n",
      "epoch 188; iter: 0; batch classifier loss: 0.049483; batch adversarial loss: 0.512944\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018786; batch adversarial loss: 0.408603\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031623; batch adversarial loss: 0.396120\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008996; batch adversarial loss: 0.467304\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014801; batch adversarial loss: 0.467293\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007897; batch adversarial loss: 0.437537\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013382; batch adversarial loss: 0.373023\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008500; batch adversarial loss: 0.394034\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029729; batch adversarial loss: 0.437724\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027796; batch adversarial loss: 0.572869\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012850; batch adversarial loss: 0.437123\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011160; batch adversarial loss: 0.499732\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676534; batch adversarial loss: 0.647263\n",
      "epoch 1; iter: 0; batch classifier loss: 0.466733; batch adversarial loss: 0.639429\n",
      "epoch 2; iter: 0; batch classifier loss: 0.452896; batch adversarial loss: 0.605562\n",
      "epoch 3; iter: 0; batch classifier loss: 0.382454; batch adversarial loss: 0.578684\n",
      "epoch 4; iter: 0; batch classifier loss: 0.390150; batch adversarial loss: 0.563957\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343533; batch adversarial loss: 0.563948\n",
      "epoch 6; iter: 0; batch classifier loss: 0.302386; batch adversarial loss: 0.524969\n",
      "epoch 7; iter: 0; batch classifier loss: 0.229805; batch adversarial loss: 0.496858\n",
      "epoch 8; iter: 0; batch classifier loss: 0.253397; batch adversarial loss: 0.526851\n",
      "epoch 9; iter: 0; batch classifier loss: 0.351680; batch adversarial loss: 0.505543\n",
      "epoch 10; iter: 0; batch classifier loss: 0.211091; batch adversarial loss: 0.534837\n",
      "epoch 11; iter: 0; batch classifier loss: 0.279796; batch adversarial loss: 0.513193\n",
      "epoch 12; iter: 0; batch classifier loss: 0.318549; batch adversarial loss: 0.545335\n",
      "epoch 13; iter: 0; batch classifier loss: 0.196109; batch adversarial loss: 0.495026\n",
      "epoch 14; iter: 0; batch classifier loss: 0.193302; batch adversarial loss: 0.520605\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260257; batch adversarial loss: 0.516921\n",
      "epoch 16; iter: 0; batch classifier loss: 0.205724; batch adversarial loss: 0.455347\n",
      "epoch 17; iter: 0; batch classifier loss: 0.183356; batch adversarial loss: 0.446800\n",
      "epoch 18; iter: 0; batch classifier loss: 0.191221; batch adversarial loss: 0.547021\n",
      "epoch 19; iter: 0; batch classifier loss: 0.248863; batch adversarial loss: 0.464934\n",
      "epoch 20; iter: 0; batch classifier loss: 0.285219; batch adversarial loss: 0.537825\n",
      "epoch 21; iter: 0; batch classifier loss: 0.285061; batch adversarial loss: 0.451214\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226540; batch adversarial loss: 0.436058\n",
      "epoch 23; iter: 0; batch classifier loss: 0.314340; batch adversarial loss: 0.530538\n",
      "epoch 24; iter: 0; batch classifier loss: 0.267348; batch adversarial loss: 0.473575\n",
      "epoch 25; iter: 0; batch classifier loss: 0.381049; batch adversarial loss: 0.474214\n",
      "epoch 26; iter: 0; batch classifier loss: 0.409976; batch adversarial loss: 0.462937\n",
      "epoch 27; iter: 0; batch classifier loss: 0.211954; batch adversarial loss: 0.460446\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169152; batch adversarial loss: 0.522621\n",
      "epoch 29; iter: 0; batch classifier loss: 0.087790; batch adversarial loss: 0.540373\n",
      "epoch 30; iter: 0; batch classifier loss: 0.125121; batch adversarial loss: 0.451930\n",
      "epoch 31; iter: 0; batch classifier loss: 0.080513; batch adversarial loss: 0.458877\n",
      "epoch 32; iter: 0; batch classifier loss: 0.106748; batch adversarial loss: 0.518541\n",
      "epoch 33; iter: 0; batch classifier loss: 0.110029; batch adversarial loss: 0.539132\n",
      "epoch 34; iter: 0; batch classifier loss: 0.163910; batch adversarial loss: 0.384728\n",
      "epoch 35; iter: 0; batch classifier loss: 0.133944; batch adversarial loss: 0.517705\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120158; batch adversarial loss: 0.476612\n",
      "epoch 37; iter: 0; batch classifier loss: 0.101237; batch adversarial loss: 0.491281\n",
      "epoch 38; iter: 0; batch classifier loss: 0.154860; batch adversarial loss: 0.445099\n",
      "epoch 39; iter: 0; batch classifier loss: 0.094773; batch adversarial loss: 0.462880\n",
      "epoch 40; iter: 0; batch classifier loss: 0.111399; batch adversarial loss: 0.462366\n",
      "epoch 41; iter: 0; batch classifier loss: 0.127699; batch adversarial loss: 0.595758\n",
      "epoch 42; iter: 0; batch classifier loss: 0.119297; batch adversarial loss: 0.424232\n",
      "epoch 43; iter: 0; batch classifier loss: 0.053366; batch adversarial loss: 0.512828\n",
      "epoch 44; iter: 0; batch classifier loss: 0.096773; batch adversarial loss: 0.434242\n",
      "epoch 45; iter: 0; batch classifier loss: 0.056524; batch adversarial loss: 0.432925\n",
      "epoch 46; iter: 0; batch classifier loss: 0.175569; batch adversarial loss: 0.510953\n",
      "epoch 47; iter: 0; batch classifier loss: 0.133468; batch adversarial loss: 0.456829\n",
      "epoch 48; iter: 0; batch classifier loss: 0.101646; batch adversarial loss: 0.474708\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098458; batch adversarial loss: 0.504433\n",
      "epoch 50; iter: 0; batch classifier loss: 0.066727; batch adversarial loss: 0.481404\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092351; batch adversarial loss: 0.446378\n",
      "epoch 52; iter: 0; batch classifier loss: 0.067799; batch adversarial loss: 0.364420\n",
      "epoch 53; iter: 0; batch classifier loss: 0.129995; batch adversarial loss: 0.588186\n",
      "epoch 54; iter: 0; batch classifier loss: 0.093384; batch adversarial loss: 0.501878\n",
      "epoch 55; iter: 0; batch classifier loss: 0.094688; batch adversarial loss: 0.451492\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095381; batch adversarial loss: 0.481516\n",
      "epoch 57; iter: 0; batch classifier loss: 0.094293; batch adversarial loss: 0.417675\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103794; batch adversarial loss: 0.437231\n",
      "epoch 59; iter: 0; batch classifier loss: 0.078406; batch adversarial loss: 0.467941\n",
      "epoch 60; iter: 0; batch classifier loss: 0.160895; batch adversarial loss: 0.435694\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114478; batch adversarial loss: 0.423991\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085972; batch adversarial loss: 0.565943\n",
      "epoch 63; iter: 0; batch classifier loss: 0.129854; batch adversarial loss: 0.440144\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083025; batch adversarial loss: 0.489588\n",
      "epoch 65; iter: 0; batch classifier loss: 0.061553; batch adversarial loss: 0.450336\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092885; batch adversarial loss: 0.447667\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095132; batch adversarial loss: 0.475484\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076277; batch adversarial loss: 0.539050\n",
      "epoch 69; iter: 0; batch classifier loss: 0.104928; batch adversarial loss: 0.548789\n",
      "epoch 70; iter: 0; batch classifier loss: 0.077759; batch adversarial loss: 0.464510\n",
      "epoch 71; iter: 0; batch classifier loss: 0.103719; batch adversarial loss: 0.439936\n",
      "epoch 72; iter: 0; batch classifier loss: 0.091350; batch adversarial loss: 0.477538\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068290; batch adversarial loss: 0.456919\n",
      "epoch 74; iter: 0; batch classifier loss: 0.071687; batch adversarial loss: 0.505110\n",
      "epoch 75; iter: 0; batch classifier loss: 0.107356; batch adversarial loss: 0.522432\n",
      "epoch 76; iter: 0; batch classifier loss: 0.120618; batch adversarial loss: 0.403132\n",
      "epoch 77; iter: 0; batch classifier loss: 0.110279; batch adversarial loss: 0.405172\n",
      "epoch 78; iter: 0; batch classifier loss: 0.096554; batch adversarial loss: 0.483283\n",
      "epoch 79; iter: 0; batch classifier loss: 0.121698; batch adversarial loss: 0.479089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.085492; batch adversarial loss: 0.459784\n",
      "epoch 81; iter: 0; batch classifier loss: 0.059220; batch adversarial loss: 0.506171\n",
      "epoch 82; iter: 0; batch classifier loss: 0.107075; batch adversarial loss: 0.463569\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081484; batch adversarial loss: 0.451890\n",
      "epoch 84; iter: 0; batch classifier loss: 0.108809; batch adversarial loss: 0.444284\n",
      "epoch 85; iter: 0; batch classifier loss: 0.094412; batch adversarial loss: 0.448680\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064477; batch adversarial loss: 0.459474\n",
      "epoch 87; iter: 0; batch classifier loss: 0.131232; batch adversarial loss: 0.437961\n",
      "epoch 88; iter: 0; batch classifier loss: 0.093461; batch adversarial loss: 0.519319\n",
      "epoch 89; iter: 0; batch classifier loss: 0.034066; batch adversarial loss: 0.459382\n",
      "epoch 90; iter: 0; batch classifier loss: 0.120286; batch adversarial loss: 0.391988\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056652; batch adversarial loss: 0.505206\n",
      "epoch 92; iter: 0; batch classifier loss: 0.075177; batch adversarial loss: 0.445574\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061724; batch adversarial loss: 0.559252\n",
      "epoch 94; iter: 0; batch classifier loss: 0.103707; batch adversarial loss: 0.447223\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045037; batch adversarial loss: 0.455305\n",
      "epoch 96; iter: 0; batch classifier loss: 0.054467; batch adversarial loss: 0.486008\n",
      "epoch 97; iter: 0; batch classifier loss: 0.109564; batch adversarial loss: 0.439916\n",
      "epoch 98; iter: 0; batch classifier loss: 0.095404; batch adversarial loss: 0.322555\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071791; batch adversarial loss: 0.436248\n",
      "epoch 100; iter: 0; batch classifier loss: 0.111932; batch adversarial loss: 0.484324\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062039; batch adversarial loss: 0.416688\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043537; batch adversarial loss: 0.448021\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076039; batch adversarial loss: 0.360788\n",
      "epoch 104; iter: 0; batch classifier loss: 0.114335; batch adversarial loss: 0.464656\n",
      "epoch 105; iter: 0; batch classifier loss: 0.110847; batch adversarial loss: 0.437131\n",
      "epoch 106; iter: 0; batch classifier loss: 0.027043; batch adversarial loss: 0.480716\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049770; batch adversarial loss: 0.377778\n",
      "epoch 108; iter: 0; batch classifier loss: 0.062055; batch adversarial loss: 0.411431\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066897; batch adversarial loss: 0.487599\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061192; batch adversarial loss: 0.428669\n",
      "epoch 111; iter: 0; batch classifier loss: 0.025607; batch adversarial loss: 0.465785\n",
      "epoch 112; iter: 0; batch classifier loss: 0.068118; batch adversarial loss: 0.414446\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047442; batch adversarial loss: 0.473299\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051604; batch adversarial loss: 0.391540\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044539; batch adversarial loss: 0.451173\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041789; batch adversarial loss: 0.472000\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036430; batch adversarial loss: 0.424600\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030548; batch adversarial loss: 0.431450\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044989; batch adversarial loss: 0.403329\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062005; batch adversarial loss: 0.400655\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052076; batch adversarial loss: 0.445127\n",
      "epoch 122; iter: 0; batch classifier loss: 0.064126; batch adversarial loss: 0.354037\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021167; batch adversarial loss: 0.469293\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029422; batch adversarial loss: 0.530032\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053093; batch adversarial loss: 0.519087\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047294; batch adversarial loss: 0.443277\n",
      "epoch 127; iter: 0; batch classifier loss: 0.074784; batch adversarial loss: 0.478222\n",
      "epoch 128; iter: 0; batch classifier loss: 0.062054; batch adversarial loss: 0.514090\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024183; batch adversarial loss: 0.511747\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023142; batch adversarial loss: 0.412333\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028218; batch adversarial loss: 0.417777\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023832; batch adversarial loss: 0.340269\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028965; batch adversarial loss: 0.503151\n",
      "epoch 134; iter: 0; batch classifier loss: 0.060346; batch adversarial loss: 0.509829\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046839; batch adversarial loss: 0.335504\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049532; batch adversarial loss: 0.420564\n",
      "epoch 137; iter: 0; batch classifier loss: 0.075580; batch adversarial loss: 0.471976\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048316; batch adversarial loss: 0.500935\n",
      "epoch 139; iter: 0; batch classifier loss: 0.027332; batch adversarial loss: 0.485730\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047985; batch adversarial loss: 0.435122\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049646; batch adversarial loss: 0.495448\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026602; batch adversarial loss: 0.493862\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040694; batch adversarial loss: 0.382508\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048433; batch adversarial loss: 0.407208\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014369; batch adversarial loss: 0.540053\n",
      "epoch 146; iter: 0; batch classifier loss: 0.059374; batch adversarial loss: 0.513121\n",
      "epoch 147; iter: 0; batch classifier loss: 0.045589; batch adversarial loss: 0.424230\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034406; batch adversarial loss: 0.502245\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017680; batch adversarial loss: 0.539538\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036460; batch adversarial loss: 0.392808\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015728; batch adversarial loss: 0.426491\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042134; batch adversarial loss: 0.455998\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022286; batch adversarial loss: 0.399845\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013136; batch adversarial loss: 0.465244\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019713; batch adversarial loss: 0.478468\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033351; batch adversarial loss: 0.376804\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040446; batch adversarial loss: 0.439858\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020956; batch adversarial loss: 0.567808\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020701; batch adversarial loss: 0.396114\n",
      "epoch 160; iter: 0; batch classifier loss: 0.053015; batch adversarial loss: 0.435934\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019072; batch adversarial loss: 0.386605\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027653; batch adversarial loss: 0.513648\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020676; batch adversarial loss: 0.373620\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010754; batch adversarial loss: 0.501169\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035955; batch adversarial loss: 0.424127\n",
      "epoch 166; iter: 0; batch classifier loss: 0.042210; batch adversarial loss: 0.395500\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020645; batch adversarial loss: 0.494017\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027022; batch adversarial loss: 0.514701\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032043; batch adversarial loss: 0.420846\n",
      "epoch 170; iter: 0; batch classifier loss: 0.047586; batch adversarial loss: 0.402373\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038425; batch adversarial loss: 0.474179\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031787; batch adversarial loss: 0.441026\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016378; batch adversarial loss: 0.438393\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029307; batch adversarial loss: 0.337010\n",
      "epoch 175; iter: 0; batch classifier loss: 0.084914; batch adversarial loss: 0.445354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.028945; batch adversarial loss: 0.390382\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042161; batch adversarial loss: 0.419402\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013377; batch adversarial loss: 0.451501\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034826; batch adversarial loss: 0.446931\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026456; batch adversarial loss: 0.408273\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035032; batch adversarial loss: 0.510477\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030206; batch adversarial loss: 0.435581\n",
      "epoch 183; iter: 0; batch classifier loss: 0.037739; batch adversarial loss: 0.419074\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019474; batch adversarial loss: 0.355200\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037574; batch adversarial loss: 0.525657\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008010; batch adversarial loss: 0.481216\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011198; batch adversarial loss: 0.340512\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029606; batch adversarial loss: 0.507332\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034770; batch adversarial loss: 0.356255\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024288; batch adversarial loss: 0.445580\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018806; batch adversarial loss: 0.482062\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033682; batch adversarial loss: 0.405637\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019163; batch adversarial loss: 0.496085\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017111; batch adversarial loss: 0.351318\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036088; batch adversarial loss: 0.457669\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012212; batch adversarial loss: 0.424631\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024854; batch adversarial loss: 0.477390\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024074; batch adversarial loss: 0.457004\n",
      "epoch 199; iter: 0; batch classifier loss: 0.069731; batch adversarial loss: 0.426490\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701680; batch adversarial loss: 0.520723\n",
      "epoch 1; iter: 0; batch classifier loss: 0.479865; batch adversarial loss: 0.579862\n",
      "epoch 2; iter: 0; batch classifier loss: 0.482118; batch adversarial loss: 0.607880\n",
      "epoch 3; iter: 0; batch classifier loss: 0.446242; batch adversarial loss: 0.559651\n",
      "epoch 4; iter: 0; batch classifier loss: 0.452612; batch adversarial loss: 0.643793\n",
      "epoch 5; iter: 0; batch classifier loss: 0.411004; batch adversarial loss: 0.527512\n",
      "epoch 6; iter: 0; batch classifier loss: 0.476944; batch adversarial loss: 0.584259\n",
      "epoch 7; iter: 0; batch classifier loss: 0.410493; batch adversarial loss: 0.591442\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569220; batch adversarial loss: 0.586505\n",
      "epoch 9; iter: 0; batch classifier loss: 0.444743; batch adversarial loss: 0.538204\n",
      "epoch 10; iter: 0; batch classifier loss: 0.492922; batch adversarial loss: 0.592326\n",
      "epoch 11; iter: 0; batch classifier loss: 0.396067; batch adversarial loss: 0.557537\n",
      "epoch 12; iter: 0; batch classifier loss: 0.405424; batch adversarial loss: 0.456768\n",
      "epoch 13; iter: 0; batch classifier loss: 0.309360; batch adversarial loss: 0.520153\n",
      "epoch 14; iter: 0; batch classifier loss: 0.258956; batch adversarial loss: 0.466993\n",
      "epoch 15; iter: 0; batch classifier loss: 0.275089; batch adversarial loss: 0.462620\n",
      "epoch 16; iter: 0; batch classifier loss: 0.224524; batch adversarial loss: 0.486721\n",
      "epoch 17; iter: 0; batch classifier loss: 0.290862; batch adversarial loss: 0.468127\n",
      "epoch 18; iter: 0; batch classifier loss: 0.233060; batch adversarial loss: 0.499995\n",
      "epoch 19; iter: 0; batch classifier loss: 0.142196; batch adversarial loss: 0.528469\n",
      "epoch 20; iter: 0; batch classifier loss: 0.225182; batch adversarial loss: 0.443885\n",
      "epoch 21; iter: 0; batch classifier loss: 0.223442; batch adversarial loss: 0.408803\n",
      "epoch 22; iter: 0; batch classifier loss: 0.236837; batch adversarial loss: 0.408452\n",
      "epoch 23; iter: 0; batch classifier loss: 0.164522; batch adversarial loss: 0.414341\n",
      "epoch 24; iter: 0; batch classifier loss: 0.176021; batch adversarial loss: 0.500383\n",
      "epoch 25; iter: 0; batch classifier loss: 0.149692; batch adversarial loss: 0.392217\n",
      "epoch 26; iter: 0; batch classifier loss: 0.183414; batch adversarial loss: 0.399156\n",
      "epoch 27; iter: 0; batch classifier loss: 0.207762; batch adversarial loss: 0.402586\n",
      "epoch 28; iter: 0; batch classifier loss: 0.165413; batch adversarial loss: 0.424837\n",
      "epoch 29; iter: 0; batch classifier loss: 0.149256; batch adversarial loss: 0.490879\n",
      "epoch 30; iter: 0; batch classifier loss: 0.173927; batch adversarial loss: 0.438510\n",
      "epoch 31; iter: 0; batch classifier loss: 0.210636; batch adversarial loss: 0.443914\n",
      "epoch 32; iter: 0; batch classifier loss: 0.118614; batch adversarial loss: 0.536006\n",
      "epoch 33; iter: 0; batch classifier loss: 0.170164; batch adversarial loss: 0.478350\n",
      "epoch 34; iter: 0; batch classifier loss: 0.096728; batch adversarial loss: 0.499530\n",
      "epoch 35; iter: 0; batch classifier loss: 0.206975; batch adversarial loss: 0.476024\n",
      "epoch 36; iter: 0; batch classifier loss: 0.144295; batch adversarial loss: 0.458265\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145955; batch adversarial loss: 0.383226\n",
      "epoch 38; iter: 0; batch classifier loss: 0.131594; batch adversarial loss: 0.465705\n",
      "epoch 39; iter: 0; batch classifier loss: 0.134285; batch adversarial loss: 0.488925\n",
      "epoch 40; iter: 0; batch classifier loss: 0.143761; batch adversarial loss: 0.463003\n",
      "epoch 41; iter: 0; batch classifier loss: 0.075419; batch adversarial loss: 0.533963\n",
      "epoch 42; iter: 0; batch classifier loss: 0.124731; batch adversarial loss: 0.526839\n",
      "epoch 43; iter: 0; batch classifier loss: 0.115715; batch adversarial loss: 0.373768\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106251; batch adversarial loss: 0.456748\n",
      "epoch 45; iter: 0; batch classifier loss: 0.163187; batch adversarial loss: 0.454093\n",
      "epoch 46; iter: 0; batch classifier loss: 0.111296; batch adversarial loss: 0.484367\n",
      "epoch 47; iter: 0; batch classifier loss: 0.145931; batch adversarial loss: 0.392806\n",
      "epoch 48; iter: 0; batch classifier loss: 0.163135; batch adversarial loss: 0.443717\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099643; batch adversarial loss: 0.438946\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111919; batch adversarial loss: 0.497220\n",
      "epoch 51; iter: 0; batch classifier loss: 0.170363; batch adversarial loss: 0.452881\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161025; batch adversarial loss: 0.499355\n",
      "epoch 53; iter: 0; batch classifier loss: 0.142248; batch adversarial loss: 0.499590\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116206; batch adversarial loss: 0.439341\n",
      "epoch 55; iter: 0; batch classifier loss: 0.150696; batch adversarial loss: 0.522889\n",
      "epoch 56; iter: 0; batch classifier loss: 0.138735; batch adversarial loss: 0.550496\n",
      "epoch 57; iter: 0; batch classifier loss: 0.146981; batch adversarial loss: 0.515744\n",
      "epoch 58; iter: 0; batch classifier loss: 0.129299; batch adversarial loss: 0.547300\n",
      "epoch 59; iter: 0; batch classifier loss: 0.077680; batch adversarial loss: 0.454545\n",
      "epoch 60; iter: 0; batch classifier loss: 0.156881; batch adversarial loss: 0.557344\n",
      "epoch 61; iter: 0; batch classifier loss: 0.128577; batch adversarial loss: 0.492270\n",
      "epoch 62; iter: 0; batch classifier loss: 0.115944; batch adversarial loss: 0.476971\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103804; batch adversarial loss: 0.429104\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078630; batch adversarial loss: 0.602008\n",
      "epoch 65; iter: 0; batch classifier loss: 0.129364; batch adversarial loss: 0.456947\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073545; batch adversarial loss: 0.538661\n",
      "epoch 67; iter: 0; batch classifier loss: 0.138783; batch adversarial loss: 0.401734\n",
      "epoch 68; iter: 0; batch classifier loss: 0.152083; batch adversarial loss: 0.370531\n",
      "epoch 69; iter: 0; batch classifier loss: 0.097305; batch adversarial loss: 0.387795\n",
      "epoch 70; iter: 0; batch classifier loss: 0.122900; batch adversarial loss: 0.464753\n",
      "epoch 71; iter: 0; batch classifier loss: 0.106220; batch adversarial loss: 0.495639\n",
      "epoch 72; iter: 0; batch classifier loss: 0.114208; batch adversarial loss: 0.473275\n",
      "epoch 73; iter: 0; batch classifier loss: 0.107250; batch adversarial loss: 0.415764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.178590; batch adversarial loss: 0.383960\n",
      "epoch 75; iter: 0; batch classifier loss: 0.120191; batch adversarial loss: 0.390864\n",
      "epoch 76; iter: 0; batch classifier loss: 0.099010; batch adversarial loss: 0.394676\n",
      "epoch 77; iter: 0; batch classifier loss: 0.107471; batch adversarial loss: 0.348706\n",
      "epoch 78; iter: 0; batch classifier loss: 0.147833; batch adversarial loss: 0.404957\n",
      "epoch 79; iter: 0; batch classifier loss: 0.129414; batch adversarial loss: 0.476116\n",
      "epoch 80; iter: 0; batch classifier loss: 0.094911; batch adversarial loss: 0.445981\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069395; batch adversarial loss: 0.526706\n",
      "epoch 82; iter: 0; batch classifier loss: 0.121238; batch adversarial loss: 0.453961\n",
      "epoch 83; iter: 0; batch classifier loss: 0.130477; batch adversarial loss: 0.472611\n",
      "epoch 84; iter: 0; batch classifier loss: 0.107917; batch adversarial loss: 0.478651\n",
      "epoch 85; iter: 0; batch classifier loss: 0.106582; batch adversarial loss: 0.489577\n",
      "epoch 86; iter: 0; batch classifier loss: 0.092527; batch adversarial loss: 0.488971\n",
      "epoch 87; iter: 0; batch classifier loss: 0.110701; batch adversarial loss: 0.451214\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078395; batch adversarial loss: 0.390189\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075128; batch adversarial loss: 0.458063\n",
      "epoch 90; iter: 0; batch classifier loss: 0.079171; batch adversarial loss: 0.408468\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063334; batch adversarial loss: 0.537134\n",
      "epoch 92; iter: 0; batch classifier loss: 0.137893; batch adversarial loss: 0.435438\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069200; batch adversarial loss: 0.431314\n",
      "epoch 94; iter: 0; batch classifier loss: 0.074252; batch adversarial loss: 0.476538\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051119; batch adversarial loss: 0.444213\n",
      "epoch 96; iter: 0; batch classifier loss: 0.089998; batch adversarial loss: 0.514595\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066433; batch adversarial loss: 0.482990\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072128; batch adversarial loss: 0.478618\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048738; batch adversarial loss: 0.496672\n",
      "epoch 100; iter: 0; batch classifier loss: 0.096038; batch adversarial loss: 0.436047\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041849; batch adversarial loss: 0.493082\n",
      "epoch 102; iter: 0; batch classifier loss: 0.075213; batch adversarial loss: 0.488148\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039009; batch adversarial loss: 0.496302\n",
      "epoch 104; iter: 0; batch classifier loss: 0.100417; batch adversarial loss: 0.326998\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044473; batch adversarial loss: 0.491684\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067075; batch adversarial loss: 0.514966\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038554; batch adversarial loss: 0.522807\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051026; batch adversarial loss: 0.406354\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054936; batch adversarial loss: 0.402943\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054385; batch adversarial loss: 0.426362\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033718; batch adversarial loss: 0.470082\n",
      "epoch 112; iter: 0; batch classifier loss: 0.067473; batch adversarial loss: 0.414138\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049351; batch adversarial loss: 0.516980\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051576; batch adversarial loss: 0.418534\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028633; batch adversarial loss: 0.495677\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039989; batch adversarial loss: 0.501644\n",
      "epoch 117; iter: 0; batch classifier loss: 0.054740; batch adversarial loss: 0.397780\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046089; batch adversarial loss: 0.416339\n",
      "epoch 119; iter: 0; batch classifier loss: 0.062181; batch adversarial loss: 0.378737\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043815; batch adversarial loss: 0.465459\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050302; batch adversarial loss: 0.407291\n",
      "epoch 122; iter: 0; batch classifier loss: 0.022821; batch adversarial loss: 0.420303\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042157; batch adversarial loss: 0.423987\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046248; batch adversarial loss: 0.450309\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027886; batch adversarial loss: 0.515116\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032782; batch adversarial loss: 0.479976\n",
      "epoch 127; iter: 0; batch classifier loss: 0.067790; batch adversarial loss: 0.471909\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036110; batch adversarial loss: 0.467699\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020504; batch adversarial loss: 0.413210\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033050; batch adversarial loss: 0.512178\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021504; batch adversarial loss: 0.397510\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037119; batch adversarial loss: 0.462688\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060999; batch adversarial loss: 0.440428\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029237; batch adversarial loss: 0.458149\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018267; batch adversarial loss: 0.500146\n",
      "epoch 136; iter: 0; batch classifier loss: 0.011901; batch adversarial loss: 0.468020\n",
      "epoch 137; iter: 0; batch classifier loss: 0.058135; batch adversarial loss: 0.405242\n",
      "epoch 138; iter: 0; batch classifier loss: 0.047951; batch adversarial loss: 0.483738\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040980; batch adversarial loss: 0.518348\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020738; batch adversarial loss: 0.527233\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024873; batch adversarial loss: 0.406713\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036360; batch adversarial loss: 0.452962\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033002; batch adversarial loss: 0.475102\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012663; batch adversarial loss: 0.455180\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020213; batch adversarial loss: 0.454941\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010795; batch adversarial loss: 0.449996\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020758; batch adversarial loss: 0.516681\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013219; batch adversarial loss: 0.424768\n",
      "epoch 149; iter: 0; batch classifier loss: 0.005425; batch adversarial loss: 0.516075\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033868; batch adversarial loss: 0.352323\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029237; batch adversarial loss: 0.348700\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013276; batch adversarial loss: 0.394109\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038864; batch adversarial loss: 0.364684\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010334; batch adversarial loss: 0.372938\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011925; batch adversarial loss: 0.393046\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019376; batch adversarial loss: 0.459783\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028040; batch adversarial loss: 0.407677\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018823; batch adversarial loss: 0.387295\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012011; batch adversarial loss: 0.429479\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020794; batch adversarial loss: 0.506457\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011120; batch adversarial loss: 0.361548\n",
      "epoch 162; iter: 0; batch classifier loss: 0.008932; batch adversarial loss: 0.494576\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032280; batch adversarial loss: 0.441951\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026153; batch adversarial loss: 0.437707\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042972; batch adversarial loss: 0.446360\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018412; batch adversarial loss: 0.494377\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011977; batch adversarial loss: 0.363354\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038938; batch adversarial loss: 0.560212\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006324; batch adversarial loss: 0.376939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.006024; batch adversarial loss: 0.367482\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018856; batch adversarial loss: 0.450452\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034175; batch adversarial loss: 0.512652\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014414; batch adversarial loss: 0.534273\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017330; batch adversarial loss: 0.333295\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006621; batch adversarial loss: 0.418052\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015115; batch adversarial loss: 0.517695\n",
      "epoch 177; iter: 0; batch classifier loss: 0.004402; batch adversarial loss: 0.388956\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017181; batch adversarial loss: 0.361171\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009466; batch adversarial loss: 0.433415\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007726; batch adversarial loss: 0.579570\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012166; batch adversarial loss: 0.442452\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007895; batch adversarial loss: 0.560610\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019096; batch adversarial loss: 0.362824\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028150; batch adversarial loss: 0.492384\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020248; batch adversarial loss: 0.437436\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007784; batch adversarial loss: 0.516248\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007061; batch adversarial loss: 0.461956\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027618; batch adversarial loss: 0.385058\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023699; batch adversarial loss: 0.436307\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020097; batch adversarial loss: 0.453731\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032004; batch adversarial loss: 0.418164\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020090; batch adversarial loss: 0.564288\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006039; batch adversarial loss: 0.382542\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017545; batch adversarial loss: 0.510284\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021962; batch adversarial loss: 0.496081\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023215; batch adversarial loss: 0.387478\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018682; batch adversarial loss: 0.460324\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006647; batch adversarial loss: 0.467431\n",
      "epoch 199; iter: 0; batch classifier loss: 0.002810; batch adversarial loss: 0.556064\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684574; batch adversarial loss: 0.732051\n",
      "epoch 1; iter: 0; batch classifier loss: 0.621946; batch adversarial loss: 0.724127\n",
      "epoch 2; iter: 0; batch classifier loss: 0.441567; batch adversarial loss: 0.625885\n",
      "epoch 3; iter: 0; batch classifier loss: 0.401691; batch adversarial loss: 0.581227\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335816; batch adversarial loss: 0.575224\n",
      "epoch 5; iter: 0; batch classifier loss: 0.363622; batch adversarial loss: 0.600851\n",
      "epoch 6; iter: 0; batch classifier loss: 0.313022; batch adversarial loss: 0.558118\n",
      "epoch 7; iter: 0; batch classifier loss: 0.285505; batch adversarial loss: 0.524280\n",
      "epoch 8; iter: 0; batch classifier loss: 0.217441; batch adversarial loss: 0.570948\n",
      "epoch 9; iter: 0; batch classifier loss: 0.310504; batch adversarial loss: 0.538500\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258688; batch adversarial loss: 0.537007\n",
      "epoch 11; iter: 0; batch classifier loss: 0.199271; batch adversarial loss: 0.609678\n",
      "epoch 12; iter: 0; batch classifier loss: 0.245727; batch adversarial loss: 0.514764\n",
      "epoch 13; iter: 0; batch classifier loss: 0.161408; batch adversarial loss: 0.495219\n",
      "epoch 14; iter: 0; batch classifier loss: 0.202576; batch adversarial loss: 0.431588\n",
      "epoch 15; iter: 0; batch classifier loss: 0.292562; batch adversarial loss: 0.466517\n",
      "epoch 16; iter: 0; batch classifier loss: 0.192181; batch adversarial loss: 0.550133\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241920; batch adversarial loss: 0.542485\n",
      "epoch 18; iter: 0; batch classifier loss: 0.215699; batch adversarial loss: 0.426978\n",
      "epoch 19; iter: 0; batch classifier loss: 0.130373; batch adversarial loss: 0.532569\n",
      "epoch 20; iter: 0; batch classifier loss: 0.183331; batch adversarial loss: 0.426824\n",
      "epoch 21; iter: 0; batch classifier loss: 0.235055; batch adversarial loss: 0.534484\n",
      "epoch 22; iter: 0; batch classifier loss: 0.259781; batch adversarial loss: 0.492196\n",
      "epoch 23; iter: 0; batch classifier loss: 0.176666; batch adversarial loss: 0.513647\n",
      "epoch 24; iter: 0; batch classifier loss: 0.190928; batch adversarial loss: 0.441204\n",
      "epoch 25; iter: 0; batch classifier loss: 0.190660; batch adversarial loss: 0.509001\n",
      "epoch 26; iter: 0; batch classifier loss: 0.121253; batch adversarial loss: 0.529194\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154368; batch adversarial loss: 0.480302\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166741; batch adversarial loss: 0.497376\n",
      "epoch 29; iter: 0; batch classifier loss: 0.148822; batch adversarial loss: 0.426906\n",
      "epoch 30; iter: 0; batch classifier loss: 0.174433; batch adversarial loss: 0.489268\n",
      "epoch 31; iter: 0; batch classifier loss: 0.142838; batch adversarial loss: 0.426220\n",
      "epoch 32; iter: 0; batch classifier loss: 0.193679; batch adversarial loss: 0.391350\n",
      "epoch 33; iter: 0; batch classifier loss: 0.148735; batch adversarial loss: 0.457530\n",
      "epoch 34; iter: 0; batch classifier loss: 0.154256; batch adversarial loss: 0.436716\n",
      "epoch 35; iter: 0; batch classifier loss: 0.156140; batch adversarial loss: 0.396146\n",
      "epoch 36; iter: 0; batch classifier loss: 0.178336; batch adversarial loss: 0.476301\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110167; batch adversarial loss: 0.462506\n",
      "epoch 38; iter: 0; batch classifier loss: 0.139640; batch adversarial loss: 0.483610\n",
      "epoch 39; iter: 0; batch classifier loss: 0.137203; batch adversarial loss: 0.485696\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103490; batch adversarial loss: 0.387004\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123725; batch adversarial loss: 0.412780\n",
      "epoch 42; iter: 0; batch classifier loss: 0.162704; batch adversarial loss: 0.446367\n",
      "epoch 43; iter: 0; batch classifier loss: 0.134432; batch adversarial loss: 0.395413\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118851; batch adversarial loss: 0.444751\n",
      "epoch 45; iter: 0; batch classifier loss: 0.107700; batch adversarial loss: 0.397683\n",
      "epoch 46; iter: 0; batch classifier loss: 0.095553; batch adversarial loss: 0.446524\n",
      "epoch 47; iter: 0; batch classifier loss: 0.144190; batch adversarial loss: 0.429669\n",
      "epoch 48; iter: 0; batch classifier loss: 0.074887; batch adversarial loss: 0.524127\n",
      "epoch 49; iter: 0; batch classifier loss: 0.175254; batch adversarial loss: 0.408719\n",
      "epoch 50; iter: 0; batch classifier loss: 0.142699; batch adversarial loss: 0.441260\n",
      "epoch 51; iter: 0; batch classifier loss: 0.101825; batch adversarial loss: 0.482660\n",
      "epoch 52; iter: 0; batch classifier loss: 0.107064; batch adversarial loss: 0.457592\n",
      "epoch 53; iter: 0; batch classifier loss: 0.121087; batch adversarial loss: 0.451460\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103992; batch adversarial loss: 0.446859\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117333; batch adversarial loss: 0.425414\n",
      "epoch 56; iter: 0; batch classifier loss: 0.107999; batch adversarial loss: 0.488152\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082376; batch adversarial loss: 0.532723\n",
      "epoch 58; iter: 0; batch classifier loss: 0.172247; batch adversarial loss: 0.553765\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084630; batch adversarial loss: 0.485626\n",
      "epoch 60; iter: 0; batch classifier loss: 0.100164; batch adversarial loss: 0.439648\n",
      "epoch 61; iter: 0; batch classifier loss: 0.137708; batch adversarial loss: 0.528094\n",
      "epoch 62; iter: 0; batch classifier loss: 0.063842; batch adversarial loss: 0.471288\n",
      "epoch 63; iter: 0; batch classifier loss: 0.131278; batch adversarial loss: 0.499651\n",
      "epoch 64; iter: 0; batch classifier loss: 0.044918; batch adversarial loss: 0.457474\n",
      "epoch 65; iter: 0; batch classifier loss: 0.048054; batch adversarial loss: 0.470567\n",
      "epoch 66; iter: 0; batch classifier loss: 0.074429; batch adversarial loss: 0.521152\n",
      "epoch 67; iter: 0; batch classifier loss: 0.078221; batch adversarial loss: 0.426598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.126466; batch adversarial loss: 0.522251\n",
      "epoch 69; iter: 0; batch classifier loss: 0.067784; batch adversarial loss: 0.473982\n",
      "epoch 70; iter: 0; batch classifier loss: 0.089429; batch adversarial loss: 0.411462\n",
      "epoch 71; iter: 0; batch classifier loss: 0.123057; batch adversarial loss: 0.412293\n",
      "epoch 72; iter: 0; batch classifier loss: 0.051762; batch adversarial loss: 0.551652\n",
      "epoch 73; iter: 0; batch classifier loss: 0.043821; batch adversarial loss: 0.442603\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053584; batch adversarial loss: 0.432802\n",
      "epoch 75; iter: 0; batch classifier loss: 0.028231; batch adversarial loss: 0.425013\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083444; batch adversarial loss: 0.437950\n",
      "epoch 77; iter: 0; batch classifier loss: 0.060002; batch adversarial loss: 0.497929\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056191; batch adversarial loss: 0.439352\n",
      "epoch 79; iter: 0; batch classifier loss: 0.107762; batch adversarial loss: 0.409582\n",
      "epoch 80; iter: 0; batch classifier loss: 0.058751; batch adversarial loss: 0.484102\n",
      "epoch 81; iter: 0; batch classifier loss: 0.022155; batch adversarial loss: 0.423484\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090993; batch adversarial loss: 0.460172\n",
      "epoch 83; iter: 0; batch classifier loss: 0.038094; batch adversarial loss: 0.420890\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080605; batch adversarial loss: 0.414131\n",
      "epoch 85; iter: 0; batch classifier loss: 0.057151; batch adversarial loss: 0.446282\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058788; batch adversarial loss: 0.366630\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059413; batch adversarial loss: 0.480948\n",
      "epoch 88; iter: 0; batch classifier loss: 0.035878; batch adversarial loss: 0.567560\n",
      "epoch 89; iter: 0; batch classifier loss: 0.088633; batch adversarial loss: 0.457561\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056632; batch adversarial loss: 0.460053\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057374; batch adversarial loss: 0.472626\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048294; batch adversarial loss: 0.496920\n",
      "epoch 93; iter: 0; batch classifier loss: 0.073207; batch adversarial loss: 0.511741\n",
      "epoch 94; iter: 0; batch classifier loss: 0.045889; batch adversarial loss: 0.440563\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060012; batch adversarial loss: 0.513222\n",
      "epoch 96; iter: 0; batch classifier loss: 0.029712; batch adversarial loss: 0.426277\n",
      "epoch 97; iter: 0; batch classifier loss: 0.090540; batch adversarial loss: 0.392804\n",
      "epoch 98; iter: 0; batch classifier loss: 0.033639; batch adversarial loss: 0.430635\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071775; batch adversarial loss: 0.488876\n",
      "epoch 100; iter: 0; batch classifier loss: 0.032310; batch adversarial loss: 0.356128\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042522; batch adversarial loss: 0.475362\n",
      "epoch 102; iter: 0; batch classifier loss: 0.070035; batch adversarial loss: 0.380077\n",
      "epoch 103; iter: 0; batch classifier loss: 0.027615; batch adversarial loss: 0.528935\n",
      "epoch 104; iter: 0; batch classifier loss: 0.052890; batch adversarial loss: 0.427528\n",
      "epoch 105; iter: 0; batch classifier loss: 0.068740; batch adversarial loss: 0.416431\n",
      "epoch 106; iter: 0; batch classifier loss: 0.022114; batch adversarial loss: 0.458754\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045195; batch adversarial loss: 0.413278\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052849; batch adversarial loss: 0.452388\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051920; batch adversarial loss: 0.355140\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034926; batch adversarial loss: 0.419766\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044270; batch adversarial loss: 0.442192\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063018; batch adversarial loss: 0.441148\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057270; batch adversarial loss: 0.473486\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042076; batch adversarial loss: 0.473095\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024905; batch adversarial loss: 0.460886\n",
      "epoch 116; iter: 0; batch classifier loss: 0.010945; batch adversarial loss: 0.542260\n",
      "epoch 117; iter: 0; batch classifier loss: 0.021593; batch adversarial loss: 0.440493\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029661; batch adversarial loss: 0.423553\n",
      "epoch 119; iter: 0; batch classifier loss: 0.014588; batch adversarial loss: 0.387289\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028216; batch adversarial loss: 0.355305\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029320; batch adversarial loss: 0.505040\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048165; batch adversarial loss: 0.514495\n",
      "epoch 123; iter: 0; batch classifier loss: 0.058760; batch adversarial loss: 0.457961\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038184; batch adversarial loss: 0.516291\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025826; batch adversarial loss: 0.424745\n",
      "epoch 126; iter: 0; batch classifier loss: 0.069795; batch adversarial loss: 0.469800\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021123; batch adversarial loss: 0.459189\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027381; batch adversarial loss: 0.486389\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018763; batch adversarial loss: 0.476884\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033611; batch adversarial loss: 0.491770\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033930; batch adversarial loss: 0.378424\n",
      "epoch 132; iter: 0; batch classifier loss: 0.013930; batch adversarial loss: 0.554079\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038109; batch adversarial loss: 0.397161\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050427; batch adversarial loss: 0.387292\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012517; batch adversarial loss: 0.480521\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031286; batch adversarial loss: 0.434613\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028872; batch adversarial loss: 0.351165\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035279; batch adversarial loss: 0.491915\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010628; batch adversarial loss: 0.462837\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029596; batch adversarial loss: 0.453873\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019976; batch adversarial loss: 0.478637\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019812; batch adversarial loss: 0.478377\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028837; batch adversarial loss: 0.533518\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033346; batch adversarial loss: 0.403256\n",
      "epoch 145; iter: 0; batch classifier loss: 0.055703; batch adversarial loss: 0.298932\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034207; batch adversarial loss: 0.488021\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031961; batch adversarial loss: 0.501208\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029220; batch adversarial loss: 0.442407\n",
      "epoch 149; iter: 0; batch classifier loss: 0.004516; batch adversarial loss: 0.521307\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023665; batch adversarial loss: 0.422074\n",
      "epoch 151; iter: 0; batch classifier loss: 0.059994; batch adversarial loss: 0.409697\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035864; batch adversarial loss: 0.413060\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019050; batch adversarial loss: 0.364840\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018004; batch adversarial loss: 0.474666\n",
      "epoch 155; iter: 0; batch classifier loss: 0.047963; batch adversarial loss: 0.497816\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032273; batch adversarial loss: 0.412057\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009485; batch adversarial loss: 0.452924\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021343; batch adversarial loss: 0.412120\n",
      "epoch 159; iter: 0; batch classifier loss: 0.055189; batch adversarial loss: 0.364840\n",
      "epoch 160; iter: 0; batch classifier loss: 0.004204; batch adversarial loss: 0.447118\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009665; batch adversarial loss: 0.486613\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019206; batch adversarial loss: 0.551017\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040715; batch adversarial loss: 0.384745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.048589; batch adversarial loss: 0.460740\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009249; batch adversarial loss: 0.324645\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020201; batch adversarial loss: 0.474794\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034748; batch adversarial loss: 0.404869\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026449; batch adversarial loss: 0.402272\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022479; batch adversarial loss: 0.493617\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013296; batch adversarial loss: 0.376623\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025864; batch adversarial loss: 0.413290\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020053; batch adversarial loss: 0.459078\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015727; batch adversarial loss: 0.446520\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017329; batch adversarial loss: 0.489978\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026976; batch adversarial loss: 0.362277\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014187; batch adversarial loss: 0.467244\n",
      "epoch 177; iter: 0; batch classifier loss: 0.003284; batch adversarial loss: 0.365366\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022885; batch adversarial loss: 0.484141\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033899; batch adversarial loss: 0.422964\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016205; batch adversarial loss: 0.454289\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037679; batch adversarial loss: 0.495804\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020677; batch adversarial loss: 0.416841\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014792; batch adversarial loss: 0.484038\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007939; batch adversarial loss: 0.508278\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009731; batch adversarial loss: 0.470454\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005571; batch adversarial loss: 0.508432\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030588; batch adversarial loss: 0.458940\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028984; batch adversarial loss: 0.425062\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013383; batch adversarial loss: 0.547169\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006919; batch adversarial loss: 0.425094\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025607; batch adversarial loss: 0.466757\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011071; batch adversarial loss: 0.438496\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007992; batch adversarial loss: 0.559611\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015986; batch adversarial loss: 0.424533\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016856; batch adversarial loss: 0.514232\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007116; batch adversarial loss: 0.410068\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021380; batch adversarial loss: 0.421831\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020537; batch adversarial loss: 0.362478\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030911; batch adversarial loss: 0.456218\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682685; batch adversarial loss: 0.525306\n",
      "epoch 1; iter: 0; batch classifier loss: 0.419739; batch adversarial loss: 0.624162\n",
      "epoch 2; iter: 0; batch classifier loss: 0.397461; batch adversarial loss: 0.611623\n",
      "epoch 3; iter: 0; batch classifier loss: 0.413283; batch adversarial loss: 0.583729\n",
      "epoch 4; iter: 0; batch classifier loss: 0.372360; batch adversarial loss: 0.622506\n",
      "epoch 5; iter: 0; batch classifier loss: 0.371673; batch adversarial loss: 0.577921\n",
      "epoch 6; iter: 0; batch classifier loss: 0.416412; batch adversarial loss: 0.569155\n",
      "epoch 7; iter: 0; batch classifier loss: 0.404314; batch adversarial loss: 0.502831\n",
      "epoch 8; iter: 0; batch classifier loss: 0.414260; batch adversarial loss: 0.561606\n",
      "epoch 9; iter: 0; batch classifier loss: 0.479251; batch adversarial loss: 0.572191\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517345; batch adversarial loss: 0.574868\n",
      "epoch 11; iter: 0; batch classifier loss: 0.552074; batch adversarial loss: 0.541946\n",
      "epoch 12; iter: 0; batch classifier loss: 0.570170; batch adversarial loss: 0.521186\n",
      "epoch 13; iter: 0; batch classifier loss: 0.487727; batch adversarial loss: 0.531185\n",
      "epoch 14; iter: 0; batch classifier loss: 0.462332; batch adversarial loss: 0.460360\n",
      "epoch 15; iter: 0; batch classifier loss: 0.336146; batch adversarial loss: 0.484577\n",
      "epoch 16; iter: 0; batch classifier loss: 0.263133; batch adversarial loss: 0.546346\n",
      "epoch 17; iter: 0; batch classifier loss: 0.277895; batch adversarial loss: 0.434310\n",
      "epoch 18; iter: 0; batch classifier loss: 0.198235; batch adversarial loss: 0.537169\n",
      "epoch 19; iter: 0; batch classifier loss: 0.256968; batch adversarial loss: 0.479816\n",
      "epoch 20; iter: 0; batch classifier loss: 0.201497; batch adversarial loss: 0.464789\n",
      "epoch 21; iter: 0; batch classifier loss: 0.228214; batch adversarial loss: 0.440803\n",
      "epoch 22; iter: 0; batch classifier loss: 0.225535; batch adversarial loss: 0.471416\n",
      "epoch 23; iter: 0; batch classifier loss: 0.195178; batch adversarial loss: 0.430810\n",
      "epoch 24; iter: 0; batch classifier loss: 0.215122; batch adversarial loss: 0.557395\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201217; batch adversarial loss: 0.395517\n",
      "epoch 26; iter: 0; batch classifier loss: 0.166329; batch adversarial loss: 0.403890\n",
      "epoch 27; iter: 0; batch classifier loss: 0.197533; batch adversarial loss: 0.528882\n",
      "epoch 28; iter: 0; batch classifier loss: 0.198217; batch adversarial loss: 0.422340\n",
      "epoch 29; iter: 0; batch classifier loss: 0.129822; batch adversarial loss: 0.490490\n",
      "epoch 30; iter: 0; batch classifier loss: 0.202956; batch adversarial loss: 0.438292\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156358; batch adversarial loss: 0.469405\n",
      "epoch 32; iter: 0; batch classifier loss: 0.131160; batch adversarial loss: 0.510465\n",
      "epoch 33; iter: 0; batch classifier loss: 0.160419; batch adversarial loss: 0.460400\n",
      "epoch 34; iter: 0; batch classifier loss: 0.197731; batch adversarial loss: 0.378141\n",
      "epoch 35; iter: 0; batch classifier loss: 0.246538; batch adversarial loss: 0.468849\n",
      "epoch 36; iter: 0; batch classifier loss: 0.214636; batch adversarial loss: 0.369316\n",
      "epoch 37; iter: 0; batch classifier loss: 0.164600; batch adversarial loss: 0.479371\n",
      "epoch 38; iter: 0; batch classifier loss: 0.176064; batch adversarial loss: 0.472814\n",
      "epoch 39; iter: 0; batch classifier loss: 0.186943; batch adversarial loss: 0.413726\n",
      "epoch 40; iter: 0; batch classifier loss: 0.123847; batch adversarial loss: 0.553465\n",
      "epoch 41; iter: 0; batch classifier loss: 0.256618; batch adversarial loss: 0.501437\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131513; batch adversarial loss: 0.506970\n",
      "epoch 43; iter: 0; batch classifier loss: 0.155252; batch adversarial loss: 0.369570\n",
      "epoch 44; iter: 0; batch classifier loss: 0.194441; batch adversarial loss: 0.405912\n",
      "epoch 45; iter: 0; batch classifier loss: 0.186703; batch adversarial loss: 0.369971\n",
      "epoch 46; iter: 0; batch classifier loss: 0.174114; batch adversarial loss: 0.433714\n",
      "epoch 47; iter: 0; batch classifier loss: 0.215085; batch adversarial loss: 0.426911\n",
      "epoch 48; iter: 0; batch classifier loss: 0.157047; batch adversarial loss: 0.607615\n",
      "epoch 49; iter: 0; batch classifier loss: 0.171796; batch adversarial loss: 0.436200\n",
      "epoch 50; iter: 0; batch classifier loss: 0.209682; batch adversarial loss: 0.400133\n",
      "epoch 51; iter: 0; batch classifier loss: 0.203709; batch adversarial loss: 0.536944\n",
      "epoch 52; iter: 0; batch classifier loss: 0.158963; batch adversarial loss: 0.413805\n",
      "epoch 53; iter: 0; batch classifier loss: 0.193166; batch adversarial loss: 0.497050\n",
      "epoch 54; iter: 0; batch classifier loss: 0.244123; batch adversarial loss: 0.495543\n",
      "epoch 55; iter: 0; batch classifier loss: 0.263063; batch adversarial loss: 0.412067\n",
      "epoch 56; iter: 0; batch classifier loss: 0.195758; batch adversarial loss: 0.519039\n",
      "epoch 57; iter: 0; batch classifier loss: 0.129647; batch adversarial loss: 0.465327\n",
      "epoch 58; iter: 0; batch classifier loss: 0.151885; batch adversarial loss: 0.443657\n",
      "epoch 59; iter: 0; batch classifier loss: 0.185530; batch adversarial loss: 0.454787\n",
      "epoch 60; iter: 0; batch classifier loss: 0.237637; batch adversarial loss: 0.412077\n",
      "epoch 61; iter: 0; batch classifier loss: 0.154199; batch adversarial loss: 0.499705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.255597; batch adversarial loss: 0.420689\n",
      "epoch 63; iter: 0; batch classifier loss: 0.217360; batch adversarial loss: 0.421851\n",
      "epoch 64; iter: 0; batch classifier loss: 0.212176; batch adversarial loss: 0.394494\n",
      "epoch 65; iter: 0; batch classifier loss: 0.209334; batch adversarial loss: 0.457924\n",
      "epoch 66; iter: 0; batch classifier loss: 0.165495; batch adversarial loss: 0.472679\n",
      "epoch 67; iter: 0; batch classifier loss: 0.220614; batch adversarial loss: 0.433808\n",
      "epoch 68; iter: 0; batch classifier loss: 0.202687; batch adversarial loss: 0.435302\n",
      "epoch 69; iter: 0; batch classifier loss: 0.237203; batch adversarial loss: 0.420803\n",
      "epoch 70; iter: 0; batch classifier loss: 0.157721; batch adversarial loss: 0.384426\n",
      "epoch 71; iter: 0; batch classifier loss: 0.215356; batch adversarial loss: 0.397605\n",
      "epoch 72; iter: 0; batch classifier loss: 0.239746; batch adversarial loss: 0.383443\n",
      "epoch 73; iter: 0; batch classifier loss: 0.172571; batch adversarial loss: 0.323954\n",
      "epoch 74; iter: 0; batch classifier loss: 0.179347; batch adversarial loss: 0.509396\n",
      "epoch 75; iter: 0; batch classifier loss: 0.247274; batch adversarial loss: 0.458236\n",
      "epoch 76; iter: 0; batch classifier loss: 0.266066; batch adversarial loss: 0.434156\n",
      "epoch 77; iter: 0; batch classifier loss: 0.245810; batch adversarial loss: 0.397160\n",
      "epoch 78; iter: 0; batch classifier loss: 0.198847; batch adversarial loss: 0.384760\n",
      "epoch 79; iter: 0; batch classifier loss: 0.220108; batch adversarial loss: 0.496091\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076791; batch adversarial loss: 0.495255\n",
      "epoch 81; iter: 0; batch classifier loss: 0.082112; batch adversarial loss: 0.407954\n",
      "epoch 82; iter: 0; batch classifier loss: 0.055418; batch adversarial loss: 0.416742\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083917; batch adversarial loss: 0.371679\n",
      "epoch 84; iter: 0; batch classifier loss: 0.109810; batch adversarial loss: 0.404577\n",
      "epoch 85; iter: 0; batch classifier loss: 0.072391; batch adversarial loss: 0.398288\n",
      "epoch 86; iter: 0; batch classifier loss: 0.047007; batch adversarial loss: 0.540363\n",
      "epoch 87; iter: 0; batch classifier loss: 0.097748; batch adversarial loss: 0.394679\n",
      "epoch 88; iter: 0; batch classifier loss: 0.085062; batch adversarial loss: 0.392043\n",
      "epoch 89; iter: 0; batch classifier loss: 0.071887; batch adversarial loss: 0.348255\n",
      "epoch 90; iter: 0; batch classifier loss: 0.072002; batch adversarial loss: 0.443380\n",
      "epoch 91; iter: 0; batch classifier loss: 0.095856; batch adversarial loss: 0.390984\n",
      "epoch 92; iter: 0; batch classifier loss: 0.083188; batch adversarial loss: 0.386381\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078029; batch adversarial loss: 0.366543\n",
      "epoch 94; iter: 0; batch classifier loss: 0.071889; batch adversarial loss: 0.492884\n",
      "epoch 95; iter: 0; batch classifier loss: 0.102568; batch adversarial loss: 0.442692\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051192; batch adversarial loss: 0.487033\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061587; batch adversarial loss: 0.441087\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063492; batch adversarial loss: 0.463182\n",
      "epoch 99; iter: 0; batch classifier loss: 0.134291; batch adversarial loss: 0.489930\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060822; batch adversarial loss: 0.528356\n",
      "epoch 101; iter: 0; batch classifier loss: 0.052913; batch adversarial loss: 0.495440\n",
      "epoch 102; iter: 0; batch classifier loss: 0.076964; batch adversarial loss: 0.435125\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039873; batch adversarial loss: 0.459083\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071893; batch adversarial loss: 0.443534\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057708; batch adversarial loss: 0.526641\n",
      "epoch 106; iter: 0; batch classifier loss: 0.066048; batch adversarial loss: 0.452526\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041738; batch adversarial loss: 0.414799\n",
      "epoch 108; iter: 0; batch classifier loss: 0.050256; batch adversarial loss: 0.480865\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036317; batch adversarial loss: 0.429798\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051709; batch adversarial loss: 0.450100\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042123; batch adversarial loss: 0.402674\n",
      "epoch 112; iter: 0; batch classifier loss: 0.061756; batch adversarial loss: 0.447119\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028347; batch adversarial loss: 0.405136\n",
      "epoch 114; iter: 0; batch classifier loss: 0.076256; batch adversarial loss: 0.473220\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052422; batch adversarial loss: 0.424349\n",
      "epoch 116; iter: 0; batch classifier loss: 0.031972; batch adversarial loss: 0.380073\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060438; batch adversarial loss: 0.473256\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053365; batch adversarial loss: 0.450079\n",
      "epoch 119; iter: 0; batch classifier loss: 0.079648; batch adversarial loss: 0.469935\n",
      "epoch 120; iter: 0; batch classifier loss: 0.059661; batch adversarial loss: 0.457719\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042155; batch adversarial loss: 0.563681\n",
      "epoch 122; iter: 0; batch classifier loss: 0.083748; batch adversarial loss: 0.470014\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043660; batch adversarial loss: 0.470593\n",
      "epoch 124; iter: 0; batch classifier loss: 0.060659; batch adversarial loss: 0.388355\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043214; batch adversarial loss: 0.410913\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044598; batch adversarial loss: 0.471144\n",
      "epoch 127; iter: 0; batch classifier loss: 0.064117; batch adversarial loss: 0.464640\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058578; batch adversarial loss: 0.425638\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031378; batch adversarial loss: 0.381575\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043271; batch adversarial loss: 0.516612\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027203; batch adversarial loss: 0.387970\n",
      "epoch 132; iter: 0; batch classifier loss: 0.018006; batch adversarial loss: 0.376926\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045252; batch adversarial loss: 0.457899\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024491; batch adversarial loss: 0.508680\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024922; batch adversarial loss: 0.411880\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018823; batch adversarial loss: 0.499425\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039635; batch adversarial loss: 0.520029\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016067; batch adversarial loss: 0.344337\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037282; batch adversarial loss: 0.384736\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046203; batch adversarial loss: 0.432963\n",
      "epoch 141; iter: 0; batch classifier loss: 0.012002; batch adversarial loss: 0.367319\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016252; batch adversarial loss: 0.452919\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018933; batch adversarial loss: 0.429160\n",
      "epoch 144; iter: 0; batch classifier loss: 0.065806; batch adversarial loss: 0.374265\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021893; batch adversarial loss: 0.652840\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025868; batch adversarial loss: 0.466004\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033125; batch adversarial loss: 0.458978\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037401; batch adversarial loss: 0.498803\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036465; batch adversarial loss: 0.440271\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028441; batch adversarial loss: 0.413231\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029999; batch adversarial loss: 0.447345\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029760; batch adversarial loss: 0.449698\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020597; batch adversarial loss: 0.551306\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014527; batch adversarial loss: 0.452676\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025428; batch adversarial loss: 0.482055\n",
      "epoch 156; iter: 0; batch classifier loss: 0.006187; batch adversarial loss: 0.370360\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013300; batch adversarial loss: 0.524619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.028793; batch adversarial loss: 0.411421\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017634; batch adversarial loss: 0.456129\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015560; batch adversarial loss: 0.402946\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009180; batch adversarial loss: 0.497724\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026356; batch adversarial loss: 0.489059\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027429; batch adversarial loss: 0.558939\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016541; batch adversarial loss: 0.502824\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044742; batch adversarial loss: 0.473774\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016559; batch adversarial loss: 0.409631\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008652; batch adversarial loss: 0.446839\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014559; batch adversarial loss: 0.487230\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014155; batch adversarial loss: 0.406741\n",
      "epoch 170; iter: 0; batch classifier loss: 0.074919; batch adversarial loss: 0.412427\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019356; batch adversarial loss: 0.512797\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015424; batch adversarial loss: 0.419881\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010301; batch adversarial loss: 0.585130\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006713; batch adversarial loss: 0.484558\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028774; batch adversarial loss: 0.554109\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010566; batch adversarial loss: 0.517483\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028777; batch adversarial loss: 0.425243\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011758; batch adversarial loss: 0.382558\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027127; batch adversarial loss: 0.481598\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006478; batch adversarial loss: 0.486377\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023640; batch adversarial loss: 0.439125\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033022; batch adversarial loss: 0.442843\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007240; batch adversarial loss: 0.438091\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027277; batch adversarial loss: 0.438682\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027038; batch adversarial loss: 0.388005\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027786; batch adversarial loss: 0.423784\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020025; batch adversarial loss: 0.503826\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010229; batch adversarial loss: 0.416526\n",
      "epoch 189; iter: 0; batch classifier loss: 0.003187; batch adversarial loss: 0.540434\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018013; batch adversarial loss: 0.408851\n",
      "epoch 191; iter: 0; batch classifier loss: 0.048785; batch adversarial loss: 0.427716\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023272; batch adversarial loss: 0.503675\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018207; batch adversarial loss: 0.434929\n",
      "epoch 194; iter: 0; batch classifier loss: 0.003542; batch adversarial loss: 0.426242\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014894; batch adversarial loss: 0.483542\n",
      "epoch 196; iter: 0; batch classifier loss: 0.044988; batch adversarial loss: 0.412901\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018352; batch adversarial loss: 0.404780\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017035; batch adversarial loss: 0.470380\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015407; batch adversarial loss: 0.499626\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688983; batch adversarial loss: 0.722516\n",
      "epoch 1; iter: 0; batch classifier loss: 0.462946; batch adversarial loss: 0.656802\n",
      "epoch 2; iter: 0; batch classifier loss: 0.386082; batch adversarial loss: 0.636171\n",
      "epoch 3; iter: 0; batch classifier loss: 0.401112; batch adversarial loss: 0.613528\n",
      "epoch 4; iter: 0; batch classifier loss: 0.339856; batch adversarial loss: 0.565295\n",
      "epoch 5; iter: 0; batch classifier loss: 0.330278; batch adversarial loss: 0.569851\n",
      "epoch 6; iter: 0; batch classifier loss: 0.308887; batch adversarial loss: 0.549647\n",
      "epoch 7; iter: 0; batch classifier loss: 0.294789; batch adversarial loss: 0.563455\n",
      "epoch 8; iter: 0; batch classifier loss: 0.408641; batch adversarial loss: 0.537179\n",
      "epoch 9; iter: 0; batch classifier loss: 0.462776; batch adversarial loss: 0.545740\n",
      "epoch 10; iter: 0; batch classifier loss: 0.303424; batch adversarial loss: 0.592349\n",
      "epoch 11; iter: 0; batch classifier loss: 0.291831; batch adversarial loss: 0.529077\n",
      "epoch 12; iter: 0; batch classifier loss: 0.340399; batch adversarial loss: 0.532674\n",
      "epoch 13; iter: 0; batch classifier loss: 0.347719; batch adversarial loss: 0.519768\n",
      "epoch 14; iter: 0; batch classifier loss: 0.323771; batch adversarial loss: 0.560471\n",
      "epoch 15; iter: 0; batch classifier loss: 0.346458; batch adversarial loss: 0.515562\n",
      "epoch 16; iter: 0; batch classifier loss: 0.280972; batch adversarial loss: 0.474942\n",
      "epoch 17; iter: 0; batch classifier loss: 0.234065; batch adversarial loss: 0.541953\n",
      "epoch 18; iter: 0; batch classifier loss: 0.260590; batch adversarial loss: 0.565964\n",
      "epoch 19; iter: 0; batch classifier loss: 0.299204; batch adversarial loss: 0.487356\n",
      "epoch 20; iter: 0; batch classifier loss: 0.273687; batch adversarial loss: 0.474919\n",
      "epoch 21; iter: 0; batch classifier loss: 0.261876; batch adversarial loss: 0.496569\n",
      "epoch 22; iter: 0; batch classifier loss: 0.262490; batch adversarial loss: 0.508476\n",
      "epoch 23; iter: 0; batch classifier loss: 0.219320; batch adversarial loss: 0.454578\n",
      "epoch 24; iter: 0; batch classifier loss: 0.220308; batch adversarial loss: 0.425399\n",
      "epoch 25; iter: 0; batch classifier loss: 0.188446; batch adversarial loss: 0.435383\n",
      "epoch 26; iter: 0; batch classifier loss: 0.224054; batch adversarial loss: 0.463617\n",
      "epoch 27; iter: 0; batch classifier loss: 0.195668; batch adversarial loss: 0.574648\n",
      "epoch 28; iter: 0; batch classifier loss: 0.223388; batch adversarial loss: 0.520218\n",
      "epoch 29; iter: 0; batch classifier loss: 0.191637; batch adversarial loss: 0.445544\n",
      "epoch 30; iter: 0; batch classifier loss: 0.260110; batch adversarial loss: 0.445683\n",
      "epoch 31; iter: 0; batch classifier loss: 0.232263; batch adversarial loss: 0.457863\n",
      "epoch 32; iter: 0; batch classifier loss: 0.194855; batch adversarial loss: 0.486103\n",
      "epoch 33; iter: 0; batch classifier loss: 0.161006; batch adversarial loss: 0.441634\n",
      "epoch 34; iter: 0; batch classifier loss: 0.170162; batch adversarial loss: 0.499731\n",
      "epoch 35; iter: 0; batch classifier loss: 0.254227; batch adversarial loss: 0.411457\n",
      "epoch 36; iter: 0; batch classifier loss: 0.162475; batch adversarial loss: 0.570958\n",
      "epoch 37; iter: 0; batch classifier loss: 0.163003; batch adversarial loss: 0.507952\n",
      "epoch 38; iter: 0; batch classifier loss: 0.191409; batch adversarial loss: 0.586844\n",
      "epoch 39; iter: 0; batch classifier loss: 0.227553; batch adversarial loss: 0.545056\n",
      "epoch 40; iter: 0; batch classifier loss: 0.211547; batch adversarial loss: 0.469341\n",
      "epoch 41; iter: 0; batch classifier loss: 0.163530; batch adversarial loss: 0.489850\n",
      "epoch 42; iter: 0; batch classifier loss: 0.137325; batch adversarial loss: 0.530527\n",
      "epoch 43; iter: 0; batch classifier loss: 0.178929; batch adversarial loss: 0.469212\n",
      "epoch 44; iter: 0; batch classifier loss: 0.153981; batch adversarial loss: 0.469808\n",
      "epoch 45; iter: 0; batch classifier loss: 0.145560; batch adversarial loss: 0.488090\n",
      "epoch 46; iter: 0; batch classifier loss: 0.152520; batch adversarial loss: 0.451776\n",
      "epoch 47; iter: 0; batch classifier loss: 0.151408; batch adversarial loss: 0.380735\n",
      "epoch 48; iter: 0; batch classifier loss: 0.156687; batch adversarial loss: 0.469862\n",
      "epoch 49; iter: 0; batch classifier loss: 0.183797; batch adversarial loss: 0.464263\n",
      "epoch 50; iter: 0; batch classifier loss: 0.126898; batch adversarial loss: 0.522452\n",
      "epoch 51; iter: 0; batch classifier loss: 0.171129; batch adversarial loss: 0.398440\n",
      "epoch 52; iter: 0; batch classifier loss: 0.139025; batch adversarial loss: 0.515783\n",
      "epoch 53; iter: 0; batch classifier loss: 0.127420; batch adversarial loss: 0.493223\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127753; batch adversarial loss: 0.433909\n",
      "epoch 55; iter: 0; batch classifier loss: 0.121632; batch adversarial loss: 0.476455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.110856; batch adversarial loss: 0.468858\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072498; batch adversarial loss: 0.552299\n",
      "epoch 58; iter: 0; batch classifier loss: 0.068939; batch adversarial loss: 0.529598\n",
      "epoch 59; iter: 0; batch classifier loss: 0.128810; batch adversarial loss: 0.419533\n",
      "epoch 60; iter: 0; batch classifier loss: 0.130370; batch adversarial loss: 0.493849\n",
      "epoch 61; iter: 0; batch classifier loss: 0.082858; batch adversarial loss: 0.361029\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087277; batch adversarial loss: 0.431357\n",
      "epoch 63; iter: 0; batch classifier loss: 0.081917; batch adversarial loss: 0.482320\n",
      "epoch 64; iter: 0; batch classifier loss: 0.079805; batch adversarial loss: 0.377627\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077588; batch adversarial loss: 0.432842\n",
      "epoch 66; iter: 0; batch classifier loss: 0.081789; batch adversarial loss: 0.559358\n",
      "epoch 67; iter: 0; batch classifier loss: 0.137336; batch adversarial loss: 0.494565\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081497; batch adversarial loss: 0.381856\n",
      "epoch 69; iter: 0; batch classifier loss: 0.053691; batch adversarial loss: 0.440562\n",
      "epoch 70; iter: 0; batch classifier loss: 0.122246; batch adversarial loss: 0.476278\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071795; batch adversarial loss: 0.436616\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100957; batch adversarial loss: 0.446096\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076922; batch adversarial loss: 0.528537\n",
      "epoch 74; iter: 0; batch classifier loss: 0.126664; batch adversarial loss: 0.570502\n",
      "epoch 75; iter: 0; batch classifier loss: 0.065794; batch adversarial loss: 0.510104\n",
      "epoch 76; iter: 0; batch classifier loss: 0.027526; batch adversarial loss: 0.466659\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069292; batch adversarial loss: 0.464362\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076724; batch adversarial loss: 0.448484\n",
      "epoch 79; iter: 0; batch classifier loss: 0.069940; batch adversarial loss: 0.385484\n",
      "epoch 80; iter: 0; batch classifier loss: 0.094265; batch adversarial loss: 0.418714\n",
      "epoch 81; iter: 0; batch classifier loss: 0.048044; batch adversarial loss: 0.637549\n",
      "epoch 82; iter: 0; batch classifier loss: 0.086247; batch adversarial loss: 0.472509\n",
      "epoch 83; iter: 0; batch classifier loss: 0.050792; batch adversarial loss: 0.466456\n",
      "epoch 84; iter: 0; batch classifier loss: 0.091585; batch adversarial loss: 0.453464\n",
      "epoch 85; iter: 0; batch classifier loss: 0.062228; batch adversarial loss: 0.475717\n",
      "epoch 86; iter: 0; batch classifier loss: 0.093742; batch adversarial loss: 0.516285\n",
      "epoch 87; iter: 0; batch classifier loss: 0.044364; batch adversarial loss: 0.394707\n",
      "epoch 88; iter: 0; batch classifier loss: 0.079693; batch adversarial loss: 0.401841\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050963; batch adversarial loss: 0.428617\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045653; batch adversarial loss: 0.393985\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052037; batch adversarial loss: 0.462384\n",
      "epoch 92; iter: 0; batch classifier loss: 0.028417; batch adversarial loss: 0.462850\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052093; batch adversarial loss: 0.379350\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058718; batch adversarial loss: 0.430639\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055385; batch adversarial loss: 0.443164\n",
      "epoch 96; iter: 0; batch classifier loss: 0.052941; batch adversarial loss: 0.405651\n",
      "epoch 97; iter: 0; batch classifier loss: 0.033397; batch adversarial loss: 0.525438\n",
      "epoch 98; iter: 0; batch classifier loss: 0.043131; batch adversarial loss: 0.423441\n",
      "epoch 99; iter: 0; batch classifier loss: 0.117685; batch adversarial loss: 0.419100\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038414; batch adversarial loss: 0.417571\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048955; batch adversarial loss: 0.550597\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033033; batch adversarial loss: 0.381856\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039806; batch adversarial loss: 0.509363\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043926; batch adversarial loss: 0.421264\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034204; batch adversarial loss: 0.549610\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042849; batch adversarial loss: 0.431947\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033937; batch adversarial loss: 0.414699\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048187; batch adversarial loss: 0.397402\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054299; batch adversarial loss: 0.512933\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041787; batch adversarial loss: 0.403967\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057513; batch adversarial loss: 0.471077\n",
      "epoch 112; iter: 0; batch classifier loss: 0.022324; batch adversarial loss: 0.475669\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028781; batch adversarial loss: 0.381232\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028772; batch adversarial loss: 0.468654\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034034; batch adversarial loss: 0.411995\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048322; batch adversarial loss: 0.417668\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030363; batch adversarial loss: 0.489230\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052345; batch adversarial loss: 0.449984\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046609; batch adversarial loss: 0.497874\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041738; batch adversarial loss: 0.450814\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038103; batch adversarial loss: 0.400008\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021963; batch adversarial loss: 0.528628\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030772; batch adversarial loss: 0.484976\n",
      "epoch 124; iter: 0; batch classifier loss: 0.063309; batch adversarial loss: 0.442074\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028650; batch adversarial loss: 0.539237\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025116; batch adversarial loss: 0.471431\n",
      "epoch 127; iter: 0; batch classifier loss: 0.015303; batch adversarial loss: 0.385293\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036624; batch adversarial loss: 0.420666\n",
      "epoch 129; iter: 0; batch classifier loss: 0.058546; batch adversarial loss: 0.453956\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030599; batch adversarial loss: 0.432830\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032048; batch adversarial loss: 0.447667\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045707; batch adversarial loss: 0.501546\n",
      "epoch 133; iter: 0; batch classifier loss: 0.012835; batch adversarial loss: 0.399531\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050370; batch adversarial loss: 0.447361\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027886; batch adversarial loss: 0.469330\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026720; batch adversarial loss: 0.435126\n",
      "epoch 137; iter: 0; batch classifier loss: 0.013335; batch adversarial loss: 0.520684\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026660; batch adversarial loss: 0.471879\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041078; batch adversarial loss: 0.503005\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040965; batch adversarial loss: 0.472949\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026204; batch adversarial loss: 0.444141\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043915; batch adversarial loss: 0.503048\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017794; batch adversarial loss: 0.551855\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017545; batch adversarial loss: 0.443852\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022904; batch adversarial loss: 0.401062\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039393; batch adversarial loss: 0.484201\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040105; batch adversarial loss: 0.469999\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023467; batch adversarial loss: 0.467888\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024202; batch adversarial loss: 0.461882\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010672; batch adversarial loss: 0.462384\n",
      "epoch 151; iter: 0; batch classifier loss: 0.006677; batch adversarial loss: 0.392633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.024880; batch adversarial loss: 0.507926\n",
      "epoch 153; iter: 0; batch classifier loss: 0.009947; batch adversarial loss: 0.401511\n",
      "epoch 154; iter: 0; batch classifier loss: 0.008416; batch adversarial loss: 0.426461\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015850; batch adversarial loss: 0.412094\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013928; batch adversarial loss: 0.487112\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017245; batch adversarial loss: 0.520635\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031010; batch adversarial loss: 0.552702\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024990; batch adversarial loss: 0.482911\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032844; batch adversarial loss: 0.492354\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015313; batch adversarial loss: 0.411791\n",
      "epoch 162; iter: 0; batch classifier loss: 0.003945; batch adversarial loss: 0.403273\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045400; batch adversarial loss: 0.446629\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030637; batch adversarial loss: 0.508403\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015498; batch adversarial loss: 0.514136\n",
      "epoch 166; iter: 0; batch classifier loss: 0.004946; batch adversarial loss: 0.383870\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022864; batch adversarial loss: 0.408607\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012877; batch adversarial loss: 0.437170\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006140; batch adversarial loss: 0.439090\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024527; batch adversarial loss: 0.358287\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017778; batch adversarial loss: 0.524141\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036966; batch adversarial loss: 0.483672\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010409; batch adversarial loss: 0.544125\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010313; batch adversarial loss: 0.431862\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018824; batch adversarial loss: 0.506190\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030506; batch adversarial loss: 0.475946\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008349; batch adversarial loss: 0.460708\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009380; batch adversarial loss: 0.502162\n",
      "epoch 179; iter: 0; batch classifier loss: 0.045482; batch adversarial loss: 0.414191\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013688; batch adversarial loss: 0.397617\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013867; batch adversarial loss: 0.430821\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011807; batch adversarial loss: 0.437230\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021207; batch adversarial loss: 0.409824\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011655; batch adversarial loss: 0.478542\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021531; batch adversarial loss: 0.365753\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014767; batch adversarial loss: 0.540539\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026811; batch adversarial loss: 0.537314\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016640; batch adversarial loss: 0.540497\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036331; batch adversarial loss: 0.446652\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018414; batch adversarial loss: 0.468610\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032697; batch adversarial loss: 0.432380\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009930; batch adversarial loss: 0.558437\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009910; batch adversarial loss: 0.526252\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030851; batch adversarial loss: 0.393834\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028159; batch adversarial loss: 0.462356\n",
      "epoch 196; iter: 0; batch classifier loss: 0.039408; batch adversarial loss: 0.443634\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009134; batch adversarial loss: 0.379864\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010057; batch adversarial loss: 0.469552\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007840; batch adversarial loss: 0.474911\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701517; batch adversarial loss: 0.878721\n",
      "epoch 1; iter: 0; batch classifier loss: 0.634897; batch adversarial loss: 0.889200\n",
      "epoch 2; iter: 0; batch classifier loss: 0.743463; batch adversarial loss: 0.841956\n",
      "epoch 3; iter: 0; batch classifier loss: 0.770511; batch adversarial loss: 0.784754\n",
      "epoch 4; iter: 0; batch classifier loss: 0.796386; batch adversarial loss: 0.754444\n",
      "epoch 5; iter: 0; batch classifier loss: 0.631911; batch adversarial loss: 0.652440\n",
      "epoch 6; iter: 0; batch classifier loss: 0.608952; batch adversarial loss: 0.599884\n",
      "epoch 7; iter: 0; batch classifier loss: 0.474096; batch adversarial loss: 0.550721\n",
      "epoch 8; iter: 0; batch classifier loss: 0.302471; batch adversarial loss: 0.535191\n",
      "epoch 9; iter: 0; batch classifier loss: 0.327762; batch adversarial loss: 0.524039\n",
      "epoch 10; iter: 0; batch classifier loss: 0.262867; batch adversarial loss: 0.484754\n",
      "epoch 11; iter: 0; batch classifier loss: 0.228276; batch adversarial loss: 0.515175\n",
      "epoch 12; iter: 0; batch classifier loss: 0.263755; batch adversarial loss: 0.526621\n",
      "epoch 13; iter: 0; batch classifier loss: 0.270062; batch adversarial loss: 0.517098\n",
      "epoch 14; iter: 0; batch classifier loss: 0.267031; batch adversarial loss: 0.540148\n",
      "epoch 15; iter: 0; batch classifier loss: 0.232856; batch adversarial loss: 0.514884\n",
      "epoch 16; iter: 0; batch classifier loss: 0.259111; batch adversarial loss: 0.516010\n",
      "epoch 17; iter: 0; batch classifier loss: 0.235960; batch adversarial loss: 0.501037\n",
      "epoch 18; iter: 0; batch classifier loss: 0.184671; batch adversarial loss: 0.485199\n",
      "epoch 19; iter: 0; batch classifier loss: 0.241230; batch adversarial loss: 0.535635\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220661; batch adversarial loss: 0.459497\n",
      "epoch 21; iter: 0; batch classifier loss: 0.217226; batch adversarial loss: 0.520193\n",
      "epoch 22; iter: 0; batch classifier loss: 0.199748; batch adversarial loss: 0.495562\n",
      "epoch 23; iter: 0; batch classifier loss: 0.169204; batch adversarial loss: 0.418484\n",
      "epoch 24; iter: 0; batch classifier loss: 0.167044; batch adversarial loss: 0.503962\n",
      "epoch 25; iter: 0; batch classifier loss: 0.145888; batch adversarial loss: 0.571909\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182222; batch adversarial loss: 0.432961\n",
      "epoch 27; iter: 0; batch classifier loss: 0.158593; batch adversarial loss: 0.382907\n",
      "epoch 28; iter: 0; batch classifier loss: 0.177613; batch adversarial loss: 0.510594\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197939; batch adversarial loss: 0.492288\n",
      "epoch 30; iter: 0; batch classifier loss: 0.178631; batch adversarial loss: 0.465602\n",
      "epoch 31; iter: 0; batch classifier loss: 0.193111; batch adversarial loss: 0.547415\n",
      "epoch 32; iter: 0; batch classifier loss: 0.145826; batch adversarial loss: 0.481750\n",
      "epoch 33; iter: 0; batch classifier loss: 0.099835; batch adversarial loss: 0.516142\n",
      "epoch 34; iter: 0; batch classifier loss: 0.158708; batch adversarial loss: 0.449520\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125811; batch adversarial loss: 0.475365\n",
      "epoch 36; iter: 0; batch classifier loss: 0.124922; batch adversarial loss: 0.466672\n",
      "epoch 37; iter: 0; batch classifier loss: 0.095547; batch adversarial loss: 0.455013\n",
      "epoch 38; iter: 0; batch classifier loss: 0.146017; batch adversarial loss: 0.498380\n",
      "epoch 39; iter: 0; batch classifier loss: 0.153351; batch adversarial loss: 0.430378\n",
      "epoch 40; iter: 0; batch classifier loss: 0.134611; batch adversarial loss: 0.459797\n",
      "epoch 41; iter: 0; batch classifier loss: 0.134600; batch adversarial loss: 0.487180\n",
      "epoch 42; iter: 0; batch classifier loss: 0.147483; batch adversarial loss: 0.364699\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112492; batch adversarial loss: 0.471368\n",
      "epoch 44; iter: 0; batch classifier loss: 0.110914; batch adversarial loss: 0.517396\n",
      "epoch 45; iter: 0; batch classifier loss: 0.083742; batch adversarial loss: 0.465219\n",
      "epoch 46; iter: 0; batch classifier loss: 0.057890; batch adversarial loss: 0.450196\n",
      "epoch 47; iter: 0; batch classifier loss: 0.130711; batch adversarial loss: 0.383682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.114488; batch adversarial loss: 0.512867\n",
      "epoch 49; iter: 0; batch classifier loss: 0.127837; batch adversarial loss: 0.451088\n",
      "epoch 50; iter: 0; batch classifier loss: 0.114360; batch adversarial loss: 0.453011\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122535; batch adversarial loss: 0.461140\n",
      "epoch 52; iter: 0; batch classifier loss: 0.091671; batch adversarial loss: 0.453595\n",
      "epoch 53; iter: 0; batch classifier loss: 0.113424; batch adversarial loss: 0.583683\n",
      "epoch 54; iter: 0; batch classifier loss: 0.119552; batch adversarial loss: 0.462316\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103385; batch adversarial loss: 0.465720\n",
      "epoch 56; iter: 0; batch classifier loss: 0.116222; batch adversarial loss: 0.439946\n",
      "epoch 57; iter: 0; batch classifier loss: 0.165860; batch adversarial loss: 0.436032\n",
      "epoch 58; iter: 0; batch classifier loss: 0.143706; batch adversarial loss: 0.522306\n",
      "epoch 59; iter: 0; batch classifier loss: 0.093717; batch adversarial loss: 0.446940\n",
      "epoch 60; iter: 0; batch classifier loss: 0.111688; batch adversarial loss: 0.476822\n",
      "epoch 61; iter: 0; batch classifier loss: 0.070456; batch adversarial loss: 0.475569\n",
      "epoch 62; iter: 0; batch classifier loss: 0.125561; batch adversarial loss: 0.372935\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085469; batch adversarial loss: 0.529566\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076004; batch adversarial loss: 0.521883\n",
      "epoch 65; iter: 0; batch classifier loss: 0.060763; batch adversarial loss: 0.526464\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086540; batch adversarial loss: 0.518912\n",
      "epoch 67; iter: 0; batch classifier loss: 0.086455; batch adversarial loss: 0.322345\n",
      "epoch 68; iter: 0; batch classifier loss: 0.087552; batch adversarial loss: 0.450781\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094898; batch adversarial loss: 0.472429\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091604; batch adversarial loss: 0.494403\n",
      "epoch 71; iter: 0; batch classifier loss: 0.087867; batch adversarial loss: 0.496307\n",
      "epoch 72; iter: 0; batch classifier loss: 0.093027; batch adversarial loss: 0.593503\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089759; batch adversarial loss: 0.451103\n",
      "epoch 74; iter: 0; batch classifier loss: 0.088674; batch adversarial loss: 0.489499\n",
      "epoch 75; iter: 0; batch classifier loss: 0.062450; batch adversarial loss: 0.437507\n",
      "epoch 76; iter: 0; batch classifier loss: 0.074443; batch adversarial loss: 0.505783\n",
      "epoch 77; iter: 0; batch classifier loss: 0.053335; batch adversarial loss: 0.486893\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056403; batch adversarial loss: 0.543275\n",
      "epoch 79; iter: 0; batch classifier loss: 0.121238; batch adversarial loss: 0.375738\n",
      "epoch 80; iter: 0; batch classifier loss: 0.123738; batch adversarial loss: 0.461074\n",
      "epoch 81; iter: 0; batch classifier loss: 0.078500; batch adversarial loss: 0.463253\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061149; batch adversarial loss: 0.486030\n",
      "epoch 83; iter: 0; batch classifier loss: 0.130330; batch adversarial loss: 0.507919\n",
      "epoch 84; iter: 0; batch classifier loss: 0.121311; batch adversarial loss: 0.416755\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067606; batch adversarial loss: 0.547032\n",
      "epoch 86; iter: 0; batch classifier loss: 0.049330; batch adversarial loss: 0.486659\n",
      "epoch 87; iter: 0; batch classifier loss: 0.119202; batch adversarial loss: 0.522638\n",
      "epoch 88; iter: 0; batch classifier loss: 0.084413; batch adversarial loss: 0.391567\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059824; batch adversarial loss: 0.487498\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059096; batch adversarial loss: 0.461326\n",
      "epoch 91; iter: 0; batch classifier loss: 0.042594; batch adversarial loss: 0.531267\n",
      "epoch 92; iter: 0; batch classifier loss: 0.075860; batch adversarial loss: 0.457182\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052790; batch adversarial loss: 0.475826\n",
      "epoch 94; iter: 0; batch classifier loss: 0.111468; batch adversarial loss: 0.480163\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054090; batch adversarial loss: 0.484761\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063114; batch adversarial loss: 0.385519\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072612; batch adversarial loss: 0.427690\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052502; batch adversarial loss: 0.500491\n",
      "epoch 99; iter: 0; batch classifier loss: 0.100108; batch adversarial loss: 0.510273\n",
      "epoch 100; iter: 0; batch classifier loss: 0.089898; batch adversarial loss: 0.453657\n",
      "epoch 101; iter: 0; batch classifier loss: 0.024088; batch adversarial loss: 0.432428\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048835; batch adversarial loss: 0.460350\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059839; batch adversarial loss: 0.539797\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069375; batch adversarial loss: 0.404450\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075346; batch adversarial loss: 0.429410\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057330; batch adversarial loss: 0.455788\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063416; batch adversarial loss: 0.493180\n",
      "epoch 108; iter: 0; batch classifier loss: 0.066487; batch adversarial loss: 0.544417\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042533; batch adversarial loss: 0.557249\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033981; batch adversarial loss: 0.459855\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046154; batch adversarial loss: 0.465981\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053154; batch adversarial loss: 0.463227\n",
      "epoch 113; iter: 0; batch classifier loss: 0.068731; batch adversarial loss: 0.483812\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062560; batch adversarial loss: 0.481680\n",
      "epoch 115; iter: 0; batch classifier loss: 0.088644; batch adversarial loss: 0.486566\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043357; batch adversarial loss: 0.521857\n",
      "epoch 117; iter: 0; batch classifier loss: 0.088818; batch adversarial loss: 0.540726\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035713; batch adversarial loss: 0.438119\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040668; batch adversarial loss: 0.461785\n",
      "epoch 120; iter: 0; batch classifier loss: 0.101611; batch adversarial loss: 0.462426\n",
      "epoch 121; iter: 0; batch classifier loss: 0.020342; batch adversarial loss: 0.505778\n",
      "epoch 122; iter: 0; batch classifier loss: 0.058578; batch adversarial loss: 0.477968\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057104; batch adversarial loss: 0.463756\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023793; batch adversarial loss: 0.452940\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057161; batch adversarial loss: 0.400092\n",
      "epoch 126; iter: 0; batch classifier loss: 0.016474; batch adversarial loss: 0.488980\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025122; batch adversarial loss: 0.446214\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051141; batch adversarial loss: 0.410814\n",
      "epoch 129; iter: 0; batch classifier loss: 0.049094; batch adversarial loss: 0.384128\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047194; batch adversarial loss: 0.442051\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048113; batch adversarial loss: 0.501160\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053017; batch adversarial loss: 0.460560\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044619; batch adversarial loss: 0.505154\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035279; batch adversarial loss: 0.482452\n",
      "epoch 135; iter: 0; batch classifier loss: 0.056823; batch adversarial loss: 0.473665\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020874; batch adversarial loss: 0.518099\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026984; batch adversarial loss: 0.442863\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046988; batch adversarial loss: 0.403603\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049604; batch adversarial loss: 0.447105\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023530; batch adversarial loss: 0.389746\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034968; batch adversarial loss: 0.386146\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041543; batch adversarial loss: 0.450291\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051066; batch adversarial loss: 0.449955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.027167; batch adversarial loss: 0.506940\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029390; batch adversarial loss: 0.548516\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041063; batch adversarial loss: 0.500837\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038269; batch adversarial loss: 0.414199\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023684; batch adversarial loss: 0.422933\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034365; batch adversarial loss: 0.471598\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035410; batch adversarial loss: 0.427297\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042533; batch adversarial loss: 0.451434\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015848; batch adversarial loss: 0.465991\n",
      "epoch 153; iter: 0; batch classifier loss: 0.054132; batch adversarial loss: 0.449635\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025535; batch adversarial loss: 0.521735\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031308; batch adversarial loss: 0.408168\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045539; batch adversarial loss: 0.525076\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006754; batch adversarial loss: 0.364260\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034398; batch adversarial loss: 0.471742\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042182; batch adversarial loss: 0.462237\n",
      "epoch 160; iter: 0; batch classifier loss: 0.050496; batch adversarial loss: 0.475562\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026759; batch adversarial loss: 0.338630\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024463; batch adversarial loss: 0.425171\n",
      "epoch 163; iter: 0; batch classifier loss: 0.051638; batch adversarial loss: 0.563527\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030048; batch adversarial loss: 0.449471\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023776; batch adversarial loss: 0.516560\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010793; batch adversarial loss: 0.441018\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019681; batch adversarial loss: 0.536043\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028930; batch adversarial loss: 0.411772\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007685; batch adversarial loss: 0.525048\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021805; batch adversarial loss: 0.365663\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019480; batch adversarial loss: 0.464323\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013903; batch adversarial loss: 0.532913\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017402; batch adversarial loss: 0.428873\n",
      "epoch 174; iter: 0; batch classifier loss: 0.046210; batch adversarial loss: 0.492539\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017049; batch adversarial loss: 0.384744\n",
      "epoch 176; iter: 0; batch classifier loss: 0.038158; batch adversarial loss: 0.433988\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027702; batch adversarial loss: 0.473510\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032685; batch adversarial loss: 0.516520\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030239; batch adversarial loss: 0.391368\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015084; batch adversarial loss: 0.410662\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021434; batch adversarial loss: 0.425247\n",
      "epoch 182; iter: 0; batch classifier loss: 0.004192; batch adversarial loss: 0.519416\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008904; batch adversarial loss: 0.489314\n",
      "epoch 184; iter: 0; batch classifier loss: 0.048596; batch adversarial loss: 0.434698\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011264; batch adversarial loss: 0.416083\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031071; batch adversarial loss: 0.375781\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018640; batch adversarial loss: 0.450403\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022676; batch adversarial loss: 0.525588\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009062; batch adversarial loss: 0.505396\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009564; batch adversarial loss: 0.500799\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021081; batch adversarial loss: 0.451453\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021395; batch adversarial loss: 0.444320\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009529; batch adversarial loss: 0.495020\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023385; batch adversarial loss: 0.394466\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010349; batch adversarial loss: 0.448636\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010673; batch adversarial loss: 0.391593\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014533; batch adversarial loss: 0.501787\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005946; batch adversarial loss: 0.382033\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031877; batch adversarial loss: 0.392937\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720641; batch adversarial loss: 0.494071\n",
      "epoch 1; iter: 0; batch classifier loss: 0.511639; batch adversarial loss: 0.594875\n",
      "epoch 2; iter: 0; batch classifier loss: 0.439796; batch adversarial loss: 0.624771\n",
      "epoch 3; iter: 0; batch classifier loss: 0.403955; batch adversarial loss: 0.539384\n",
      "epoch 4; iter: 0; batch classifier loss: 0.318291; batch adversarial loss: 0.580384\n",
      "epoch 5; iter: 0; batch classifier loss: 0.291211; batch adversarial loss: 0.502380\n",
      "epoch 6; iter: 0; batch classifier loss: 0.270962; batch adversarial loss: 0.512514\n",
      "epoch 7; iter: 0; batch classifier loss: 0.273280; batch adversarial loss: 0.564329\n",
      "epoch 8; iter: 0; batch classifier loss: 0.237782; batch adversarial loss: 0.556647\n",
      "epoch 9; iter: 0; batch classifier loss: 0.251781; batch adversarial loss: 0.532426\n",
      "epoch 10; iter: 0; batch classifier loss: 0.270026; batch adversarial loss: 0.506029\n",
      "epoch 11; iter: 0; batch classifier loss: 0.295787; batch adversarial loss: 0.517735\n",
      "epoch 12; iter: 0; batch classifier loss: 0.275475; batch adversarial loss: 0.530668\n",
      "epoch 13; iter: 0; batch classifier loss: 0.284677; batch adversarial loss: 0.552393\n",
      "epoch 14; iter: 0; batch classifier loss: 0.272854; batch adversarial loss: 0.556963\n",
      "epoch 15; iter: 0; batch classifier loss: 0.233703; batch adversarial loss: 0.583301\n",
      "epoch 16; iter: 0; batch classifier loss: 0.276289; batch adversarial loss: 0.467793\n",
      "epoch 17; iter: 0; batch classifier loss: 0.347943; batch adversarial loss: 0.642588\n",
      "epoch 18; iter: 0; batch classifier loss: 0.343578; batch adversarial loss: 0.492301\n",
      "epoch 19; iter: 0; batch classifier loss: 0.417817; batch adversarial loss: 0.486375\n",
      "epoch 20; iter: 0; batch classifier loss: 0.368633; batch adversarial loss: 0.490790\n",
      "epoch 21; iter: 0; batch classifier loss: 0.411210; batch adversarial loss: 0.504587\n",
      "epoch 22; iter: 0; batch classifier loss: 0.246828; batch adversarial loss: 0.510752\n",
      "epoch 23; iter: 0; batch classifier loss: 0.191988; batch adversarial loss: 0.552157\n",
      "epoch 24; iter: 0; batch classifier loss: 0.163923; batch adversarial loss: 0.477590\n",
      "epoch 25; iter: 0; batch classifier loss: 0.165628; batch adversarial loss: 0.490156\n",
      "epoch 26; iter: 0; batch classifier loss: 0.148663; batch adversarial loss: 0.469404\n",
      "epoch 27; iter: 0; batch classifier loss: 0.163071; batch adversarial loss: 0.488620\n",
      "epoch 28; iter: 0; batch classifier loss: 0.124528; batch adversarial loss: 0.445146\n",
      "epoch 29; iter: 0; batch classifier loss: 0.113851; batch adversarial loss: 0.473346\n",
      "epoch 30; iter: 0; batch classifier loss: 0.133192; batch adversarial loss: 0.430503\n",
      "epoch 31; iter: 0; batch classifier loss: 0.112024; batch adversarial loss: 0.505120\n",
      "epoch 32; iter: 0; batch classifier loss: 0.098732; batch adversarial loss: 0.431973\n",
      "epoch 33; iter: 0; batch classifier loss: 0.137580; batch adversarial loss: 0.524048\n",
      "epoch 34; iter: 0; batch classifier loss: 0.154709; batch adversarial loss: 0.418398\n",
      "epoch 35; iter: 0; batch classifier loss: 0.123984; batch adversarial loss: 0.450937\n",
      "epoch 36; iter: 0; batch classifier loss: 0.097171; batch adversarial loss: 0.453094\n",
      "epoch 37; iter: 0; batch classifier loss: 0.133692; batch adversarial loss: 0.489920\n",
      "epoch 38; iter: 0; batch classifier loss: 0.105650; batch adversarial loss: 0.537323\n",
      "epoch 39; iter: 0; batch classifier loss: 0.134015; batch adversarial loss: 0.454913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.096050; batch adversarial loss: 0.495620\n",
      "epoch 41; iter: 0; batch classifier loss: 0.137861; batch adversarial loss: 0.446660\n",
      "epoch 42; iter: 0; batch classifier loss: 0.085442; batch adversarial loss: 0.403264\n",
      "epoch 43; iter: 0; batch classifier loss: 0.071810; batch adversarial loss: 0.550243\n",
      "epoch 44; iter: 0; batch classifier loss: 0.126316; batch adversarial loss: 0.533740\n",
      "epoch 45; iter: 0; batch classifier loss: 0.088663; batch adversarial loss: 0.468215\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113390; batch adversarial loss: 0.391681\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100290; batch adversarial loss: 0.436768\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099270; batch adversarial loss: 0.409499\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094384; batch adversarial loss: 0.359684\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094355; batch adversarial loss: 0.501330\n",
      "epoch 51; iter: 0; batch classifier loss: 0.069545; batch adversarial loss: 0.413997\n",
      "epoch 52; iter: 0; batch classifier loss: 0.163572; batch adversarial loss: 0.410966\n",
      "epoch 53; iter: 0; batch classifier loss: 0.092009; batch adversarial loss: 0.488969\n",
      "epoch 54; iter: 0; batch classifier loss: 0.120395; batch adversarial loss: 0.450802\n",
      "epoch 55; iter: 0; batch classifier loss: 0.076203; batch adversarial loss: 0.488936\n",
      "epoch 56; iter: 0; batch classifier loss: 0.092448; batch adversarial loss: 0.440632\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061224; batch adversarial loss: 0.520612\n",
      "epoch 58; iter: 0; batch classifier loss: 0.057439; batch adversarial loss: 0.513479\n",
      "epoch 59; iter: 0; batch classifier loss: 0.091731; batch adversarial loss: 0.466140\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070590; batch adversarial loss: 0.451885\n",
      "epoch 61; iter: 0; batch classifier loss: 0.054964; batch adversarial loss: 0.421613\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090420; batch adversarial loss: 0.518251\n",
      "epoch 63; iter: 0; batch classifier loss: 0.024907; batch adversarial loss: 0.507432\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082164; batch adversarial loss: 0.382551\n",
      "epoch 65; iter: 0; batch classifier loss: 0.100645; batch adversarial loss: 0.521222\n",
      "epoch 66; iter: 0; batch classifier loss: 0.106845; batch adversarial loss: 0.378421\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080134; batch adversarial loss: 0.490085\n",
      "epoch 68; iter: 0; batch classifier loss: 0.118279; batch adversarial loss: 0.424572\n",
      "epoch 69; iter: 0; batch classifier loss: 0.124224; batch adversarial loss: 0.516937\n",
      "epoch 70; iter: 0; batch classifier loss: 0.118897; batch adversarial loss: 0.420386\n",
      "epoch 71; iter: 0; batch classifier loss: 0.094928; batch adversarial loss: 0.406065\n",
      "epoch 72; iter: 0; batch classifier loss: 0.098116; batch adversarial loss: 0.470079\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090470; batch adversarial loss: 0.444445\n",
      "epoch 74; iter: 0; batch classifier loss: 0.090118; batch adversarial loss: 0.531922\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069384; batch adversarial loss: 0.475407\n",
      "epoch 76; iter: 0; batch classifier loss: 0.113369; batch adversarial loss: 0.424967\n",
      "epoch 77; iter: 0; batch classifier loss: 0.093618; batch adversarial loss: 0.498318\n",
      "epoch 78; iter: 0; batch classifier loss: 0.103881; batch adversarial loss: 0.409187\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085943; batch adversarial loss: 0.549529\n",
      "epoch 80; iter: 0; batch classifier loss: 0.046093; batch adversarial loss: 0.486060\n",
      "epoch 81; iter: 0; batch classifier loss: 0.102350; batch adversarial loss: 0.514474\n",
      "epoch 82; iter: 0; batch classifier loss: 0.102478; batch adversarial loss: 0.431692\n",
      "epoch 83; iter: 0; batch classifier loss: 0.119510; batch adversarial loss: 0.362261\n",
      "epoch 84; iter: 0; batch classifier loss: 0.130734; batch adversarial loss: 0.477776\n",
      "epoch 85; iter: 0; batch classifier loss: 0.096849; batch adversarial loss: 0.487273\n",
      "epoch 86; iter: 0; batch classifier loss: 0.038366; batch adversarial loss: 0.387351\n",
      "epoch 87; iter: 0; batch classifier loss: 0.124103; batch adversarial loss: 0.498650\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069687; batch adversarial loss: 0.344072\n",
      "epoch 89; iter: 0; batch classifier loss: 0.083060; batch adversarial loss: 0.448924\n",
      "epoch 90; iter: 0; batch classifier loss: 0.129304; batch adversarial loss: 0.499233\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070634; batch adversarial loss: 0.515909\n",
      "epoch 92; iter: 0; batch classifier loss: 0.117206; batch adversarial loss: 0.437714\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064777; batch adversarial loss: 0.544937\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068838; batch adversarial loss: 0.512203\n",
      "epoch 95; iter: 0; batch classifier loss: 0.067401; batch adversarial loss: 0.417788\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043956; batch adversarial loss: 0.421815\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066467; batch adversarial loss: 0.483805\n",
      "epoch 98; iter: 0; batch classifier loss: 0.104362; batch adversarial loss: 0.503860\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058160; batch adversarial loss: 0.492676\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076370; batch adversarial loss: 0.424724\n",
      "epoch 101; iter: 0; batch classifier loss: 0.076396; batch adversarial loss: 0.495944\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053508; batch adversarial loss: 0.483539\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058863; batch adversarial loss: 0.498505\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059869; batch adversarial loss: 0.479758\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051391; batch adversarial loss: 0.458085\n",
      "epoch 106; iter: 0; batch classifier loss: 0.069859; batch adversarial loss: 0.419919\n",
      "epoch 107; iter: 0; batch classifier loss: 0.095204; batch adversarial loss: 0.376052\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069362; batch adversarial loss: 0.397206\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045779; batch adversarial loss: 0.425483\n",
      "epoch 110; iter: 0; batch classifier loss: 0.032900; batch adversarial loss: 0.439872\n",
      "epoch 111; iter: 0; batch classifier loss: 0.067718; batch adversarial loss: 0.532503\n",
      "epoch 112; iter: 0; batch classifier loss: 0.071023; batch adversarial loss: 0.448043\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027782; batch adversarial loss: 0.497048\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044674; batch adversarial loss: 0.549244\n",
      "epoch 115; iter: 0; batch classifier loss: 0.090394; batch adversarial loss: 0.496266\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058766; batch adversarial loss: 0.441854\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067334; batch adversarial loss: 0.382445\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039821; batch adversarial loss: 0.428678\n",
      "epoch 119; iter: 0; batch classifier loss: 0.067657; batch adversarial loss: 0.437373\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036902; batch adversarial loss: 0.464443\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054194; batch adversarial loss: 0.468611\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038364; batch adversarial loss: 0.389273\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052972; batch adversarial loss: 0.448097\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029269; batch adversarial loss: 0.497566\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017612; batch adversarial loss: 0.577459\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057666; batch adversarial loss: 0.500655\n",
      "epoch 127; iter: 0; batch classifier loss: 0.072439; batch adversarial loss: 0.434846\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033768; batch adversarial loss: 0.520406\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042068; batch adversarial loss: 0.421063\n",
      "epoch 130; iter: 0; batch classifier loss: 0.062284; batch adversarial loss: 0.501010\n",
      "epoch 131; iter: 0; batch classifier loss: 0.067979; batch adversarial loss: 0.487567\n",
      "epoch 132; iter: 0; batch classifier loss: 0.065991; batch adversarial loss: 0.407219\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043775; batch adversarial loss: 0.465885\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031211; batch adversarial loss: 0.483760\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046346; batch adversarial loss: 0.479937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.043725; batch adversarial loss: 0.467950\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026110; batch adversarial loss: 0.366455\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021773; batch adversarial loss: 0.445184\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025697; batch adversarial loss: 0.465423\n",
      "epoch 140; iter: 0; batch classifier loss: 0.064718; batch adversarial loss: 0.578406\n",
      "epoch 141; iter: 0; batch classifier loss: 0.056416; batch adversarial loss: 0.494620\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017493; batch adversarial loss: 0.523700\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042115; batch adversarial loss: 0.507018\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031995; batch adversarial loss: 0.468369\n",
      "epoch 145; iter: 0; batch classifier loss: 0.051059; batch adversarial loss: 0.506867\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033614; batch adversarial loss: 0.447909\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038296; batch adversarial loss: 0.408942\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028262; batch adversarial loss: 0.466150\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029774; batch adversarial loss: 0.428461\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019260; batch adversarial loss: 0.513202\n",
      "epoch 151; iter: 0; batch classifier loss: 0.007800; batch adversarial loss: 0.435746\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018980; batch adversarial loss: 0.563258\n",
      "epoch 153; iter: 0; batch classifier loss: 0.051241; batch adversarial loss: 0.374912\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032868; batch adversarial loss: 0.443076\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022347; batch adversarial loss: 0.377566\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022735; batch adversarial loss: 0.480093\n",
      "epoch 157; iter: 0; batch classifier loss: 0.058534; batch adversarial loss: 0.448731\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008345; batch adversarial loss: 0.518049\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012638; batch adversarial loss: 0.518262\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010343; batch adversarial loss: 0.358518\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015582; batch adversarial loss: 0.472323\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013591; batch adversarial loss: 0.491289\n",
      "epoch 163; iter: 0; batch classifier loss: 0.046017; batch adversarial loss: 0.451717\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036901; batch adversarial loss: 0.373331\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018385; batch adversarial loss: 0.455208\n",
      "epoch 166; iter: 0; batch classifier loss: 0.048598; batch adversarial loss: 0.458370\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026072; batch adversarial loss: 0.528628\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017059; batch adversarial loss: 0.501535\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038052; batch adversarial loss: 0.396372\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032758; batch adversarial loss: 0.474020\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017099; batch adversarial loss: 0.443926\n",
      "epoch 172; iter: 0; batch classifier loss: 0.041865; batch adversarial loss: 0.446523\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006774; batch adversarial loss: 0.448662\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030092; batch adversarial loss: 0.435631\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013691; batch adversarial loss: 0.480178\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018383; batch adversarial loss: 0.439716\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007098; batch adversarial loss: 0.532712\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022682; batch adversarial loss: 0.402244\n",
      "epoch 179; iter: 0; batch classifier loss: 0.079232; batch adversarial loss: 0.457050\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016341; batch adversarial loss: 0.579479\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030500; batch adversarial loss: 0.463439\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021687; batch adversarial loss: 0.387471\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019670; batch adversarial loss: 0.441729\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019733; batch adversarial loss: 0.434882\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018972; batch adversarial loss: 0.425414\n",
      "epoch 186; iter: 0; batch classifier loss: 0.047616; batch adversarial loss: 0.491871\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042778; batch adversarial loss: 0.418892\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027682; batch adversarial loss: 0.375362\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010907; batch adversarial loss: 0.504159\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020693; batch adversarial loss: 0.500196\n",
      "epoch 191; iter: 0; batch classifier loss: 0.041759; batch adversarial loss: 0.507840\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014922; batch adversarial loss: 0.428531\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016340; batch adversarial loss: 0.420528\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019355; batch adversarial loss: 0.435000\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023295; batch adversarial loss: 0.379798\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023919; batch adversarial loss: 0.454640\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012434; batch adversarial loss: 0.425995\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007378; batch adversarial loss: 0.455200\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026565; batch adversarial loss: 0.335214\n",
      "epoch 0; iter: 0; batch classifier loss: 0.721645; batch adversarial loss: 0.632243\n",
      "epoch 1; iter: 0; batch classifier loss: 0.396377; batch adversarial loss: 0.621861\n",
      "epoch 2; iter: 0; batch classifier loss: 0.352112; batch adversarial loss: 0.571448\n",
      "epoch 3; iter: 0; batch classifier loss: 0.426463; batch adversarial loss: 0.597236\n",
      "epoch 4; iter: 0; batch classifier loss: 0.439920; batch adversarial loss: 0.594349\n",
      "epoch 5; iter: 0; batch classifier loss: 0.421357; batch adversarial loss: 0.571980\n",
      "epoch 6; iter: 0; batch classifier loss: 0.466665; batch adversarial loss: 0.568138\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549426; batch adversarial loss: 0.571524\n",
      "epoch 8; iter: 0; batch classifier loss: 0.469392; batch adversarial loss: 0.593213\n",
      "epoch 9; iter: 0; batch classifier loss: 0.569710; batch adversarial loss: 0.571247\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484646; batch adversarial loss: 0.564903\n",
      "epoch 11; iter: 0; batch classifier loss: 0.376409; batch adversarial loss: 0.540867\n",
      "epoch 12; iter: 0; batch classifier loss: 0.313310; batch adversarial loss: 0.530578\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336504; batch adversarial loss: 0.536920\n",
      "epoch 14; iter: 0; batch classifier loss: 0.305941; batch adversarial loss: 0.491372\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274736; batch adversarial loss: 0.523115\n",
      "epoch 16; iter: 0; batch classifier loss: 0.320639; batch adversarial loss: 0.532978\n",
      "epoch 17; iter: 0; batch classifier loss: 0.283537; batch adversarial loss: 0.538484\n",
      "epoch 18; iter: 0; batch classifier loss: 0.235066; batch adversarial loss: 0.475102\n",
      "epoch 19; iter: 0; batch classifier loss: 0.226777; batch adversarial loss: 0.542533\n",
      "epoch 20; iter: 0; batch classifier loss: 0.265383; batch adversarial loss: 0.491818\n",
      "epoch 21; iter: 0; batch classifier loss: 0.240093; batch adversarial loss: 0.568683\n",
      "epoch 22; iter: 0; batch classifier loss: 0.168447; batch adversarial loss: 0.483975\n",
      "epoch 23; iter: 0; batch classifier loss: 0.225429; batch adversarial loss: 0.464748\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195081; batch adversarial loss: 0.450286\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179224; batch adversarial loss: 0.516381\n",
      "epoch 26; iter: 0; batch classifier loss: 0.200740; batch adversarial loss: 0.437230\n",
      "epoch 27; iter: 0; batch classifier loss: 0.158242; batch adversarial loss: 0.563426\n",
      "epoch 28; iter: 0; batch classifier loss: 0.216970; batch adversarial loss: 0.379355\n",
      "epoch 29; iter: 0; batch classifier loss: 0.224227; batch adversarial loss: 0.486876\n",
      "epoch 30; iter: 0; batch classifier loss: 0.147149; batch adversarial loss: 0.425673\n",
      "epoch 31; iter: 0; batch classifier loss: 0.131205; batch adversarial loss: 0.494338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.150718; batch adversarial loss: 0.533960\n",
      "epoch 33; iter: 0; batch classifier loss: 0.165782; batch adversarial loss: 0.515253\n",
      "epoch 34; iter: 0; batch classifier loss: 0.156657; batch adversarial loss: 0.414968\n",
      "epoch 35; iter: 0; batch classifier loss: 0.212855; batch adversarial loss: 0.394462\n",
      "epoch 36; iter: 0; batch classifier loss: 0.175052; batch adversarial loss: 0.484215\n",
      "epoch 37; iter: 0; batch classifier loss: 0.114748; batch adversarial loss: 0.419860\n",
      "epoch 38; iter: 0; batch classifier loss: 0.150442; batch adversarial loss: 0.442841\n",
      "epoch 39; iter: 0; batch classifier loss: 0.154843; batch adversarial loss: 0.520727\n",
      "epoch 40; iter: 0; batch classifier loss: 0.127510; batch adversarial loss: 0.544804\n",
      "epoch 41; iter: 0; batch classifier loss: 0.226800; batch adversarial loss: 0.607345\n",
      "epoch 42; iter: 0; batch classifier loss: 0.166539; batch adversarial loss: 0.449136\n",
      "epoch 43; iter: 0; batch classifier loss: 0.076699; batch adversarial loss: 0.507476\n",
      "epoch 44; iter: 0; batch classifier loss: 0.121737; batch adversarial loss: 0.403524\n",
      "epoch 45; iter: 0; batch classifier loss: 0.109260; batch adversarial loss: 0.490826\n",
      "epoch 46; iter: 0; batch classifier loss: 0.105635; batch adversarial loss: 0.499854\n",
      "epoch 47; iter: 0; batch classifier loss: 0.166518; batch adversarial loss: 0.460647\n",
      "epoch 48; iter: 0; batch classifier loss: 0.132857; batch adversarial loss: 0.404039\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094885; batch adversarial loss: 0.448227\n",
      "epoch 50; iter: 0; batch classifier loss: 0.080805; batch adversarial loss: 0.441366\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092867; batch adversarial loss: 0.565547\n",
      "epoch 52; iter: 0; batch classifier loss: 0.104583; batch adversarial loss: 0.439956\n",
      "epoch 53; iter: 0; batch classifier loss: 0.112385; batch adversarial loss: 0.340900\n",
      "epoch 54; iter: 0; batch classifier loss: 0.071564; batch adversarial loss: 0.532163\n",
      "epoch 55; iter: 0; batch classifier loss: 0.136117; batch adversarial loss: 0.384737\n",
      "epoch 56; iter: 0; batch classifier loss: 0.114461; batch adversarial loss: 0.585759\n",
      "epoch 57; iter: 0; batch classifier loss: 0.120237; batch adversarial loss: 0.423425\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077667; batch adversarial loss: 0.471766\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097916; batch adversarial loss: 0.569357\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061301; batch adversarial loss: 0.417851\n",
      "epoch 61; iter: 0; batch classifier loss: 0.115673; batch adversarial loss: 0.449689\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075071; batch adversarial loss: 0.455872\n",
      "epoch 63; iter: 0; batch classifier loss: 0.071857; batch adversarial loss: 0.527702\n",
      "epoch 64; iter: 0; batch classifier loss: 0.120115; batch adversarial loss: 0.415059\n",
      "epoch 65; iter: 0; batch classifier loss: 0.053136; batch adversarial loss: 0.511880\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093145; batch adversarial loss: 0.444708\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107405; batch adversarial loss: 0.398282\n",
      "epoch 68; iter: 0; batch classifier loss: 0.067567; batch adversarial loss: 0.471863\n",
      "epoch 69; iter: 0; batch classifier loss: 0.067622; batch adversarial loss: 0.406132\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065465; batch adversarial loss: 0.428924\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084775; batch adversarial loss: 0.443894\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064750; batch adversarial loss: 0.437126\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085554; batch adversarial loss: 0.413014\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069162; batch adversarial loss: 0.440246\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061954; batch adversarial loss: 0.502796\n",
      "epoch 76; iter: 0; batch classifier loss: 0.090256; batch adversarial loss: 0.470312\n",
      "epoch 77; iter: 0; batch classifier loss: 0.097666; batch adversarial loss: 0.362880\n",
      "epoch 78; iter: 0; batch classifier loss: 0.102217; batch adversarial loss: 0.402596\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060306; batch adversarial loss: 0.465330\n",
      "epoch 80; iter: 0; batch classifier loss: 0.049280; batch adversarial loss: 0.443225\n",
      "epoch 81; iter: 0; batch classifier loss: 0.078479; batch adversarial loss: 0.493607\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056636; batch adversarial loss: 0.586027\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059134; batch adversarial loss: 0.401146\n",
      "epoch 84; iter: 0; batch classifier loss: 0.022620; batch adversarial loss: 0.439765\n",
      "epoch 85; iter: 0; batch classifier loss: 0.057195; batch adversarial loss: 0.442073\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063007; batch adversarial loss: 0.413051\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066332; batch adversarial loss: 0.446461\n",
      "epoch 88; iter: 0; batch classifier loss: 0.034069; batch adversarial loss: 0.442740\n",
      "epoch 89; iter: 0; batch classifier loss: 0.092527; batch adversarial loss: 0.495331\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042462; batch adversarial loss: 0.388077\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068822; batch adversarial loss: 0.501163\n",
      "epoch 92; iter: 0; batch classifier loss: 0.049548; batch adversarial loss: 0.423470\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039043; batch adversarial loss: 0.495070\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043188; batch adversarial loss: 0.431394\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063163; batch adversarial loss: 0.439109\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055266; batch adversarial loss: 0.469006\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053023; batch adversarial loss: 0.478158\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063719; batch adversarial loss: 0.429950\n",
      "epoch 99; iter: 0; batch classifier loss: 0.025859; batch adversarial loss: 0.407368\n",
      "epoch 100; iter: 0; batch classifier loss: 0.072807; batch adversarial loss: 0.420072\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056788; batch adversarial loss: 0.349877\n",
      "epoch 102; iter: 0; batch classifier loss: 0.017893; batch adversarial loss: 0.451026\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060907; batch adversarial loss: 0.478743\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066035; batch adversarial loss: 0.490723\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038824; batch adversarial loss: 0.478416\n",
      "epoch 106; iter: 0; batch classifier loss: 0.070987; batch adversarial loss: 0.497382\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045872; batch adversarial loss: 0.439218\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037074; batch adversarial loss: 0.414660\n",
      "epoch 109; iter: 0; batch classifier loss: 0.025422; batch adversarial loss: 0.474085\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031071; batch adversarial loss: 0.413526\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046393; batch adversarial loss: 0.414344\n",
      "epoch 112; iter: 0; batch classifier loss: 0.021406; batch adversarial loss: 0.444720\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042320; batch adversarial loss: 0.457011\n",
      "epoch 114; iter: 0; batch classifier loss: 0.021499; batch adversarial loss: 0.368769\n",
      "epoch 115; iter: 0; batch classifier loss: 0.015335; batch adversarial loss: 0.509007\n",
      "epoch 116; iter: 0; batch classifier loss: 0.015323; batch adversarial loss: 0.360082\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027267; batch adversarial loss: 0.515765\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051635; batch adversarial loss: 0.397482\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023038; batch adversarial loss: 0.420019\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020569; batch adversarial loss: 0.392798\n",
      "epoch 121; iter: 0; batch classifier loss: 0.056500; batch adversarial loss: 0.474022\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025792; batch adversarial loss: 0.417933\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036562; batch adversarial loss: 0.384921\n",
      "epoch 124; iter: 0; batch classifier loss: 0.017233; batch adversarial loss: 0.523384\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053077; batch adversarial loss: 0.372773\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019842; batch adversarial loss: 0.400907\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036663; batch adversarial loss: 0.451509\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026012; batch adversarial loss: 0.436298\n",
      "epoch 129; iter: 0; batch classifier loss: 0.069091; batch adversarial loss: 0.419125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.054345; batch adversarial loss: 0.383329\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035726; batch adversarial loss: 0.397563\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023001; batch adversarial loss: 0.428968\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037148; batch adversarial loss: 0.429769\n",
      "epoch 134; iter: 0; batch classifier loss: 0.010933; batch adversarial loss: 0.479401\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021235; batch adversarial loss: 0.498802\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023488; batch adversarial loss: 0.446463\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034151; batch adversarial loss: 0.392756\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013454; batch adversarial loss: 0.522950\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031727; batch adversarial loss: 0.453217\n",
      "epoch 140; iter: 0; batch classifier loss: 0.011285; batch adversarial loss: 0.507895\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035975; batch adversarial loss: 0.449770\n",
      "epoch 142; iter: 0; batch classifier loss: 0.064311; batch adversarial loss: 0.527349\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016783; batch adversarial loss: 0.402031\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023386; batch adversarial loss: 0.491337\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035537; batch adversarial loss: 0.459412\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026606; batch adversarial loss: 0.441817\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026730; batch adversarial loss: 0.446023\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023915; batch adversarial loss: 0.508832\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026679; batch adversarial loss: 0.429491\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024625; batch adversarial loss: 0.371756\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011616; batch adversarial loss: 0.478856\n",
      "epoch 152; iter: 0; batch classifier loss: 0.006295; batch adversarial loss: 0.348779\n",
      "epoch 153; iter: 0; batch classifier loss: 0.047154; batch adversarial loss: 0.486346\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019260; batch adversarial loss: 0.535508\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010300; batch adversarial loss: 0.405429\n",
      "epoch 156; iter: 0; batch classifier loss: 0.007749; batch adversarial loss: 0.407355\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030672; batch adversarial loss: 0.482438\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036766; batch adversarial loss: 0.443277\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029772; batch adversarial loss: 0.358952\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025548; batch adversarial loss: 0.456053\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012687; batch adversarial loss: 0.399462\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014374; batch adversarial loss: 0.467133\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026347; batch adversarial loss: 0.415110\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043297; batch adversarial loss: 0.377731\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019884; batch adversarial loss: 0.462596\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022510; batch adversarial loss: 0.461815\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034669; batch adversarial loss: 0.517434\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017217; batch adversarial loss: 0.439215\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028309; batch adversarial loss: 0.502557\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035344; batch adversarial loss: 0.517354\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008936; batch adversarial loss: 0.480620\n",
      "epoch 172; iter: 0; batch classifier loss: 0.039231; batch adversarial loss: 0.350644\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010583; batch adversarial loss: 0.462760\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007493; batch adversarial loss: 0.520659\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032399; batch adversarial loss: 0.389760\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029824; batch adversarial loss: 0.493931\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027387; batch adversarial loss: 0.356919\n",
      "epoch 178; iter: 0; batch classifier loss: 0.004317; batch adversarial loss: 0.524182\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025562; batch adversarial loss: 0.442293\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007303; batch adversarial loss: 0.432731\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006306; batch adversarial loss: 0.476794\n",
      "epoch 182; iter: 0; batch classifier loss: 0.003601; batch adversarial loss: 0.461169\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017681; batch adversarial loss: 0.544840\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032681; batch adversarial loss: 0.520060\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014897; batch adversarial loss: 0.640520\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023837; batch adversarial loss: 0.515037\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042457; batch adversarial loss: 0.461557\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015166; batch adversarial loss: 0.421435\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007729; batch adversarial loss: 0.455643\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008072; batch adversarial loss: 0.483563\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020137; batch adversarial loss: 0.484780\n",
      "epoch 192; iter: 0; batch classifier loss: 0.042020; batch adversarial loss: 0.460259\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016224; batch adversarial loss: 0.474910\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012700; batch adversarial loss: 0.414834\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021989; batch adversarial loss: 0.399101\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018881; batch adversarial loss: 0.502614\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015015; batch adversarial loss: 0.473640\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020222; batch adversarial loss: 0.500094\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012167; batch adversarial loss: 0.394717\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702388; batch adversarial loss: 0.672158\n",
      "epoch 1; iter: 0; batch classifier loss: 0.479078; batch adversarial loss: 0.643871\n",
      "epoch 2; iter: 0; batch classifier loss: 0.372360; batch adversarial loss: 0.620867\n",
      "epoch 3; iter: 0; batch classifier loss: 0.340849; batch adversarial loss: 0.584978\n",
      "epoch 4; iter: 0; batch classifier loss: 0.309520; batch adversarial loss: 0.569427\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343991; batch adversarial loss: 0.533174\n",
      "epoch 6; iter: 0; batch classifier loss: 0.284911; batch adversarial loss: 0.512131\n",
      "epoch 7; iter: 0; batch classifier loss: 0.268205; batch adversarial loss: 0.501139\n",
      "epoch 8; iter: 0; batch classifier loss: 0.213901; batch adversarial loss: 0.514837\n",
      "epoch 9; iter: 0; batch classifier loss: 0.228619; batch adversarial loss: 0.519055\n",
      "epoch 10; iter: 0; batch classifier loss: 0.219771; batch adversarial loss: 0.495101\n",
      "epoch 11; iter: 0; batch classifier loss: 0.218989; batch adversarial loss: 0.531566\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251837; batch adversarial loss: 0.479212\n",
      "epoch 13; iter: 0; batch classifier loss: 0.197401; batch adversarial loss: 0.520788\n",
      "epoch 14; iter: 0; batch classifier loss: 0.192853; batch adversarial loss: 0.512029\n",
      "epoch 15; iter: 0; batch classifier loss: 0.142923; batch adversarial loss: 0.505581\n",
      "epoch 16; iter: 0; batch classifier loss: 0.241858; batch adversarial loss: 0.517528\n",
      "epoch 17; iter: 0; batch classifier loss: 0.180840; batch adversarial loss: 0.520352\n",
      "epoch 18; iter: 0; batch classifier loss: 0.185617; batch adversarial loss: 0.551572\n",
      "epoch 19; iter: 0; batch classifier loss: 0.152920; batch adversarial loss: 0.490989\n",
      "epoch 20; iter: 0; batch classifier loss: 0.139321; batch adversarial loss: 0.475686\n",
      "epoch 21; iter: 0; batch classifier loss: 0.135197; batch adversarial loss: 0.528993\n",
      "epoch 22; iter: 0; batch classifier loss: 0.252653; batch adversarial loss: 0.510714\n",
      "epoch 23; iter: 0; batch classifier loss: 0.195878; batch adversarial loss: 0.478711\n",
      "epoch 24; iter: 0; batch classifier loss: 0.204512; batch adversarial loss: 0.467992\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237458; batch adversarial loss: 0.543717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.259511; batch adversarial loss: 0.564755\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241299; batch adversarial loss: 0.461833\n",
      "epoch 28; iter: 0; batch classifier loss: 0.345378; batch adversarial loss: 0.545187\n",
      "epoch 29; iter: 0; batch classifier loss: 0.303966; batch adversarial loss: 0.488582\n",
      "epoch 30; iter: 0; batch classifier loss: 0.292131; batch adversarial loss: 0.444440\n",
      "epoch 31; iter: 0; batch classifier loss: 0.199053; batch adversarial loss: 0.429067\n",
      "epoch 32; iter: 0; batch classifier loss: 0.115784; batch adversarial loss: 0.511992\n",
      "epoch 33; iter: 0; batch classifier loss: 0.118323; batch adversarial loss: 0.504515\n",
      "epoch 34; iter: 0; batch classifier loss: 0.115050; batch adversarial loss: 0.456938\n",
      "epoch 35; iter: 0; batch classifier loss: 0.093844; batch adversarial loss: 0.471286\n",
      "epoch 36; iter: 0; batch classifier loss: 0.063912; batch adversarial loss: 0.466821\n",
      "epoch 37; iter: 0; batch classifier loss: 0.158133; batch adversarial loss: 0.450923\n",
      "epoch 38; iter: 0; batch classifier loss: 0.105913; batch adversarial loss: 0.500545\n",
      "epoch 39; iter: 0; batch classifier loss: 0.152495; batch adversarial loss: 0.516722\n",
      "epoch 40; iter: 0; batch classifier loss: 0.128957; batch adversarial loss: 0.398415\n",
      "epoch 41; iter: 0; batch classifier loss: 0.139775; batch adversarial loss: 0.504781\n",
      "epoch 42; iter: 0; batch classifier loss: 0.072384; batch adversarial loss: 0.512212\n",
      "epoch 43; iter: 0; batch classifier loss: 0.067729; batch adversarial loss: 0.432756\n",
      "epoch 44; iter: 0; batch classifier loss: 0.122119; batch adversarial loss: 0.443210\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102875; batch adversarial loss: 0.408607\n",
      "epoch 46; iter: 0; batch classifier loss: 0.063386; batch adversarial loss: 0.461541\n",
      "epoch 47; iter: 0; batch classifier loss: 0.073355; batch adversarial loss: 0.426355\n",
      "epoch 48; iter: 0; batch classifier loss: 0.074629; batch adversarial loss: 0.483589\n",
      "epoch 49; iter: 0; batch classifier loss: 0.097344; batch adversarial loss: 0.488028\n",
      "epoch 50; iter: 0; batch classifier loss: 0.103280; batch adversarial loss: 0.475727\n",
      "epoch 51; iter: 0; batch classifier loss: 0.102908; batch adversarial loss: 0.389766\n",
      "epoch 52; iter: 0; batch classifier loss: 0.058302; batch adversarial loss: 0.449211\n",
      "epoch 53; iter: 0; batch classifier loss: 0.125304; batch adversarial loss: 0.453247\n",
      "epoch 54; iter: 0; batch classifier loss: 0.075544; batch adversarial loss: 0.570736\n",
      "epoch 55; iter: 0; batch classifier loss: 0.099913; batch adversarial loss: 0.356591\n",
      "epoch 56; iter: 0; batch classifier loss: 0.092684; batch adversarial loss: 0.545703\n",
      "epoch 57; iter: 0; batch classifier loss: 0.142264; batch adversarial loss: 0.433459\n",
      "epoch 58; iter: 0; batch classifier loss: 0.135756; batch adversarial loss: 0.374877\n",
      "epoch 59; iter: 0; batch classifier loss: 0.119861; batch adversarial loss: 0.407029\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105817; batch adversarial loss: 0.414890\n",
      "epoch 61; iter: 0; batch classifier loss: 0.117195; batch adversarial loss: 0.333425\n",
      "epoch 62; iter: 0; batch classifier loss: 0.056765; batch adversarial loss: 0.440547\n",
      "epoch 63; iter: 0; batch classifier loss: 0.075712; batch adversarial loss: 0.505473\n",
      "epoch 64; iter: 0; batch classifier loss: 0.116447; batch adversarial loss: 0.520379\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082748; batch adversarial loss: 0.532700\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092546; batch adversarial loss: 0.490565\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073196; batch adversarial loss: 0.409931\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078967; batch adversarial loss: 0.433475\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073470; batch adversarial loss: 0.467529\n",
      "epoch 70; iter: 0; batch classifier loss: 0.120498; batch adversarial loss: 0.322544\n",
      "epoch 71; iter: 0; batch classifier loss: 0.112524; batch adversarial loss: 0.459109\n",
      "epoch 72; iter: 0; batch classifier loss: 0.117112; batch adversarial loss: 0.530433\n",
      "epoch 73; iter: 0; batch classifier loss: 0.095836; batch adversarial loss: 0.525941\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073803; batch adversarial loss: 0.457098\n",
      "epoch 75; iter: 0; batch classifier loss: 0.064655; batch adversarial loss: 0.500687\n",
      "epoch 76; iter: 0; batch classifier loss: 0.115068; batch adversarial loss: 0.529651\n",
      "epoch 77; iter: 0; batch classifier loss: 0.128284; batch adversarial loss: 0.430570\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079296; batch adversarial loss: 0.443418\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067089; batch adversarial loss: 0.409560\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074260; batch adversarial loss: 0.579707\n",
      "epoch 81; iter: 0; batch classifier loss: 0.102219; batch adversarial loss: 0.515833\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083629; batch adversarial loss: 0.404081\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079617; batch adversarial loss: 0.524940\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064490; batch adversarial loss: 0.433777\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051842; batch adversarial loss: 0.484912\n",
      "epoch 86; iter: 0; batch classifier loss: 0.108034; batch adversarial loss: 0.421819\n",
      "epoch 87; iter: 0; batch classifier loss: 0.089494; batch adversarial loss: 0.482533\n",
      "epoch 88; iter: 0; batch classifier loss: 0.091582; batch adversarial loss: 0.546132\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053869; batch adversarial loss: 0.462221\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062850; batch adversarial loss: 0.433525\n",
      "epoch 91; iter: 0; batch classifier loss: 0.095735; batch adversarial loss: 0.476185\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060870; batch adversarial loss: 0.431956\n",
      "epoch 93; iter: 0; batch classifier loss: 0.094554; batch adversarial loss: 0.410535\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066428; batch adversarial loss: 0.473942\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063115; batch adversarial loss: 0.391001\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075114; batch adversarial loss: 0.512411\n",
      "epoch 97; iter: 0; batch classifier loss: 0.068270; batch adversarial loss: 0.518364\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046352; batch adversarial loss: 0.548524\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049111; batch adversarial loss: 0.542894\n",
      "epoch 100; iter: 0; batch classifier loss: 0.104323; batch adversarial loss: 0.409131\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037955; batch adversarial loss: 0.450558\n",
      "epoch 102; iter: 0; batch classifier loss: 0.040004; batch adversarial loss: 0.426709\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046822; batch adversarial loss: 0.464566\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057459; batch adversarial loss: 0.454475\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075516; batch adversarial loss: 0.550255\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067948; batch adversarial loss: 0.491804\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039963; batch adversarial loss: 0.438532\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036680; batch adversarial loss: 0.506522\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046710; batch adversarial loss: 0.556527\n",
      "epoch 110; iter: 0; batch classifier loss: 0.020289; batch adversarial loss: 0.450693\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051108; batch adversarial loss: 0.493071\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059888; batch adversarial loss: 0.439110\n",
      "epoch 113; iter: 0; batch classifier loss: 0.061703; batch adversarial loss: 0.476038\n",
      "epoch 114; iter: 0; batch classifier loss: 0.065904; batch adversarial loss: 0.485038\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062324; batch adversarial loss: 0.515485\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062402; batch adversarial loss: 0.513702\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044600; batch adversarial loss: 0.409251\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033351; batch adversarial loss: 0.433223\n",
      "epoch 119; iter: 0; batch classifier loss: 0.069784; batch adversarial loss: 0.427139\n",
      "epoch 120; iter: 0; batch classifier loss: 0.019820; batch adversarial loss: 0.509089\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052452; batch adversarial loss: 0.513212\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059879; batch adversarial loss: 0.463488\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050286; batch adversarial loss: 0.344775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.051160; batch adversarial loss: 0.424811\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033863; batch adversarial loss: 0.485980\n",
      "epoch 126; iter: 0; batch classifier loss: 0.079581; batch adversarial loss: 0.472191\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025734; batch adversarial loss: 0.444827\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026423; batch adversarial loss: 0.526223\n",
      "epoch 129; iter: 0; batch classifier loss: 0.015545; batch adversarial loss: 0.549559\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061856; batch adversarial loss: 0.471616\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029135; batch adversarial loss: 0.589283\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044063; batch adversarial loss: 0.433881\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018162; batch adversarial loss: 0.433789\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031965; batch adversarial loss: 0.366143\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023681; batch adversarial loss: 0.505589\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023479; batch adversarial loss: 0.465189\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029385; batch adversarial loss: 0.375880\n",
      "epoch 138; iter: 0; batch classifier loss: 0.062177; batch adversarial loss: 0.389645\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050311; batch adversarial loss: 0.493226\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021519; batch adversarial loss: 0.460195\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025997; batch adversarial loss: 0.601139\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044410; batch adversarial loss: 0.488034\n",
      "epoch 143; iter: 0; batch classifier loss: 0.047979; batch adversarial loss: 0.400280\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027109; batch adversarial loss: 0.501662\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018854; batch adversarial loss: 0.435157\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032300; batch adversarial loss: 0.548738\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026860; batch adversarial loss: 0.520634\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045215; batch adversarial loss: 0.499916\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034057; batch adversarial loss: 0.477259\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011354; batch adversarial loss: 0.386425\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032058; batch adversarial loss: 0.495303\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045516; batch adversarial loss: 0.460827\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031576; batch adversarial loss: 0.409485\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031463; batch adversarial loss: 0.448744\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026911; batch adversarial loss: 0.439097\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026687; batch adversarial loss: 0.531659\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017601; batch adversarial loss: 0.457721\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032995; batch adversarial loss: 0.532857\n",
      "epoch 159; iter: 0; batch classifier loss: 0.071839; batch adversarial loss: 0.441581\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029644; batch adversarial loss: 0.452469\n",
      "epoch 161; iter: 0; batch classifier loss: 0.068656; batch adversarial loss: 0.451504\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037966; batch adversarial loss: 0.459112\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013830; batch adversarial loss: 0.462895\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019000; batch adversarial loss: 0.393361\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037067; batch adversarial loss: 0.527203\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040127; batch adversarial loss: 0.495599\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021017; batch adversarial loss: 0.407750\n",
      "epoch 168; iter: 0; batch classifier loss: 0.042195; batch adversarial loss: 0.346525\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037812; batch adversarial loss: 0.453971\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033773; batch adversarial loss: 0.450641\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013222; batch adversarial loss: 0.496247\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011710; batch adversarial loss: 0.412728\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029568; batch adversarial loss: 0.434317\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014152; batch adversarial loss: 0.507741\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035349; batch adversarial loss: 0.363646\n",
      "epoch 176; iter: 0; batch classifier loss: 0.036148; batch adversarial loss: 0.412544\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022126; batch adversarial loss: 0.512654\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006890; batch adversarial loss: 0.450023\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040577; batch adversarial loss: 0.551073\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018181; batch adversarial loss: 0.510996\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010566; batch adversarial loss: 0.510691\n",
      "epoch 182; iter: 0; batch classifier loss: 0.057386; batch adversarial loss: 0.504111\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021045; batch adversarial loss: 0.478384\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026314; batch adversarial loss: 0.556235\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031128; batch adversarial loss: 0.445005\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025380; batch adversarial loss: 0.389339\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030658; batch adversarial loss: 0.426800\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018799; batch adversarial loss: 0.439926\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010856; batch adversarial loss: 0.496106\n",
      "epoch 190; iter: 0; batch classifier loss: 0.060621; batch adversarial loss: 0.420128\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019917; batch adversarial loss: 0.446905\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016341; batch adversarial loss: 0.476191\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015653; batch adversarial loss: 0.564589\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018755; batch adversarial loss: 0.496628\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024919; batch adversarial loss: 0.501326\n",
      "epoch 196; iter: 0; batch classifier loss: 0.039260; batch adversarial loss: 0.447522\n",
      "epoch 197; iter: 0; batch classifier loss: 0.041628; batch adversarial loss: 0.461432\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003071; batch adversarial loss: 0.524566\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008146; batch adversarial loss: 0.505681\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702220; batch adversarial loss: 0.725366\n",
      "epoch 1; iter: 0; batch classifier loss: 0.505695; batch adversarial loss: 0.644861\n",
      "epoch 2; iter: 0; batch classifier loss: 0.434404; batch adversarial loss: 0.632208\n",
      "epoch 3; iter: 0; batch classifier loss: 0.406608; batch adversarial loss: 0.602461\n",
      "epoch 4; iter: 0; batch classifier loss: 0.321181; batch adversarial loss: 0.578526\n",
      "epoch 5; iter: 0; batch classifier loss: 0.258147; batch adversarial loss: 0.549967\n",
      "epoch 6; iter: 0; batch classifier loss: 0.376840; batch adversarial loss: 0.547813\n",
      "epoch 7; iter: 0; batch classifier loss: 0.238740; batch adversarial loss: 0.514684\n",
      "epoch 8; iter: 0; batch classifier loss: 0.274020; batch adversarial loss: 0.533925\n",
      "epoch 9; iter: 0; batch classifier loss: 0.339174; batch adversarial loss: 0.489197\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269580; batch adversarial loss: 0.519898\n",
      "epoch 11; iter: 0; batch classifier loss: 0.216968; batch adversarial loss: 0.573712\n",
      "epoch 12; iter: 0; batch classifier loss: 0.216672; batch adversarial loss: 0.527771\n",
      "epoch 13; iter: 0; batch classifier loss: 0.258788; batch adversarial loss: 0.409967\n",
      "epoch 14; iter: 0; batch classifier loss: 0.291133; batch adversarial loss: 0.548002\n",
      "epoch 15; iter: 0; batch classifier loss: 0.250362; batch adversarial loss: 0.444892\n",
      "epoch 16; iter: 0; batch classifier loss: 0.193895; batch adversarial loss: 0.559173\n",
      "epoch 17; iter: 0; batch classifier loss: 0.248474; batch adversarial loss: 0.534998\n",
      "epoch 18; iter: 0; batch classifier loss: 0.231445; batch adversarial loss: 0.452109\n",
      "epoch 19; iter: 0; batch classifier loss: 0.186750; batch adversarial loss: 0.471502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.212660; batch adversarial loss: 0.429489\n",
      "epoch 21; iter: 0; batch classifier loss: 0.274426; batch adversarial loss: 0.502846\n",
      "epoch 22; iter: 0; batch classifier loss: 0.165185; batch adversarial loss: 0.442528\n",
      "epoch 23; iter: 0; batch classifier loss: 0.197606; batch adversarial loss: 0.483004\n",
      "epoch 24; iter: 0; batch classifier loss: 0.211213; batch adversarial loss: 0.452590\n",
      "epoch 25; iter: 0; batch classifier loss: 0.138217; batch adversarial loss: 0.443272\n",
      "epoch 26; iter: 0; batch classifier loss: 0.251473; batch adversarial loss: 0.476162\n",
      "epoch 27; iter: 0; batch classifier loss: 0.128313; batch adversarial loss: 0.440571\n",
      "epoch 28; iter: 0; batch classifier loss: 0.181032; batch adversarial loss: 0.439580\n",
      "epoch 29; iter: 0; batch classifier loss: 0.130938; batch adversarial loss: 0.414055\n",
      "epoch 30; iter: 0; batch classifier loss: 0.158769; batch adversarial loss: 0.385041\n",
      "epoch 31; iter: 0; batch classifier loss: 0.124443; batch adversarial loss: 0.483088\n",
      "epoch 32; iter: 0; batch classifier loss: 0.157426; batch adversarial loss: 0.483638\n",
      "epoch 33; iter: 0; batch classifier loss: 0.150209; batch adversarial loss: 0.469675\n",
      "epoch 34; iter: 0; batch classifier loss: 0.159319; batch adversarial loss: 0.461231\n",
      "epoch 35; iter: 0; batch classifier loss: 0.191719; batch adversarial loss: 0.545135\n",
      "epoch 36; iter: 0; batch classifier loss: 0.184305; batch adversarial loss: 0.497826\n",
      "epoch 37; iter: 0; batch classifier loss: 0.147837; batch adversarial loss: 0.457314\n",
      "epoch 38; iter: 0; batch classifier loss: 0.113717; batch adversarial loss: 0.482976\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148308; batch adversarial loss: 0.476289\n",
      "epoch 40; iter: 0; batch classifier loss: 0.189432; batch adversarial loss: 0.478483\n",
      "epoch 41; iter: 0; batch classifier loss: 0.159343; batch adversarial loss: 0.420250\n",
      "epoch 42; iter: 0; batch classifier loss: 0.212298; batch adversarial loss: 0.413930\n",
      "epoch 43; iter: 0; batch classifier loss: 0.164738; batch adversarial loss: 0.381234\n",
      "epoch 44; iter: 0; batch classifier loss: 0.158875; batch adversarial loss: 0.476053\n",
      "epoch 45; iter: 0; batch classifier loss: 0.198772; batch adversarial loss: 0.428964\n",
      "epoch 46; iter: 0; batch classifier loss: 0.206529; batch adversarial loss: 0.416935\n",
      "epoch 47; iter: 0; batch classifier loss: 0.178639; batch adversarial loss: 0.409030\n",
      "epoch 48; iter: 0; batch classifier loss: 0.274774; batch adversarial loss: 0.435871\n",
      "epoch 49; iter: 0; batch classifier loss: 0.144037; batch adversarial loss: 0.498523\n",
      "epoch 50; iter: 0; batch classifier loss: 0.171959; batch adversarial loss: 0.385471\n",
      "epoch 51; iter: 0; batch classifier loss: 0.125857; batch adversarial loss: 0.433261\n",
      "epoch 52; iter: 0; batch classifier loss: 0.201639; batch adversarial loss: 0.440825\n",
      "epoch 53; iter: 0; batch classifier loss: 0.164471; batch adversarial loss: 0.367293\n",
      "epoch 54; iter: 0; batch classifier loss: 0.152720; batch adversarial loss: 0.422585\n",
      "epoch 55; iter: 0; batch classifier loss: 0.197441; batch adversarial loss: 0.452810\n",
      "epoch 56; iter: 0; batch classifier loss: 0.153256; batch adversarial loss: 0.477870\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107858; batch adversarial loss: 0.415912\n",
      "epoch 58; iter: 0; batch classifier loss: 0.167754; batch adversarial loss: 0.428342\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105372; batch adversarial loss: 0.458996\n",
      "epoch 60; iter: 0; batch classifier loss: 0.126104; batch adversarial loss: 0.472612\n",
      "epoch 61; iter: 0; batch classifier loss: 0.143177; batch adversarial loss: 0.483013\n",
      "epoch 62; iter: 0; batch classifier loss: 0.180266; batch adversarial loss: 0.350373\n",
      "epoch 63; iter: 0; batch classifier loss: 0.129249; batch adversarial loss: 0.481959\n",
      "epoch 64; iter: 0; batch classifier loss: 0.110889; batch adversarial loss: 0.513246\n",
      "epoch 65; iter: 0; batch classifier loss: 0.193449; batch adversarial loss: 0.462274\n",
      "epoch 66; iter: 0; batch classifier loss: 0.168163; batch adversarial loss: 0.422534\n",
      "epoch 67; iter: 0; batch classifier loss: 0.127641; batch adversarial loss: 0.526193\n",
      "epoch 68; iter: 0; batch classifier loss: 0.150044; batch adversarial loss: 0.575531\n",
      "epoch 69; iter: 0; batch classifier loss: 0.109215; batch adversarial loss: 0.426304\n",
      "epoch 70; iter: 0; batch classifier loss: 0.124179; batch adversarial loss: 0.459307\n",
      "epoch 71; iter: 0; batch classifier loss: 0.196010; batch adversarial loss: 0.472233\n",
      "epoch 72; iter: 0; batch classifier loss: 0.134548; batch adversarial loss: 0.424417\n",
      "epoch 73; iter: 0; batch classifier loss: 0.146142; batch adversarial loss: 0.535543\n",
      "epoch 74; iter: 0; batch classifier loss: 0.100044; batch adversarial loss: 0.475630\n",
      "epoch 75; iter: 0; batch classifier loss: 0.153582; batch adversarial loss: 0.567813\n",
      "epoch 76; iter: 0; batch classifier loss: 0.126211; batch adversarial loss: 0.543696\n",
      "epoch 77; iter: 0; batch classifier loss: 0.124780; batch adversarial loss: 0.434659\n",
      "epoch 78; iter: 0; batch classifier loss: 0.116179; batch adversarial loss: 0.427408\n",
      "epoch 79; iter: 0; batch classifier loss: 0.105490; batch adversarial loss: 0.571160\n",
      "epoch 80; iter: 0; batch classifier loss: 0.117216; batch adversarial loss: 0.427945\n",
      "epoch 81; iter: 0; batch classifier loss: 0.154657; batch adversarial loss: 0.380711\n",
      "epoch 82; iter: 0; batch classifier loss: 0.187592; batch adversarial loss: 0.477557\n",
      "epoch 83; iter: 0; batch classifier loss: 0.107085; batch adversarial loss: 0.372958\n",
      "epoch 84; iter: 0; batch classifier loss: 0.166086; batch adversarial loss: 0.554719\n",
      "epoch 85; iter: 0; batch classifier loss: 0.120453; batch adversarial loss: 0.380816\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062947; batch adversarial loss: 0.433628\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055528; batch adversarial loss: 0.445216\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069339; batch adversarial loss: 0.459018\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075809; batch adversarial loss: 0.503433\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060441; batch adversarial loss: 0.446179\n",
      "epoch 91; iter: 0; batch classifier loss: 0.098988; batch adversarial loss: 0.535499\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060121; batch adversarial loss: 0.510059\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062525; batch adversarial loss: 0.566277\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042188; batch adversarial loss: 0.430166\n",
      "epoch 95; iter: 0; batch classifier loss: 0.088125; batch adversarial loss: 0.355235\n",
      "epoch 96; iter: 0; batch classifier loss: 0.067151; batch adversarial loss: 0.475122\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063796; batch adversarial loss: 0.510964\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074710; batch adversarial loss: 0.408065\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052855; batch adversarial loss: 0.391768\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043814; batch adversarial loss: 0.549616\n",
      "epoch 101; iter: 0; batch classifier loss: 0.085349; batch adversarial loss: 0.478269\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051475; batch adversarial loss: 0.438348\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048311; batch adversarial loss: 0.440972\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053991; batch adversarial loss: 0.463301\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043254; batch adversarial loss: 0.438877\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063370; batch adversarial loss: 0.363965\n",
      "epoch 107; iter: 0; batch classifier loss: 0.091262; batch adversarial loss: 0.481968\n",
      "epoch 108; iter: 0; batch classifier loss: 0.061509; batch adversarial loss: 0.469512\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061163; batch adversarial loss: 0.385034\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050799; batch adversarial loss: 0.483526\n",
      "epoch 111; iter: 0; batch classifier loss: 0.014662; batch adversarial loss: 0.501574\n",
      "epoch 112; iter: 0; batch classifier loss: 0.017580; batch adversarial loss: 0.451375\n",
      "epoch 113; iter: 0; batch classifier loss: 0.024458; batch adversarial loss: 0.550395\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042429; batch adversarial loss: 0.367171\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028105; batch adversarial loss: 0.452771\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041172; batch adversarial loss: 0.521202\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035195; batch adversarial loss: 0.477532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.030811; batch adversarial loss: 0.452498\n",
      "epoch 119; iter: 0; batch classifier loss: 0.024899; batch adversarial loss: 0.454804\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038648; batch adversarial loss: 0.458718\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035279; batch adversarial loss: 0.382398\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015282; batch adversarial loss: 0.483302\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053160; batch adversarial loss: 0.397315\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021041; batch adversarial loss: 0.450330\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026675; batch adversarial loss: 0.377365\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032898; batch adversarial loss: 0.516831\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025848; batch adversarial loss: 0.529484\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037961; batch adversarial loss: 0.388842\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021023; batch adversarial loss: 0.489725\n",
      "epoch 130; iter: 0; batch classifier loss: 0.063419; batch adversarial loss: 0.393183\n",
      "epoch 131; iter: 0; batch classifier loss: 0.059951; batch adversarial loss: 0.424186\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053627; batch adversarial loss: 0.483385\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034151; batch adversarial loss: 0.450965\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021449; batch adversarial loss: 0.430991\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038729; batch adversarial loss: 0.436100\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041112; batch adversarial loss: 0.377456\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034720; batch adversarial loss: 0.539816\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053719; batch adversarial loss: 0.446172\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015045; batch adversarial loss: 0.463932\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038244; batch adversarial loss: 0.553309\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041238; batch adversarial loss: 0.431849\n",
      "epoch 142; iter: 0; batch classifier loss: 0.088173; batch adversarial loss: 0.453823\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022848; batch adversarial loss: 0.408671\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052087; batch adversarial loss: 0.504355\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037151; batch adversarial loss: 0.393071\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037267; batch adversarial loss: 0.388902\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035542; batch adversarial loss: 0.407709\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031339; batch adversarial loss: 0.404890\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024575; batch adversarial loss: 0.424791\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024270; batch adversarial loss: 0.495545\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036299; batch adversarial loss: 0.418049\n",
      "epoch 152; iter: 0; batch classifier loss: 0.050671; batch adversarial loss: 0.456563\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038541; batch adversarial loss: 0.361416\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027912; batch adversarial loss: 0.536346\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035287; batch adversarial loss: 0.495554\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021395; batch adversarial loss: 0.523974\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037613; batch adversarial loss: 0.548397\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023604; batch adversarial loss: 0.565281\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028904; batch adversarial loss: 0.482359\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008255; batch adversarial loss: 0.397406\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018351; batch adversarial loss: 0.375303\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022354; batch adversarial loss: 0.368637\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009132; batch adversarial loss: 0.442845\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011329; batch adversarial loss: 0.425460\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022325; batch adversarial loss: 0.435280\n",
      "epoch 166; iter: 0; batch classifier loss: 0.068140; batch adversarial loss: 0.390107\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017175; batch adversarial loss: 0.404299\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020976; batch adversarial loss: 0.427948\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018024; batch adversarial loss: 0.450506\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020206; batch adversarial loss: 0.424037\n",
      "epoch 171; iter: 0; batch classifier loss: 0.042340; batch adversarial loss: 0.394094\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031240; batch adversarial loss: 0.491651\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013381; batch adversarial loss: 0.537658\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030318; batch adversarial loss: 0.470750\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010898; batch adversarial loss: 0.451638\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022611; batch adversarial loss: 0.403816\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007972; batch adversarial loss: 0.538353\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019871; batch adversarial loss: 0.427817\n",
      "epoch 179; iter: 0; batch classifier loss: 0.057632; batch adversarial loss: 0.351414\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017379; batch adversarial loss: 0.380956\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029160; batch adversarial loss: 0.415683\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009643; batch adversarial loss: 0.477678\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014003; batch adversarial loss: 0.397239\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018649; batch adversarial loss: 0.370594\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012779; batch adversarial loss: 0.542863\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015986; batch adversarial loss: 0.508939\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015285; batch adversarial loss: 0.481465\n",
      "epoch 188; iter: 0; batch classifier loss: 0.050089; batch adversarial loss: 0.367251\n",
      "epoch 189; iter: 0; batch classifier loss: 0.062478; batch adversarial loss: 0.425824\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022707; batch adversarial loss: 0.457682\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010758; batch adversarial loss: 0.465951\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010788; batch adversarial loss: 0.345775\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021960; batch adversarial loss: 0.516514\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015516; batch adversarial loss: 0.447422\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034041; batch adversarial loss: 0.417836\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018934; batch adversarial loss: 0.347970\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013359; batch adversarial loss: 0.483236\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039726; batch adversarial loss: 0.474888\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018475; batch adversarial loss: 0.466218\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693525; batch adversarial loss: 0.572456\n",
      "epoch 1; iter: 0; batch classifier loss: 0.491882; batch adversarial loss: 0.587471\n",
      "epoch 2; iter: 0; batch classifier loss: 0.409536; batch adversarial loss: 0.588337\n",
      "epoch 3; iter: 0; batch classifier loss: 0.513946; batch adversarial loss: 0.597672\n",
      "epoch 4; iter: 0; batch classifier loss: 0.483609; batch adversarial loss: 0.629118\n",
      "epoch 5; iter: 0; batch classifier loss: 0.547484; batch adversarial loss: 0.628798\n",
      "epoch 6; iter: 0; batch classifier loss: 0.487360; batch adversarial loss: 0.570817\n",
      "epoch 7; iter: 0; batch classifier loss: 0.453663; batch adversarial loss: 0.588899\n",
      "epoch 8; iter: 0; batch classifier loss: 0.432001; batch adversarial loss: 0.576032\n",
      "epoch 9; iter: 0; batch classifier loss: 0.395356; batch adversarial loss: 0.547307\n",
      "epoch 10; iter: 0; batch classifier loss: 0.426078; batch adversarial loss: 0.536895\n",
      "epoch 11; iter: 0; batch classifier loss: 0.383913; batch adversarial loss: 0.492156\n",
      "epoch 12; iter: 0; batch classifier loss: 0.354431; batch adversarial loss: 0.461893\n",
      "epoch 13; iter: 0; batch classifier loss: 0.333010; batch adversarial loss: 0.515878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.311775; batch adversarial loss: 0.484189\n",
      "epoch 15; iter: 0; batch classifier loss: 0.249756; batch adversarial loss: 0.529915\n",
      "epoch 16; iter: 0; batch classifier loss: 0.347272; batch adversarial loss: 0.424531\n",
      "epoch 17; iter: 0; batch classifier loss: 0.281708; batch adversarial loss: 0.491880\n",
      "epoch 18; iter: 0; batch classifier loss: 0.294886; batch adversarial loss: 0.442763\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261999; batch adversarial loss: 0.381935\n",
      "epoch 20; iter: 0; batch classifier loss: 0.239872; batch adversarial loss: 0.469532\n",
      "epoch 21; iter: 0; batch classifier loss: 0.285334; batch adversarial loss: 0.464626\n",
      "epoch 22; iter: 0; batch classifier loss: 0.245846; batch adversarial loss: 0.516930\n",
      "epoch 23; iter: 0; batch classifier loss: 0.201527; batch adversarial loss: 0.557430\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194506; batch adversarial loss: 0.575089\n",
      "epoch 25; iter: 0; batch classifier loss: 0.293590; batch adversarial loss: 0.424509\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208343; batch adversarial loss: 0.500534\n",
      "epoch 27; iter: 0; batch classifier loss: 0.201362; batch adversarial loss: 0.490496\n",
      "epoch 28; iter: 0; batch classifier loss: 0.207066; batch adversarial loss: 0.585942\n",
      "epoch 29; iter: 0; batch classifier loss: 0.198520; batch adversarial loss: 0.525894\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167026; batch adversarial loss: 0.483176\n",
      "epoch 31; iter: 0; batch classifier loss: 0.229982; batch adversarial loss: 0.383007\n",
      "epoch 32; iter: 0; batch classifier loss: 0.151213; batch adversarial loss: 0.506761\n",
      "epoch 33; iter: 0; batch classifier loss: 0.177072; batch adversarial loss: 0.472984\n",
      "epoch 34; iter: 0; batch classifier loss: 0.250062; batch adversarial loss: 0.428692\n",
      "epoch 35; iter: 0; batch classifier loss: 0.134688; batch adversarial loss: 0.546622\n",
      "epoch 36; iter: 0; batch classifier loss: 0.243326; batch adversarial loss: 0.413183\n",
      "epoch 37; iter: 0; batch classifier loss: 0.194335; batch adversarial loss: 0.340768\n",
      "epoch 38; iter: 0; batch classifier loss: 0.189884; batch adversarial loss: 0.457579\n",
      "epoch 39; iter: 0; batch classifier loss: 0.195583; batch adversarial loss: 0.467464\n",
      "epoch 40; iter: 0; batch classifier loss: 0.200575; batch adversarial loss: 0.456656\n",
      "epoch 41; iter: 0; batch classifier loss: 0.159632; batch adversarial loss: 0.374744\n",
      "epoch 42; iter: 0; batch classifier loss: 0.179157; batch adversarial loss: 0.398562\n",
      "epoch 43; iter: 0; batch classifier loss: 0.185795; batch adversarial loss: 0.437895\n",
      "epoch 44; iter: 0; batch classifier loss: 0.177862; batch adversarial loss: 0.427912\n",
      "epoch 45; iter: 0; batch classifier loss: 0.146142; batch adversarial loss: 0.468467\n",
      "epoch 46; iter: 0; batch classifier loss: 0.209282; batch adversarial loss: 0.447767\n",
      "epoch 47; iter: 0; batch classifier loss: 0.205197; batch adversarial loss: 0.386012\n",
      "epoch 48; iter: 0; batch classifier loss: 0.194253; batch adversarial loss: 0.376022\n",
      "epoch 49; iter: 0; batch classifier loss: 0.183248; batch adversarial loss: 0.434115\n",
      "epoch 50; iter: 0; batch classifier loss: 0.152019; batch adversarial loss: 0.531209\n",
      "epoch 51; iter: 0; batch classifier loss: 0.243257; batch adversarial loss: 0.436727\n",
      "epoch 52; iter: 0; batch classifier loss: 0.126300; batch adversarial loss: 0.459356\n",
      "epoch 53; iter: 0; batch classifier loss: 0.110501; batch adversarial loss: 0.433785\n",
      "epoch 54; iter: 0; batch classifier loss: 0.152184; batch adversarial loss: 0.543978\n",
      "epoch 55; iter: 0; batch classifier loss: 0.222096; batch adversarial loss: 0.361322\n",
      "epoch 56; iter: 0; batch classifier loss: 0.116957; batch adversarial loss: 0.446119\n",
      "epoch 57; iter: 0; batch classifier loss: 0.085661; batch adversarial loss: 0.411053\n",
      "epoch 58; iter: 0; batch classifier loss: 0.151910; batch adversarial loss: 0.420348\n",
      "epoch 59; iter: 0; batch classifier loss: 0.263495; batch adversarial loss: 0.434146\n",
      "epoch 60; iter: 0; batch classifier loss: 0.163077; batch adversarial loss: 0.397766\n",
      "epoch 61; iter: 0; batch classifier loss: 0.132743; batch adversarial loss: 0.519557\n",
      "epoch 62; iter: 0; batch classifier loss: 0.173545; batch adversarial loss: 0.471998\n",
      "epoch 63; iter: 0; batch classifier loss: 0.111315; batch adversarial loss: 0.421615\n",
      "epoch 64; iter: 0; batch classifier loss: 0.145579; batch adversarial loss: 0.458812\n",
      "epoch 65; iter: 0; batch classifier loss: 0.180377; batch adversarial loss: 0.409649\n",
      "epoch 66; iter: 0; batch classifier loss: 0.112947; batch adversarial loss: 0.433989\n",
      "epoch 67; iter: 0; batch classifier loss: 0.103495; batch adversarial loss: 0.470924\n",
      "epoch 68; iter: 0; batch classifier loss: 0.210211; batch adversarial loss: 0.358454\n",
      "epoch 69; iter: 0; batch classifier loss: 0.192027; batch adversarial loss: 0.533066\n",
      "epoch 70; iter: 0; batch classifier loss: 0.112785; batch adversarial loss: 0.445628\n",
      "epoch 71; iter: 0; batch classifier loss: 0.148347; batch adversarial loss: 0.533469\n",
      "epoch 72; iter: 0; batch classifier loss: 0.139991; batch adversarial loss: 0.484583\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085081; batch adversarial loss: 0.372368\n",
      "epoch 74; iter: 0; batch classifier loss: 0.113007; batch adversarial loss: 0.395137\n",
      "epoch 75; iter: 0; batch classifier loss: 0.144343; batch adversarial loss: 0.323141\n",
      "epoch 76; iter: 0; batch classifier loss: 0.200760; batch adversarial loss: 0.445422\n",
      "epoch 77; iter: 0; batch classifier loss: 0.130886; batch adversarial loss: 0.470572\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075730; batch adversarial loss: 0.435102\n",
      "epoch 79; iter: 0; batch classifier loss: 0.137626; batch adversarial loss: 0.444170\n",
      "epoch 80; iter: 0; batch classifier loss: 0.098594; batch adversarial loss: 0.436038\n",
      "epoch 81; iter: 0; batch classifier loss: 0.121502; batch adversarial loss: 0.446924\n",
      "epoch 82; iter: 0; batch classifier loss: 0.188451; batch adversarial loss: 0.521739\n",
      "epoch 83; iter: 0; batch classifier loss: 0.191770; batch adversarial loss: 0.447260\n",
      "epoch 84; iter: 0; batch classifier loss: 0.165880; batch adversarial loss: 0.372534\n",
      "epoch 85; iter: 0; batch classifier loss: 0.136489; batch adversarial loss: 0.457809\n",
      "epoch 86; iter: 0; batch classifier loss: 0.189168; batch adversarial loss: 0.508029\n",
      "epoch 87; iter: 0; batch classifier loss: 0.141764; batch adversarial loss: 0.435160\n",
      "epoch 88; iter: 0; batch classifier loss: 0.132401; batch adversarial loss: 0.458863\n",
      "epoch 89; iter: 0; batch classifier loss: 0.076910; batch adversarial loss: 0.446323\n",
      "epoch 90; iter: 0; batch classifier loss: 0.142470; batch adversarial loss: 0.482749\n",
      "epoch 91; iter: 0; batch classifier loss: 0.148178; batch adversarial loss: 0.458460\n",
      "epoch 92; iter: 0; batch classifier loss: 0.136247; batch adversarial loss: 0.557685\n",
      "epoch 93; iter: 0; batch classifier loss: 0.156039; batch adversarial loss: 0.410044\n",
      "epoch 94; iter: 0; batch classifier loss: 0.129296; batch adversarial loss: 0.495052\n",
      "epoch 95; iter: 0; batch classifier loss: 0.095860; batch adversarial loss: 0.421490\n",
      "epoch 96; iter: 0; batch classifier loss: 0.136568; batch adversarial loss: 0.446522\n",
      "epoch 97; iter: 0; batch classifier loss: 0.104791; batch adversarial loss: 0.383699\n",
      "epoch 98; iter: 0; batch classifier loss: 0.116025; batch adversarial loss: 0.507067\n",
      "epoch 99; iter: 0; batch classifier loss: 0.102689; batch adversarial loss: 0.458420\n",
      "epoch 100; iter: 0; batch classifier loss: 0.071601; batch adversarial loss: 0.519759\n",
      "epoch 101; iter: 0; batch classifier loss: 0.113736; batch adversarial loss: 0.359720\n",
      "epoch 102; iter: 0; batch classifier loss: 0.102766; batch adversarial loss: 0.445852\n",
      "epoch 103; iter: 0; batch classifier loss: 0.132221; batch adversarial loss: 0.482196\n",
      "epoch 104; iter: 0; batch classifier loss: 0.075259; batch adversarial loss: 0.419496\n",
      "epoch 105; iter: 0; batch classifier loss: 0.124260; batch adversarial loss: 0.459292\n",
      "epoch 106; iter: 0; batch classifier loss: 0.157759; batch adversarial loss: 0.419646\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034076; batch adversarial loss: 0.534059\n",
      "epoch 108; iter: 0; batch classifier loss: 0.085127; batch adversarial loss: 0.531302\n",
      "epoch 109; iter: 0; batch classifier loss: 0.091088; batch adversarial loss: 0.448971\n",
      "epoch 110; iter: 0; batch classifier loss: 0.089767; batch adversarial loss: 0.519522\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037154; batch adversarial loss: 0.443044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.045650; batch adversarial loss: 0.407349\n",
      "epoch 113; iter: 0; batch classifier loss: 0.094086; batch adversarial loss: 0.380617\n",
      "epoch 114; iter: 0; batch classifier loss: 0.081806; batch adversarial loss: 0.485932\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043984; batch adversarial loss: 0.474905\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046238; batch adversarial loss: 0.478935\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033429; batch adversarial loss: 0.482018\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049940; batch adversarial loss: 0.444213\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045736; batch adversarial loss: 0.425837\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032992; batch adversarial loss: 0.454270\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043876; batch adversarial loss: 0.394310\n",
      "epoch 122; iter: 0; batch classifier loss: 0.078968; batch adversarial loss: 0.441202\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051930; batch adversarial loss: 0.415641\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022993; batch adversarial loss: 0.414131\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026880; batch adversarial loss: 0.451940\n",
      "epoch 126; iter: 0; batch classifier loss: 0.079967; batch adversarial loss: 0.407226\n",
      "epoch 127; iter: 0; batch classifier loss: 0.017057; batch adversarial loss: 0.450807\n",
      "epoch 128; iter: 0; batch classifier loss: 0.070539; batch adversarial loss: 0.464498\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052937; batch adversarial loss: 0.404736\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023816; batch adversarial loss: 0.510792\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029242; batch adversarial loss: 0.476849\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026262; batch adversarial loss: 0.548835\n",
      "epoch 133; iter: 0; batch classifier loss: 0.009058; batch adversarial loss: 0.460021\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052576; batch adversarial loss: 0.474400\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026358; batch adversarial loss: 0.465719\n",
      "epoch 136; iter: 0; batch classifier loss: 0.015491; batch adversarial loss: 0.495355\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038523; batch adversarial loss: 0.521267\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021873; batch adversarial loss: 0.371285\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021646; batch adversarial loss: 0.429935\n",
      "epoch 140; iter: 0; batch classifier loss: 0.016966; batch adversarial loss: 0.422666\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043871; batch adversarial loss: 0.491139\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019079; batch adversarial loss: 0.499755\n",
      "epoch 143; iter: 0; batch classifier loss: 0.044388; batch adversarial loss: 0.340374\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013896; batch adversarial loss: 0.478727\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028986; batch adversarial loss: 0.377992\n",
      "epoch 146; iter: 0; batch classifier loss: 0.009451; batch adversarial loss: 0.438942\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041892; batch adversarial loss: 0.522057\n",
      "epoch 148; iter: 0; batch classifier loss: 0.070589; batch adversarial loss: 0.408756\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024065; batch adversarial loss: 0.402117\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013647; batch adversarial loss: 0.372001\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030645; batch adversarial loss: 0.514583\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010876; batch adversarial loss: 0.543925\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015574; batch adversarial loss: 0.409506\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022120; batch adversarial loss: 0.423552\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017344; batch adversarial loss: 0.343685\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015424; batch adversarial loss: 0.336877\n",
      "epoch 157; iter: 0; batch classifier loss: 0.045758; batch adversarial loss: 0.423994\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009524; batch adversarial loss: 0.397441\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040933; batch adversarial loss: 0.373432\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025057; batch adversarial loss: 0.460590\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015247; batch adversarial loss: 0.489237\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026358; batch adversarial loss: 0.430026\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019800; batch adversarial loss: 0.546230\n",
      "epoch 164; iter: 0; batch classifier loss: 0.042605; batch adversarial loss: 0.467220\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044767; batch adversarial loss: 0.414114\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034759; batch adversarial loss: 0.423861\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017752; batch adversarial loss: 0.467602\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027116; batch adversarial loss: 0.487643\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012817; batch adversarial loss: 0.434969\n",
      "epoch 170; iter: 0; batch classifier loss: 0.005801; batch adversarial loss: 0.425038\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014155; batch adversarial loss: 0.470488\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017095; batch adversarial loss: 0.419419\n",
      "epoch 173; iter: 0; batch classifier loss: 0.051007; batch adversarial loss: 0.432323\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031331; batch adversarial loss: 0.475616\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023756; batch adversarial loss: 0.491908\n",
      "epoch 176; iter: 0; batch classifier loss: 0.005360; batch adversarial loss: 0.445511\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037062; batch adversarial loss: 0.398138\n",
      "epoch 178; iter: 0; batch classifier loss: 0.041774; batch adversarial loss: 0.481464\n",
      "epoch 179; iter: 0; batch classifier loss: 0.005348; batch adversarial loss: 0.464210\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008095; batch adversarial loss: 0.416194\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015817; batch adversarial loss: 0.395197\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029325; batch adversarial loss: 0.462191\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018508; batch adversarial loss: 0.424497\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010231; batch adversarial loss: 0.427640\n",
      "epoch 185; iter: 0; batch classifier loss: 0.003534; batch adversarial loss: 0.378256\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025784; batch adversarial loss: 0.407609\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031020; batch adversarial loss: 0.470896\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031442; batch adversarial loss: 0.461919\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021974; batch adversarial loss: 0.415330\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021770; batch adversarial loss: 0.522304\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037510; batch adversarial loss: 0.459211\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009571; batch adversarial loss: 0.453979\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010291; batch adversarial loss: 0.518825\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018108; batch adversarial loss: 0.422328\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006947; batch adversarial loss: 0.489957\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018202; batch adversarial loss: 0.433010\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012598; batch adversarial loss: 0.409046\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004454; batch adversarial loss: 0.466087\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013962; batch adversarial loss: 0.530079\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669613; batch adversarial loss: 0.889662\n",
      "epoch 1; iter: 0; batch classifier loss: 0.518986; batch adversarial loss: 1.019507\n",
      "epoch 2; iter: 0; batch classifier loss: 0.490888; batch adversarial loss: 0.958843\n",
      "epoch 3; iter: 0; batch classifier loss: 0.630618; batch adversarial loss: 0.890213\n",
      "epoch 4; iter: 0; batch classifier loss: 0.733737; batch adversarial loss: 0.830520\n",
      "epoch 5; iter: 0; batch classifier loss: 0.677981; batch adversarial loss: 0.731364\n",
      "epoch 6; iter: 0; batch classifier loss: 0.531931; batch adversarial loss: 0.681237\n",
      "epoch 7; iter: 0; batch classifier loss: 0.332731; batch adversarial loss: 0.631364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.283815; batch adversarial loss: 0.598140\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273968; batch adversarial loss: 0.585456\n",
      "epoch 10; iter: 0; batch classifier loss: 0.220358; batch adversarial loss: 0.585207\n",
      "epoch 11; iter: 0; batch classifier loss: 0.224124; batch adversarial loss: 0.574165\n",
      "epoch 12; iter: 0; batch classifier loss: 0.266341; batch adversarial loss: 0.581325\n",
      "epoch 13; iter: 0; batch classifier loss: 0.291072; batch adversarial loss: 0.533417\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249916; batch adversarial loss: 0.505600\n",
      "epoch 15; iter: 0; batch classifier loss: 0.221091; batch adversarial loss: 0.548508\n",
      "epoch 16; iter: 0; batch classifier loss: 0.205601; batch adversarial loss: 0.535879\n",
      "epoch 17; iter: 0; batch classifier loss: 0.193961; batch adversarial loss: 0.499450\n",
      "epoch 18; iter: 0; batch classifier loss: 0.191407; batch adversarial loss: 0.518924\n",
      "epoch 19; iter: 0; batch classifier loss: 0.172734; batch adversarial loss: 0.475425\n",
      "epoch 20; iter: 0; batch classifier loss: 0.149351; batch adversarial loss: 0.493258\n",
      "epoch 21; iter: 0; batch classifier loss: 0.191237; batch adversarial loss: 0.474078\n",
      "epoch 22; iter: 0; batch classifier loss: 0.161990; batch adversarial loss: 0.489319\n",
      "epoch 23; iter: 0; batch classifier loss: 0.144377; batch adversarial loss: 0.474069\n",
      "epoch 24; iter: 0; batch classifier loss: 0.140903; batch adversarial loss: 0.461334\n",
      "epoch 25; iter: 0; batch classifier loss: 0.194688; batch adversarial loss: 0.487172\n",
      "epoch 26; iter: 0; batch classifier loss: 0.118868; batch adversarial loss: 0.413453\n",
      "epoch 27; iter: 0; batch classifier loss: 0.105754; batch adversarial loss: 0.386105\n",
      "epoch 28; iter: 0; batch classifier loss: 0.183209; batch adversarial loss: 0.428293\n",
      "epoch 29; iter: 0; batch classifier loss: 0.112442; batch adversarial loss: 0.490323\n",
      "epoch 30; iter: 0; batch classifier loss: 0.095710; batch adversarial loss: 0.364428\n",
      "epoch 31; iter: 0; batch classifier loss: 0.159934; batch adversarial loss: 0.395315\n",
      "epoch 32; iter: 0; batch classifier loss: 0.098597; batch adversarial loss: 0.396131\n",
      "epoch 33; iter: 0; batch classifier loss: 0.094256; batch adversarial loss: 0.479872\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122457; batch adversarial loss: 0.441712\n",
      "epoch 35; iter: 0; batch classifier loss: 0.094132; batch adversarial loss: 0.515473\n",
      "epoch 36; iter: 0; batch classifier loss: 0.092322; batch adversarial loss: 0.432171\n",
      "epoch 37; iter: 0; batch classifier loss: 0.097340; batch adversarial loss: 0.420120\n",
      "epoch 38; iter: 0; batch classifier loss: 0.104756; batch adversarial loss: 0.444159\n",
      "epoch 39; iter: 0; batch classifier loss: 0.076208; batch adversarial loss: 0.402315\n",
      "epoch 40; iter: 0; batch classifier loss: 0.083284; batch adversarial loss: 0.446949\n",
      "epoch 41; iter: 0; batch classifier loss: 0.101123; batch adversarial loss: 0.483949\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088232; batch adversarial loss: 0.417176\n",
      "epoch 43; iter: 0; batch classifier loss: 0.046465; batch adversarial loss: 0.478604\n",
      "epoch 44; iter: 0; batch classifier loss: 0.057033; batch adversarial loss: 0.478039\n",
      "epoch 45; iter: 0; batch classifier loss: 0.085970; batch adversarial loss: 0.476699\n",
      "epoch 46; iter: 0; batch classifier loss: 0.062165; batch adversarial loss: 0.475039\n",
      "epoch 47; iter: 0; batch classifier loss: 0.073555; batch adversarial loss: 0.458087\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092034; batch adversarial loss: 0.449811\n",
      "epoch 49; iter: 0; batch classifier loss: 0.061100; batch adversarial loss: 0.460031\n",
      "epoch 50; iter: 0; batch classifier loss: 0.048956; batch adversarial loss: 0.348664\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081466; batch adversarial loss: 0.464756\n",
      "epoch 52; iter: 0; batch classifier loss: 0.056488; batch adversarial loss: 0.354127\n",
      "epoch 53; iter: 0; batch classifier loss: 0.092284; batch adversarial loss: 0.407007\n",
      "epoch 54; iter: 0; batch classifier loss: 0.044733; batch adversarial loss: 0.410731\n",
      "epoch 55; iter: 0; batch classifier loss: 0.075158; batch adversarial loss: 0.393140\n",
      "epoch 56; iter: 0; batch classifier loss: 0.072607; batch adversarial loss: 0.410881\n",
      "epoch 57; iter: 0; batch classifier loss: 0.060617; batch adversarial loss: 0.461222\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078723; batch adversarial loss: 0.486402\n",
      "epoch 59; iter: 0; batch classifier loss: 0.033442; batch adversarial loss: 0.543176\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065539; batch adversarial loss: 0.431704\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090671; batch adversarial loss: 0.522641\n",
      "epoch 62; iter: 0; batch classifier loss: 0.061521; batch adversarial loss: 0.394448\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092418; batch adversarial loss: 0.419685\n",
      "epoch 64; iter: 0; batch classifier loss: 0.062339; batch adversarial loss: 0.557289\n",
      "epoch 65; iter: 0; batch classifier loss: 0.066449; batch adversarial loss: 0.315030\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075228; batch adversarial loss: 0.501104\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065443; batch adversarial loss: 0.501528\n",
      "epoch 68; iter: 0; batch classifier loss: 0.073871; batch adversarial loss: 0.457361\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061780; batch adversarial loss: 0.439678\n",
      "epoch 70; iter: 0; batch classifier loss: 0.054896; batch adversarial loss: 0.435697\n",
      "epoch 71; iter: 0; batch classifier loss: 0.068196; batch adversarial loss: 0.408561\n",
      "epoch 72; iter: 0; batch classifier loss: 0.049088; batch adversarial loss: 0.392060\n",
      "epoch 73; iter: 0; batch classifier loss: 0.040759; batch adversarial loss: 0.367046\n",
      "epoch 74; iter: 0; batch classifier loss: 0.104448; batch adversarial loss: 0.463803\n",
      "epoch 75; iter: 0; batch classifier loss: 0.052900; batch adversarial loss: 0.449433\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064955; batch adversarial loss: 0.479590\n",
      "epoch 77; iter: 0; batch classifier loss: 0.086423; batch adversarial loss: 0.480431\n",
      "epoch 78; iter: 0; batch classifier loss: 0.039841; batch adversarial loss: 0.422691\n",
      "epoch 79; iter: 0; batch classifier loss: 0.051371; batch adversarial loss: 0.486578\n",
      "epoch 80; iter: 0; batch classifier loss: 0.065399; batch adversarial loss: 0.530179\n",
      "epoch 81; iter: 0; batch classifier loss: 0.045453; batch adversarial loss: 0.451452\n",
      "epoch 82; iter: 0; batch classifier loss: 0.084228; batch adversarial loss: 0.396489\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065083; batch adversarial loss: 0.415654\n",
      "epoch 84; iter: 0; batch classifier loss: 0.033709; batch adversarial loss: 0.429652\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045601; batch adversarial loss: 0.391031\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057282; batch adversarial loss: 0.385933\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049403; batch adversarial loss: 0.421473\n",
      "epoch 88; iter: 0; batch classifier loss: 0.061628; batch adversarial loss: 0.483838\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063066; batch adversarial loss: 0.470061\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062294; batch adversarial loss: 0.478203\n",
      "epoch 91; iter: 0; batch classifier loss: 0.037363; batch adversarial loss: 0.415031\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065219; batch adversarial loss: 0.411583\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050533; batch adversarial loss: 0.436971\n",
      "epoch 94; iter: 0; batch classifier loss: 0.054883; batch adversarial loss: 0.448162\n",
      "epoch 95; iter: 0; batch classifier loss: 0.034859; batch adversarial loss: 0.420966\n",
      "epoch 96; iter: 0; batch classifier loss: 0.054281; batch adversarial loss: 0.463791\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080015; batch adversarial loss: 0.528430\n",
      "epoch 98; iter: 0; batch classifier loss: 0.089313; batch adversarial loss: 0.448015\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069763; batch adversarial loss: 0.510749\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053051; batch adversarial loss: 0.405146\n",
      "epoch 101; iter: 0; batch classifier loss: 0.081299; batch adversarial loss: 0.490459\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054132; batch adversarial loss: 0.439043\n",
      "epoch 103; iter: 0; batch classifier loss: 0.077163; batch adversarial loss: 0.445538\n",
      "epoch 104; iter: 0; batch classifier loss: 0.054893; batch adversarial loss: 0.454913\n",
      "epoch 105; iter: 0; batch classifier loss: 0.039548; batch adversarial loss: 0.417462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.085501; batch adversarial loss: 0.427619\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059755; batch adversarial loss: 0.535684\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052688; batch adversarial loss: 0.393986\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067145; batch adversarial loss: 0.418895\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051632; batch adversarial loss: 0.458039\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051619; batch adversarial loss: 0.439183\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063017; batch adversarial loss: 0.491664\n",
      "epoch 113; iter: 0; batch classifier loss: 0.016874; batch adversarial loss: 0.423199\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059000; batch adversarial loss: 0.508358\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053565; batch adversarial loss: 0.500708\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052573; batch adversarial loss: 0.488330\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056421; batch adversarial loss: 0.492966\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056316; batch adversarial loss: 0.445561\n",
      "epoch 119; iter: 0; batch classifier loss: 0.066972; batch adversarial loss: 0.435909\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038245; batch adversarial loss: 0.418724\n",
      "epoch 121; iter: 0; batch classifier loss: 0.056344; batch adversarial loss: 0.601757\n",
      "epoch 122; iter: 0; batch classifier loss: 0.068998; batch adversarial loss: 0.432422\n",
      "epoch 123; iter: 0; batch classifier loss: 0.061324; batch adversarial loss: 0.381637\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037560; batch adversarial loss: 0.401751\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041048; batch adversarial loss: 0.464614\n",
      "epoch 126; iter: 0; batch classifier loss: 0.073761; batch adversarial loss: 0.421899\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031646; batch adversarial loss: 0.446567\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052306; batch adversarial loss: 0.426244\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025116; batch adversarial loss: 0.470130\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024841; batch adversarial loss: 0.493583\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049403; batch adversarial loss: 0.542809\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047906; batch adversarial loss: 0.461234\n",
      "epoch 133; iter: 0; batch classifier loss: 0.056492; batch adversarial loss: 0.432435\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045219; batch adversarial loss: 0.469168\n",
      "epoch 135; iter: 0; batch classifier loss: 0.086717; batch adversarial loss: 0.460511\n",
      "epoch 136; iter: 0; batch classifier loss: 0.082595; batch adversarial loss: 0.411048\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038935; batch adversarial loss: 0.461108\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046694; batch adversarial loss: 0.399646\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034626; batch adversarial loss: 0.385327\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044681; batch adversarial loss: 0.551081\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053451; batch adversarial loss: 0.405186\n",
      "epoch 142; iter: 0; batch classifier loss: 0.064511; batch adversarial loss: 0.514977\n",
      "epoch 143; iter: 0; batch classifier loss: 0.044954; batch adversarial loss: 0.460898\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047162; batch adversarial loss: 0.394232\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032758; batch adversarial loss: 0.480426\n",
      "epoch 146; iter: 0; batch classifier loss: 0.043607; batch adversarial loss: 0.416565\n",
      "epoch 147; iter: 0; batch classifier loss: 0.049742; batch adversarial loss: 0.438195\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039385; batch adversarial loss: 0.514652\n",
      "epoch 149; iter: 0; batch classifier loss: 0.077301; batch adversarial loss: 0.471043\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040040; batch adversarial loss: 0.423549\n",
      "epoch 151; iter: 0; batch classifier loss: 0.049246; batch adversarial loss: 0.423439\n",
      "epoch 152; iter: 0; batch classifier loss: 0.051983; batch adversarial loss: 0.453998\n",
      "epoch 153; iter: 0; batch classifier loss: 0.053214; batch adversarial loss: 0.389400\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046495; batch adversarial loss: 0.468075\n",
      "epoch 155; iter: 0; batch classifier loss: 0.058399; batch adversarial loss: 0.417724\n",
      "epoch 156; iter: 0; batch classifier loss: 0.069716; batch adversarial loss: 0.423640\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042596; batch adversarial loss: 0.428498\n",
      "epoch 158; iter: 0; batch classifier loss: 0.055875; batch adversarial loss: 0.442532\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040386; batch adversarial loss: 0.427740\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027350; batch adversarial loss: 0.355252\n",
      "epoch 161; iter: 0; batch classifier loss: 0.065544; batch adversarial loss: 0.592858\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031666; batch adversarial loss: 0.502925\n",
      "epoch 163; iter: 0; batch classifier loss: 0.055539; batch adversarial loss: 0.396037\n",
      "epoch 164; iter: 0; batch classifier loss: 0.045177; batch adversarial loss: 0.445728\n",
      "epoch 165; iter: 0; batch classifier loss: 0.061262; batch adversarial loss: 0.488940\n",
      "epoch 166; iter: 0; batch classifier loss: 0.049491; batch adversarial loss: 0.516411\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029452; batch adversarial loss: 0.424428\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026828; batch adversarial loss: 0.456068\n",
      "epoch 169; iter: 0; batch classifier loss: 0.053617; batch adversarial loss: 0.543207\n",
      "epoch 170; iter: 0; batch classifier loss: 0.051786; batch adversarial loss: 0.441682\n",
      "epoch 171; iter: 0; batch classifier loss: 0.065649; batch adversarial loss: 0.449758\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032301; batch adversarial loss: 0.439252\n",
      "epoch 173; iter: 0; batch classifier loss: 0.041679; batch adversarial loss: 0.458370\n",
      "epoch 174; iter: 0; batch classifier loss: 0.043939; batch adversarial loss: 0.446167\n",
      "epoch 175; iter: 0; batch classifier loss: 0.048100; batch adversarial loss: 0.476439\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040158; batch adversarial loss: 0.516241\n",
      "epoch 177; iter: 0; batch classifier loss: 0.050027; batch adversarial loss: 0.479291\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029272; batch adversarial loss: 0.362556\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031608; batch adversarial loss: 0.486671\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035097; batch adversarial loss: 0.469419\n",
      "epoch 181; iter: 0; batch classifier loss: 0.058575; batch adversarial loss: 0.483607\n",
      "epoch 182; iter: 0; batch classifier loss: 0.046028; batch adversarial loss: 0.487352\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039546; batch adversarial loss: 0.465778\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040865; batch adversarial loss: 0.510464\n",
      "epoch 185; iter: 0; batch classifier loss: 0.054036; batch adversarial loss: 0.488653\n",
      "epoch 186; iter: 0; batch classifier loss: 0.038808; batch adversarial loss: 0.412447\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035396; batch adversarial loss: 0.385099\n",
      "epoch 188; iter: 0; batch classifier loss: 0.048914; batch adversarial loss: 0.462141\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031114; batch adversarial loss: 0.429277\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033868; batch adversarial loss: 0.442277\n",
      "epoch 191; iter: 0; batch classifier loss: 0.057898; batch adversarial loss: 0.448471\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027769; batch adversarial loss: 0.419646\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037540; batch adversarial loss: 0.393009\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041110; batch adversarial loss: 0.435732\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013858; batch adversarial loss: 0.487783\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019385; batch adversarial loss: 0.400146\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045897; batch adversarial loss: 0.499633\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023212; batch adversarial loss: 0.488657\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023679; batch adversarial loss: 0.389985\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677221; batch adversarial loss: 0.592830\n",
      "epoch 1; iter: 0; batch classifier loss: 0.413669; batch adversarial loss: 0.624109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.409923; batch adversarial loss: 0.580644\n",
      "epoch 3; iter: 0; batch classifier loss: 0.408657; batch adversarial loss: 0.570818\n",
      "epoch 4; iter: 0; batch classifier loss: 0.346756; batch adversarial loss: 0.553394\n",
      "epoch 5; iter: 0; batch classifier loss: 0.279080; batch adversarial loss: 0.611554\n",
      "epoch 6; iter: 0; batch classifier loss: 0.386813; batch adversarial loss: 0.558663\n",
      "epoch 7; iter: 0; batch classifier loss: 0.359278; batch adversarial loss: 0.536102\n",
      "epoch 8; iter: 0; batch classifier loss: 0.506793; batch adversarial loss: 0.566894\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499510; batch adversarial loss: 0.520524\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484891; batch adversarial loss: 0.550091\n",
      "epoch 11; iter: 0; batch classifier loss: 0.417903; batch adversarial loss: 0.496036\n",
      "epoch 12; iter: 0; batch classifier loss: 0.496068; batch adversarial loss: 0.489666\n",
      "epoch 13; iter: 0; batch classifier loss: 0.341281; batch adversarial loss: 0.527160\n",
      "epoch 14; iter: 0; batch classifier loss: 0.282283; batch adversarial loss: 0.480597\n",
      "epoch 15; iter: 0; batch classifier loss: 0.265738; batch adversarial loss: 0.427973\n",
      "epoch 16; iter: 0; batch classifier loss: 0.277280; batch adversarial loss: 0.532665\n",
      "epoch 17; iter: 0; batch classifier loss: 0.195391; batch adversarial loss: 0.471975\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237595; batch adversarial loss: 0.435507\n",
      "epoch 19; iter: 0; batch classifier loss: 0.244975; batch adversarial loss: 0.527422\n",
      "epoch 20; iter: 0; batch classifier loss: 0.197063; batch adversarial loss: 0.474913\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186719; batch adversarial loss: 0.458184\n",
      "epoch 22; iter: 0; batch classifier loss: 0.139581; batch adversarial loss: 0.525607\n",
      "epoch 23; iter: 0; batch classifier loss: 0.190395; batch adversarial loss: 0.482287\n",
      "epoch 24; iter: 0; batch classifier loss: 0.146965; batch adversarial loss: 0.451102\n",
      "epoch 25; iter: 0; batch classifier loss: 0.195341; batch adversarial loss: 0.506589\n",
      "epoch 26; iter: 0; batch classifier loss: 0.185162; batch adversarial loss: 0.427176\n",
      "epoch 27; iter: 0; batch classifier loss: 0.141476; batch adversarial loss: 0.492736\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160954; batch adversarial loss: 0.413640\n",
      "epoch 29; iter: 0; batch classifier loss: 0.161378; batch adversarial loss: 0.498932\n",
      "epoch 30; iter: 0; batch classifier loss: 0.188009; batch adversarial loss: 0.413599\n",
      "epoch 31; iter: 0; batch classifier loss: 0.145907; batch adversarial loss: 0.490987\n",
      "epoch 32; iter: 0; batch classifier loss: 0.143859; batch adversarial loss: 0.383187\n",
      "epoch 33; iter: 0; batch classifier loss: 0.098115; batch adversarial loss: 0.453716\n",
      "epoch 34; iter: 0; batch classifier loss: 0.150863; batch adversarial loss: 0.377824\n",
      "epoch 35; iter: 0; batch classifier loss: 0.074742; batch adversarial loss: 0.525959\n",
      "epoch 36; iter: 0; batch classifier loss: 0.121745; batch adversarial loss: 0.403577\n",
      "epoch 37; iter: 0; batch classifier loss: 0.152179; batch adversarial loss: 0.490613\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117280; batch adversarial loss: 0.438874\n",
      "epoch 39; iter: 0; batch classifier loss: 0.096389; batch adversarial loss: 0.391146\n",
      "epoch 40; iter: 0; batch classifier loss: 0.128638; batch adversarial loss: 0.411124\n",
      "epoch 41; iter: 0; batch classifier loss: 0.155786; batch adversarial loss: 0.492271\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106684; batch adversarial loss: 0.521652\n",
      "epoch 43; iter: 0; batch classifier loss: 0.126388; batch adversarial loss: 0.466356\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112417; batch adversarial loss: 0.474293\n",
      "epoch 45; iter: 0; batch classifier loss: 0.096724; batch adversarial loss: 0.407732\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131941; batch adversarial loss: 0.477954\n",
      "epoch 47; iter: 0; batch classifier loss: 0.150541; batch adversarial loss: 0.469923\n",
      "epoch 48; iter: 0; batch classifier loss: 0.136800; batch adversarial loss: 0.442658\n",
      "epoch 49; iter: 0; batch classifier loss: 0.172844; batch adversarial loss: 0.468228\n",
      "epoch 50; iter: 0; batch classifier loss: 0.160385; batch adversarial loss: 0.462166\n",
      "epoch 51; iter: 0; batch classifier loss: 0.148959; batch adversarial loss: 0.476682\n",
      "epoch 52; iter: 0; batch classifier loss: 0.120157; batch adversarial loss: 0.487745\n",
      "epoch 53; iter: 0; batch classifier loss: 0.249498; batch adversarial loss: 0.376001\n",
      "epoch 54; iter: 0; batch classifier loss: 0.137770; batch adversarial loss: 0.514437\n",
      "epoch 55; iter: 0; batch classifier loss: 0.141140; batch adversarial loss: 0.551310\n",
      "epoch 56; iter: 0; batch classifier loss: 0.185701; batch adversarial loss: 0.501426\n",
      "epoch 57; iter: 0; batch classifier loss: 0.157942; batch adversarial loss: 0.413765\n",
      "epoch 58; iter: 0; batch classifier loss: 0.115775; batch adversarial loss: 0.515172\n",
      "epoch 59; iter: 0; batch classifier loss: 0.159002; batch adversarial loss: 0.395532\n",
      "epoch 60; iter: 0; batch classifier loss: 0.123531; batch adversarial loss: 0.507853\n",
      "epoch 61; iter: 0; batch classifier loss: 0.231592; batch adversarial loss: 0.397408\n",
      "epoch 62; iter: 0; batch classifier loss: 0.125444; batch adversarial loss: 0.583675\n",
      "epoch 63; iter: 0; batch classifier loss: 0.200891; batch adversarial loss: 0.458962\n",
      "epoch 64; iter: 0; batch classifier loss: 0.156958; batch adversarial loss: 0.601686\n",
      "epoch 65; iter: 0; batch classifier loss: 0.137231; batch adversarial loss: 0.521332\n",
      "epoch 66; iter: 0; batch classifier loss: 0.132053; batch adversarial loss: 0.362114\n",
      "epoch 67; iter: 0; batch classifier loss: 0.204579; batch adversarial loss: 0.449336\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082685; batch adversarial loss: 0.505132\n",
      "epoch 69; iter: 0; batch classifier loss: 0.175115; batch adversarial loss: 0.442315\n",
      "epoch 70; iter: 0; batch classifier loss: 0.261380; batch adversarial loss: 0.401849\n",
      "epoch 71; iter: 0; batch classifier loss: 0.222242; batch adversarial loss: 0.559178\n",
      "epoch 72; iter: 0; batch classifier loss: 0.228923; batch adversarial loss: 0.459377\n",
      "epoch 73; iter: 0; batch classifier loss: 0.175150; batch adversarial loss: 0.406927\n",
      "epoch 74; iter: 0; batch classifier loss: 0.168191; batch adversarial loss: 0.421779\n",
      "epoch 75; iter: 0; batch classifier loss: 0.212847; batch adversarial loss: 0.455302\n",
      "epoch 76; iter: 0; batch classifier loss: 0.258324; batch adversarial loss: 0.424142\n",
      "epoch 77; iter: 0; batch classifier loss: 0.136411; batch adversarial loss: 0.339504\n",
      "epoch 78; iter: 0; batch classifier loss: 0.182551; batch adversarial loss: 0.483069\n",
      "epoch 79; iter: 0; batch classifier loss: 0.210245; batch adversarial loss: 0.459167\n",
      "epoch 80; iter: 0; batch classifier loss: 0.184174; batch adversarial loss: 0.447708\n",
      "epoch 81; iter: 0; batch classifier loss: 0.182706; batch adversarial loss: 0.494988\n",
      "epoch 82; iter: 0; batch classifier loss: 0.212234; batch adversarial loss: 0.506887\n",
      "epoch 83; iter: 0; batch classifier loss: 0.219658; batch adversarial loss: 0.519326\n",
      "epoch 84; iter: 0; batch classifier loss: 0.236624; batch adversarial loss: 0.506655\n",
      "epoch 85; iter: 0; batch classifier loss: 0.139996; batch adversarial loss: 0.435051\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068169; batch adversarial loss: 0.519346\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082684; batch adversarial loss: 0.494174\n",
      "epoch 88; iter: 0; batch classifier loss: 0.087918; batch adversarial loss: 0.430805\n",
      "epoch 89; iter: 0; batch classifier loss: 0.077015; batch adversarial loss: 0.552110\n",
      "epoch 90; iter: 0; batch classifier loss: 0.096174; batch adversarial loss: 0.457578\n",
      "epoch 91; iter: 0; batch classifier loss: 0.173726; batch adversarial loss: 0.512359\n",
      "epoch 92; iter: 0; batch classifier loss: 0.117269; batch adversarial loss: 0.397327\n",
      "epoch 93; iter: 0; batch classifier loss: 0.169154; batch adversarial loss: 0.422235\n",
      "epoch 94; iter: 0; batch classifier loss: 0.155972; batch adversarial loss: 0.499451\n",
      "epoch 95; iter: 0; batch classifier loss: 0.148726; batch adversarial loss: 0.469841\n",
      "epoch 96; iter: 0; batch classifier loss: 0.126344; batch adversarial loss: 0.435109\n",
      "epoch 97; iter: 0; batch classifier loss: 0.180415; batch adversarial loss: 0.451050\n",
      "epoch 98; iter: 0; batch classifier loss: 0.138592; batch adversarial loss: 0.407482\n",
      "epoch 99; iter: 0; batch classifier loss: 0.095408; batch adversarial loss: 0.520891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.127877; batch adversarial loss: 0.468506\n",
      "epoch 101; iter: 0; batch classifier loss: 0.157478; batch adversarial loss: 0.463082\n",
      "epoch 102; iter: 0; batch classifier loss: 0.154331; batch adversarial loss: 0.461024\n",
      "epoch 103; iter: 0; batch classifier loss: 0.145133; batch adversarial loss: 0.482101\n",
      "epoch 104; iter: 0; batch classifier loss: 0.109852; batch adversarial loss: 0.533208\n",
      "epoch 105; iter: 0; batch classifier loss: 0.146854; batch adversarial loss: 0.453572\n",
      "epoch 106; iter: 0; batch classifier loss: 0.111983; batch adversarial loss: 0.483809\n",
      "epoch 107; iter: 0; batch classifier loss: 0.115303; batch adversarial loss: 0.525441\n",
      "epoch 108; iter: 0; batch classifier loss: 0.135980; batch adversarial loss: 0.438724\n",
      "epoch 109; iter: 0; batch classifier loss: 0.114651; batch adversarial loss: 0.502498\n",
      "epoch 110; iter: 0; batch classifier loss: 0.086914; batch adversarial loss: 0.468003\n",
      "epoch 111; iter: 0; batch classifier loss: 0.101538; batch adversarial loss: 0.440380\n",
      "epoch 112; iter: 0; batch classifier loss: 0.110079; batch adversarial loss: 0.402280\n",
      "epoch 113; iter: 0; batch classifier loss: 0.105463; batch adversarial loss: 0.395487\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080023; batch adversarial loss: 0.580435\n",
      "epoch 115; iter: 0; batch classifier loss: 0.124351; batch adversarial loss: 0.470545\n",
      "epoch 116; iter: 0; batch classifier loss: 0.090058; batch adversarial loss: 0.440875\n",
      "epoch 117; iter: 0; batch classifier loss: 0.089092; batch adversarial loss: 0.486099\n",
      "epoch 118; iter: 0; batch classifier loss: 0.110421; batch adversarial loss: 0.475506\n",
      "epoch 119; iter: 0; batch classifier loss: 0.066112; batch adversarial loss: 0.526937\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074706; batch adversarial loss: 0.492176\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058360; batch adversarial loss: 0.482383\n",
      "epoch 122; iter: 0; batch classifier loss: 0.069750; batch adversarial loss: 0.392829\n",
      "epoch 123; iter: 0; batch classifier loss: 0.066204; batch adversarial loss: 0.490577\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041942; batch adversarial loss: 0.381916\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050676; batch adversarial loss: 0.338084\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040257; batch adversarial loss: 0.408276\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027490; batch adversarial loss: 0.539840\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021915; batch adversarial loss: 0.567140\n",
      "epoch 129; iter: 0; batch classifier loss: 0.058190; batch adversarial loss: 0.380593\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037216; batch adversarial loss: 0.392856\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028896; batch adversarial loss: 0.415356\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034840; batch adversarial loss: 0.507270\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031708; batch adversarial loss: 0.452771\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036917; batch adversarial loss: 0.548142\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031024; batch adversarial loss: 0.478793\n",
      "epoch 136; iter: 0; batch classifier loss: 0.059306; batch adversarial loss: 0.489254\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028661; batch adversarial loss: 0.453665\n",
      "epoch 138; iter: 0; batch classifier loss: 0.069129; batch adversarial loss: 0.412883\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018951; batch adversarial loss: 0.492346\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038318; batch adversarial loss: 0.492411\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024737; batch adversarial loss: 0.458719\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028779; batch adversarial loss: 0.407510\n",
      "epoch 143; iter: 0; batch classifier loss: 0.088092; batch adversarial loss: 0.524291\n",
      "epoch 144; iter: 0; batch classifier loss: 0.044032; batch adversarial loss: 0.470602\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023149; batch adversarial loss: 0.463279\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023634; batch adversarial loss: 0.578033\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017948; batch adversarial loss: 0.459652\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014212; batch adversarial loss: 0.450843\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018196; batch adversarial loss: 0.485020\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027922; batch adversarial loss: 0.462460\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018742; batch adversarial loss: 0.438621\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037154; batch adversarial loss: 0.400168\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042018; batch adversarial loss: 0.468775\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015193; batch adversarial loss: 0.420686\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036138; batch adversarial loss: 0.428479\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029819; batch adversarial loss: 0.435542\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026577; batch adversarial loss: 0.443086\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035726; batch adversarial loss: 0.396516\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025629; batch adversarial loss: 0.385314\n",
      "epoch 160; iter: 0; batch classifier loss: 0.040804; batch adversarial loss: 0.489255\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015705; batch adversarial loss: 0.447269\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014890; batch adversarial loss: 0.433113\n",
      "epoch 163; iter: 0; batch classifier loss: 0.044131; batch adversarial loss: 0.461944\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023095; batch adversarial loss: 0.536761\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029989; batch adversarial loss: 0.481438\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011856; batch adversarial loss: 0.446563\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016725; batch adversarial loss: 0.387499\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026478; batch adversarial loss: 0.460605\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018535; batch adversarial loss: 0.453827\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034012; batch adversarial loss: 0.450189\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026572; batch adversarial loss: 0.469915\n",
      "epoch 172; iter: 0; batch classifier loss: 0.053153; batch adversarial loss: 0.448988\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037691; batch adversarial loss: 0.402505\n",
      "epoch 174; iter: 0; batch classifier loss: 0.050904; batch adversarial loss: 0.560257\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008034; batch adversarial loss: 0.463802\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017143; batch adversarial loss: 0.438046\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021664; batch adversarial loss: 0.412438\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017098; batch adversarial loss: 0.508456\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009193; batch adversarial loss: 0.461433\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014547; batch adversarial loss: 0.470071\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010962; batch adversarial loss: 0.398208\n",
      "epoch 182; iter: 0; batch classifier loss: 0.002702; batch adversarial loss: 0.503395\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020055; batch adversarial loss: 0.490308\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025647; batch adversarial loss: 0.496052\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018180; batch adversarial loss: 0.501247\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011261; batch adversarial loss: 0.466664\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044940; batch adversarial loss: 0.410437\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030066; batch adversarial loss: 0.484437\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013910; batch adversarial loss: 0.401522\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010407; batch adversarial loss: 0.418242\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022676; batch adversarial loss: 0.376906\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017981; batch adversarial loss: 0.516841\n",
      "epoch 193; iter: 0; batch classifier loss: 0.003880; batch adversarial loss: 0.423614\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023044; batch adversarial loss: 0.428577\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033973; batch adversarial loss: 0.495016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.006906; batch adversarial loss: 0.579710\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032800; batch adversarial loss: 0.524631\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012655; batch adversarial loss: 0.478023\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015325; batch adversarial loss: 0.369324\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687385; batch adversarial loss: 0.762849\n",
      "epoch 1; iter: 0; batch classifier loss: 0.409917; batch adversarial loss: 0.722546\n",
      "epoch 2; iter: 0; batch classifier loss: 0.394895; batch adversarial loss: 0.672338\n",
      "epoch 3; iter: 0; batch classifier loss: 0.407892; batch adversarial loss: 0.628575\n",
      "epoch 4; iter: 0; batch classifier loss: 0.359110; batch adversarial loss: 0.626642\n",
      "epoch 5; iter: 0; batch classifier loss: 0.352059; batch adversarial loss: 0.597735\n",
      "epoch 6; iter: 0; batch classifier loss: 0.396566; batch adversarial loss: 0.584301\n",
      "epoch 7; iter: 0; batch classifier loss: 0.340844; batch adversarial loss: 0.550393\n",
      "epoch 8; iter: 0; batch classifier loss: 0.334516; batch adversarial loss: 0.585025\n",
      "epoch 9; iter: 0; batch classifier loss: 0.339427; batch adversarial loss: 0.550755\n",
      "epoch 10; iter: 0; batch classifier loss: 0.398346; batch adversarial loss: 0.560813\n",
      "epoch 11; iter: 0; batch classifier loss: 0.329834; batch adversarial loss: 0.520475\n",
      "epoch 12; iter: 0; batch classifier loss: 0.442434; batch adversarial loss: 0.548756\n",
      "epoch 13; iter: 0; batch classifier loss: 0.450531; batch adversarial loss: 0.530422\n",
      "epoch 14; iter: 0; batch classifier loss: 0.383292; batch adversarial loss: 0.527816\n",
      "epoch 15; iter: 0; batch classifier loss: 0.369568; batch adversarial loss: 0.472523\n",
      "epoch 16; iter: 0; batch classifier loss: 0.366131; batch adversarial loss: 0.553991\n",
      "epoch 17; iter: 0; batch classifier loss: 0.355927; batch adversarial loss: 0.484180\n",
      "epoch 18; iter: 0; batch classifier loss: 0.287003; batch adversarial loss: 0.472480\n",
      "epoch 19; iter: 0; batch classifier loss: 0.301479; batch adversarial loss: 0.477817\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313006; batch adversarial loss: 0.498464\n",
      "epoch 21; iter: 0; batch classifier loss: 0.306028; batch adversarial loss: 0.437625\n",
      "epoch 22; iter: 0; batch classifier loss: 0.364937; batch adversarial loss: 0.526344\n",
      "epoch 23; iter: 0; batch classifier loss: 0.268225; batch adversarial loss: 0.482826\n",
      "epoch 24; iter: 0; batch classifier loss: 0.324481; batch adversarial loss: 0.492837\n",
      "epoch 25; iter: 0; batch classifier loss: 0.343989; batch adversarial loss: 0.446182\n",
      "epoch 26; iter: 0; batch classifier loss: 0.318690; batch adversarial loss: 0.514801\n",
      "epoch 27; iter: 0; batch classifier loss: 0.338061; batch adversarial loss: 0.472803\n",
      "epoch 28; iter: 0; batch classifier loss: 0.231608; batch adversarial loss: 0.520293\n",
      "epoch 29; iter: 0; batch classifier loss: 0.295404; batch adversarial loss: 0.468066\n",
      "epoch 30; iter: 0; batch classifier loss: 0.246379; batch adversarial loss: 0.511083\n",
      "epoch 31; iter: 0; batch classifier loss: 0.356420; batch adversarial loss: 0.484000\n",
      "epoch 32; iter: 0; batch classifier loss: 0.208571; batch adversarial loss: 0.469847\n",
      "epoch 33; iter: 0; batch classifier loss: 0.216932; batch adversarial loss: 0.458419\n",
      "epoch 34; iter: 0; batch classifier loss: 0.274006; batch adversarial loss: 0.492395\n",
      "epoch 35; iter: 0; batch classifier loss: 0.268902; batch adversarial loss: 0.439866\n",
      "epoch 36; iter: 0; batch classifier loss: 0.192862; batch adversarial loss: 0.542578\n",
      "epoch 37; iter: 0; batch classifier loss: 0.230826; batch adversarial loss: 0.486947\n",
      "epoch 38; iter: 0; batch classifier loss: 0.274774; batch adversarial loss: 0.380770\n",
      "epoch 39; iter: 0; batch classifier loss: 0.268741; batch adversarial loss: 0.471385\n",
      "epoch 40; iter: 0; batch classifier loss: 0.253351; batch adversarial loss: 0.453983\n",
      "epoch 41; iter: 0; batch classifier loss: 0.210371; batch adversarial loss: 0.460306\n",
      "epoch 42; iter: 0; batch classifier loss: 0.207325; batch adversarial loss: 0.448039\n",
      "epoch 43; iter: 0; batch classifier loss: 0.268220; batch adversarial loss: 0.498015\n",
      "epoch 44; iter: 0; batch classifier loss: 0.193386; batch adversarial loss: 0.544451\n",
      "epoch 45; iter: 0; batch classifier loss: 0.239446; batch adversarial loss: 0.343346\n",
      "epoch 46; iter: 0; batch classifier loss: 0.264988; batch adversarial loss: 0.516684\n",
      "epoch 47; iter: 0; batch classifier loss: 0.171712; batch adversarial loss: 0.444434\n",
      "epoch 48; iter: 0; batch classifier loss: 0.288491; batch adversarial loss: 0.402577\n",
      "epoch 49; iter: 0; batch classifier loss: 0.230602; batch adversarial loss: 0.470070\n",
      "epoch 50; iter: 0; batch classifier loss: 0.197310; batch adversarial loss: 0.519117\n",
      "epoch 51; iter: 0; batch classifier loss: 0.191935; batch adversarial loss: 0.464035\n",
      "epoch 52; iter: 0; batch classifier loss: 0.269965; batch adversarial loss: 0.457334\n",
      "epoch 53; iter: 0; batch classifier loss: 0.213843; batch adversarial loss: 0.448733\n",
      "epoch 54; iter: 0; batch classifier loss: 0.237505; batch adversarial loss: 0.396912\n",
      "epoch 55; iter: 0; batch classifier loss: 0.260984; batch adversarial loss: 0.458283\n",
      "epoch 56; iter: 0; batch classifier loss: 0.190616; batch adversarial loss: 0.411091\n",
      "epoch 57; iter: 0; batch classifier loss: 0.234919; batch adversarial loss: 0.471911\n",
      "epoch 58; iter: 0; batch classifier loss: 0.262420; batch adversarial loss: 0.421198\n",
      "epoch 59; iter: 0; batch classifier loss: 0.218605; batch adversarial loss: 0.446974\n",
      "epoch 60; iter: 0; batch classifier loss: 0.187004; batch adversarial loss: 0.506625\n",
      "epoch 61; iter: 0; batch classifier loss: 0.190045; batch adversarial loss: 0.518987\n",
      "epoch 62; iter: 0; batch classifier loss: 0.228614; batch adversarial loss: 0.484258\n",
      "epoch 63; iter: 0; batch classifier loss: 0.169393; batch adversarial loss: 0.446644\n",
      "epoch 64; iter: 0; batch classifier loss: 0.238119; batch adversarial loss: 0.485222\n",
      "epoch 65; iter: 0; batch classifier loss: 0.234191; batch adversarial loss: 0.410316\n",
      "epoch 66; iter: 0; batch classifier loss: 0.165999; batch adversarial loss: 0.348973\n",
      "epoch 67; iter: 0; batch classifier loss: 0.183836; batch adversarial loss: 0.373799\n",
      "epoch 68; iter: 0; batch classifier loss: 0.152215; batch adversarial loss: 0.409343\n",
      "epoch 69; iter: 0; batch classifier loss: 0.141165; batch adversarial loss: 0.469874\n",
      "epoch 70; iter: 0; batch classifier loss: 0.212826; batch adversarial loss: 0.544907\n",
      "epoch 71; iter: 0; batch classifier loss: 0.214030; batch adversarial loss: 0.447187\n",
      "epoch 72; iter: 0; batch classifier loss: 0.145634; batch adversarial loss: 0.483317\n",
      "epoch 73; iter: 0; batch classifier loss: 0.236310; batch adversarial loss: 0.444994\n",
      "epoch 74; iter: 0; batch classifier loss: 0.303427; batch adversarial loss: 0.446893\n",
      "epoch 75; iter: 0; batch classifier loss: 0.166093; batch adversarial loss: 0.373400\n",
      "epoch 76; iter: 0; batch classifier loss: 0.192214; batch adversarial loss: 0.334865\n",
      "epoch 77; iter: 0; batch classifier loss: 0.272296; batch adversarial loss: 0.471063\n",
      "epoch 78; iter: 0; batch classifier loss: 0.164144; batch adversarial loss: 0.372934\n",
      "epoch 79; iter: 0; batch classifier loss: 0.156387; batch adversarial loss: 0.359527\n",
      "epoch 80; iter: 0; batch classifier loss: 0.241123; batch adversarial loss: 0.457979\n",
      "epoch 81; iter: 0; batch classifier loss: 0.300381; batch adversarial loss: 0.508854\n",
      "epoch 82; iter: 0; batch classifier loss: 0.209893; batch adversarial loss: 0.434624\n",
      "epoch 83; iter: 0; batch classifier loss: 0.183479; batch adversarial loss: 0.494878\n",
      "epoch 84; iter: 0; batch classifier loss: 0.239513; batch adversarial loss: 0.458834\n",
      "epoch 85; iter: 0; batch classifier loss: 0.172816; batch adversarial loss: 0.544294\n",
      "epoch 86; iter: 0; batch classifier loss: 0.101462; batch adversarial loss: 0.371338\n",
      "epoch 87; iter: 0; batch classifier loss: 0.065170; batch adversarial loss: 0.493311\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062189; batch adversarial loss: 0.325980\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074602; batch adversarial loss: 0.438930\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047031; batch adversarial loss: 0.517425\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077136; batch adversarial loss: 0.403585\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044180; batch adversarial loss: 0.497955\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046800; batch adversarial loss: 0.499666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.038809; batch adversarial loss: 0.426839\n",
      "epoch 95; iter: 0; batch classifier loss: 0.061120; batch adversarial loss: 0.391417\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044262; batch adversarial loss: 0.480309\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037360; batch adversarial loss: 0.445945\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052157; batch adversarial loss: 0.433731\n",
      "epoch 99; iter: 0; batch classifier loss: 0.109928; batch adversarial loss: 0.400001\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061316; batch adversarial loss: 0.438453\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063063; batch adversarial loss: 0.373950\n",
      "epoch 102; iter: 0; batch classifier loss: 0.076856; batch adversarial loss: 0.537295\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060840; batch adversarial loss: 0.428961\n",
      "epoch 104; iter: 0; batch classifier loss: 0.068082; batch adversarial loss: 0.455127\n",
      "epoch 105; iter: 0; batch classifier loss: 0.073820; batch adversarial loss: 0.485057\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063995; batch adversarial loss: 0.489540\n",
      "epoch 107; iter: 0; batch classifier loss: 0.057731; batch adversarial loss: 0.399722\n",
      "epoch 108; iter: 0; batch classifier loss: 0.083936; batch adversarial loss: 0.419456\n",
      "epoch 109; iter: 0; batch classifier loss: 0.101761; batch adversarial loss: 0.474003\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046088; batch adversarial loss: 0.433262\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058693; batch adversarial loss: 0.472994\n",
      "epoch 112; iter: 0; batch classifier loss: 0.076292; batch adversarial loss: 0.487818\n",
      "epoch 113; iter: 0; batch classifier loss: 0.080235; batch adversarial loss: 0.469962\n",
      "epoch 114; iter: 0; batch classifier loss: 0.085219; batch adversarial loss: 0.393764\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042199; batch adversarial loss: 0.399839\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054624; batch adversarial loss: 0.500110\n",
      "epoch 117; iter: 0; batch classifier loss: 0.068506; batch adversarial loss: 0.422018\n",
      "epoch 118; iter: 0; batch classifier loss: 0.078350; batch adversarial loss: 0.398704\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073318; batch adversarial loss: 0.409981\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041724; batch adversarial loss: 0.452193\n",
      "epoch 121; iter: 0; batch classifier loss: 0.078045; batch adversarial loss: 0.396369\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062326; batch adversarial loss: 0.500867\n",
      "epoch 123; iter: 0; batch classifier loss: 0.102487; batch adversarial loss: 0.411067\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050615; batch adversarial loss: 0.424972\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043835; batch adversarial loss: 0.375662\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055487; batch adversarial loss: 0.445613\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050481; batch adversarial loss: 0.385498\n",
      "epoch 128; iter: 0; batch classifier loss: 0.082277; batch adversarial loss: 0.378964\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048845; batch adversarial loss: 0.392190\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061976; batch adversarial loss: 0.394803\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051799; batch adversarial loss: 0.459331\n",
      "epoch 132; iter: 0; batch classifier loss: 0.061292; batch adversarial loss: 0.512970\n",
      "epoch 133; iter: 0; batch classifier loss: 0.068042; batch adversarial loss: 0.513098\n",
      "epoch 134; iter: 0; batch classifier loss: 0.059929; batch adversarial loss: 0.480028\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045065; batch adversarial loss: 0.430712\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057766; batch adversarial loss: 0.404717\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032094; batch adversarial loss: 0.427152\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056593; batch adversarial loss: 0.458001\n",
      "epoch 139; iter: 0; batch classifier loss: 0.077480; batch adversarial loss: 0.525061\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048865; batch adversarial loss: 0.531026\n",
      "epoch 141; iter: 0; batch classifier loss: 0.078776; batch adversarial loss: 0.415895\n",
      "epoch 142; iter: 0; batch classifier loss: 0.061646; batch adversarial loss: 0.388218\n",
      "epoch 143; iter: 0; batch classifier loss: 0.047291; batch adversarial loss: 0.463534\n",
      "epoch 144; iter: 0; batch classifier loss: 0.067038; batch adversarial loss: 0.411646\n",
      "epoch 145; iter: 0; batch classifier loss: 0.067592; batch adversarial loss: 0.468184\n",
      "epoch 146; iter: 0; batch classifier loss: 0.091096; batch adversarial loss: 0.383994\n",
      "epoch 147; iter: 0; batch classifier loss: 0.072881; batch adversarial loss: 0.448756\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027772; batch adversarial loss: 0.419385\n",
      "epoch 149; iter: 0; batch classifier loss: 0.067099; batch adversarial loss: 0.361658\n",
      "epoch 150; iter: 0; batch classifier loss: 0.053073; batch adversarial loss: 0.437549\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043203; batch adversarial loss: 0.412596\n",
      "epoch 152; iter: 0; batch classifier loss: 0.070552; batch adversarial loss: 0.491296\n",
      "epoch 153; iter: 0; batch classifier loss: 0.061146; batch adversarial loss: 0.412137\n",
      "epoch 154; iter: 0; batch classifier loss: 0.050056; batch adversarial loss: 0.526170\n",
      "epoch 155; iter: 0; batch classifier loss: 0.059112; batch adversarial loss: 0.397916\n",
      "epoch 156; iter: 0; batch classifier loss: 0.057926; batch adversarial loss: 0.395298\n",
      "epoch 157; iter: 0; batch classifier loss: 0.068435; batch adversarial loss: 0.502301\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044596; batch adversarial loss: 0.408295\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043878; batch adversarial loss: 0.459594\n",
      "epoch 160; iter: 0; batch classifier loss: 0.067103; batch adversarial loss: 0.508606\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040790; batch adversarial loss: 0.462868\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034230; batch adversarial loss: 0.497894\n",
      "epoch 163; iter: 0; batch classifier loss: 0.057709; batch adversarial loss: 0.400591\n",
      "epoch 164; iter: 0; batch classifier loss: 0.050424; batch adversarial loss: 0.392413\n",
      "epoch 165; iter: 0; batch classifier loss: 0.050638; batch adversarial loss: 0.435273\n",
      "epoch 166; iter: 0; batch classifier loss: 0.088480; batch adversarial loss: 0.386539\n",
      "epoch 167; iter: 0; batch classifier loss: 0.063224; batch adversarial loss: 0.355601\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034202; batch adversarial loss: 0.323862\n",
      "epoch 169; iter: 0; batch classifier loss: 0.047247; batch adversarial loss: 0.373596\n",
      "epoch 170; iter: 0; batch classifier loss: 0.046645; batch adversarial loss: 0.436431\n",
      "epoch 171; iter: 0; batch classifier loss: 0.070127; batch adversarial loss: 0.547656\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028608; batch adversarial loss: 0.412417\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018498; batch adversarial loss: 0.384028\n",
      "epoch 174; iter: 0; batch classifier loss: 0.050017; batch adversarial loss: 0.469055\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036402; batch adversarial loss: 0.320679\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045345; batch adversarial loss: 0.453133\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027459; batch adversarial loss: 0.537424\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036486; batch adversarial loss: 0.473500\n",
      "epoch 179; iter: 0; batch classifier loss: 0.050997; batch adversarial loss: 0.434199\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049094; batch adversarial loss: 0.434643\n",
      "epoch 181; iter: 0; batch classifier loss: 0.045060; batch adversarial loss: 0.426131\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031492; batch adversarial loss: 0.474320\n",
      "epoch 183; iter: 0; batch classifier loss: 0.071383; batch adversarial loss: 0.319474\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025469; batch adversarial loss: 0.459088\n",
      "epoch 185; iter: 0; batch classifier loss: 0.054821; batch adversarial loss: 0.410606\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028103; batch adversarial loss: 0.505196\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039463; batch adversarial loss: 0.381514\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033643; batch adversarial loss: 0.461046\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031517; batch adversarial loss: 0.441565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.054530; batch adversarial loss: 0.384167\n",
      "epoch 191; iter: 0; batch classifier loss: 0.039947; batch adversarial loss: 0.456895\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040454; batch adversarial loss: 0.314030\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030313; batch adversarial loss: 0.411024\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031252; batch adversarial loss: 0.436907\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028826; batch adversarial loss: 0.414307\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028606; batch adversarial loss: 0.473043\n",
      "epoch 197; iter: 0; batch classifier loss: 0.051091; batch adversarial loss: 0.477552\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026471; batch adversarial loss: 0.404991\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033360; batch adversarial loss: 0.425616\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692260; batch adversarial loss: 0.697533\n",
      "epoch 1; iter: 0; batch classifier loss: 0.451918; batch adversarial loss: 0.656797\n",
      "epoch 2; iter: 0; batch classifier loss: 0.454264; batch adversarial loss: 0.615852\n",
      "epoch 3; iter: 0; batch classifier loss: 0.335013; batch adversarial loss: 0.613111\n",
      "epoch 4; iter: 0; batch classifier loss: 0.384678; batch adversarial loss: 0.547616\n",
      "epoch 5; iter: 0; batch classifier loss: 0.340325; batch adversarial loss: 0.559176\n",
      "epoch 6; iter: 0; batch classifier loss: 0.294701; batch adversarial loss: 0.536860\n",
      "epoch 7; iter: 0; batch classifier loss: 0.287943; batch adversarial loss: 0.517838\n",
      "epoch 8; iter: 0; batch classifier loss: 0.261651; batch adversarial loss: 0.526980\n",
      "epoch 9; iter: 0; batch classifier loss: 0.216983; batch adversarial loss: 0.488571\n",
      "epoch 10; iter: 0; batch classifier loss: 0.234170; batch adversarial loss: 0.521115\n",
      "epoch 11; iter: 0; batch classifier loss: 0.191725; batch adversarial loss: 0.553540\n",
      "epoch 12; iter: 0; batch classifier loss: 0.218955; batch adversarial loss: 0.510775\n",
      "epoch 13; iter: 0; batch classifier loss: 0.193402; batch adversarial loss: 0.490279\n",
      "epoch 14; iter: 0; batch classifier loss: 0.141700; batch adversarial loss: 0.504057\n",
      "epoch 15; iter: 0; batch classifier loss: 0.186878; batch adversarial loss: 0.484884\n",
      "epoch 16; iter: 0; batch classifier loss: 0.154084; batch adversarial loss: 0.456731\n",
      "epoch 17; iter: 0; batch classifier loss: 0.170019; batch adversarial loss: 0.441413\n",
      "epoch 18; iter: 0; batch classifier loss: 0.182392; batch adversarial loss: 0.504471\n",
      "epoch 19; iter: 0; batch classifier loss: 0.207915; batch adversarial loss: 0.565267\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204722; batch adversarial loss: 0.433959\n",
      "epoch 21; iter: 0; batch classifier loss: 0.141498; batch adversarial loss: 0.517101\n",
      "epoch 22; iter: 0; batch classifier loss: 0.250737; batch adversarial loss: 0.523109\n",
      "epoch 23; iter: 0; batch classifier loss: 0.142755; batch adversarial loss: 0.485357\n",
      "epoch 24; iter: 0; batch classifier loss: 0.140182; batch adversarial loss: 0.509814\n",
      "epoch 25; iter: 0; batch classifier loss: 0.162824; batch adversarial loss: 0.490414\n",
      "epoch 26; iter: 0; batch classifier loss: 0.240608; batch adversarial loss: 0.568673\n",
      "epoch 27; iter: 0; batch classifier loss: 0.186717; batch adversarial loss: 0.471565\n",
      "epoch 28; iter: 0; batch classifier loss: 0.147615; batch adversarial loss: 0.493024\n",
      "epoch 29; iter: 0; batch classifier loss: 0.310707; batch adversarial loss: 0.506166\n",
      "epoch 30; iter: 0; batch classifier loss: 0.159857; batch adversarial loss: 0.449560\n",
      "epoch 31; iter: 0; batch classifier loss: 0.230679; batch adversarial loss: 0.551642\n",
      "epoch 32; iter: 0; batch classifier loss: 0.213616; batch adversarial loss: 0.525887\n",
      "epoch 33; iter: 0; batch classifier loss: 0.217117; batch adversarial loss: 0.411950\n",
      "epoch 34; iter: 0; batch classifier loss: 0.225033; batch adversarial loss: 0.482400\n",
      "epoch 35; iter: 0; batch classifier loss: 0.171392; batch adversarial loss: 0.467389\n",
      "epoch 36; iter: 0; batch classifier loss: 0.174228; batch adversarial loss: 0.484310\n",
      "epoch 37; iter: 0; batch classifier loss: 0.239373; batch adversarial loss: 0.370522\n",
      "epoch 38; iter: 0; batch classifier loss: 0.161416; batch adversarial loss: 0.520793\n",
      "epoch 39; iter: 0; batch classifier loss: 0.085507; batch adversarial loss: 0.410078\n",
      "epoch 40; iter: 0; batch classifier loss: 0.066756; batch adversarial loss: 0.456477\n",
      "epoch 41; iter: 0; batch classifier loss: 0.102676; batch adversarial loss: 0.496919\n",
      "epoch 42; iter: 0; batch classifier loss: 0.090788; batch adversarial loss: 0.494537\n",
      "epoch 43; iter: 0; batch classifier loss: 0.125846; batch adversarial loss: 0.492295\n",
      "epoch 44; iter: 0; batch classifier loss: 0.158880; batch adversarial loss: 0.458086\n",
      "epoch 45; iter: 0; batch classifier loss: 0.100829; batch adversarial loss: 0.436907\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116081; batch adversarial loss: 0.408955\n",
      "epoch 47; iter: 0; batch classifier loss: 0.107982; batch adversarial loss: 0.524199\n",
      "epoch 48; iter: 0; batch classifier loss: 0.074864; batch adversarial loss: 0.469003\n",
      "epoch 49; iter: 0; batch classifier loss: 0.064613; batch adversarial loss: 0.482971\n",
      "epoch 50; iter: 0; batch classifier loss: 0.102553; batch adversarial loss: 0.454667\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106162; batch adversarial loss: 0.485193\n",
      "epoch 52; iter: 0; batch classifier loss: 0.072764; batch adversarial loss: 0.447532\n",
      "epoch 53; iter: 0; batch classifier loss: 0.064136; batch adversarial loss: 0.465467\n",
      "epoch 54; iter: 0; batch classifier loss: 0.068915; batch adversarial loss: 0.532232\n",
      "epoch 55; iter: 0; batch classifier loss: 0.074496; batch adversarial loss: 0.525091\n",
      "epoch 56; iter: 0; batch classifier loss: 0.056802; batch adversarial loss: 0.481617\n",
      "epoch 57; iter: 0; batch classifier loss: 0.087196; batch adversarial loss: 0.323402\n",
      "epoch 58; iter: 0; batch classifier loss: 0.096784; batch adversarial loss: 0.421481\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099409; batch adversarial loss: 0.440072\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076188; batch adversarial loss: 0.448221\n",
      "epoch 61; iter: 0; batch classifier loss: 0.062874; batch adversarial loss: 0.544090\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093658; batch adversarial loss: 0.433722\n",
      "epoch 63; iter: 0; batch classifier loss: 0.137636; batch adversarial loss: 0.434258\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070288; batch adversarial loss: 0.448284\n",
      "epoch 65; iter: 0; batch classifier loss: 0.096123; batch adversarial loss: 0.502601\n",
      "epoch 66; iter: 0; batch classifier loss: 0.067208; batch adversarial loss: 0.479705\n",
      "epoch 67; iter: 0; batch classifier loss: 0.060008; batch adversarial loss: 0.433576\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094222; batch adversarial loss: 0.424981\n",
      "epoch 69; iter: 0; batch classifier loss: 0.054638; batch adversarial loss: 0.469204\n",
      "epoch 70; iter: 0; batch classifier loss: 0.063376; batch adversarial loss: 0.422259\n",
      "epoch 71; iter: 0; batch classifier loss: 0.055779; batch adversarial loss: 0.427192\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082415; batch adversarial loss: 0.445525\n",
      "epoch 73; iter: 0; batch classifier loss: 0.063925; batch adversarial loss: 0.521038\n",
      "epoch 74; iter: 0; batch classifier loss: 0.109609; batch adversarial loss: 0.416991\n",
      "epoch 75; iter: 0; batch classifier loss: 0.107409; batch adversarial loss: 0.450908\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066330; batch adversarial loss: 0.498387\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062595; batch adversarial loss: 0.484826\n",
      "epoch 78; iter: 0; batch classifier loss: 0.051334; batch adversarial loss: 0.413796\n",
      "epoch 79; iter: 0; batch classifier loss: 0.098300; batch adversarial loss: 0.446429\n",
      "epoch 80; iter: 0; batch classifier loss: 0.098275; batch adversarial loss: 0.451564\n",
      "epoch 81; iter: 0; batch classifier loss: 0.056647; batch adversarial loss: 0.473477\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075746; batch adversarial loss: 0.507627\n",
      "epoch 83; iter: 0; batch classifier loss: 0.100798; batch adversarial loss: 0.448723\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070042; batch adversarial loss: 0.422305\n",
      "epoch 85; iter: 0; batch classifier loss: 0.115017; batch adversarial loss: 0.424341\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081384; batch adversarial loss: 0.461795\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076290; batch adversarial loss: 0.422037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.087381; batch adversarial loss: 0.459564\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078124; batch adversarial loss: 0.429616\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042771; batch adversarial loss: 0.432063\n",
      "epoch 91; iter: 0; batch classifier loss: 0.065365; batch adversarial loss: 0.523800\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082423; batch adversarial loss: 0.394654\n",
      "epoch 93; iter: 0; batch classifier loss: 0.087406; batch adversarial loss: 0.507412\n",
      "epoch 94; iter: 0; batch classifier loss: 0.030967; batch adversarial loss: 0.475542\n",
      "epoch 95; iter: 0; batch classifier loss: 0.062210; batch adversarial loss: 0.516571\n",
      "epoch 96; iter: 0; batch classifier loss: 0.079869; batch adversarial loss: 0.495775\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060150; batch adversarial loss: 0.430800\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035270; batch adversarial loss: 0.445935\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056477; batch adversarial loss: 0.473128\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044325; batch adversarial loss: 0.449393\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053420; batch adversarial loss: 0.454437\n",
      "epoch 102; iter: 0; batch classifier loss: 0.095781; batch adversarial loss: 0.499991\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044129; batch adversarial loss: 0.425867\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059353; batch adversarial loss: 0.496869\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055616; batch adversarial loss: 0.364216\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051190; batch adversarial loss: 0.454089\n",
      "epoch 107; iter: 0; batch classifier loss: 0.077851; batch adversarial loss: 0.588679\n",
      "epoch 108; iter: 0; batch classifier loss: 0.122574; batch adversarial loss: 0.539068\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062549; batch adversarial loss: 0.350991\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057521; batch adversarial loss: 0.358633\n",
      "epoch 111; iter: 0; batch classifier loss: 0.074665; batch adversarial loss: 0.488114\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030989; batch adversarial loss: 0.442709\n",
      "epoch 113; iter: 0; batch classifier loss: 0.077697; batch adversarial loss: 0.439774\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037032; batch adversarial loss: 0.388615\n",
      "epoch 115; iter: 0; batch classifier loss: 0.066884; batch adversarial loss: 0.449146\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046573; batch adversarial loss: 0.356926\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038239; batch adversarial loss: 0.466995\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026602; batch adversarial loss: 0.457564\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055888; batch adversarial loss: 0.455482\n",
      "epoch 120; iter: 0; batch classifier loss: 0.029458; batch adversarial loss: 0.496538\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033484; batch adversarial loss: 0.489956\n",
      "epoch 122; iter: 0; batch classifier loss: 0.080777; batch adversarial loss: 0.370353\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032299; batch adversarial loss: 0.459946\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036814; batch adversarial loss: 0.432460\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031175; batch adversarial loss: 0.427223\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031206; batch adversarial loss: 0.533528\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032848; batch adversarial loss: 0.521869\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041211; batch adversarial loss: 0.497358\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040880; batch adversarial loss: 0.411476\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056479; batch adversarial loss: 0.420352\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038505; batch adversarial loss: 0.394790\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021805; batch adversarial loss: 0.439364\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042449; batch adversarial loss: 0.423705\n",
      "epoch 134; iter: 0; batch classifier loss: 0.076084; batch adversarial loss: 0.526267\n",
      "epoch 135; iter: 0; batch classifier loss: 0.063500; batch adversarial loss: 0.456053\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030013; batch adversarial loss: 0.441334\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034206; batch adversarial loss: 0.401616\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035838; batch adversarial loss: 0.448603\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043974; batch adversarial loss: 0.498800\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046098; batch adversarial loss: 0.436745\n",
      "epoch 141; iter: 0; batch classifier loss: 0.065652; batch adversarial loss: 0.437602\n",
      "epoch 142; iter: 0; batch classifier loss: 0.038361; batch adversarial loss: 0.477883\n",
      "epoch 143; iter: 0; batch classifier loss: 0.049672; batch adversarial loss: 0.432683\n",
      "epoch 144; iter: 0; batch classifier loss: 0.075066; batch adversarial loss: 0.536028\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041442; batch adversarial loss: 0.465802\n",
      "epoch 146; iter: 0; batch classifier loss: 0.103657; batch adversarial loss: 0.511250\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039701; batch adversarial loss: 0.420861\n",
      "epoch 148; iter: 0; batch classifier loss: 0.061219; batch adversarial loss: 0.496789\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018634; batch adversarial loss: 0.421595\n",
      "epoch 150; iter: 0; batch classifier loss: 0.078206; batch adversarial loss: 0.486054\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035109; batch adversarial loss: 0.359856\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043096; batch adversarial loss: 0.454047\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038907; batch adversarial loss: 0.454761\n",
      "epoch 154; iter: 0; batch classifier loss: 0.048054; batch adversarial loss: 0.437202\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031049; batch adversarial loss: 0.475466\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025041; batch adversarial loss: 0.530734\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013807; batch adversarial loss: 0.363849\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034726; batch adversarial loss: 0.443720\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026103; batch adversarial loss: 0.523869\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021859; batch adversarial loss: 0.489254\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018133; batch adversarial loss: 0.491197\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025224; batch adversarial loss: 0.478676\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037608; batch adversarial loss: 0.472463\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013858; batch adversarial loss: 0.464173\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038104; batch adversarial loss: 0.515387\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035555; batch adversarial loss: 0.461709\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011581; batch adversarial loss: 0.476884\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023323; batch adversarial loss: 0.396616\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018041; batch adversarial loss: 0.429401\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037481; batch adversarial loss: 0.379962\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013330; batch adversarial loss: 0.473010\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032748; batch adversarial loss: 0.521080\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012024; batch adversarial loss: 0.408661\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011068; batch adversarial loss: 0.521482\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016060; batch adversarial loss: 0.441175\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009241; batch adversarial loss: 0.472376\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020191; batch adversarial loss: 0.421059\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014668; batch adversarial loss: 0.515887\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026411; batch adversarial loss: 0.495270\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018725; batch adversarial loss: 0.503068\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021993; batch adversarial loss: 0.498526\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034593; batch adversarial loss: 0.489819\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036896; batch adversarial loss: 0.450612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.009905; batch adversarial loss: 0.444263\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025052; batch adversarial loss: 0.484092\n",
      "epoch 186; iter: 0; batch classifier loss: 0.051509; batch adversarial loss: 0.522597\n",
      "epoch 187; iter: 0; batch classifier loss: 0.048223; batch adversarial loss: 0.524673\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029973; batch adversarial loss: 0.456793\n",
      "epoch 189; iter: 0; batch classifier loss: 0.047414; batch adversarial loss: 0.422291\n",
      "epoch 190; iter: 0; batch classifier loss: 0.043758; batch adversarial loss: 0.472510\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013441; batch adversarial loss: 0.433701\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026541; batch adversarial loss: 0.414273\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015989; batch adversarial loss: 0.382909\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018527; batch adversarial loss: 0.470634\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036011; batch adversarial loss: 0.485874\n",
      "epoch 196; iter: 0; batch classifier loss: 0.034663; batch adversarial loss: 0.446842\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033112; batch adversarial loss: 0.411781\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030078; batch adversarial loss: 0.475695\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011390; batch adversarial loss: 0.475319\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698259; batch adversarial loss: 0.856489\n",
      "epoch 1; iter: 0; batch classifier loss: 0.653843; batch adversarial loss: 0.878568\n",
      "epoch 2; iter: 0; batch classifier loss: 0.803692; batch adversarial loss: 0.850256\n",
      "epoch 3; iter: 0; batch classifier loss: 0.872052; batch adversarial loss: 0.788289\n",
      "epoch 4; iter: 0; batch classifier loss: 0.783890; batch adversarial loss: 0.735541\n",
      "epoch 5; iter: 0; batch classifier loss: 0.684817; batch adversarial loss: 0.673397\n",
      "epoch 6; iter: 0; batch classifier loss: 0.522114; batch adversarial loss: 0.640466\n",
      "epoch 7; iter: 0; batch classifier loss: 0.323089; batch adversarial loss: 0.573527\n",
      "epoch 8; iter: 0; batch classifier loss: 0.336086; batch adversarial loss: 0.548900\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363156; batch adversarial loss: 0.578311\n",
      "epoch 10; iter: 0; batch classifier loss: 0.392366; batch adversarial loss: 0.484159\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273441; batch adversarial loss: 0.536069\n",
      "epoch 12; iter: 0; batch classifier loss: 0.347719; batch adversarial loss: 0.499014\n",
      "epoch 13; iter: 0; batch classifier loss: 0.277931; batch adversarial loss: 0.473503\n",
      "epoch 14; iter: 0; batch classifier loss: 0.270107; batch adversarial loss: 0.510231\n",
      "epoch 15; iter: 0; batch classifier loss: 0.285499; batch adversarial loss: 0.536949\n",
      "epoch 16; iter: 0; batch classifier loss: 0.292261; batch adversarial loss: 0.491210\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221031; batch adversarial loss: 0.556304\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251197; batch adversarial loss: 0.539152\n",
      "epoch 19; iter: 0; batch classifier loss: 0.249926; batch adversarial loss: 0.486692\n",
      "epoch 20; iter: 0; batch classifier loss: 0.205199; batch adversarial loss: 0.465835\n",
      "epoch 21; iter: 0; batch classifier loss: 0.207805; batch adversarial loss: 0.480485\n",
      "epoch 22; iter: 0; batch classifier loss: 0.187431; batch adversarial loss: 0.506257\n",
      "epoch 23; iter: 0; batch classifier loss: 0.135837; batch adversarial loss: 0.500859\n",
      "epoch 24; iter: 0; batch classifier loss: 0.232383; batch adversarial loss: 0.490881\n",
      "epoch 25; iter: 0; batch classifier loss: 0.252679; batch adversarial loss: 0.420842\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194606; batch adversarial loss: 0.433300\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181652; batch adversarial loss: 0.477825\n",
      "epoch 28; iter: 0; batch classifier loss: 0.149194; batch adversarial loss: 0.477691\n",
      "epoch 29; iter: 0; batch classifier loss: 0.151801; batch adversarial loss: 0.521996\n",
      "epoch 30; iter: 0; batch classifier loss: 0.114832; batch adversarial loss: 0.411275\n",
      "epoch 31; iter: 0; batch classifier loss: 0.123882; batch adversarial loss: 0.531531\n",
      "epoch 32; iter: 0; batch classifier loss: 0.079830; batch adversarial loss: 0.562905\n",
      "epoch 33; iter: 0; batch classifier loss: 0.120865; batch adversarial loss: 0.471271\n",
      "epoch 34; iter: 0; batch classifier loss: 0.161121; batch adversarial loss: 0.454243\n",
      "epoch 35; iter: 0; batch classifier loss: 0.143156; batch adversarial loss: 0.454108\n",
      "epoch 36; iter: 0; batch classifier loss: 0.110067; batch adversarial loss: 0.488432\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132479; batch adversarial loss: 0.465373\n",
      "epoch 38; iter: 0; batch classifier loss: 0.141066; batch adversarial loss: 0.512453\n",
      "epoch 39; iter: 0; batch classifier loss: 0.067152; batch adversarial loss: 0.450542\n",
      "epoch 40; iter: 0; batch classifier loss: 0.097483; batch adversarial loss: 0.426133\n",
      "epoch 41; iter: 0; batch classifier loss: 0.153623; batch adversarial loss: 0.484561\n",
      "epoch 42; iter: 0; batch classifier loss: 0.148960; batch adversarial loss: 0.432005\n",
      "epoch 43; iter: 0; batch classifier loss: 0.154362; batch adversarial loss: 0.445307\n",
      "epoch 44; iter: 0; batch classifier loss: 0.148498; batch adversarial loss: 0.462873\n",
      "epoch 45; iter: 0; batch classifier loss: 0.111069; batch adversarial loss: 0.427436\n",
      "epoch 46; iter: 0; batch classifier loss: 0.065864; batch adversarial loss: 0.422615\n",
      "epoch 47; iter: 0; batch classifier loss: 0.105926; batch adversarial loss: 0.549447\n",
      "epoch 48; iter: 0; batch classifier loss: 0.090189; batch adversarial loss: 0.475628\n",
      "epoch 49; iter: 0; batch classifier loss: 0.120837; batch adversarial loss: 0.375066\n",
      "epoch 50; iter: 0; batch classifier loss: 0.125730; batch adversarial loss: 0.406764\n",
      "epoch 51; iter: 0; batch classifier loss: 0.115041; batch adversarial loss: 0.483862\n",
      "epoch 52; iter: 0; batch classifier loss: 0.124700; batch adversarial loss: 0.363692\n",
      "epoch 53; iter: 0; batch classifier loss: 0.114506; batch adversarial loss: 0.381047\n",
      "epoch 54; iter: 0; batch classifier loss: 0.059685; batch adversarial loss: 0.549376\n",
      "epoch 55; iter: 0; batch classifier loss: 0.112068; batch adversarial loss: 0.515652\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084264; batch adversarial loss: 0.570218\n",
      "epoch 57; iter: 0; batch classifier loss: 0.067758; batch adversarial loss: 0.472091\n",
      "epoch 58; iter: 0; batch classifier loss: 0.061774; batch adversarial loss: 0.412664\n",
      "epoch 59; iter: 0; batch classifier loss: 0.048662; batch adversarial loss: 0.465297\n",
      "epoch 60; iter: 0; batch classifier loss: 0.092304; batch adversarial loss: 0.450467\n",
      "epoch 61; iter: 0; batch classifier loss: 0.089288; batch adversarial loss: 0.419633\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081258; batch adversarial loss: 0.620308\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116142; batch adversarial loss: 0.418014\n",
      "epoch 64; iter: 0; batch classifier loss: 0.116366; batch adversarial loss: 0.452966\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087584; batch adversarial loss: 0.544977\n",
      "epoch 66; iter: 0; batch classifier loss: 0.098902; batch adversarial loss: 0.431341\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101701; batch adversarial loss: 0.410927\n",
      "epoch 68; iter: 0; batch classifier loss: 0.053710; batch adversarial loss: 0.372385\n",
      "epoch 69; iter: 0; batch classifier loss: 0.157810; batch adversarial loss: 0.417012\n",
      "epoch 70; iter: 0; batch classifier loss: 0.055202; batch adversarial loss: 0.433141\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058656; batch adversarial loss: 0.411175\n",
      "epoch 72; iter: 0; batch classifier loss: 0.120053; batch adversarial loss: 0.465938\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087166; batch adversarial loss: 0.527419\n",
      "epoch 74; iter: 0; batch classifier loss: 0.095385; batch adversarial loss: 0.511362\n",
      "epoch 75; iter: 0; batch classifier loss: 0.116130; batch adversarial loss: 0.396747\n",
      "epoch 76; iter: 0; batch classifier loss: 0.057930; batch adversarial loss: 0.380588\n",
      "epoch 77; iter: 0; batch classifier loss: 0.114569; batch adversarial loss: 0.370955\n",
      "epoch 78; iter: 0; batch classifier loss: 0.053112; batch adversarial loss: 0.498047\n",
      "epoch 79; iter: 0; batch classifier loss: 0.069063; batch adversarial loss: 0.425912\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083714; batch adversarial loss: 0.471360\n",
      "epoch 81; iter: 0; batch classifier loss: 0.058193; batch adversarial loss: 0.420495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.082828; batch adversarial loss: 0.411657\n",
      "epoch 83; iter: 0; batch classifier loss: 0.046307; batch adversarial loss: 0.388329\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060754; batch adversarial loss: 0.436986\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058464; batch adversarial loss: 0.529678\n",
      "epoch 86; iter: 0; batch classifier loss: 0.115113; batch adversarial loss: 0.464114\n",
      "epoch 87; iter: 0; batch classifier loss: 0.086615; batch adversarial loss: 0.434690\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049807; batch adversarial loss: 0.362382\n",
      "epoch 89; iter: 0; batch classifier loss: 0.039184; batch adversarial loss: 0.542583\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045985; batch adversarial loss: 0.471188\n",
      "epoch 91; iter: 0; batch classifier loss: 0.040015; batch adversarial loss: 0.511277\n",
      "epoch 92; iter: 0; batch classifier loss: 0.046542; batch adversarial loss: 0.516812\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052221; batch adversarial loss: 0.355102\n",
      "epoch 94; iter: 0; batch classifier loss: 0.032558; batch adversarial loss: 0.409570\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071842; batch adversarial loss: 0.569730\n",
      "epoch 96; iter: 0; batch classifier loss: 0.028831; batch adversarial loss: 0.447295\n",
      "epoch 97; iter: 0; batch classifier loss: 0.038629; batch adversarial loss: 0.414369\n",
      "epoch 98; iter: 0; batch classifier loss: 0.099139; batch adversarial loss: 0.505040\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071705; batch adversarial loss: 0.422142\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065626; batch adversarial loss: 0.481373\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054989; batch adversarial loss: 0.485018\n",
      "epoch 102; iter: 0; batch classifier loss: 0.073272; batch adversarial loss: 0.414566\n",
      "epoch 103; iter: 0; batch classifier loss: 0.030718; batch adversarial loss: 0.516685\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060227; batch adversarial loss: 0.530479\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052919; batch adversarial loss: 0.482822\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063796; batch adversarial loss: 0.486495\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047442; batch adversarial loss: 0.545303\n",
      "epoch 108; iter: 0; batch classifier loss: 0.025471; batch adversarial loss: 0.452667\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071784; batch adversarial loss: 0.544255\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049025; batch adversarial loss: 0.456124\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053971; batch adversarial loss: 0.448505\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035910; batch adversarial loss: 0.467783\n",
      "epoch 113; iter: 0; batch classifier loss: 0.062875; batch adversarial loss: 0.448322\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039866; batch adversarial loss: 0.454358\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034166; batch adversarial loss: 0.451124\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057462; batch adversarial loss: 0.512611\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043835; batch adversarial loss: 0.471861\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051077; batch adversarial loss: 0.476504\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070149; batch adversarial loss: 0.361354\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044910; batch adversarial loss: 0.467838\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026967; batch adversarial loss: 0.565136\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036296; batch adversarial loss: 0.378754\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026895; batch adversarial loss: 0.377167\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057291; batch adversarial loss: 0.409556\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023446; batch adversarial loss: 0.575055\n",
      "epoch 126; iter: 0; batch classifier loss: 0.018392; batch adversarial loss: 0.494783\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042451; batch adversarial loss: 0.507487\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029263; batch adversarial loss: 0.464239\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029894; batch adversarial loss: 0.344620\n",
      "epoch 130; iter: 0; batch classifier loss: 0.058669; batch adversarial loss: 0.413332\n",
      "epoch 131; iter: 0; batch classifier loss: 0.063677; batch adversarial loss: 0.482936\n",
      "epoch 132; iter: 0; batch classifier loss: 0.062560; batch adversarial loss: 0.378282\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046090; batch adversarial loss: 0.448033\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050708; batch adversarial loss: 0.438019\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036838; batch adversarial loss: 0.446932\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024873; batch adversarial loss: 0.375145\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043337; batch adversarial loss: 0.483638\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017774; batch adversarial loss: 0.376819\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022708; batch adversarial loss: 0.414327\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045215; batch adversarial loss: 0.465687\n",
      "epoch 141; iter: 0; batch classifier loss: 0.058545; batch adversarial loss: 0.498337\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013217; batch adversarial loss: 0.441543\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010589; batch adversarial loss: 0.387844\n",
      "epoch 144; iter: 0; batch classifier loss: 0.042793; batch adversarial loss: 0.414215\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027559; batch adversarial loss: 0.527757\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017455; batch adversarial loss: 0.533139\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042884; batch adversarial loss: 0.472217\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040203; batch adversarial loss: 0.494918\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014460; batch adversarial loss: 0.522102\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038440; batch adversarial loss: 0.501166\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010603; batch adversarial loss: 0.430143\n",
      "epoch 152; iter: 0; batch classifier loss: 0.090893; batch adversarial loss: 0.475938\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024910; batch adversarial loss: 0.415545\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038454; batch adversarial loss: 0.401865\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026252; batch adversarial loss: 0.457547\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045389; batch adversarial loss: 0.451195\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024966; batch adversarial loss: 0.586882\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032433; batch adversarial loss: 0.403877\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036256; batch adversarial loss: 0.438430\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018733; batch adversarial loss: 0.426249\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013772; batch adversarial loss: 0.385777\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009083; batch adversarial loss: 0.460841\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045049; batch adversarial loss: 0.376244\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023105; batch adversarial loss: 0.454728\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024606; batch adversarial loss: 0.468849\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031797; batch adversarial loss: 0.522116\n",
      "epoch 167; iter: 0; batch classifier loss: 0.045624; batch adversarial loss: 0.509334\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005026; batch adversarial loss: 0.431313\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021120; batch adversarial loss: 0.487227\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023657; batch adversarial loss: 0.433442\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036688; batch adversarial loss: 0.424017\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025609; batch adversarial loss: 0.443973\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018584; batch adversarial loss: 0.439520\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012695; batch adversarial loss: 0.410551\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011827; batch adversarial loss: 0.486775\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027453; batch adversarial loss: 0.459563\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024890; batch adversarial loss: 0.449212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.017892; batch adversarial loss: 0.465419\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010847; batch adversarial loss: 0.480712\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011642; batch adversarial loss: 0.539528\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018670; batch adversarial loss: 0.533807\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025035; batch adversarial loss: 0.456729\n",
      "epoch 183; iter: 0; batch classifier loss: 0.037910; batch adversarial loss: 0.411078\n",
      "epoch 184; iter: 0; batch classifier loss: 0.048203; batch adversarial loss: 0.323302\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026667; batch adversarial loss: 0.429487\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009538; batch adversarial loss: 0.448197\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030175; batch adversarial loss: 0.532072\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027825; batch adversarial loss: 0.418088\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028830; batch adversarial loss: 0.358797\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011420; batch adversarial loss: 0.549683\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015901; batch adversarial loss: 0.427188\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020681; batch adversarial loss: 0.495804\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015047; batch adversarial loss: 0.454851\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030047; batch adversarial loss: 0.422754\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014048; batch adversarial loss: 0.494191\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023125; batch adversarial loss: 0.453904\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019370; batch adversarial loss: 0.501803\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007563; batch adversarial loss: 0.469753\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013745; batch adversarial loss: 0.325218\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680936; batch adversarial loss: 0.618392\n",
      "epoch 1; iter: 0; batch classifier loss: 0.473058; batch adversarial loss: 0.620232\n",
      "epoch 2; iter: 0; batch classifier loss: 0.558797; batch adversarial loss: 0.588818\n",
      "epoch 3; iter: 0; batch classifier loss: 0.462749; batch adversarial loss: 0.628541\n",
      "epoch 4; iter: 0; batch classifier loss: 0.481204; batch adversarial loss: 0.620815\n",
      "epoch 5; iter: 0; batch classifier loss: 0.431107; batch adversarial loss: 0.574799\n",
      "epoch 6; iter: 0; batch classifier loss: 0.497226; batch adversarial loss: 0.590820\n",
      "epoch 7; iter: 0; batch classifier loss: 0.427946; batch adversarial loss: 0.542727\n",
      "epoch 8; iter: 0; batch classifier loss: 0.426368; batch adversarial loss: 0.569130\n",
      "epoch 9; iter: 0; batch classifier loss: 0.370604; batch adversarial loss: 0.501322\n",
      "epoch 10; iter: 0; batch classifier loss: 0.415933; batch adversarial loss: 0.480147\n",
      "epoch 11; iter: 0; batch classifier loss: 0.277891; batch adversarial loss: 0.529406\n",
      "epoch 12; iter: 0; batch classifier loss: 0.430984; batch adversarial loss: 0.534105\n",
      "epoch 13; iter: 0; batch classifier loss: 0.338785; batch adversarial loss: 0.468871\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389783; batch adversarial loss: 0.495389\n",
      "epoch 15; iter: 0; batch classifier loss: 0.377630; batch adversarial loss: 0.555795\n",
      "epoch 16; iter: 0; batch classifier loss: 0.302397; batch adversarial loss: 0.595891\n",
      "epoch 17; iter: 0; batch classifier loss: 0.307117; batch adversarial loss: 0.481548\n",
      "epoch 18; iter: 0; batch classifier loss: 0.211955; batch adversarial loss: 0.517550\n",
      "epoch 19; iter: 0; batch classifier loss: 0.274552; batch adversarial loss: 0.404149\n",
      "epoch 20; iter: 0; batch classifier loss: 0.267787; batch adversarial loss: 0.522101\n",
      "epoch 21; iter: 0; batch classifier loss: 0.274692; batch adversarial loss: 0.481775\n",
      "epoch 22; iter: 0; batch classifier loss: 0.219012; batch adversarial loss: 0.420216\n",
      "epoch 23; iter: 0; batch classifier loss: 0.212315; batch adversarial loss: 0.582217\n",
      "epoch 24; iter: 0; batch classifier loss: 0.217940; batch adversarial loss: 0.436410\n",
      "epoch 25; iter: 0; batch classifier loss: 0.227385; batch adversarial loss: 0.356766\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187213; batch adversarial loss: 0.458679\n",
      "epoch 27; iter: 0; batch classifier loss: 0.261691; batch adversarial loss: 0.524263\n",
      "epoch 28; iter: 0; batch classifier loss: 0.250170; batch adversarial loss: 0.493006\n",
      "epoch 29; iter: 0; batch classifier loss: 0.243536; batch adversarial loss: 0.556164\n",
      "epoch 30; iter: 0; batch classifier loss: 0.238935; batch adversarial loss: 0.462565\n",
      "epoch 31; iter: 0; batch classifier loss: 0.207242; batch adversarial loss: 0.515920\n",
      "epoch 32; iter: 0; batch classifier loss: 0.251031; batch adversarial loss: 0.466891\n",
      "epoch 33; iter: 0; batch classifier loss: 0.213619; batch adversarial loss: 0.440273\n",
      "epoch 34; iter: 0; batch classifier loss: 0.250123; batch adversarial loss: 0.504787\n",
      "epoch 35; iter: 0; batch classifier loss: 0.184603; batch adversarial loss: 0.527605\n",
      "epoch 36; iter: 0; batch classifier loss: 0.235484; batch adversarial loss: 0.458241\n",
      "epoch 37; iter: 0; batch classifier loss: 0.255112; batch adversarial loss: 0.390336\n",
      "epoch 38; iter: 0; batch classifier loss: 0.198936; batch adversarial loss: 0.501644\n",
      "epoch 39; iter: 0; batch classifier loss: 0.267557; batch adversarial loss: 0.431179\n",
      "epoch 40; iter: 0; batch classifier loss: 0.319266; batch adversarial loss: 0.475659\n",
      "epoch 41; iter: 0; batch classifier loss: 0.267781; batch adversarial loss: 0.448799\n",
      "epoch 42; iter: 0; batch classifier loss: 0.215705; batch adversarial loss: 0.527751\n",
      "epoch 43; iter: 0; batch classifier loss: 0.228857; batch adversarial loss: 0.446245\n",
      "epoch 44; iter: 0; batch classifier loss: 0.260483; batch adversarial loss: 0.519803\n",
      "epoch 45; iter: 0; batch classifier loss: 0.232688; batch adversarial loss: 0.494140\n",
      "epoch 46; iter: 0; batch classifier loss: 0.253152; batch adversarial loss: 0.460157\n",
      "epoch 47; iter: 0; batch classifier loss: 0.221657; batch adversarial loss: 0.458932\n",
      "epoch 48; iter: 0; batch classifier loss: 0.124409; batch adversarial loss: 0.389919\n",
      "epoch 49; iter: 0; batch classifier loss: 0.169579; batch adversarial loss: 0.435738\n",
      "epoch 50; iter: 0; batch classifier loss: 0.142275; batch adversarial loss: 0.435614\n",
      "epoch 51; iter: 0; batch classifier loss: 0.113803; batch adversarial loss: 0.540715\n",
      "epoch 52; iter: 0; batch classifier loss: 0.214179; batch adversarial loss: 0.469007\n",
      "epoch 53; iter: 0; batch classifier loss: 0.152243; batch adversarial loss: 0.471061\n",
      "epoch 54; iter: 0; batch classifier loss: 0.200981; batch adversarial loss: 0.528599\n",
      "epoch 55; iter: 0; batch classifier loss: 0.347268; batch adversarial loss: 0.434136\n",
      "epoch 56; iter: 0; batch classifier loss: 0.159062; batch adversarial loss: 0.614640\n",
      "epoch 57; iter: 0; batch classifier loss: 0.203921; batch adversarial loss: 0.494591\n",
      "epoch 58; iter: 0; batch classifier loss: 0.202567; batch adversarial loss: 0.424040\n",
      "epoch 59; iter: 0; batch classifier loss: 0.204488; batch adversarial loss: 0.459206\n",
      "epoch 60; iter: 0; batch classifier loss: 0.185461; batch adversarial loss: 0.458037\n",
      "epoch 61; iter: 0; batch classifier loss: 0.119702; batch adversarial loss: 0.446396\n",
      "epoch 62; iter: 0; batch classifier loss: 0.161319; batch adversarial loss: 0.447203\n",
      "epoch 63; iter: 0; batch classifier loss: 0.131963; batch adversarial loss: 0.408999\n",
      "epoch 64; iter: 0; batch classifier loss: 0.206369; batch adversarial loss: 0.496010\n",
      "epoch 65; iter: 0; batch classifier loss: 0.133276; batch adversarial loss: 0.409382\n",
      "epoch 66; iter: 0; batch classifier loss: 0.165166; batch adversarial loss: 0.459489\n",
      "epoch 67; iter: 0; batch classifier loss: 0.235485; batch adversarial loss: 0.385981\n",
      "epoch 68; iter: 0; batch classifier loss: 0.232160; batch adversarial loss: 0.434988\n",
      "epoch 69; iter: 0; batch classifier loss: 0.171157; batch adversarial loss: 0.434953\n",
      "epoch 70; iter: 0; batch classifier loss: 0.155152; batch adversarial loss: 0.433830\n",
      "epoch 71; iter: 0; batch classifier loss: 0.159527; batch adversarial loss: 0.483619\n",
      "epoch 72; iter: 0; batch classifier loss: 0.119082; batch adversarial loss: 0.569677\n",
      "epoch 73; iter: 0; batch classifier loss: 0.146618; batch adversarial loss: 0.336607\n",
      "epoch 74; iter: 0; batch classifier loss: 0.244557; batch adversarial loss: 0.398484\n",
      "epoch 75; iter: 0; batch classifier loss: 0.112346; batch adversarial loss: 0.445498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.149157; batch adversarial loss: 0.492845\n",
      "epoch 77; iter: 0; batch classifier loss: 0.274148; batch adversarial loss: 0.472538\n",
      "epoch 78; iter: 0; batch classifier loss: 0.193697; batch adversarial loss: 0.483051\n",
      "epoch 79; iter: 0; batch classifier loss: 0.193322; batch adversarial loss: 0.482763\n",
      "epoch 80; iter: 0; batch classifier loss: 0.178115; batch adversarial loss: 0.434922\n",
      "epoch 81; iter: 0; batch classifier loss: 0.109972; batch adversarial loss: 0.482953\n",
      "epoch 82; iter: 0; batch classifier loss: 0.042695; batch adversarial loss: 0.626947\n",
      "epoch 83; iter: 0; batch classifier loss: 0.034738; batch adversarial loss: 0.498551\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052642; batch adversarial loss: 0.481947\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060391; batch adversarial loss: 0.507971\n",
      "epoch 86; iter: 0; batch classifier loss: 0.047208; batch adversarial loss: 0.493292\n",
      "epoch 87; iter: 0; batch classifier loss: 0.044533; batch adversarial loss: 0.379105\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050214; batch adversarial loss: 0.439463\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047948; batch adversarial loss: 0.458012\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068734; batch adversarial loss: 0.411986\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074213; batch adversarial loss: 0.434209\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069203; batch adversarial loss: 0.501102\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061586; batch adversarial loss: 0.511775\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072732; batch adversarial loss: 0.462302\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060519; batch adversarial loss: 0.412738\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061915; batch adversarial loss: 0.466580\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042919; batch adversarial loss: 0.404735\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046356; batch adversarial loss: 0.479506\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051075; batch adversarial loss: 0.367004\n",
      "epoch 100; iter: 0; batch classifier loss: 0.077561; batch adversarial loss: 0.427161\n",
      "epoch 101; iter: 0; batch classifier loss: 0.069947; batch adversarial loss: 0.536161\n",
      "epoch 102; iter: 0; batch classifier loss: 0.089353; batch adversarial loss: 0.429211\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053678; batch adversarial loss: 0.430134\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073938; batch adversarial loss: 0.410461\n",
      "epoch 105; iter: 0; batch classifier loss: 0.071774; batch adversarial loss: 0.467188\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064153; batch adversarial loss: 0.505610\n",
      "epoch 107; iter: 0; batch classifier loss: 0.081518; batch adversarial loss: 0.565710\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057167; batch adversarial loss: 0.421279\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045033; batch adversarial loss: 0.430009\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036241; batch adversarial loss: 0.434368\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046433; batch adversarial loss: 0.417422\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055770; batch adversarial loss: 0.389251\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054596; batch adversarial loss: 0.546766\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050983; batch adversarial loss: 0.388362\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032142; batch adversarial loss: 0.457593\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033659; batch adversarial loss: 0.493182\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048430; batch adversarial loss: 0.477389\n",
      "epoch 118; iter: 0; batch classifier loss: 0.070721; batch adversarial loss: 0.409271\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057187; batch adversarial loss: 0.432298\n",
      "epoch 120; iter: 0; batch classifier loss: 0.073098; batch adversarial loss: 0.463564\n",
      "epoch 121; iter: 0; batch classifier loss: 0.066628; batch adversarial loss: 0.536686\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034348; batch adversarial loss: 0.452218\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044635; batch adversarial loss: 0.474278\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042632; batch adversarial loss: 0.408765\n",
      "epoch 125; iter: 0; batch classifier loss: 0.069216; batch adversarial loss: 0.428753\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035597; batch adversarial loss: 0.490004\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048932; batch adversarial loss: 0.453275\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046103; batch adversarial loss: 0.461822\n",
      "epoch 129; iter: 0; batch classifier loss: 0.103458; batch adversarial loss: 0.378622\n",
      "epoch 130; iter: 0; batch classifier loss: 0.067882; batch adversarial loss: 0.463434\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041619; batch adversarial loss: 0.495502\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032736; batch adversarial loss: 0.383849\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040391; batch adversarial loss: 0.502093\n",
      "epoch 134; iter: 0; batch classifier loss: 0.058251; batch adversarial loss: 0.395558\n",
      "epoch 135; iter: 0; batch classifier loss: 0.083546; batch adversarial loss: 0.458203\n",
      "epoch 136; iter: 0; batch classifier loss: 0.075449; batch adversarial loss: 0.476922\n",
      "epoch 137; iter: 0; batch classifier loss: 0.085805; batch adversarial loss: 0.415661\n",
      "epoch 138; iter: 0; batch classifier loss: 0.084733; batch adversarial loss: 0.418564\n",
      "epoch 139; iter: 0; batch classifier loss: 0.059961; batch adversarial loss: 0.454746\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052045; batch adversarial loss: 0.425525\n",
      "epoch 141; iter: 0; batch classifier loss: 0.056502; batch adversarial loss: 0.440489\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050773; batch adversarial loss: 0.364962\n",
      "epoch 143; iter: 0; batch classifier loss: 0.065056; batch adversarial loss: 0.479673\n",
      "epoch 144; iter: 0; batch classifier loss: 0.046361; batch adversarial loss: 0.468416\n",
      "epoch 145; iter: 0; batch classifier loss: 0.093387; batch adversarial loss: 0.381353\n",
      "epoch 146; iter: 0; batch classifier loss: 0.071926; batch adversarial loss: 0.404740\n",
      "epoch 147; iter: 0; batch classifier loss: 0.061700; batch adversarial loss: 0.369654\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029692; batch adversarial loss: 0.367305\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034789; batch adversarial loss: 0.380543\n",
      "epoch 150; iter: 0; batch classifier loss: 0.053981; batch adversarial loss: 0.468420\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035015; batch adversarial loss: 0.483841\n",
      "epoch 152; iter: 0; batch classifier loss: 0.047406; batch adversarial loss: 0.474378\n",
      "epoch 153; iter: 0; batch classifier loss: 0.065113; batch adversarial loss: 0.510023\n",
      "epoch 154; iter: 0; batch classifier loss: 0.048132; batch adversarial loss: 0.351719\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041547; batch adversarial loss: 0.440166\n",
      "epoch 156; iter: 0; batch classifier loss: 0.059361; batch adversarial loss: 0.346124\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029441; batch adversarial loss: 0.365152\n",
      "epoch 158; iter: 0; batch classifier loss: 0.075335; batch adversarial loss: 0.525259\n",
      "epoch 159; iter: 0; batch classifier loss: 0.066736; batch adversarial loss: 0.412672\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046981; batch adversarial loss: 0.472446\n",
      "epoch 161; iter: 0; batch classifier loss: 0.049491; batch adversarial loss: 0.372748\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040325; batch adversarial loss: 0.537957\n",
      "epoch 163; iter: 0; batch classifier loss: 0.068892; batch adversarial loss: 0.512918\n",
      "epoch 164; iter: 0; batch classifier loss: 0.052950; batch adversarial loss: 0.390138\n",
      "epoch 165; iter: 0; batch classifier loss: 0.056185; batch adversarial loss: 0.495604\n",
      "epoch 166; iter: 0; batch classifier loss: 0.050439; batch adversarial loss: 0.454524\n",
      "epoch 167; iter: 0; batch classifier loss: 0.051393; batch adversarial loss: 0.406800\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034943; batch adversarial loss: 0.359780\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044790; batch adversarial loss: 0.480324\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037807; batch adversarial loss: 0.496065\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029449; batch adversarial loss: 0.411837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.034067; batch adversarial loss: 0.479470\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034415; batch adversarial loss: 0.456079\n",
      "epoch 174; iter: 0; batch classifier loss: 0.049942; batch adversarial loss: 0.470583\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024701; batch adversarial loss: 0.453871\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025272; batch adversarial loss: 0.407730\n",
      "epoch 177; iter: 0; batch classifier loss: 0.040663; batch adversarial loss: 0.411549\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040058; batch adversarial loss: 0.486333\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030398; batch adversarial loss: 0.428169\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040330; batch adversarial loss: 0.373109\n",
      "epoch 181; iter: 0; batch classifier loss: 0.043842; batch adversarial loss: 0.465159\n",
      "epoch 182; iter: 0; batch classifier loss: 0.048985; batch adversarial loss: 0.497495\n",
      "epoch 183; iter: 0; batch classifier loss: 0.037249; batch adversarial loss: 0.497021\n",
      "epoch 184; iter: 0; batch classifier loss: 0.045680; batch adversarial loss: 0.459429\n",
      "epoch 185; iter: 0; batch classifier loss: 0.039365; batch adversarial loss: 0.379009\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028672; batch adversarial loss: 0.351519\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012928; batch adversarial loss: 0.440332\n",
      "epoch 188; iter: 0; batch classifier loss: 0.036427; batch adversarial loss: 0.369563\n",
      "epoch 189; iter: 0; batch classifier loss: 0.040705; batch adversarial loss: 0.440433\n",
      "epoch 190; iter: 0; batch classifier loss: 0.046851; batch adversarial loss: 0.387165\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021527; batch adversarial loss: 0.479397\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025649; batch adversarial loss: 0.436045\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021621; batch adversarial loss: 0.431780\n",
      "epoch 194; iter: 0; batch classifier loss: 0.042915; batch adversarial loss: 0.373998\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030571; batch adversarial loss: 0.436486\n",
      "epoch 196; iter: 0; batch classifier loss: 0.040857; batch adversarial loss: 0.380052\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023487; batch adversarial loss: 0.531562\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022066; batch adversarial loss: 0.388116\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023971; batch adversarial loss: 0.564649\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677564; batch adversarial loss: 1.045318\n",
      "epoch 1; iter: 0; batch classifier loss: 0.643929; batch adversarial loss: 1.091015\n",
      "epoch 2; iter: 0; batch classifier loss: 0.996638; batch adversarial loss: 1.219555\n",
      "epoch 3; iter: 0; batch classifier loss: 0.920497; batch adversarial loss: 1.089298\n",
      "epoch 4; iter: 0; batch classifier loss: 1.042604; batch adversarial loss: 0.992941\n",
      "epoch 5; iter: 0; batch classifier loss: 1.056948; batch adversarial loss: 0.903998\n",
      "epoch 6; iter: 0; batch classifier loss: 1.311565; batch adversarial loss: 0.829790\n",
      "epoch 7; iter: 0; batch classifier loss: 1.121966; batch adversarial loss: 0.748093\n",
      "epoch 8; iter: 0; batch classifier loss: 1.129594; batch adversarial loss: 0.678528\n",
      "epoch 9; iter: 0; batch classifier loss: 0.863215; batch adversarial loss: 0.631197\n",
      "epoch 10; iter: 0; batch classifier loss: 0.932371; batch adversarial loss: 0.581314\n",
      "epoch 11; iter: 0; batch classifier loss: 0.987237; batch adversarial loss: 0.605474\n",
      "epoch 12; iter: 0; batch classifier loss: 0.468697; batch adversarial loss: 0.565572\n",
      "epoch 13; iter: 0; batch classifier loss: 0.364554; batch adversarial loss: 0.509090\n",
      "epoch 14; iter: 0; batch classifier loss: 0.342934; batch adversarial loss: 0.537936\n",
      "epoch 15; iter: 0; batch classifier loss: 0.277415; batch adversarial loss: 0.515173\n",
      "epoch 16; iter: 0; batch classifier loss: 0.291672; batch adversarial loss: 0.482054\n",
      "epoch 17; iter: 0; batch classifier loss: 0.215280; batch adversarial loss: 0.509534\n",
      "epoch 18; iter: 0; batch classifier loss: 0.260558; batch adversarial loss: 0.464301\n",
      "epoch 19; iter: 0; batch classifier loss: 0.351571; batch adversarial loss: 0.464381\n",
      "epoch 20; iter: 0; batch classifier loss: 0.279975; batch adversarial loss: 0.478353\n",
      "epoch 21; iter: 0; batch classifier loss: 0.196547; batch adversarial loss: 0.476992\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206748; batch adversarial loss: 0.450044\n",
      "epoch 23; iter: 0; batch classifier loss: 0.200555; batch adversarial loss: 0.503940\n",
      "epoch 24; iter: 0; batch classifier loss: 0.245337; batch adversarial loss: 0.443343\n",
      "epoch 25; iter: 0; batch classifier loss: 0.322030; batch adversarial loss: 0.449685\n",
      "epoch 26; iter: 0; batch classifier loss: 0.275156; batch adversarial loss: 0.472811\n",
      "epoch 27; iter: 0; batch classifier loss: 0.243101; batch adversarial loss: 0.412047\n",
      "epoch 28; iter: 0; batch classifier loss: 0.268754; batch adversarial loss: 0.488878\n",
      "epoch 29; iter: 0; batch classifier loss: 0.324356; batch adversarial loss: 0.450733\n",
      "epoch 30; iter: 0; batch classifier loss: 0.223919; batch adversarial loss: 0.456432\n",
      "epoch 31; iter: 0; batch classifier loss: 0.246553; batch adversarial loss: 0.487199\n",
      "epoch 32; iter: 0; batch classifier loss: 0.257959; batch adversarial loss: 0.444479\n",
      "epoch 33; iter: 0; batch classifier loss: 0.215800; batch adversarial loss: 0.517154\n",
      "epoch 34; iter: 0; batch classifier loss: 0.224390; batch adversarial loss: 0.489830\n",
      "epoch 35; iter: 0; batch classifier loss: 0.223815; batch adversarial loss: 0.468430\n",
      "epoch 36; iter: 0; batch classifier loss: 0.238699; batch adversarial loss: 0.437012\n",
      "epoch 37; iter: 0; batch classifier loss: 0.229515; batch adversarial loss: 0.459209\n",
      "epoch 38; iter: 0; batch classifier loss: 0.157440; batch adversarial loss: 0.475380\n",
      "epoch 39; iter: 0; batch classifier loss: 0.241107; batch adversarial loss: 0.430784\n",
      "epoch 40; iter: 0; batch classifier loss: 0.140252; batch adversarial loss: 0.476739\n",
      "epoch 41; iter: 0; batch classifier loss: 0.249157; batch adversarial loss: 0.393747\n",
      "epoch 42; iter: 0; batch classifier loss: 0.164251; batch adversarial loss: 0.497251\n",
      "epoch 43; iter: 0; batch classifier loss: 0.166096; batch adversarial loss: 0.518710\n",
      "epoch 44; iter: 0; batch classifier loss: 0.191563; batch adversarial loss: 0.436188\n",
      "epoch 45; iter: 0; batch classifier loss: 0.199756; batch adversarial loss: 0.372338\n",
      "epoch 46; iter: 0; batch classifier loss: 0.245912; batch adversarial loss: 0.436094\n",
      "epoch 47; iter: 0; batch classifier loss: 0.158618; batch adversarial loss: 0.503817\n",
      "epoch 48; iter: 0; batch classifier loss: 0.240835; batch adversarial loss: 0.401059\n",
      "epoch 49; iter: 0; batch classifier loss: 0.164849; batch adversarial loss: 0.366737\n",
      "epoch 50; iter: 0; batch classifier loss: 0.197759; batch adversarial loss: 0.448246\n",
      "epoch 51; iter: 0; batch classifier loss: 0.155961; batch adversarial loss: 0.465244\n",
      "epoch 52; iter: 0; batch classifier loss: 0.163672; batch adversarial loss: 0.410582\n",
      "epoch 53; iter: 0; batch classifier loss: 0.210544; batch adversarial loss: 0.438254\n",
      "epoch 54; iter: 0; batch classifier loss: 0.168859; batch adversarial loss: 0.480179\n",
      "epoch 55; iter: 0; batch classifier loss: 0.144275; batch adversarial loss: 0.409788\n",
      "epoch 56; iter: 0; batch classifier loss: 0.177978; batch adversarial loss: 0.447258\n",
      "epoch 57; iter: 0; batch classifier loss: 0.132074; batch adversarial loss: 0.448227\n",
      "epoch 58; iter: 0; batch classifier loss: 0.144261; batch adversarial loss: 0.415121\n",
      "epoch 59; iter: 0; batch classifier loss: 0.161698; batch adversarial loss: 0.489483\n",
      "epoch 60; iter: 0; batch classifier loss: 0.168906; batch adversarial loss: 0.354882\n",
      "epoch 61; iter: 0; batch classifier loss: 0.116502; batch adversarial loss: 0.497854\n",
      "epoch 62; iter: 0; batch classifier loss: 0.140630; batch adversarial loss: 0.523722\n",
      "epoch 63; iter: 0; batch classifier loss: 0.150862; batch adversarial loss: 0.524557\n",
      "epoch 64; iter: 0; batch classifier loss: 0.149150; batch adversarial loss: 0.465887\n",
      "epoch 65; iter: 0; batch classifier loss: 0.175470; batch adversarial loss: 0.439755\n",
      "epoch 66; iter: 0; batch classifier loss: 0.109760; batch adversarial loss: 0.432159\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171746; batch adversarial loss: 0.435179\n",
      "epoch 68; iter: 0; batch classifier loss: 0.116984; batch adversarial loss: 0.464888\n",
      "epoch 69; iter: 0; batch classifier loss: 0.152056; batch adversarial loss: 0.572958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.179491; batch adversarial loss: 0.417203\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078729; batch adversarial loss: 0.483314\n",
      "epoch 72; iter: 0; batch classifier loss: 0.150072; batch adversarial loss: 0.491685\n",
      "epoch 73; iter: 0; batch classifier loss: 0.145364; batch adversarial loss: 0.447707\n",
      "epoch 74; iter: 0; batch classifier loss: 0.115219; batch adversarial loss: 0.396983\n",
      "epoch 75; iter: 0; batch classifier loss: 0.155205; batch adversarial loss: 0.453535\n",
      "epoch 76; iter: 0; batch classifier loss: 0.149617; batch adversarial loss: 0.390020\n",
      "epoch 77; iter: 0; batch classifier loss: 0.134485; batch adversarial loss: 0.429925\n",
      "epoch 78; iter: 0; batch classifier loss: 0.156880; batch adversarial loss: 0.429365\n",
      "epoch 79; iter: 0; batch classifier loss: 0.109361; batch adversarial loss: 0.379180\n",
      "epoch 80; iter: 0; batch classifier loss: 0.111148; batch adversarial loss: 0.491492\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067100; batch adversarial loss: 0.541238\n",
      "epoch 82; iter: 0; batch classifier loss: 0.127460; batch adversarial loss: 0.492147\n",
      "epoch 83; iter: 0; batch classifier loss: 0.090488; batch adversarial loss: 0.507541\n",
      "epoch 84; iter: 0; batch classifier loss: 0.172451; batch adversarial loss: 0.483196\n",
      "epoch 85; iter: 0; batch classifier loss: 0.109253; batch adversarial loss: 0.497131\n",
      "epoch 86; iter: 0; batch classifier loss: 0.097789; batch adversarial loss: 0.421062\n",
      "epoch 87; iter: 0; batch classifier loss: 0.113016; batch adversarial loss: 0.414884\n",
      "epoch 88; iter: 0; batch classifier loss: 0.106161; batch adversarial loss: 0.539108\n",
      "epoch 89; iter: 0; batch classifier loss: 0.091074; batch adversarial loss: 0.469841\n",
      "epoch 90; iter: 0; batch classifier loss: 0.127493; batch adversarial loss: 0.411625\n",
      "epoch 91; iter: 0; batch classifier loss: 0.106448; batch adversarial loss: 0.476964\n",
      "epoch 92; iter: 0; batch classifier loss: 0.160661; batch adversarial loss: 0.442233\n",
      "epoch 93; iter: 0; batch classifier loss: 0.148968; batch adversarial loss: 0.381000\n",
      "epoch 94; iter: 0; batch classifier loss: 0.111078; batch adversarial loss: 0.484861\n",
      "epoch 95; iter: 0; batch classifier loss: 0.105594; batch adversarial loss: 0.495351\n",
      "epoch 96; iter: 0; batch classifier loss: 0.088311; batch adversarial loss: 0.455876\n",
      "epoch 97; iter: 0; batch classifier loss: 0.118956; batch adversarial loss: 0.427483\n",
      "epoch 98; iter: 0; batch classifier loss: 0.121746; batch adversarial loss: 0.442431\n",
      "epoch 99; iter: 0; batch classifier loss: 0.144098; batch adversarial loss: 0.467723\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049299; batch adversarial loss: 0.528655\n",
      "epoch 101; iter: 0; batch classifier loss: 0.136928; batch adversarial loss: 0.489746\n",
      "epoch 102; iter: 0; batch classifier loss: 0.086874; batch adversarial loss: 0.370027\n",
      "epoch 103; iter: 0; batch classifier loss: 0.126929; batch adversarial loss: 0.428450\n",
      "epoch 104; iter: 0; batch classifier loss: 0.098101; batch adversarial loss: 0.505680\n",
      "epoch 105; iter: 0; batch classifier loss: 0.123364; batch adversarial loss: 0.454808\n",
      "epoch 106; iter: 0; batch classifier loss: 0.150479; batch adversarial loss: 0.380968\n",
      "epoch 107; iter: 0; batch classifier loss: 0.157653; batch adversarial loss: 0.567178\n",
      "epoch 108; iter: 0; batch classifier loss: 0.096792; batch adversarial loss: 0.469813\n",
      "epoch 109; iter: 0; batch classifier loss: 0.176448; batch adversarial loss: 0.465038\n",
      "epoch 110; iter: 0; batch classifier loss: 0.088914; batch adversarial loss: 0.528627\n",
      "epoch 111; iter: 0; batch classifier loss: 0.139578; batch adversarial loss: 0.416773\n",
      "epoch 112; iter: 0; batch classifier loss: 0.110950; batch adversarial loss: 0.434272\n",
      "epoch 113; iter: 0; batch classifier loss: 0.142109; batch adversarial loss: 0.395854\n",
      "epoch 114; iter: 0; batch classifier loss: 0.131815; batch adversarial loss: 0.471156\n",
      "epoch 115; iter: 0; batch classifier loss: 0.131969; batch adversarial loss: 0.435747\n",
      "epoch 116; iter: 0; batch classifier loss: 0.071093; batch adversarial loss: 0.446697\n",
      "epoch 117; iter: 0; batch classifier loss: 0.115954; batch adversarial loss: 0.430290\n",
      "epoch 118; iter: 0; batch classifier loss: 0.077427; batch adversarial loss: 0.507838\n",
      "epoch 119; iter: 0; batch classifier loss: 0.121869; batch adversarial loss: 0.479673\n",
      "epoch 120; iter: 0; batch classifier loss: 0.067488; batch adversarial loss: 0.392281\n",
      "epoch 121; iter: 0; batch classifier loss: 0.075546; batch adversarial loss: 0.497432\n",
      "epoch 122; iter: 0; batch classifier loss: 0.070469; batch adversarial loss: 0.538967\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034014; batch adversarial loss: 0.569575\n",
      "epoch 124; iter: 0; batch classifier loss: 0.045636; batch adversarial loss: 0.397814\n",
      "epoch 125; iter: 0; batch classifier loss: 0.106080; batch adversarial loss: 0.555407\n",
      "epoch 126; iter: 0; batch classifier loss: 0.098826; batch adversarial loss: 0.403297\n",
      "epoch 127; iter: 0; batch classifier loss: 0.079868; batch adversarial loss: 0.422817\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046100; batch adversarial loss: 0.454932\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028654; batch adversarial loss: 0.464913\n",
      "epoch 130; iter: 0; batch classifier loss: 0.066205; batch adversarial loss: 0.563279\n",
      "epoch 131; iter: 0; batch classifier loss: 0.075785; batch adversarial loss: 0.404893\n",
      "epoch 132; iter: 0; batch classifier loss: 0.059758; batch adversarial loss: 0.402649\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032086; batch adversarial loss: 0.410433\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045571; batch adversarial loss: 0.495505\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026200; batch adversarial loss: 0.402991\n",
      "epoch 136; iter: 0; batch classifier loss: 0.070082; batch adversarial loss: 0.457870\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030656; batch adversarial loss: 0.507864\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035559; batch adversarial loss: 0.483568\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024476; batch adversarial loss: 0.498428\n",
      "epoch 140; iter: 0; batch classifier loss: 0.054787; batch adversarial loss: 0.486735\n",
      "epoch 141; iter: 0; batch classifier loss: 0.059683; batch adversarial loss: 0.389339\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027184; batch adversarial loss: 0.562805\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026536; batch adversarial loss: 0.407246\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020399; batch adversarial loss: 0.416484\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021156; batch adversarial loss: 0.546020\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028987; batch adversarial loss: 0.468481\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046702; batch adversarial loss: 0.508850\n",
      "epoch 148; iter: 0; batch classifier loss: 0.056129; batch adversarial loss: 0.454043\n",
      "epoch 149; iter: 0; batch classifier loss: 0.043350; batch adversarial loss: 0.521627\n",
      "epoch 150; iter: 0; batch classifier loss: 0.071752; batch adversarial loss: 0.389965\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029584; batch adversarial loss: 0.426702\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041850; batch adversarial loss: 0.431571\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022590; batch adversarial loss: 0.461898\n",
      "epoch 154; iter: 0; batch classifier loss: 0.050342; batch adversarial loss: 0.482410\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011375; batch adversarial loss: 0.495673\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039382; batch adversarial loss: 0.519969\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023291; batch adversarial loss: 0.340725\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010804; batch adversarial loss: 0.490011\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024979; batch adversarial loss: 0.508515\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023350; batch adversarial loss: 0.518615\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013341; batch adversarial loss: 0.482114\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016590; batch adversarial loss: 0.468053\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027600; batch adversarial loss: 0.522762\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030416; batch adversarial loss: 0.416081\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019907; batch adversarial loss: 0.419313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.018650; batch adversarial loss: 0.508979\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019660; batch adversarial loss: 0.418248\n",
      "epoch 168; iter: 0; batch classifier loss: 0.039954; batch adversarial loss: 0.535376\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014955; batch adversarial loss: 0.426726\n",
      "epoch 170; iter: 0; batch classifier loss: 0.042371; batch adversarial loss: 0.515291\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005541; batch adversarial loss: 0.446929\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024812; batch adversarial loss: 0.429481\n",
      "epoch 173; iter: 0; batch classifier loss: 0.045809; batch adversarial loss: 0.491950\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013954; batch adversarial loss: 0.468868\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042411; batch adversarial loss: 0.452237\n",
      "epoch 176; iter: 0; batch classifier loss: 0.005052; batch adversarial loss: 0.480206\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023226; batch adversarial loss: 0.513186\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020292; batch adversarial loss: 0.514768\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033800; batch adversarial loss: 0.404276\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028331; batch adversarial loss: 0.433605\n",
      "epoch 181; iter: 0; batch classifier loss: 0.002491; batch adversarial loss: 0.472765\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024277; batch adversarial loss: 0.418952\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009044; batch adversarial loss: 0.410157\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012682; batch adversarial loss: 0.461866\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016898; batch adversarial loss: 0.391067\n",
      "epoch 186; iter: 0; batch classifier loss: 0.058112; batch adversarial loss: 0.523297\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005483; batch adversarial loss: 0.524743\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006531; batch adversarial loss: 0.409140\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006080; batch adversarial loss: 0.426067\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014149; batch adversarial loss: 0.411661\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011607; batch adversarial loss: 0.318664\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035992; batch adversarial loss: 0.390039\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022448; batch adversarial loss: 0.457605\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012638; batch adversarial loss: 0.444743\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014178; batch adversarial loss: 0.405986\n",
      "epoch 196; iter: 0; batch classifier loss: 0.003731; batch adversarial loss: 0.430645\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020902; batch adversarial loss: 0.512014\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012620; batch adversarial loss: 0.549929\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012568; batch adversarial loss: 0.489134\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696426; batch adversarial loss: 1.033381\n",
      "epoch 1; iter: 0; batch classifier loss: 0.653029; batch adversarial loss: 1.109036\n",
      "epoch 2; iter: 0; batch classifier loss: 0.917009; batch adversarial loss: 1.135769\n",
      "epoch 3; iter: 0; batch classifier loss: 1.122635; batch adversarial loss: 1.065413\n",
      "epoch 4; iter: 0; batch classifier loss: 1.122941; batch adversarial loss: 0.961278\n",
      "epoch 5; iter: 0; batch classifier loss: 1.050051; batch adversarial loss: 0.850739\n",
      "epoch 6; iter: 0; batch classifier loss: 1.071904; batch adversarial loss: 0.770436\n",
      "epoch 7; iter: 0; batch classifier loss: 0.977605; batch adversarial loss: 0.701374\n",
      "epoch 8; iter: 0; batch classifier loss: 0.864402; batch adversarial loss: 0.662213\n",
      "epoch 9; iter: 0; batch classifier loss: 0.695106; batch adversarial loss: 0.659950\n",
      "epoch 10; iter: 0; batch classifier loss: 0.640541; batch adversarial loss: 0.595060\n",
      "epoch 11; iter: 0; batch classifier loss: 0.379642; batch adversarial loss: 0.590159\n",
      "epoch 12; iter: 0; batch classifier loss: 0.370692; batch adversarial loss: 0.546821\n",
      "epoch 13; iter: 0; batch classifier loss: 0.378821; batch adversarial loss: 0.540709\n",
      "epoch 14; iter: 0; batch classifier loss: 0.268312; batch adversarial loss: 0.523487\n",
      "epoch 15; iter: 0; batch classifier loss: 0.308227; batch adversarial loss: 0.458621\n",
      "epoch 16; iter: 0; batch classifier loss: 0.271247; batch adversarial loss: 0.514125\n",
      "epoch 17; iter: 0; batch classifier loss: 0.234293; batch adversarial loss: 0.475764\n",
      "epoch 18; iter: 0; batch classifier loss: 0.319531; batch adversarial loss: 0.439445\n",
      "epoch 19; iter: 0; batch classifier loss: 0.280072; batch adversarial loss: 0.472410\n",
      "epoch 20; iter: 0; batch classifier loss: 0.202745; batch adversarial loss: 0.446177\n",
      "epoch 21; iter: 0; batch classifier loss: 0.210847; batch adversarial loss: 0.417847\n",
      "epoch 22; iter: 0; batch classifier loss: 0.237799; batch adversarial loss: 0.482074\n",
      "epoch 23; iter: 0; batch classifier loss: 0.279999; batch adversarial loss: 0.506962\n",
      "epoch 24; iter: 0; batch classifier loss: 0.233017; batch adversarial loss: 0.477147\n",
      "epoch 25; iter: 0; batch classifier loss: 0.247508; batch adversarial loss: 0.493822\n",
      "epoch 26; iter: 0; batch classifier loss: 0.250227; batch adversarial loss: 0.439663\n",
      "epoch 27; iter: 0; batch classifier loss: 0.224426; batch adversarial loss: 0.373210\n",
      "epoch 28; iter: 0; batch classifier loss: 0.180134; batch adversarial loss: 0.464507\n",
      "epoch 29; iter: 0; batch classifier loss: 0.270135; batch adversarial loss: 0.478205\n",
      "epoch 30; iter: 0; batch classifier loss: 0.201248; batch adversarial loss: 0.431560\n",
      "epoch 31; iter: 0; batch classifier loss: 0.192267; batch adversarial loss: 0.451215\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165066; batch adversarial loss: 0.495177\n",
      "epoch 33; iter: 0; batch classifier loss: 0.251177; batch adversarial loss: 0.451061\n",
      "epoch 34; iter: 0; batch classifier loss: 0.245120; batch adversarial loss: 0.418814\n",
      "epoch 35; iter: 0; batch classifier loss: 0.241495; batch adversarial loss: 0.442978\n",
      "epoch 36; iter: 0; batch classifier loss: 0.198549; batch adversarial loss: 0.451512\n",
      "epoch 37; iter: 0; batch classifier loss: 0.221172; batch adversarial loss: 0.492565\n",
      "epoch 38; iter: 0; batch classifier loss: 0.213871; batch adversarial loss: 0.502788\n",
      "epoch 39; iter: 0; batch classifier loss: 0.186384; batch adversarial loss: 0.567055\n",
      "epoch 40; iter: 0; batch classifier loss: 0.266903; batch adversarial loss: 0.511157\n",
      "epoch 41; iter: 0; batch classifier loss: 0.170886; batch adversarial loss: 0.426119\n",
      "epoch 42; iter: 0; batch classifier loss: 0.192110; batch adversarial loss: 0.476013\n",
      "epoch 43; iter: 0; batch classifier loss: 0.251801; batch adversarial loss: 0.408145\n",
      "epoch 44; iter: 0; batch classifier loss: 0.179342; batch adversarial loss: 0.468000\n",
      "epoch 45; iter: 0; batch classifier loss: 0.171983; batch adversarial loss: 0.457288\n",
      "epoch 46; iter: 0; batch classifier loss: 0.217049; batch adversarial loss: 0.505257\n",
      "epoch 47; iter: 0; batch classifier loss: 0.216493; batch adversarial loss: 0.455279\n",
      "epoch 48; iter: 0; batch classifier loss: 0.187565; batch adversarial loss: 0.503502\n",
      "epoch 49; iter: 0; batch classifier loss: 0.270204; batch adversarial loss: 0.382215\n",
      "epoch 50; iter: 0; batch classifier loss: 0.184412; batch adversarial loss: 0.436514\n",
      "epoch 51; iter: 0; batch classifier loss: 0.163783; batch adversarial loss: 0.501050\n",
      "epoch 52; iter: 0; batch classifier loss: 0.236343; batch adversarial loss: 0.423416\n",
      "epoch 53; iter: 0; batch classifier loss: 0.193938; batch adversarial loss: 0.451628\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122120; batch adversarial loss: 0.421876\n",
      "epoch 55; iter: 0; batch classifier loss: 0.139125; batch adversarial loss: 0.519787\n",
      "epoch 56; iter: 0; batch classifier loss: 0.132622; batch adversarial loss: 0.501604\n",
      "epoch 57; iter: 0; batch classifier loss: 0.167193; batch adversarial loss: 0.505604\n",
      "epoch 58; iter: 0; batch classifier loss: 0.147200; batch adversarial loss: 0.441516\n",
      "epoch 59; iter: 0; batch classifier loss: 0.155988; batch adversarial loss: 0.515833\n",
      "epoch 60; iter: 0; batch classifier loss: 0.166292; batch adversarial loss: 0.469848\n",
      "epoch 61; iter: 0; batch classifier loss: 0.158956; batch adversarial loss: 0.553981\n",
      "epoch 62; iter: 0; batch classifier loss: 0.206170; batch adversarial loss: 0.447721\n",
      "epoch 63; iter: 0; batch classifier loss: 0.196359; batch adversarial loss: 0.435603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.194755; batch adversarial loss: 0.444786\n",
      "epoch 65; iter: 0; batch classifier loss: 0.174492; batch adversarial loss: 0.523037\n",
      "epoch 66; iter: 0; batch classifier loss: 0.183559; batch adversarial loss: 0.397319\n",
      "epoch 67; iter: 0; batch classifier loss: 0.177786; batch adversarial loss: 0.488962\n",
      "epoch 68; iter: 0; batch classifier loss: 0.222079; batch adversarial loss: 0.466065\n",
      "epoch 69; iter: 0; batch classifier loss: 0.202684; batch adversarial loss: 0.421052\n",
      "epoch 70; iter: 0; batch classifier loss: 0.213408; batch adversarial loss: 0.442275\n",
      "epoch 71; iter: 0; batch classifier loss: 0.150702; batch adversarial loss: 0.480891\n",
      "epoch 72; iter: 0; batch classifier loss: 0.216847; batch adversarial loss: 0.405304\n",
      "epoch 73; iter: 0; batch classifier loss: 0.130863; batch adversarial loss: 0.415570\n",
      "epoch 74; iter: 0; batch classifier loss: 0.158147; batch adversarial loss: 0.426706\n",
      "epoch 75; iter: 0; batch classifier loss: 0.143393; batch adversarial loss: 0.536014\n",
      "epoch 76; iter: 0; batch classifier loss: 0.220898; batch adversarial loss: 0.428358\n",
      "epoch 77; iter: 0; batch classifier loss: 0.190854; batch adversarial loss: 0.445071\n",
      "epoch 78; iter: 0; batch classifier loss: 0.169439; batch adversarial loss: 0.472165\n",
      "epoch 79; iter: 0; batch classifier loss: 0.201486; batch adversarial loss: 0.540784\n",
      "epoch 80; iter: 0; batch classifier loss: 0.186515; batch adversarial loss: 0.505497\n",
      "epoch 81; iter: 0; batch classifier loss: 0.156217; batch adversarial loss: 0.575486\n",
      "epoch 82; iter: 0; batch classifier loss: 0.161540; batch adversarial loss: 0.467875\n",
      "epoch 83; iter: 0; batch classifier loss: 0.160914; batch adversarial loss: 0.475816\n",
      "epoch 84; iter: 0; batch classifier loss: 0.177723; batch adversarial loss: 0.536487\n",
      "epoch 85; iter: 0; batch classifier loss: 0.200717; batch adversarial loss: 0.434980\n",
      "epoch 86; iter: 0; batch classifier loss: 0.127073; batch adversarial loss: 0.544465\n",
      "epoch 87; iter: 0; batch classifier loss: 0.150321; batch adversarial loss: 0.488709\n",
      "epoch 88; iter: 0; batch classifier loss: 0.223124; batch adversarial loss: 0.507148\n",
      "epoch 89; iter: 0; batch classifier loss: 0.145466; batch adversarial loss: 0.483543\n",
      "epoch 90; iter: 0; batch classifier loss: 0.186428; batch adversarial loss: 0.519628\n",
      "epoch 91; iter: 0; batch classifier loss: 0.200268; batch adversarial loss: 0.445807\n",
      "epoch 92; iter: 0; batch classifier loss: 0.171610; batch adversarial loss: 0.432536\n",
      "epoch 93; iter: 0; batch classifier loss: 0.160178; batch adversarial loss: 0.423772\n",
      "epoch 94; iter: 0; batch classifier loss: 0.174402; batch adversarial loss: 0.494159\n",
      "epoch 95; iter: 0; batch classifier loss: 0.213305; batch adversarial loss: 0.492084\n",
      "epoch 96; iter: 0; batch classifier loss: 0.151094; batch adversarial loss: 0.532659\n",
      "epoch 97; iter: 0; batch classifier loss: 0.239852; batch adversarial loss: 0.480581\n",
      "epoch 98; iter: 0; batch classifier loss: 0.253629; batch adversarial loss: 0.436279\n",
      "epoch 99; iter: 0; batch classifier loss: 0.139205; batch adversarial loss: 0.467947\n",
      "epoch 100; iter: 0; batch classifier loss: 0.183174; batch adversarial loss: 0.435647\n",
      "epoch 101; iter: 0; batch classifier loss: 0.155233; batch adversarial loss: 0.400967\n",
      "epoch 102; iter: 0; batch classifier loss: 0.212499; batch adversarial loss: 0.457929\n",
      "epoch 103; iter: 0; batch classifier loss: 0.183280; batch adversarial loss: 0.411169\n",
      "epoch 104; iter: 0; batch classifier loss: 0.191962; batch adversarial loss: 0.509666\n",
      "epoch 105; iter: 0; batch classifier loss: 0.201979; batch adversarial loss: 0.371587\n",
      "epoch 106; iter: 0; batch classifier loss: 0.192950; batch adversarial loss: 0.458903\n",
      "epoch 107; iter: 0; batch classifier loss: 0.234598; batch adversarial loss: 0.556440\n",
      "epoch 108; iter: 0; batch classifier loss: 0.170322; batch adversarial loss: 0.434237\n",
      "epoch 109; iter: 0; batch classifier loss: 0.170927; batch adversarial loss: 0.399612\n",
      "epoch 110; iter: 0; batch classifier loss: 0.179701; batch adversarial loss: 0.471341\n",
      "epoch 111; iter: 0; batch classifier loss: 0.210927; batch adversarial loss: 0.458970\n",
      "epoch 112; iter: 0; batch classifier loss: 0.240993; batch adversarial loss: 0.385573\n",
      "epoch 113; iter: 0; batch classifier loss: 0.205145; batch adversarial loss: 0.384692\n",
      "epoch 114; iter: 0; batch classifier loss: 0.261685; batch adversarial loss: 0.494693\n",
      "epoch 115; iter: 0; batch classifier loss: 0.275242; batch adversarial loss: 0.446743\n",
      "epoch 116; iter: 0; batch classifier loss: 0.165578; batch adversarial loss: 0.555983\n",
      "epoch 117; iter: 0; batch classifier loss: 0.207717; batch adversarial loss: 0.446776\n",
      "epoch 118; iter: 0; batch classifier loss: 0.216536; batch adversarial loss: 0.470776\n",
      "epoch 119; iter: 0; batch classifier loss: 0.180582; batch adversarial loss: 0.471038\n",
      "epoch 120; iter: 0; batch classifier loss: 0.239576; batch adversarial loss: 0.555325\n",
      "epoch 121; iter: 0; batch classifier loss: 0.193288; batch adversarial loss: 0.385759\n",
      "epoch 122; iter: 0; batch classifier loss: 0.215464; batch adversarial loss: 0.507327\n",
      "epoch 123; iter: 0; batch classifier loss: 0.221461; batch adversarial loss: 0.434479\n",
      "epoch 124; iter: 0; batch classifier loss: 0.259936; batch adversarial loss: 0.410395\n",
      "epoch 125; iter: 0; batch classifier loss: 0.127349; batch adversarial loss: 0.470897\n",
      "epoch 126; iter: 0; batch classifier loss: 0.150887; batch adversarial loss: 0.434075\n",
      "epoch 127; iter: 0; batch classifier loss: 0.170532; batch adversarial loss: 0.457664\n",
      "epoch 128; iter: 0; batch classifier loss: 0.219606; batch adversarial loss: 0.509568\n",
      "epoch 129; iter: 0; batch classifier loss: 0.221126; batch adversarial loss: 0.470170\n",
      "epoch 130; iter: 0; batch classifier loss: 0.192529; batch adversarial loss: 0.484658\n",
      "epoch 131; iter: 0; batch classifier loss: 0.143242; batch adversarial loss: 0.447107\n",
      "epoch 132; iter: 0; batch classifier loss: 0.168353; batch adversarial loss: 0.446342\n",
      "epoch 133; iter: 0; batch classifier loss: 0.324309; batch adversarial loss: 0.471622\n",
      "epoch 134; iter: 0; batch classifier loss: 0.225910; batch adversarial loss: 0.434507\n",
      "epoch 135; iter: 0; batch classifier loss: 0.072174; batch adversarial loss: 0.458567\n",
      "epoch 136; iter: 0; batch classifier loss: 0.077789; batch adversarial loss: 0.372408\n",
      "epoch 137; iter: 0; batch classifier loss: 0.071099; batch adversarial loss: 0.417010\n",
      "epoch 138; iter: 0; batch classifier loss: 0.061122; batch adversarial loss: 0.462124\n",
      "epoch 139; iter: 0; batch classifier loss: 0.078510; batch adversarial loss: 0.492835\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037815; batch adversarial loss: 0.458295\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053796; batch adversarial loss: 0.417540\n",
      "epoch 142; iter: 0; batch classifier loss: 0.046859; batch adversarial loss: 0.356593\n",
      "epoch 143; iter: 0; batch classifier loss: 0.089643; batch adversarial loss: 0.453369\n",
      "epoch 144; iter: 0; batch classifier loss: 0.043294; batch adversarial loss: 0.462868\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045059; batch adversarial loss: 0.460250\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041092; batch adversarial loss: 0.456841\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050801; batch adversarial loss: 0.419210\n",
      "epoch 148; iter: 0; batch classifier loss: 0.059085; batch adversarial loss: 0.400261\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020316; batch adversarial loss: 0.417605\n",
      "epoch 150; iter: 0; batch classifier loss: 0.076998; batch adversarial loss: 0.480191\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055283; batch adversarial loss: 0.431843\n",
      "epoch 152; iter: 0; batch classifier loss: 0.051304; batch adversarial loss: 0.457934\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034730; batch adversarial loss: 0.425176\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040883; batch adversarial loss: 0.517538\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031352; batch adversarial loss: 0.480077\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038262; batch adversarial loss: 0.423254\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027515; batch adversarial loss: 0.532279\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035746; batch adversarial loss: 0.554472\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018114; batch adversarial loss: 0.428906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.039162; batch adversarial loss: 0.442083\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024044; batch adversarial loss: 0.441876\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013489; batch adversarial loss: 0.550460\n",
      "epoch 163; iter: 0; batch classifier loss: 0.059066; batch adversarial loss: 0.458328\n",
      "epoch 164; iter: 0; batch classifier loss: 0.071744; batch adversarial loss: 0.556450\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023534; batch adversarial loss: 0.322736\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021637; batch adversarial loss: 0.473961\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021338; batch adversarial loss: 0.512284\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028806; batch adversarial loss: 0.482923\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023893; batch adversarial loss: 0.573256\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038450; batch adversarial loss: 0.528307\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025147; batch adversarial loss: 0.441973\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020395; batch adversarial loss: 0.432011\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021127; batch adversarial loss: 0.416985\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009235; batch adversarial loss: 0.532753\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021515; batch adversarial loss: 0.496964\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015630; batch adversarial loss: 0.475600\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022051; batch adversarial loss: 0.483069\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018527; batch adversarial loss: 0.388042\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017574; batch adversarial loss: 0.499385\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012025; batch adversarial loss: 0.428872\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020509; batch adversarial loss: 0.425157\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009323; batch adversarial loss: 0.412898\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015870; batch adversarial loss: 0.519369\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018821; batch adversarial loss: 0.449677\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009225; batch adversarial loss: 0.488536\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018080; batch adversarial loss: 0.523865\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008403; batch adversarial loss: 0.490663\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032549; batch adversarial loss: 0.554534\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024840; batch adversarial loss: 0.453161\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016190; batch adversarial loss: 0.426117\n",
      "epoch 191; iter: 0; batch classifier loss: 0.045564; batch adversarial loss: 0.493743\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025234; batch adversarial loss: 0.448022\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010080; batch adversarial loss: 0.534427\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019306; batch adversarial loss: 0.429428\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011715; batch adversarial loss: 0.390287\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011450; batch adversarial loss: 0.444458\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017208; batch adversarial loss: 0.374851\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014339; batch adversarial loss: 0.372350\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010108; batch adversarial loss: 0.368390\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692300; batch adversarial loss: 0.624484\n",
      "epoch 1; iter: 0; batch classifier loss: 0.415699; batch adversarial loss: 0.633040\n",
      "epoch 2; iter: 0; batch classifier loss: 0.373000; batch adversarial loss: 0.609464\n",
      "epoch 3; iter: 0; batch classifier loss: 0.277864; batch adversarial loss: 0.595642\n",
      "epoch 4; iter: 0; batch classifier loss: 0.285497; batch adversarial loss: 0.529222\n",
      "epoch 5; iter: 0; batch classifier loss: 0.324542; batch adversarial loss: 0.564561\n",
      "epoch 6; iter: 0; batch classifier loss: 0.325459; batch adversarial loss: 0.530634\n",
      "epoch 7; iter: 0; batch classifier loss: 0.322603; batch adversarial loss: 0.493245\n",
      "epoch 8; iter: 0; batch classifier loss: 0.246516; batch adversarial loss: 0.561301\n",
      "epoch 9; iter: 0; batch classifier loss: 0.254518; batch adversarial loss: 0.560454\n",
      "epoch 10; iter: 0; batch classifier loss: 0.279046; batch adversarial loss: 0.544000\n",
      "epoch 11; iter: 0; batch classifier loss: 0.320690; batch adversarial loss: 0.503848\n",
      "epoch 12; iter: 0; batch classifier loss: 0.367289; batch adversarial loss: 0.510063\n",
      "epoch 13; iter: 0; batch classifier loss: 0.307666; batch adversarial loss: 0.514069\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497077; batch adversarial loss: 0.576277\n",
      "epoch 15; iter: 0; batch classifier loss: 0.452824; batch adversarial loss: 0.468263\n",
      "epoch 16; iter: 0; batch classifier loss: 0.451705; batch adversarial loss: 0.510041\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505099; batch adversarial loss: 0.520492\n",
      "epoch 18; iter: 0; batch classifier loss: 0.374244; batch adversarial loss: 0.467845\n",
      "epoch 19; iter: 0; batch classifier loss: 0.239180; batch adversarial loss: 0.492882\n",
      "epoch 20; iter: 0; batch classifier loss: 0.196877; batch adversarial loss: 0.521673\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186642; batch adversarial loss: 0.455847\n",
      "epoch 22; iter: 0; batch classifier loss: 0.208104; batch adversarial loss: 0.423970\n",
      "epoch 23; iter: 0; batch classifier loss: 0.176159; batch adversarial loss: 0.469346\n",
      "epoch 24; iter: 0; batch classifier loss: 0.151740; batch adversarial loss: 0.427953\n",
      "epoch 25; iter: 0; batch classifier loss: 0.134358; batch adversarial loss: 0.443678\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194126; batch adversarial loss: 0.444134\n",
      "epoch 27; iter: 0; batch classifier loss: 0.122508; batch adversarial loss: 0.436067\n",
      "epoch 28; iter: 0; batch classifier loss: 0.112157; batch adversarial loss: 0.416046\n",
      "epoch 29; iter: 0; batch classifier loss: 0.146448; batch adversarial loss: 0.398877\n",
      "epoch 30; iter: 0; batch classifier loss: 0.095137; batch adversarial loss: 0.474602\n",
      "epoch 31; iter: 0; batch classifier loss: 0.106076; batch adversarial loss: 0.373887\n",
      "epoch 32; iter: 0; batch classifier loss: 0.077739; batch adversarial loss: 0.406335\n",
      "epoch 33; iter: 0; batch classifier loss: 0.134102; batch adversarial loss: 0.448734\n",
      "epoch 34; iter: 0; batch classifier loss: 0.136971; batch adversarial loss: 0.406674\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161415; batch adversarial loss: 0.400326\n",
      "epoch 36; iter: 0; batch classifier loss: 0.149994; batch adversarial loss: 0.517887\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145136; batch adversarial loss: 0.441584\n",
      "epoch 38; iter: 0; batch classifier loss: 0.108838; batch adversarial loss: 0.437355\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106058; batch adversarial loss: 0.550957\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099757; batch adversarial loss: 0.468321\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135734; batch adversarial loss: 0.428922\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096953; batch adversarial loss: 0.354061\n",
      "epoch 43; iter: 0; batch classifier loss: 0.123146; batch adversarial loss: 0.539222\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085599; batch adversarial loss: 0.435070\n",
      "epoch 45; iter: 0; batch classifier loss: 0.133740; batch adversarial loss: 0.439082\n",
      "epoch 46; iter: 0; batch classifier loss: 0.072612; batch adversarial loss: 0.367663\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113828; batch adversarial loss: 0.485623\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129237; batch adversarial loss: 0.354669\n",
      "epoch 49; iter: 0; batch classifier loss: 0.134593; batch adversarial loss: 0.420945\n",
      "epoch 50; iter: 0; batch classifier loss: 0.085949; batch adversarial loss: 0.464144\n",
      "epoch 51; iter: 0; batch classifier loss: 0.124308; batch adversarial loss: 0.401184\n",
      "epoch 52; iter: 0; batch classifier loss: 0.081505; batch adversarial loss: 0.397055\n",
      "epoch 53; iter: 0; batch classifier loss: 0.135595; batch adversarial loss: 0.467851\n",
      "epoch 54; iter: 0; batch classifier loss: 0.070007; batch adversarial loss: 0.486762\n",
      "epoch 55; iter: 0; batch classifier loss: 0.092719; batch adversarial loss: 0.350175\n",
      "epoch 56; iter: 0; batch classifier loss: 0.107744; batch adversarial loss: 0.436074\n",
      "epoch 57; iter: 0; batch classifier loss: 0.105938; batch adversarial loss: 0.434288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.146163; batch adversarial loss: 0.400047\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087861; batch adversarial loss: 0.439805\n",
      "epoch 60; iter: 0; batch classifier loss: 0.124219; batch adversarial loss: 0.404538\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091646; batch adversarial loss: 0.444272\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092984; batch adversarial loss: 0.601621\n",
      "epoch 63; iter: 0; batch classifier loss: 0.148149; batch adversarial loss: 0.438310\n",
      "epoch 64; iter: 0; batch classifier loss: 0.137831; batch adversarial loss: 0.470949\n",
      "epoch 65; iter: 0; batch classifier loss: 0.178941; batch adversarial loss: 0.598201\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078135; batch adversarial loss: 0.451715\n",
      "epoch 67; iter: 0; batch classifier loss: 0.085380; batch adversarial loss: 0.401275\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094583; batch adversarial loss: 0.447858\n",
      "epoch 69; iter: 0; batch classifier loss: 0.093620; batch adversarial loss: 0.346936\n",
      "epoch 70; iter: 0; batch classifier loss: 0.092844; batch adversarial loss: 0.369974\n",
      "epoch 71; iter: 0; batch classifier loss: 0.054361; batch adversarial loss: 0.440942\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064270; batch adversarial loss: 0.458193\n",
      "epoch 73; iter: 0; batch classifier loss: 0.126292; batch adversarial loss: 0.491105\n",
      "epoch 74; iter: 0; batch classifier loss: 0.115368; batch adversarial loss: 0.501780\n",
      "epoch 75; iter: 0; batch classifier loss: 0.140585; batch adversarial loss: 0.456829\n",
      "epoch 76; iter: 0; batch classifier loss: 0.113061; batch adversarial loss: 0.434897\n",
      "epoch 77; iter: 0; batch classifier loss: 0.089328; batch adversarial loss: 0.449415\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075988; batch adversarial loss: 0.475320\n",
      "epoch 79; iter: 0; batch classifier loss: 0.112862; batch adversarial loss: 0.388329\n",
      "epoch 80; iter: 0; batch classifier loss: 0.100821; batch adversarial loss: 0.504691\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120073; batch adversarial loss: 0.435671\n",
      "epoch 82; iter: 0; batch classifier loss: 0.116747; batch adversarial loss: 0.314720\n",
      "epoch 83; iter: 0; batch classifier loss: 0.171866; batch adversarial loss: 0.522084\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103977; batch adversarial loss: 0.401615\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074590; batch adversarial loss: 0.439105\n",
      "epoch 86; iter: 0; batch classifier loss: 0.092618; batch adversarial loss: 0.318180\n",
      "epoch 87; iter: 0; batch classifier loss: 0.075241; batch adversarial loss: 0.396410\n",
      "epoch 88; iter: 0; batch classifier loss: 0.137878; batch adversarial loss: 0.404509\n",
      "epoch 89; iter: 0; batch classifier loss: 0.121623; batch adversarial loss: 0.514842\n",
      "epoch 90; iter: 0; batch classifier loss: 0.140876; batch adversarial loss: 0.581666\n",
      "epoch 91; iter: 0; batch classifier loss: 0.086534; batch adversarial loss: 0.428752\n",
      "epoch 92; iter: 0; batch classifier loss: 0.053351; batch adversarial loss: 0.385118\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053188; batch adversarial loss: 0.355257\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083686; batch adversarial loss: 0.453843\n",
      "epoch 95; iter: 0; batch classifier loss: 0.075699; batch adversarial loss: 0.480158\n",
      "epoch 96; iter: 0; batch classifier loss: 0.099196; batch adversarial loss: 0.390530\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088710; batch adversarial loss: 0.495801\n",
      "epoch 98; iter: 0; batch classifier loss: 0.080656; batch adversarial loss: 0.467343\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045266; batch adversarial loss: 0.514386\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075747; batch adversarial loss: 0.403853\n",
      "epoch 101; iter: 0; batch classifier loss: 0.067984; batch adversarial loss: 0.400734\n",
      "epoch 102; iter: 0; batch classifier loss: 0.064199; batch adversarial loss: 0.326167\n",
      "epoch 103; iter: 0; batch classifier loss: 0.114369; batch adversarial loss: 0.505937\n",
      "epoch 104; iter: 0; batch classifier loss: 0.074472; batch adversarial loss: 0.523817\n",
      "epoch 105; iter: 0; batch classifier loss: 0.025140; batch adversarial loss: 0.381641\n",
      "epoch 106; iter: 0; batch classifier loss: 0.072508; batch adversarial loss: 0.429833\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058623; batch adversarial loss: 0.473526\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037248; batch adversarial loss: 0.407527\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047391; batch adversarial loss: 0.445921\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043094; batch adversarial loss: 0.331175\n",
      "epoch 111; iter: 0; batch classifier loss: 0.063902; batch adversarial loss: 0.447057\n",
      "epoch 112; iter: 0; batch classifier loss: 0.061565; batch adversarial loss: 0.375548\n",
      "epoch 113; iter: 0; batch classifier loss: 0.073969; batch adversarial loss: 0.401438\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061809; batch adversarial loss: 0.450777\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062500; batch adversarial loss: 0.430158\n",
      "epoch 116; iter: 0; batch classifier loss: 0.061937; batch adversarial loss: 0.496149\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033197; batch adversarial loss: 0.436455\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031885; batch adversarial loss: 0.445400\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054233; batch adversarial loss: 0.406449\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044352; batch adversarial loss: 0.418016\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045729; batch adversarial loss: 0.404046\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043047; batch adversarial loss: 0.416544\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028346; batch adversarial loss: 0.526660\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042528; batch adversarial loss: 0.507173\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034693; batch adversarial loss: 0.483448\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038635; batch adversarial loss: 0.399624\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030991; batch adversarial loss: 0.467135\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031202; batch adversarial loss: 0.484792\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040114; batch adversarial loss: 0.404929\n",
      "epoch 130; iter: 0; batch classifier loss: 0.071833; batch adversarial loss: 0.420364\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030353; batch adversarial loss: 0.518054\n",
      "epoch 132; iter: 0; batch classifier loss: 0.075211; batch adversarial loss: 0.495170\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031307; batch adversarial loss: 0.392328\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035123; batch adversarial loss: 0.418687\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045644; batch adversarial loss: 0.385793\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033588; batch adversarial loss: 0.370078\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032469; batch adversarial loss: 0.432458\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041979; batch adversarial loss: 0.512136\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046972; batch adversarial loss: 0.478839\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023820; batch adversarial loss: 0.520370\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025582; batch adversarial loss: 0.451546\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034070; batch adversarial loss: 0.476357\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026670; batch adversarial loss: 0.437070\n",
      "epoch 144; iter: 0; batch classifier loss: 0.042849; batch adversarial loss: 0.348310\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013641; batch adversarial loss: 0.472830\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021684; batch adversarial loss: 0.466017\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024191; batch adversarial loss: 0.401649\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020293; batch adversarial loss: 0.513203\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046331; batch adversarial loss: 0.436084\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038433; batch adversarial loss: 0.388129\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023552; batch adversarial loss: 0.569120\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033948; batch adversarial loss: 0.458673\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034162; batch adversarial loss: 0.489656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.004830; batch adversarial loss: 0.466278\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026658; batch adversarial loss: 0.480533\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044083; batch adversarial loss: 0.434861\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039384; batch adversarial loss: 0.424521\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036571; batch adversarial loss: 0.500564\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039669; batch adversarial loss: 0.460781\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010627; batch adversarial loss: 0.506714\n",
      "epoch 161; iter: 0; batch classifier loss: 0.041412; batch adversarial loss: 0.559534\n",
      "epoch 162; iter: 0; batch classifier loss: 0.058018; batch adversarial loss: 0.433491\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006154; batch adversarial loss: 0.397304\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020513; batch adversarial loss: 0.378752\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011941; batch adversarial loss: 0.481066\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032020; batch adversarial loss: 0.499505\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011051; batch adversarial loss: 0.467905\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008727; batch adversarial loss: 0.411247\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006774; batch adversarial loss: 0.395403\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013032; batch adversarial loss: 0.482864\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014363; batch adversarial loss: 0.524709\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026168; batch adversarial loss: 0.411803\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016362; batch adversarial loss: 0.391990\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017317; batch adversarial loss: 0.525146\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036721; batch adversarial loss: 0.430894\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013995; batch adversarial loss: 0.512384\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026744; batch adversarial loss: 0.528198\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023109; batch adversarial loss: 0.445674\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021857; batch adversarial loss: 0.491311\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020373; batch adversarial loss: 0.388023\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008585; batch adversarial loss: 0.480809\n",
      "epoch 182; iter: 0; batch classifier loss: 0.063647; batch adversarial loss: 0.391092\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026906; batch adversarial loss: 0.419799\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017093; batch adversarial loss: 0.405406\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042987; batch adversarial loss: 0.418917\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022227; batch adversarial loss: 0.354306\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009745; batch adversarial loss: 0.403882\n",
      "epoch 188; iter: 0; batch classifier loss: 0.037835; batch adversarial loss: 0.474564\n",
      "epoch 189; iter: 0; batch classifier loss: 0.005640; batch adversarial loss: 0.447311\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023394; batch adversarial loss: 0.454260\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033863; batch adversarial loss: 0.399186\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015637; batch adversarial loss: 0.441437\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025365; batch adversarial loss: 0.382202\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025911; batch adversarial loss: 0.492812\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020904; batch adversarial loss: 0.483149\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025461; batch adversarial loss: 0.463639\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039000; batch adversarial loss: 0.525502\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004532; batch adversarial loss: 0.405218\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016496; batch adversarial loss: 0.486755\n",
      "epoch 0; iter: 0; batch classifier loss: 0.757548; batch adversarial loss: 0.744198\n",
      "epoch 1; iter: 0; batch classifier loss: 0.456309; batch adversarial loss: 0.741886\n",
      "epoch 2; iter: 0; batch classifier loss: 0.467226; batch adversarial loss: 0.716441\n",
      "epoch 3; iter: 0; batch classifier loss: 0.390811; batch adversarial loss: 0.672298\n",
      "epoch 4; iter: 0; batch classifier loss: 0.333909; batch adversarial loss: 0.650035\n",
      "epoch 5; iter: 0; batch classifier loss: 0.337994; batch adversarial loss: 0.634822\n",
      "epoch 6; iter: 0; batch classifier loss: 0.381711; batch adversarial loss: 0.583974\n",
      "epoch 7; iter: 0; batch classifier loss: 0.348106; batch adversarial loss: 0.567668\n",
      "epoch 8; iter: 0; batch classifier loss: 0.280039; batch adversarial loss: 0.527875\n",
      "epoch 9; iter: 0; batch classifier loss: 0.255276; batch adversarial loss: 0.506995\n",
      "epoch 10; iter: 0; batch classifier loss: 0.224363; batch adversarial loss: 0.512810\n",
      "epoch 11; iter: 0; batch classifier loss: 0.267859; batch adversarial loss: 0.442322\n",
      "epoch 12; iter: 0; batch classifier loss: 0.186558; batch adversarial loss: 0.456659\n",
      "epoch 13; iter: 0; batch classifier loss: 0.170231; batch adversarial loss: 0.481635\n",
      "epoch 14; iter: 0; batch classifier loss: 0.210350; batch adversarial loss: 0.469416\n",
      "epoch 15; iter: 0; batch classifier loss: 0.218269; batch adversarial loss: 0.438827\n",
      "epoch 16; iter: 0; batch classifier loss: 0.218525; batch adversarial loss: 0.393277\n",
      "epoch 17; iter: 0; batch classifier loss: 0.206391; batch adversarial loss: 0.479434\n",
      "epoch 18; iter: 0; batch classifier loss: 0.291957; batch adversarial loss: 0.438566\n",
      "epoch 19; iter: 0; batch classifier loss: 0.185290; batch adversarial loss: 0.397176\n",
      "epoch 20; iter: 0; batch classifier loss: 0.196774; batch adversarial loss: 0.398687\n",
      "epoch 21; iter: 0; batch classifier loss: 0.141608; batch adversarial loss: 0.429732\n",
      "epoch 22; iter: 0; batch classifier loss: 0.142346; batch adversarial loss: 0.447115\n",
      "epoch 23; iter: 0; batch classifier loss: 0.177074; batch adversarial loss: 0.441456\n",
      "epoch 24; iter: 0; batch classifier loss: 0.205405; batch adversarial loss: 0.367197\n",
      "epoch 25; iter: 0; batch classifier loss: 0.202087; batch adversarial loss: 0.430093\n",
      "epoch 26; iter: 0; batch classifier loss: 0.155106; batch adversarial loss: 0.389864\n",
      "epoch 27; iter: 0; batch classifier loss: 0.147226; batch adversarial loss: 0.380896\n",
      "epoch 28; iter: 0; batch classifier loss: 0.204044; batch adversarial loss: 0.392424\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197982; batch adversarial loss: 0.443173\n",
      "epoch 30; iter: 0; batch classifier loss: 0.123079; batch adversarial loss: 0.510939\n",
      "epoch 31; iter: 0; batch classifier loss: 0.205686; batch adversarial loss: 0.477724\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154902; batch adversarial loss: 0.406431\n",
      "epoch 33; iter: 0; batch classifier loss: 0.154522; batch adversarial loss: 0.419085\n",
      "epoch 34; iter: 0; batch classifier loss: 0.130199; batch adversarial loss: 0.439201\n",
      "epoch 35; iter: 0; batch classifier loss: 0.141701; batch adversarial loss: 0.459075\n",
      "epoch 36; iter: 0; batch classifier loss: 0.167724; batch adversarial loss: 0.367652\n",
      "epoch 37; iter: 0; batch classifier loss: 0.131857; batch adversarial loss: 0.421822\n",
      "epoch 38; iter: 0; batch classifier loss: 0.165879; batch adversarial loss: 0.432068\n",
      "epoch 39; iter: 0; batch classifier loss: 0.127814; batch adversarial loss: 0.402396\n",
      "epoch 40; iter: 0; batch classifier loss: 0.136320; batch adversarial loss: 0.459330\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104176; batch adversarial loss: 0.483385\n",
      "epoch 42; iter: 0; batch classifier loss: 0.089304; batch adversarial loss: 0.415529\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104305; batch adversarial loss: 0.383990\n",
      "epoch 44; iter: 0; batch classifier loss: 0.094175; batch adversarial loss: 0.427303\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097720; batch adversarial loss: 0.367529\n",
      "epoch 46; iter: 0; batch classifier loss: 0.106621; batch adversarial loss: 0.487331\n",
      "epoch 47; iter: 0; batch classifier loss: 0.181794; batch adversarial loss: 0.452308\n",
      "epoch 48; iter: 0; batch classifier loss: 0.102062; batch adversarial loss: 0.513463\n",
      "epoch 49; iter: 0; batch classifier loss: 0.083727; batch adversarial loss: 0.404485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.070433; batch adversarial loss: 0.335147\n",
      "epoch 51; iter: 0; batch classifier loss: 0.146958; batch adversarial loss: 0.404380\n",
      "epoch 52; iter: 0; batch classifier loss: 0.063313; batch adversarial loss: 0.493131\n",
      "epoch 53; iter: 0; batch classifier loss: 0.080225; batch adversarial loss: 0.499722\n",
      "epoch 54; iter: 0; batch classifier loss: 0.093495; batch adversarial loss: 0.473473\n",
      "epoch 55; iter: 0; batch classifier loss: 0.162251; batch adversarial loss: 0.444360\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081426; batch adversarial loss: 0.510139\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073145; batch adversarial loss: 0.386560\n",
      "epoch 58; iter: 0; batch classifier loss: 0.074811; batch adversarial loss: 0.349112\n",
      "epoch 59; iter: 0; batch classifier loss: 0.050309; batch adversarial loss: 0.397046\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065699; batch adversarial loss: 0.397325\n",
      "epoch 61; iter: 0; batch classifier loss: 0.076708; batch adversarial loss: 0.393795\n",
      "epoch 62; iter: 0; batch classifier loss: 0.115826; batch adversarial loss: 0.378373\n",
      "epoch 63; iter: 0; batch classifier loss: 0.051824; batch adversarial loss: 0.378950\n",
      "epoch 64; iter: 0; batch classifier loss: 0.134912; batch adversarial loss: 0.460399\n",
      "epoch 65; iter: 0; batch classifier loss: 0.130074; batch adversarial loss: 0.474500\n",
      "epoch 66; iter: 0; batch classifier loss: 0.107306; batch adversarial loss: 0.448977\n",
      "epoch 67; iter: 0; batch classifier loss: 0.075829; batch adversarial loss: 0.456635\n",
      "epoch 68; iter: 0; batch classifier loss: 0.065780; batch adversarial loss: 0.423644\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094700; batch adversarial loss: 0.416521\n",
      "epoch 70; iter: 0; batch classifier loss: 0.072060; batch adversarial loss: 0.445657\n",
      "epoch 71; iter: 0; batch classifier loss: 0.091227; batch adversarial loss: 0.442250\n",
      "epoch 72; iter: 0; batch classifier loss: 0.061115; batch adversarial loss: 0.427149\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087504; batch adversarial loss: 0.402458\n",
      "epoch 74; iter: 0; batch classifier loss: 0.094965; batch adversarial loss: 0.496580\n",
      "epoch 75; iter: 0; batch classifier loss: 0.100047; batch adversarial loss: 0.397957\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064392; batch adversarial loss: 0.379512\n",
      "epoch 77; iter: 0; batch classifier loss: 0.040154; batch adversarial loss: 0.455067\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079656; batch adversarial loss: 0.498190\n",
      "epoch 79; iter: 0; batch classifier loss: 0.108583; batch adversarial loss: 0.436062\n",
      "epoch 80; iter: 0; batch classifier loss: 0.058923; batch adversarial loss: 0.419003\n",
      "epoch 81; iter: 0; batch classifier loss: 0.046355; batch adversarial loss: 0.428177\n",
      "epoch 82; iter: 0; batch classifier loss: 0.055496; batch adversarial loss: 0.360570\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078472; batch adversarial loss: 0.422048\n",
      "epoch 84; iter: 0; batch classifier loss: 0.039433; batch adversarial loss: 0.395031\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070230; batch adversarial loss: 0.448323\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072265; batch adversarial loss: 0.364859\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048245; batch adversarial loss: 0.505524\n",
      "epoch 88; iter: 0; batch classifier loss: 0.066558; batch adversarial loss: 0.476118\n",
      "epoch 89; iter: 0; batch classifier loss: 0.070799; batch adversarial loss: 0.516552\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045072; batch adversarial loss: 0.380781\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050192; batch adversarial loss: 0.499350\n",
      "epoch 92; iter: 0; batch classifier loss: 0.039087; batch adversarial loss: 0.495082\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080849; batch adversarial loss: 0.387250\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062109; batch adversarial loss: 0.497617\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045234; batch adversarial loss: 0.432322\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048778; batch adversarial loss: 0.316799\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076659; batch adversarial loss: 0.443387\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042521; batch adversarial loss: 0.382325\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044177; batch adversarial loss: 0.369735\n",
      "epoch 100; iter: 0; batch classifier loss: 0.089467; batch adversarial loss: 0.512194\n",
      "epoch 101; iter: 0; batch classifier loss: 0.033711; batch adversarial loss: 0.471017\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032255; batch adversarial loss: 0.454643\n",
      "epoch 103; iter: 0; batch classifier loss: 0.028280; batch adversarial loss: 0.391858\n",
      "epoch 104; iter: 0; batch classifier loss: 0.022207; batch adversarial loss: 0.429202\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048827; batch adversarial loss: 0.521927\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047929; batch adversarial loss: 0.494308\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028952; batch adversarial loss: 0.489992\n",
      "epoch 108; iter: 0; batch classifier loss: 0.021980; batch adversarial loss: 0.453619\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057600; batch adversarial loss: 0.489971\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047890; batch adversarial loss: 0.414275\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029551; batch adversarial loss: 0.420612\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026683; batch adversarial loss: 0.428782\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048515; batch adversarial loss: 0.457282\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037930; batch adversarial loss: 0.516612\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022990; batch adversarial loss: 0.407367\n",
      "epoch 116; iter: 0; batch classifier loss: 0.047063; batch adversarial loss: 0.468774\n",
      "epoch 117; iter: 0; batch classifier loss: 0.054322; batch adversarial loss: 0.502019\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025678; batch adversarial loss: 0.482739\n",
      "epoch 119; iter: 0; batch classifier loss: 0.017281; batch adversarial loss: 0.525294\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043237; batch adversarial loss: 0.547087\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030519; batch adversarial loss: 0.445043\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049994; batch adversarial loss: 0.420411\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024295; batch adversarial loss: 0.409698\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021716; batch adversarial loss: 0.405301\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018430; batch adversarial loss: 0.539203\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020963; batch adversarial loss: 0.480940\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047856; batch adversarial loss: 0.530740\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024170; batch adversarial loss: 0.534783\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031990; batch adversarial loss: 0.381777\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040212; batch adversarial loss: 0.433136\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043760; batch adversarial loss: 0.456923\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050963; batch adversarial loss: 0.403311\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027698; batch adversarial loss: 0.457022\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023723; batch adversarial loss: 0.473719\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040944; batch adversarial loss: 0.440612\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028812; batch adversarial loss: 0.491543\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023194; batch adversarial loss: 0.398285\n",
      "epoch 138; iter: 0; batch classifier loss: 0.012717; batch adversarial loss: 0.447589\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043440; batch adversarial loss: 0.485180\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033211; batch adversarial loss: 0.456605\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032130; batch adversarial loss: 0.480009\n",
      "epoch 142; iter: 0; batch classifier loss: 0.053095; batch adversarial loss: 0.565458\n",
      "epoch 143; iter: 0; batch classifier loss: 0.045309; batch adversarial loss: 0.490689\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014198; batch adversarial loss: 0.485902\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014288; batch adversarial loss: 0.502623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.048350; batch adversarial loss: 0.527000\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024996; batch adversarial loss: 0.467016\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042297; batch adversarial loss: 0.543372\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024526; batch adversarial loss: 0.460061\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023790; batch adversarial loss: 0.454134\n",
      "epoch 151; iter: 0; batch classifier loss: 0.065446; batch adversarial loss: 0.551904\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037353; batch adversarial loss: 0.496059\n",
      "epoch 153; iter: 0; batch classifier loss: 0.099671; batch adversarial loss: 0.665215\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043216; batch adversarial loss: 0.371065\n",
      "epoch 155; iter: 0; batch classifier loss: 0.094897; batch adversarial loss: 0.697904\n",
      "epoch 156; iter: 0; batch classifier loss: 0.154443; batch adversarial loss: 0.672886\n",
      "epoch 157; iter: 0; batch classifier loss: 0.071201; batch adversarial loss: 0.566209\n",
      "epoch 158; iter: 0; batch classifier loss: 0.083665; batch adversarial loss: 0.615709\n",
      "epoch 159; iter: 0; batch classifier loss: 0.175197; batch adversarial loss: 0.706006\n",
      "epoch 160; iter: 0; batch classifier loss: 0.087892; batch adversarial loss: 0.748815\n",
      "epoch 161; iter: 0; batch classifier loss: 0.242736; batch adversarial loss: 0.850210\n",
      "epoch 162; iter: 0; batch classifier loss: 0.156889; batch adversarial loss: 0.677841\n",
      "epoch 163; iter: 0; batch classifier loss: 0.127639; batch adversarial loss: 0.618568\n",
      "epoch 164; iter: 0; batch classifier loss: 0.178575; batch adversarial loss: 0.741178\n",
      "epoch 165; iter: 0; batch classifier loss: 0.182816; batch adversarial loss: 0.711015\n",
      "epoch 166; iter: 0; batch classifier loss: 0.199337; batch adversarial loss: 0.778924\n",
      "epoch 167; iter: 0; batch classifier loss: 0.180032; batch adversarial loss: 0.833148\n",
      "epoch 168; iter: 0; batch classifier loss: 0.264291; batch adversarial loss: 0.716132\n",
      "epoch 169; iter: 0; batch classifier loss: 0.154816; batch adversarial loss: 0.600651\n",
      "epoch 170; iter: 0; batch classifier loss: 0.272587; batch adversarial loss: 0.811345\n",
      "epoch 171; iter: 0; batch classifier loss: 0.109451; batch adversarial loss: 0.531327\n",
      "epoch 172; iter: 0; batch classifier loss: 0.217729; batch adversarial loss: 0.716264\n",
      "epoch 173; iter: 0; batch classifier loss: 0.143412; batch adversarial loss: 0.680128\n",
      "epoch 174; iter: 0; batch classifier loss: 0.132134; batch adversarial loss: 0.525971\n",
      "epoch 175; iter: 0; batch classifier loss: 0.175838; batch adversarial loss: 0.619387\n",
      "epoch 176; iter: 0; batch classifier loss: 0.132547; batch adversarial loss: 0.602329\n",
      "epoch 177; iter: 0; batch classifier loss: 0.121536; batch adversarial loss: 0.571863\n",
      "epoch 178; iter: 0; batch classifier loss: 0.164504; batch adversarial loss: 0.551906\n",
      "epoch 179; iter: 0; batch classifier loss: 0.116772; batch adversarial loss: 0.557254\n",
      "epoch 180; iter: 0; batch classifier loss: 0.145611; batch adversarial loss: 0.534236\n",
      "epoch 181; iter: 0; batch classifier loss: 0.213949; batch adversarial loss: 0.647249\n",
      "epoch 182; iter: 0; batch classifier loss: 0.106656; batch adversarial loss: 0.480552\n",
      "epoch 183; iter: 0; batch classifier loss: 0.232854; batch adversarial loss: 0.681132\n",
      "epoch 184; iter: 0; batch classifier loss: 0.124934; batch adversarial loss: 0.499151\n",
      "epoch 185; iter: 0; batch classifier loss: 0.215171; batch adversarial loss: 0.636583\n",
      "epoch 186; iter: 0; batch classifier loss: 0.127384; batch adversarial loss: 0.478855\n",
      "epoch 187; iter: 0; batch classifier loss: 0.160007; batch adversarial loss: 0.630411\n",
      "epoch 188; iter: 0; batch classifier loss: 0.135476; batch adversarial loss: 0.505244\n",
      "epoch 189; iter: 0; batch classifier loss: 0.127299; batch adversarial loss: 0.518956\n",
      "epoch 190; iter: 0; batch classifier loss: 0.182341; batch adversarial loss: 0.657075\n",
      "epoch 191; iter: 0; batch classifier loss: 0.123779; batch adversarial loss: 0.519033\n",
      "epoch 192; iter: 0; batch classifier loss: 0.157948; batch adversarial loss: 0.518280\n",
      "epoch 193; iter: 0; batch classifier loss: 0.117487; batch adversarial loss: 0.530234\n",
      "epoch 194; iter: 0; batch classifier loss: 0.150850; batch adversarial loss: 0.547813\n",
      "epoch 195; iter: 0; batch classifier loss: 0.113969; batch adversarial loss: 0.525024\n",
      "epoch 196; iter: 0; batch classifier loss: 0.133039; batch adversarial loss: 0.522225\n",
      "epoch 197; iter: 0; batch classifier loss: 0.130340; batch adversarial loss: 0.495202\n",
      "epoch 198; iter: 0; batch classifier loss: 0.130389; batch adversarial loss: 0.547787\n",
      "epoch 199; iter: 0; batch classifier loss: 0.085822; batch adversarial loss: 0.450761\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689120; batch adversarial loss: 0.601329\n",
      "epoch 1; iter: 0; batch classifier loss: 0.492705; batch adversarial loss: 0.635701\n",
      "epoch 2; iter: 0; batch classifier loss: 0.381189; batch adversarial loss: 0.604272\n",
      "epoch 3; iter: 0; batch classifier loss: 0.445426; batch adversarial loss: 0.606126\n",
      "epoch 4; iter: 0; batch classifier loss: 0.445832; batch adversarial loss: 0.616384\n",
      "epoch 5; iter: 0; batch classifier loss: 0.443602; batch adversarial loss: 0.624008\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513749; batch adversarial loss: 0.559184\n",
      "epoch 7; iter: 0; batch classifier loss: 0.627816; batch adversarial loss: 0.571962\n",
      "epoch 8; iter: 0; batch classifier loss: 0.465826; batch adversarial loss: 0.563095\n",
      "epoch 9; iter: 0; batch classifier loss: 0.460530; batch adversarial loss: 0.526662\n",
      "epoch 10; iter: 0; batch classifier loss: 0.346402; batch adversarial loss: 0.539654\n",
      "epoch 11; iter: 0; batch classifier loss: 0.363494; batch adversarial loss: 0.542944\n",
      "epoch 12; iter: 0; batch classifier loss: 0.381468; batch adversarial loss: 0.478753\n",
      "epoch 13; iter: 0; batch classifier loss: 0.317496; batch adversarial loss: 0.473390\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302537; batch adversarial loss: 0.473928\n",
      "epoch 15; iter: 0; batch classifier loss: 0.244028; batch adversarial loss: 0.528902\n",
      "epoch 16; iter: 0; batch classifier loss: 0.352056; batch adversarial loss: 0.476928\n",
      "epoch 17; iter: 0; batch classifier loss: 0.243429; batch adversarial loss: 0.496211\n",
      "epoch 18; iter: 0; batch classifier loss: 0.290296; batch adversarial loss: 0.532330\n",
      "epoch 19; iter: 0; batch classifier loss: 0.217596; batch adversarial loss: 0.439933\n",
      "epoch 20; iter: 0; batch classifier loss: 0.253715; batch adversarial loss: 0.380566\n",
      "epoch 21; iter: 0; batch classifier loss: 0.273032; batch adversarial loss: 0.417612\n",
      "epoch 22; iter: 0; batch classifier loss: 0.186634; batch adversarial loss: 0.448424\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203518; batch adversarial loss: 0.446122\n",
      "epoch 24; iter: 0; batch classifier loss: 0.198367; batch adversarial loss: 0.524404\n",
      "epoch 25; iter: 0; batch classifier loss: 0.155963; batch adversarial loss: 0.494884\n",
      "epoch 26; iter: 0; batch classifier loss: 0.228167; batch adversarial loss: 0.436463\n",
      "epoch 27; iter: 0; batch classifier loss: 0.161509; batch adversarial loss: 0.498574\n",
      "epoch 28; iter: 0; batch classifier loss: 0.196884; batch adversarial loss: 0.436687\n",
      "epoch 29; iter: 0; batch classifier loss: 0.148468; batch adversarial loss: 0.526400\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167328; batch adversarial loss: 0.510483\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141272; batch adversarial loss: 0.496928\n",
      "epoch 32; iter: 0; batch classifier loss: 0.158792; batch adversarial loss: 0.466423\n",
      "epoch 33; iter: 0; batch classifier loss: 0.139635; batch adversarial loss: 0.440420\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148404; batch adversarial loss: 0.423633\n",
      "epoch 35; iter: 0; batch classifier loss: 0.143400; batch adversarial loss: 0.435660\n",
      "epoch 36; iter: 0; batch classifier loss: 0.081639; batch adversarial loss: 0.527795\n",
      "epoch 37; iter: 0; batch classifier loss: 0.193863; batch adversarial loss: 0.466321\n",
      "epoch 38; iter: 0; batch classifier loss: 0.175962; batch adversarial loss: 0.512312\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131992; batch adversarial loss: 0.375298\n",
      "epoch 40; iter: 0; batch classifier loss: 0.172417; batch adversarial loss: 0.455502\n",
      "epoch 41; iter: 0; batch classifier loss: 0.161513; batch adversarial loss: 0.487436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.139055; batch adversarial loss: 0.449557\n",
      "epoch 43; iter: 0; batch classifier loss: 0.187238; batch adversarial loss: 0.444375\n",
      "epoch 44; iter: 0; batch classifier loss: 0.164250; batch adversarial loss: 0.413047\n",
      "epoch 45; iter: 0; batch classifier loss: 0.116042; batch adversarial loss: 0.471787\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086138; batch adversarial loss: 0.532261\n",
      "epoch 47; iter: 0; batch classifier loss: 0.115647; batch adversarial loss: 0.548247\n",
      "epoch 48; iter: 0; batch classifier loss: 0.121574; batch adversarial loss: 0.410952\n",
      "epoch 49; iter: 0; batch classifier loss: 0.150626; batch adversarial loss: 0.472562\n",
      "epoch 50; iter: 0; batch classifier loss: 0.202001; batch adversarial loss: 0.390459\n",
      "epoch 51; iter: 0; batch classifier loss: 0.160919; batch adversarial loss: 0.439223\n",
      "epoch 52; iter: 0; batch classifier loss: 0.228432; batch adversarial loss: 0.427605\n",
      "epoch 53; iter: 0; batch classifier loss: 0.107801; batch adversarial loss: 0.556725\n",
      "epoch 54; iter: 0; batch classifier loss: 0.147031; batch adversarial loss: 0.445422\n",
      "epoch 55; iter: 0; batch classifier loss: 0.144422; batch adversarial loss: 0.452507\n",
      "epoch 56; iter: 0; batch classifier loss: 0.126604; batch adversarial loss: 0.465406\n",
      "epoch 57; iter: 0; batch classifier loss: 0.166077; batch adversarial loss: 0.500743\n",
      "epoch 58; iter: 0; batch classifier loss: 0.156474; batch adversarial loss: 0.485203\n",
      "epoch 59; iter: 0; batch classifier loss: 0.156101; batch adversarial loss: 0.383677\n",
      "epoch 60; iter: 0; batch classifier loss: 0.189628; batch adversarial loss: 0.484433\n",
      "epoch 61; iter: 0; batch classifier loss: 0.150132; batch adversarial loss: 0.415022\n",
      "epoch 62; iter: 0; batch classifier loss: 0.154252; batch adversarial loss: 0.447124\n",
      "epoch 63; iter: 0; batch classifier loss: 0.141881; batch adversarial loss: 0.508914\n",
      "epoch 64; iter: 0; batch classifier loss: 0.174076; batch adversarial loss: 0.457793\n",
      "epoch 65; iter: 0; batch classifier loss: 0.164287; batch adversarial loss: 0.437341\n",
      "epoch 66; iter: 0; batch classifier loss: 0.160408; batch adversarial loss: 0.557493\n",
      "epoch 67; iter: 0; batch classifier loss: 0.111802; batch adversarial loss: 0.528636\n",
      "epoch 68; iter: 0; batch classifier loss: 0.136649; batch adversarial loss: 0.450862\n",
      "epoch 69; iter: 0; batch classifier loss: 0.176566; batch adversarial loss: 0.506394\n",
      "epoch 70; iter: 0; batch classifier loss: 0.150464; batch adversarial loss: 0.424602\n",
      "epoch 71; iter: 0; batch classifier loss: 0.113295; batch adversarial loss: 0.553315\n",
      "epoch 72; iter: 0; batch classifier loss: 0.147758; batch adversarial loss: 0.506995\n",
      "epoch 73; iter: 0; batch classifier loss: 0.140358; batch adversarial loss: 0.490783\n",
      "epoch 74; iter: 0; batch classifier loss: 0.134668; batch adversarial loss: 0.467880\n",
      "epoch 75; iter: 0; batch classifier loss: 0.163223; batch adversarial loss: 0.467266\n",
      "epoch 76; iter: 0; batch classifier loss: 0.224435; batch adversarial loss: 0.456886\n",
      "epoch 77; iter: 0; batch classifier loss: 0.164073; batch adversarial loss: 0.501984\n",
      "epoch 78; iter: 0; batch classifier loss: 0.119820; batch adversarial loss: 0.500391\n",
      "epoch 79; iter: 0; batch classifier loss: 0.172394; batch adversarial loss: 0.554097\n",
      "epoch 80; iter: 0; batch classifier loss: 0.117395; batch adversarial loss: 0.477992\n",
      "epoch 81; iter: 0; batch classifier loss: 0.141870; batch adversarial loss: 0.460977\n",
      "epoch 82; iter: 0; batch classifier loss: 0.146247; batch adversarial loss: 0.541545\n",
      "epoch 83; iter: 0; batch classifier loss: 0.182907; batch adversarial loss: 0.512293\n",
      "epoch 84; iter: 0; batch classifier loss: 0.122371; batch adversarial loss: 0.399713\n",
      "epoch 85; iter: 0; batch classifier loss: 0.177661; batch adversarial loss: 0.431620\n",
      "epoch 86; iter: 0; batch classifier loss: 0.096986; batch adversarial loss: 0.375097\n",
      "epoch 87; iter: 0; batch classifier loss: 0.134350; batch adversarial loss: 0.505041\n",
      "epoch 88; iter: 0; batch classifier loss: 0.096151; batch adversarial loss: 0.453100\n",
      "epoch 89; iter: 0; batch classifier loss: 0.166627; batch adversarial loss: 0.443732\n",
      "epoch 90; iter: 0; batch classifier loss: 0.109788; batch adversarial loss: 0.607000\n",
      "epoch 91; iter: 0; batch classifier loss: 0.076523; batch adversarial loss: 0.497979\n",
      "epoch 92; iter: 0; batch classifier loss: 0.186199; batch adversarial loss: 0.504032\n",
      "epoch 93; iter: 0; batch classifier loss: 0.149410; batch adversarial loss: 0.541412\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083962; batch adversarial loss: 0.534920\n",
      "epoch 95; iter: 0; batch classifier loss: 0.116299; batch adversarial loss: 0.414004\n",
      "epoch 96; iter: 0; batch classifier loss: 0.112727; batch adversarial loss: 0.431414\n",
      "epoch 97; iter: 0; batch classifier loss: 0.085413; batch adversarial loss: 0.477491\n",
      "epoch 98; iter: 0; batch classifier loss: 0.075422; batch adversarial loss: 0.408617\n",
      "epoch 99; iter: 0; batch classifier loss: 0.089251; batch adversarial loss: 0.481401\n",
      "epoch 100; iter: 0; batch classifier loss: 0.088841; batch adversarial loss: 0.421967\n",
      "epoch 101; iter: 0; batch classifier loss: 0.028002; batch adversarial loss: 0.487388\n",
      "epoch 102; iter: 0; batch classifier loss: 0.096266; batch adversarial loss: 0.376397\n",
      "epoch 103; iter: 0; batch classifier loss: 0.077521; batch adversarial loss: 0.543381\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073953; batch adversarial loss: 0.432694\n",
      "epoch 105; iter: 0; batch classifier loss: 0.087598; batch adversarial loss: 0.420407\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062230; batch adversarial loss: 0.468674\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035657; batch adversarial loss: 0.443069\n",
      "epoch 108; iter: 0; batch classifier loss: 0.066113; batch adversarial loss: 0.444919\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038913; batch adversarial loss: 0.467180\n",
      "epoch 110; iter: 0; batch classifier loss: 0.087839; batch adversarial loss: 0.510460\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051773; batch adversarial loss: 0.388476\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025096; batch adversarial loss: 0.519047\n",
      "epoch 113; iter: 0; batch classifier loss: 0.067808; batch adversarial loss: 0.412653\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047351; batch adversarial loss: 0.433588\n",
      "epoch 115; iter: 0; batch classifier loss: 0.092419; batch adversarial loss: 0.434289\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055028; batch adversarial loss: 0.494947\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048810; batch adversarial loss: 0.428464\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047236; batch adversarial loss: 0.461147\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053566; batch adversarial loss: 0.386348\n",
      "epoch 120; iter: 0; batch classifier loss: 0.026759; batch adversarial loss: 0.486468\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050523; batch adversarial loss: 0.388945\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042933; batch adversarial loss: 0.399054\n",
      "epoch 123; iter: 0; batch classifier loss: 0.062856; batch adversarial loss: 0.430216\n",
      "epoch 124; iter: 0; batch classifier loss: 0.072976; batch adversarial loss: 0.468119\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027325; batch adversarial loss: 0.481992\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044250; batch adversarial loss: 0.437321\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050241; batch adversarial loss: 0.467697\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058048; batch adversarial loss: 0.608620\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041563; batch adversarial loss: 0.554737\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040276; batch adversarial loss: 0.498062\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055435; batch adversarial loss: 0.442131\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033317; batch adversarial loss: 0.521052\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019461; batch adversarial loss: 0.542778\n",
      "epoch 134; iter: 0; batch classifier loss: 0.055164; batch adversarial loss: 0.471593\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024059; batch adversarial loss: 0.438220\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026243; batch adversarial loss: 0.471106\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034347; batch adversarial loss: 0.470505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.059895; batch adversarial loss: 0.469493\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020852; batch adversarial loss: 0.441214\n",
      "epoch 140; iter: 0; batch classifier loss: 0.054628; batch adversarial loss: 0.495192\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053161; batch adversarial loss: 0.396071\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021224; batch adversarial loss: 0.477843\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019017; batch adversarial loss: 0.482264\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029866; batch adversarial loss: 0.510584\n",
      "epoch 145; iter: 0; batch classifier loss: 0.092038; batch adversarial loss: 0.363731\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039480; batch adversarial loss: 0.425784\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032117; batch adversarial loss: 0.543824\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036419; batch adversarial loss: 0.453530\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026773; batch adversarial loss: 0.392369\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030245; batch adversarial loss: 0.492022\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025600; batch adversarial loss: 0.498133\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034488; batch adversarial loss: 0.467647\n",
      "epoch 153; iter: 0; batch classifier loss: 0.053138; batch adversarial loss: 0.495386\n",
      "epoch 154; iter: 0; batch classifier loss: 0.008821; batch adversarial loss: 0.463055\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025626; batch adversarial loss: 0.378098\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019888; batch adversarial loss: 0.432274\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019976; batch adversarial loss: 0.430357\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026116; batch adversarial loss: 0.451731\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012465; batch adversarial loss: 0.471840\n",
      "epoch 160; iter: 0; batch classifier loss: 0.056514; batch adversarial loss: 0.504771\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017131; batch adversarial loss: 0.418566\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011237; batch adversarial loss: 0.499901\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022319; batch adversarial loss: 0.480625\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020321; batch adversarial loss: 0.465746\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029138; batch adversarial loss: 0.496378\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023500; batch adversarial loss: 0.407123\n",
      "epoch 167; iter: 0; batch classifier loss: 0.066186; batch adversarial loss: 0.516850\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035126; batch adversarial loss: 0.520544\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024074; batch adversarial loss: 0.440213\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036920; batch adversarial loss: 0.388774\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016408; batch adversarial loss: 0.511461\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018553; batch adversarial loss: 0.494388\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042141; batch adversarial loss: 0.516234\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027802; batch adversarial loss: 0.512682\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028523; batch adversarial loss: 0.526435\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011994; batch adversarial loss: 0.441277\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014445; batch adversarial loss: 0.417151\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008816; batch adversarial loss: 0.408181\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020351; batch adversarial loss: 0.443957\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020633; batch adversarial loss: 0.474354\n",
      "epoch 181; iter: 0; batch classifier loss: 0.004871; batch adversarial loss: 0.465356\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031618; batch adversarial loss: 0.453187\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031690; batch adversarial loss: 0.424299\n",
      "epoch 184; iter: 0; batch classifier loss: 0.064271; batch adversarial loss: 0.563502\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038933; batch adversarial loss: 0.477211\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012659; batch adversarial loss: 0.445685\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018596; batch adversarial loss: 0.363855\n",
      "epoch 188; iter: 0; batch classifier loss: 0.038725; batch adversarial loss: 0.353101\n",
      "epoch 189; iter: 0; batch classifier loss: 0.038888; batch adversarial loss: 0.401376\n",
      "epoch 190; iter: 0; batch classifier loss: 0.044287; batch adversarial loss: 0.480159\n",
      "epoch 191; iter: 0; batch classifier loss: 0.004112; batch adversarial loss: 0.520443\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019051; batch adversarial loss: 0.492485\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026728; batch adversarial loss: 0.433605\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013706; batch adversarial loss: 0.422760\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005780; batch adversarial loss: 0.522939\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017389; batch adversarial loss: 0.388941\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032823; batch adversarial loss: 0.451238\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004414; batch adversarial loss: 0.509349\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005925; batch adversarial loss: 0.373152\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720328; batch adversarial loss: 0.874135\n",
      "epoch 1; iter: 0; batch classifier loss: 0.504941; batch adversarial loss: 0.857058\n",
      "epoch 2; iter: 0; batch classifier loss: 0.432818; batch adversarial loss: 0.830482\n",
      "epoch 3; iter: 0; batch classifier loss: 0.455596; batch adversarial loss: 0.747760\n",
      "epoch 4; iter: 0; batch classifier loss: 0.317347; batch adversarial loss: 0.689377\n",
      "epoch 5; iter: 0; batch classifier loss: 0.399784; batch adversarial loss: 0.663873\n",
      "epoch 6; iter: 0; batch classifier loss: 0.387152; batch adversarial loss: 0.622987\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306363; batch adversarial loss: 0.631446\n",
      "epoch 8; iter: 0; batch classifier loss: 0.315529; batch adversarial loss: 0.581233\n",
      "epoch 9; iter: 0; batch classifier loss: 0.344430; batch adversarial loss: 0.569451\n",
      "epoch 10; iter: 0; batch classifier loss: 0.199239; batch adversarial loss: 0.532044\n",
      "epoch 11; iter: 0; batch classifier loss: 0.317160; batch adversarial loss: 0.544198\n",
      "epoch 12; iter: 0; batch classifier loss: 0.259348; batch adversarial loss: 0.555784\n",
      "epoch 13; iter: 0; batch classifier loss: 0.218725; batch adversarial loss: 0.497717\n",
      "epoch 14; iter: 0; batch classifier loss: 0.276741; batch adversarial loss: 0.485611\n",
      "epoch 15; iter: 0; batch classifier loss: 0.247081; batch adversarial loss: 0.491327\n",
      "epoch 16; iter: 0; batch classifier loss: 0.205921; batch adversarial loss: 0.454215\n",
      "epoch 17; iter: 0; batch classifier loss: 0.215668; batch adversarial loss: 0.504196\n",
      "epoch 18; iter: 0; batch classifier loss: 0.219297; batch adversarial loss: 0.529409\n",
      "epoch 19; iter: 0; batch classifier loss: 0.241913; batch adversarial loss: 0.438739\n",
      "epoch 20; iter: 0; batch classifier loss: 0.238532; batch adversarial loss: 0.394353\n",
      "epoch 21; iter: 0; batch classifier loss: 0.211727; batch adversarial loss: 0.405079\n",
      "epoch 22; iter: 0; batch classifier loss: 0.310545; batch adversarial loss: 0.345159\n",
      "epoch 23; iter: 0; batch classifier loss: 0.204668; batch adversarial loss: 0.470072\n",
      "epoch 24; iter: 0; batch classifier loss: 0.170945; batch adversarial loss: 0.550651\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132648; batch adversarial loss: 0.457048\n",
      "epoch 26; iter: 0; batch classifier loss: 0.160764; batch adversarial loss: 0.400142\n",
      "epoch 27; iter: 0; batch classifier loss: 0.138194; batch adversarial loss: 0.430397\n",
      "epoch 28; iter: 0; batch classifier loss: 0.190515; batch adversarial loss: 0.468229\n",
      "epoch 29; iter: 0; batch classifier loss: 0.174140; batch adversarial loss: 0.380403\n",
      "epoch 30; iter: 0; batch classifier loss: 0.146805; batch adversarial loss: 0.453476\n",
      "epoch 31; iter: 0; batch classifier loss: 0.176665; batch adversarial loss: 0.440981\n",
      "epoch 32; iter: 0; batch classifier loss: 0.198991; batch adversarial loss: 0.354925\n",
      "epoch 33; iter: 0; batch classifier loss: 0.168013; batch adversarial loss: 0.382894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.171512; batch adversarial loss: 0.433338\n",
      "epoch 35; iter: 0; batch classifier loss: 0.139134; batch adversarial loss: 0.392349\n",
      "epoch 36; iter: 0; batch classifier loss: 0.168787; batch adversarial loss: 0.455068\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113370; batch adversarial loss: 0.452744\n",
      "epoch 38; iter: 0; batch classifier loss: 0.111520; batch adversarial loss: 0.356273\n",
      "epoch 39; iter: 0; batch classifier loss: 0.136165; batch adversarial loss: 0.497882\n",
      "epoch 40; iter: 0; batch classifier loss: 0.208287; batch adversarial loss: 0.334640\n",
      "epoch 41; iter: 0; batch classifier loss: 0.180966; batch adversarial loss: 0.420369\n",
      "epoch 42; iter: 0; batch classifier loss: 0.185846; batch adversarial loss: 0.429070\n",
      "epoch 43; iter: 0; batch classifier loss: 0.103869; batch adversarial loss: 0.349863\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124893; batch adversarial loss: 0.445505\n",
      "epoch 45; iter: 0; batch classifier loss: 0.129830; batch adversarial loss: 0.459310\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112746; batch adversarial loss: 0.416561\n",
      "epoch 47; iter: 0; batch classifier loss: 0.151612; batch adversarial loss: 0.384762\n",
      "epoch 48; iter: 0; batch classifier loss: 0.111663; batch adversarial loss: 0.458557\n",
      "epoch 49; iter: 0; batch classifier loss: 0.105729; batch adversarial loss: 0.391626\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111081; batch adversarial loss: 0.436007\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109273; batch adversarial loss: 0.395736\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082364; batch adversarial loss: 0.398025\n",
      "epoch 53; iter: 0; batch classifier loss: 0.144547; batch adversarial loss: 0.456319\n",
      "epoch 54; iter: 0; batch classifier loss: 0.136941; batch adversarial loss: 0.467151\n",
      "epoch 55; iter: 0; batch classifier loss: 0.112276; batch adversarial loss: 0.469380\n",
      "epoch 56; iter: 0; batch classifier loss: 0.097193; batch adversarial loss: 0.450659\n",
      "epoch 57; iter: 0; batch classifier loss: 0.155699; batch adversarial loss: 0.404362\n",
      "epoch 58; iter: 0; batch classifier loss: 0.114389; batch adversarial loss: 0.451564\n",
      "epoch 59; iter: 0; batch classifier loss: 0.057978; batch adversarial loss: 0.368476\n",
      "epoch 60; iter: 0; batch classifier loss: 0.085373; batch adversarial loss: 0.428014\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091931; batch adversarial loss: 0.420938\n",
      "epoch 62; iter: 0; batch classifier loss: 0.124097; batch adversarial loss: 0.547187\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100000; batch adversarial loss: 0.447862\n",
      "epoch 64; iter: 0; batch classifier loss: 0.123270; batch adversarial loss: 0.448432\n",
      "epoch 65; iter: 0; batch classifier loss: 0.102442; batch adversarial loss: 0.464147\n",
      "epoch 66; iter: 0; batch classifier loss: 0.053379; batch adversarial loss: 0.333213\n",
      "epoch 67; iter: 0; batch classifier loss: 0.159121; batch adversarial loss: 0.405173\n",
      "epoch 68; iter: 0; batch classifier loss: 0.127537; batch adversarial loss: 0.317879\n",
      "epoch 69; iter: 0; batch classifier loss: 0.092897; batch adversarial loss: 0.491009\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070525; batch adversarial loss: 0.508969\n",
      "epoch 71; iter: 0; batch classifier loss: 0.060598; batch adversarial loss: 0.391983\n",
      "epoch 72; iter: 0; batch classifier loss: 0.063539; batch adversarial loss: 0.429100\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087390; batch adversarial loss: 0.470903\n",
      "epoch 74; iter: 0; batch classifier loss: 0.061182; batch adversarial loss: 0.433864\n",
      "epoch 75; iter: 0; batch classifier loss: 0.070551; batch adversarial loss: 0.434902\n",
      "epoch 76; iter: 0; batch classifier loss: 0.087546; batch adversarial loss: 0.381298\n",
      "epoch 77; iter: 0; batch classifier loss: 0.138931; batch adversarial loss: 0.354505\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082481; batch adversarial loss: 0.418763\n",
      "epoch 79; iter: 0; batch classifier loss: 0.083736; batch adversarial loss: 0.507755\n",
      "epoch 80; iter: 0; batch classifier loss: 0.108865; batch adversarial loss: 0.418472\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077729; batch adversarial loss: 0.406692\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083326; batch adversarial loss: 0.487281\n",
      "epoch 83; iter: 0; batch classifier loss: 0.088334; batch adversarial loss: 0.492196\n",
      "epoch 84; iter: 0; batch classifier loss: 0.099457; batch adversarial loss: 0.434497\n",
      "epoch 85; iter: 0; batch classifier loss: 0.102220; batch adversarial loss: 0.454385\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084767; batch adversarial loss: 0.442609\n",
      "epoch 87; iter: 0; batch classifier loss: 0.108051; batch adversarial loss: 0.417195\n",
      "epoch 88; iter: 0; batch classifier loss: 0.081361; batch adversarial loss: 0.442461\n",
      "epoch 89; iter: 0; batch classifier loss: 0.120210; batch adversarial loss: 0.486064\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068907; batch adversarial loss: 0.432906\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074164; batch adversarial loss: 0.402632\n",
      "epoch 92; iter: 0; batch classifier loss: 0.078558; batch adversarial loss: 0.354324\n",
      "epoch 93; iter: 0; batch classifier loss: 0.095306; batch adversarial loss: 0.440689\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075001; batch adversarial loss: 0.374456\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056261; batch adversarial loss: 0.437603\n",
      "epoch 96; iter: 0; batch classifier loss: 0.089223; batch adversarial loss: 0.393467\n",
      "epoch 97; iter: 0; batch classifier loss: 0.091360; batch adversarial loss: 0.444698\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067294; batch adversarial loss: 0.459683\n",
      "epoch 99; iter: 0; batch classifier loss: 0.110236; batch adversarial loss: 0.451279\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076525; batch adversarial loss: 0.411370\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051073; batch adversarial loss: 0.420418\n",
      "epoch 102; iter: 0; batch classifier loss: 0.073701; batch adversarial loss: 0.399374\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078999; batch adversarial loss: 0.433173\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057091; batch adversarial loss: 0.441112\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053520; batch adversarial loss: 0.434638\n",
      "epoch 106; iter: 0; batch classifier loss: 0.074458; batch adversarial loss: 0.427615\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059995; batch adversarial loss: 0.442878\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055006; batch adversarial loss: 0.427621\n",
      "epoch 109; iter: 0; batch classifier loss: 0.088709; batch adversarial loss: 0.463462\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058232; batch adversarial loss: 0.399372\n",
      "epoch 111; iter: 0; batch classifier loss: 0.078800; batch adversarial loss: 0.522021\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063751; batch adversarial loss: 0.354047\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045974; batch adversarial loss: 0.467859\n",
      "epoch 114; iter: 0; batch classifier loss: 0.090740; batch adversarial loss: 0.420818\n",
      "epoch 115; iter: 0; batch classifier loss: 0.069921; batch adversarial loss: 0.419526\n",
      "epoch 116; iter: 0; batch classifier loss: 0.095360; batch adversarial loss: 0.388808\n",
      "epoch 117; iter: 0; batch classifier loss: 0.077256; batch adversarial loss: 0.524761\n",
      "epoch 118; iter: 0; batch classifier loss: 0.066834; batch adversarial loss: 0.474331\n",
      "epoch 119; iter: 0; batch classifier loss: 0.074196; batch adversarial loss: 0.367041\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047170; batch adversarial loss: 0.382365\n",
      "epoch 121; iter: 0; batch classifier loss: 0.069042; batch adversarial loss: 0.440415\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049620; batch adversarial loss: 0.484273\n",
      "epoch 123; iter: 0; batch classifier loss: 0.077012; batch adversarial loss: 0.446972\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067192; batch adversarial loss: 0.442106\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058801; batch adversarial loss: 0.442955\n",
      "epoch 126; iter: 0; batch classifier loss: 0.053509; batch adversarial loss: 0.512308\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027778; batch adversarial loss: 0.506944\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042206; batch adversarial loss: 0.466210\n",
      "epoch 129; iter: 0; batch classifier loss: 0.068542; batch adversarial loss: 0.400770\n",
      "epoch 130; iter: 0; batch classifier loss: 0.067648; batch adversarial loss: 0.454802\n",
      "epoch 131; iter: 0; batch classifier loss: 0.083583; batch adversarial loss: 0.433228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.078418; batch adversarial loss: 0.393685\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032618; batch adversarial loss: 0.471945\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053953; batch adversarial loss: 0.427294\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032462; batch adversarial loss: 0.459641\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049737; batch adversarial loss: 0.466766\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026815; batch adversarial loss: 0.477710\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031398; batch adversarial loss: 0.455033\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043724; batch adversarial loss: 0.494988\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022775; batch adversarial loss: 0.502782\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045188; batch adversarial loss: 0.427572\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032683; batch adversarial loss: 0.507260\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028975; batch adversarial loss: 0.409684\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052133; batch adversarial loss: 0.459395\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033314; batch adversarial loss: 0.433667\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021535; batch adversarial loss: 0.484019\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038282; batch adversarial loss: 0.439894\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034291; batch adversarial loss: 0.428717\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038687; batch adversarial loss: 0.435265\n",
      "epoch 150; iter: 0; batch classifier loss: 0.051728; batch adversarial loss: 0.460139\n",
      "epoch 151; iter: 0; batch classifier loss: 0.065086; batch adversarial loss: 0.558662\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044513; batch adversarial loss: 0.528887\n",
      "epoch 153; iter: 0; batch classifier loss: 0.049975; batch adversarial loss: 0.598008\n",
      "epoch 154; iter: 0; batch classifier loss: 0.048360; batch adversarial loss: 0.462510\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024651; batch adversarial loss: 0.493380\n",
      "epoch 156; iter: 0; batch classifier loss: 0.143521; batch adversarial loss: 0.743630\n",
      "epoch 157; iter: 0; batch classifier loss: 0.129768; batch adversarial loss: 0.680392\n",
      "epoch 158; iter: 0; batch classifier loss: 0.136405; batch adversarial loss: 0.679449\n",
      "epoch 159; iter: 0; batch classifier loss: 0.136557; batch adversarial loss: 0.686830\n",
      "epoch 160; iter: 0; batch classifier loss: 0.207398; batch adversarial loss: 0.771380\n",
      "epoch 161; iter: 0; batch classifier loss: 0.169904; batch adversarial loss: 0.757529\n",
      "epoch 162; iter: 0; batch classifier loss: 0.141463; batch adversarial loss: 0.631072\n",
      "epoch 163; iter: 0; batch classifier loss: 0.158762; batch adversarial loss: 0.654724\n",
      "epoch 164; iter: 0; batch classifier loss: 0.228934; batch adversarial loss: 0.860999\n",
      "epoch 165; iter: 0; batch classifier loss: 0.171620; batch adversarial loss: 0.578002\n",
      "epoch 166; iter: 0; batch classifier loss: 0.169199; batch adversarial loss: 0.752176\n",
      "epoch 167; iter: 0; batch classifier loss: 0.181637; batch adversarial loss: 0.722310\n",
      "epoch 168; iter: 0; batch classifier loss: 0.227656; batch adversarial loss: 0.732891\n",
      "epoch 169; iter: 0; batch classifier loss: 0.156600; batch adversarial loss: 0.581464\n",
      "epoch 170; iter: 0; batch classifier loss: 0.188534; batch adversarial loss: 0.699243\n",
      "epoch 171; iter: 0; batch classifier loss: 0.173804; batch adversarial loss: 0.632912\n",
      "epoch 172; iter: 0; batch classifier loss: 0.177045; batch adversarial loss: 0.646975\n",
      "epoch 173; iter: 0; batch classifier loss: 0.161437; batch adversarial loss: 0.571861\n",
      "epoch 174; iter: 0; batch classifier loss: 0.174886; batch adversarial loss: 0.647830\n",
      "epoch 175; iter: 0; batch classifier loss: 0.174954; batch adversarial loss: 0.649093\n",
      "epoch 176; iter: 0; batch classifier loss: 0.172442; batch adversarial loss: 0.525357\n",
      "epoch 177; iter: 0; batch classifier loss: 0.168266; batch adversarial loss: 0.634761\n",
      "epoch 178; iter: 0; batch classifier loss: 0.222549; batch adversarial loss: 0.757071\n",
      "epoch 179; iter: 0; batch classifier loss: 0.180598; batch adversarial loss: 0.624853\n",
      "epoch 180; iter: 0; batch classifier loss: 0.123935; batch adversarial loss: 0.513954\n",
      "epoch 181; iter: 0; batch classifier loss: 0.145825; batch adversarial loss: 0.545409\n",
      "epoch 182; iter: 0; batch classifier loss: 0.170516; batch adversarial loss: 0.560841\n",
      "epoch 183; iter: 0; batch classifier loss: 0.113446; batch adversarial loss: 0.472837\n",
      "epoch 184; iter: 0; batch classifier loss: 0.176950; batch adversarial loss: 0.567412\n",
      "epoch 185; iter: 0; batch classifier loss: 0.199144; batch adversarial loss: 0.722418\n",
      "epoch 186; iter: 0; batch classifier loss: 0.196881; batch adversarial loss: 0.591200\n",
      "epoch 187; iter: 0; batch classifier loss: 0.234942; batch adversarial loss: 0.631428\n",
      "epoch 188; iter: 0; batch classifier loss: 0.221934; batch adversarial loss: 0.716363\n",
      "epoch 189; iter: 0; batch classifier loss: 0.179665; batch adversarial loss: 0.550630\n",
      "epoch 190; iter: 0; batch classifier loss: 0.170134; batch adversarial loss: 0.551951\n",
      "epoch 191; iter: 0; batch classifier loss: 0.084288; batch adversarial loss: 0.490543\n",
      "epoch 192; iter: 0; batch classifier loss: 0.179041; batch adversarial loss: 0.582427\n",
      "epoch 193; iter: 0; batch classifier loss: 0.127209; batch adversarial loss: 0.503307\n",
      "epoch 194; iter: 0; batch classifier loss: 0.112819; batch adversarial loss: 0.445976\n",
      "epoch 195; iter: 0; batch classifier loss: 0.174809; batch adversarial loss: 0.605518\n",
      "epoch 196; iter: 0; batch classifier loss: 0.181456; batch adversarial loss: 0.605316\n",
      "epoch 197; iter: 0; batch classifier loss: 0.133363; batch adversarial loss: 0.568300\n",
      "epoch 198; iter: 0; batch classifier loss: 0.139912; batch adversarial loss: 0.490634\n",
      "epoch 199; iter: 0; batch classifier loss: 0.123002; batch adversarial loss: 0.452816\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692871; batch adversarial loss: 0.633288\n",
      "epoch 1; iter: 0; batch classifier loss: 0.411215; batch adversarial loss: 0.616462\n",
      "epoch 2; iter: 0; batch classifier loss: 0.323377; batch adversarial loss: 0.599143\n",
      "epoch 3; iter: 0; batch classifier loss: 0.292899; batch adversarial loss: 0.587730\n",
      "epoch 4; iter: 0; batch classifier loss: 0.316667; batch adversarial loss: 0.574347\n",
      "epoch 5; iter: 0; batch classifier loss: 0.314236; batch adversarial loss: 0.527293\n",
      "epoch 6; iter: 0; batch classifier loss: 0.303071; batch adversarial loss: 0.513970\n",
      "epoch 7; iter: 0; batch classifier loss: 0.230183; batch adversarial loss: 0.543889\n",
      "epoch 8; iter: 0; batch classifier loss: 0.309228; batch adversarial loss: 0.525767\n",
      "epoch 9; iter: 0; batch classifier loss: 0.266924; batch adversarial loss: 0.500569\n",
      "epoch 10; iter: 0; batch classifier loss: 0.203270; batch adversarial loss: 0.490121\n",
      "epoch 11; iter: 0; batch classifier loss: 0.201257; batch adversarial loss: 0.477515\n",
      "epoch 12; iter: 0; batch classifier loss: 0.237504; batch adversarial loss: 0.526996\n",
      "epoch 13; iter: 0; batch classifier loss: 0.221830; batch adversarial loss: 0.503312\n",
      "epoch 14; iter: 0; batch classifier loss: 0.246881; batch adversarial loss: 0.471882\n",
      "epoch 15; iter: 0; batch classifier loss: 0.226602; batch adversarial loss: 0.483700\n",
      "epoch 16; iter: 0; batch classifier loss: 0.256849; batch adversarial loss: 0.483222\n",
      "epoch 17; iter: 0; batch classifier loss: 0.338149; batch adversarial loss: 0.526620\n",
      "epoch 18; iter: 0; batch classifier loss: 0.286886; batch adversarial loss: 0.496523\n",
      "epoch 19; iter: 0; batch classifier loss: 0.392781; batch adversarial loss: 0.516566\n",
      "epoch 20; iter: 0; batch classifier loss: 0.365424; batch adversarial loss: 0.531785\n",
      "epoch 21; iter: 0; batch classifier loss: 0.554965; batch adversarial loss: 0.497587\n",
      "epoch 22; iter: 0; batch classifier loss: 0.339253; batch adversarial loss: 0.421699\n",
      "epoch 23; iter: 0; batch classifier loss: 0.239097; batch adversarial loss: 0.437819\n",
      "epoch 24; iter: 0; batch classifier loss: 0.173234; batch adversarial loss: 0.438056\n",
      "epoch 25; iter: 0; batch classifier loss: 0.212623; batch adversarial loss: 0.433122\n",
      "epoch 26; iter: 0; batch classifier loss: 0.154197; batch adversarial loss: 0.458805\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178975; batch adversarial loss: 0.466159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.162063; batch adversarial loss: 0.419041\n",
      "epoch 29; iter: 0; batch classifier loss: 0.130900; batch adversarial loss: 0.396334\n",
      "epoch 30; iter: 0; batch classifier loss: 0.137304; batch adversarial loss: 0.444467\n",
      "epoch 31; iter: 0; batch classifier loss: 0.133014; batch adversarial loss: 0.458813\n",
      "epoch 32; iter: 0; batch classifier loss: 0.130556; batch adversarial loss: 0.447608\n",
      "epoch 33; iter: 0; batch classifier loss: 0.098669; batch adversarial loss: 0.517515\n",
      "epoch 34; iter: 0; batch classifier loss: 0.100540; batch adversarial loss: 0.432345\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129734; batch adversarial loss: 0.462532\n",
      "epoch 36; iter: 0; batch classifier loss: 0.093705; batch adversarial loss: 0.488487\n",
      "epoch 37; iter: 0; batch classifier loss: 0.116742; batch adversarial loss: 0.505703\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148571; batch adversarial loss: 0.431611\n",
      "epoch 39; iter: 0; batch classifier loss: 0.095525; batch adversarial loss: 0.489714\n",
      "epoch 40; iter: 0; batch classifier loss: 0.106338; batch adversarial loss: 0.523381\n",
      "epoch 41; iter: 0; batch classifier loss: 0.107102; batch adversarial loss: 0.346705\n",
      "epoch 42; iter: 0; batch classifier loss: 0.153845; batch adversarial loss: 0.450784\n",
      "epoch 43; iter: 0; batch classifier loss: 0.140153; batch adversarial loss: 0.495821\n",
      "epoch 44; iter: 0; batch classifier loss: 0.115370; batch adversarial loss: 0.438956\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089573; batch adversarial loss: 0.379947\n",
      "epoch 46; iter: 0; batch classifier loss: 0.084911; batch adversarial loss: 0.383633\n",
      "epoch 47; iter: 0; batch classifier loss: 0.144798; batch adversarial loss: 0.397822\n",
      "epoch 48; iter: 0; batch classifier loss: 0.133710; batch adversarial loss: 0.477953\n",
      "epoch 49; iter: 0; batch classifier loss: 0.151538; batch adversarial loss: 0.476796\n",
      "epoch 50; iter: 0; batch classifier loss: 0.115743; batch adversarial loss: 0.466031\n",
      "epoch 51; iter: 0; batch classifier loss: 0.116765; batch adversarial loss: 0.482793\n",
      "epoch 52; iter: 0; batch classifier loss: 0.174246; batch adversarial loss: 0.413110\n",
      "epoch 53; iter: 0; batch classifier loss: 0.091132; batch adversarial loss: 0.571452\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108614; batch adversarial loss: 0.414816\n",
      "epoch 55; iter: 0; batch classifier loss: 0.165967; batch adversarial loss: 0.476448\n",
      "epoch 56; iter: 0; batch classifier loss: 0.167830; batch adversarial loss: 0.436191\n",
      "epoch 57; iter: 0; batch classifier loss: 0.175566; batch adversarial loss: 0.327358\n",
      "epoch 58; iter: 0; batch classifier loss: 0.106648; batch adversarial loss: 0.451052\n",
      "epoch 59; iter: 0; batch classifier loss: 0.113936; batch adversarial loss: 0.452545\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122098; batch adversarial loss: 0.456448\n",
      "epoch 61; iter: 0; batch classifier loss: 0.145675; batch adversarial loss: 0.357867\n",
      "epoch 62; iter: 0; batch classifier loss: 0.124265; batch adversarial loss: 0.406413\n",
      "epoch 63; iter: 0; batch classifier loss: 0.143231; batch adversarial loss: 0.482883\n",
      "epoch 64; iter: 0; batch classifier loss: 0.146698; batch adversarial loss: 0.422900\n",
      "epoch 65; iter: 0; batch classifier loss: 0.132935; batch adversarial loss: 0.463043\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088848; batch adversarial loss: 0.394587\n",
      "epoch 67; iter: 0; batch classifier loss: 0.142037; batch adversarial loss: 0.450229\n",
      "epoch 68; iter: 0; batch classifier loss: 0.136109; batch adversarial loss: 0.485066\n",
      "epoch 69; iter: 0; batch classifier loss: 0.085427; batch adversarial loss: 0.380531\n",
      "epoch 70; iter: 0; batch classifier loss: 0.107731; batch adversarial loss: 0.403288\n",
      "epoch 71; iter: 0; batch classifier loss: 0.156163; batch adversarial loss: 0.495999\n",
      "epoch 72; iter: 0; batch classifier loss: 0.165109; batch adversarial loss: 0.411785\n",
      "epoch 73; iter: 0; batch classifier loss: 0.140448; batch adversarial loss: 0.435242\n",
      "epoch 74; iter: 0; batch classifier loss: 0.113822; batch adversarial loss: 0.411132\n",
      "epoch 75; iter: 0; batch classifier loss: 0.119866; batch adversarial loss: 0.501728\n",
      "epoch 76; iter: 0; batch classifier loss: 0.111863; batch adversarial loss: 0.471890\n",
      "epoch 77; iter: 0; batch classifier loss: 0.110872; batch adversarial loss: 0.467845\n",
      "epoch 78; iter: 0; batch classifier loss: 0.159022; batch adversarial loss: 0.438941\n",
      "epoch 79; iter: 0; batch classifier loss: 0.125944; batch adversarial loss: 0.468988\n",
      "epoch 80; iter: 0; batch classifier loss: 0.096428; batch adversarial loss: 0.407272\n",
      "epoch 81; iter: 0; batch classifier loss: 0.138398; batch adversarial loss: 0.505414\n",
      "epoch 82; iter: 0; batch classifier loss: 0.106739; batch adversarial loss: 0.420131\n",
      "epoch 83; iter: 0; batch classifier loss: 0.144149; batch adversarial loss: 0.425276\n",
      "epoch 84; iter: 0; batch classifier loss: 0.087694; batch adversarial loss: 0.351946\n",
      "epoch 85; iter: 0; batch classifier loss: 0.089394; batch adversarial loss: 0.442877\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081486; batch adversarial loss: 0.483124\n",
      "epoch 87; iter: 0; batch classifier loss: 0.120802; batch adversarial loss: 0.446252\n",
      "epoch 88; iter: 0; batch classifier loss: 0.138185; batch adversarial loss: 0.434669\n",
      "epoch 89; iter: 0; batch classifier loss: 0.113110; batch adversarial loss: 0.502113\n",
      "epoch 90; iter: 0; batch classifier loss: 0.142016; batch adversarial loss: 0.475880\n",
      "epoch 91; iter: 0; batch classifier loss: 0.173128; batch adversarial loss: 0.440893\n",
      "epoch 92; iter: 0; batch classifier loss: 0.141611; batch adversarial loss: 0.471807\n",
      "epoch 93; iter: 0; batch classifier loss: 0.159197; batch adversarial loss: 0.427786\n",
      "epoch 94; iter: 0; batch classifier loss: 0.119152; batch adversarial loss: 0.345337\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070833; batch adversarial loss: 0.392783\n",
      "epoch 96; iter: 0; batch classifier loss: 0.095479; batch adversarial loss: 0.450872\n",
      "epoch 97; iter: 0; batch classifier loss: 0.124017; batch adversarial loss: 0.478950\n",
      "epoch 98; iter: 0; batch classifier loss: 0.075425; batch adversarial loss: 0.499093\n",
      "epoch 99; iter: 0; batch classifier loss: 0.087543; batch adversarial loss: 0.422192\n",
      "epoch 100; iter: 0; batch classifier loss: 0.114375; batch adversarial loss: 0.473414\n",
      "epoch 101; iter: 0; batch classifier loss: 0.137769; batch adversarial loss: 0.406477\n",
      "epoch 102; iter: 0; batch classifier loss: 0.113737; batch adversarial loss: 0.401038\n",
      "epoch 103; iter: 0; batch classifier loss: 0.144500; batch adversarial loss: 0.436099\n",
      "epoch 104; iter: 0; batch classifier loss: 0.108327; batch adversarial loss: 0.381910\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066433; batch adversarial loss: 0.502794\n",
      "epoch 106; iter: 0; batch classifier loss: 0.099724; batch adversarial loss: 0.422464\n",
      "epoch 107; iter: 0; batch classifier loss: 0.064758; batch adversarial loss: 0.461306\n",
      "epoch 108; iter: 0; batch classifier loss: 0.098898; batch adversarial loss: 0.592738\n",
      "epoch 109; iter: 0; batch classifier loss: 0.089471; batch adversarial loss: 0.480075\n",
      "epoch 110; iter: 0; batch classifier loss: 0.095573; batch adversarial loss: 0.463402\n",
      "epoch 111; iter: 0; batch classifier loss: 0.072577; batch adversarial loss: 0.447673\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043848; batch adversarial loss: 0.505854\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057851; batch adversarial loss: 0.414527\n",
      "epoch 114; iter: 0; batch classifier loss: 0.088306; batch adversarial loss: 0.339140\n",
      "epoch 115; iter: 0; batch classifier loss: 0.067850; batch adversarial loss: 0.424673\n",
      "epoch 116; iter: 0; batch classifier loss: 0.106018; batch adversarial loss: 0.546667\n",
      "epoch 117; iter: 0; batch classifier loss: 0.083545; batch adversarial loss: 0.491672\n",
      "epoch 118; iter: 0; batch classifier loss: 0.070192; batch adversarial loss: 0.429678\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073167; batch adversarial loss: 0.470331\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053988; batch adversarial loss: 0.492624\n",
      "epoch 121; iter: 0; batch classifier loss: 0.072240; batch adversarial loss: 0.539327\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062912; batch adversarial loss: 0.517604\n",
      "epoch 123; iter: 0; batch classifier loss: 0.056422; batch adversarial loss: 0.397163\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044658; batch adversarial loss: 0.452517\n",
      "epoch 125; iter: 0; batch classifier loss: 0.094152; batch adversarial loss: 0.393720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.039814; batch adversarial loss: 0.510168\n",
      "epoch 127; iter: 0; batch classifier loss: 0.090396; batch adversarial loss: 0.499311\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036582; batch adversarial loss: 0.442365\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034686; batch adversarial loss: 0.359083\n",
      "epoch 130; iter: 0; batch classifier loss: 0.062343; batch adversarial loss: 0.459809\n",
      "epoch 131; iter: 0; batch classifier loss: 0.072882; batch adversarial loss: 0.506683\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033700; batch adversarial loss: 0.441798\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046047; batch adversarial loss: 0.479657\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052646; batch adversarial loss: 0.461112\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047987; batch adversarial loss: 0.514281\n",
      "epoch 136; iter: 0; batch classifier loss: 0.055411; batch adversarial loss: 0.544644\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043628; batch adversarial loss: 0.365726\n",
      "epoch 138; iter: 0; batch classifier loss: 0.087649; batch adversarial loss: 0.513602\n",
      "epoch 139; iter: 0; batch classifier loss: 0.070320; batch adversarial loss: 0.423254\n",
      "epoch 140; iter: 0; batch classifier loss: 0.056946; batch adversarial loss: 0.444703\n",
      "epoch 141; iter: 0; batch classifier loss: 0.059745; batch adversarial loss: 0.460119\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014415; batch adversarial loss: 0.543975\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034831; batch adversarial loss: 0.370329\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038207; batch adversarial loss: 0.513499\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031202; batch adversarial loss: 0.467545\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034969; batch adversarial loss: 0.426416\n",
      "epoch 147; iter: 0; batch classifier loss: 0.077181; batch adversarial loss: 0.455989\n",
      "epoch 148; iter: 0; batch classifier loss: 0.063576; batch adversarial loss: 0.454850\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051875; batch adversarial loss: 0.420589\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020848; batch adversarial loss: 0.398445\n",
      "epoch 151; iter: 0; batch classifier loss: 0.064651; batch adversarial loss: 0.519424\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018495; batch adversarial loss: 0.468965\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038979; batch adversarial loss: 0.390820\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023199; batch adversarial loss: 0.457726\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022952; batch adversarial loss: 0.500510\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031713; batch adversarial loss: 0.506241\n",
      "epoch 157; iter: 0; batch classifier loss: 0.053657; batch adversarial loss: 0.389182\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023283; batch adversarial loss: 0.375696\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031041; batch adversarial loss: 0.512969\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030570; batch adversarial loss: 0.504096\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040283; batch adversarial loss: 0.403537\n",
      "epoch 162; iter: 0; batch classifier loss: 0.051997; batch adversarial loss: 0.485842\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023965; batch adversarial loss: 0.436861\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025991; batch adversarial loss: 0.406570\n",
      "epoch 165; iter: 0; batch classifier loss: 0.053398; batch adversarial loss: 0.388223\n",
      "epoch 166; iter: 0; batch classifier loss: 0.067166; batch adversarial loss: 0.358114\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025468; batch adversarial loss: 0.360082\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012205; batch adversarial loss: 0.401781\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008506; batch adversarial loss: 0.453406\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019190; batch adversarial loss: 0.433867\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022053; batch adversarial loss: 0.458700\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026523; batch adversarial loss: 0.449997\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012228; batch adversarial loss: 0.400247\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041522; batch adversarial loss: 0.470982\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013416; batch adversarial loss: 0.330630\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030140; batch adversarial loss: 0.490535\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018754; batch adversarial loss: 0.433890\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015137; batch adversarial loss: 0.527779\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022215; batch adversarial loss: 0.390937\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031207; batch adversarial loss: 0.462274\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017951; batch adversarial loss: 0.531279\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019089; batch adversarial loss: 0.491922\n",
      "epoch 183; iter: 0; batch classifier loss: 0.044718; batch adversarial loss: 0.525719\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024610; batch adversarial loss: 0.393113\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012579; batch adversarial loss: 0.458664\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021881; batch adversarial loss: 0.427373\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032640; batch adversarial loss: 0.377666\n",
      "epoch 188; iter: 0; batch classifier loss: 0.036575; batch adversarial loss: 0.484017\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021632; batch adversarial loss: 0.494047\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016638; batch adversarial loss: 0.433855\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017364; batch adversarial loss: 0.423234\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029991; batch adversarial loss: 0.469832\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021225; batch adversarial loss: 0.408104\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016498; batch adversarial loss: 0.506772\n",
      "epoch 195; iter: 0; batch classifier loss: 0.007791; batch adversarial loss: 0.517852\n",
      "epoch 196; iter: 0; batch classifier loss: 0.046630; batch adversarial loss: 0.412081\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025193; batch adversarial loss: 0.531504\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038857; batch adversarial loss: 0.429126\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019527; batch adversarial loss: 0.392353\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729063; batch adversarial loss: 0.624474\n",
      "epoch 1; iter: 0; batch classifier loss: 0.408020; batch adversarial loss: 0.632956\n",
      "epoch 2; iter: 0; batch classifier loss: 0.452808; batch adversarial loss: 0.609968\n",
      "epoch 3; iter: 0; batch classifier loss: 0.344958; batch adversarial loss: 0.587662\n",
      "epoch 4; iter: 0; batch classifier loss: 0.447833; batch adversarial loss: 0.578764\n",
      "epoch 5; iter: 0; batch classifier loss: 0.447221; batch adversarial loss: 0.575573\n",
      "epoch 6; iter: 0; batch classifier loss: 0.501891; batch adversarial loss: 0.596331\n",
      "epoch 7; iter: 0; batch classifier loss: 0.507118; batch adversarial loss: 0.605372\n",
      "epoch 8; iter: 0; batch classifier loss: 0.439874; batch adversarial loss: 0.555926\n",
      "epoch 9; iter: 0; batch classifier loss: 0.401777; batch adversarial loss: 0.546133\n",
      "epoch 10; iter: 0; batch classifier loss: 0.396954; batch adversarial loss: 0.581402\n",
      "epoch 11; iter: 0; batch classifier loss: 0.385955; batch adversarial loss: 0.571321\n",
      "epoch 12; iter: 0; batch classifier loss: 0.379603; batch adversarial loss: 0.530648\n",
      "epoch 13; iter: 0; batch classifier loss: 0.354167; batch adversarial loss: 0.520221\n",
      "epoch 14; iter: 0; batch classifier loss: 0.278932; batch adversarial loss: 0.561240\n",
      "epoch 15; iter: 0; batch classifier loss: 0.248875; batch adversarial loss: 0.532913\n",
      "epoch 16; iter: 0; batch classifier loss: 0.264850; batch adversarial loss: 0.575267\n",
      "epoch 17; iter: 0; batch classifier loss: 0.314042; batch adversarial loss: 0.495833\n",
      "epoch 18; iter: 0; batch classifier loss: 0.277672; batch adversarial loss: 0.465977\n",
      "epoch 19; iter: 0; batch classifier loss: 0.229036; batch adversarial loss: 0.450629\n",
      "epoch 20; iter: 0; batch classifier loss: 0.206340; batch adversarial loss: 0.425629\n",
      "epoch 21; iter: 0; batch classifier loss: 0.201158; batch adversarial loss: 0.486784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.246142; batch adversarial loss: 0.495868\n",
      "epoch 23; iter: 0; batch classifier loss: 0.156505; batch adversarial loss: 0.515672\n",
      "epoch 24; iter: 0; batch classifier loss: 0.217929; batch adversarial loss: 0.484571\n",
      "epoch 25; iter: 0; batch classifier loss: 0.222791; batch adversarial loss: 0.535552\n",
      "epoch 26; iter: 0; batch classifier loss: 0.196483; batch adversarial loss: 0.498223\n",
      "epoch 27; iter: 0; batch classifier loss: 0.197231; batch adversarial loss: 0.482779\n",
      "epoch 28; iter: 0; batch classifier loss: 0.182375; batch adversarial loss: 0.623035\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197989; batch adversarial loss: 0.515697\n",
      "epoch 30; iter: 0; batch classifier loss: 0.195031; batch adversarial loss: 0.567223\n",
      "epoch 31; iter: 0; batch classifier loss: 0.239791; batch adversarial loss: 0.447277\n",
      "epoch 32; iter: 0; batch classifier loss: 0.229242; batch adversarial loss: 0.448938\n",
      "epoch 33; iter: 0; batch classifier loss: 0.265887; batch adversarial loss: 0.444945\n",
      "epoch 34; iter: 0; batch classifier loss: 0.231465; batch adversarial loss: 0.439357\n",
      "epoch 35; iter: 0; batch classifier loss: 0.195168; batch adversarial loss: 0.480328\n",
      "epoch 36; iter: 0; batch classifier loss: 0.216335; batch adversarial loss: 0.478773\n",
      "epoch 37; iter: 0; batch classifier loss: 0.267180; batch adversarial loss: 0.441047\n",
      "epoch 38; iter: 0; batch classifier loss: 0.230171; batch adversarial loss: 0.435939\n",
      "epoch 39; iter: 0; batch classifier loss: 0.230019; batch adversarial loss: 0.460814\n",
      "epoch 40; iter: 0; batch classifier loss: 0.229766; batch adversarial loss: 0.409359\n",
      "epoch 41; iter: 0; batch classifier loss: 0.201123; batch adversarial loss: 0.471986\n",
      "epoch 42; iter: 0; batch classifier loss: 0.249082; batch adversarial loss: 0.454722\n",
      "epoch 43; iter: 0; batch classifier loss: 0.196626; batch adversarial loss: 0.420300\n",
      "epoch 44; iter: 0; batch classifier loss: 0.252314; batch adversarial loss: 0.533756\n",
      "epoch 45; iter: 0; batch classifier loss: 0.199192; batch adversarial loss: 0.406794\n",
      "epoch 46; iter: 0; batch classifier loss: 0.163384; batch adversarial loss: 0.474762\n",
      "epoch 47; iter: 0; batch classifier loss: 0.242462; batch adversarial loss: 0.437946\n",
      "epoch 48; iter: 0; batch classifier loss: 0.261953; batch adversarial loss: 0.391977\n",
      "epoch 49; iter: 0; batch classifier loss: 0.220753; batch adversarial loss: 0.471259\n",
      "epoch 50; iter: 0; batch classifier loss: 0.301349; batch adversarial loss: 0.495255\n",
      "epoch 51; iter: 0; batch classifier loss: 0.162198; batch adversarial loss: 0.436582\n",
      "epoch 52; iter: 0; batch classifier loss: 0.255506; batch adversarial loss: 0.528154\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098632; batch adversarial loss: 0.551480\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097213; batch adversarial loss: 0.433062\n",
      "epoch 55; iter: 0; batch classifier loss: 0.080330; batch adversarial loss: 0.453275\n",
      "epoch 56; iter: 0; batch classifier loss: 0.059479; batch adversarial loss: 0.444478\n",
      "epoch 57; iter: 0; batch classifier loss: 0.115241; batch adversarial loss: 0.447875\n",
      "epoch 58; iter: 0; batch classifier loss: 0.092636; batch adversarial loss: 0.449594\n",
      "epoch 59; iter: 0; batch classifier loss: 0.149366; batch adversarial loss: 0.339884\n",
      "epoch 60; iter: 0; batch classifier loss: 0.172869; batch adversarial loss: 0.524380\n",
      "epoch 61; iter: 0; batch classifier loss: 0.143006; batch adversarial loss: 0.490236\n",
      "epoch 62; iter: 0; batch classifier loss: 0.145667; batch adversarial loss: 0.500725\n",
      "epoch 63; iter: 0; batch classifier loss: 0.125614; batch adversarial loss: 0.483340\n",
      "epoch 64; iter: 0; batch classifier loss: 0.171732; batch adversarial loss: 0.502525\n",
      "epoch 65; iter: 0; batch classifier loss: 0.138026; batch adversarial loss: 0.417119\n",
      "epoch 66; iter: 0; batch classifier loss: 0.099320; batch adversarial loss: 0.502689\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101170; batch adversarial loss: 0.514289\n",
      "epoch 68; iter: 0; batch classifier loss: 0.149412; batch adversarial loss: 0.441536\n",
      "epoch 69; iter: 0; batch classifier loss: 0.178749; batch adversarial loss: 0.422348\n",
      "epoch 70; iter: 0; batch classifier loss: 0.162413; batch adversarial loss: 0.434054\n",
      "epoch 71; iter: 0; batch classifier loss: 0.100535; batch adversarial loss: 0.494233\n",
      "epoch 72; iter: 0; batch classifier loss: 0.135790; batch adversarial loss: 0.438477\n",
      "epoch 73; iter: 0; batch classifier loss: 0.154993; batch adversarial loss: 0.544878\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102174; batch adversarial loss: 0.434962\n",
      "epoch 75; iter: 0; batch classifier loss: 0.089726; batch adversarial loss: 0.436249\n",
      "epoch 76; iter: 0; batch classifier loss: 0.084671; batch adversarial loss: 0.489239\n",
      "epoch 77; iter: 0; batch classifier loss: 0.123259; batch adversarial loss: 0.481870\n",
      "epoch 78; iter: 0; batch classifier loss: 0.101587; batch adversarial loss: 0.474165\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072050; batch adversarial loss: 0.434634\n",
      "epoch 80; iter: 0; batch classifier loss: 0.094529; batch adversarial loss: 0.436551\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083612; batch adversarial loss: 0.430467\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075606; batch adversarial loss: 0.415005\n",
      "epoch 83; iter: 0; batch classifier loss: 0.100396; batch adversarial loss: 0.394486\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069999; batch adversarial loss: 0.559670\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064026; batch adversarial loss: 0.477296\n",
      "epoch 86; iter: 0; batch classifier loss: 0.104339; batch adversarial loss: 0.497760\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083070; batch adversarial loss: 0.452742\n",
      "epoch 88; iter: 0; batch classifier loss: 0.116221; batch adversarial loss: 0.399418\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057941; batch adversarial loss: 0.405020\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064511; batch adversarial loss: 0.471258\n",
      "epoch 91; iter: 0; batch classifier loss: 0.116319; batch adversarial loss: 0.439979\n",
      "epoch 92; iter: 0; batch classifier loss: 0.085366; batch adversarial loss: 0.478435\n",
      "epoch 93; iter: 0; batch classifier loss: 0.108550; batch adversarial loss: 0.491033\n",
      "epoch 94; iter: 0; batch classifier loss: 0.084080; batch adversarial loss: 0.427457\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070701; batch adversarial loss: 0.457052\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046015; batch adversarial loss: 0.471697\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077404; batch adversarial loss: 0.606147\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056788; batch adversarial loss: 0.518628\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073074; batch adversarial loss: 0.489466\n",
      "epoch 100; iter: 0; batch classifier loss: 0.070957; batch adversarial loss: 0.390013\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041460; batch adversarial loss: 0.612755\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043933; batch adversarial loss: 0.465092\n",
      "epoch 103; iter: 0; batch classifier loss: 0.030423; batch adversarial loss: 0.437355\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041886; batch adversarial loss: 0.525420\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050600; batch adversarial loss: 0.485759\n",
      "epoch 106; iter: 0; batch classifier loss: 0.048757; batch adversarial loss: 0.408140\n",
      "epoch 107; iter: 0; batch classifier loss: 0.021088; batch adversarial loss: 0.480562\n",
      "epoch 108; iter: 0; batch classifier loss: 0.066827; batch adversarial loss: 0.378325\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036175; batch adversarial loss: 0.417826\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044450; batch adversarial loss: 0.436978\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043090; batch adversarial loss: 0.500008\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047493; batch adversarial loss: 0.527334\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037708; batch adversarial loss: 0.377164\n",
      "epoch 114; iter: 0; batch classifier loss: 0.015460; batch adversarial loss: 0.394483\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059700; batch adversarial loss: 0.418486\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036653; batch adversarial loss: 0.432314\n",
      "epoch 117; iter: 0; batch classifier loss: 0.016138; batch adversarial loss: 0.473288\n",
      "epoch 118; iter: 0; batch classifier loss: 0.023494; batch adversarial loss: 0.486730\n",
      "epoch 119; iter: 0; batch classifier loss: 0.018000; batch adversarial loss: 0.520028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.021069; batch adversarial loss: 0.419681\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021694; batch adversarial loss: 0.582539\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030206; batch adversarial loss: 0.480356\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019242; batch adversarial loss: 0.449397\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039231; batch adversarial loss: 0.470177\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020924; batch adversarial loss: 0.406960\n",
      "epoch 126; iter: 0; batch classifier loss: 0.062593; batch adversarial loss: 0.459999\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037599; batch adversarial loss: 0.411000\n",
      "epoch 128; iter: 0; batch classifier loss: 0.015303; batch adversarial loss: 0.447281\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050042; batch adversarial loss: 0.407489\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036178; batch adversarial loss: 0.510456\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032515; batch adversarial loss: 0.556683\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040497; batch adversarial loss: 0.462635\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048624; batch adversarial loss: 0.482212\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024207; batch adversarial loss: 0.408378\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031104; batch adversarial loss: 0.367081\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044327; batch adversarial loss: 0.588289\n",
      "epoch 137; iter: 0; batch classifier loss: 0.007405; batch adversarial loss: 0.538401\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014167; batch adversarial loss: 0.503633\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021347; batch adversarial loss: 0.484833\n",
      "epoch 140; iter: 0; batch classifier loss: 0.059577; batch adversarial loss: 0.458326\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025465; batch adversarial loss: 0.428270\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013835; batch adversarial loss: 0.457108\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020824; batch adversarial loss: 0.502776\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049490; batch adversarial loss: 0.531597\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015311; batch adversarial loss: 0.452430\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027122; batch adversarial loss: 0.438551\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036366; batch adversarial loss: 0.532225\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041396; batch adversarial loss: 0.515168\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027189; batch adversarial loss: 0.450475\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033518; batch adversarial loss: 0.467814\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029489; batch adversarial loss: 0.459704\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018074; batch adversarial loss: 0.525504\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012933; batch adversarial loss: 0.526717\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033775; batch adversarial loss: 0.414177\n",
      "epoch 155; iter: 0; batch classifier loss: 0.053371; batch adversarial loss: 0.423302\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034571; batch adversarial loss: 0.466645\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024843; batch adversarial loss: 0.494510\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024931; batch adversarial loss: 0.491569\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010475; batch adversarial loss: 0.508147\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017080; batch adversarial loss: 0.465255\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024552; batch adversarial loss: 0.449779\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019294; batch adversarial loss: 0.565981\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009490; batch adversarial loss: 0.455067\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016212; batch adversarial loss: 0.447255\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027640; batch adversarial loss: 0.458216\n",
      "epoch 166; iter: 0; batch classifier loss: 0.005750; batch adversarial loss: 0.507394\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017960; batch adversarial loss: 0.431878\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021509; batch adversarial loss: 0.405448\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010169; batch adversarial loss: 0.546393\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017803; batch adversarial loss: 0.532786\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030169; batch adversarial loss: 0.461648\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034785; batch adversarial loss: 0.460506\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018034; batch adversarial loss: 0.443447\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013157; batch adversarial loss: 0.494488\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023953; batch adversarial loss: 0.454052\n",
      "epoch 176; iter: 0; batch classifier loss: 0.005772; batch adversarial loss: 0.519283\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008621; batch adversarial loss: 0.459054\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023934; batch adversarial loss: 0.493827\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037191; batch adversarial loss: 0.512215\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031112; batch adversarial loss: 0.446997\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009319; batch adversarial loss: 0.415953\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009964; batch adversarial loss: 0.526289\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010360; batch adversarial loss: 0.485845\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035152; batch adversarial loss: 0.543726\n",
      "epoch 185; iter: 0; batch classifier loss: 0.030366; batch adversarial loss: 0.434492\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013394; batch adversarial loss: 0.460342\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011399; batch adversarial loss: 0.393956\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017116; batch adversarial loss: 0.453922\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011609; batch adversarial loss: 0.443044\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016255; batch adversarial loss: 0.500276\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012950; batch adversarial loss: 0.456852\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007240; batch adversarial loss: 0.505918\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006524; batch adversarial loss: 0.468530\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017972; batch adversarial loss: 0.472774\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008945; batch adversarial loss: 0.452368\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012193; batch adversarial loss: 0.572443\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016533; batch adversarial loss: 0.515864\n",
      "epoch 198; iter: 0; batch classifier loss: 0.036613; batch adversarial loss: 0.449715\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018805; batch adversarial loss: 0.520870\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683184; batch adversarial loss: 0.650288\n",
      "epoch 1; iter: 0; batch classifier loss: 0.464651; batch adversarial loss: 0.651911\n",
      "epoch 2; iter: 0; batch classifier loss: 0.309872; batch adversarial loss: 0.643566\n",
      "epoch 3; iter: 0; batch classifier loss: 0.310089; batch adversarial loss: 0.626333\n",
      "epoch 4; iter: 0; batch classifier loss: 0.360871; batch adversarial loss: 0.562685\n",
      "epoch 5; iter: 0; batch classifier loss: 0.310631; batch adversarial loss: 0.565508\n",
      "epoch 6; iter: 0; batch classifier loss: 0.313978; batch adversarial loss: 0.512733\n",
      "epoch 7; iter: 0; batch classifier loss: 0.275534; batch adversarial loss: 0.522996\n",
      "epoch 8; iter: 0; batch classifier loss: 0.289824; batch adversarial loss: 0.527307\n",
      "epoch 9; iter: 0; batch classifier loss: 0.278068; batch adversarial loss: 0.540244\n",
      "epoch 10; iter: 0; batch classifier loss: 0.224070; batch adversarial loss: 0.485475\n",
      "epoch 11; iter: 0; batch classifier loss: 0.259005; batch adversarial loss: 0.524102\n",
      "epoch 12; iter: 0; batch classifier loss: 0.237092; batch adversarial loss: 0.485155\n",
      "epoch 13; iter: 0; batch classifier loss: 0.197383; batch adversarial loss: 0.480461\n",
      "epoch 14; iter: 0; batch classifier loss: 0.179976; batch adversarial loss: 0.428331\n",
      "epoch 15; iter: 0; batch classifier loss: 0.192726; batch adversarial loss: 0.420143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.151632; batch adversarial loss: 0.553040\n",
      "epoch 17; iter: 0; batch classifier loss: 0.190221; batch adversarial loss: 0.524839\n",
      "epoch 18; iter: 0; batch classifier loss: 0.234408; batch adversarial loss: 0.491741\n",
      "epoch 19; iter: 0; batch classifier loss: 0.201272; batch adversarial loss: 0.481440\n",
      "epoch 20; iter: 0; batch classifier loss: 0.136572; batch adversarial loss: 0.582149\n",
      "epoch 21; iter: 0; batch classifier loss: 0.223437; batch adversarial loss: 0.487338\n",
      "epoch 22; iter: 0; batch classifier loss: 0.244057; batch adversarial loss: 0.483153\n",
      "epoch 23; iter: 0; batch classifier loss: 0.211201; batch adversarial loss: 0.612379\n",
      "epoch 24; iter: 0; batch classifier loss: 0.219484; batch adversarial loss: 0.516903\n",
      "epoch 25; iter: 0; batch classifier loss: 0.187430; batch adversarial loss: 0.441214\n",
      "epoch 26; iter: 0; batch classifier loss: 0.190751; batch adversarial loss: 0.522985\n",
      "epoch 27; iter: 0; batch classifier loss: 0.191378; batch adversarial loss: 0.455038\n",
      "epoch 28; iter: 0; batch classifier loss: 0.208013; batch adversarial loss: 0.553203\n",
      "epoch 29; iter: 0; batch classifier loss: 0.247753; batch adversarial loss: 0.432988\n",
      "epoch 30; iter: 0; batch classifier loss: 0.224476; batch adversarial loss: 0.498418\n",
      "epoch 31; iter: 0; batch classifier loss: 0.238520; batch adversarial loss: 0.476764\n",
      "epoch 32; iter: 0; batch classifier loss: 0.333423; batch adversarial loss: 0.574855\n",
      "epoch 33; iter: 0; batch classifier loss: 0.320481; batch adversarial loss: 0.503078\n",
      "epoch 34; iter: 0; batch classifier loss: 0.188265; batch adversarial loss: 0.478285\n",
      "epoch 35; iter: 0; batch classifier loss: 0.131798; batch adversarial loss: 0.456781\n",
      "epoch 36; iter: 0; batch classifier loss: 0.138566; batch adversarial loss: 0.475519\n",
      "epoch 37; iter: 0; batch classifier loss: 0.105503; batch adversarial loss: 0.457859\n",
      "epoch 38; iter: 0; batch classifier loss: 0.075411; batch adversarial loss: 0.439347\n",
      "epoch 39; iter: 0; batch classifier loss: 0.122989; batch adversarial loss: 0.431519\n",
      "epoch 40; iter: 0; batch classifier loss: 0.096968; batch adversarial loss: 0.484462\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125617; batch adversarial loss: 0.404116\n",
      "epoch 42; iter: 0; batch classifier loss: 0.135249; batch adversarial loss: 0.492147\n",
      "epoch 43; iter: 0; batch classifier loss: 0.070202; batch adversarial loss: 0.386082\n",
      "epoch 44; iter: 0; batch classifier loss: 0.068379; batch adversarial loss: 0.505700\n",
      "epoch 45; iter: 0; batch classifier loss: 0.077063; batch adversarial loss: 0.415205\n",
      "epoch 46; iter: 0; batch classifier loss: 0.075414; batch adversarial loss: 0.464676\n",
      "epoch 47; iter: 0; batch classifier loss: 0.046932; batch adversarial loss: 0.500183\n",
      "epoch 48; iter: 0; batch classifier loss: 0.067029; batch adversarial loss: 0.528411\n",
      "epoch 49; iter: 0; batch classifier loss: 0.071818; batch adversarial loss: 0.471923\n",
      "epoch 50; iter: 0; batch classifier loss: 0.059560; batch adversarial loss: 0.483710\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073405; batch adversarial loss: 0.446085\n",
      "epoch 52; iter: 0; batch classifier loss: 0.081217; batch adversarial loss: 0.510424\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076824; batch adversarial loss: 0.388102\n",
      "epoch 54; iter: 0; batch classifier loss: 0.056906; batch adversarial loss: 0.520703\n",
      "epoch 55; iter: 0; batch classifier loss: 0.049311; batch adversarial loss: 0.469267\n",
      "epoch 56; iter: 0; batch classifier loss: 0.062218; batch adversarial loss: 0.504338\n",
      "epoch 57; iter: 0; batch classifier loss: 0.053754; batch adversarial loss: 0.431947\n",
      "epoch 58; iter: 0; batch classifier loss: 0.067282; batch adversarial loss: 0.385655\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074847; batch adversarial loss: 0.435002\n",
      "epoch 60; iter: 0; batch classifier loss: 0.143957; batch adversarial loss: 0.448185\n",
      "epoch 61; iter: 0; batch classifier loss: 0.064759; batch adversarial loss: 0.426690\n",
      "epoch 62; iter: 0; batch classifier loss: 0.074536; batch adversarial loss: 0.419844\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091879; batch adversarial loss: 0.525118\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066479; batch adversarial loss: 0.477982\n",
      "epoch 65; iter: 0; batch classifier loss: 0.068901; batch adversarial loss: 0.470473\n",
      "epoch 66; iter: 0; batch classifier loss: 0.042585; batch adversarial loss: 0.519271\n",
      "epoch 67; iter: 0; batch classifier loss: 0.076723; batch adversarial loss: 0.464266\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060529; batch adversarial loss: 0.452880\n",
      "epoch 69; iter: 0; batch classifier loss: 0.050033; batch adversarial loss: 0.494867\n",
      "epoch 70; iter: 0; batch classifier loss: 0.072507; batch adversarial loss: 0.476373\n",
      "epoch 71; iter: 0; batch classifier loss: 0.070528; batch adversarial loss: 0.437000\n",
      "epoch 72; iter: 0; batch classifier loss: 0.105225; batch adversarial loss: 0.538132\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089968; batch adversarial loss: 0.418112\n",
      "epoch 74; iter: 0; batch classifier loss: 0.131973; batch adversarial loss: 0.449169\n",
      "epoch 75; iter: 0; batch classifier loss: 0.081676; batch adversarial loss: 0.437897\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083709; batch adversarial loss: 0.438303\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065901; batch adversarial loss: 0.444243\n",
      "epoch 78; iter: 0; batch classifier loss: 0.103545; batch adversarial loss: 0.476411\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053039; batch adversarial loss: 0.444923\n",
      "epoch 80; iter: 0; batch classifier loss: 0.065062; batch adversarial loss: 0.432844\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076989; batch adversarial loss: 0.511118\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061894; batch adversarial loss: 0.539892\n",
      "epoch 83; iter: 0; batch classifier loss: 0.053888; batch adversarial loss: 0.421583\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080165; batch adversarial loss: 0.432109\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060194; batch adversarial loss: 0.475337\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052156; batch adversarial loss: 0.600142\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072309; batch adversarial loss: 0.495909\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059877; batch adversarial loss: 0.416300\n",
      "epoch 89; iter: 0; batch classifier loss: 0.083395; batch adversarial loss: 0.419688\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042617; batch adversarial loss: 0.582726\n",
      "epoch 91; iter: 0; batch classifier loss: 0.049573; batch adversarial loss: 0.369604\n",
      "epoch 92; iter: 0; batch classifier loss: 0.090158; batch adversarial loss: 0.472717\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046279; batch adversarial loss: 0.409325\n",
      "epoch 94; iter: 0; batch classifier loss: 0.073706; batch adversarial loss: 0.457116\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056053; batch adversarial loss: 0.419596\n",
      "epoch 96; iter: 0; batch classifier loss: 0.103185; batch adversarial loss: 0.402552\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069341; batch adversarial loss: 0.476701\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049909; batch adversarial loss: 0.403798\n",
      "epoch 99; iter: 0; batch classifier loss: 0.077062; batch adversarial loss: 0.392945\n",
      "epoch 100; iter: 0; batch classifier loss: 0.086184; batch adversarial loss: 0.364568\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053806; batch adversarial loss: 0.453168\n",
      "epoch 102; iter: 0; batch classifier loss: 0.075146; batch adversarial loss: 0.499574\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042826; batch adversarial loss: 0.458132\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083365; batch adversarial loss: 0.500794\n",
      "epoch 105; iter: 0; batch classifier loss: 0.063830; batch adversarial loss: 0.482865\n",
      "epoch 106; iter: 0; batch classifier loss: 0.082652; batch adversarial loss: 0.453969\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065193; batch adversarial loss: 0.404207\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060754; batch adversarial loss: 0.520023\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051512; batch adversarial loss: 0.502328\n",
      "epoch 110; iter: 0; batch classifier loss: 0.075379; batch adversarial loss: 0.458546\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032808; batch adversarial loss: 0.394416\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037902; batch adversarial loss: 0.421848\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034385; batch adversarial loss: 0.505164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.059444; batch adversarial loss: 0.449463\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046074; batch adversarial loss: 0.488321\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027932; batch adversarial loss: 0.485542\n",
      "epoch 117; iter: 0; batch classifier loss: 0.066573; batch adversarial loss: 0.380218\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037670; batch adversarial loss: 0.383956\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054053; batch adversarial loss: 0.545983\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057454; batch adversarial loss: 0.471122\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031055; batch adversarial loss: 0.560913\n",
      "epoch 122; iter: 0; batch classifier loss: 0.018491; batch adversarial loss: 0.432118\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040083; batch adversarial loss: 0.602065\n",
      "epoch 124; iter: 0; batch classifier loss: 0.070428; batch adversarial loss: 0.366619\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030477; batch adversarial loss: 0.467269\n",
      "epoch 126; iter: 0; batch classifier loss: 0.053270; batch adversarial loss: 0.469819\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060835; batch adversarial loss: 0.543991\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018026; batch adversarial loss: 0.405109\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050384; batch adversarial loss: 0.489468\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028865; batch adversarial loss: 0.497702\n",
      "epoch 131; iter: 0; batch classifier loss: 0.067371; batch adversarial loss: 0.359000\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046248; batch adversarial loss: 0.329728\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036416; batch adversarial loss: 0.523922\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042395; batch adversarial loss: 0.460299\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057642; batch adversarial loss: 0.515307\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041974; batch adversarial loss: 0.390214\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026432; batch adversarial loss: 0.366012\n",
      "epoch 138; iter: 0; batch classifier loss: 0.070971; batch adversarial loss: 0.411138\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039168; batch adversarial loss: 0.573080\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052833; batch adversarial loss: 0.437773\n",
      "epoch 141; iter: 0; batch classifier loss: 0.012202; batch adversarial loss: 0.482476\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014260; batch adversarial loss: 0.473826\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037586; batch adversarial loss: 0.405150\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022678; batch adversarial loss: 0.487739\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029707; batch adversarial loss: 0.536417\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023866; batch adversarial loss: 0.446587\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036714; batch adversarial loss: 0.520240\n",
      "epoch 148; iter: 0; batch classifier loss: 0.068369; batch adversarial loss: 0.515617\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019338; batch adversarial loss: 0.464393\n",
      "epoch 150; iter: 0; batch classifier loss: 0.061491; batch adversarial loss: 0.479916\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055510; batch adversarial loss: 0.477549\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031288; batch adversarial loss: 0.419706\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028416; batch adversarial loss: 0.421972\n",
      "epoch 154; iter: 0; batch classifier loss: 0.009854; batch adversarial loss: 0.553356\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052359; batch adversarial loss: 0.390430\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015942; batch adversarial loss: 0.479041\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035149; batch adversarial loss: 0.427125\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018672; batch adversarial loss: 0.508295\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017461; batch adversarial loss: 0.422554\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017331; batch adversarial loss: 0.421952\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013514; batch adversarial loss: 0.474594\n",
      "epoch 162; iter: 0; batch classifier loss: 0.049447; batch adversarial loss: 0.464644\n",
      "epoch 163; iter: 0; batch classifier loss: 0.060557; batch adversarial loss: 0.461808\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024550; batch adversarial loss: 0.421369\n",
      "epoch 165; iter: 0; batch classifier loss: 0.054800; batch adversarial loss: 0.483261\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017013; batch adversarial loss: 0.353653\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026513; batch adversarial loss: 0.511503\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026106; batch adversarial loss: 0.471742\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025088; batch adversarial loss: 0.484917\n",
      "epoch 170; iter: 0; batch classifier loss: 0.041255; batch adversarial loss: 0.421504\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015439; batch adversarial loss: 0.439501\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025982; batch adversarial loss: 0.559350\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027405; batch adversarial loss: 0.490608\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019868; batch adversarial loss: 0.391216\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020108; batch adversarial loss: 0.480414\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019228; batch adversarial loss: 0.390946\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013771; batch adversarial loss: 0.477892\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025629; batch adversarial loss: 0.471188\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008925; batch adversarial loss: 0.386647\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011315; batch adversarial loss: 0.498561\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036176; batch adversarial loss: 0.381142\n",
      "epoch 182; iter: 0; batch classifier loss: 0.045901; batch adversarial loss: 0.466980\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026946; batch adversarial loss: 0.461592\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014103; batch adversarial loss: 0.490428\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010182; batch adversarial loss: 0.545101\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041513; batch adversarial loss: 0.514968\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023435; batch adversarial loss: 0.428512\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017713; batch adversarial loss: 0.439431\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009211; batch adversarial loss: 0.499827\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012758; batch adversarial loss: 0.492046\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028795; batch adversarial loss: 0.483473\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034269; batch adversarial loss: 0.471752\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021182; batch adversarial loss: 0.570293\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034758; batch adversarial loss: 0.429633\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023323; batch adversarial loss: 0.540988\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024453; batch adversarial loss: 0.582501\n",
      "epoch 197; iter: 0; batch classifier loss: 0.047889; batch adversarial loss: 0.349154\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019645; batch adversarial loss: 0.436042\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020150; batch adversarial loss: 0.525447\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686431; batch adversarial loss: 0.607721\n",
      "epoch 1; iter: 0; batch classifier loss: 0.456283; batch adversarial loss: 0.629262\n",
      "epoch 2; iter: 0; batch classifier loss: 0.484476; batch adversarial loss: 0.597804\n",
      "epoch 3; iter: 0; batch classifier loss: 0.522231; batch adversarial loss: 0.586026\n",
      "epoch 4; iter: 0; batch classifier loss: 0.412102; batch adversarial loss: 0.583447\n",
      "epoch 5; iter: 0; batch classifier loss: 0.476990; batch adversarial loss: 0.587168\n",
      "epoch 6; iter: 0; batch classifier loss: 0.381712; batch adversarial loss: 0.580425\n",
      "epoch 7; iter: 0; batch classifier loss: 0.392665; batch adversarial loss: 0.575728\n",
      "epoch 8; iter: 0; batch classifier loss: 0.378961; batch adversarial loss: 0.590909\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520154; batch adversarial loss: 0.495105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.381695; batch adversarial loss: 0.475631\n",
      "epoch 11; iter: 0; batch classifier loss: 0.302471; batch adversarial loss: 0.540743\n",
      "epoch 12; iter: 0; batch classifier loss: 0.383744; batch adversarial loss: 0.481702\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336859; batch adversarial loss: 0.498072\n",
      "epoch 14; iter: 0; batch classifier loss: 0.269299; batch adversarial loss: 0.511621\n",
      "epoch 15; iter: 0; batch classifier loss: 0.281928; batch adversarial loss: 0.531244\n",
      "epoch 16; iter: 0; batch classifier loss: 0.298672; batch adversarial loss: 0.453343\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269550; batch adversarial loss: 0.540393\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269826; batch adversarial loss: 0.422010\n",
      "epoch 19; iter: 0; batch classifier loss: 0.275925; batch adversarial loss: 0.444424\n",
      "epoch 20; iter: 0; batch classifier loss: 0.205864; batch adversarial loss: 0.452388\n",
      "epoch 21; iter: 0; batch classifier loss: 0.220686; batch adversarial loss: 0.392403\n",
      "epoch 22; iter: 0; batch classifier loss: 0.208487; batch adversarial loss: 0.491208\n",
      "epoch 23; iter: 0; batch classifier loss: 0.150337; batch adversarial loss: 0.461532\n",
      "epoch 24; iter: 0; batch classifier loss: 0.252066; batch adversarial loss: 0.533488\n",
      "epoch 25; iter: 0; batch classifier loss: 0.208452; batch adversarial loss: 0.467417\n",
      "epoch 26; iter: 0; batch classifier loss: 0.206123; batch adversarial loss: 0.433080\n",
      "epoch 27; iter: 0; batch classifier loss: 0.224568; batch adversarial loss: 0.438875\n",
      "epoch 28; iter: 0; batch classifier loss: 0.210941; batch adversarial loss: 0.489850\n",
      "epoch 29; iter: 0; batch classifier loss: 0.200691; batch adversarial loss: 0.522692\n",
      "epoch 30; iter: 0; batch classifier loss: 0.124538; batch adversarial loss: 0.498186\n",
      "epoch 31; iter: 0; batch classifier loss: 0.270441; batch adversarial loss: 0.449500\n",
      "epoch 32; iter: 0; batch classifier loss: 0.202484; batch adversarial loss: 0.449681\n",
      "epoch 33; iter: 0; batch classifier loss: 0.233906; batch adversarial loss: 0.475749\n",
      "epoch 34; iter: 0; batch classifier loss: 0.209719; batch adversarial loss: 0.424219\n",
      "epoch 35; iter: 0; batch classifier loss: 0.281800; batch adversarial loss: 0.525291\n",
      "epoch 36; iter: 0; batch classifier loss: 0.231380; batch adversarial loss: 0.426167\n",
      "epoch 37; iter: 0; batch classifier loss: 0.165513; batch adversarial loss: 0.531651\n",
      "epoch 38; iter: 0; batch classifier loss: 0.270849; batch adversarial loss: 0.426054\n",
      "epoch 39; iter: 0; batch classifier loss: 0.208642; batch adversarial loss: 0.456078\n",
      "epoch 40; iter: 0; batch classifier loss: 0.207456; batch adversarial loss: 0.502869\n",
      "epoch 41; iter: 0; batch classifier loss: 0.243073; batch adversarial loss: 0.432144\n",
      "epoch 42; iter: 0; batch classifier loss: 0.264763; batch adversarial loss: 0.484328\n",
      "epoch 43; iter: 0; batch classifier loss: 0.234010; batch adversarial loss: 0.449420\n",
      "epoch 44; iter: 0; batch classifier loss: 0.326555; batch adversarial loss: 0.435836\n",
      "epoch 45; iter: 0; batch classifier loss: 0.233379; batch adversarial loss: 0.473881\n",
      "epoch 46; iter: 0; batch classifier loss: 0.231721; batch adversarial loss: 0.507689\n",
      "epoch 47; iter: 0; batch classifier loss: 0.266146; batch adversarial loss: 0.446306\n",
      "epoch 48; iter: 0; batch classifier loss: 0.334082; batch adversarial loss: 0.412835\n",
      "epoch 49; iter: 0; batch classifier loss: 0.171560; batch adversarial loss: 0.364083\n",
      "epoch 50; iter: 0; batch classifier loss: 0.190385; batch adversarial loss: 0.460906\n",
      "epoch 51; iter: 0; batch classifier loss: 0.199050; batch adversarial loss: 0.447220\n",
      "epoch 52; iter: 0; batch classifier loss: 0.107521; batch adversarial loss: 0.532268\n",
      "epoch 53; iter: 0; batch classifier loss: 0.240003; batch adversarial loss: 0.506849\n",
      "epoch 54; iter: 0; batch classifier loss: 0.174525; batch adversarial loss: 0.446813\n",
      "epoch 55; iter: 0; batch classifier loss: 0.187313; batch adversarial loss: 0.470202\n",
      "epoch 56; iter: 0; batch classifier loss: 0.168399; batch adversarial loss: 0.471560\n",
      "epoch 57; iter: 0; batch classifier loss: 0.182426; batch adversarial loss: 0.459114\n",
      "epoch 58; iter: 0; batch classifier loss: 0.158270; batch adversarial loss: 0.409654\n",
      "epoch 59; iter: 0; batch classifier loss: 0.129777; batch adversarial loss: 0.544935\n",
      "epoch 60; iter: 0; batch classifier loss: 0.182175; batch adversarial loss: 0.519264\n",
      "epoch 61; iter: 0; batch classifier loss: 0.211781; batch adversarial loss: 0.570885\n",
      "epoch 62; iter: 0; batch classifier loss: 0.167706; batch adversarial loss: 0.445927\n",
      "epoch 63; iter: 0; batch classifier loss: 0.185313; batch adversarial loss: 0.446235\n",
      "epoch 64; iter: 0; batch classifier loss: 0.155860; batch adversarial loss: 0.520989\n",
      "epoch 65; iter: 0; batch classifier loss: 0.165259; batch adversarial loss: 0.569222\n",
      "epoch 66; iter: 0; batch classifier loss: 0.256414; batch adversarial loss: 0.433711\n",
      "epoch 67; iter: 0; batch classifier loss: 0.083959; batch adversarial loss: 0.396470\n",
      "epoch 68; iter: 0; batch classifier loss: 0.123231; batch adversarial loss: 0.545750\n",
      "epoch 69; iter: 0; batch classifier loss: 0.146364; batch adversarial loss: 0.531785\n",
      "epoch 70; iter: 0; batch classifier loss: 0.270991; batch adversarial loss: 0.483933\n",
      "epoch 71; iter: 0; batch classifier loss: 0.134547; batch adversarial loss: 0.496421\n",
      "epoch 72; iter: 0; batch classifier loss: 0.121538; batch adversarial loss: 0.493954\n",
      "epoch 73; iter: 0; batch classifier loss: 0.265221; batch adversarial loss: 0.410286\n",
      "epoch 74; iter: 0; batch classifier loss: 0.195765; batch adversarial loss: 0.569492\n",
      "epoch 75; iter: 0; batch classifier loss: 0.187249; batch adversarial loss: 0.409553\n",
      "epoch 76; iter: 0; batch classifier loss: 0.115753; batch adversarial loss: 0.558599\n",
      "epoch 77; iter: 0; batch classifier loss: 0.258828; batch adversarial loss: 0.397298\n",
      "epoch 78; iter: 0; batch classifier loss: 0.201852; batch adversarial loss: 0.532846\n",
      "epoch 79; iter: 0; batch classifier loss: 0.156160; batch adversarial loss: 0.384671\n",
      "epoch 80; iter: 0; batch classifier loss: 0.118263; batch adversarial loss: 0.533593\n",
      "epoch 81; iter: 0; batch classifier loss: 0.182844; batch adversarial loss: 0.520529\n",
      "epoch 82; iter: 0; batch classifier loss: 0.257443; batch adversarial loss: 0.470800\n",
      "epoch 83; iter: 0; batch classifier loss: 0.184563; batch adversarial loss: 0.346925\n",
      "epoch 84; iter: 0; batch classifier loss: 0.231320; batch adversarial loss: 0.471293\n",
      "epoch 85; iter: 0; batch classifier loss: 0.139148; batch adversarial loss: 0.508033\n",
      "epoch 86; iter: 0; batch classifier loss: 0.142276; batch adversarial loss: 0.345034\n",
      "epoch 87; iter: 0; batch classifier loss: 0.070367; batch adversarial loss: 0.507566\n",
      "epoch 88; iter: 0; batch classifier loss: 0.210832; batch adversarial loss: 0.497922\n",
      "epoch 89; iter: 0; batch classifier loss: 0.184237; batch adversarial loss: 0.443703\n",
      "epoch 90; iter: 0; batch classifier loss: 0.174561; batch adversarial loss: 0.409373\n",
      "epoch 91; iter: 0; batch classifier loss: 0.121329; batch adversarial loss: 0.483206\n",
      "epoch 92; iter: 0; batch classifier loss: 0.189949; batch adversarial loss: 0.384817\n",
      "epoch 93; iter: 0; batch classifier loss: 0.177403; batch adversarial loss: 0.422982\n",
      "epoch 94; iter: 0; batch classifier loss: 0.248274; batch adversarial loss: 0.421077\n",
      "epoch 95; iter: 0; batch classifier loss: 0.242394; batch adversarial loss: 0.397042\n",
      "epoch 96; iter: 0; batch classifier loss: 0.197231; batch adversarial loss: 0.459275\n",
      "epoch 97; iter: 0; batch classifier loss: 0.181645; batch adversarial loss: 0.594622\n",
      "epoch 98; iter: 0; batch classifier loss: 0.130303; batch adversarial loss: 0.432670\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055158; batch adversarial loss: 0.493781\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067045; batch adversarial loss: 0.430936\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056823; batch adversarial loss: 0.505668\n",
      "epoch 102; iter: 0; batch classifier loss: 0.065066; batch adversarial loss: 0.423574\n",
      "epoch 103; iter: 0; batch classifier loss: 0.051765; batch adversarial loss: 0.420245\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053451; batch adversarial loss: 0.539698\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029531; batch adversarial loss: 0.426533\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037855; batch adversarial loss: 0.515176\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034123; batch adversarial loss: 0.424965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.059386; batch adversarial loss: 0.399651\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030926; batch adversarial loss: 0.350026\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061025; batch adversarial loss: 0.354814\n",
      "epoch 111; iter: 0; batch classifier loss: 0.080180; batch adversarial loss: 0.407828\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027382; batch adversarial loss: 0.442616\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047409; batch adversarial loss: 0.459407\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047043; batch adversarial loss: 0.421076\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051264; batch adversarial loss: 0.463563\n",
      "epoch 116; iter: 0; batch classifier loss: 0.061984; batch adversarial loss: 0.347831\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047183; batch adversarial loss: 0.430238\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069958; batch adversarial loss: 0.486397\n",
      "epoch 119; iter: 0; batch classifier loss: 0.087436; batch adversarial loss: 0.475317\n",
      "epoch 120; iter: 0; batch classifier loss: 0.082520; batch adversarial loss: 0.399805\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053744; batch adversarial loss: 0.339493\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051462; batch adversarial loss: 0.393608\n",
      "epoch 123; iter: 0; batch classifier loss: 0.089486; batch adversarial loss: 0.338166\n",
      "epoch 124; iter: 0; batch classifier loss: 0.061130; batch adversarial loss: 0.454573\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062586; batch adversarial loss: 0.421408\n",
      "epoch 126; iter: 0; batch classifier loss: 0.106761; batch adversarial loss: 0.451321\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048257; batch adversarial loss: 0.423790\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061178; batch adversarial loss: 0.483614\n",
      "epoch 129; iter: 0; batch classifier loss: 0.057926; batch adversarial loss: 0.378374\n",
      "epoch 130; iter: 0; batch classifier loss: 0.052312; batch adversarial loss: 0.554992\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055681; batch adversarial loss: 0.462556\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026550; batch adversarial loss: 0.334659\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041536; batch adversarial loss: 0.501894\n",
      "epoch 134; iter: 0; batch classifier loss: 0.077808; batch adversarial loss: 0.456032\n",
      "epoch 135; iter: 0; batch classifier loss: 0.052179; batch adversarial loss: 0.427852\n",
      "epoch 136; iter: 0; batch classifier loss: 0.055737; batch adversarial loss: 0.485763\n",
      "epoch 137; iter: 0; batch classifier loss: 0.075953; batch adversarial loss: 0.484351\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026217; batch adversarial loss: 0.453907\n",
      "epoch 139; iter: 0; batch classifier loss: 0.057987; batch adversarial loss: 0.363874\n",
      "epoch 140; iter: 0; batch classifier loss: 0.068059; batch adversarial loss: 0.376876\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046652; batch adversarial loss: 0.487535\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050087; batch adversarial loss: 0.479698\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033685; batch adversarial loss: 0.342549\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052408; batch adversarial loss: 0.390724\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042494; batch adversarial loss: 0.361447\n",
      "epoch 146; iter: 0; batch classifier loss: 0.071017; batch adversarial loss: 0.471917\n",
      "epoch 147; iter: 0; batch classifier loss: 0.070824; batch adversarial loss: 0.417520\n",
      "epoch 148; iter: 0; batch classifier loss: 0.072479; batch adversarial loss: 0.420011\n",
      "epoch 149; iter: 0; batch classifier loss: 0.054572; batch adversarial loss: 0.436310\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042188; batch adversarial loss: 0.436826\n",
      "epoch 151; iter: 0; batch classifier loss: 0.104792; batch adversarial loss: 0.456043\n",
      "epoch 152; iter: 0; batch classifier loss: 0.057251; batch adversarial loss: 0.428255\n",
      "epoch 153; iter: 0; batch classifier loss: 0.084695; batch adversarial loss: 0.448391\n",
      "epoch 154; iter: 0; batch classifier loss: 0.042752; batch adversarial loss: 0.430215\n",
      "epoch 155; iter: 0; batch classifier loss: 0.055988; batch adversarial loss: 0.498345\n",
      "epoch 156; iter: 0; batch classifier loss: 0.070279; batch adversarial loss: 0.467077\n",
      "epoch 157; iter: 0; batch classifier loss: 0.115397; batch adversarial loss: 0.363487\n",
      "epoch 158; iter: 0; batch classifier loss: 0.065864; batch adversarial loss: 0.442370\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036176; batch adversarial loss: 0.413306\n",
      "epoch 160; iter: 0; batch classifier loss: 0.050793; batch adversarial loss: 0.471216\n",
      "epoch 161; iter: 0; batch classifier loss: 0.061941; batch adversarial loss: 0.310363\n",
      "epoch 162; iter: 0; batch classifier loss: 0.087032; batch adversarial loss: 0.514200\n",
      "epoch 163; iter: 0; batch classifier loss: 0.071156; batch adversarial loss: 0.380665\n",
      "epoch 164; iter: 0; batch classifier loss: 0.051885; batch adversarial loss: 0.387407\n",
      "epoch 165; iter: 0; batch classifier loss: 0.046523; batch adversarial loss: 0.429650\n",
      "epoch 166; iter: 0; batch classifier loss: 0.060822; batch adversarial loss: 0.430344\n",
      "epoch 167; iter: 0; batch classifier loss: 0.055926; batch adversarial loss: 0.438921\n",
      "epoch 168; iter: 0; batch classifier loss: 0.066013; batch adversarial loss: 0.380143\n",
      "epoch 169; iter: 0; batch classifier loss: 0.049497; batch adversarial loss: 0.354573\n",
      "epoch 170; iter: 0; batch classifier loss: 0.055101; batch adversarial loss: 0.491830\n",
      "epoch 171; iter: 0; batch classifier loss: 0.053342; batch adversarial loss: 0.423473\n",
      "epoch 172; iter: 0; batch classifier loss: 0.054979; batch adversarial loss: 0.381348\n",
      "epoch 173; iter: 0; batch classifier loss: 0.043497; batch adversarial loss: 0.372383\n",
      "epoch 174; iter: 0; batch classifier loss: 0.056691; batch adversarial loss: 0.419896\n",
      "epoch 175; iter: 0; batch classifier loss: 0.060445; batch adversarial loss: 0.438194\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032015; batch adversarial loss: 0.438537\n",
      "epoch 177; iter: 0; batch classifier loss: 0.062931; batch adversarial loss: 0.401691\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039577; batch adversarial loss: 0.362010\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030621; batch adversarial loss: 0.428923\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030709; batch adversarial loss: 0.367925\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038550; batch adversarial loss: 0.383602\n",
      "epoch 182; iter: 0; batch classifier loss: 0.073767; batch adversarial loss: 0.418273\n",
      "epoch 183; iter: 0; batch classifier loss: 0.052888; batch adversarial loss: 0.404892\n",
      "epoch 184; iter: 0; batch classifier loss: 0.054234; batch adversarial loss: 0.441108\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029530; batch adversarial loss: 0.461873\n",
      "epoch 186; iter: 0; batch classifier loss: 0.051740; batch adversarial loss: 0.464542\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044139; batch adversarial loss: 0.444594\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035642; batch adversarial loss: 0.480620\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030949; batch adversarial loss: 0.419095\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030066; batch adversarial loss: 0.427516\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036883; batch adversarial loss: 0.364626\n",
      "epoch 192; iter: 0; batch classifier loss: 0.052304; batch adversarial loss: 0.417830\n",
      "epoch 193; iter: 0; batch classifier loss: 0.042888; batch adversarial loss: 0.418043\n",
      "epoch 194; iter: 0; batch classifier loss: 0.048305; batch adversarial loss: 0.417258\n",
      "epoch 195; iter: 0; batch classifier loss: 0.039952; batch adversarial loss: 0.477043\n",
      "epoch 196; iter: 0; batch classifier loss: 0.044596; batch adversarial loss: 0.449475\n",
      "epoch 197; iter: 0; batch classifier loss: 0.054760; batch adversarial loss: 0.403604\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037491; batch adversarial loss: 0.533236\n",
      "epoch 199; iter: 0; batch classifier loss: 0.039631; batch adversarial loss: 0.485223\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701631; batch adversarial loss: 0.527776\n",
      "epoch 1; iter: 0; batch classifier loss: 0.496143; batch adversarial loss: 0.580895\n",
      "epoch 2; iter: 0; batch classifier loss: 0.382046; batch adversarial loss: 0.566563\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374518; batch adversarial loss: 0.563969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.355252; batch adversarial loss: 0.607854\n",
      "epoch 5; iter: 0; batch classifier loss: 0.417845; batch adversarial loss: 0.581563\n",
      "epoch 6; iter: 0; batch classifier loss: 0.343110; batch adversarial loss: 0.545488\n",
      "epoch 7; iter: 0; batch classifier loss: 0.386469; batch adversarial loss: 0.559117\n",
      "epoch 8; iter: 0; batch classifier loss: 0.397520; batch adversarial loss: 0.517287\n",
      "epoch 9; iter: 0; batch classifier loss: 0.495465; batch adversarial loss: 0.622058\n",
      "epoch 10; iter: 0; batch classifier loss: 0.418105; batch adversarial loss: 0.529404\n",
      "epoch 11; iter: 0; batch classifier loss: 0.477779; batch adversarial loss: 0.560185\n",
      "epoch 12; iter: 0; batch classifier loss: 0.482761; batch adversarial loss: 0.571559\n",
      "epoch 13; iter: 0; batch classifier loss: 0.438695; batch adversarial loss: 0.550139\n",
      "epoch 14; iter: 0; batch classifier loss: 0.393371; batch adversarial loss: 0.508990\n",
      "epoch 15; iter: 0; batch classifier loss: 0.321700; batch adversarial loss: 0.518532\n",
      "epoch 16; iter: 0; batch classifier loss: 0.248590; batch adversarial loss: 0.482718\n",
      "epoch 17; iter: 0; batch classifier loss: 0.167628; batch adversarial loss: 0.512273\n",
      "epoch 18; iter: 0; batch classifier loss: 0.164472; batch adversarial loss: 0.491947\n",
      "epoch 19; iter: 0; batch classifier loss: 0.199370; batch adversarial loss: 0.492455\n",
      "epoch 20; iter: 0; batch classifier loss: 0.225721; batch adversarial loss: 0.439321\n",
      "epoch 21; iter: 0; batch classifier loss: 0.192009; batch adversarial loss: 0.399006\n",
      "epoch 22; iter: 0; batch classifier loss: 0.146655; batch adversarial loss: 0.427579\n",
      "epoch 23; iter: 0; batch classifier loss: 0.134910; batch adversarial loss: 0.530510\n",
      "epoch 24; iter: 0; batch classifier loss: 0.187719; batch adversarial loss: 0.410257\n",
      "epoch 25; iter: 0; batch classifier loss: 0.147956; batch adversarial loss: 0.558469\n",
      "epoch 26; iter: 0; batch classifier loss: 0.195271; batch adversarial loss: 0.449215\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175220; batch adversarial loss: 0.532208\n",
      "epoch 28; iter: 0; batch classifier loss: 0.102178; batch adversarial loss: 0.420306\n",
      "epoch 29; iter: 0; batch classifier loss: 0.123987; batch adversarial loss: 0.391029\n",
      "epoch 30; iter: 0; batch classifier loss: 0.163327; batch adversarial loss: 0.374876\n",
      "epoch 31; iter: 0; batch classifier loss: 0.169583; batch adversarial loss: 0.420799\n",
      "epoch 32; iter: 0; batch classifier loss: 0.124124; batch adversarial loss: 0.517629\n",
      "epoch 33; iter: 0; batch classifier loss: 0.089235; batch adversarial loss: 0.471235\n",
      "epoch 34; iter: 0; batch classifier loss: 0.077992; batch adversarial loss: 0.446138\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129271; batch adversarial loss: 0.486723\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102208; batch adversarial loss: 0.547788\n",
      "epoch 37; iter: 0; batch classifier loss: 0.158197; batch adversarial loss: 0.391574\n",
      "epoch 38; iter: 0; batch classifier loss: 0.159226; batch adversarial loss: 0.447540\n",
      "epoch 39; iter: 0; batch classifier loss: 0.127577; batch adversarial loss: 0.368447\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091102; batch adversarial loss: 0.475609\n",
      "epoch 41; iter: 0; batch classifier loss: 0.119529; batch adversarial loss: 0.459550\n",
      "epoch 42; iter: 0; batch classifier loss: 0.109634; batch adversarial loss: 0.512796\n",
      "epoch 43; iter: 0; batch classifier loss: 0.071635; batch adversarial loss: 0.437136\n",
      "epoch 44; iter: 0; batch classifier loss: 0.160372; batch adversarial loss: 0.412041\n",
      "epoch 45; iter: 0; batch classifier loss: 0.087639; batch adversarial loss: 0.580437\n",
      "epoch 46; iter: 0; batch classifier loss: 0.088640; batch adversarial loss: 0.491760\n",
      "epoch 47; iter: 0; batch classifier loss: 0.098460; batch adversarial loss: 0.432854\n",
      "epoch 48; iter: 0; batch classifier loss: 0.096539; batch adversarial loss: 0.491501\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098695; batch adversarial loss: 0.415187\n",
      "epoch 50; iter: 0; batch classifier loss: 0.103444; batch adversarial loss: 0.543823\n",
      "epoch 51; iter: 0; batch classifier loss: 0.102657; batch adversarial loss: 0.450691\n",
      "epoch 52; iter: 0; batch classifier loss: 0.158785; batch adversarial loss: 0.533390\n",
      "epoch 53; iter: 0; batch classifier loss: 0.081457; batch adversarial loss: 0.414590\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095731; batch adversarial loss: 0.375449\n",
      "epoch 55; iter: 0; batch classifier loss: 0.118311; batch adversarial loss: 0.393057\n",
      "epoch 56; iter: 0; batch classifier loss: 0.075183; batch adversarial loss: 0.409162\n",
      "epoch 57; iter: 0; batch classifier loss: 0.132796; batch adversarial loss: 0.495596\n",
      "epoch 58; iter: 0; batch classifier loss: 0.092808; batch adversarial loss: 0.568075\n",
      "epoch 59; iter: 0; batch classifier loss: 0.136229; batch adversarial loss: 0.369590\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118539; batch adversarial loss: 0.437742\n",
      "epoch 61; iter: 0; batch classifier loss: 0.098472; batch adversarial loss: 0.430680\n",
      "epoch 62; iter: 0; batch classifier loss: 0.148887; batch adversarial loss: 0.423745\n",
      "epoch 63; iter: 0; batch classifier loss: 0.111274; batch adversarial loss: 0.456635\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057389; batch adversarial loss: 0.492364\n",
      "epoch 65; iter: 0; batch classifier loss: 0.104803; batch adversarial loss: 0.439010\n",
      "epoch 66; iter: 0; batch classifier loss: 0.076156; batch adversarial loss: 0.362906\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098660; batch adversarial loss: 0.475093\n",
      "epoch 68; iter: 0; batch classifier loss: 0.089472; batch adversarial loss: 0.467241\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072659; batch adversarial loss: 0.474364\n",
      "epoch 70; iter: 0; batch classifier loss: 0.142957; batch adversarial loss: 0.473800\n",
      "epoch 71; iter: 0; batch classifier loss: 0.147213; batch adversarial loss: 0.531494\n",
      "epoch 72; iter: 0; batch classifier loss: 0.120124; batch adversarial loss: 0.380449\n",
      "epoch 73; iter: 0; batch classifier loss: 0.122086; batch adversarial loss: 0.496175\n",
      "epoch 74; iter: 0; batch classifier loss: 0.172269; batch adversarial loss: 0.473834\n",
      "epoch 75; iter: 0; batch classifier loss: 0.129593; batch adversarial loss: 0.415303\n",
      "epoch 76; iter: 0; batch classifier loss: 0.094625; batch adversarial loss: 0.404101\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094271; batch adversarial loss: 0.475784\n",
      "epoch 78; iter: 0; batch classifier loss: 0.129397; batch adversarial loss: 0.505935\n",
      "epoch 79; iter: 0; batch classifier loss: 0.101790; batch adversarial loss: 0.441557\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078179; batch adversarial loss: 0.412726\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120024; batch adversarial loss: 0.533490\n",
      "epoch 82; iter: 0; batch classifier loss: 0.175731; batch adversarial loss: 0.500564\n",
      "epoch 83; iter: 0; batch classifier loss: 0.095582; batch adversarial loss: 0.385098\n",
      "epoch 84; iter: 0; batch classifier loss: 0.123254; batch adversarial loss: 0.431117\n",
      "epoch 85; iter: 0; batch classifier loss: 0.122672; batch adversarial loss: 0.407542\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069306; batch adversarial loss: 0.571602\n",
      "epoch 87; iter: 0; batch classifier loss: 0.095714; batch adversarial loss: 0.461308\n",
      "epoch 88; iter: 0; batch classifier loss: 0.101968; batch adversarial loss: 0.451793\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098774; batch adversarial loss: 0.481010\n",
      "epoch 90; iter: 0; batch classifier loss: 0.093731; batch adversarial loss: 0.415826\n",
      "epoch 91; iter: 0; batch classifier loss: 0.154607; batch adversarial loss: 0.474630\n",
      "epoch 92; iter: 0; batch classifier loss: 0.141597; batch adversarial loss: 0.356208\n",
      "epoch 93; iter: 0; batch classifier loss: 0.088666; batch adversarial loss: 0.482287\n",
      "epoch 94; iter: 0; batch classifier loss: 0.082521; batch adversarial loss: 0.375003\n",
      "epoch 95; iter: 0; batch classifier loss: 0.098342; batch adversarial loss: 0.587655\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096749; batch adversarial loss: 0.448451\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061835; batch adversarial loss: 0.495801\n",
      "epoch 98; iter: 0; batch classifier loss: 0.094270; batch adversarial loss: 0.427565\n",
      "epoch 99; iter: 0; batch classifier loss: 0.060327; batch adversarial loss: 0.499893\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046271; batch adversarial loss: 0.444285\n",
      "epoch 101; iter: 0; batch classifier loss: 0.117148; batch adversarial loss: 0.541981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.077180; batch adversarial loss: 0.428278\n",
      "epoch 103; iter: 0; batch classifier loss: 0.132807; batch adversarial loss: 0.403848\n",
      "epoch 104; iter: 0; batch classifier loss: 0.110403; batch adversarial loss: 0.482194\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066760; batch adversarial loss: 0.469195\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037789; batch adversarial loss: 0.430969\n",
      "epoch 107; iter: 0; batch classifier loss: 0.086285; batch adversarial loss: 0.443079\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037343; batch adversarial loss: 0.434436\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046905; batch adversarial loss: 0.494009\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046718; batch adversarial loss: 0.489377\n",
      "epoch 111; iter: 0; batch classifier loss: 0.083774; batch adversarial loss: 0.455447\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056099; batch adversarial loss: 0.515853\n",
      "epoch 113; iter: 0; batch classifier loss: 0.077077; batch adversarial loss: 0.502233\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046803; batch adversarial loss: 0.515424\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070203; batch adversarial loss: 0.426105\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036498; batch adversarial loss: 0.462202\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035306; batch adversarial loss: 0.429693\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057870; batch adversarial loss: 0.514529\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051204; batch adversarial loss: 0.442095\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060355; batch adversarial loss: 0.381722\n",
      "epoch 121; iter: 0; batch classifier loss: 0.016437; batch adversarial loss: 0.575698\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041591; batch adversarial loss: 0.443274\n",
      "epoch 123; iter: 0; batch classifier loss: 0.058081; batch adversarial loss: 0.532322\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048474; batch adversarial loss: 0.418630\n",
      "epoch 125; iter: 0; batch classifier loss: 0.089904; batch adversarial loss: 0.505061\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043668; batch adversarial loss: 0.437062\n",
      "epoch 127; iter: 0; batch classifier loss: 0.055851; batch adversarial loss: 0.421511\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049870; batch adversarial loss: 0.409083\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047972; batch adversarial loss: 0.464469\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031120; batch adversarial loss: 0.472071\n",
      "epoch 131; iter: 0; batch classifier loss: 0.095663; batch adversarial loss: 0.514059\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030773; batch adversarial loss: 0.437064\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040501; batch adversarial loss: 0.447174\n",
      "epoch 134; iter: 0; batch classifier loss: 0.060452; batch adversarial loss: 0.473630\n",
      "epoch 135; iter: 0; batch classifier loss: 0.065434; batch adversarial loss: 0.463275\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027953; batch adversarial loss: 0.455065\n",
      "epoch 137; iter: 0; batch classifier loss: 0.082558; batch adversarial loss: 0.452601\n",
      "epoch 138; iter: 0; batch classifier loss: 0.057773; batch adversarial loss: 0.402823\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041733; batch adversarial loss: 0.452035\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037764; batch adversarial loss: 0.492122\n",
      "epoch 141; iter: 0; batch classifier loss: 0.061461; batch adversarial loss: 0.472953\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032146; batch adversarial loss: 0.447471\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031622; batch adversarial loss: 0.479732\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023978; batch adversarial loss: 0.513102\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031824; batch adversarial loss: 0.418946\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044268; batch adversarial loss: 0.554542\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041779; batch adversarial loss: 0.437165\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023403; batch adversarial loss: 0.357160\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021547; batch adversarial loss: 0.512852\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018604; batch adversarial loss: 0.432079\n",
      "epoch 151; iter: 0; batch classifier loss: 0.046309; batch adversarial loss: 0.430282\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008617; batch adversarial loss: 0.464378\n",
      "epoch 153; iter: 0; batch classifier loss: 0.046063; batch adversarial loss: 0.519251\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052329; batch adversarial loss: 0.423374\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034620; batch adversarial loss: 0.367922\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018664; batch adversarial loss: 0.412281\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024081; batch adversarial loss: 0.427011\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028200; batch adversarial loss: 0.579965\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033870; batch adversarial loss: 0.452156\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008753; batch adversarial loss: 0.398724\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043475; batch adversarial loss: 0.487125\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019162; batch adversarial loss: 0.496537\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026358; batch adversarial loss: 0.520509\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022011; batch adversarial loss: 0.475682\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012317; batch adversarial loss: 0.423088\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022150; batch adversarial loss: 0.461782\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012731; batch adversarial loss: 0.500745\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041299; batch adversarial loss: 0.525150\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008072; batch adversarial loss: 0.559317\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019550; batch adversarial loss: 0.473757\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027530; batch adversarial loss: 0.532524\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008534; batch adversarial loss: 0.491105\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032211; batch adversarial loss: 0.424633\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041365; batch adversarial loss: 0.410889\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014919; batch adversarial loss: 0.439600\n",
      "epoch 176; iter: 0; batch classifier loss: 0.043421; batch adversarial loss: 0.462228\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037256; batch adversarial loss: 0.469476\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024473; batch adversarial loss: 0.421031\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030909; batch adversarial loss: 0.382639\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025980; batch adversarial loss: 0.458771\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019554; batch adversarial loss: 0.519214\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013139; batch adversarial loss: 0.426774\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019933; batch adversarial loss: 0.463232\n",
      "epoch 184; iter: 0; batch classifier loss: 0.047705; batch adversarial loss: 0.437192\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023667; batch adversarial loss: 0.513730\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031254; batch adversarial loss: 0.373139\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010964; batch adversarial loss: 0.493577\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023026; batch adversarial loss: 0.495452\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029046; batch adversarial loss: 0.473513\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026246; batch adversarial loss: 0.383410\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017007; batch adversarial loss: 0.471917\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019367; batch adversarial loss: 0.412206\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017120; batch adversarial loss: 0.499860\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020410; batch adversarial loss: 0.478388\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008540; batch adversarial loss: 0.486492\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022663; batch adversarial loss: 0.394975\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013791; batch adversarial loss: 0.376635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.024247; batch adversarial loss: 0.438738\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013962; batch adversarial loss: 0.468680\n",
      "epoch 0; iter: 0; batch classifier loss: 0.649474; batch adversarial loss: 0.872025\n",
      "epoch 1; iter: 0; batch classifier loss: 0.565222; batch adversarial loss: 0.978192\n",
      "epoch 2; iter: 0; batch classifier loss: 0.563932; batch adversarial loss: 0.975713\n",
      "epoch 3; iter: 0; batch classifier loss: 0.686229; batch adversarial loss: 0.913266\n",
      "epoch 4; iter: 0; batch classifier loss: 0.827533; batch adversarial loss: 0.830511\n",
      "epoch 5; iter: 0; batch classifier loss: 0.723788; batch adversarial loss: 0.753706\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590830; batch adversarial loss: 0.679130\n",
      "epoch 7; iter: 0; batch classifier loss: 0.397990; batch adversarial loss: 0.619339\n",
      "epoch 8; iter: 0; batch classifier loss: 0.304613; batch adversarial loss: 0.581263\n",
      "epoch 9; iter: 0; batch classifier loss: 0.212550; batch adversarial loss: 0.586886\n",
      "epoch 10; iter: 0; batch classifier loss: 0.303010; batch adversarial loss: 0.555315\n",
      "epoch 11; iter: 0; batch classifier loss: 0.283543; batch adversarial loss: 0.567691\n",
      "epoch 12; iter: 0; batch classifier loss: 0.233139; batch adversarial loss: 0.509609\n",
      "epoch 13; iter: 0; batch classifier loss: 0.238031; batch adversarial loss: 0.507351\n",
      "epoch 14; iter: 0; batch classifier loss: 0.257039; batch adversarial loss: 0.518395\n",
      "epoch 15; iter: 0; batch classifier loss: 0.224269; batch adversarial loss: 0.476376\n",
      "epoch 16; iter: 0; batch classifier loss: 0.280567; batch adversarial loss: 0.474702\n",
      "epoch 17; iter: 0; batch classifier loss: 0.249972; batch adversarial loss: 0.440921\n",
      "epoch 18; iter: 0; batch classifier loss: 0.172101; batch adversarial loss: 0.420843\n",
      "epoch 19; iter: 0; batch classifier loss: 0.262246; batch adversarial loss: 0.431230\n",
      "epoch 20; iter: 0; batch classifier loss: 0.161274; batch adversarial loss: 0.447046\n",
      "epoch 21; iter: 0; batch classifier loss: 0.266690; batch adversarial loss: 0.437567\n",
      "epoch 22; iter: 0; batch classifier loss: 0.171229; batch adversarial loss: 0.481538\n",
      "epoch 23; iter: 0; batch classifier loss: 0.198946; batch adversarial loss: 0.444900\n",
      "epoch 24; iter: 0; batch classifier loss: 0.171940; batch adversarial loss: 0.364897\n",
      "epoch 25; iter: 0; batch classifier loss: 0.113003; batch adversarial loss: 0.393284\n",
      "epoch 26; iter: 0; batch classifier loss: 0.168974; batch adversarial loss: 0.410913\n",
      "epoch 27; iter: 0; batch classifier loss: 0.134812; batch adversarial loss: 0.466757\n",
      "epoch 28; iter: 0; batch classifier loss: 0.143254; batch adversarial loss: 0.418447\n",
      "epoch 29; iter: 0; batch classifier loss: 0.118405; batch adversarial loss: 0.439708\n",
      "epoch 30; iter: 0; batch classifier loss: 0.174994; batch adversarial loss: 0.434493\n",
      "epoch 31; iter: 0; batch classifier loss: 0.146528; batch adversarial loss: 0.457582\n",
      "epoch 32; iter: 0; batch classifier loss: 0.108377; batch adversarial loss: 0.508808\n",
      "epoch 33; iter: 0; batch classifier loss: 0.088091; batch adversarial loss: 0.529873\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142096; batch adversarial loss: 0.467060\n",
      "epoch 35; iter: 0; batch classifier loss: 0.131957; batch adversarial loss: 0.404992\n",
      "epoch 36; iter: 0; batch classifier loss: 0.090778; batch adversarial loss: 0.407426\n",
      "epoch 37; iter: 0; batch classifier loss: 0.063089; batch adversarial loss: 0.389377\n",
      "epoch 38; iter: 0; batch classifier loss: 0.116143; batch adversarial loss: 0.376790\n",
      "epoch 39; iter: 0; batch classifier loss: 0.117011; batch adversarial loss: 0.446818\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091772; batch adversarial loss: 0.409052\n",
      "epoch 41; iter: 0; batch classifier loss: 0.060143; batch adversarial loss: 0.458033\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116606; batch adversarial loss: 0.531907\n",
      "epoch 43; iter: 0; batch classifier loss: 0.078418; batch adversarial loss: 0.389120\n",
      "epoch 44; iter: 0; batch classifier loss: 0.080408; batch adversarial loss: 0.425618\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086069; batch adversarial loss: 0.454056\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104424; batch adversarial loss: 0.388287\n",
      "epoch 47; iter: 0; batch classifier loss: 0.057471; batch adversarial loss: 0.423092\n",
      "epoch 48; iter: 0; batch classifier loss: 0.064557; batch adversarial loss: 0.437267\n",
      "epoch 49; iter: 0; batch classifier loss: 0.103550; batch adversarial loss: 0.460255\n",
      "epoch 50; iter: 0; batch classifier loss: 0.134646; batch adversarial loss: 0.353662\n",
      "epoch 51; iter: 0; batch classifier loss: 0.057362; batch adversarial loss: 0.396836\n",
      "epoch 52; iter: 0; batch classifier loss: 0.130110; batch adversarial loss: 0.389670\n",
      "epoch 53; iter: 0; batch classifier loss: 0.113001; batch adversarial loss: 0.407178\n",
      "epoch 54; iter: 0; batch classifier loss: 0.067901; batch adversarial loss: 0.376969\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086567; batch adversarial loss: 0.492987\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084281; batch adversarial loss: 0.436453\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082345; batch adversarial loss: 0.431519\n",
      "epoch 58; iter: 0; batch classifier loss: 0.038050; batch adversarial loss: 0.461949\n",
      "epoch 59; iter: 0; batch classifier loss: 0.051614; batch adversarial loss: 0.414644\n",
      "epoch 60; iter: 0; batch classifier loss: 0.075717; batch adversarial loss: 0.446714\n",
      "epoch 61; iter: 0; batch classifier loss: 0.082447; batch adversarial loss: 0.428923\n",
      "epoch 62; iter: 0; batch classifier loss: 0.100733; batch adversarial loss: 0.402871\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079293; batch adversarial loss: 0.450598\n",
      "epoch 64; iter: 0; batch classifier loss: 0.054641; batch adversarial loss: 0.376321\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079394; batch adversarial loss: 0.353918\n",
      "epoch 66; iter: 0; batch classifier loss: 0.059910; batch adversarial loss: 0.427603\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065963; batch adversarial loss: 0.421142\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076778; batch adversarial loss: 0.412403\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076988; batch adversarial loss: 0.470371\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066514; batch adversarial loss: 0.264914\n",
      "epoch 71; iter: 0; batch classifier loss: 0.047330; batch adversarial loss: 0.436696\n",
      "epoch 72; iter: 0; batch classifier loss: 0.040261; batch adversarial loss: 0.481823\n",
      "epoch 73; iter: 0; batch classifier loss: 0.071211; batch adversarial loss: 0.381919\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073688; batch adversarial loss: 0.407125\n",
      "epoch 75; iter: 0; batch classifier loss: 0.058588; batch adversarial loss: 0.354591\n",
      "epoch 76; iter: 0; batch classifier loss: 0.047528; batch adversarial loss: 0.355590\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062596; batch adversarial loss: 0.333679\n",
      "epoch 78; iter: 0; batch classifier loss: 0.104770; batch adversarial loss: 0.426165\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060571; batch adversarial loss: 0.442795\n",
      "epoch 80; iter: 0; batch classifier loss: 0.066150; batch adversarial loss: 0.431961\n",
      "epoch 81; iter: 0; batch classifier loss: 0.046025; batch adversarial loss: 0.342244\n",
      "epoch 82; iter: 0; batch classifier loss: 0.085727; batch adversarial loss: 0.332906\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072776; batch adversarial loss: 0.443075\n",
      "epoch 84; iter: 0; batch classifier loss: 0.042653; batch adversarial loss: 0.375736\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088265; batch adversarial loss: 0.462941\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065932; batch adversarial loss: 0.403432\n",
      "epoch 87; iter: 0; batch classifier loss: 0.043593; batch adversarial loss: 0.493877\n",
      "epoch 88; iter: 0; batch classifier loss: 0.061908; batch adversarial loss: 0.384228\n",
      "epoch 89; iter: 0; batch classifier loss: 0.029149; batch adversarial loss: 0.428247\n",
      "epoch 90; iter: 0; batch classifier loss: 0.089152; batch adversarial loss: 0.468769\n",
      "epoch 91; iter: 0; batch classifier loss: 0.076473; batch adversarial loss: 0.476269\n",
      "epoch 92; iter: 0; batch classifier loss: 0.032798; batch adversarial loss: 0.475601\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069505; batch adversarial loss: 0.348547\n",
      "epoch 94; iter: 0; batch classifier loss: 0.060698; batch adversarial loss: 0.415753\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042322; batch adversarial loss: 0.503347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.039103; batch adversarial loss: 0.387704\n",
      "epoch 97; iter: 0; batch classifier loss: 0.040304; batch adversarial loss: 0.388376\n",
      "epoch 98; iter: 0; batch classifier loss: 0.070226; batch adversarial loss: 0.432146\n",
      "epoch 99; iter: 0; batch classifier loss: 0.066896; batch adversarial loss: 0.469081\n",
      "epoch 100; iter: 0; batch classifier loss: 0.042202; batch adversarial loss: 0.376040\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056211; batch adversarial loss: 0.381759\n",
      "epoch 102; iter: 0; batch classifier loss: 0.076305; batch adversarial loss: 0.426894\n",
      "epoch 103; iter: 0; batch classifier loss: 0.051637; batch adversarial loss: 0.421183\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065136; batch adversarial loss: 0.487823\n",
      "epoch 105; iter: 0; batch classifier loss: 0.109126; batch adversarial loss: 0.443817\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039790; batch adversarial loss: 0.353954\n",
      "epoch 107; iter: 0; batch classifier loss: 0.080757; batch adversarial loss: 0.368586\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058030; batch adversarial loss: 0.436104\n",
      "epoch 109; iter: 0; batch classifier loss: 0.087449; batch adversarial loss: 0.393733\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051929; batch adversarial loss: 0.483209\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042374; batch adversarial loss: 0.333475\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040668; batch adversarial loss: 0.430172\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052326; batch adversarial loss: 0.433432\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052804; batch adversarial loss: 0.474328\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054126; batch adversarial loss: 0.449052\n",
      "epoch 116; iter: 0; batch classifier loss: 0.061253; batch adversarial loss: 0.476460\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033477; batch adversarial loss: 0.451348\n",
      "epoch 118; iter: 0; batch classifier loss: 0.090435; batch adversarial loss: 0.421911\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048402; batch adversarial loss: 0.401784\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074238; batch adversarial loss: 0.490461\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049748; batch adversarial loss: 0.402573\n",
      "epoch 122; iter: 0; batch classifier loss: 0.063879; batch adversarial loss: 0.552769\n",
      "epoch 123; iter: 0; batch classifier loss: 0.062659; batch adversarial loss: 0.484718\n",
      "epoch 124; iter: 0; batch classifier loss: 0.058360; batch adversarial loss: 0.392128\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053403; batch adversarial loss: 0.396091\n",
      "epoch 126; iter: 0; batch classifier loss: 0.128570; batch adversarial loss: 0.399694\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035543; batch adversarial loss: 0.432427\n",
      "epoch 128; iter: 0; batch classifier loss: 0.102186; batch adversarial loss: 0.543597\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029942; batch adversarial loss: 0.460381\n",
      "epoch 130; iter: 0; batch classifier loss: 0.081268; batch adversarial loss: 0.443108\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055655; batch adversarial loss: 0.408180\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021617; batch adversarial loss: 0.403110\n",
      "epoch 133; iter: 0; batch classifier loss: 0.076827; batch adversarial loss: 0.431794\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043337; batch adversarial loss: 0.432349\n",
      "epoch 135; iter: 0; batch classifier loss: 0.069108; batch adversarial loss: 0.401168\n",
      "epoch 136; iter: 0; batch classifier loss: 0.058077; batch adversarial loss: 0.451944\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042996; batch adversarial loss: 0.483357\n",
      "epoch 138; iter: 0; batch classifier loss: 0.095705; batch adversarial loss: 0.458710\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029635; batch adversarial loss: 0.421192\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023049; batch adversarial loss: 0.504875\n",
      "epoch 141; iter: 0; batch classifier loss: 0.056011; batch adversarial loss: 0.389837\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036289; batch adversarial loss: 0.367380\n",
      "epoch 143; iter: 0; batch classifier loss: 0.057106; batch adversarial loss: 0.373058\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048589; batch adversarial loss: 0.387327\n",
      "epoch 145; iter: 0; batch classifier loss: 0.082354; batch adversarial loss: 0.552219\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039392; batch adversarial loss: 0.468931\n",
      "epoch 147; iter: 0; batch classifier loss: 0.054917; batch adversarial loss: 0.421747\n",
      "epoch 148; iter: 0; batch classifier loss: 0.080263; batch adversarial loss: 0.360988\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035408; batch adversarial loss: 0.427016\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033139; batch adversarial loss: 0.448815\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040348; batch adversarial loss: 0.378565\n",
      "epoch 152; iter: 0; batch classifier loss: 0.085317; batch adversarial loss: 0.470629\n",
      "epoch 153; iter: 0; batch classifier loss: 0.058224; batch adversarial loss: 0.393406\n",
      "epoch 154; iter: 0; batch classifier loss: 0.051732; batch adversarial loss: 0.500688\n",
      "epoch 155; iter: 0; batch classifier loss: 0.054366; batch adversarial loss: 0.462744\n",
      "epoch 156; iter: 0; batch classifier loss: 0.088379; batch adversarial loss: 0.358822\n",
      "epoch 157; iter: 0; batch classifier loss: 0.060841; batch adversarial loss: 0.440215\n",
      "epoch 158; iter: 0; batch classifier loss: 0.072106; batch adversarial loss: 0.381492\n",
      "epoch 159; iter: 0; batch classifier loss: 0.079235; batch adversarial loss: 0.484042\n",
      "epoch 160; iter: 0; batch classifier loss: 0.050739; batch adversarial loss: 0.426099\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033569; batch adversarial loss: 0.363817\n",
      "epoch 162; iter: 0; batch classifier loss: 0.048152; batch adversarial loss: 0.424968\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038003; batch adversarial loss: 0.387218\n",
      "epoch 164; iter: 0; batch classifier loss: 0.055414; batch adversarial loss: 0.492150\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033353; batch adversarial loss: 0.400618\n",
      "epoch 166; iter: 0; batch classifier loss: 0.052922; batch adversarial loss: 0.413503\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029891; batch adversarial loss: 0.394436\n",
      "epoch 168; iter: 0; batch classifier loss: 0.043786; batch adversarial loss: 0.420784\n",
      "epoch 169; iter: 0; batch classifier loss: 0.051081; batch adversarial loss: 0.339395\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029203; batch adversarial loss: 0.375241\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047580; batch adversarial loss: 0.411864\n",
      "epoch 172; iter: 0; batch classifier loss: 0.047654; batch adversarial loss: 0.467359\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029726; batch adversarial loss: 0.364779\n",
      "epoch 174; iter: 0; batch classifier loss: 0.046781; batch adversarial loss: 0.410689\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029266; batch adversarial loss: 0.345172\n",
      "epoch 176; iter: 0; batch classifier loss: 0.053674; batch adversarial loss: 0.475311\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036837; batch adversarial loss: 0.409990\n",
      "epoch 178; iter: 0; batch classifier loss: 0.047675; batch adversarial loss: 0.456226\n",
      "epoch 179; iter: 0; batch classifier loss: 0.045385; batch adversarial loss: 0.451317\n",
      "epoch 180; iter: 0; batch classifier loss: 0.047704; batch adversarial loss: 0.457182\n",
      "epoch 181; iter: 0; batch classifier loss: 0.061495; batch adversarial loss: 0.435450\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029803; batch adversarial loss: 0.447699\n",
      "epoch 183; iter: 0; batch classifier loss: 0.049228; batch adversarial loss: 0.368007\n",
      "epoch 184; iter: 0; batch classifier loss: 0.050211; batch adversarial loss: 0.365209\n",
      "epoch 185; iter: 0; batch classifier loss: 0.059596; batch adversarial loss: 0.497180\n",
      "epoch 186; iter: 0; batch classifier loss: 0.044864; batch adversarial loss: 0.486287\n",
      "epoch 187; iter: 0; batch classifier loss: 0.050217; batch adversarial loss: 0.394818\n",
      "epoch 188; iter: 0; batch classifier loss: 0.071964; batch adversarial loss: 0.431486\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031149; batch adversarial loss: 0.426782\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035844; batch adversarial loss: 0.338182\n",
      "epoch 191; iter: 0; batch classifier loss: 0.038327; batch adversarial loss: 0.490202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.064362; batch adversarial loss: 0.440773\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037659; batch adversarial loss: 0.364911\n",
      "epoch 194; iter: 0; batch classifier loss: 0.029119; batch adversarial loss: 0.366529\n",
      "epoch 195; iter: 0; batch classifier loss: 0.066526; batch adversarial loss: 0.507488\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030257; batch adversarial loss: 0.457534\n",
      "epoch 197; iter: 0; batch classifier loss: 0.046708; batch adversarial loss: 0.513886\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028609; batch adversarial loss: 0.430788\n",
      "epoch 199; iter: 0; batch classifier loss: 0.029175; batch adversarial loss: 0.381788\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696476; batch adversarial loss: 0.702070\n",
      "epoch 1; iter: 0; batch classifier loss: 0.575335; batch adversarial loss: 0.664227\n",
      "epoch 2; iter: 0; batch classifier loss: 0.479968; batch adversarial loss: 0.629439\n",
      "epoch 3; iter: 0; batch classifier loss: 0.410855; batch adversarial loss: 0.621344\n",
      "epoch 4; iter: 0; batch classifier loss: 0.401098; batch adversarial loss: 0.619269\n",
      "epoch 5; iter: 0; batch classifier loss: 0.444171; batch adversarial loss: 0.602981\n",
      "epoch 6; iter: 0; batch classifier loss: 0.373807; batch adversarial loss: 0.591422\n",
      "epoch 7; iter: 0; batch classifier loss: 0.570199; batch adversarial loss: 0.568939\n",
      "epoch 8; iter: 0; batch classifier loss: 0.368884; batch adversarial loss: 0.553582\n",
      "epoch 9; iter: 0; batch classifier loss: 0.459213; batch adversarial loss: 0.566579\n",
      "epoch 10; iter: 0; batch classifier loss: 0.346607; batch adversarial loss: 0.538438\n",
      "epoch 11; iter: 0; batch classifier loss: 0.410423; batch adversarial loss: 0.477559\n",
      "epoch 12; iter: 0; batch classifier loss: 0.376579; batch adversarial loss: 0.491194\n",
      "epoch 13; iter: 0; batch classifier loss: 0.369275; batch adversarial loss: 0.497800\n",
      "epoch 14; iter: 0; batch classifier loss: 0.411734; batch adversarial loss: 0.503975\n",
      "epoch 15; iter: 0; batch classifier loss: 0.415994; batch adversarial loss: 0.497817\n",
      "epoch 16; iter: 0; batch classifier loss: 0.371982; batch adversarial loss: 0.463697\n",
      "epoch 17; iter: 0; batch classifier loss: 0.338839; batch adversarial loss: 0.494896\n",
      "epoch 18; iter: 0; batch classifier loss: 0.419760; batch adversarial loss: 0.516126\n",
      "epoch 19; iter: 0; batch classifier loss: 0.269438; batch adversarial loss: 0.560708\n",
      "epoch 20; iter: 0; batch classifier loss: 0.274241; batch adversarial loss: 0.465116\n",
      "epoch 21; iter: 0; batch classifier loss: 0.210572; batch adversarial loss: 0.564766\n",
      "epoch 22; iter: 0; batch classifier loss: 0.239591; batch adversarial loss: 0.424716\n",
      "epoch 23; iter: 0; batch classifier loss: 0.230701; batch adversarial loss: 0.482914\n",
      "epoch 24; iter: 0; batch classifier loss: 0.197277; batch adversarial loss: 0.483983\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215967; batch adversarial loss: 0.479429\n",
      "epoch 26; iter: 0; batch classifier loss: 0.232247; batch adversarial loss: 0.421400\n",
      "epoch 27; iter: 0; batch classifier loss: 0.219420; batch adversarial loss: 0.468198\n",
      "epoch 28; iter: 0; batch classifier loss: 0.215400; batch adversarial loss: 0.482979\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178142; batch adversarial loss: 0.443930\n",
      "epoch 30; iter: 0; batch classifier loss: 0.140652; batch adversarial loss: 0.534779\n",
      "epoch 31; iter: 0; batch classifier loss: 0.171227; batch adversarial loss: 0.474343\n",
      "epoch 32; iter: 0; batch classifier loss: 0.141407; batch adversarial loss: 0.505416\n",
      "epoch 33; iter: 0; batch classifier loss: 0.185193; batch adversarial loss: 0.522949\n",
      "epoch 34; iter: 0; batch classifier loss: 0.182691; batch adversarial loss: 0.444061\n",
      "epoch 35; iter: 0; batch classifier loss: 0.199411; batch adversarial loss: 0.469682\n",
      "epoch 36; iter: 0; batch classifier loss: 0.202694; batch adversarial loss: 0.430172\n",
      "epoch 37; iter: 0; batch classifier loss: 0.213733; batch adversarial loss: 0.391336\n",
      "epoch 38; iter: 0; batch classifier loss: 0.192395; batch adversarial loss: 0.439036\n",
      "epoch 39; iter: 0; batch classifier loss: 0.166577; batch adversarial loss: 0.438143\n",
      "epoch 40; iter: 0; batch classifier loss: 0.159312; batch adversarial loss: 0.418263\n",
      "epoch 41; iter: 0; batch classifier loss: 0.159576; batch adversarial loss: 0.574273\n",
      "epoch 42; iter: 0; batch classifier loss: 0.142672; batch adversarial loss: 0.490195\n",
      "epoch 43; iter: 0; batch classifier loss: 0.158037; batch adversarial loss: 0.351951\n",
      "epoch 44; iter: 0; batch classifier loss: 0.209935; batch adversarial loss: 0.487361\n",
      "epoch 45; iter: 0; batch classifier loss: 0.166894; batch adversarial loss: 0.471454\n",
      "epoch 46; iter: 0; batch classifier loss: 0.164991; batch adversarial loss: 0.481673\n",
      "epoch 47; iter: 0; batch classifier loss: 0.142920; batch adversarial loss: 0.467566\n",
      "epoch 48; iter: 0; batch classifier loss: 0.139818; batch adversarial loss: 0.463099\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094915; batch adversarial loss: 0.470995\n",
      "epoch 50; iter: 0; batch classifier loss: 0.125242; batch adversarial loss: 0.433775\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109789; batch adversarial loss: 0.479565\n",
      "epoch 52; iter: 0; batch classifier loss: 0.139779; batch adversarial loss: 0.405684\n",
      "epoch 53; iter: 0; batch classifier loss: 0.117719; batch adversarial loss: 0.458818\n",
      "epoch 54; iter: 0; batch classifier loss: 0.105115; batch adversarial loss: 0.485849\n",
      "epoch 55; iter: 0; batch classifier loss: 0.108762; batch adversarial loss: 0.451339\n",
      "epoch 56; iter: 0; batch classifier loss: 0.120440; batch adversarial loss: 0.478608\n",
      "epoch 57; iter: 0; batch classifier loss: 0.096138; batch adversarial loss: 0.569947\n",
      "epoch 58; iter: 0; batch classifier loss: 0.116064; batch adversarial loss: 0.451104\n",
      "epoch 59; iter: 0; batch classifier loss: 0.095966; batch adversarial loss: 0.434180\n",
      "epoch 60; iter: 0; batch classifier loss: 0.073072; batch adversarial loss: 0.409291\n",
      "epoch 61; iter: 0; batch classifier loss: 0.085686; batch adversarial loss: 0.526886\n",
      "epoch 62; iter: 0; batch classifier loss: 0.047083; batch adversarial loss: 0.464965\n",
      "epoch 63; iter: 0; batch classifier loss: 0.057859; batch adversarial loss: 0.504773\n",
      "epoch 64; iter: 0; batch classifier loss: 0.086615; batch adversarial loss: 0.456618\n",
      "epoch 65; iter: 0; batch classifier loss: 0.059103; batch adversarial loss: 0.468991\n",
      "epoch 66; iter: 0; batch classifier loss: 0.110496; batch adversarial loss: 0.472977\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069648; batch adversarial loss: 0.539758\n",
      "epoch 68; iter: 0; batch classifier loss: 0.073487; batch adversarial loss: 0.546138\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075477; batch adversarial loss: 0.504167\n",
      "epoch 70; iter: 0; batch classifier loss: 0.106726; batch adversarial loss: 0.452522\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092676; batch adversarial loss: 0.467848\n",
      "epoch 72; iter: 0; batch classifier loss: 0.104997; batch adversarial loss: 0.365977\n",
      "epoch 73; iter: 0; batch classifier loss: 0.072118; batch adversarial loss: 0.563849\n",
      "epoch 74; iter: 0; batch classifier loss: 0.062795; batch adversarial loss: 0.463353\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083813; batch adversarial loss: 0.436404\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063652; batch adversarial loss: 0.456324\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104023; batch adversarial loss: 0.403336\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082914; batch adversarial loss: 0.419908\n",
      "epoch 79; iter: 0; batch classifier loss: 0.104732; batch adversarial loss: 0.391219\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068613; batch adversarial loss: 0.426685\n",
      "epoch 81; iter: 0; batch classifier loss: 0.112232; batch adversarial loss: 0.327764\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059607; batch adversarial loss: 0.535989\n",
      "epoch 83; iter: 0; batch classifier loss: 0.047861; batch adversarial loss: 0.553203\n",
      "epoch 84; iter: 0; batch classifier loss: 0.043345; batch adversarial loss: 0.469086\n",
      "epoch 85; iter: 0; batch classifier loss: 0.035645; batch adversarial loss: 0.568403\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053922; batch adversarial loss: 0.462783\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053583; batch adversarial loss: 0.440208\n",
      "epoch 88; iter: 0; batch classifier loss: 0.045551; batch adversarial loss: 0.412922\n",
      "epoch 89; iter: 0; batch classifier loss: 0.045826; batch adversarial loss: 0.420029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.043015; batch adversarial loss: 0.383565\n",
      "epoch 91; iter: 0; batch classifier loss: 0.085113; batch adversarial loss: 0.359801\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050010; batch adversarial loss: 0.499733\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043442; batch adversarial loss: 0.472942\n",
      "epoch 94; iter: 0; batch classifier loss: 0.034371; batch adversarial loss: 0.517864\n",
      "epoch 95; iter: 0; batch classifier loss: 0.035912; batch adversarial loss: 0.445599\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061186; batch adversarial loss: 0.360039\n",
      "epoch 97; iter: 0; batch classifier loss: 0.074267; batch adversarial loss: 0.497941\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045196; batch adversarial loss: 0.369751\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037148; batch adversarial loss: 0.475298\n",
      "epoch 100; iter: 0; batch classifier loss: 0.032324; batch adversarial loss: 0.493571\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037584; batch adversarial loss: 0.371421\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068483; batch adversarial loss: 0.411969\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033912; batch adversarial loss: 0.439879\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041142; batch adversarial loss: 0.525289\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038546; batch adversarial loss: 0.444824\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061123; batch adversarial loss: 0.478427\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066410; batch adversarial loss: 0.403821\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038081; batch adversarial loss: 0.473619\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067432; batch adversarial loss: 0.432333\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026221; batch adversarial loss: 0.371116\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048273; batch adversarial loss: 0.473456\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024569; batch adversarial loss: 0.456318\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047884; batch adversarial loss: 0.411289\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053637; batch adversarial loss: 0.358799\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034252; batch adversarial loss: 0.375185\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029705; batch adversarial loss: 0.511627\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033077; batch adversarial loss: 0.413887\n",
      "epoch 118; iter: 0; batch classifier loss: 0.014634; batch adversarial loss: 0.378732\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048602; batch adversarial loss: 0.452214\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033150; batch adversarial loss: 0.538437\n",
      "epoch 121; iter: 0; batch classifier loss: 0.022368; batch adversarial loss: 0.459087\n",
      "epoch 122; iter: 0; batch classifier loss: 0.014811; batch adversarial loss: 0.417421\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024650; batch adversarial loss: 0.441825\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037456; batch adversarial loss: 0.441238\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038173; batch adversarial loss: 0.423236\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021215; batch adversarial loss: 0.467808\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019161; batch adversarial loss: 0.531935\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024628; batch adversarial loss: 0.486446\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031357; batch adversarial loss: 0.449515\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024235; batch adversarial loss: 0.462578\n",
      "epoch 131; iter: 0; batch classifier loss: 0.057899; batch adversarial loss: 0.440463\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039159; batch adversarial loss: 0.430111\n",
      "epoch 133; iter: 0; batch classifier loss: 0.010447; batch adversarial loss: 0.457836\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029416; batch adversarial loss: 0.407155\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057387; batch adversarial loss: 0.492590\n",
      "epoch 136; iter: 0; batch classifier loss: 0.011367; batch adversarial loss: 0.497181\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037104; batch adversarial loss: 0.459098\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035992; batch adversarial loss: 0.498362\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015701; batch adversarial loss: 0.355860\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031339; batch adversarial loss: 0.553689\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032264; batch adversarial loss: 0.525322\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017068; batch adversarial loss: 0.491430\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022075; batch adversarial loss: 0.537214\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034690; batch adversarial loss: 0.489169\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016719; batch adversarial loss: 0.439183\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024203; batch adversarial loss: 0.393761\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031443; batch adversarial loss: 0.390066\n",
      "epoch 148; iter: 0; batch classifier loss: 0.009209; batch adversarial loss: 0.443484\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036595; batch adversarial loss: 0.472692\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030479; batch adversarial loss: 0.547609\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021061; batch adversarial loss: 0.407745\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016127; batch adversarial loss: 0.434231\n",
      "epoch 153; iter: 0; batch classifier loss: 0.046156; batch adversarial loss: 0.400532\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028241; batch adversarial loss: 0.454269\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019012; batch adversarial loss: 0.410332\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017030; batch adversarial loss: 0.501220\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016268; batch adversarial loss: 0.434219\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018229; batch adversarial loss: 0.383524\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020929; batch adversarial loss: 0.477963\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007709; batch adversarial loss: 0.418905\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017122; batch adversarial loss: 0.496245\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031240; batch adversarial loss: 0.573850\n",
      "epoch 163; iter: 0; batch classifier loss: 0.008811; batch adversarial loss: 0.481494\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038682; batch adversarial loss: 0.372862\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021302; batch adversarial loss: 0.446917\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019949; batch adversarial loss: 0.387531\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033690; batch adversarial loss: 0.521072\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038519; batch adversarial loss: 0.601838\n",
      "epoch 169; iter: 0; batch classifier loss: 0.005576; batch adversarial loss: 0.404868\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034693; batch adversarial loss: 0.448623\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014893; batch adversarial loss: 0.416328\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021964; batch adversarial loss: 0.542456\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009346; batch adversarial loss: 0.510750\n",
      "epoch 174; iter: 0; batch classifier loss: 0.003628; batch adversarial loss: 0.446216\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037297; batch adversarial loss: 0.486167\n",
      "epoch 176; iter: 0; batch classifier loss: 0.003408; batch adversarial loss: 0.516934\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025161; batch adversarial loss: 0.469146\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032823; batch adversarial loss: 0.458571\n",
      "epoch 179; iter: 0; batch classifier loss: 0.041809; batch adversarial loss: 0.426432\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017289; batch adversarial loss: 0.432108\n",
      "epoch 181; iter: 0; batch classifier loss: 0.005057; batch adversarial loss: 0.539054\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032488; batch adversarial loss: 0.484663\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015900; batch adversarial loss: 0.513575\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029432; batch adversarial loss: 0.491258\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019205; batch adversarial loss: 0.484103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.027346; batch adversarial loss: 0.510225\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009557; batch adversarial loss: 0.483608\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012101; batch adversarial loss: 0.546616\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006872; batch adversarial loss: 0.430296\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006235; batch adversarial loss: 0.441089\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026892; batch adversarial loss: 0.576884\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004458; batch adversarial loss: 0.409686\n",
      "epoch 193; iter: 0; batch classifier loss: 0.002329; batch adversarial loss: 0.383005\n",
      "epoch 194; iter: 0; batch classifier loss: 0.045697; batch adversarial loss: 0.437709\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004882; batch adversarial loss: 0.412335\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012055; batch adversarial loss: 0.416566\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009180; batch adversarial loss: 0.408675\n",
      "epoch 198; iter: 0; batch classifier loss: 0.049160; batch adversarial loss: 0.509469\n",
      "epoch 199; iter: 0; batch classifier loss: 0.003575; batch adversarial loss: 0.460754\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666643; batch adversarial loss: 0.689717\n",
      "epoch 1; iter: 0; batch classifier loss: 0.408215; batch adversarial loss: 0.657624\n",
      "epoch 2; iter: 0; batch classifier loss: 0.450894; batch adversarial loss: 0.638884\n",
      "epoch 3; iter: 0; batch classifier loss: 0.496175; batch adversarial loss: 0.627804\n",
      "epoch 4; iter: 0; batch classifier loss: 0.416225; batch adversarial loss: 0.588305\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552555; batch adversarial loss: 0.574628\n",
      "epoch 6; iter: 0; batch classifier loss: 0.508378; batch adversarial loss: 0.600439\n",
      "epoch 7; iter: 0; batch classifier loss: 0.449266; batch adversarial loss: 0.578540\n",
      "epoch 8; iter: 0; batch classifier loss: 0.377360; batch adversarial loss: 0.557151\n",
      "epoch 9; iter: 0; batch classifier loss: 0.337381; batch adversarial loss: 0.542783\n",
      "epoch 10; iter: 0; batch classifier loss: 0.359928; batch adversarial loss: 0.486176\n",
      "epoch 11; iter: 0; batch classifier loss: 0.425567; batch adversarial loss: 0.522226\n",
      "epoch 12; iter: 0; batch classifier loss: 0.379777; batch adversarial loss: 0.518588\n",
      "epoch 13; iter: 0; batch classifier loss: 0.337283; batch adversarial loss: 0.490615\n",
      "epoch 14; iter: 0; batch classifier loss: 0.256796; batch adversarial loss: 0.538504\n",
      "epoch 15; iter: 0; batch classifier loss: 0.330859; batch adversarial loss: 0.519657\n",
      "epoch 16; iter: 0; batch classifier loss: 0.343882; batch adversarial loss: 0.500824\n",
      "epoch 17; iter: 0; batch classifier loss: 0.304629; batch adversarial loss: 0.494861\n",
      "epoch 18; iter: 0; batch classifier loss: 0.224981; batch adversarial loss: 0.493800\n",
      "epoch 19; iter: 0; batch classifier loss: 0.248842; batch adversarial loss: 0.488071\n",
      "epoch 20; iter: 0; batch classifier loss: 0.256582; batch adversarial loss: 0.505640\n",
      "epoch 21; iter: 0; batch classifier loss: 0.259910; batch adversarial loss: 0.493339\n",
      "epoch 22; iter: 0; batch classifier loss: 0.288617; batch adversarial loss: 0.514343\n",
      "epoch 23; iter: 0; batch classifier loss: 0.235624; batch adversarial loss: 0.512188\n",
      "epoch 24; iter: 0; batch classifier loss: 0.205226; batch adversarial loss: 0.465312\n",
      "epoch 25; iter: 0; batch classifier loss: 0.293895; batch adversarial loss: 0.472608\n",
      "epoch 26; iter: 0; batch classifier loss: 0.271142; batch adversarial loss: 0.434651\n",
      "epoch 27; iter: 0; batch classifier loss: 0.245757; batch adversarial loss: 0.468846\n",
      "epoch 28; iter: 0; batch classifier loss: 0.262698; batch adversarial loss: 0.412395\n",
      "epoch 29; iter: 0; batch classifier loss: 0.225360; batch adversarial loss: 0.452850\n",
      "epoch 30; iter: 0; batch classifier loss: 0.275568; batch adversarial loss: 0.500157\n",
      "epoch 31; iter: 0; batch classifier loss: 0.183182; batch adversarial loss: 0.473117\n",
      "epoch 32; iter: 0; batch classifier loss: 0.260444; batch adversarial loss: 0.456086\n",
      "epoch 33; iter: 0; batch classifier loss: 0.277417; batch adversarial loss: 0.461033\n",
      "epoch 34; iter: 0; batch classifier loss: 0.267363; batch adversarial loss: 0.434287\n",
      "epoch 35; iter: 0; batch classifier loss: 0.275166; batch adversarial loss: 0.392887\n",
      "epoch 36; iter: 0; batch classifier loss: 0.171745; batch adversarial loss: 0.524767\n",
      "epoch 37; iter: 0; batch classifier loss: 0.214914; batch adversarial loss: 0.426157\n",
      "epoch 38; iter: 0; batch classifier loss: 0.244595; batch adversarial loss: 0.467524\n",
      "epoch 39; iter: 0; batch classifier loss: 0.198937; batch adversarial loss: 0.502937\n",
      "epoch 40; iter: 0; batch classifier loss: 0.215591; batch adversarial loss: 0.453481\n",
      "epoch 41; iter: 0; batch classifier loss: 0.249207; batch adversarial loss: 0.447552\n",
      "epoch 42; iter: 0; batch classifier loss: 0.253278; batch adversarial loss: 0.435724\n",
      "epoch 43; iter: 0; batch classifier loss: 0.227666; batch adversarial loss: 0.437255\n",
      "epoch 44; iter: 0; batch classifier loss: 0.209367; batch adversarial loss: 0.426820\n",
      "epoch 45; iter: 0; batch classifier loss: 0.207915; batch adversarial loss: 0.413059\n",
      "epoch 46; iter: 0; batch classifier loss: 0.227793; batch adversarial loss: 0.471338\n",
      "epoch 47; iter: 0; batch classifier loss: 0.242468; batch adversarial loss: 0.470525\n",
      "epoch 48; iter: 0; batch classifier loss: 0.207010; batch adversarial loss: 0.448011\n",
      "epoch 49; iter: 0; batch classifier loss: 0.158533; batch adversarial loss: 0.423209\n",
      "epoch 50; iter: 0; batch classifier loss: 0.182537; batch adversarial loss: 0.447730\n",
      "epoch 51; iter: 0; batch classifier loss: 0.166597; batch adversarial loss: 0.446847\n",
      "epoch 52; iter: 0; batch classifier loss: 0.324601; batch adversarial loss: 0.446782\n",
      "epoch 53; iter: 0; batch classifier loss: 0.137838; batch adversarial loss: 0.529176\n",
      "epoch 54; iter: 0; batch classifier loss: 0.147120; batch adversarial loss: 0.410981\n",
      "epoch 55; iter: 0; batch classifier loss: 0.193651; batch adversarial loss: 0.519349\n",
      "epoch 56; iter: 0; batch classifier loss: 0.164476; batch adversarial loss: 0.483226\n",
      "epoch 57; iter: 0; batch classifier loss: 0.209063; batch adversarial loss: 0.422002\n",
      "epoch 58; iter: 0; batch classifier loss: 0.198910; batch adversarial loss: 0.459706\n",
      "epoch 59; iter: 0; batch classifier loss: 0.204253; batch adversarial loss: 0.433721\n",
      "epoch 60; iter: 0; batch classifier loss: 0.189216; batch adversarial loss: 0.446342\n",
      "epoch 61; iter: 0; batch classifier loss: 0.254488; batch adversarial loss: 0.459644\n",
      "epoch 62; iter: 0; batch classifier loss: 0.144196; batch adversarial loss: 0.554364\n",
      "epoch 63; iter: 0; batch classifier loss: 0.206808; batch adversarial loss: 0.470070\n",
      "epoch 64; iter: 0; batch classifier loss: 0.179788; batch adversarial loss: 0.554326\n",
      "epoch 65; iter: 0; batch classifier loss: 0.133098; batch adversarial loss: 0.446291\n",
      "epoch 66; iter: 0; batch classifier loss: 0.128060; batch adversarial loss: 0.446034\n",
      "epoch 67; iter: 0; batch classifier loss: 0.111082; batch adversarial loss: 0.449784\n",
      "epoch 68; iter: 0; batch classifier loss: 0.169870; batch adversarial loss: 0.414098\n",
      "epoch 69; iter: 0; batch classifier loss: 0.202322; batch adversarial loss: 0.351147\n",
      "epoch 70; iter: 0; batch classifier loss: 0.132569; batch adversarial loss: 0.385782\n",
      "epoch 71; iter: 0; batch classifier loss: 0.188695; batch adversarial loss: 0.492927\n",
      "epoch 72; iter: 0; batch classifier loss: 0.209266; batch adversarial loss: 0.374718\n",
      "epoch 73; iter: 0; batch classifier loss: 0.200950; batch adversarial loss: 0.531553\n",
      "epoch 74; iter: 0; batch classifier loss: 0.162392; batch adversarial loss: 0.595175\n",
      "epoch 75; iter: 0; batch classifier loss: 0.173505; batch adversarial loss: 0.373637\n",
      "epoch 76; iter: 0; batch classifier loss: 0.160194; batch adversarial loss: 0.493255\n",
      "epoch 77; iter: 0; batch classifier loss: 0.197583; batch adversarial loss: 0.481679\n",
      "epoch 78; iter: 0; batch classifier loss: 0.217717; batch adversarial loss: 0.470181\n",
      "epoch 79; iter: 0; batch classifier loss: 0.189801; batch adversarial loss: 0.397616\n",
      "epoch 80; iter: 0; batch classifier loss: 0.184212; batch adversarial loss: 0.458924\n",
      "epoch 81; iter: 0; batch classifier loss: 0.192055; batch adversarial loss: 0.422173\n",
      "epoch 82; iter: 0; batch classifier loss: 0.210644; batch adversarial loss: 0.435812\n",
      "epoch 83; iter: 0; batch classifier loss: 0.145990; batch adversarial loss: 0.470740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.139541; batch adversarial loss: 0.456684\n",
      "epoch 85; iter: 0; batch classifier loss: 0.151485; batch adversarial loss: 0.494382\n",
      "epoch 86; iter: 0; batch classifier loss: 0.130204; batch adversarial loss: 0.433585\n",
      "epoch 87; iter: 0; batch classifier loss: 0.104607; batch adversarial loss: 0.472109\n",
      "epoch 88; iter: 0; batch classifier loss: 0.119585; batch adversarial loss: 0.446494\n",
      "epoch 89; iter: 0; batch classifier loss: 0.216702; batch adversarial loss: 0.507648\n",
      "epoch 90; iter: 0; batch classifier loss: 0.153136; batch adversarial loss: 0.505971\n",
      "epoch 91; iter: 0; batch classifier loss: 0.122622; batch adversarial loss: 0.471428\n",
      "epoch 92; iter: 0; batch classifier loss: 0.120493; batch adversarial loss: 0.514408\n",
      "epoch 93; iter: 0; batch classifier loss: 0.082376; batch adversarial loss: 0.560233\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050176; batch adversarial loss: 0.395526\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053920; batch adversarial loss: 0.543063\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068038; batch adversarial loss: 0.412244\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048778; batch adversarial loss: 0.475393\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059233; batch adversarial loss: 0.478247\n",
      "epoch 99; iter: 0; batch classifier loss: 0.079765; batch adversarial loss: 0.535685\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034089; batch adversarial loss: 0.437859\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040625; batch adversarial loss: 0.391299\n",
      "epoch 102; iter: 0; batch classifier loss: 0.088728; batch adversarial loss: 0.450769\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033569; batch adversarial loss: 0.413967\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043550; batch adversarial loss: 0.438053\n",
      "epoch 105; iter: 0; batch classifier loss: 0.039409; batch adversarial loss: 0.443117\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042851; batch adversarial loss: 0.469229\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065124; batch adversarial loss: 0.497860\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049957; batch adversarial loss: 0.491096\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054920; batch adversarial loss: 0.414533\n",
      "epoch 110; iter: 0; batch classifier loss: 0.055298; batch adversarial loss: 0.401451\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035711; batch adversarial loss: 0.436251\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039214; batch adversarial loss: 0.507071\n",
      "epoch 113; iter: 0; batch classifier loss: 0.067518; batch adversarial loss: 0.406978\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039890; batch adversarial loss: 0.500631\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042930; batch adversarial loss: 0.478156\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038783; batch adversarial loss: 0.556812\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052113; batch adversarial loss: 0.401560\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054659; batch adversarial loss: 0.418617\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030898; batch adversarial loss: 0.412938\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031320; batch adversarial loss: 0.462879\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027181; batch adversarial loss: 0.471323\n",
      "epoch 122; iter: 0; batch classifier loss: 0.022508; batch adversarial loss: 0.409990\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038930; batch adversarial loss: 0.505697\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035969; batch adversarial loss: 0.438003\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044269; batch adversarial loss: 0.478066\n",
      "epoch 126; iter: 0; batch classifier loss: 0.068556; batch adversarial loss: 0.450682\n",
      "epoch 127; iter: 0; batch classifier loss: 0.059536; batch adversarial loss: 0.512114\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049001; batch adversarial loss: 0.422485\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022444; batch adversarial loss: 0.407494\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018927; batch adversarial loss: 0.559886\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022116; batch adversarial loss: 0.367428\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019598; batch adversarial loss: 0.452268\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036592; batch adversarial loss: 0.452777\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016001; batch adversarial loss: 0.388449\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012257; batch adversarial loss: 0.453718\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039576; batch adversarial loss: 0.450137\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020285; batch adversarial loss: 0.470507\n",
      "epoch 138; iter: 0; batch classifier loss: 0.006326; batch adversarial loss: 0.492990\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009818; batch adversarial loss: 0.485896\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019791; batch adversarial loss: 0.504358\n",
      "epoch 141; iter: 0; batch classifier loss: 0.006950; batch adversarial loss: 0.509753\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018042; batch adversarial loss: 0.503511\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027927; batch adversarial loss: 0.505335\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013555; batch adversarial loss: 0.433478\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026205; batch adversarial loss: 0.528183\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017795; batch adversarial loss: 0.447127\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014107; batch adversarial loss: 0.500505\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026576; batch adversarial loss: 0.449423\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016333; batch adversarial loss: 0.358025\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020232; batch adversarial loss: 0.459916\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033509; batch adversarial loss: 0.533935\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029370; batch adversarial loss: 0.563754\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020767; batch adversarial loss: 0.497358\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026102; batch adversarial loss: 0.415156\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014732; batch adversarial loss: 0.487858\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014320; batch adversarial loss: 0.417868\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012228; batch adversarial loss: 0.427456\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038413; batch adversarial loss: 0.564169\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036291; batch adversarial loss: 0.470864\n",
      "epoch 160; iter: 0; batch classifier loss: 0.005032; batch adversarial loss: 0.456515\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032826; batch adversarial loss: 0.393025\n",
      "epoch 162; iter: 0; batch classifier loss: 0.003667; batch adversarial loss: 0.471455\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019447; batch adversarial loss: 0.499159\n",
      "epoch 164; iter: 0; batch classifier loss: 0.005325; batch adversarial loss: 0.546071\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021702; batch adversarial loss: 0.460260\n",
      "epoch 166; iter: 0; batch classifier loss: 0.048281; batch adversarial loss: 0.430367\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012697; batch adversarial loss: 0.511142\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012590; batch adversarial loss: 0.520452\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006777; batch adversarial loss: 0.422094\n",
      "epoch 170; iter: 0; batch classifier loss: 0.041741; batch adversarial loss: 0.492101\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023816; batch adversarial loss: 0.498441\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021614; batch adversarial loss: 0.402917\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014351; batch adversarial loss: 0.516088\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006968; batch adversarial loss: 0.486506\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015482; batch adversarial loss: 0.484102\n",
      "epoch 176; iter: 0; batch classifier loss: 0.004576; batch adversarial loss: 0.546016\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008418; batch adversarial loss: 0.551935\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031252; batch adversarial loss: 0.402924\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037511; batch adversarial loss: 0.487775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.021218; batch adversarial loss: 0.389327\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009814; batch adversarial loss: 0.644522\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032111; batch adversarial loss: 0.500507\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016197; batch adversarial loss: 0.506260\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006461; batch adversarial loss: 0.366387\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007007; batch adversarial loss: 0.473289\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028099; batch adversarial loss: 0.453306\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014223; batch adversarial loss: 0.461304\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029506; batch adversarial loss: 0.424521\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023402; batch adversarial loss: 0.457882\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007429; batch adversarial loss: 0.462842\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005779; batch adversarial loss: 0.416626\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018352; batch adversarial loss: 0.494175\n",
      "epoch 193; iter: 0; batch classifier loss: 0.040677; batch adversarial loss: 0.395744\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014945; batch adversarial loss: 0.435246\n",
      "epoch 195; iter: 0; batch classifier loss: 0.007314; batch adversarial loss: 0.427197\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018431; batch adversarial loss: 0.478699\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026848; batch adversarial loss: 0.420850\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009228; batch adversarial loss: 0.447235\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005565; batch adversarial loss: 0.368346\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679301; batch adversarial loss: 0.823735\n",
      "epoch 1; iter: 0; batch classifier loss: 0.417033; batch adversarial loss: 0.806859\n",
      "epoch 2; iter: 0; batch classifier loss: 0.447121; batch adversarial loss: 0.783425\n",
      "epoch 3; iter: 0; batch classifier loss: 0.480496; batch adversarial loss: 0.727095\n",
      "epoch 4; iter: 0; batch classifier loss: 0.472294; batch adversarial loss: 0.688117\n",
      "epoch 5; iter: 0; batch classifier loss: 0.526807; batch adversarial loss: 0.624709\n",
      "epoch 6; iter: 0; batch classifier loss: 0.411881; batch adversarial loss: 0.595058\n",
      "epoch 7; iter: 0; batch classifier loss: 0.291978; batch adversarial loss: 0.573999\n",
      "epoch 8; iter: 0; batch classifier loss: 0.303747; batch adversarial loss: 0.539467\n",
      "epoch 9; iter: 0; batch classifier loss: 0.301035; batch adversarial loss: 0.524331\n",
      "epoch 10; iter: 0; batch classifier loss: 0.257573; batch adversarial loss: 0.542316\n",
      "epoch 11; iter: 0; batch classifier loss: 0.276964; batch adversarial loss: 0.535025\n",
      "epoch 12; iter: 0; batch classifier loss: 0.222378; batch adversarial loss: 0.495429\n",
      "epoch 13; iter: 0; batch classifier loss: 0.206049; batch adversarial loss: 0.524006\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236918; batch adversarial loss: 0.510861\n",
      "epoch 15; iter: 0; batch classifier loss: 0.141992; batch adversarial loss: 0.503512\n",
      "epoch 16; iter: 0; batch classifier loss: 0.188655; batch adversarial loss: 0.501034\n",
      "epoch 17; iter: 0; batch classifier loss: 0.147225; batch adversarial loss: 0.493402\n",
      "epoch 18; iter: 0; batch classifier loss: 0.225999; batch adversarial loss: 0.427139\n",
      "epoch 19; iter: 0; batch classifier loss: 0.182912; batch adversarial loss: 0.507851\n",
      "epoch 20; iter: 0; batch classifier loss: 0.219838; batch adversarial loss: 0.434103\n",
      "epoch 21; iter: 0; batch classifier loss: 0.126182; batch adversarial loss: 0.447059\n",
      "epoch 22; iter: 0; batch classifier loss: 0.172492; batch adversarial loss: 0.507914\n",
      "epoch 23; iter: 0; batch classifier loss: 0.152969; batch adversarial loss: 0.522974\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168964; batch adversarial loss: 0.450411\n",
      "epoch 25; iter: 0; batch classifier loss: 0.166092; batch adversarial loss: 0.431578\n",
      "epoch 26; iter: 0; batch classifier loss: 0.101408; batch adversarial loss: 0.459066\n",
      "epoch 27; iter: 0; batch classifier loss: 0.220045; batch adversarial loss: 0.432248\n",
      "epoch 28; iter: 0; batch classifier loss: 0.131578; batch adversarial loss: 0.443700\n",
      "epoch 29; iter: 0; batch classifier loss: 0.128905; batch adversarial loss: 0.490465\n",
      "epoch 30; iter: 0; batch classifier loss: 0.129618; batch adversarial loss: 0.497953\n",
      "epoch 31; iter: 0; batch classifier loss: 0.122062; batch adversarial loss: 0.492750\n",
      "epoch 32; iter: 0; batch classifier loss: 0.118361; batch adversarial loss: 0.444240\n",
      "epoch 33; iter: 0; batch classifier loss: 0.097427; batch adversarial loss: 0.419670\n",
      "epoch 34; iter: 0; batch classifier loss: 0.083359; batch adversarial loss: 0.467861\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130778; batch adversarial loss: 0.464941\n",
      "epoch 36; iter: 0; batch classifier loss: 0.108121; batch adversarial loss: 0.392399\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132152; batch adversarial loss: 0.442720\n",
      "epoch 38; iter: 0; batch classifier loss: 0.076060; batch adversarial loss: 0.417746\n",
      "epoch 39; iter: 0; batch classifier loss: 0.087883; batch adversarial loss: 0.405064\n",
      "epoch 40; iter: 0; batch classifier loss: 0.143538; batch adversarial loss: 0.442808\n",
      "epoch 41; iter: 0; batch classifier loss: 0.122298; batch adversarial loss: 0.605571\n",
      "epoch 42; iter: 0; batch classifier loss: 0.101858; batch adversarial loss: 0.435013\n",
      "epoch 43; iter: 0; batch classifier loss: 0.118975; batch adversarial loss: 0.360247\n",
      "epoch 44; iter: 0; batch classifier loss: 0.063822; batch adversarial loss: 0.401147\n",
      "epoch 45; iter: 0; batch classifier loss: 0.078746; batch adversarial loss: 0.360057\n",
      "epoch 46; iter: 0; batch classifier loss: 0.078821; batch adversarial loss: 0.475776\n",
      "epoch 47; iter: 0; batch classifier loss: 0.048799; batch adversarial loss: 0.410201\n",
      "epoch 48; iter: 0; batch classifier loss: 0.143447; batch adversarial loss: 0.465146\n",
      "epoch 49; iter: 0; batch classifier loss: 0.100684; batch adversarial loss: 0.385808\n",
      "epoch 50; iter: 0; batch classifier loss: 0.071886; batch adversarial loss: 0.448697\n",
      "epoch 51; iter: 0; batch classifier loss: 0.062952; batch adversarial loss: 0.454953\n",
      "epoch 52; iter: 0; batch classifier loss: 0.095502; batch adversarial loss: 0.423270\n",
      "epoch 53; iter: 0; batch classifier loss: 0.077150; batch adversarial loss: 0.434163\n",
      "epoch 54; iter: 0; batch classifier loss: 0.093294; batch adversarial loss: 0.355156\n",
      "epoch 55; iter: 0; batch classifier loss: 0.080945; batch adversarial loss: 0.465354\n",
      "epoch 56; iter: 0; batch classifier loss: 0.078604; batch adversarial loss: 0.401056\n",
      "epoch 57; iter: 0; batch classifier loss: 0.096456; batch adversarial loss: 0.438136\n",
      "epoch 58; iter: 0; batch classifier loss: 0.061727; batch adversarial loss: 0.429585\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067954; batch adversarial loss: 0.433170\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087884; batch adversarial loss: 0.405654\n",
      "epoch 61; iter: 0; batch classifier loss: 0.101827; batch adversarial loss: 0.378094\n",
      "epoch 62; iter: 0; batch classifier loss: 0.068674; batch adversarial loss: 0.469860\n",
      "epoch 63; iter: 0; batch classifier loss: 0.056889; batch adversarial loss: 0.518752\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078795; batch adversarial loss: 0.515729\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074350; batch adversarial loss: 0.412982\n",
      "epoch 66; iter: 0; batch classifier loss: 0.076937; batch adversarial loss: 0.449322\n",
      "epoch 67; iter: 0; batch classifier loss: 0.075328; batch adversarial loss: 0.515868\n",
      "epoch 68; iter: 0; batch classifier loss: 0.083776; batch adversarial loss: 0.472726\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072139; batch adversarial loss: 0.489102\n",
      "epoch 70; iter: 0; batch classifier loss: 0.075438; batch adversarial loss: 0.401138\n",
      "epoch 71; iter: 0; batch classifier loss: 0.036971; batch adversarial loss: 0.359049\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064319; batch adversarial loss: 0.403163\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079851; batch adversarial loss: 0.538619\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081324; batch adversarial loss: 0.549289\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071891; batch adversarial loss: 0.445255\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064914; batch adversarial loss: 0.443452\n",
      "epoch 77; iter: 0; batch classifier loss: 0.046525; batch adversarial loss: 0.398251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.038550; batch adversarial loss: 0.436652\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065863; batch adversarial loss: 0.396533\n",
      "epoch 80; iter: 0; batch classifier loss: 0.029577; batch adversarial loss: 0.466317\n",
      "epoch 81; iter: 0; batch classifier loss: 0.092045; batch adversarial loss: 0.508088\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056243; batch adversarial loss: 0.440839\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068434; batch adversarial loss: 0.473858\n",
      "epoch 84; iter: 0; batch classifier loss: 0.105083; batch adversarial loss: 0.509892\n",
      "epoch 85; iter: 0; batch classifier loss: 0.053749; batch adversarial loss: 0.433735\n",
      "epoch 86; iter: 0; batch classifier loss: 0.050252; batch adversarial loss: 0.411403\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067977; batch adversarial loss: 0.410264\n",
      "epoch 88; iter: 0; batch classifier loss: 0.086369; batch adversarial loss: 0.393899\n",
      "epoch 89; iter: 0; batch classifier loss: 0.039234; batch adversarial loss: 0.393758\n",
      "epoch 90; iter: 0; batch classifier loss: 0.099064; batch adversarial loss: 0.430366\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055464; batch adversarial loss: 0.426852\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051000; batch adversarial loss: 0.398568\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052459; batch adversarial loss: 0.567777\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081719; batch adversarial loss: 0.437527\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071372; batch adversarial loss: 0.493921\n",
      "epoch 96; iter: 0; batch classifier loss: 0.034672; batch adversarial loss: 0.402738\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076105; batch adversarial loss: 0.459089\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045437; batch adversarial loss: 0.443566\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067318; batch adversarial loss: 0.422143\n",
      "epoch 100; iter: 0; batch classifier loss: 0.030693; batch adversarial loss: 0.449196\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042889; batch adversarial loss: 0.373356\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062349; batch adversarial loss: 0.416855\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046252; batch adversarial loss: 0.378422\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043710; batch adversarial loss: 0.420264\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057598; batch adversarial loss: 0.485041\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033700; batch adversarial loss: 0.490644\n",
      "epoch 107; iter: 0; batch classifier loss: 0.042775; batch adversarial loss: 0.386440\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067568; batch adversarial loss: 0.412615\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064956; batch adversarial loss: 0.454016\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042044; batch adversarial loss: 0.334847\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059163; batch adversarial loss: 0.394876\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056339; batch adversarial loss: 0.522935\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059442; batch adversarial loss: 0.454894\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039294; batch adversarial loss: 0.459103\n",
      "epoch 115; iter: 0; batch classifier loss: 0.066295; batch adversarial loss: 0.406447\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057104; batch adversarial loss: 0.361195\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046103; batch adversarial loss: 0.433770\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033195; batch adversarial loss: 0.436426\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054804; batch adversarial loss: 0.381849\n",
      "epoch 120; iter: 0; batch classifier loss: 0.084263; batch adversarial loss: 0.463016\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051218; batch adversarial loss: 0.466499\n",
      "epoch 122; iter: 0; batch classifier loss: 0.058046; batch adversarial loss: 0.402778\n",
      "epoch 123; iter: 0; batch classifier loss: 0.060416; batch adversarial loss: 0.487871\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051258; batch adversarial loss: 0.422510\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054810; batch adversarial loss: 0.391003\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038373; batch adversarial loss: 0.434342\n",
      "epoch 127; iter: 0; batch classifier loss: 0.058748; batch adversarial loss: 0.491295\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044834; batch adversarial loss: 0.467827\n",
      "epoch 129; iter: 0; batch classifier loss: 0.112511; batch adversarial loss: 0.493255\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039233; batch adversarial loss: 0.438104\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051503; batch adversarial loss: 0.452488\n",
      "epoch 132; iter: 0; batch classifier loss: 0.062252; batch adversarial loss: 0.396030\n",
      "epoch 133; iter: 0; batch classifier loss: 0.070151; batch adversarial loss: 0.489729\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053944; batch adversarial loss: 0.389653\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057682; batch adversarial loss: 0.430474\n",
      "epoch 136; iter: 0; batch classifier loss: 0.069378; batch adversarial loss: 0.445300\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052009; batch adversarial loss: 0.464226\n",
      "epoch 138; iter: 0; batch classifier loss: 0.065326; batch adversarial loss: 0.428494\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025207; batch adversarial loss: 0.411899\n",
      "epoch 140; iter: 0; batch classifier loss: 0.060955; batch adversarial loss: 0.402423\n",
      "epoch 141; iter: 0; batch classifier loss: 0.078701; batch adversarial loss: 0.419001\n",
      "epoch 142; iter: 0; batch classifier loss: 0.057255; batch adversarial loss: 0.409131\n",
      "epoch 143; iter: 0; batch classifier loss: 0.070290; batch adversarial loss: 0.402870\n",
      "epoch 144; iter: 0; batch classifier loss: 0.055702; batch adversarial loss: 0.435685\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035078; batch adversarial loss: 0.427129\n",
      "epoch 146; iter: 0; batch classifier loss: 0.070123; batch adversarial loss: 0.547068\n",
      "epoch 147; iter: 0; batch classifier loss: 0.071931; batch adversarial loss: 0.470496\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037458; batch adversarial loss: 0.519552\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037618; batch adversarial loss: 0.374066\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029977; batch adversarial loss: 0.448481\n",
      "epoch 151; iter: 0; batch classifier loss: 0.065728; batch adversarial loss: 0.406788\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035242; batch adversarial loss: 0.368081\n",
      "epoch 153; iter: 0; batch classifier loss: 0.053910; batch adversarial loss: 0.579849\n",
      "epoch 154; iter: 0; batch classifier loss: 0.047689; batch adversarial loss: 0.434112\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034578; batch adversarial loss: 0.433403\n",
      "epoch 156; iter: 0; batch classifier loss: 0.061977; batch adversarial loss: 0.350428\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040937; batch adversarial loss: 0.377920\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023776; batch adversarial loss: 0.411743\n",
      "epoch 159; iter: 0; batch classifier loss: 0.046143; batch adversarial loss: 0.444571\n",
      "epoch 160; iter: 0; batch classifier loss: 0.042049; batch adversarial loss: 0.476979\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043235; batch adversarial loss: 0.389139\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028572; batch adversarial loss: 0.542745\n",
      "epoch 163; iter: 0; batch classifier loss: 0.050355; batch adversarial loss: 0.445130\n",
      "epoch 164; iter: 0; batch classifier loss: 0.044078; batch adversarial loss: 0.359517\n",
      "epoch 165; iter: 0; batch classifier loss: 0.043343; batch adversarial loss: 0.455028\n",
      "epoch 166; iter: 0; batch classifier loss: 0.052244; batch adversarial loss: 0.455173\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041855; batch adversarial loss: 0.338168\n",
      "epoch 168; iter: 0; batch classifier loss: 0.052348; batch adversarial loss: 0.370670\n",
      "epoch 169; iter: 0; batch classifier loss: 0.077245; batch adversarial loss: 0.410926\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035374; batch adversarial loss: 0.502936\n",
      "epoch 171; iter: 0; batch classifier loss: 0.037185; batch adversarial loss: 0.391190\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025283; batch adversarial loss: 0.420130\n",
      "epoch 173; iter: 0; batch classifier loss: 0.057420; batch adversarial loss: 0.502324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.037493; batch adversarial loss: 0.384639\n",
      "epoch 175; iter: 0; batch classifier loss: 0.047645; batch adversarial loss: 0.466197\n",
      "epoch 176; iter: 0; batch classifier loss: 0.053200; batch adversarial loss: 0.490427\n",
      "epoch 177; iter: 0; batch classifier loss: 0.043260; batch adversarial loss: 0.495394\n",
      "epoch 178; iter: 0; batch classifier loss: 0.049749; batch adversarial loss: 0.409346\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030728; batch adversarial loss: 0.445676\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039000; batch adversarial loss: 0.399044\n",
      "epoch 181; iter: 0; batch classifier loss: 0.041095; batch adversarial loss: 0.485768\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023130; batch adversarial loss: 0.482149\n",
      "epoch 183; iter: 0; batch classifier loss: 0.038002; batch adversarial loss: 0.515468\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019599; batch adversarial loss: 0.440636\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018728; batch adversarial loss: 0.448076\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026438; batch adversarial loss: 0.399849\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026179; batch adversarial loss: 0.456497\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028802; batch adversarial loss: 0.491384\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032605; batch adversarial loss: 0.516872\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029761; batch adversarial loss: 0.488173\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033010; batch adversarial loss: 0.370767\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024655; batch adversarial loss: 0.443416\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023984; batch adversarial loss: 0.429402\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020910; batch adversarial loss: 0.485196\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034100; batch adversarial loss: 0.479459\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027500; batch adversarial loss: 0.420588\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037850; batch adversarial loss: 0.409650\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022930; batch adversarial loss: 0.491046\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027524; batch adversarial loss: 0.387900\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690716; batch adversarial loss: 0.555594\n",
      "epoch 1; iter: 0; batch classifier loss: 0.464094; batch adversarial loss: 0.599830\n",
      "epoch 2; iter: 0; batch classifier loss: 0.335088; batch adversarial loss: 0.595521\n",
      "epoch 3; iter: 0; batch classifier loss: 0.306324; batch adversarial loss: 0.600693\n",
      "epoch 4; iter: 0; batch classifier loss: 0.439697; batch adversarial loss: 0.565365\n",
      "epoch 5; iter: 0; batch classifier loss: 0.283738; batch adversarial loss: 0.597715\n",
      "epoch 6; iter: 0; batch classifier loss: 0.317180; batch adversarial loss: 0.535153\n",
      "epoch 7; iter: 0; batch classifier loss: 0.362749; batch adversarial loss: 0.551831\n",
      "epoch 8; iter: 0; batch classifier loss: 0.272478; batch adversarial loss: 0.522055\n",
      "epoch 9; iter: 0; batch classifier loss: 0.252796; batch adversarial loss: 0.475875\n",
      "epoch 10; iter: 0; batch classifier loss: 0.290623; batch adversarial loss: 0.473938\n",
      "epoch 11; iter: 0; batch classifier loss: 0.270539; batch adversarial loss: 0.566781\n",
      "epoch 12; iter: 0; batch classifier loss: 0.270896; batch adversarial loss: 0.513213\n",
      "epoch 13; iter: 0; batch classifier loss: 0.290215; batch adversarial loss: 0.511090\n",
      "epoch 14; iter: 0; batch classifier loss: 0.336142; batch adversarial loss: 0.483911\n",
      "epoch 15; iter: 0; batch classifier loss: 0.315568; batch adversarial loss: 0.560912\n",
      "epoch 16; iter: 0; batch classifier loss: 0.385680; batch adversarial loss: 0.516141\n",
      "epoch 17; iter: 0; batch classifier loss: 0.437266; batch adversarial loss: 0.539143\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478441; batch adversarial loss: 0.500492\n",
      "epoch 19; iter: 0; batch classifier loss: 0.385905; batch adversarial loss: 0.460077\n",
      "epoch 20; iter: 0; batch classifier loss: 0.260600; batch adversarial loss: 0.408712\n",
      "epoch 21; iter: 0; batch classifier loss: 0.188315; batch adversarial loss: 0.484759\n",
      "epoch 22; iter: 0; batch classifier loss: 0.200993; batch adversarial loss: 0.464890\n",
      "epoch 23; iter: 0; batch classifier loss: 0.200464; batch adversarial loss: 0.540210\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159600; batch adversarial loss: 0.426474\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179871; batch adversarial loss: 0.428375\n",
      "epoch 26; iter: 0; batch classifier loss: 0.118921; batch adversarial loss: 0.473160\n",
      "epoch 27; iter: 0; batch classifier loss: 0.125431; batch adversarial loss: 0.476476\n",
      "epoch 28; iter: 0; batch classifier loss: 0.144843; batch adversarial loss: 0.461010\n",
      "epoch 29; iter: 0; batch classifier loss: 0.165941; batch adversarial loss: 0.400771\n",
      "epoch 30; iter: 0; batch classifier loss: 0.126618; batch adversarial loss: 0.431348\n",
      "epoch 31; iter: 0; batch classifier loss: 0.147999; batch adversarial loss: 0.435828\n",
      "epoch 32; iter: 0; batch classifier loss: 0.166249; batch adversarial loss: 0.456257\n",
      "epoch 33; iter: 0; batch classifier loss: 0.102219; batch adversarial loss: 0.498420\n",
      "epoch 34; iter: 0; batch classifier loss: 0.094396; batch adversarial loss: 0.461119\n",
      "epoch 35; iter: 0; batch classifier loss: 0.159201; batch adversarial loss: 0.506799\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128339; batch adversarial loss: 0.475621\n",
      "epoch 37; iter: 0; batch classifier loss: 0.148849; batch adversarial loss: 0.492771\n",
      "epoch 38; iter: 0; batch classifier loss: 0.129741; batch adversarial loss: 0.462277\n",
      "epoch 39; iter: 0; batch classifier loss: 0.087154; batch adversarial loss: 0.506197\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099764; batch adversarial loss: 0.435740\n",
      "epoch 41; iter: 0; batch classifier loss: 0.112742; batch adversarial loss: 0.407355\n",
      "epoch 42; iter: 0; batch classifier loss: 0.147592; batch adversarial loss: 0.428615\n",
      "epoch 43; iter: 0; batch classifier loss: 0.075228; batch adversarial loss: 0.408114\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101420; batch adversarial loss: 0.409548\n",
      "epoch 45; iter: 0; batch classifier loss: 0.115249; batch adversarial loss: 0.484380\n",
      "epoch 46; iter: 0; batch classifier loss: 0.093928; batch adversarial loss: 0.418306\n",
      "epoch 47; iter: 0; batch classifier loss: 0.074562; batch adversarial loss: 0.393631\n",
      "epoch 48; iter: 0; batch classifier loss: 0.142400; batch adversarial loss: 0.378995\n",
      "epoch 49; iter: 0; batch classifier loss: 0.110374; batch adversarial loss: 0.530612\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087857; batch adversarial loss: 0.376364\n",
      "epoch 51; iter: 0; batch classifier loss: 0.143660; batch adversarial loss: 0.418715\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099714; batch adversarial loss: 0.408652\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088091; batch adversarial loss: 0.349243\n",
      "epoch 54; iter: 0; batch classifier loss: 0.173621; batch adversarial loss: 0.416772\n",
      "epoch 55; iter: 0; batch classifier loss: 0.075017; batch adversarial loss: 0.482297\n",
      "epoch 56; iter: 0; batch classifier loss: 0.176214; batch adversarial loss: 0.454677\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110838; batch adversarial loss: 0.423793\n",
      "epoch 58; iter: 0; batch classifier loss: 0.105535; batch adversarial loss: 0.505836\n",
      "epoch 59; iter: 0; batch classifier loss: 0.091909; batch adversarial loss: 0.430575\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079829; batch adversarial loss: 0.448201\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087463; batch adversarial loss: 0.354199\n",
      "epoch 62; iter: 0; batch classifier loss: 0.123802; batch adversarial loss: 0.387036\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098306; batch adversarial loss: 0.450727\n",
      "epoch 64; iter: 0; batch classifier loss: 0.119679; batch adversarial loss: 0.442246\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122833; batch adversarial loss: 0.498538\n",
      "epoch 66; iter: 0; batch classifier loss: 0.081680; batch adversarial loss: 0.526541\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082900; batch adversarial loss: 0.432317\n",
      "epoch 68; iter: 0; batch classifier loss: 0.178505; batch adversarial loss: 0.441844\n",
      "epoch 69; iter: 0; batch classifier loss: 0.194514; batch adversarial loss: 0.469297\n",
      "epoch 70; iter: 0; batch classifier loss: 0.131690; batch adversarial loss: 0.416621\n",
      "epoch 71; iter: 0; batch classifier loss: 0.151937; batch adversarial loss: 0.445105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.150409; batch adversarial loss: 0.378446\n",
      "epoch 73; iter: 0; batch classifier loss: 0.140883; batch adversarial loss: 0.487224\n",
      "epoch 74; iter: 0; batch classifier loss: 0.132085; batch adversarial loss: 0.526155\n",
      "epoch 75; iter: 0; batch classifier loss: 0.053958; batch adversarial loss: 0.451517\n",
      "epoch 76; iter: 0; batch classifier loss: 0.091643; batch adversarial loss: 0.381652\n",
      "epoch 77; iter: 0; batch classifier loss: 0.089068; batch adversarial loss: 0.511445\n",
      "epoch 78; iter: 0; batch classifier loss: 0.127402; batch adversarial loss: 0.521548\n",
      "epoch 79; iter: 0; batch classifier loss: 0.138551; batch adversarial loss: 0.422269\n",
      "epoch 80; iter: 0; batch classifier loss: 0.130772; batch adversarial loss: 0.511613\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075642; batch adversarial loss: 0.481359\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072034; batch adversarial loss: 0.354141\n",
      "epoch 83; iter: 0; batch classifier loss: 0.163427; batch adversarial loss: 0.495980\n",
      "epoch 84; iter: 0; batch classifier loss: 0.112175; batch adversarial loss: 0.402466\n",
      "epoch 85; iter: 0; batch classifier loss: 0.096338; batch adversarial loss: 0.435067\n",
      "epoch 86; iter: 0; batch classifier loss: 0.120730; batch adversarial loss: 0.449383\n",
      "epoch 87; iter: 0; batch classifier loss: 0.070127; batch adversarial loss: 0.440969\n",
      "epoch 88; iter: 0; batch classifier loss: 0.135909; batch adversarial loss: 0.335421\n",
      "epoch 89; iter: 0; batch classifier loss: 0.108753; batch adversarial loss: 0.447466\n",
      "epoch 90; iter: 0; batch classifier loss: 0.096065; batch adversarial loss: 0.456533\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082047; batch adversarial loss: 0.486122\n",
      "epoch 92; iter: 0; batch classifier loss: 0.114572; batch adversarial loss: 0.471667\n",
      "epoch 93; iter: 0; batch classifier loss: 0.130631; batch adversarial loss: 0.502616\n",
      "epoch 94; iter: 0; batch classifier loss: 0.092177; batch adversarial loss: 0.387182\n",
      "epoch 95; iter: 0; batch classifier loss: 0.092386; batch adversarial loss: 0.476307\n",
      "epoch 96; iter: 0; batch classifier loss: 0.172358; batch adversarial loss: 0.483665\n",
      "epoch 97; iter: 0; batch classifier loss: 0.112071; batch adversarial loss: 0.468204\n",
      "epoch 98; iter: 0; batch classifier loss: 0.107207; batch adversarial loss: 0.440656\n",
      "epoch 99; iter: 0; batch classifier loss: 0.130801; batch adversarial loss: 0.366104\n",
      "epoch 100; iter: 0; batch classifier loss: 0.107716; batch adversarial loss: 0.438776\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075888; batch adversarial loss: 0.468665\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051283; batch adversarial loss: 0.526531\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063067; batch adversarial loss: 0.482187\n",
      "epoch 104; iter: 0; batch classifier loss: 0.101623; batch adversarial loss: 0.537909\n",
      "epoch 105; iter: 0; batch classifier loss: 0.101124; batch adversarial loss: 0.503596\n",
      "epoch 106; iter: 0; batch classifier loss: 0.086258; batch adversarial loss: 0.403986\n",
      "epoch 107; iter: 0; batch classifier loss: 0.119275; batch adversarial loss: 0.452066\n",
      "epoch 108; iter: 0; batch classifier loss: 0.113852; batch adversarial loss: 0.481261\n",
      "epoch 109; iter: 0; batch classifier loss: 0.082446; batch adversarial loss: 0.507655\n",
      "epoch 110; iter: 0; batch classifier loss: 0.080138; batch adversarial loss: 0.423908\n",
      "epoch 111; iter: 0; batch classifier loss: 0.067275; batch adversarial loss: 0.444265\n",
      "epoch 112; iter: 0; batch classifier loss: 0.065279; batch adversarial loss: 0.590261\n",
      "epoch 113; iter: 0; batch classifier loss: 0.076293; batch adversarial loss: 0.468488\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080074; batch adversarial loss: 0.441499\n",
      "epoch 115; iter: 0; batch classifier loss: 0.091053; batch adversarial loss: 0.423382\n",
      "epoch 116; iter: 0; batch classifier loss: 0.082976; batch adversarial loss: 0.425425\n",
      "epoch 117; iter: 0; batch classifier loss: 0.075245; batch adversarial loss: 0.445371\n",
      "epoch 118; iter: 0; batch classifier loss: 0.091672; batch adversarial loss: 0.454230\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052590; batch adversarial loss: 0.468160\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044480; batch adversarial loss: 0.578171\n",
      "epoch 121; iter: 0; batch classifier loss: 0.063167; batch adversarial loss: 0.338588\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034560; batch adversarial loss: 0.564439\n",
      "epoch 123; iter: 0; batch classifier loss: 0.058484; batch adversarial loss: 0.447061\n",
      "epoch 124; iter: 0; batch classifier loss: 0.072185; batch adversarial loss: 0.372663\n",
      "epoch 125; iter: 0; batch classifier loss: 0.082274; batch adversarial loss: 0.467115\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036855; batch adversarial loss: 0.490204\n",
      "epoch 127; iter: 0; batch classifier loss: 0.057107; batch adversarial loss: 0.468751\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029727; batch adversarial loss: 0.436662\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047896; batch adversarial loss: 0.394115\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061640; batch adversarial loss: 0.339022\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045646; batch adversarial loss: 0.323184\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053356; batch adversarial loss: 0.378445\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048747; batch adversarial loss: 0.481332\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025716; batch adversarial loss: 0.558328\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039211; batch adversarial loss: 0.446675\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031077; batch adversarial loss: 0.436782\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018096; batch adversarial loss: 0.424718\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035436; batch adversarial loss: 0.477712\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033759; batch adversarial loss: 0.409247\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040441; batch adversarial loss: 0.527058\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039349; batch adversarial loss: 0.443793\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014469; batch adversarial loss: 0.469331\n",
      "epoch 143; iter: 0; batch classifier loss: 0.061800; batch adversarial loss: 0.331230\n",
      "epoch 144; iter: 0; batch classifier loss: 0.051626; batch adversarial loss: 0.434944\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027911; batch adversarial loss: 0.486327\n",
      "epoch 146; iter: 0; batch classifier loss: 0.062688; batch adversarial loss: 0.371940\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016529; batch adversarial loss: 0.428314\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013407; batch adversarial loss: 0.428494\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029009; batch adversarial loss: 0.488859\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036353; batch adversarial loss: 0.517693\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027131; batch adversarial loss: 0.446534\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024316; batch adversarial loss: 0.461639\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028701; batch adversarial loss: 0.451917\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029869; batch adversarial loss: 0.432990\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023528; batch adversarial loss: 0.483654\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021182; batch adversarial loss: 0.479414\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022791; batch adversarial loss: 0.423985\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022440; batch adversarial loss: 0.452108\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032970; batch adversarial loss: 0.420383\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033633; batch adversarial loss: 0.445635\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030072; batch adversarial loss: 0.469229\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021182; batch adversarial loss: 0.438661\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037521; batch adversarial loss: 0.481177\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036310; batch adversarial loss: 0.461075\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014571; batch adversarial loss: 0.391993\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020660; batch adversarial loss: 0.436063\n",
      "epoch 167; iter: 0; batch classifier loss: 0.044407; batch adversarial loss: 0.427562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.024318; batch adversarial loss: 0.431350\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024200; batch adversarial loss: 0.466067\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015406; batch adversarial loss: 0.428227\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028591; batch adversarial loss: 0.545626\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014246; batch adversarial loss: 0.468535\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025031; batch adversarial loss: 0.420563\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037428; batch adversarial loss: 0.447178\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021255; batch adversarial loss: 0.494352\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009079; batch adversarial loss: 0.382342\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009301; batch adversarial loss: 0.538572\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029419; batch adversarial loss: 0.512333\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034195; batch adversarial loss: 0.408215\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015862; batch adversarial loss: 0.454381\n",
      "epoch 181; iter: 0; batch classifier loss: 0.060710; batch adversarial loss: 0.465084\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011564; batch adversarial loss: 0.430057\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026287; batch adversarial loss: 0.402705\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008786; batch adversarial loss: 0.469264\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022660; batch adversarial loss: 0.340925\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015069; batch adversarial loss: 0.393138\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012847; batch adversarial loss: 0.334776\n",
      "epoch 188; iter: 0; batch classifier loss: 0.043110; batch adversarial loss: 0.389873\n",
      "epoch 189; iter: 0; batch classifier loss: 0.073106; batch adversarial loss: 0.388741\n",
      "epoch 190; iter: 0; batch classifier loss: 0.049635; batch adversarial loss: 0.401726\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008008; batch adversarial loss: 0.419968\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023590; batch adversarial loss: 0.418044\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009535; batch adversarial loss: 0.416333\n",
      "epoch 194; iter: 0; batch classifier loss: 0.045843; batch adversarial loss: 0.440365\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014793; batch adversarial loss: 0.489575\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021723; batch adversarial loss: 0.386992\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004128; batch adversarial loss: 0.466940\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021075; batch adversarial loss: 0.418125\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007785; batch adversarial loss: 0.522178\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683293; batch adversarial loss: 0.622185\n",
      "epoch 1; iter: 0; batch classifier loss: 0.466142; batch adversarial loss: 0.648821\n",
      "epoch 2; iter: 0; batch classifier loss: 0.475142; batch adversarial loss: 0.620900\n",
      "epoch 3; iter: 0; batch classifier loss: 0.439999; batch adversarial loss: 0.592417\n",
      "epoch 4; iter: 0; batch classifier loss: 0.397105; batch adversarial loss: 0.618269\n",
      "epoch 5; iter: 0; batch classifier loss: 0.438318; batch adversarial loss: 0.633628\n",
      "epoch 6; iter: 0; batch classifier loss: 0.546265; batch adversarial loss: 0.588586\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545598; batch adversarial loss: 0.595265\n",
      "epoch 8; iter: 0; batch classifier loss: 0.518690; batch adversarial loss: 0.526780\n",
      "epoch 9; iter: 0; batch classifier loss: 0.400584; batch adversarial loss: 0.559450\n",
      "epoch 10; iter: 0; batch classifier loss: 0.387300; batch adversarial loss: 0.522168\n",
      "epoch 11; iter: 0; batch classifier loss: 0.330780; batch adversarial loss: 0.536666\n",
      "epoch 12; iter: 0; batch classifier loss: 0.308972; batch adversarial loss: 0.524164\n",
      "epoch 13; iter: 0; batch classifier loss: 0.295244; batch adversarial loss: 0.524879\n",
      "epoch 14; iter: 0; batch classifier loss: 0.243817; batch adversarial loss: 0.497641\n",
      "epoch 15; iter: 0; batch classifier loss: 0.253608; batch adversarial loss: 0.492782\n",
      "epoch 16; iter: 0; batch classifier loss: 0.199059; batch adversarial loss: 0.578273\n",
      "epoch 17; iter: 0; batch classifier loss: 0.318924; batch adversarial loss: 0.471302\n",
      "epoch 18; iter: 0; batch classifier loss: 0.279700; batch adversarial loss: 0.467092\n",
      "epoch 19; iter: 0; batch classifier loss: 0.197107; batch adversarial loss: 0.494224\n",
      "epoch 20; iter: 0; batch classifier loss: 0.263524; batch adversarial loss: 0.573227\n",
      "epoch 21; iter: 0; batch classifier loss: 0.201475; batch adversarial loss: 0.472539\n",
      "epoch 22; iter: 0; batch classifier loss: 0.212213; batch adversarial loss: 0.466838\n",
      "epoch 23; iter: 0; batch classifier loss: 0.135213; batch adversarial loss: 0.464077\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280726; batch adversarial loss: 0.499240\n",
      "epoch 25; iter: 0; batch classifier loss: 0.170589; batch adversarial loss: 0.425410\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176728; batch adversarial loss: 0.510229\n",
      "epoch 27; iter: 0; batch classifier loss: 0.176467; batch adversarial loss: 0.477063\n",
      "epoch 28; iter: 0; batch classifier loss: 0.167086; batch adversarial loss: 0.456235\n",
      "epoch 29; iter: 0; batch classifier loss: 0.184671; batch adversarial loss: 0.455315\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162327; batch adversarial loss: 0.413744\n",
      "epoch 31; iter: 0; batch classifier loss: 0.148703; batch adversarial loss: 0.416370\n",
      "epoch 32; iter: 0; batch classifier loss: 0.117588; batch adversarial loss: 0.469236\n",
      "epoch 33; iter: 0; batch classifier loss: 0.165336; batch adversarial loss: 0.576959\n",
      "epoch 34; iter: 0; batch classifier loss: 0.157711; batch adversarial loss: 0.433700\n",
      "epoch 35; iter: 0; batch classifier loss: 0.192073; batch adversarial loss: 0.454115\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150151; batch adversarial loss: 0.512199\n",
      "epoch 37; iter: 0; batch classifier loss: 0.116520; batch adversarial loss: 0.393991\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117422; batch adversarial loss: 0.562377\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131412; batch adversarial loss: 0.423876\n",
      "epoch 40; iter: 0; batch classifier loss: 0.164939; batch adversarial loss: 0.460142\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142468; batch adversarial loss: 0.424445\n",
      "epoch 42; iter: 0; batch classifier loss: 0.114683; batch adversarial loss: 0.375326\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150249; batch adversarial loss: 0.445276\n",
      "epoch 44; iter: 0; batch classifier loss: 0.150342; batch adversarial loss: 0.422701\n",
      "epoch 45; iter: 0; batch classifier loss: 0.147090; batch adversarial loss: 0.402305\n",
      "epoch 46; iter: 0; batch classifier loss: 0.132456; batch adversarial loss: 0.497109\n",
      "epoch 47; iter: 0; batch classifier loss: 0.079867; batch adversarial loss: 0.545452\n",
      "epoch 48; iter: 0; batch classifier loss: 0.140810; batch adversarial loss: 0.530013\n",
      "epoch 49; iter: 0; batch classifier loss: 0.102568; batch adversarial loss: 0.493687\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096222; batch adversarial loss: 0.417219\n",
      "epoch 51; iter: 0; batch classifier loss: 0.156690; batch adversarial loss: 0.491933\n",
      "epoch 52; iter: 0; batch classifier loss: 0.090717; batch adversarial loss: 0.537343\n",
      "epoch 53; iter: 0; batch classifier loss: 0.115653; batch adversarial loss: 0.483015\n",
      "epoch 54; iter: 0; batch classifier loss: 0.084386; batch adversarial loss: 0.532989\n",
      "epoch 55; iter: 0; batch classifier loss: 0.135115; batch adversarial loss: 0.495347\n",
      "epoch 56; iter: 0; batch classifier loss: 0.117265; batch adversarial loss: 0.503933\n",
      "epoch 57; iter: 0; batch classifier loss: 0.097310; batch adversarial loss: 0.527524\n",
      "epoch 58; iter: 0; batch classifier loss: 0.106523; batch adversarial loss: 0.468514\n",
      "epoch 59; iter: 0; batch classifier loss: 0.154597; batch adversarial loss: 0.370546\n",
      "epoch 60; iter: 0; batch classifier loss: 0.148514; batch adversarial loss: 0.487523\n",
      "epoch 61; iter: 0; batch classifier loss: 0.141453; batch adversarial loss: 0.449921\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108360; batch adversarial loss: 0.436997\n",
      "epoch 63; iter: 0; batch classifier loss: 0.062337; batch adversarial loss: 0.506707\n",
      "epoch 64; iter: 0; batch classifier loss: 0.109806; batch adversarial loss: 0.458704\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065033; batch adversarial loss: 0.483796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.109702; batch adversarial loss: 0.461386\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061641; batch adversarial loss: 0.514913\n",
      "epoch 68; iter: 0; batch classifier loss: 0.085614; batch adversarial loss: 0.404434\n",
      "epoch 69; iter: 0; batch classifier loss: 0.108281; batch adversarial loss: 0.394275\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070267; batch adversarial loss: 0.426379\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081654; batch adversarial loss: 0.489151\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071737; batch adversarial loss: 0.427966\n",
      "epoch 73; iter: 0; batch classifier loss: 0.092713; batch adversarial loss: 0.451495\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069442; batch adversarial loss: 0.479249\n",
      "epoch 75; iter: 0; batch classifier loss: 0.097475; batch adversarial loss: 0.559121\n",
      "epoch 76; iter: 0; batch classifier loss: 0.128090; batch adversarial loss: 0.404666\n",
      "epoch 77; iter: 0; batch classifier loss: 0.154326; batch adversarial loss: 0.379448\n",
      "epoch 78; iter: 0; batch classifier loss: 0.052311; batch adversarial loss: 0.490743\n",
      "epoch 79; iter: 0; batch classifier loss: 0.089778; batch adversarial loss: 0.426905\n",
      "epoch 80; iter: 0; batch classifier loss: 0.089059; batch adversarial loss: 0.453357\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084278; batch adversarial loss: 0.518204\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067252; batch adversarial loss: 0.448842\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114140; batch adversarial loss: 0.421924\n",
      "epoch 84; iter: 0; batch classifier loss: 0.039858; batch adversarial loss: 0.463154\n",
      "epoch 85; iter: 0; batch classifier loss: 0.108636; batch adversarial loss: 0.443693\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057778; batch adversarial loss: 0.530423\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073967; batch adversarial loss: 0.428873\n",
      "epoch 88; iter: 0; batch classifier loss: 0.065567; batch adversarial loss: 0.474021\n",
      "epoch 89; iter: 0; batch classifier loss: 0.067339; batch adversarial loss: 0.397102\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066021; batch adversarial loss: 0.481964\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071429; batch adversarial loss: 0.447610\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057660; batch adversarial loss: 0.455955\n",
      "epoch 93; iter: 0; batch classifier loss: 0.119024; batch adversarial loss: 0.420262\n",
      "epoch 94; iter: 0; batch classifier loss: 0.092542; batch adversarial loss: 0.509802\n",
      "epoch 95; iter: 0; batch classifier loss: 0.090955; batch adversarial loss: 0.501270\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055998; batch adversarial loss: 0.468110\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048910; batch adversarial loss: 0.449829\n",
      "epoch 98; iter: 0; batch classifier loss: 0.038466; batch adversarial loss: 0.531851\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041216; batch adversarial loss: 0.406937\n",
      "epoch 100; iter: 0; batch classifier loss: 0.073771; batch adversarial loss: 0.450033\n",
      "epoch 101; iter: 0; batch classifier loss: 0.078776; batch adversarial loss: 0.436655\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041509; batch adversarial loss: 0.407357\n",
      "epoch 103; iter: 0; batch classifier loss: 0.088266; batch adversarial loss: 0.514312\n",
      "epoch 104; iter: 0; batch classifier loss: 0.079568; batch adversarial loss: 0.457061\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051723; batch adversarial loss: 0.476603\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045666; batch adversarial loss: 0.463495\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047799; batch adversarial loss: 0.484857\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048108; batch adversarial loss: 0.552830\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067552; batch adversarial loss: 0.478564\n",
      "epoch 110; iter: 0; batch classifier loss: 0.032796; batch adversarial loss: 0.524187\n",
      "epoch 111; iter: 0; batch classifier loss: 0.083708; batch adversarial loss: 0.562485\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036806; batch adversarial loss: 0.510924\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046135; batch adversarial loss: 0.377891\n",
      "epoch 114; iter: 0; batch classifier loss: 0.055164; batch adversarial loss: 0.507802\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057073; batch adversarial loss: 0.458828\n",
      "epoch 116; iter: 0; batch classifier loss: 0.075739; batch adversarial loss: 0.446666\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031563; batch adversarial loss: 0.494095\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028609; batch adversarial loss: 0.535467\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050821; batch adversarial loss: 0.494181\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064449; batch adversarial loss: 0.463018\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035371; batch adversarial loss: 0.368017\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066999; batch adversarial loss: 0.426381\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026687; batch adversarial loss: 0.399746\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038097; batch adversarial loss: 0.530414\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061606; batch adversarial loss: 0.451917\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032453; batch adversarial loss: 0.462473\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035588; batch adversarial loss: 0.412688\n",
      "epoch 128; iter: 0; batch classifier loss: 0.060641; batch adversarial loss: 0.572613\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018648; batch adversarial loss: 0.472842\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032512; batch adversarial loss: 0.469496\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055618; batch adversarial loss: 0.385331\n",
      "epoch 132; iter: 0; batch classifier loss: 0.062747; batch adversarial loss: 0.487808\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036610; batch adversarial loss: 0.449963\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040631; batch adversarial loss: 0.505005\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020334; batch adversarial loss: 0.546457\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033882; batch adversarial loss: 0.417632\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012115; batch adversarial loss: 0.591872\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048434; batch adversarial loss: 0.454016\n",
      "epoch 139; iter: 0; batch classifier loss: 0.059241; batch adversarial loss: 0.481585\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036580; batch adversarial loss: 0.472312\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045120; batch adversarial loss: 0.471613\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030535; batch adversarial loss: 0.484442\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025798; batch adversarial loss: 0.598183\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039439; batch adversarial loss: 0.490327\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045438; batch adversarial loss: 0.470089\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026618; batch adversarial loss: 0.451836\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033591; batch adversarial loss: 0.489965\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028019; batch adversarial loss: 0.450675\n",
      "epoch 149; iter: 0; batch classifier loss: 0.050173; batch adversarial loss: 0.438354\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018421; batch adversarial loss: 0.439558\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029165; batch adversarial loss: 0.478991\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028822; batch adversarial loss: 0.373823\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028832; batch adversarial loss: 0.464871\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011139; batch adversarial loss: 0.406652\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040954; batch adversarial loss: 0.500440\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011768; batch adversarial loss: 0.462961\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024959; batch adversarial loss: 0.462209\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022872; batch adversarial loss: 0.390502\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045938; batch adversarial loss: 0.373408\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032128; batch adversarial loss: 0.452619\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014754; batch adversarial loss: 0.439221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.021516; batch adversarial loss: 0.365570\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013101; batch adversarial loss: 0.424470\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043383; batch adversarial loss: 0.426486\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014692; batch adversarial loss: 0.534478\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017964; batch adversarial loss: 0.409476\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023474; batch adversarial loss: 0.448497\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022591; batch adversarial loss: 0.440120\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030950; batch adversarial loss: 0.548590\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016880; batch adversarial loss: 0.365766\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011124; batch adversarial loss: 0.538178\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028007; batch adversarial loss: 0.459126\n",
      "epoch 173; iter: 0; batch classifier loss: 0.050110; batch adversarial loss: 0.466871\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023544; batch adversarial loss: 0.503983\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041748; batch adversarial loss: 0.414374\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029125; batch adversarial loss: 0.402940\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015564; batch adversarial loss: 0.385792\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012990; batch adversarial loss: 0.535514\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035877; batch adversarial loss: 0.511443\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022240; batch adversarial loss: 0.403945\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023347; batch adversarial loss: 0.560821\n",
      "epoch 182; iter: 0; batch classifier loss: 0.049415; batch adversarial loss: 0.485011\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029198; batch adversarial loss: 0.450273\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018789; batch adversarial loss: 0.472089\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020762; batch adversarial loss: 0.387768\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037951; batch adversarial loss: 0.434799\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006559; batch adversarial loss: 0.482379\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009285; batch adversarial loss: 0.566321\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014082; batch adversarial loss: 0.437862\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023038; batch adversarial loss: 0.501569\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010446; batch adversarial loss: 0.350708\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030523; batch adversarial loss: 0.491289\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010072; batch adversarial loss: 0.460729\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017129; batch adversarial loss: 0.503618\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010214; batch adversarial loss: 0.509462\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007909; batch adversarial loss: 0.494978\n",
      "epoch 197; iter: 0; batch classifier loss: 0.059306; batch adversarial loss: 0.459621\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014587; batch adversarial loss: 0.466580\n",
      "epoch 199; iter: 0; batch classifier loss: 0.055286; batch adversarial loss: 0.539762\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699781; batch adversarial loss: 0.771876\n",
      "epoch 1; iter: 0; batch classifier loss: 0.492246; batch adversarial loss: 0.717881\n",
      "epoch 2; iter: 0; batch classifier loss: 0.742996; batch adversarial loss: 0.739864\n",
      "epoch 3; iter: 0; batch classifier loss: 0.649287; batch adversarial loss: 0.672116\n",
      "epoch 4; iter: 0; batch classifier loss: 0.468099; batch adversarial loss: 0.612996\n",
      "epoch 5; iter: 0; batch classifier loss: 0.384598; batch adversarial loss: 0.619281\n",
      "epoch 6; iter: 0; batch classifier loss: 0.418901; batch adversarial loss: 0.578614\n",
      "epoch 7; iter: 0; batch classifier loss: 0.363966; batch adversarial loss: 0.568001\n",
      "epoch 8; iter: 0; batch classifier loss: 0.389803; batch adversarial loss: 0.564555\n",
      "epoch 9; iter: 0; batch classifier loss: 0.370638; batch adversarial loss: 0.534324\n",
      "epoch 10; iter: 0; batch classifier loss: 0.318943; batch adversarial loss: 0.515313\n",
      "epoch 11; iter: 0; batch classifier loss: 0.289154; batch adversarial loss: 0.523608\n",
      "epoch 12; iter: 0; batch classifier loss: 0.312336; batch adversarial loss: 0.506052\n",
      "epoch 13; iter: 0; batch classifier loss: 0.303518; batch adversarial loss: 0.505805\n",
      "epoch 14; iter: 0; batch classifier loss: 0.250631; batch adversarial loss: 0.491835\n",
      "epoch 15; iter: 0; batch classifier loss: 0.277417; batch adversarial loss: 0.534961\n",
      "epoch 16; iter: 0; batch classifier loss: 0.254654; batch adversarial loss: 0.557271\n",
      "epoch 17; iter: 0; batch classifier loss: 0.315530; batch adversarial loss: 0.514543\n",
      "epoch 18; iter: 0; batch classifier loss: 0.261303; batch adversarial loss: 0.500651\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261851; batch adversarial loss: 0.491781\n",
      "epoch 20; iter: 0; batch classifier loss: 0.259307; batch adversarial loss: 0.473198\n",
      "epoch 21; iter: 0; batch classifier loss: 0.280721; batch adversarial loss: 0.468226\n",
      "epoch 22; iter: 0; batch classifier loss: 0.212963; batch adversarial loss: 0.485885\n",
      "epoch 23; iter: 0; batch classifier loss: 0.188215; batch adversarial loss: 0.478482\n",
      "epoch 24; iter: 0; batch classifier loss: 0.218052; batch adversarial loss: 0.470391\n",
      "epoch 25; iter: 0; batch classifier loss: 0.157305; batch adversarial loss: 0.405376\n",
      "epoch 26; iter: 0; batch classifier loss: 0.202340; batch adversarial loss: 0.444168\n",
      "epoch 27; iter: 0; batch classifier loss: 0.146899; batch adversarial loss: 0.442105\n",
      "epoch 28; iter: 0; batch classifier loss: 0.236418; batch adversarial loss: 0.435594\n",
      "epoch 29; iter: 0; batch classifier loss: 0.199392; batch adversarial loss: 0.452389\n",
      "epoch 30; iter: 0; batch classifier loss: 0.182834; batch adversarial loss: 0.492855\n",
      "epoch 31; iter: 0; batch classifier loss: 0.183976; batch adversarial loss: 0.548919\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140645; batch adversarial loss: 0.462209\n",
      "epoch 33; iter: 0; batch classifier loss: 0.179154; batch adversarial loss: 0.453254\n",
      "epoch 34; iter: 0; batch classifier loss: 0.141298; batch adversarial loss: 0.550727\n",
      "epoch 35; iter: 0; batch classifier loss: 0.169230; batch adversarial loss: 0.451437\n",
      "epoch 36; iter: 0; batch classifier loss: 0.171737; batch adversarial loss: 0.481787\n",
      "epoch 37; iter: 0; batch classifier loss: 0.159218; batch adversarial loss: 0.467262\n",
      "epoch 38; iter: 0; batch classifier loss: 0.157420; batch adversarial loss: 0.516418\n",
      "epoch 39; iter: 0; batch classifier loss: 0.177178; batch adversarial loss: 0.420739\n",
      "epoch 40; iter: 0; batch classifier loss: 0.144723; batch adversarial loss: 0.463552\n",
      "epoch 41; iter: 0; batch classifier loss: 0.127329; batch adversarial loss: 0.501255\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117559; batch adversarial loss: 0.497019\n",
      "epoch 43; iter: 0; batch classifier loss: 0.153906; batch adversarial loss: 0.493411\n",
      "epoch 44; iter: 0; batch classifier loss: 0.173925; batch adversarial loss: 0.560775\n",
      "epoch 45; iter: 0; batch classifier loss: 0.153582; batch adversarial loss: 0.472766\n",
      "epoch 46; iter: 0; batch classifier loss: 0.184323; batch adversarial loss: 0.556406\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106160; batch adversarial loss: 0.463641\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100983; batch adversarial loss: 0.474377\n",
      "epoch 49; iter: 0; batch classifier loss: 0.168001; batch adversarial loss: 0.458394\n",
      "epoch 50; iter: 0; batch classifier loss: 0.143100; batch adversarial loss: 0.493052\n",
      "epoch 51; iter: 0; batch classifier loss: 0.133187; batch adversarial loss: 0.516896\n",
      "epoch 52; iter: 0; batch classifier loss: 0.124805; batch adversarial loss: 0.446420\n",
      "epoch 53; iter: 0; batch classifier loss: 0.133234; batch adversarial loss: 0.435322\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090411; batch adversarial loss: 0.469545\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079630; batch adversarial loss: 0.501226\n",
      "epoch 56; iter: 0; batch classifier loss: 0.104252; batch adversarial loss: 0.513869\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082967; batch adversarial loss: 0.420581\n",
      "epoch 58; iter: 0; batch classifier loss: 0.167222; batch adversarial loss: 0.489005\n",
      "epoch 59; iter: 0; batch classifier loss: 0.113660; batch adversarial loss: 0.466862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.106560; batch adversarial loss: 0.440289\n",
      "epoch 61; iter: 0; batch classifier loss: 0.102933; batch adversarial loss: 0.495359\n",
      "epoch 62; iter: 0; batch classifier loss: 0.091683; batch adversarial loss: 0.431406\n",
      "epoch 63; iter: 0; batch classifier loss: 0.121988; batch adversarial loss: 0.403299\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106135; batch adversarial loss: 0.445877\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065927; batch adversarial loss: 0.538120\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096987; batch adversarial loss: 0.488582\n",
      "epoch 67; iter: 0; batch classifier loss: 0.115380; batch adversarial loss: 0.495196\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076239; batch adversarial loss: 0.566037\n",
      "epoch 69; iter: 0; batch classifier loss: 0.049902; batch adversarial loss: 0.463429\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066390; batch adversarial loss: 0.453586\n",
      "epoch 71; iter: 0; batch classifier loss: 0.062563; batch adversarial loss: 0.542435\n",
      "epoch 72; iter: 0; batch classifier loss: 0.049301; batch adversarial loss: 0.466439\n",
      "epoch 73; iter: 0; batch classifier loss: 0.063886; batch adversarial loss: 0.476273\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069439; batch adversarial loss: 0.403670\n",
      "epoch 75; iter: 0; batch classifier loss: 0.100757; batch adversarial loss: 0.508938\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064299; batch adversarial loss: 0.437902\n",
      "epoch 77; iter: 0; batch classifier loss: 0.126007; batch adversarial loss: 0.442862\n",
      "epoch 78; iter: 0; batch classifier loss: 0.101138; batch adversarial loss: 0.452068\n",
      "epoch 79; iter: 0; batch classifier loss: 0.058754; batch adversarial loss: 0.410882\n",
      "epoch 80; iter: 0; batch classifier loss: 0.111449; batch adversarial loss: 0.413296\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074226; batch adversarial loss: 0.418725\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073850; batch adversarial loss: 0.444344\n",
      "epoch 83; iter: 0; batch classifier loss: 0.053101; batch adversarial loss: 0.373689\n",
      "epoch 84; iter: 0; batch classifier loss: 0.066674; batch adversarial loss: 0.451626\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052545; batch adversarial loss: 0.473816\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067979; batch adversarial loss: 0.473842\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067074; batch adversarial loss: 0.488279\n",
      "epoch 88; iter: 0; batch classifier loss: 0.129200; batch adversarial loss: 0.548450\n",
      "epoch 89; iter: 0; batch classifier loss: 0.085619; batch adversarial loss: 0.444010\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053466; batch adversarial loss: 0.412235\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067837; batch adversarial loss: 0.499861\n",
      "epoch 92; iter: 0; batch classifier loss: 0.028474; batch adversarial loss: 0.471036\n",
      "epoch 93; iter: 0; batch classifier loss: 0.038857; batch adversarial loss: 0.489765\n",
      "epoch 94; iter: 0; batch classifier loss: 0.034716; batch adversarial loss: 0.503349\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064210; batch adversarial loss: 0.402225\n",
      "epoch 96; iter: 0; batch classifier loss: 0.039325; batch adversarial loss: 0.517685\n",
      "epoch 97; iter: 0; batch classifier loss: 0.097306; batch adversarial loss: 0.509933\n",
      "epoch 98; iter: 0; batch classifier loss: 0.029414; batch adversarial loss: 0.459780\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048151; batch adversarial loss: 0.457151\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051638; batch adversarial loss: 0.494295\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063335; batch adversarial loss: 0.402726\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033517; batch adversarial loss: 0.430082\n",
      "epoch 103; iter: 0; batch classifier loss: 0.024249; batch adversarial loss: 0.422272\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041830; batch adversarial loss: 0.428215\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042535; batch adversarial loss: 0.480661\n",
      "epoch 106; iter: 0; batch classifier loss: 0.073060; batch adversarial loss: 0.511321\n",
      "epoch 107; iter: 0; batch classifier loss: 0.029471; batch adversarial loss: 0.450524\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030958; batch adversarial loss: 0.356402\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046141; batch adversarial loss: 0.595955\n",
      "epoch 110; iter: 0; batch classifier loss: 0.024459; batch adversarial loss: 0.445548\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033329; batch adversarial loss: 0.453043\n",
      "epoch 112; iter: 0; batch classifier loss: 0.069916; batch adversarial loss: 0.359803\n",
      "epoch 113; iter: 0; batch classifier loss: 0.036731; batch adversarial loss: 0.467449\n",
      "epoch 114; iter: 0; batch classifier loss: 0.031594; batch adversarial loss: 0.497474\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035248; batch adversarial loss: 0.485078\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024205; batch adversarial loss: 0.513449\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039294; batch adversarial loss: 0.404772\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041733; batch adversarial loss: 0.515904\n",
      "epoch 119; iter: 0; batch classifier loss: 0.012640; batch adversarial loss: 0.485522\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034830; batch adversarial loss: 0.397667\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035393; batch adversarial loss: 0.479522\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034034; batch adversarial loss: 0.521255\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040338; batch adversarial loss: 0.395830\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021142; batch adversarial loss: 0.537989\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026900; batch adversarial loss: 0.409770\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017060; batch adversarial loss: 0.531407\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025092; batch adversarial loss: 0.601292\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058024; batch adversarial loss: 0.423075\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023919; batch adversarial loss: 0.425147\n",
      "epoch 130; iter: 0; batch classifier loss: 0.063526; batch adversarial loss: 0.490823\n",
      "epoch 131; iter: 0; batch classifier loss: 0.059662; batch adversarial loss: 0.389577\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020014; batch adversarial loss: 0.543856\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034091; batch adversarial loss: 0.504111\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035825; batch adversarial loss: 0.472918\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027536; batch adversarial loss: 0.445049\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018469; batch adversarial loss: 0.407627\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037970; batch adversarial loss: 0.369655\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018849; batch adversarial loss: 0.450327\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014002; batch adversarial loss: 0.484495\n",
      "epoch 140; iter: 0; batch classifier loss: 0.009121; batch adversarial loss: 0.468054\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021451; batch adversarial loss: 0.420323\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034596; batch adversarial loss: 0.474113\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022126; batch adversarial loss: 0.417991\n",
      "epoch 144; iter: 0; batch classifier loss: 0.044190; batch adversarial loss: 0.543525\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013031; batch adversarial loss: 0.461688\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045910; batch adversarial loss: 0.427899\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015100; batch adversarial loss: 0.512363\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017050; batch adversarial loss: 0.419797\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029556; batch adversarial loss: 0.545895\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036906; batch adversarial loss: 0.448303\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021848; batch adversarial loss: 0.375388\n",
      "epoch 152; iter: 0; batch classifier loss: 0.004992; batch adversarial loss: 0.507433\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023721; batch adversarial loss: 0.542390\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022753; batch adversarial loss: 0.463002\n",
      "epoch 155; iter: 0; batch classifier loss: 0.008005; batch adversarial loss: 0.521865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.028179; batch adversarial loss: 0.441071\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034504; batch adversarial loss: 0.488991\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016679; batch adversarial loss: 0.477840\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019725; batch adversarial loss: 0.459273\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018296; batch adversarial loss: 0.515165\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025369; batch adversarial loss: 0.540541\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018457; batch adversarial loss: 0.470660\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033117; batch adversarial loss: 0.392412\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033439; batch adversarial loss: 0.458176\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012415; batch adversarial loss: 0.402414\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023477; batch adversarial loss: 0.447362\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020658; batch adversarial loss: 0.484710\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007302; batch adversarial loss: 0.467740\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007377; batch adversarial loss: 0.498104\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010003; batch adversarial loss: 0.479091\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025703; batch adversarial loss: 0.482478\n",
      "epoch 172; iter: 0; batch classifier loss: 0.050006; batch adversarial loss: 0.554971\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012277; batch adversarial loss: 0.422602\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012630; batch adversarial loss: 0.398315\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022688; batch adversarial loss: 0.419195\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016520; batch adversarial loss: 0.433780\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025224; batch adversarial loss: 0.448967\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010018; batch adversarial loss: 0.489444\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011598; batch adversarial loss: 0.389616\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017901; batch adversarial loss: 0.484378\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016537; batch adversarial loss: 0.562918\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012669; batch adversarial loss: 0.551239\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005743; batch adversarial loss: 0.491757\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019472; batch adversarial loss: 0.415630\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022502; batch adversarial loss: 0.427194\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011466; batch adversarial loss: 0.472165\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009896; batch adversarial loss: 0.485792\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008061; batch adversarial loss: 0.446680\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007510; batch adversarial loss: 0.558681\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012747; batch adversarial loss: 0.377358\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027388; batch adversarial loss: 0.505781\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016833; batch adversarial loss: 0.542073\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032423; batch adversarial loss: 0.510806\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006007; batch adversarial loss: 0.501246\n",
      "epoch 195; iter: 0; batch classifier loss: 0.007376; batch adversarial loss: 0.358171\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006241; batch adversarial loss: 0.399820\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015443; batch adversarial loss: 0.515473\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019829; batch adversarial loss: 0.398135\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007169; batch adversarial loss: 0.357623\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685632; batch adversarial loss: 0.798803\n",
      "epoch 1; iter: 0; batch classifier loss: 0.412630; batch adversarial loss: 0.735525\n",
      "epoch 2; iter: 0; batch classifier loss: 0.359751; batch adversarial loss: 0.700428\n",
      "epoch 3; iter: 0; batch classifier loss: 0.370755; batch adversarial loss: 0.658694\n",
      "epoch 4; iter: 0; batch classifier loss: 0.330568; batch adversarial loss: 0.595534\n",
      "epoch 5; iter: 0; batch classifier loss: 0.263581; batch adversarial loss: 0.608364\n",
      "epoch 6; iter: 0; batch classifier loss: 0.308402; batch adversarial loss: 0.550953\n",
      "epoch 7; iter: 0; batch classifier loss: 0.283586; batch adversarial loss: 0.509173\n",
      "epoch 8; iter: 0; batch classifier loss: 0.300379; batch adversarial loss: 0.545113\n",
      "epoch 9; iter: 0; batch classifier loss: 0.342084; batch adversarial loss: 0.553703\n",
      "epoch 10; iter: 0; batch classifier loss: 0.388540; batch adversarial loss: 0.562262\n",
      "epoch 11; iter: 0; batch classifier loss: 0.398306; batch adversarial loss: 0.531205\n",
      "epoch 12; iter: 0; batch classifier loss: 0.343739; batch adversarial loss: 0.526385\n",
      "epoch 13; iter: 0; batch classifier loss: 0.334365; batch adversarial loss: 0.526982\n",
      "epoch 14; iter: 0; batch classifier loss: 0.399747; batch adversarial loss: 0.488191\n",
      "epoch 15; iter: 0; batch classifier loss: 0.331207; batch adversarial loss: 0.549901\n",
      "epoch 16; iter: 0; batch classifier loss: 0.316582; batch adversarial loss: 0.497662\n",
      "epoch 17; iter: 0; batch classifier loss: 0.251665; batch adversarial loss: 0.457587\n",
      "epoch 18; iter: 0; batch classifier loss: 0.305115; batch adversarial loss: 0.483719\n",
      "epoch 19; iter: 0; batch classifier loss: 0.281335; batch adversarial loss: 0.553402\n",
      "epoch 20; iter: 0; batch classifier loss: 0.305773; batch adversarial loss: 0.491280\n",
      "epoch 21; iter: 0; batch classifier loss: 0.280040; batch adversarial loss: 0.500093\n",
      "epoch 22; iter: 0; batch classifier loss: 0.263090; batch adversarial loss: 0.489907\n",
      "epoch 23; iter: 0; batch classifier loss: 0.202565; batch adversarial loss: 0.441699\n",
      "epoch 24; iter: 0; batch classifier loss: 0.332853; batch adversarial loss: 0.539741\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237379; batch adversarial loss: 0.508233\n",
      "epoch 26; iter: 0; batch classifier loss: 0.255601; batch adversarial loss: 0.409169\n",
      "epoch 27; iter: 0; batch classifier loss: 0.274261; batch adversarial loss: 0.392764\n",
      "epoch 28; iter: 0; batch classifier loss: 0.174795; batch adversarial loss: 0.415152\n",
      "epoch 29; iter: 0; batch classifier loss: 0.228969; batch adversarial loss: 0.342585\n",
      "epoch 30; iter: 0; batch classifier loss: 0.262402; batch adversarial loss: 0.422625\n",
      "epoch 31; iter: 0; batch classifier loss: 0.260263; batch adversarial loss: 0.470089\n",
      "epoch 32; iter: 0; batch classifier loss: 0.237510; batch adversarial loss: 0.425877\n",
      "epoch 33; iter: 0; batch classifier loss: 0.259803; batch adversarial loss: 0.412860\n",
      "epoch 34; iter: 0; batch classifier loss: 0.244772; batch adversarial loss: 0.428966\n",
      "epoch 35; iter: 0; batch classifier loss: 0.244275; batch adversarial loss: 0.549285\n",
      "epoch 36; iter: 0; batch classifier loss: 0.165336; batch adversarial loss: 0.481799\n",
      "epoch 37; iter: 0; batch classifier loss: 0.204779; batch adversarial loss: 0.474688\n",
      "epoch 38; iter: 0; batch classifier loss: 0.201622; batch adversarial loss: 0.432196\n",
      "epoch 39; iter: 0; batch classifier loss: 0.184785; batch adversarial loss: 0.482835\n",
      "epoch 40; iter: 0; batch classifier loss: 0.253804; batch adversarial loss: 0.511442\n",
      "epoch 41; iter: 0; batch classifier loss: 0.201001; batch adversarial loss: 0.494595\n",
      "epoch 42; iter: 0; batch classifier loss: 0.276923; batch adversarial loss: 0.424069\n",
      "epoch 43; iter: 0; batch classifier loss: 0.239391; batch adversarial loss: 0.447381\n",
      "epoch 44; iter: 0; batch classifier loss: 0.250223; batch adversarial loss: 0.458241\n",
      "epoch 45; iter: 0; batch classifier loss: 0.232342; batch adversarial loss: 0.517745\n",
      "epoch 46; iter: 0; batch classifier loss: 0.262476; batch adversarial loss: 0.447420\n",
      "epoch 47; iter: 0; batch classifier loss: 0.268698; batch adversarial loss: 0.495506\n",
      "epoch 48; iter: 0; batch classifier loss: 0.171733; batch adversarial loss: 0.635065\n",
      "epoch 49; iter: 0; batch classifier loss: 0.210990; batch adversarial loss: 0.412640\n",
      "epoch 50; iter: 0; batch classifier loss: 0.240820; batch adversarial loss: 0.375919\n",
      "epoch 51; iter: 0; batch classifier loss: 0.251422; batch adversarial loss: 0.519517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.212131; batch adversarial loss: 0.412059\n",
      "epoch 53; iter: 0; batch classifier loss: 0.277825; batch adversarial loss: 0.577601\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122359; batch adversarial loss: 0.434973\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096918; batch adversarial loss: 0.445223\n",
      "epoch 56; iter: 0; batch classifier loss: 0.093583; batch adversarial loss: 0.458172\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106309; batch adversarial loss: 0.473385\n",
      "epoch 58; iter: 0; batch classifier loss: 0.076562; batch adversarial loss: 0.458807\n",
      "epoch 59; iter: 0; batch classifier loss: 0.061690; batch adversarial loss: 0.507499\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072892; batch adversarial loss: 0.437600\n",
      "epoch 61; iter: 0; batch classifier loss: 0.076650; batch adversarial loss: 0.580674\n",
      "epoch 62; iter: 0; batch classifier loss: 0.059690; batch adversarial loss: 0.431824\n",
      "epoch 63; iter: 0; batch classifier loss: 0.071533; batch adversarial loss: 0.452558\n",
      "epoch 64; iter: 0; batch classifier loss: 0.081380; batch adversarial loss: 0.513223\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122916; batch adversarial loss: 0.515976\n",
      "epoch 66; iter: 0; batch classifier loss: 0.130689; batch adversarial loss: 0.417037\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101790; batch adversarial loss: 0.406937\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081826; batch adversarial loss: 0.417668\n",
      "epoch 69; iter: 0; batch classifier loss: 0.125523; batch adversarial loss: 0.436256\n",
      "epoch 70; iter: 0; batch classifier loss: 0.060742; batch adversarial loss: 0.444993\n",
      "epoch 71; iter: 0; batch classifier loss: 0.088052; batch adversarial loss: 0.400329\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100470; batch adversarial loss: 0.429313\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087141; batch adversarial loss: 0.500191\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101627; batch adversarial loss: 0.485809\n",
      "epoch 75; iter: 0; batch classifier loss: 0.041326; batch adversarial loss: 0.393483\n",
      "epoch 76; iter: 0; batch classifier loss: 0.028009; batch adversarial loss: 0.390024\n",
      "epoch 77; iter: 0; batch classifier loss: 0.075540; batch adversarial loss: 0.356973\n",
      "epoch 78; iter: 0; batch classifier loss: 0.050678; batch adversarial loss: 0.463434\n",
      "epoch 79; iter: 0; batch classifier loss: 0.052564; batch adversarial loss: 0.513894\n",
      "epoch 80; iter: 0; batch classifier loss: 0.046425; batch adversarial loss: 0.463448\n",
      "epoch 81; iter: 0; batch classifier loss: 0.045750; batch adversarial loss: 0.458205\n",
      "epoch 82; iter: 0; batch classifier loss: 0.032604; batch adversarial loss: 0.422321\n",
      "epoch 83; iter: 0; batch classifier loss: 0.042057; batch adversarial loss: 0.417468\n",
      "epoch 84; iter: 0; batch classifier loss: 0.110178; batch adversarial loss: 0.417304\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058933; batch adversarial loss: 0.422958\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066968; batch adversarial loss: 0.448915\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059153; batch adversarial loss: 0.459228\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042122; batch adversarial loss: 0.472972\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073780; batch adversarial loss: 0.414752\n",
      "epoch 90; iter: 0; batch classifier loss: 0.071137; batch adversarial loss: 0.497328\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055362; batch adversarial loss: 0.490120\n",
      "epoch 92; iter: 0; batch classifier loss: 0.042755; batch adversarial loss: 0.418332\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044242; batch adversarial loss: 0.513738\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062382; batch adversarial loss: 0.401132\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039972; batch adversarial loss: 0.413549\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051865; batch adversarial loss: 0.467133\n",
      "epoch 97; iter: 0; batch classifier loss: 0.022985; batch adversarial loss: 0.479329\n",
      "epoch 98; iter: 0; batch classifier loss: 0.037401; batch adversarial loss: 0.511275\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038072; batch adversarial loss: 0.532190\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034658; batch adversarial loss: 0.449521\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037634; batch adversarial loss: 0.451455\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031893; batch adversarial loss: 0.450204\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047396; batch adversarial loss: 0.375584\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038625; batch adversarial loss: 0.637295\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035317; batch adversarial loss: 0.421694\n",
      "epoch 106; iter: 0; batch classifier loss: 0.023584; batch adversarial loss: 0.429422\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035858; batch adversarial loss: 0.410811\n",
      "epoch 108; iter: 0; batch classifier loss: 0.019383; batch adversarial loss: 0.450883\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039053; batch adversarial loss: 0.508190\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051443; batch adversarial loss: 0.406199\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042597; batch adversarial loss: 0.510952\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063195; batch adversarial loss: 0.414831\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033006; batch adversarial loss: 0.514878\n",
      "epoch 114; iter: 0; batch classifier loss: 0.011001; batch adversarial loss: 0.513339\n",
      "epoch 115; iter: 0; batch classifier loss: 0.017980; batch adversarial loss: 0.505284\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046577; batch adversarial loss: 0.537601\n",
      "epoch 117; iter: 0; batch classifier loss: 0.014039; batch adversarial loss: 0.450886\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026471; batch adversarial loss: 0.424855\n",
      "epoch 119; iter: 0; batch classifier loss: 0.028573; batch adversarial loss: 0.482085\n",
      "epoch 120; iter: 0; batch classifier loss: 0.014454; batch adversarial loss: 0.540372\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037398; batch adversarial loss: 0.392854\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046735; batch adversarial loss: 0.466218\n",
      "epoch 123; iter: 0; batch classifier loss: 0.015230; batch adversarial loss: 0.529279\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023164; batch adversarial loss: 0.405076\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023769; batch adversarial loss: 0.424717\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029274; batch adversarial loss: 0.476333\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051505; batch adversarial loss: 0.444703\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041837; batch adversarial loss: 0.490810\n",
      "epoch 129; iter: 0; batch classifier loss: 0.011097; batch adversarial loss: 0.414111\n",
      "epoch 130; iter: 0; batch classifier loss: 0.062799; batch adversarial loss: 0.495004\n",
      "epoch 131; iter: 0; batch classifier loss: 0.014766; batch adversarial loss: 0.561666\n",
      "epoch 132; iter: 0; batch classifier loss: 0.065397; batch adversarial loss: 0.377720\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040645; batch adversarial loss: 0.430181\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028106; batch adversarial loss: 0.454139\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019732; batch adversarial loss: 0.478744\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044863; batch adversarial loss: 0.399299\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027436; batch adversarial loss: 0.463957\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021145; batch adversarial loss: 0.517876\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036018; batch adversarial loss: 0.356261\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026042; batch adversarial loss: 0.377392\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039439; batch adversarial loss: 0.427780\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044021; batch adversarial loss: 0.431949\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010595; batch adversarial loss: 0.497509\n",
      "epoch 144; iter: 0; batch classifier loss: 0.058733; batch adversarial loss: 0.434386\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040280; batch adversarial loss: 0.469149\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016574; batch adversarial loss: 0.411132\n",
      "epoch 147; iter: 0; batch classifier loss: 0.006912; batch adversarial loss: 0.480703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.030062; batch adversarial loss: 0.419939\n",
      "epoch 149; iter: 0; batch classifier loss: 0.005929; batch adversarial loss: 0.445706\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030774; batch adversarial loss: 0.523683\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009518; batch adversarial loss: 0.397825\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043687; batch adversarial loss: 0.472135\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034286; batch adversarial loss: 0.467977\n",
      "epoch 154; iter: 0; batch classifier loss: 0.009501; batch adversarial loss: 0.424450\n",
      "epoch 155; iter: 0; batch classifier loss: 0.006853; batch adversarial loss: 0.476764\n",
      "epoch 156; iter: 0; batch classifier loss: 0.006186; batch adversarial loss: 0.446452\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019089; batch adversarial loss: 0.468345\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022461; batch adversarial loss: 0.452532\n",
      "epoch 159; iter: 0; batch classifier loss: 0.009669; batch adversarial loss: 0.579983\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032891; batch adversarial loss: 0.425271\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010368; batch adversarial loss: 0.475838\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011286; batch adversarial loss: 0.490347\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026360; batch adversarial loss: 0.492127\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015549; batch adversarial loss: 0.416943\n",
      "epoch 165; iter: 0; batch classifier loss: 0.054213; batch adversarial loss: 0.463660\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037057; batch adversarial loss: 0.475319\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021840; batch adversarial loss: 0.464027\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022922; batch adversarial loss: 0.424379\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033235; batch adversarial loss: 0.446153\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012302; batch adversarial loss: 0.401015\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031110; batch adversarial loss: 0.506559\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020484; batch adversarial loss: 0.454942\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021617; batch adversarial loss: 0.464708\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020398; batch adversarial loss: 0.494293\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023745; batch adversarial loss: 0.482842\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008144; batch adversarial loss: 0.509495\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021572; batch adversarial loss: 0.483476\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017589; batch adversarial loss: 0.430728\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012735; batch adversarial loss: 0.400936\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015730; batch adversarial loss: 0.530091\n",
      "epoch 181; iter: 0; batch classifier loss: 0.047290; batch adversarial loss: 0.506595\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006175; batch adversarial loss: 0.484089\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020010; batch adversarial loss: 0.473304\n",
      "epoch 184; iter: 0; batch classifier loss: 0.050108; batch adversarial loss: 0.446949\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023421; batch adversarial loss: 0.508002\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012754; batch adversarial loss: 0.444026\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036015; batch adversarial loss: 0.339529\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034494; batch adversarial loss: 0.354339\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020050; batch adversarial loss: 0.413423\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011150; batch adversarial loss: 0.541843\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013932; batch adversarial loss: 0.505409\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031687; batch adversarial loss: 0.446549\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019500; batch adversarial loss: 0.352213\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020509; batch adversarial loss: 0.433296\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017750; batch adversarial loss: 0.459644\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008048; batch adversarial loss: 0.358902\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010143; batch adversarial loss: 0.381873\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004742; batch adversarial loss: 0.461006\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018496; batch adversarial loss: 0.393294\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692025; batch adversarial loss: 0.709619\n",
      "epoch 1; iter: 0; batch classifier loss: 0.466699; batch adversarial loss: 0.669397\n",
      "epoch 2; iter: 0; batch classifier loss: 0.389090; batch adversarial loss: 0.649391\n",
      "epoch 3; iter: 0; batch classifier loss: 0.326319; batch adversarial loss: 0.628630\n",
      "epoch 4; iter: 0; batch classifier loss: 0.327542; batch adversarial loss: 0.568984\n",
      "epoch 5; iter: 0; batch classifier loss: 0.350536; batch adversarial loss: 0.580797\n",
      "epoch 6; iter: 0; batch classifier loss: 0.330723; batch adversarial loss: 0.563618\n",
      "epoch 7; iter: 0; batch classifier loss: 0.328725; batch adversarial loss: 0.561164\n",
      "epoch 8; iter: 0; batch classifier loss: 0.313953; batch adversarial loss: 0.540159\n",
      "epoch 9; iter: 0; batch classifier loss: 0.244847; batch adversarial loss: 0.607651\n",
      "epoch 10; iter: 0; batch classifier loss: 0.345285; batch adversarial loss: 0.527380\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403381; batch adversarial loss: 0.572358\n",
      "epoch 12; iter: 0; batch classifier loss: 0.430981; batch adversarial loss: 0.588842\n",
      "epoch 13; iter: 0; batch classifier loss: 0.490768; batch adversarial loss: 0.592334\n",
      "epoch 14; iter: 0; batch classifier loss: 0.440581; batch adversarial loss: 0.465486\n",
      "epoch 15; iter: 0; batch classifier loss: 0.292667; batch adversarial loss: 0.493014\n",
      "epoch 16; iter: 0; batch classifier loss: 0.236828; batch adversarial loss: 0.509905\n",
      "epoch 17; iter: 0; batch classifier loss: 0.212488; batch adversarial loss: 0.555953\n",
      "epoch 18; iter: 0; batch classifier loss: 0.287753; batch adversarial loss: 0.478651\n",
      "epoch 19; iter: 0; batch classifier loss: 0.267596; batch adversarial loss: 0.534930\n",
      "epoch 20; iter: 0; batch classifier loss: 0.231163; batch adversarial loss: 0.522877\n",
      "epoch 21; iter: 0; batch classifier loss: 0.206683; batch adversarial loss: 0.537999\n",
      "epoch 22; iter: 0; batch classifier loss: 0.183167; batch adversarial loss: 0.486335\n",
      "epoch 23; iter: 0; batch classifier loss: 0.208962; batch adversarial loss: 0.486616\n",
      "epoch 24; iter: 0; batch classifier loss: 0.205305; batch adversarial loss: 0.528500\n",
      "epoch 25; iter: 0; batch classifier loss: 0.239934; batch adversarial loss: 0.419610\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182082; batch adversarial loss: 0.443475\n",
      "epoch 27; iter: 0; batch classifier loss: 0.180316; batch adversarial loss: 0.522359\n",
      "epoch 28; iter: 0; batch classifier loss: 0.149365; batch adversarial loss: 0.488903\n",
      "epoch 29; iter: 0; batch classifier loss: 0.168230; batch adversarial loss: 0.396863\n",
      "epoch 30; iter: 0; batch classifier loss: 0.125995; batch adversarial loss: 0.391383\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134727; batch adversarial loss: 0.475698\n",
      "epoch 32; iter: 0; batch classifier loss: 0.167015; batch adversarial loss: 0.446557\n",
      "epoch 33; iter: 0; batch classifier loss: 0.135157; batch adversarial loss: 0.420492\n",
      "epoch 34; iter: 0; batch classifier loss: 0.202659; batch adversarial loss: 0.486040\n",
      "epoch 35; iter: 0; batch classifier loss: 0.141370; batch adversarial loss: 0.453213\n",
      "epoch 36; iter: 0; batch classifier loss: 0.137951; batch adversarial loss: 0.399141\n",
      "epoch 37; iter: 0; batch classifier loss: 0.140375; batch adversarial loss: 0.467822\n",
      "epoch 38; iter: 0; batch classifier loss: 0.141684; batch adversarial loss: 0.405748\n",
      "epoch 39; iter: 0; batch classifier loss: 0.157924; batch adversarial loss: 0.360037\n",
      "epoch 40; iter: 0; batch classifier loss: 0.151966; batch adversarial loss: 0.440502\n",
      "epoch 41; iter: 0; batch classifier loss: 0.138243; batch adversarial loss: 0.399325\n",
      "epoch 42; iter: 0; batch classifier loss: 0.128704; batch adversarial loss: 0.414042\n",
      "epoch 43; iter: 0; batch classifier loss: 0.111534; batch adversarial loss: 0.396876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.072395; batch adversarial loss: 0.497220\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099698; batch adversarial loss: 0.477542\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112547; batch adversarial loss: 0.490592\n",
      "epoch 47; iter: 0; batch classifier loss: 0.122028; batch adversarial loss: 0.494273\n",
      "epoch 48; iter: 0; batch classifier loss: 0.105824; batch adversarial loss: 0.447484\n",
      "epoch 49; iter: 0; batch classifier loss: 0.092382; batch adversarial loss: 0.543284\n",
      "epoch 50; iter: 0; batch classifier loss: 0.142435; batch adversarial loss: 0.478201\n",
      "epoch 51; iter: 0; batch classifier loss: 0.095051; batch adversarial loss: 0.411431\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109431; batch adversarial loss: 0.498922\n",
      "epoch 53; iter: 0; batch classifier loss: 0.114864; batch adversarial loss: 0.432042\n",
      "epoch 54; iter: 0; batch classifier loss: 0.082481; batch adversarial loss: 0.428381\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083072; batch adversarial loss: 0.456723\n",
      "epoch 56; iter: 0; batch classifier loss: 0.048282; batch adversarial loss: 0.426003\n",
      "epoch 57; iter: 0; batch classifier loss: 0.092213; batch adversarial loss: 0.445829\n",
      "epoch 58; iter: 0; batch classifier loss: 0.114260; batch adversarial loss: 0.421488\n",
      "epoch 59; iter: 0; batch classifier loss: 0.075974; batch adversarial loss: 0.547921\n",
      "epoch 60; iter: 0; batch classifier loss: 0.080624; batch adversarial loss: 0.454805\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078513; batch adversarial loss: 0.513513\n",
      "epoch 62; iter: 0; batch classifier loss: 0.043914; batch adversarial loss: 0.440515\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100915; batch adversarial loss: 0.478540\n",
      "epoch 64; iter: 0; batch classifier loss: 0.048123; batch adversarial loss: 0.506431\n",
      "epoch 65; iter: 0; batch classifier loss: 0.106172; batch adversarial loss: 0.523095\n",
      "epoch 66; iter: 0; batch classifier loss: 0.052579; batch adversarial loss: 0.539790\n",
      "epoch 67; iter: 0; batch classifier loss: 0.093171; batch adversarial loss: 0.360289\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082150; batch adversarial loss: 0.434706\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070680; batch adversarial loss: 0.419692\n",
      "epoch 70; iter: 0; batch classifier loss: 0.058040; batch adversarial loss: 0.378921\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064703; batch adversarial loss: 0.422582\n",
      "epoch 72; iter: 0; batch classifier loss: 0.040208; batch adversarial loss: 0.377681\n",
      "epoch 73; iter: 0; batch classifier loss: 0.038179; batch adversarial loss: 0.426497\n",
      "epoch 74; iter: 0; batch classifier loss: 0.057936; batch adversarial loss: 0.557064\n",
      "epoch 75; iter: 0; batch classifier loss: 0.097157; batch adversarial loss: 0.413798\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059730; batch adversarial loss: 0.444607\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071322; batch adversarial loss: 0.518266\n",
      "epoch 78; iter: 0; batch classifier loss: 0.060016; batch adversarial loss: 0.504154\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080490; batch adversarial loss: 0.574143\n",
      "epoch 80; iter: 0; batch classifier loss: 0.097270; batch adversarial loss: 0.435282\n",
      "epoch 81; iter: 0; batch classifier loss: 0.098648; batch adversarial loss: 0.385674\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067180; batch adversarial loss: 0.418063\n",
      "epoch 83; iter: 0; batch classifier loss: 0.041674; batch adversarial loss: 0.438135\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055792; batch adversarial loss: 0.495989\n",
      "epoch 85; iter: 0; batch classifier loss: 0.048429; batch adversarial loss: 0.370915\n",
      "epoch 86; iter: 0; batch classifier loss: 0.098547; batch adversarial loss: 0.473904\n",
      "epoch 87; iter: 0; batch classifier loss: 0.038971; batch adversarial loss: 0.519313\n",
      "epoch 88; iter: 0; batch classifier loss: 0.034836; batch adversarial loss: 0.565188\n",
      "epoch 89; iter: 0; batch classifier loss: 0.031739; batch adversarial loss: 0.463855\n",
      "epoch 90; iter: 0; batch classifier loss: 0.114613; batch adversarial loss: 0.496606\n",
      "epoch 91; iter: 0; batch classifier loss: 0.041888; batch adversarial loss: 0.505354\n",
      "epoch 92; iter: 0; batch classifier loss: 0.092883; batch adversarial loss: 0.501659\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058849; batch adversarial loss: 0.459875\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075186; batch adversarial loss: 0.457463\n",
      "epoch 95; iter: 0; batch classifier loss: 0.023459; batch adversarial loss: 0.408321\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044215; batch adversarial loss: 0.407653\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044727; batch adversarial loss: 0.396545\n",
      "epoch 98; iter: 0; batch classifier loss: 0.024373; batch adversarial loss: 0.504562\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037488; batch adversarial loss: 0.432137\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051187; batch adversarial loss: 0.374540\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050159; batch adversarial loss: 0.446916\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029584; batch adversarial loss: 0.572434\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050896; batch adversarial loss: 0.446018\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046876; batch adversarial loss: 0.387117\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053822; batch adversarial loss: 0.470283\n",
      "epoch 106; iter: 0; batch classifier loss: 0.027983; batch adversarial loss: 0.461436\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059049; batch adversarial loss: 0.471000\n",
      "epoch 108; iter: 0; batch classifier loss: 0.016826; batch adversarial loss: 0.453237\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041704; batch adversarial loss: 0.495801\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028331; batch adversarial loss: 0.426188\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036789; batch adversarial loss: 0.508778\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043422; batch adversarial loss: 0.513397\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033606; batch adversarial loss: 0.527551\n",
      "epoch 114; iter: 0; batch classifier loss: 0.014176; batch adversarial loss: 0.472614\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042784; batch adversarial loss: 0.399181\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068913; batch adversarial loss: 0.422380\n",
      "epoch 117; iter: 0; batch classifier loss: 0.021743; batch adversarial loss: 0.512943\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048629; batch adversarial loss: 0.605513\n",
      "epoch 119; iter: 0; batch classifier loss: 0.062292; batch adversarial loss: 0.440996\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041069; batch adversarial loss: 0.347048\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039624; batch adversarial loss: 0.551436\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042639; batch adversarial loss: 0.476781\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067118; batch adversarial loss: 0.446627\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026700; batch adversarial loss: 0.463971\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036854; batch adversarial loss: 0.549530\n",
      "epoch 126; iter: 0; batch classifier loss: 0.018625; batch adversarial loss: 0.452744\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026031; batch adversarial loss: 0.470775\n",
      "epoch 128; iter: 0; batch classifier loss: 0.065231; batch adversarial loss: 0.466687\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023295; batch adversarial loss: 0.441890\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026725; batch adversarial loss: 0.433445\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028896; batch adversarial loss: 0.362910\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027755; batch adversarial loss: 0.424363\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029860; batch adversarial loss: 0.416364\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040982; batch adversarial loss: 0.497856\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031744; batch adversarial loss: 0.517343\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026920; batch adversarial loss: 0.482159\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048122; batch adversarial loss: 0.375448\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019900; batch adversarial loss: 0.381815\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022016; batch adversarial loss: 0.514580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.038072; batch adversarial loss: 0.436379\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033991; batch adversarial loss: 0.485257\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045265; batch adversarial loss: 0.392463\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023572; batch adversarial loss: 0.459223\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022824; batch adversarial loss: 0.556309\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012693; batch adversarial loss: 0.415058\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031893; batch adversarial loss: 0.505835\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035640; batch adversarial loss: 0.487296\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022516; batch adversarial loss: 0.493625\n",
      "epoch 149; iter: 0; batch classifier loss: 0.009603; batch adversarial loss: 0.429316\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036301; batch adversarial loss: 0.445715\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014884; batch adversarial loss: 0.494599\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016791; batch adversarial loss: 0.436134\n",
      "epoch 153; iter: 0; batch classifier loss: 0.055721; batch adversarial loss: 0.418061\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010278; batch adversarial loss: 0.465331\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024091; batch adversarial loss: 0.436498\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026784; batch adversarial loss: 0.428218\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019266; batch adversarial loss: 0.464104\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010002; batch adversarial loss: 0.464848\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010115; batch adversarial loss: 0.330355\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029622; batch adversarial loss: 0.463057\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022393; batch adversarial loss: 0.397968\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027850; batch adversarial loss: 0.547878\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013691; batch adversarial loss: 0.492960\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016556; batch adversarial loss: 0.370390\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032805; batch adversarial loss: 0.434981\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033539; batch adversarial loss: 0.470504\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010111; batch adversarial loss: 0.454698\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021189; batch adversarial loss: 0.405392\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024662; batch adversarial loss: 0.476169\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020204; batch adversarial loss: 0.469252\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026548; batch adversarial loss: 0.519701\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017563; batch adversarial loss: 0.367960\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013086; batch adversarial loss: 0.361103\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017451; batch adversarial loss: 0.472695\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022502; batch adversarial loss: 0.437262\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012089; batch adversarial loss: 0.482828\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026139; batch adversarial loss: 0.556618\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013148; batch adversarial loss: 0.466775\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026422; batch adversarial loss: 0.485319\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013321; batch adversarial loss: 0.397302\n",
      "epoch 181; iter: 0; batch classifier loss: 0.069600; batch adversarial loss: 0.406548\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022479; batch adversarial loss: 0.362857\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028321; batch adversarial loss: 0.480054\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009989; batch adversarial loss: 0.508456\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019370; batch adversarial loss: 0.400187\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005116; batch adversarial loss: 0.483201\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025457; batch adversarial loss: 0.430359\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008919; batch adversarial loss: 0.413727\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008932; batch adversarial loss: 0.423147\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013842; batch adversarial loss: 0.327811\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019900; batch adversarial loss: 0.487749\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007581; batch adversarial loss: 0.503095\n",
      "epoch 193; iter: 0; batch classifier loss: 0.040277; batch adversarial loss: 0.433230\n",
      "epoch 194; iter: 0; batch classifier loss: 0.051807; batch adversarial loss: 0.380910\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009808; batch adversarial loss: 0.533684\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009747; batch adversarial loss: 0.463361\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028383; batch adversarial loss: 0.427957\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011681; batch adversarial loss: 0.470930\n",
      "epoch 199; iter: 0; batch classifier loss: 0.037474; batch adversarial loss: 0.583979\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682081; batch adversarial loss: 0.850950\n",
      "epoch 1; iter: 0; batch classifier loss: 0.464572; batch adversarial loss: 0.933129\n",
      "epoch 2; iter: 0; batch classifier loss: 0.371242; batch adversarial loss: 0.936542\n",
      "epoch 3; iter: 0; batch classifier loss: 0.335188; batch adversarial loss: 0.917107\n",
      "epoch 4; iter: 0; batch classifier loss: 0.368940; batch adversarial loss: 0.780158\n",
      "epoch 5; iter: 0; batch classifier loss: 0.275904; batch adversarial loss: 0.721757\n",
      "epoch 6; iter: 0; batch classifier loss: 0.234380; batch adversarial loss: 0.688015\n",
      "epoch 7; iter: 0; batch classifier loss: 0.242606; batch adversarial loss: 0.672166\n",
      "epoch 8; iter: 0; batch classifier loss: 0.281660; batch adversarial loss: 0.639144\n",
      "epoch 9; iter: 0; batch classifier loss: 0.312524; batch adversarial loss: 0.668769\n",
      "epoch 10; iter: 0; batch classifier loss: 0.209077; batch adversarial loss: 0.631930\n",
      "epoch 11; iter: 0; batch classifier loss: 0.218385; batch adversarial loss: 0.606118\n",
      "epoch 12; iter: 0; batch classifier loss: 0.281297; batch adversarial loss: 0.598987\n",
      "epoch 13; iter: 0; batch classifier loss: 0.301824; batch adversarial loss: 0.560200\n",
      "epoch 14; iter: 0; batch classifier loss: 0.202307; batch adversarial loss: 0.520019\n",
      "epoch 15; iter: 0; batch classifier loss: 0.209335; batch adversarial loss: 0.529630\n",
      "epoch 16; iter: 0; batch classifier loss: 0.179099; batch adversarial loss: 0.480565\n",
      "epoch 17; iter: 0; batch classifier loss: 0.205209; batch adversarial loss: 0.461014\n",
      "epoch 18; iter: 0; batch classifier loss: 0.194649; batch adversarial loss: 0.477519\n",
      "epoch 19; iter: 0; batch classifier loss: 0.179867; batch adversarial loss: 0.473721\n",
      "epoch 20; iter: 0; batch classifier loss: 0.263935; batch adversarial loss: 0.498604\n",
      "epoch 21; iter: 0; batch classifier loss: 0.219365; batch adversarial loss: 0.452346\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189861; batch adversarial loss: 0.510098\n",
      "epoch 23; iter: 0; batch classifier loss: 0.215558; batch adversarial loss: 0.391459\n",
      "epoch 24; iter: 0; batch classifier loss: 0.198054; batch adversarial loss: 0.433877\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177315; batch adversarial loss: 0.389682\n",
      "epoch 26; iter: 0; batch classifier loss: 0.156227; batch adversarial loss: 0.500869\n",
      "epoch 27; iter: 0; batch classifier loss: 0.218283; batch adversarial loss: 0.464735\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185209; batch adversarial loss: 0.434987\n",
      "epoch 29; iter: 0; batch classifier loss: 0.173176; batch adversarial loss: 0.400665\n",
      "epoch 30; iter: 0; batch classifier loss: 0.204325; batch adversarial loss: 0.351697\n",
      "epoch 31; iter: 0; batch classifier loss: 0.158154; batch adversarial loss: 0.394011\n",
      "epoch 32; iter: 0; batch classifier loss: 0.130964; batch adversarial loss: 0.417841\n",
      "epoch 33; iter: 0; batch classifier loss: 0.106657; batch adversarial loss: 0.443435\n",
      "epoch 34; iter: 0; batch classifier loss: 0.153694; batch adversarial loss: 0.381773\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142452; batch adversarial loss: 0.418189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.112271; batch adversarial loss: 0.354960\n",
      "epoch 37; iter: 0; batch classifier loss: 0.151424; batch adversarial loss: 0.332701\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115547; batch adversarial loss: 0.393985\n",
      "epoch 39; iter: 0; batch classifier loss: 0.114737; batch adversarial loss: 0.487893\n",
      "epoch 40; iter: 0; batch classifier loss: 0.153871; batch adversarial loss: 0.377475\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135528; batch adversarial loss: 0.414387\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120961; batch adversarial loss: 0.427788\n",
      "epoch 43; iter: 0; batch classifier loss: 0.143114; batch adversarial loss: 0.386573\n",
      "epoch 44; iter: 0; batch classifier loss: 0.096470; batch adversarial loss: 0.391685\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103936; batch adversarial loss: 0.434093\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131530; batch adversarial loss: 0.447075\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106746; batch adversarial loss: 0.372340\n",
      "epoch 48; iter: 0; batch classifier loss: 0.073860; batch adversarial loss: 0.385750\n",
      "epoch 49; iter: 0; batch classifier loss: 0.104266; batch adversarial loss: 0.358628\n",
      "epoch 50; iter: 0; batch classifier loss: 0.092144; batch adversarial loss: 0.364679\n",
      "epoch 51; iter: 0; batch classifier loss: 0.102350; batch adversarial loss: 0.433971\n",
      "epoch 52; iter: 0; batch classifier loss: 0.105833; batch adversarial loss: 0.421096\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084117; batch adversarial loss: 0.434053\n",
      "epoch 54; iter: 0; batch classifier loss: 0.068204; batch adversarial loss: 0.497774\n",
      "epoch 55; iter: 0; batch classifier loss: 0.055587; batch adversarial loss: 0.365720\n",
      "epoch 56; iter: 0; batch classifier loss: 0.062187; batch adversarial loss: 0.451511\n",
      "epoch 57; iter: 0; batch classifier loss: 0.055445; batch adversarial loss: 0.449750\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103748; batch adversarial loss: 0.445707\n",
      "epoch 59; iter: 0; batch classifier loss: 0.065562; batch adversarial loss: 0.460595\n",
      "epoch 60; iter: 0; batch classifier loss: 0.073012; batch adversarial loss: 0.414022\n",
      "epoch 61; iter: 0; batch classifier loss: 0.069646; batch adversarial loss: 0.368055\n",
      "epoch 62; iter: 0; batch classifier loss: 0.117127; batch adversarial loss: 0.356158\n",
      "epoch 63; iter: 0; batch classifier loss: 0.067540; batch adversarial loss: 0.466066\n",
      "epoch 64; iter: 0; batch classifier loss: 0.113671; batch adversarial loss: 0.429325\n",
      "epoch 65; iter: 0; batch classifier loss: 0.071693; batch adversarial loss: 0.513411\n",
      "epoch 66; iter: 0; batch classifier loss: 0.071217; batch adversarial loss: 0.344665\n",
      "epoch 67; iter: 0; batch classifier loss: 0.063172; batch adversarial loss: 0.466787\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078528; batch adversarial loss: 0.301090\n",
      "epoch 69; iter: 0; batch classifier loss: 0.119643; batch adversarial loss: 0.505188\n",
      "epoch 70; iter: 0; batch classifier loss: 0.057927; batch adversarial loss: 0.417961\n",
      "epoch 71; iter: 0; batch classifier loss: 0.085803; batch adversarial loss: 0.446718\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085057; batch adversarial loss: 0.431325\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065123; batch adversarial loss: 0.435697\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082867; batch adversarial loss: 0.512857\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069718; batch adversarial loss: 0.433911\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063575; batch adversarial loss: 0.523553\n",
      "epoch 77; iter: 0; batch classifier loss: 0.046374; batch adversarial loss: 0.366817\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059695; batch adversarial loss: 0.431629\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060786; batch adversarial loss: 0.404864\n",
      "epoch 80; iter: 0; batch classifier loss: 0.049860; batch adversarial loss: 0.415934\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068438; batch adversarial loss: 0.496722\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066227; batch adversarial loss: 0.458097\n",
      "epoch 83; iter: 0; batch classifier loss: 0.040548; batch adversarial loss: 0.488770\n",
      "epoch 84; iter: 0; batch classifier loss: 0.043874; batch adversarial loss: 0.475710\n",
      "epoch 85; iter: 0; batch classifier loss: 0.030877; batch adversarial loss: 0.461238\n",
      "epoch 86; iter: 0; batch classifier loss: 0.047723; batch adversarial loss: 0.409539\n",
      "epoch 87; iter: 0; batch classifier loss: 0.052311; batch adversarial loss: 0.398324\n",
      "epoch 88; iter: 0; batch classifier loss: 0.024065; batch adversarial loss: 0.457056\n",
      "epoch 89; iter: 0; batch classifier loss: 0.024837; batch adversarial loss: 0.434414\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052934; batch adversarial loss: 0.433268\n",
      "epoch 91; iter: 0; batch classifier loss: 0.038279; batch adversarial loss: 0.553018\n",
      "epoch 92; iter: 0; batch classifier loss: 0.026433; batch adversarial loss: 0.476811\n",
      "epoch 93; iter: 0; batch classifier loss: 0.032303; batch adversarial loss: 0.489424\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053241; batch adversarial loss: 0.479388\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070859; batch adversarial loss: 0.336707\n",
      "epoch 96; iter: 0; batch classifier loss: 0.033148; batch adversarial loss: 0.457829\n",
      "epoch 97; iter: 0; batch classifier loss: 0.035256; batch adversarial loss: 0.528540\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056817; batch adversarial loss: 0.510732\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069923; batch adversarial loss: 0.507213\n",
      "epoch 100; iter: 0; batch classifier loss: 0.019155; batch adversarial loss: 0.408044\n",
      "epoch 101; iter: 0; batch classifier loss: 0.031924; batch adversarial loss: 0.450041\n",
      "epoch 102; iter: 0; batch classifier loss: 0.028550; batch adversarial loss: 0.389781\n",
      "epoch 103; iter: 0; batch classifier loss: 0.025937; batch adversarial loss: 0.408484\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038310; batch adversarial loss: 0.450246\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031491; batch adversarial loss: 0.458833\n",
      "epoch 106; iter: 0; batch classifier loss: 0.021312; batch adversarial loss: 0.541994\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034483; batch adversarial loss: 0.362768\n",
      "epoch 108; iter: 0; batch classifier loss: 0.034612; batch adversarial loss: 0.457884\n",
      "epoch 109; iter: 0; batch classifier loss: 0.020539; batch adversarial loss: 0.407705\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033575; batch adversarial loss: 0.386297\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030002; batch adversarial loss: 0.438650\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039999; batch adversarial loss: 0.443918\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021931; batch adversarial loss: 0.489230\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042250; batch adversarial loss: 0.442691\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041567; batch adversarial loss: 0.451112\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029251; batch adversarial loss: 0.506353\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026926; batch adversarial loss: 0.430264\n",
      "epoch 118; iter: 0; batch classifier loss: 0.015350; batch adversarial loss: 0.498482\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038068; batch adversarial loss: 0.399475\n",
      "epoch 120; iter: 0; batch classifier loss: 0.017457; batch adversarial loss: 0.424616\n",
      "epoch 121; iter: 0; batch classifier loss: 0.013254; batch adversarial loss: 0.431654\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021393; batch adversarial loss: 0.514201\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034262; batch adversarial loss: 0.405141\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038654; batch adversarial loss: 0.382518\n",
      "epoch 125; iter: 0; batch classifier loss: 0.014834; batch adversarial loss: 0.413131\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027122; batch adversarial loss: 0.448131\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022027; batch adversarial loss: 0.368553\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018816; batch adversarial loss: 0.402066\n",
      "epoch 129; iter: 0; batch classifier loss: 0.013170; batch adversarial loss: 0.419167\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029907; batch adversarial loss: 0.428843\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029031; batch adversarial loss: 0.448757\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032321; batch adversarial loss: 0.474252\n",
      "epoch 133; iter: 0; batch classifier loss: 0.009917; batch adversarial loss: 0.438116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.018272; batch adversarial loss: 0.437496\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013297; batch adversarial loss: 0.439860\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013008; batch adversarial loss: 0.452180\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028000; batch adversarial loss: 0.378376\n",
      "epoch 138; iter: 0; batch classifier loss: 0.015779; batch adversarial loss: 0.457015\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016061; batch adversarial loss: 0.415916\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023052; batch adversarial loss: 0.363401\n",
      "epoch 141; iter: 0; batch classifier loss: 0.007816; batch adversarial loss: 0.423502\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025599; batch adversarial loss: 0.372697\n",
      "epoch 143; iter: 0; batch classifier loss: 0.007528; batch adversarial loss: 0.426053\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012722; batch adversarial loss: 0.433128\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013803; batch adversarial loss: 0.434623\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027684; batch adversarial loss: 0.434574\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028845; batch adversarial loss: 0.502265\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021724; batch adversarial loss: 0.385092\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036605; batch adversarial loss: 0.489298\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022800; batch adversarial loss: 0.402430\n",
      "epoch 151; iter: 0; batch classifier loss: 0.054009; batch adversarial loss: 0.561352\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017214; batch adversarial loss: 0.449366\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014624; batch adversarial loss: 0.563159\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031335; batch adversarial loss: 0.472872\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016129; batch adversarial loss: 0.503093\n",
      "epoch 156; iter: 0; batch classifier loss: 0.008378; batch adversarial loss: 0.412488\n",
      "epoch 157; iter: 0; batch classifier loss: 0.049220; batch adversarial loss: 0.459326\n",
      "epoch 158; iter: 0; batch classifier loss: 0.004378; batch adversarial loss: 0.478912\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016042; batch adversarial loss: 0.462570\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021226; batch adversarial loss: 0.497211\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022881; batch adversarial loss: 0.511840\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015224; batch adversarial loss: 0.540594\n",
      "epoch 163; iter: 0; batch classifier loss: 0.005612; batch adversarial loss: 0.483696\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014179; batch adversarial loss: 0.372359\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008691; batch adversarial loss: 0.459122\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033729; batch adversarial loss: 0.494233\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012037; batch adversarial loss: 0.532588\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007547; batch adversarial loss: 0.477638\n",
      "epoch 169; iter: 0; batch classifier loss: 0.047338; batch adversarial loss: 0.673643\n",
      "epoch 170; iter: 0; batch classifier loss: 0.085342; batch adversarial loss: 0.575037\n",
      "epoch 171; iter: 0; batch classifier loss: 0.066556; batch adversarial loss: 0.605480\n",
      "epoch 172; iter: 0; batch classifier loss: 0.103925; batch adversarial loss: 0.690999\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042668; batch adversarial loss: 0.437309\n",
      "epoch 174; iter: 0; batch classifier loss: 0.097700; batch adversarial loss: 0.547550\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035791; batch adversarial loss: 0.527485\n",
      "epoch 176; iter: 0; batch classifier loss: 0.095523; batch adversarial loss: 0.533660\n",
      "epoch 177; iter: 0; batch classifier loss: 0.064469; batch adversarial loss: 0.450036\n",
      "epoch 178; iter: 0; batch classifier loss: 0.092052; batch adversarial loss: 0.632890\n",
      "epoch 179; iter: 0; batch classifier loss: 0.067193; batch adversarial loss: 0.622645\n",
      "epoch 180; iter: 0; batch classifier loss: 0.088715; batch adversarial loss: 0.620783\n",
      "epoch 181; iter: 0; batch classifier loss: 0.136284; batch adversarial loss: 0.669572\n",
      "epoch 182; iter: 0; batch classifier loss: 0.111101; batch adversarial loss: 0.688714\n",
      "epoch 183; iter: 0; batch classifier loss: 0.095091; batch adversarial loss: 0.525138\n",
      "epoch 184; iter: 0; batch classifier loss: 0.058527; batch adversarial loss: 0.518186\n",
      "epoch 185; iter: 0; batch classifier loss: 0.160854; batch adversarial loss: 0.651248\n",
      "epoch 186; iter: 0; batch classifier loss: 0.096489; batch adversarial loss: 0.544967\n",
      "epoch 187; iter: 0; batch classifier loss: 0.128397; batch adversarial loss: 0.636084\n",
      "epoch 188; iter: 0; batch classifier loss: 0.082449; batch adversarial loss: 0.586613\n",
      "epoch 189; iter: 0; batch classifier loss: 0.126656; batch adversarial loss: 0.675767\n",
      "epoch 190; iter: 0; batch classifier loss: 0.093329; batch adversarial loss: 0.474007\n",
      "epoch 191; iter: 0; batch classifier loss: 0.168914; batch adversarial loss: 0.618943\n",
      "epoch 192; iter: 0; batch classifier loss: 0.158182; batch adversarial loss: 0.697834\n",
      "epoch 193; iter: 0; batch classifier loss: 0.153122; batch adversarial loss: 0.606682\n",
      "epoch 194; iter: 0; batch classifier loss: 0.070886; batch adversarial loss: 0.528086\n",
      "epoch 195; iter: 0; batch classifier loss: 0.121607; batch adversarial loss: 0.573077\n",
      "epoch 196; iter: 0; batch classifier loss: 0.148536; batch adversarial loss: 0.555646\n",
      "epoch 197; iter: 0; batch classifier loss: 0.139867; batch adversarial loss: 0.648840\n",
      "epoch 198; iter: 0; batch classifier loss: 0.136530; batch adversarial loss: 0.562300\n",
      "epoch 199; iter: 0; batch classifier loss: 0.158909; batch adversarial loss: 0.567701\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683492; batch adversarial loss: 0.825480\n",
      "epoch 1; iter: 0; batch classifier loss: 0.481669; batch adversarial loss: 0.770595\n",
      "epoch 2; iter: 0; batch classifier loss: 0.400622; batch adversarial loss: 0.753656\n",
      "epoch 3; iter: 0; batch classifier loss: 0.359291; batch adversarial loss: 0.686405\n",
      "epoch 4; iter: 0; batch classifier loss: 0.309666; batch adversarial loss: 0.676742\n",
      "epoch 5; iter: 0; batch classifier loss: 0.316172; batch adversarial loss: 0.673472\n",
      "epoch 6; iter: 0; batch classifier loss: 0.319165; batch adversarial loss: 0.586462\n",
      "epoch 7; iter: 0; batch classifier loss: 0.241250; batch adversarial loss: 0.586748\n",
      "epoch 8; iter: 0; batch classifier loss: 0.303307; batch adversarial loss: 0.561890\n",
      "epoch 9; iter: 0; batch classifier loss: 0.314007; batch adversarial loss: 0.530955\n",
      "epoch 10; iter: 0; batch classifier loss: 0.273107; batch adversarial loss: 0.486971\n",
      "epoch 11; iter: 0; batch classifier loss: 0.237006; batch adversarial loss: 0.452476\n",
      "epoch 12; iter: 0; batch classifier loss: 0.235769; batch adversarial loss: 0.486915\n",
      "epoch 13; iter: 0; batch classifier loss: 0.198385; batch adversarial loss: 0.475851\n",
      "epoch 14; iter: 0; batch classifier loss: 0.208404; batch adversarial loss: 0.461495\n",
      "epoch 15; iter: 0; batch classifier loss: 0.191798; batch adversarial loss: 0.454077\n",
      "epoch 16; iter: 0; batch classifier loss: 0.152291; batch adversarial loss: 0.524287\n",
      "epoch 17; iter: 0; batch classifier loss: 0.168335; batch adversarial loss: 0.450299\n",
      "epoch 18; iter: 0; batch classifier loss: 0.148129; batch adversarial loss: 0.452845\n",
      "epoch 19; iter: 0; batch classifier loss: 0.144901; batch adversarial loss: 0.451746\n",
      "epoch 20; iter: 0; batch classifier loss: 0.136756; batch adversarial loss: 0.454144\n",
      "epoch 21; iter: 0; batch classifier loss: 0.117280; batch adversarial loss: 0.426141\n",
      "epoch 22; iter: 0; batch classifier loss: 0.093518; batch adversarial loss: 0.464753\n",
      "epoch 23; iter: 0; batch classifier loss: 0.138081; batch adversarial loss: 0.464104\n",
      "epoch 24; iter: 0; batch classifier loss: 0.158191; batch adversarial loss: 0.490367\n",
      "epoch 25; iter: 0; batch classifier loss: 0.123673; batch adversarial loss: 0.424319\n",
      "epoch 26; iter: 0; batch classifier loss: 0.122991; batch adversarial loss: 0.453996\n",
      "epoch 27; iter: 0; batch classifier loss: 0.146188; batch adversarial loss: 0.469869\n",
      "epoch 28; iter: 0; batch classifier loss: 0.097781; batch adversarial loss: 0.511219\n",
      "epoch 29; iter: 0; batch classifier loss: 0.104984; batch adversarial loss: 0.456715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.096392; batch adversarial loss: 0.493241\n",
      "epoch 31; iter: 0; batch classifier loss: 0.144288; batch adversarial loss: 0.556086\n",
      "epoch 32; iter: 0; batch classifier loss: 0.115553; batch adversarial loss: 0.462578\n",
      "epoch 33; iter: 0; batch classifier loss: 0.160150; batch adversarial loss: 0.640568\n",
      "epoch 34; iter: 0; batch classifier loss: 0.124436; batch adversarial loss: 0.414252\n",
      "epoch 35; iter: 0; batch classifier loss: 0.162086; batch adversarial loss: 0.587243\n",
      "epoch 36; iter: 0; batch classifier loss: 0.155772; batch adversarial loss: 0.444425\n",
      "epoch 37; iter: 0; batch classifier loss: 0.206061; batch adversarial loss: 0.594826\n",
      "epoch 38; iter: 0; batch classifier loss: 0.193268; batch adversarial loss: 0.655393\n",
      "epoch 39; iter: 0; batch classifier loss: 0.078567; batch adversarial loss: 0.376680\n",
      "epoch 40; iter: 0; batch classifier loss: 0.157841; batch adversarial loss: 0.499565\n",
      "epoch 41; iter: 0; batch classifier loss: 0.170857; batch adversarial loss: 0.520590\n",
      "epoch 42; iter: 0; batch classifier loss: 0.135140; batch adversarial loss: 0.464285\n",
      "epoch 43; iter: 0; batch classifier loss: 0.152815; batch adversarial loss: 0.454555\n",
      "epoch 44; iter: 0; batch classifier loss: 0.177778; batch adversarial loss: 0.509242\n",
      "epoch 45; iter: 0; batch classifier loss: 0.176942; batch adversarial loss: 0.549362\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117900; batch adversarial loss: 0.485033\n",
      "epoch 47; iter: 0; batch classifier loss: 0.137068; batch adversarial loss: 0.449526\n",
      "epoch 48; iter: 0; batch classifier loss: 0.167004; batch adversarial loss: 0.478272\n",
      "epoch 49; iter: 0; batch classifier loss: 0.137028; batch adversarial loss: 0.442062\n",
      "epoch 50; iter: 0; batch classifier loss: 0.150974; batch adversarial loss: 0.552958\n",
      "epoch 51; iter: 0; batch classifier loss: 0.148225; batch adversarial loss: 0.447896\n",
      "epoch 52; iter: 0; batch classifier loss: 0.066156; batch adversarial loss: 0.471243\n",
      "epoch 53; iter: 0; batch classifier loss: 0.045414; batch adversarial loss: 0.492076\n",
      "epoch 54; iter: 0; batch classifier loss: 0.057711; batch adversarial loss: 0.536796\n",
      "epoch 55; iter: 0; batch classifier loss: 0.042767; batch adversarial loss: 0.474775\n",
      "epoch 56; iter: 0; batch classifier loss: 0.071804; batch adversarial loss: 0.466855\n",
      "epoch 57; iter: 0; batch classifier loss: 0.053368; batch adversarial loss: 0.514737\n",
      "epoch 58; iter: 0; batch classifier loss: 0.099224; batch adversarial loss: 0.457499\n",
      "epoch 59; iter: 0; batch classifier loss: 0.065006; batch adversarial loss: 0.421998\n",
      "epoch 60; iter: 0; batch classifier loss: 0.117424; batch adversarial loss: 0.394832\n",
      "epoch 61; iter: 0; batch classifier loss: 0.081488; batch adversarial loss: 0.424855\n",
      "epoch 62; iter: 0; batch classifier loss: 0.113533; batch adversarial loss: 0.387511\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099816; batch adversarial loss: 0.432687\n",
      "epoch 64; iter: 0; batch classifier loss: 0.061236; batch adversarial loss: 0.387293\n",
      "epoch 65; iter: 0; batch classifier loss: 0.101017; batch adversarial loss: 0.435563\n",
      "epoch 66; iter: 0; batch classifier loss: 0.120050; batch adversarial loss: 0.484688\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107737; batch adversarial loss: 0.468384\n",
      "epoch 68; iter: 0; batch classifier loss: 0.097126; batch adversarial loss: 0.515259\n",
      "epoch 69; iter: 0; batch classifier loss: 0.110661; batch adversarial loss: 0.405356\n",
      "epoch 70; iter: 0; batch classifier loss: 0.085138; batch adversarial loss: 0.392216\n",
      "epoch 71; iter: 0; batch classifier loss: 0.075096; batch adversarial loss: 0.487215\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072471; batch adversarial loss: 0.409324\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101870; batch adversarial loss: 0.484327\n",
      "epoch 74; iter: 0; batch classifier loss: 0.105787; batch adversarial loss: 0.512205\n",
      "epoch 75; iter: 0; batch classifier loss: 0.038693; batch adversarial loss: 0.426236\n",
      "epoch 76; iter: 0; batch classifier loss: 0.115865; batch adversarial loss: 0.445691\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087015; batch adversarial loss: 0.460455\n",
      "epoch 78; iter: 0; batch classifier loss: 0.115153; batch adversarial loss: 0.459838\n",
      "epoch 79; iter: 0; batch classifier loss: 0.094746; batch adversarial loss: 0.399530\n",
      "epoch 80; iter: 0; batch classifier loss: 0.093968; batch adversarial loss: 0.499267\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066915; batch adversarial loss: 0.459056\n",
      "epoch 82; iter: 0; batch classifier loss: 0.093912; batch adversarial loss: 0.416014\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086800; batch adversarial loss: 0.475513\n",
      "epoch 84; iter: 0; batch classifier loss: 0.072038; batch adversarial loss: 0.444650\n",
      "epoch 85; iter: 0; batch classifier loss: 0.126723; batch adversarial loss: 0.383931\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065211; batch adversarial loss: 0.563142\n",
      "epoch 87; iter: 0; batch classifier loss: 0.123576; batch adversarial loss: 0.371719\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059838; batch adversarial loss: 0.425074\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060280; batch adversarial loss: 0.438768\n",
      "epoch 90; iter: 0; batch classifier loss: 0.096117; batch adversarial loss: 0.484353\n",
      "epoch 91; iter: 0; batch classifier loss: 0.096180; batch adversarial loss: 0.527322\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069682; batch adversarial loss: 0.438191\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078070; batch adversarial loss: 0.479317\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056451; batch adversarial loss: 0.435377\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070336; batch adversarial loss: 0.543365\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047507; batch adversarial loss: 0.451400\n",
      "epoch 97; iter: 0; batch classifier loss: 0.096085; batch adversarial loss: 0.433528\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074642; batch adversarial loss: 0.544667\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057325; batch adversarial loss: 0.427447\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034079; batch adversarial loss: 0.494255\n",
      "epoch 101; iter: 0; batch classifier loss: 0.076290; batch adversarial loss: 0.513404\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063505; batch adversarial loss: 0.455265\n",
      "epoch 103; iter: 0; batch classifier loss: 0.051616; batch adversarial loss: 0.494222\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035891; batch adversarial loss: 0.442111\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059768; batch adversarial loss: 0.515352\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050196; batch adversarial loss: 0.479716\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044622; batch adversarial loss: 0.470263\n",
      "epoch 108; iter: 0; batch classifier loss: 0.066450; batch adversarial loss: 0.415675\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058137; batch adversarial loss: 0.455221\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067145; batch adversarial loss: 0.438741\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055473; batch adversarial loss: 0.499843\n",
      "epoch 112; iter: 0; batch classifier loss: 0.079308; batch adversarial loss: 0.600642\n",
      "epoch 113; iter: 0; batch classifier loss: 0.107788; batch adversarial loss: 0.419067\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053047; batch adversarial loss: 0.539287\n",
      "epoch 115; iter: 0; batch classifier loss: 0.073271; batch adversarial loss: 0.525957\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032928; batch adversarial loss: 0.498421\n",
      "epoch 117; iter: 0; batch classifier loss: 0.022638; batch adversarial loss: 0.545417\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037180; batch adversarial loss: 0.443743\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056886; batch adversarial loss: 0.511814\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033514; batch adversarial loss: 0.481285\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037699; batch adversarial loss: 0.438431\n",
      "epoch 122; iter: 0; batch classifier loss: 0.022677; batch adversarial loss: 0.434007\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032688; batch adversarial loss: 0.484762\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037932; batch adversarial loss: 0.480521\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054104; batch adversarial loss: 0.402042\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021534; batch adversarial loss: 0.477661\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046996; batch adversarial loss: 0.581177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.033540; batch adversarial loss: 0.434904\n",
      "epoch 129; iter: 0; batch classifier loss: 0.053334; batch adversarial loss: 0.451323\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040256; batch adversarial loss: 0.417214\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051594; batch adversarial loss: 0.526086\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024244; batch adversarial loss: 0.434361\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028462; batch adversarial loss: 0.377768\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036847; batch adversarial loss: 0.487497\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033257; batch adversarial loss: 0.417596\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028842; batch adversarial loss: 0.527228\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044678; batch adversarial loss: 0.440903\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025109; batch adversarial loss: 0.508590\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037850; batch adversarial loss: 0.492027\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040482; batch adversarial loss: 0.431458\n",
      "epoch 141; iter: 0; batch classifier loss: 0.072795; batch adversarial loss: 0.503245\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014635; batch adversarial loss: 0.530418\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022867; batch adversarial loss: 0.463499\n",
      "epoch 144; iter: 0; batch classifier loss: 0.035065; batch adversarial loss: 0.527673\n",
      "epoch 145; iter: 0; batch classifier loss: 0.008937; batch adversarial loss: 0.483661\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030196; batch adversarial loss: 0.530859\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052081; batch adversarial loss: 0.480348\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045600; batch adversarial loss: 0.399099\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033747; batch adversarial loss: 0.443247\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021005; batch adversarial loss: 0.543233\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044661; batch adversarial loss: 0.436229\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021008; batch adversarial loss: 0.545878\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025916; batch adversarial loss: 0.513753\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043814; batch adversarial loss: 0.450419\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013221; batch adversarial loss: 0.479356\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022979; batch adversarial loss: 0.513155\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036870; batch adversarial loss: 0.436428\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048680; batch adversarial loss: 0.476861\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014686; batch adversarial loss: 0.523079\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014492; batch adversarial loss: 0.427861\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028859; batch adversarial loss: 0.389213\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022548; batch adversarial loss: 0.490841\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042835; batch adversarial loss: 0.368087\n",
      "epoch 164; iter: 0; batch classifier loss: 0.054125; batch adversarial loss: 0.502634\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030638; batch adversarial loss: 0.371985\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015925; batch adversarial loss: 0.443537\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012024; batch adversarial loss: 0.483430\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038300; batch adversarial loss: 0.406896\n",
      "epoch 169; iter: 0; batch classifier loss: 0.047541; batch adversarial loss: 0.526689\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009542; batch adversarial loss: 0.429788\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015112; batch adversarial loss: 0.366453\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012439; batch adversarial loss: 0.406105\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023806; batch adversarial loss: 0.434501\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020608; batch adversarial loss: 0.320773\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018958; batch adversarial loss: 0.494788\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032043; batch adversarial loss: 0.484753\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013640; batch adversarial loss: 0.549586\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007646; batch adversarial loss: 0.424763\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020761; batch adversarial loss: 0.495054\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029401; batch adversarial loss: 0.615808\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021284; batch adversarial loss: 0.456597\n",
      "epoch 182; iter: 0; batch classifier loss: 0.053641; batch adversarial loss: 0.494325\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024895; batch adversarial loss: 0.486806\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015253; batch adversarial loss: 0.474129\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012731; batch adversarial loss: 0.415620\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027958; batch adversarial loss: 0.497132\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019659; batch adversarial loss: 0.495123\n",
      "epoch 188; iter: 0; batch classifier loss: 0.039414; batch adversarial loss: 0.436230\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009848; batch adversarial loss: 0.494817\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021583; batch adversarial loss: 0.517690\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014473; batch adversarial loss: 0.590416\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030972; batch adversarial loss: 0.376857\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023283; batch adversarial loss: 0.407093\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010409; batch adversarial loss: 0.461499\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025404; batch adversarial loss: 0.569579\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011445; batch adversarial loss: 0.492292\n",
      "epoch 197; iter: 0; batch classifier loss: 0.041377; batch adversarial loss: 0.464807\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008107; batch adversarial loss: 0.446524\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027456; batch adversarial loss: 0.527379\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695314; batch adversarial loss: 0.684751\n",
      "epoch 1; iter: 0; batch classifier loss: 0.491432; batch adversarial loss: 0.660083\n",
      "epoch 2; iter: 0; batch classifier loss: 0.496688; batch adversarial loss: 0.644057\n",
      "epoch 3; iter: 0; batch classifier loss: 0.477577; batch adversarial loss: 0.616136\n",
      "epoch 4; iter: 0; batch classifier loss: 0.432610; batch adversarial loss: 0.596312\n",
      "epoch 5; iter: 0; batch classifier loss: 0.484592; batch adversarial loss: 0.584000\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535752; batch adversarial loss: 0.588980\n",
      "epoch 7; iter: 0; batch classifier loss: 0.473913; batch adversarial loss: 0.557609\n",
      "epoch 8; iter: 0; batch classifier loss: 0.368741; batch adversarial loss: 0.560721\n",
      "epoch 9; iter: 0; batch classifier loss: 0.322457; batch adversarial loss: 0.567440\n",
      "epoch 10; iter: 0; batch classifier loss: 0.339270; batch adversarial loss: 0.571284\n",
      "epoch 11; iter: 0; batch classifier loss: 0.394446; batch adversarial loss: 0.481046\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514267; batch adversarial loss: 0.507621\n",
      "epoch 13; iter: 0; batch classifier loss: 0.443187; batch adversarial loss: 0.503414\n",
      "epoch 14; iter: 0; batch classifier loss: 0.314309; batch adversarial loss: 0.480491\n",
      "epoch 15; iter: 0; batch classifier loss: 0.372910; batch adversarial loss: 0.488713\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281307; batch adversarial loss: 0.511449\n",
      "epoch 17; iter: 0; batch classifier loss: 0.304153; batch adversarial loss: 0.458689\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320596; batch adversarial loss: 0.472266\n",
      "epoch 19; iter: 0; batch classifier loss: 0.258645; batch adversarial loss: 0.427199\n",
      "epoch 20; iter: 0; batch classifier loss: 0.324057; batch adversarial loss: 0.483495\n",
      "epoch 21; iter: 0; batch classifier loss: 0.266586; batch adversarial loss: 0.459845\n",
      "epoch 22; iter: 0; batch classifier loss: 0.303601; batch adversarial loss: 0.453966\n",
      "epoch 23; iter: 0; batch classifier loss: 0.322025; batch adversarial loss: 0.406566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.219762; batch adversarial loss: 0.474852\n",
      "epoch 25; iter: 0; batch classifier loss: 0.382294; batch adversarial loss: 0.393377\n",
      "epoch 26; iter: 0; batch classifier loss: 0.218426; batch adversarial loss: 0.475343\n",
      "epoch 27; iter: 0; batch classifier loss: 0.217435; batch adversarial loss: 0.529452\n",
      "epoch 28; iter: 0; batch classifier loss: 0.291925; batch adversarial loss: 0.457260\n",
      "epoch 29; iter: 0; batch classifier loss: 0.295750; batch adversarial loss: 0.378751\n",
      "epoch 30; iter: 0; batch classifier loss: 0.323366; batch adversarial loss: 0.402771\n",
      "epoch 31; iter: 0; batch classifier loss: 0.269440; batch adversarial loss: 0.514571\n",
      "epoch 32; iter: 0; batch classifier loss: 0.200157; batch adversarial loss: 0.487623\n",
      "epoch 33; iter: 0; batch classifier loss: 0.301783; batch adversarial loss: 0.463431\n",
      "epoch 34; iter: 0; batch classifier loss: 0.183207; batch adversarial loss: 0.448414\n",
      "epoch 35; iter: 0; batch classifier loss: 0.288365; batch adversarial loss: 0.507208\n",
      "epoch 36; iter: 0; batch classifier loss: 0.283422; batch adversarial loss: 0.428450\n",
      "epoch 37; iter: 0; batch classifier loss: 0.246408; batch adversarial loss: 0.522871\n",
      "epoch 38; iter: 0; batch classifier loss: 0.196158; batch adversarial loss: 0.429200\n",
      "epoch 39; iter: 0; batch classifier loss: 0.264703; batch adversarial loss: 0.445111\n",
      "epoch 40; iter: 0; batch classifier loss: 0.255909; batch adversarial loss: 0.403229\n",
      "epoch 41; iter: 0; batch classifier loss: 0.229059; batch adversarial loss: 0.472512\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235455; batch adversarial loss: 0.368947\n",
      "epoch 43; iter: 0; batch classifier loss: 0.189355; batch adversarial loss: 0.379256\n",
      "epoch 44; iter: 0; batch classifier loss: 0.267009; batch adversarial loss: 0.425181\n",
      "epoch 45; iter: 0; batch classifier loss: 0.240421; batch adversarial loss: 0.471304\n",
      "epoch 46; iter: 0; batch classifier loss: 0.331293; batch adversarial loss: 0.401419\n",
      "epoch 47; iter: 0; batch classifier loss: 0.222691; batch adversarial loss: 0.353886\n",
      "epoch 48; iter: 0; batch classifier loss: 0.306000; batch adversarial loss: 0.400510\n",
      "epoch 49; iter: 0; batch classifier loss: 0.160740; batch adversarial loss: 0.447996\n",
      "epoch 50; iter: 0; batch classifier loss: 0.160167; batch adversarial loss: 0.398407\n",
      "epoch 51; iter: 0; batch classifier loss: 0.182848; batch adversarial loss: 0.433502\n",
      "epoch 52; iter: 0; batch classifier loss: 0.234609; batch adversarial loss: 0.436189\n",
      "epoch 53; iter: 0; batch classifier loss: 0.162526; batch adversarial loss: 0.458270\n",
      "epoch 54; iter: 0; batch classifier loss: 0.168532; batch adversarial loss: 0.434801\n",
      "epoch 55; iter: 0; batch classifier loss: 0.243615; batch adversarial loss: 0.495342\n",
      "epoch 56; iter: 0; batch classifier loss: 0.129618; batch adversarial loss: 0.482976\n",
      "epoch 57; iter: 0; batch classifier loss: 0.144594; batch adversarial loss: 0.386749\n",
      "epoch 58; iter: 0; batch classifier loss: 0.173367; batch adversarial loss: 0.434295\n",
      "epoch 59; iter: 0; batch classifier loss: 0.203187; batch adversarial loss: 0.448075\n",
      "epoch 60; iter: 0; batch classifier loss: 0.151348; batch adversarial loss: 0.445688\n",
      "epoch 61; iter: 0; batch classifier loss: 0.196743; batch adversarial loss: 0.361417\n",
      "epoch 62; iter: 0; batch classifier loss: 0.262854; batch adversarial loss: 0.533962\n",
      "epoch 63; iter: 0; batch classifier loss: 0.179875; batch adversarial loss: 0.386285\n",
      "epoch 64; iter: 0; batch classifier loss: 0.202363; batch adversarial loss: 0.421825\n",
      "epoch 65; iter: 0; batch classifier loss: 0.227791; batch adversarial loss: 0.507608\n",
      "epoch 66; iter: 0; batch classifier loss: 0.183779; batch adversarial loss: 0.506948\n",
      "epoch 67; iter: 0; batch classifier loss: 0.185603; batch adversarial loss: 0.495040\n",
      "epoch 68; iter: 0; batch classifier loss: 0.251262; batch adversarial loss: 0.519484\n",
      "epoch 69; iter: 0; batch classifier loss: 0.115761; batch adversarial loss: 0.383546\n",
      "epoch 70; iter: 0; batch classifier loss: 0.051946; batch adversarial loss: 0.433403\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069771; batch adversarial loss: 0.466730\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064791; batch adversarial loss: 0.406269\n",
      "epoch 73; iter: 0; batch classifier loss: 0.053699; batch adversarial loss: 0.485085\n",
      "epoch 74; iter: 0; batch classifier loss: 0.083044; batch adversarial loss: 0.392287\n",
      "epoch 75; iter: 0; batch classifier loss: 0.058034; batch adversarial loss: 0.434249\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082929; batch adversarial loss: 0.424068\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069440; batch adversarial loss: 0.417647\n",
      "epoch 78; iter: 0; batch classifier loss: 0.102693; batch adversarial loss: 0.371361\n",
      "epoch 79; iter: 0; batch classifier loss: 0.120483; batch adversarial loss: 0.485261\n",
      "epoch 80; iter: 0; batch classifier loss: 0.107490; batch adversarial loss: 0.522136\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074916; batch adversarial loss: 0.505175\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076852; batch adversarial loss: 0.517291\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094434; batch adversarial loss: 0.531513\n",
      "epoch 84; iter: 0; batch classifier loss: 0.097961; batch adversarial loss: 0.391217\n",
      "epoch 85; iter: 0; batch classifier loss: 0.103747; batch adversarial loss: 0.484493\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064167; batch adversarial loss: 0.402101\n",
      "epoch 87; iter: 0; batch classifier loss: 0.051847; batch adversarial loss: 0.518494\n",
      "epoch 88; iter: 0; batch classifier loss: 0.047185; batch adversarial loss: 0.389974\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059569; batch adversarial loss: 0.447865\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060454; batch adversarial loss: 0.413656\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043513; batch adversarial loss: 0.484036\n",
      "epoch 92; iter: 0; batch classifier loss: 0.020337; batch adversarial loss: 0.516681\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055974; batch adversarial loss: 0.401203\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051091; batch adversarial loss: 0.389224\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087507; batch adversarial loss: 0.436296\n",
      "epoch 96; iter: 0; batch classifier loss: 0.031233; batch adversarial loss: 0.396651\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037240; batch adversarial loss: 0.492499\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055382; batch adversarial loss: 0.504146\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043703; batch adversarial loss: 0.459410\n",
      "epoch 100; iter: 0; batch classifier loss: 0.063565; batch adversarial loss: 0.385385\n",
      "epoch 101; iter: 0; batch classifier loss: 0.031707; batch adversarial loss: 0.536511\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053619; batch adversarial loss: 0.417099\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053077; batch adversarial loss: 0.552595\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039236; batch adversarial loss: 0.367657\n",
      "epoch 105; iter: 0; batch classifier loss: 0.022690; batch adversarial loss: 0.555328\n",
      "epoch 106; iter: 0; batch classifier loss: 0.065034; batch adversarial loss: 0.406729\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038116; batch adversarial loss: 0.354824\n",
      "epoch 108; iter: 0; batch classifier loss: 0.074783; batch adversarial loss: 0.516534\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062865; batch adversarial loss: 0.498844\n",
      "epoch 110; iter: 0; batch classifier loss: 0.020856; batch adversarial loss: 0.431903\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054195; batch adversarial loss: 0.365616\n",
      "epoch 112; iter: 0; batch classifier loss: 0.018440; batch adversarial loss: 0.396936\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052977; batch adversarial loss: 0.427744\n",
      "epoch 114; iter: 0; batch classifier loss: 0.024426; batch adversarial loss: 0.402242\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038801; batch adversarial loss: 0.433171\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021180; batch adversarial loss: 0.535088\n",
      "epoch 117; iter: 0; batch classifier loss: 0.021548; batch adversarial loss: 0.415661\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026475; batch adversarial loss: 0.411876\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037397; batch adversarial loss: 0.453834\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041269; batch adversarial loss: 0.365531\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060325; batch adversarial loss: 0.434244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.017267; batch adversarial loss: 0.409585\n",
      "epoch 123; iter: 0; batch classifier loss: 0.015353; batch adversarial loss: 0.491925\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039711; batch adversarial loss: 0.455121\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034183; batch adversarial loss: 0.493860\n",
      "epoch 126; iter: 0; batch classifier loss: 0.061322; batch adversarial loss: 0.389947\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025716; batch adversarial loss: 0.413913\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019410; batch adversarial loss: 0.521801\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035538; batch adversarial loss: 0.454824\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027405; batch adversarial loss: 0.459758\n",
      "epoch 131; iter: 0; batch classifier loss: 0.012730; batch adversarial loss: 0.455545\n",
      "epoch 132; iter: 0; batch classifier loss: 0.011895; batch adversarial loss: 0.542100\n",
      "epoch 133; iter: 0; batch classifier loss: 0.050391; batch adversarial loss: 0.533336\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021919; batch adversarial loss: 0.325598\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013698; batch adversarial loss: 0.438590\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023320; batch adversarial loss: 0.441987\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049228; batch adversarial loss: 0.435404\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011818; batch adversarial loss: 0.540298\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009159; batch adversarial loss: 0.427136\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019960; batch adversarial loss: 0.389790\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034686; batch adversarial loss: 0.419134\n",
      "epoch 142; iter: 0; batch classifier loss: 0.011822; batch adversarial loss: 0.447261\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033576; batch adversarial loss: 0.402063\n",
      "epoch 144; iter: 0; batch classifier loss: 0.007887; batch adversarial loss: 0.429221\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026753; batch adversarial loss: 0.478870\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010648; batch adversarial loss: 0.541492\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021511; batch adversarial loss: 0.505963\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024961; batch adversarial loss: 0.507019\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011131; batch adversarial loss: 0.468694\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015836; batch adversarial loss: 0.396816\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030338; batch adversarial loss: 0.510175\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019119; batch adversarial loss: 0.383754\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017309; batch adversarial loss: 0.420126\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020726; batch adversarial loss: 0.581617\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017985; batch adversarial loss: 0.460219\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017426; batch adversarial loss: 0.548315\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024314; batch adversarial loss: 0.500141\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037555; batch adversarial loss: 0.454754\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033308; batch adversarial loss: 0.410445\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007362; batch adversarial loss: 0.501434\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020602; batch adversarial loss: 0.458344\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015808; batch adversarial loss: 0.530437\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010320; batch adversarial loss: 0.422899\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020249; batch adversarial loss: 0.423206\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016406; batch adversarial loss: 0.404786\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033248; batch adversarial loss: 0.467179\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006260; batch adversarial loss: 0.444516\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005212; batch adversarial loss: 0.420725\n",
      "epoch 169; iter: 0; batch classifier loss: 0.005358; batch adversarial loss: 0.459404\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017761; batch adversarial loss: 0.494970\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010633; batch adversarial loss: 0.554866\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005366; batch adversarial loss: 0.442353\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028328; batch adversarial loss: 0.441122\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016588; batch adversarial loss: 0.402895\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010049; batch adversarial loss: 0.435625\n",
      "epoch 176; iter: 0; batch classifier loss: 0.002516; batch adversarial loss: 0.438021\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034088; batch adversarial loss: 0.512943\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013506; batch adversarial loss: 0.529170\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031266; batch adversarial loss: 0.385476\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028771; batch adversarial loss: 0.452681\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026200; batch adversarial loss: 0.532328\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021647; batch adversarial loss: 0.413065\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033667; batch adversarial loss: 0.451586\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013043; batch adversarial loss: 0.448325\n",
      "epoch 185; iter: 0; batch classifier loss: 0.004032; batch adversarial loss: 0.502019\n",
      "epoch 186; iter: 0; batch classifier loss: 0.048916; batch adversarial loss: 0.433786\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013191; batch adversarial loss: 0.370450\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008212; batch adversarial loss: 0.448744\n",
      "epoch 189; iter: 0; batch classifier loss: 0.048469; batch adversarial loss: 0.501180\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016550; batch adversarial loss: 0.471571\n",
      "epoch 191; iter: 0; batch classifier loss: 0.045540; batch adversarial loss: 0.436419\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011843; batch adversarial loss: 0.372019\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009817; batch adversarial loss: 0.460500\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005193; batch adversarial loss: 0.470813\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021957; batch adversarial loss: 0.433786\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009906; batch adversarial loss: 0.376536\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012607; batch adversarial loss: 0.379229\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012010; batch adversarial loss: 0.496037\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028814; batch adversarial loss: 0.433012\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693290; batch adversarial loss: 0.728389\n",
      "epoch 1; iter: 0; batch classifier loss: 0.479943; batch adversarial loss: 0.680656\n",
      "epoch 2; iter: 0; batch classifier loss: 0.407383; batch adversarial loss: 0.639495\n",
      "epoch 3; iter: 0; batch classifier loss: 0.341677; batch adversarial loss: 0.633083\n",
      "epoch 4; iter: 0; batch classifier loss: 0.384044; batch adversarial loss: 0.614329\n",
      "epoch 5; iter: 0; batch classifier loss: 0.388588; batch adversarial loss: 0.576872\n",
      "epoch 6; iter: 0; batch classifier loss: 0.342529; batch adversarial loss: 0.598349\n",
      "epoch 7; iter: 0; batch classifier loss: 0.389584; batch adversarial loss: 0.582136\n",
      "epoch 8; iter: 0; batch classifier loss: 0.479132; batch adversarial loss: 0.541157\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531123; batch adversarial loss: 0.561528\n",
      "epoch 10; iter: 0; batch classifier loss: 0.380727; batch adversarial loss: 0.515807\n",
      "epoch 11; iter: 0; batch classifier loss: 0.484952; batch adversarial loss: 0.511351\n",
      "epoch 12; iter: 0; batch classifier loss: 0.357606; batch adversarial loss: 0.557424\n",
      "epoch 13; iter: 0; batch classifier loss: 0.339532; batch adversarial loss: 0.553919\n",
      "epoch 14; iter: 0; batch classifier loss: 0.409759; batch adversarial loss: 0.536260\n",
      "epoch 15; iter: 0; batch classifier loss: 0.408661; batch adversarial loss: 0.539004\n",
      "epoch 16; iter: 0; batch classifier loss: 0.395188; batch adversarial loss: 0.515161\n",
      "epoch 17; iter: 0; batch classifier loss: 0.316652; batch adversarial loss: 0.457255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.322316; batch adversarial loss: 0.549838\n",
      "epoch 19; iter: 0; batch classifier loss: 0.364525; batch adversarial loss: 0.462595\n",
      "epoch 20; iter: 0; batch classifier loss: 0.321816; batch adversarial loss: 0.484096\n",
      "epoch 21; iter: 0; batch classifier loss: 0.323965; batch adversarial loss: 0.472896\n",
      "epoch 22; iter: 0; batch classifier loss: 0.311757; batch adversarial loss: 0.484507\n",
      "epoch 23; iter: 0; batch classifier loss: 0.269080; batch adversarial loss: 0.501022\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213640; batch adversarial loss: 0.458443\n",
      "epoch 25; iter: 0; batch classifier loss: 0.303774; batch adversarial loss: 0.422711\n",
      "epoch 26; iter: 0; batch classifier loss: 0.258809; batch adversarial loss: 0.503878\n",
      "epoch 27; iter: 0; batch classifier loss: 0.242323; batch adversarial loss: 0.475843\n",
      "epoch 28; iter: 0; batch classifier loss: 0.215543; batch adversarial loss: 0.534581\n",
      "epoch 29; iter: 0; batch classifier loss: 0.283994; batch adversarial loss: 0.482251\n",
      "epoch 30; iter: 0; batch classifier loss: 0.216256; batch adversarial loss: 0.423129\n",
      "epoch 31; iter: 0; batch classifier loss: 0.222855; batch adversarial loss: 0.446942\n",
      "epoch 32; iter: 0; batch classifier loss: 0.271749; batch adversarial loss: 0.372712\n",
      "epoch 33; iter: 0; batch classifier loss: 0.191397; batch adversarial loss: 0.598516\n",
      "epoch 34; iter: 0; batch classifier loss: 0.191875; batch adversarial loss: 0.537181\n",
      "epoch 35; iter: 0; batch classifier loss: 0.201487; batch adversarial loss: 0.455775\n",
      "epoch 36; iter: 0; batch classifier loss: 0.172913; batch adversarial loss: 0.473758\n",
      "epoch 37; iter: 0; batch classifier loss: 0.264432; batch adversarial loss: 0.503507\n",
      "epoch 38; iter: 0; batch classifier loss: 0.204204; batch adversarial loss: 0.453413\n",
      "epoch 39; iter: 0; batch classifier loss: 0.204454; batch adversarial loss: 0.385819\n",
      "epoch 40; iter: 0; batch classifier loss: 0.280117; batch adversarial loss: 0.516643\n",
      "epoch 41; iter: 0; batch classifier loss: 0.239960; batch adversarial loss: 0.469527\n",
      "epoch 42; iter: 0; batch classifier loss: 0.230808; batch adversarial loss: 0.459219\n",
      "epoch 43; iter: 0; batch classifier loss: 0.201745; batch adversarial loss: 0.425966\n",
      "epoch 44; iter: 0; batch classifier loss: 0.231797; batch adversarial loss: 0.450234\n",
      "epoch 45; iter: 0; batch classifier loss: 0.227234; batch adversarial loss: 0.460577\n",
      "epoch 46; iter: 0; batch classifier loss: 0.184380; batch adversarial loss: 0.460381\n",
      "epoch 47; iter: 0; batch classifier loss: 0.207927; batch adversarial loss: 0.563317\n",
      "epoch 48; iter: 0; batch classifier loss: 0.175643; batch adversarial loss: 0.447889\n",
      "epoch 49; iter: 0; batch classifier loss: 0.193519; batch adversarial loss: 0.459979\n",
      "epoch 50; iter: 0; batch classifier loss: 0.207627; batch adversarial loss: 0.412395\n",
      "epoch 51; iter: 0; batch classifier loss: 0.228255; batch adversarial loss: 0.482186\n",
      "epoch 52; iter: 0; batch classifier loss: 0.227625; batch adversarial loss: 0.506141\n",
      "epoch 53; iter: 0; batch classifier loss: 0.115051; batch adversarial loss: 0.494218\n",
      "epoch 54; iter: 0; batch classifier loss: 0.195107; batch adversarial loss: 0.496115\n",
      "epoch 55; iter: 0; batch classifier loss: 0.280602; batch adversarial loss: 0.482061\n",
      "epoch 56; iter: 0; batch classifier loss: 0.164326; batch adversarial loss: 0.495084\n",
      "epoch 57; iter: 0; batch classifier loss: 0.127010; batch adversarial loss: 0.471156\n",
      "epoch 58; iter: 0; batch classifier loss: 0.247250; batch adversarial loss: 0.448015\n",
      "epoch 59; iter: 0; batch classifier loss: 0.164810; batch adversarial loss: 0.506787\n",
      "epoch 60; iter: 0; batch classifier loss: 0.158417; batch adversarial loss: 0.410686\n",
      "epoch 61; iter: 0; batch classifier loss: 0.248457; batch adversarial loss: 0.411038\n",
      "epoch 62; iter: 0; batch classifier loss: 0.203641; batch adversarial loss: 0.411598\n",
      "epoch 63; iter: 0; batch classifier loss: 0.156021; batch adversarial loss: 0.517949\n",
      "epoch 64; iter: 0; batch classifier loss: 0.160681; batch adversarial loss: 0.495603\n",
      "epoch 65; iter: 0; batch classifier loss: 0.234037; batch adversarial loss: 0.470899\n",
      "epoch 66; iter: 0; batch classifier loss: 0.115024; batch adversarial loss: 0.459491\n",
      "epoch 67; iter: 0; batch classifier loss: 0.156259; batch adversarial loss: 0.481017\n",
      "epoch 68; iter: 0; batch classifier loss: 0.322592; batch adversarial loss: 0.446628\n",
      "epoch 69; iter: 0; batch classifier loss: 0.155857; batch adversarial loss: 0.446791\n",
      "epoch 70; iter: 0; batch classifier loss: 0.171322; batch adversarial loss: 0.518592\n",
      "epoch 71; iter: 0; batch classifier loss: 0.261011; batch adversarial loss: 0.507252\n",
      "epoch 72; iter: 0; batch classifier loss: 0.113711; batch adversarial loss: 0.434061\n",
      "epoch 73; iter: 0; batch classifier loss: 0.115528; batch adversarial loss: 0.459009\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053842; batch adversarial loss: 0.490002\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059742; batch adversarial loss: 0.398523\n",
      "epoch 76; iter: 0; batch classifier loss: 0.102483; batch adversarial loss: 0.526001\n",
      "epoch 77; iter: 0; batch classifier loss: 0.100528; batch adversarial loss: 0.506212\n",
      "epoch 78; iter: 0; batch classifier loss: 0.154170; batch adversarial loss: 0.474620\n",
      "epoch 79; iter: 0; batch classifier loss: 0.116734; batch adversarial loss: 0.470434\n",
      "epoch 80; iter: 0; batch classifier loss: 0.140080; batch adversarial loss: 0.456244\n",
      "epoch 81; iter: 0; batch classifier loss: 0.082187; batch adversarial loss: 0.419551\n",
      "epoch 82; iter: 0; batch classifier loss: 0.101116; batch adversarial loss: 0.417365\n",
      "epoch 83; iter: 0; batch classifier loss: 0.100422; batch adversarial loss: 0.520852\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067354; batch adversarial loss: 0.535803\n",
      "epoch 85; iter: 0; batch classifier loss: 0.111259; batch adversarial loss: 0.454513\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073043; batch adversarial loss: 0.401669\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054924; batch adversarial loss: 0.501079\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062650; batch adversarial loss: 0.436188\n",
      "epoch 89; iter: 0; batch classifier loss: 0.097422; batch adversarial loss: 0.430595\n",
      "epoch 90; iter: 0; batch classifier loss: 0.074884; batch adversarial loss: 0.517911\n",
      "epoch 91; iter: 0; batch classifier loss: 0.084905; batch adversarial loss: 0.414508\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060503; batch adversarial loss: 0.467220\n",
      "epoch 93; iter: 0; batch classifier loss: 0.040888; batch adversarial loss: 0.534997\n",
      "epoch 94; iter: 0; batch classifier loss: 0.063769; batch adversarial loss: 0.404454\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064301; batch adversarial loss: 0.419717\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051280; batch adversarial loss: 0.504777\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066615; batch adversarial loss: 0.608929\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048167; batch adversarial loss: 0.424424\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050927; batch adversarial loss: 0.426965\n",
      "epoch 100; iter: 0; batch classifier loss: 0.069538; batch adversarial loss: 0.547046\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037640; batch adversarial loss: 0.408053\n",
      "epoch 102; iter: 0; batch classifier loss: 0.061206; batch adversarial loss: 0.482203\n",
      "epoch 103; iter: 0; batch classifier loss: 0.023750; batch adversarial loss: 0.481949\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083541; batch adversarial loss: 0.464191\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061870; batch adversarial loss: 0.450623\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035326; batch adversarial loss: 0.450598\n",
      "epoch 107; iter: 0; batch classifier loss: 0.029482; batch adversarial loss: 0.534367\n",
      "epoch 108; iter: 0; batch classifier loss: 0.025553; batch adversarial loss: 0.558653\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040848; batch adversarial loss: 0.554221\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041744; batch adversarial loss: 0.425309\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034844; batch adversarial loss: 0.431035\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036129; batch adversarial loss: 0.445241\n",
      "epoch 113; iter: 0; batch classifier loss: 0.032249; batch adversarial loss: 0.433634\n",
      "epoch 114; iter: 0; batch classifier loss: 0.022847; batch adversarial loss: 0.525218\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046814; batch adversarial loss: 0.419074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.036602; batch adversarial loss: 0.388795\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037248; batch adversarial loss: 0.493994\n",
      "epoch 118; iter: 0; batch classifier loss: 0.018493; batch adversarial loss: 0.432476\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031155; batch adversarial loss: 0.434839\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024357; batch adversarial loss: 0.471276\n",
      "epoch 121; iter: 0; batch classifier loss: 0.019232; batch adversarial loss: 0.596761\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029338; batch adversarial loss: 0.385596\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036467; batch adversarial loss: 0.418798\n",
      "epoch 124; iter: 0; batch classifier loss: 0.034878; batch adversarial loss: 0.509722\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039249; batch adversarial loss: 0.563167\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033327; batch adversarial loss: 0.513641\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039035; batch adversarial loss: 0.479951\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017622; batch adversarial loss: 0.457330\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022487; batch adversarial loss: 0.536758\n",
      "epoch 130; iter: 0; batch classifier loss: 0.010667; batch adversarial loss: 0.422861\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021594; batch adversarial loss: 0.624983\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023844; batch adversarial loss: 0.440223\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015586; batch adversarial loss: 0.497446\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016292; batch adversarial loss: 0.523558\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032459; batch adversarial loss: 0.460348\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017413; batch adversarial loss: 0.472178\n",
      "epoch 137; iter: 0; batch classifier loss: 0.061108; batch adversarial loss: 0.384972\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041089; batch adversarial loss: 0.550925\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018818; batch adversarial loss: 0.507203\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030256; batch adversarial loss: 0.389634\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046377; batch adversarial loss: 0.438768\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013724; batch adversarial loss: 0.372557\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021896; batch adversarial loss: 0.339856\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026085; batch adversarial loss: 0.443951\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016712; batch adversarial loss: 0.401382\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031795; batch adversarial loss: 0.533908\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023170; batch adversarial loss: 0.437425\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012676; batch adversarial loss: 0.498370\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011579; batch adversarial loss: 0.453570\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021879; batch adversarial loss: 0.570291\n",
      "epoch 151; iter: 0; batch classifier loss: 0.057334; batch adversarial loss: 0.472858\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027831; batch adversarial loss: 0.472963\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010127; batch adversarial loss: 0.440373\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017160; batch adversarial loss: 0.367749\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013879; batch adversarial loss: 0.448368\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023494; batch adversarial loss: 0.535254\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041115; batch adversarial loss: 0.457400\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014056; batch adversarial loss: 0.558807\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012813; batch adversarial loss: 0.478846\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010892; batch adversarial loss: 0.488204\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013958; batch adversarial loss: 0.392540\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011883; batch adversarial loss: 0.422830\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014586; batch adversarial loss: 0.512781\n",
      "epoch 164; iter: 0; batch classifier loss: 0.007495; batch adversarial loss: 0.348543\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013792; batch adversarial loss: 0.530373\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009515; batch adversarial loss: 0.403530\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030555; batch adversarial loss: 0.417271\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028656; batch adversarial loss: 0.482204\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023586; batch adversarial loss: 0.372780\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018636; batch adversarial loss: 0.485974\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034781; batch adversarial loss: 0.428771\n",
      "epoch 172; iter: 0; batch classifier loss: 0.004766; batch adversarial loss: 0.430260\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036489; batch adversarial loss: 0.366252\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016897; batch adversarial loss: 0.461346\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027380; batch adversarial loss: 0.368555\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021052; batch adversarial loss: 0.429804\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025770; batch adversarial loss: 0.449776\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013278; batch adversarial loss: 0.439984\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022706; batch adversarial loss: 0.313463\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006654; batch adversarial loss: 0.378081\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013467; batch adversarial loss: 0.419118\n",
      "epoch 182; iter: 0; batch classifier loss: 0.005119; batch adversarial loss: 0.525654\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017734; batch adversarial loss: 0.442495\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022180; batch adversarial loss: 0.463287\n",
      "epoch 185; iter: 0; batch classifier loss: 0.004754; batch adversarial loss: 0.459440\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027052; batch adversarial loss: 0.362346\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011228; batch adversarial loss: 0.513797\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013501; batch adversarial loss: 0.396661\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014741; batch adversarial loss: 0.417988\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015476; batch adversarial loss: 0.488824\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013312; batch adversarial loss: 0.445501\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010927; batch adversarial loss: 0.397127\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011505; batch adversarial loss: 0.409627\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011747; batch adversarial loss: 0.517084\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031009; batch adversarial loss: 0.541696\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014622; batch adversarial loss: 0.468682\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013330; batch adversarial loss: 0.586161\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020435; batch adversarial loss: 0.419317\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009295; batch adversarial loss: 0.530454\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691658; batch adversarial loss: 0.599862\n",
      "epoch 1; iter: 0; batch classifier loss: 0.435465; batch adversarial loss: 0.620639\n",
      "epoch 2; iter: 0; batch classifier loss: 0.277968; batch adversarial loss: 0.569435\n",
      "epoch 3; iter: 0; batch classifier loss: 0.301044; batch adversarial loss: 0.557719\n",
      "epoch 4; iter: 0; batch classifier loss: 0.297593; batch adversarial loss: 0.552983\n",
      "epoch 5; iter: 0; batch classifier loss: 0.268910; batch adversarial loss: 0.532001\n",
      "epoch 6; iter: 0; batch classifier loss: 0.303356; batch adversarial loss: 0.522994\n",
      "epoch 7; iter: 0; batch classifier loss: 0.262642; batch adversarial loss: 0.556223\n",
      "epoch 8; iter: 0; batch classifier loss: 0.211542; batch adversarial loss: 0.523685\n",
      "epoch 9; iter: 0; batch classifier loss: 0.240287; batch adversarial loss: 0.488412\n",
      "epoch 10; iter: 0; batch classifier loss: 0.220762; batch adversarial loss: 0.588334\n",
      "epoch 11; iter: 0; batch classifier loss: 0.201689; batch adversarial loss: 0.530151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.277634; batch adversarial loss: 0.405133\n",
      "epoch 13; iter: 0; batch classifier loss: 0.240182; batch adversarial loss: 0.503828\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245740; batch adversarial loss: 0.554251\n",
      "epoch 15; iter: 0; batch classifier loss: 0.237420; batch adversarial loss: 0.542578\n",
      "epoch 16; iter: 0; batch classifier loss: 0.259105; batch adversarial loss: 0.549840\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349876; batch adversarial loss: 0.512103\n",
      "epoch 18; iter: 0; batch classifier loss: 0.397713; batch adversarial loss: 0.557682\n",
      "epoch 19; iter: 0; batch classifier loss: 0.475582; batch adversarial loss: 0.523925\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463810; batch adversarial loss: 0.470119\n",
      "epoch 21; iter: 0; batch classifier loss: 0.178051; batch adversarial loss: 0.487836\n",
      "epoch 22; iter: 0; batch classifier loss: 0.158577; batch adversarial loss: 0.449854\n",
      "epoch 23; iter: 0; batch classifier loss: 0.154439; batch adversarial loss: 0.492798\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168530; batch adversarial loss: 0.524162\n",
      "epoch 25; iter: 0; batch classifier loss: 0.146114; batch adversarial loss: 0.513663\n",
      "epoch 26; iter: 0; batch classifier loss: 0.195625; batch adversarial loss: 0.431925\n",
      "epoch 27; iter: 0; batch classifier loss: 0.145950; batch adversarial loss: 0.482655\n",
      "epoch 28; iter: 0; batch classifier loss: 0.177004; batch adversarial loss: 0.523202\n",
      "epoch 29; iter: 0; batch classifier loss: 0.187130; batch adversarial loss: 0.380067\n",
      "epoch 30; iter: 0; batch classifier loss: 0.126278; batch adversarial loss: 0.478220\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178557; batch adversarial loss: 0.457665\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140144; batch adversarial loss: 0.402744\n",
      "epoch 33; iter: 0; batch classifier loss: 0.154226; batch adversarial loss: 0.540391\n",
      "epoch 34; iter: 0; batch classifier loss: 0.120821; batch adversarial loss: 0.444678\n",
      "epoch 35; iter: 0; batch classifier loss: 0.202416; batch adversarial loss: 0.453536\n",
      "epoch 36; iter: 0; batch classifier loss: 0.075445; batch adversarial loss: 0.487470\n",
      "epoch 37; iter: 0; batch classifier loss: 0.065232; batch adversarial loss: 0.558144\n",
      "epoch 38; iter: 0; batch classifier loss: 0.083780; batch adversarial loss: 0.433022\n",
      "epoch 39; iter: 0; batch classifier loss: 0.152127; batch adversarial loss: 0.424187\n",
      "epoch 40; iter: 0; batch classifier loss: 0.115278; batch adversarial loss: 0.438695\n",
      "epoch 41; iter: 0; batch classifier loss: 0.114389; batch adversarial loss: 0.491946\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102179; batch adversarial loss: 0.416459\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110965; batch adversarial loss: 0.374697\n",
      "epoch 44; iter: 0; batch classifier loss: 0.102772; batch adversarial loss: 0.500669\n",
      "epoch 45; iter: 0; batch classifier loss: 0.095208; batch adversarial loss: 0.481954\n",
      "epoch 46; iter: 0; batch classifier loss: 0.090430; batch adversarial loss: 0.481926\n",
      "epoch 47; iter: 0; batch classifier loss: 0.094537; batch adversarial loss: 0.449264\n",
      "epoch 48; iter: 0; batch classifier loss: 0.158414; batch adversarial loss: 0.474337\n",
      "epoch 49; iter: 0; batch classifier loss: 0.089004; batch adversarial loss: 0.563578\n",
      "epoch 50; iter: 0; batch classifier loss: 0.116057; batch adversarial loss: 0.448465\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112389; batch adversarial loss: 0.414400\n",
      "epoch 52; iter: 0; batch classifier loss: 0.146906; batch adversarial loss: 0.381866\n",
      "epoch 53; iter: 0; batch classifier loss: 0.145051; batch adversarial loss: 0.464914\n",
      "epoch 54; iter: 0; batch classifier loss: 0.119196; batch adversarial loss: 0.463184\n",
      "epoch 55; iter: 0; batch classifier loss: 0.100632; batch adversarial loss: 0.455232\n",
      "epoch 56; iter: 0; batch classifier loss: 0.146451; batch adversarial loss: 0.405017\n",
      "epoch 57; iter: 0; batch classifier loss: 0.146578; batch adversarial loss: 0.492285\n",
      "epoch 58; iter: 0; batch classifier loss: 0.135653; batch adversarial loss: 0.382555\n",
      "epoch 59; iter: 0; batch classifier loss: 0.122991; batch adversarial loss: 0.412954\n",
      "epoch 60; iter: 0; batch classifier loss: 0.084600; batch adversarial loss: 0.630267\n",
      "epoch 61; iter: 0; batch classifier loss: 0.128525; batch adversarial loss: 0.385456\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092940; batch adversarial loss: 0.482396\n",
      "epoch 63; iter: 0; batch classifier loss: 0.087433; batch adversarial loss: 0.465283\n",
      "epoch 64; iter: 0; batch classifier loss: 0.104185; batch adversarial loss: 0.456107\n",
      "epoch 65; iter: 0; batch classifier loss: 0.072496; batch adversarial loss: 0.504943\n",
      "epoch 66; iter: 0; batch classifier loss: 0.101684; batch adversarial loss: 0.450625\n",
      "epoch 67; iter: 0; batch classifier loss: 0.109324; batch adversarial loss: 0.474966\n",
      "epoch 68; iter: 0; batch classifier loss: 0.151242; batch adversarial loss: 0.518387\n",
      "epoch 69; iter: 0; batch classifier loss: 0.162593; batch adversarial loss: 0.476864\n",
      "epoch 70; iter: 0; batch classifier loss: 0.118171; batch adversarial loss: 0.528903\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064412; batch adversarial loss: 0.463988\n",
      "epoch 72; iter: 0; batch classifier loss: 0.122567; batch adversarial loss: 0.438458\n",
      "epoch 73; iter: 0; batch classifier loss: 0.155339; batch adversarial loss: 0.370249\n",
      "epoch 74; iter: 0; batch classifier loss: 0.151817; batch adversarial loss: 0.422436\n",
      "epoch 75; iter: 0; batch classifier loss: 0.108880; batch adversarial loss: 0.467691\n",
      "epoch 76; iter: 0; batch classifier loss: 0.118423; batch adversarial loss: 0.495491\n",
      "epoch 77; iter: 0; batch classifier loss: 0.093544; batch adversarial loss: 0.558299\n",
      "epoch 78; iter: 0; batch classifier loss: 0.102878; batch adversarial loss: 0.503132\n",
      "epoch 79; iter: 0; batch classifier loss: 0.127954; batch adversarial loss: 0.517046\n",
      "epoch 80; iter: 0; batch classifier loss: 0.108966; batch adversarial loss: 0.464032\n",
      "epoch 81; iter: 0; batch classifier loss: 0.134704; batch adversarial loss: 0.449031\n",
      "epoch 82; iter: 0; batch classifier loss: 0.160393; batch adversarial loss: 0.384456\n",
      "epoch 83; iter: 0; batch classifier loss: 0.137543; batch adversarial loss: 0.457644\n",
      "epoch 84; iter: 0; batch classifier loss: 0.147483; batch adversarial loss: 0.462525\n",
      "epoch 85; iter: 0; batch classifier loss: 0.111936; batch adversarial loss: 0.422122\n",
      "epoch 86; iter: 0; batch classifier loss: 0.183779; batch adversarial loss: 0.412427\n",
      "epoch 87; iter: 0; batch classifier loss: 0.124609; batch adversarial loss: 0.477627\n",
      "epoch 88; iter: 0; batch classifier loss: 0.179809; batch adversarial loss: 0.453327\n",
      "epoch 89; iter: 0; batch classifier loss: 0.129404; batch adversarial loss: 0.476775\n",
      "epoch 90; iter: 0; batch classifier loss: 0.128269; batch adversarial loss: 0.508211\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083774; batch adversarial loss: 0.465450\n",
      "epoch 92; iter: 0; batch classifier loss: 0.114676; batch adversarial loss: 0.508320\n",
      "epoch 93; iter: 0; batch classifier loss: 0.090410; batch adversarial loss: 0.445720\n",
      "epoch 94; iter: 0; batch classifier loss: 0.118164; batch adversarial loss: 0.483385\n",
      "epoch 95; iter: 0; batch classifier loss: 0.092237; batch adversarial loss: 0.516309\n",
      "epoch 96; iter: 0; batch classifier loss: 0.095826; batch adversarial loss: 0.409995\n",
      "epoch 97; iter: 0; batch classifier loss: 0.103468; batch adversarial loss: 0.451791\n",
      "epoch 98; iter: 0; batch classifier loss: 0.116903; batch adversarial loss: 0.586811\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085266; batch adversarial loss: 0.345552\n",
      "epoch 100; iter: 0; batch classifier loss: 0.100086; batch adversarial loss: 0.407928\n",
      "epoch 101; iter: 0; batch classifier loss: 0.127491; batch adversarial loss: 0.526609\n",
      "epoch 102; iter: 0; batch classifier loss: 0.115096; batch adversarial loss: 0.508078\n",
      "epoch 103; iter: 0; batch classifier loss: 0.093241; batch adversarial loss: 0.432430\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083887; batch adversarial loss: 0.473248\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066526; batch adversarial loss: 0.497031\n",
      "epoch 106; iter: 0; batch classifier loss: 0.090382; batch adversarial loss: 0.510499\n",
      "epoch 107; iter: 0; batch classifier loss: 0.090100; batch adversarial loss: 0.451434\n",
      "epoch 108; iter: 0; batch classifier loss: 0.110569; batch adversarial loss: 0.484777\n",
      "epoch 109; iter: 0; batch classifier loss: 0.083818; batch adversarial loss: 0.516992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.064423; batch adversarial loss: 0.487710\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046121; batch adversarial loss: 0.503983\n",
      "epoch 112; iter: 0; batch classifier loss: 0.083758; batch adversarial loss: 0.399118\n",
      "epoch 113; iter: 0; batch classifier loss: 0.089461; batch adversarial loss: 0.464938\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080970; batch adversarial loss: 0.499125\n",
      "epoch 115; iter: 0; batch classifier loss: 0.106384; batch adversarial loss: 0.371798\n",
      "epoch 116; iter: 0; batch classifier loss: 0.114901; batch adversarial loss: 0.435987\n",
      "epoch 117; iter: 0; batch classifier loss: 0.062626; batch adversarial loss: 0.443875\n",
      "epoch 118; iter: 0; batch classifier loss: 0.067372; batch adversarial loss: 0.523281\n",
      "epoch 119; iter: 0; batch classifier loss: 0.067573; batch adversarial loss: 0.538625\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054970; batch adversarial loss: 0.384479\n",
      "epoch 121; iter: 0; batch classifier loss: 0.055316; batch adversarial loss: 0.489807\n",
      "epoch 122; iter: 0; batch classifier loss: 0.078891; batch adversarial loss: 0.456001\n",
      "epoch 123; iter: 0; batch classifier loss: 0.061286; batch adversarial loss: 0.471736\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041644; batch adversarial loss: 0.409735\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039617; batch adversarial loss: 0.447999\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049462; batch adversarial loss: 0.438400\n",
      "epoch 127; iter: 0; batch classifier loss: 0.052430; batch adversarial loss: 0.480452\n",
      "epoch 128; iter: 0; batch classifier loss: 0.078180; batch adversarial loss: 0.449000\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023437; batch adversarial loss: 0.518258\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029361; batch adversarial loss: 0.510296\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038774; batch adversarial loss: 0.417919\n",
      "epoch 132; iter: 0; batch classifier loss: 0.074326; batch adversarial loss: 0.493831\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022036; batch adversarial loss: 0.376475\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021526; batch adversarial loss: 0.519935\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033686; batch adversarial loss: 0.459693\n",
      "epoch 136; iter: 0; batch classifier loss: 0.068277; batch adversarial loss: 0.422961\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043687; batch adversarial loss: 0.568003\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049827; batch adversarial loss: 0.462070\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051189; batch adversarial loss: 0.483693\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028054; batch adversarial loss: 0.499071\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035532; batch adversarial loss: 0.476801\n",
      "epoch 142; iter: 0; batch classifier loss: 0.068872; batch adversarial loss: 0.447247\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039249; batch adversarial loss: 0.401803\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020319; batch adversarial loss: 0.503794\n",
      "epoch 145; iter: 0; batch classifier loss: 0.054163; batch adversarial loss: 0.387556\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024103; batch adversarial loss: 0.551575\n",
      "epoch 147; iter: 0; batch classifier loss: 0.051087; batch adversarial loss: 0.565377\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020278; batch adversarial loss: 0.487862\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024137; batch adversarial loss: 0.458440\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016355; batch adversarial loss: 0.362477\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022916; batch adversarial loss: 0.444412\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014633; batch adversarial loss: 0.376242\n",
      "epoch 153; iter: 0; batch classifier loss: 0.053693; batch adversarial loss: 0.448228\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016928; batch adversarial loss: 0.493299\n",
      "epoch 155; iter: 0; batch classifier loss: 0.039376; batch adversarial loss: 0.431977\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022880; batch adversarial loss: 0.465605\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018368; batch adversarial loss: 0.560203\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038771; batch adversarial loss: 0.425134\n",
      "epoch 159; iter: 0; batch classifier loss: 0.044375; batch adversarial loss: 0.489335\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024649; batch adversarial loss: 0.485207\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029108; batch adversarial loss: 0.450092\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024862; batch adversarial loss: 0.529930\n",
      "epoch 163; iter: 0; batch classifier loss: 0.048233; batch adversarial loss: 0.495555\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018497; batch adversarial loss: 0.500512\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034619; batch adversarial loss: 0.454434\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011100; batch adversarial loss: 0.504639\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021272; batch adversarial loss: 0.394578\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010723; batch adversarial loss: 0.520861\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015862; batch adversarial loss: 0.557858\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015684; batch adversarial loss: 0.493520\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031599; batch adversarial loss: 0.399573\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011956; batch adversarial loss: 0.482663\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024487; batch adversarial loss: 0.414555\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036495; batch adversarial loss: 0.384821\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031955; batch adversarial loss: 0.454321\n",
      "epoch 176; iter: 0; batch classifier loss: 0.065702; batch adversarial loss: 0.457125\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010010; batch adversarial loss: 0.510227\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012809; batch adversarial loss: 0.494400\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033840; batch adversarial loss: 0.466852\n",
      "epoch 180; iter: 0; batch classifier loss: 0.071863; batch adversarial loss: 0.520067\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013387; batch adversarial loss: 0.397965\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012300; batch adversarial loss: 0.394996\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027389; batch adversarial loss: 0.526249\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014480; batch adversarial loss: 0.586815\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026454; batch adversarial loss: 0.461087\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027682; batch adversarial loss: 0.532753\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010814; batch adversarial loss: 0.446054\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009766; batch adversarial loss: 0.536306\n",
      "epoch 189; iter: 0; batch classifier loss: 0.047568; batch adversarial loss: 0.446660\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018047; batch adversarial loss: 0.420927\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020551; batch adversarial loss: 0.563237\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016637; batch adversarial loss: 0.416343\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018113; batch adversarial loss: 0.429684\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032238; batch adversarial loss: 0.510384\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027990; batch adversarial loss: 0.527608\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030126; batch adversarial loss: 0.396460\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013182; batch adversarial loss: 0.425259\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013546; batch adversarial loss: 0.472835\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020806; batch adversarial loss: 0.480536\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714702; batch adversarial loss: 0.674570\n",
      "epoch 1; iter: 0; batch classifier loss: 0.497110; batch adversarial loss: 0.655615\n",
      "epoch 2; iter: 0; batch classifier loss: 0.401026; batch adversarial loss: 0.647456\n",
      "epoch 3; iter: 0; batch classifier loss: 0.428314; batch adversarial loss: 0.609614\n",
      "epoch 4; iter: 0; batch classifier loss: 0.435128; batch adversarial loss: 0.573395\n",
      "epoch 5; iter: 0; batch classifier loss: 0.563212; batch adversarial loss: 0.585442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.573824; batch adversarial loss: 0.571325\n",
      "epoch 7; iter: 0; batch classifier loss: 0.410869; batch adversarial loss: 0.595114\n",
      "epoch 8; iter: 0; batch classifier loss: 0.467035; batch adversarial loss: 0.537980\n",
      "epoch 9; iter: 0; batch classifier loss: 0.367038; batch adversarial loss: 0.575255\n",
      "epoch 10; iter: 0; batch classifier loss: 0.365657; batch adversarial loss: 0.522111\n",
      "epoch 11; iter: 0; batch classifier loss: 0.382683; batch adversarial loss: 0.504995\n",
      "epoch 12; iter: 0; batch classifier loss: 0.372380; batch adversarial loss: 0.555716\n",
      "epoch 13; iter: 0; batch classifier loss: 0.327115; batch adversarial loss: 0.531800\n",
      "epoch 14; iter: 0; batch classifier loss: 0.363743; batch adversarial loss: 0.467233\n",
      "epoch 15; iter: 0; batch classifier loss: 0.278438; batch adversarial loss: 0.509684\n",
      "epoch 16; iter: 0; batch classifier loss: 0.299243; batch adversarial loss: 0.479246\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265919; batch adversarial loss: 0.500228\n",
      "epoch 18; iter: 0; batch classifier loss: 0.283217; batch adversarial loss: 0.505286\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338327; batch adversarial loss: 0.549665\n",
      "epoch 20; iter: 0; batch classifier loss: 0.378214; batch adversarial loss: 0.496637\n",
      "epoch 21; iter: 0; batch classifier loss: 0.287632; batch adversarial loss: 0.481871\n",
      "epoch 22; iter: 0; batch classifier loss: 0.200572; batch adversarial loss: 0.551334\n",
      "epoch 23; iter: 0; batch classifier loss: 0.234298; batch adversarial loss: 0.411275\n",
      "epoch 24; iter: 0; batch classifier loss: 0.176203; batch adversarial loss: 0.464780\n",
      "epoch 25; iter: 0; batch classifier loss: 0.219630; batch adversarial loss: 0.465620\n",
      "epoch 26; iter: 0; batch classifier loss: 0.250816; batch adversarial loss: 0.444741\n",
      "epoch 27; iter: 0; batch classifier loss: 0.268211; batch adversarial loss: 0.432988\n",
      "epoch 28; iter: 0; batch classifier loss: 0.211864; batch adversarial loss: 0.516429\n",
      "epoch 29; iter: 0; batch classifier loss: 0.263053; batch adversarial loss: 0.480428\n",
      "epoch 30; iter: 0; batch classifier loss: 0.252511; batch adversarial loss: 0.451465\n",
      "epoch 31; iter: 0; batch classifier loss: 0.226498; batch adversarial loss: 0.417203\n",
      "epoch 32; iter: 0; batch classifier loss: 0.199734; batch adversarial loss: 0.483762\n",
      "epoch 33; iter: 0; batch classifier loss: 0.244933; batch adversarial loss: 0.571242\n",
      "epoch 34; iter: 0; batch classifier loss: 0.306471; batch adversarial loss: 0.423983\n",
      "epoch 35; iter: 0; batch classifier loss: 0.192070; batch adversarial loss: 0.433924\n",
      "epoch 36; iter: 0; batch classifier loss: 0.204480; batch adversarial loss: 0.442726\n",
      "epoch 37; iter: 0; batch classifier loss: 0.191387; batch adversarial loss: 0.413966\n",
      "epoch 38; iter: 0; batch classifier loss: 0.159134; batch adversarial loss: 0.496992\n",
      "epoch 39; iter: 0; batch classifier loss: 0.158007; batch adversarial loss: 0.451318\n",
      "epoch 40; iter: 0; batch classifier loss: 0.210662; batch adversarial loss: 0.447319\n",
      "epoch 41; iter: 0; batch classifier loss: 0.216537; batch adversarial loss: 0.390066\n",
      "epoch 42; iter: 0; batch classifier loss: 0.188714; batch adversarial loss: 0.467701\n",
      "epoch 43; iter: 0; batch classifier loss: 0.196871; batch adversarial loss: 0.421873\n",
      "epoch 44; iter: 0; batch classifier loss: 0.225988; batch adversarial loss: 0.506226\n",
      "epoch 45; iter: 0; batch classifier loss: 0.172536; batch adversarial loss: 0.461598\n",
      "epoch 46; iter: 0; batch classifier loss: 0.207900; batch adversarial loss: 0.448610\n",
      "epoch 47; iter: 0; batch classifier loss: 0.235924; batch adversarial loss: 0.402310\n",
      "epoch 48; iter: 0; batch classifier loss: 0.201317; batch adversarial loss: 0.494302\n",
      "epoch 49; iter: 0; batch classifier loss: 0.205471; batch adversarial loss: 0.435283\n",
      "epoch 50; iter: 0; batch classifier loss: 0.231334; batch adversarial loss: 0.412329\n",
      "epoch 51; iter: 0; batch classifier loss: 0.174710; batch adversarial loss: 0.435533\n",
      "epoch 52; iter: 0; batch classifier loss: 0.107233; batch adversarial loss: 0.432472\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094366; batch adversarial loss: 0.393416\n",
      "epoch 54; iter: 0; batch classifier loss: 0.120556; batch adversarial loss: 0.382854\n",
      "epoch 55; iter: 0; batch classifier loss: 0.111123; batch adversarial loss: 0.450568\n",
      "epoch 56; iter: 0; batch classifier loss: 0.185014; batch adversarial loss: 0.496784\n",
      "epoch 57; iter: 0; batch classifier loss: 0.142797; batch adversarial loss: 0.606771\n",
      "epoch 58; iter: 0; batch classifier loss: 0.142379; batch adversarial loss: 0.396941\n",
      "epoch 59; iter: 0; batch classifier loss: 0.128985; batch adversarial loss: 0.466348\n",
      "epoch 60; iter: 0; batch classifier loss: 0.096038; batch adversarial loss: 0.571374\n",
      "epoch 61; iter: 0; batch classifier loss: 0.163318; batch adversarial loss: 0.362876\n",
      "epoch 62; iter: 0; batch classifier loss: 0.173741; batch adversarial loss: 0.492159\n",
      "epoch 63; iter: 0; batch classifier loss: 0.143868; batch adversarial loss: 0.457786\n",
      "epoch 64; iter: 0; batch classifier loss: 0.096873; batch adversarial loss: 0.410746\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088746; batch adversarial loss: 0.432964\n",
      "epoch 66; iter: 0; batch classifier loss: 0.113713; batch adversarial loss: 0.420528\n",
      "epoch 67; iter: 0; batch classifier loss: 0.105522; batch adversarial loss: 0.435735\n",
      "epoch 68; iter: 0; batch classifier loss: 0.148411; batch adversarial loss: 0.405963\n",
      "epoch 69; iter: 0; batch classifier loss: 0.097030; batch adversarial loss: 0.549245\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103872; batch adversarial loss: 0.435832\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104230; batch adversarial loss: 0.460309\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070001; batch adversarial loss: 0.476050\n",
      "epoch 73; iter: 0; batch classifier loss: 0.066479; batch adversarial loss: 0.516732\n",
      "epoch 74; iter: 0; batch classifier loss: 0.095284; batch adversarial loss: 0.511258\n",
      "epoch 75; iter: 0; batch classifier loss: 0.097749; batch adversarial loss: 0.447203\n",
      "epoch 76; iter: 0; batch classifier loss: 0.090745; batch adversarial loss: 0.400505\n",
      "epoch 77; iter: 0; batch classifier loss: 0.101991; batch adversarial loss: 0.472616\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061331; batch adversarial loss: 0.525646\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068450; batch adversarial loss: 0.400157\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067737; batch adversarial loss: 0.502714\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073005; batch adversarial loss: 0.494117\n",
      "epoch 82; iter: 0; batch classifier loss: 0.069194; batch adversarial loss: 0.459001\n",
      "epoch 83; iter: 0; batch classifier loss: 0.075717; batch adversarial loss: 0.464233\n",
      "epoch 84; iter: 0; batch classifier loss: 0.092805; batch adversarial loss: 0.557108\n",
      "epoch 85; iter: 0; batch classifier loss: 0.048462; batch adversarial loss: 0.532842\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068708; batch adversarial loss: 0.448904\n",
      "epoch 87; iter: 0; batch classifier loss: 0.051247; batch adversarial loss: 0.551338\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050650; batch adversarial loss: 0.495650\n",
      "epoch 89; iter: 0; batch classifier loss: 0.045842; batch adversarial loss: 0.415195\n",
      "epoch 90; iter: 0; batch classifier loss: 0.049587; batch adversarial loss: 0.493563\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055723; batch adversarial loss: 0.474024\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066112; batch adversarial loss: 0.555505\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064661; batch adversarial loss: 0.322875\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049905; batch adversarial loss: 0.445823\n",
      "epoch 95; iter: 0; batch classifier loss: 0.025045; batch adversarial loss: 0.389973\n",
      "epoch 96; iter: 0; batch classifier loss: 0.025460; batch adversarial loss: 0.402132\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042895; batch adversarial loss: 0.396838\n",
      "epoch 98; iter: 0; batch classifier loss: 0.029629; batch adversarial loss: 0.458126\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040880; batch adversarial loss: 0.435567\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055876; batch adversarial loss: 0.496508\n",
      "epoch 101; iter: 0; batch classifier loss: 0.028771; batch adversarial loss: 0.414012\n",
      "epoch 102; iter: 0; batch classifier loss: 0.020270; batch adversarial loss: 0.484521\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052331; batch adversarial loss: 0.365653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.032473; batch adversarial loss: 0.395949\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037541; batch adversarial loss: 0.470088\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036482; batch adversarial loss: 0.437272\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045117; batch adversarial loss: 0.477222\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028716; batch adversarial loss: 0.524714\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037634; batch adversarial loss: 0.454674\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068599; batch adversarial loss: 0.475517\n",
      "epoch 111; iter: 0; batch classifier loss: 0.013089; batch adversarial loss: 0.479826\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039445; batch adversarial loss: 0.477274\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038072; batch adversarial loss: 0.504780\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036833; batch adversarial loss: 0.504613\n",
      "epoch 115; iter: 0; batch classifier loss: 0.014524; batch adversarial loss: 0.396245\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030558; batch adversarial loss: 0.427190\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033706; batch adversarial loss: 0.360658\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053551; batch adversarial loss: 0.458174\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041768; batch adversarial loss: 0.453750\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055880; batch adversarial loss: 0.403345\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041403; batch adversarial loss: 0.368979\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033769; batch adversarial loss: 0.469675\n",
      "epoch 123; iter: 0; batch classifier loss: 0.011102; batch adversarial loss: 0.461037\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042169; batch adversarial loss: 0.409935\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021430; batch adversarial loss: 0.382523\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037004; batch adversarial loss: 0.497169\n",
      "epoch 127; iter: 0; batch classifier loss: 0.014542; batch adversarial loss: 0.444543\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017916; batch adversarial loss: 0.530529\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036969; batch adversarial loss: 0.454774\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033657; batch adversarial loss: 0.456621\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048771; batch adversarial loss: 0.393523\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030027; batch adversarial loss: 0.409058\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018240; batch adversarial loss: 0.467680\n",
      "epoch 134; iter: 0; batch classifier loss: 0.014594; batch adversarial loss: 0.487699\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031930; batch adversarial loss: 0.419464\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013503; batch adversarial loss: 0.438395\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025305; batch adversarial loss: 0.436868\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021317; batch adversarial loss: 0.457471\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018774; batch adversarial loss: 0.392255\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017105; batch adversarial loss: 0.468733\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026976; batch adversarial loss: 0.556342\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023511; batch adversarial loss: 0.451753\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021141; batch adversarial loss: 0.443593\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017867; batch adversarial loss: 0.425300\n",
      "epoch 145; iter: 0; batch classifier loss: 0.007581; batch adversarial loss: 0.502533\n",
      "epoch 146; iter: 0; batch classifier loss: 0.012193; batch adversarial loss: 0.474706\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024341; batch adversarial loss: 0.478838\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022534; batch adversarial loss: 0.419136\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017898; batch adversarial loss: 0.462499\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017263; batch adversarial loss: 0.445858\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012111; batch adversarial loss: 0.419637\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019442; batch adversarial loss: 0.416037\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012588; batch adversarial loss: 0.515912\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025460; batch adversarial loss: 0.397274\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017340; batch adversarial loss: 0.401119\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030139; batch adversarial loss: 0.499989\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019953; batch adversarial loss: 0.547090\n",
      "epoch 158; iter: 0; batch classifier loss: 0.004454; batch adversarial loss: 0.393066\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026179; batch adversarial loss: 0.427499\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016448; batch adversarial loss: 0.438332\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016065; batch adversarial loss: 0.452282\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019635; batch adversarial loss: 0.430378\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014172; batch adversarial loss: 0.429865\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020508; batch adversarial loss: 0.346358\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020372; batch adversarial loss: 0.467285\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027949; batch adversarial loss: 0.475493\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015521; batch adversarial loss: 0.481689\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008423; batch adversarial loss: 0.396574\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021741; batch adversarial loss: 0.493670\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011576; batch adversarial loss: 0.492203\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020610; batch adversarial loss: 0.565441\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026880; batch adversarial loss: 0.495694\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007825; batch adversarial loss: 0.551155\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013997; batch adversarial loss: 0.377351\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022500; batch adversarial loss: 0.448609\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018094; batch adversarial loss: 0.500302\n",
      "epoch 177; iter: 0; batch classifier loss: 0.005546; batch adversarial loss: 0.368057\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030895; batch adversarial loss: 0.400697\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017660; batch adversarial loss: 0.306025\n",
      "epoch 180; iter: 0; batch classifier loss: 0.002982; batch adversarial loss: 0.535166\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009375; batch adversarial loss: 0.419230\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022172; batch adversarial loss: 0.451676\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031996; batch adversarial loss: 0.374313\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018060; batch adversarial loss: 0.405427\n",
      "epoch 185; iter: 0; batch classifier loss: 0.043726; batch adversarial loss: 0.443604\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017973; batch adversarial loss: 0.388491\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028496; batch adversarial loss: 0.419139\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013117; batch adversarial loss: 0.499112\n",
      "epoch 189; iter: 0; batch classifier loss: 0.002707; batch adversarial loss: 0.507610\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019902; batch adversarial loss: 0.536305\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011235; batch adversarial loss: 0.485161\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012146; batch adversarial loss: 0.456718\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013948; batch adversarial loss: 0.510998\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007325; batch adversarial loss: 0.440910\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030067; batch adversarial loss: 0.454751\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033611; batch adversarial loss: 0.407821\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006843; batch adversarial loss: 0.386065\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006269; batch adversarial loss: 0.505842\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007919; batch adversarial loss: 0.419859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.700709; batch adversarial loss: 0.920699\n",
      "epoch 1; iter: 0; batch classifier loss: 0.496075; batch adversarial loss: 0.914820\n",
      "epoch 2; iter: 0; batch classifier loss: 0.438430; batch adversarial loss: 0.863402\n",
      "epoch 3; iter: 0; batch classifier loss: 0.409601; batch adversarial loss: 0.801429\n",
      "epoch 4; iter: 0; batch classifier loss: 0.373977; batch adversarial loss: 0.732371\n",
      "epoch 5; iter: 0; batch classifier loss: 0.355942; batch adversarial loss: 0.698299\n",
      "epoch 6; iter: 0; batch classifier loss: 0.313086; batch adversarial loss: 0.663425\n",
      "epoch 7; iter: 0; batch classifier loss: 0.287566; batch adversarial loss: 0.607068\n",
      "epoch 8; iter: 0; batch classifier loss: 0.359079; batch adversarial loss: 0.623917\n",
      "epoch 9; iter: 0; batch classifier loss: 0.262182; batch adversarial loss: 0.588683\n",
      "epoch 10; iter: 0; batch classifier loss: 0.309514; batch adversarial loss: 0.572083\n",
      "epoch 11; iter: 0; batch classifier loss: 0.238414; batch adversarial loss: 0.557875\n",
      "epoch 12; iter: 0; batch classifier loss: 0.218884; batch adversarial loss: 0.568360\n",
      "epoch 13; iter: 0; batch classifier loss: 0.176040; batch adversarial loss: 0.510493\n",
      "epoch 14; iter: 0; batch classifier loss: 0.145727; batch adversarial loss: 0.529544\n",
      "epoch 15; iter: 0; batch classifier loss: 0.216472; batch adversarial loss: 0.487056\n",
      "epoch 16; iter: 0; batch classifier loss: 0.258112; batch adversarial loss: 0.459475\n",
      "epoch 17; iter: 0; batch classifier loss: 0.278077; batch adversarial loss: 0.535979\n",
      "epoch 18; iter: 0; batch classifier loss: 0.241059; batch adversarial loss: 0.442078\n",
      "epoch 19; iter: 0; batch classifier loss: 0.204616; batch adversarial loss: 0.474613\n",
      "epoch 20; iter: 0; batch classifier loss: 0.206951; batch adversarial loss: 0.472762\n",
      "epoch 21; iter: 0; batch classifier loss: 0.249818; batch adversarial loss: 0.443271\n",
      "epoch 22; iter: 0; batch classifier loss: 0.227309; batch adversarial loss: 0.426341\n",
      "epoch 23; iter: 0; batch classifier loss: 0.197106; batch adversarial loss: 0.482085\n",
      "epoch 24; iter: 0; batch classifier loss: 0.142780; batch adversarial loss: 0.462748\n",
      "epoch 25; iter: 0; batch classifier loss: 0.135226; batch adversarial loss: 0.446980\n",
      "epoch 26; iter: 0; batch classifier loss: 0.136639; batch adversarial loss: 0.526737\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181740; batch adversarial loss: 0.417927\n",
      "epoch 28; iter: 0; batch classifier loss: 0.226596; batch adversarial loss: 0.502898\n",
      "epoch 29; iter: 0; batch classifier loss: 0.141735; batch adversarial loss: 0.460380\n",
      "epoch 30; iter: 0; batch classifier loss: 0.186301; batch adversarial loss: 0.452771\n",
      "epoch 31; iter: 0; batch classifier loss: 0.150868; batch adversarial loss: 0.387426\n",
      "epoch 32; iter: 0; batch classifier loss: 0.106843; batch adversarial loss: 0.473395\n",
      "epoch 33; iter: 0; batch classifier loss: 0.115262; batch adversarial loss: 0.397804\n",
      "epoch 34; iter: 0; batch classifier loss: 0.123225; batch adversarial loss: 0.411890\n",
      "epoch 35; iter: 0; batch classifier loss: 0.083685; batch adversarial loss: 0.442914\n",
      "epoch 36; iter: 0; batch classifier loss: 0.155472; batch adversarial loss: 0.438022\n",
      "epoch 37; iter: 0; batch classifier loss: 0.136202; batch adversarial loss: 0.508945\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127987; batch adversarial loss: 0.428950\n",
      "epoch 39; iter: 0; batch classifier loss: 0.169789; batch adversarial loss: 0.448525\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124685; batch adversarial loss: 0.573342\n",
      "epoch 41; iter: 0; batch classifier loss: 0.107019; batch adversarial loss: 0.440362\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088383; batch adversarial loss: 0.425286\n",
      "epoch 43; iter: 0; batch classifier loss: 0.114787; batch adversarial loss: 0.452119\n",
      "epoch 44; iter: 0; batch classifier loss: 0.151658; batch adversarial loss: 0.574775\n",
      "epoch 45; iter: 0; batch classifier loss: 0.080879; batch adversarial loss: 0.359590\n",
      "epoch 46; iter: 0; batch classifier loss: 0.108300; batch adversarial loss: 0.427978\n",
      "epoch 47; iter: 0; batch classifier loss: 0.107688; batch adversarial loss: 0.479552\n",
      "epoch 48; iter: 0; batch classifier loss: 0.130224; batch adversarial loss: 0.475526\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119740; batch adversarial loss: 0.537881\n",
      "epoch 50; iter: 0; batch classifier loss: 0.109916; batch adversarial loss: 0.397453\n",
      "epoch 51; iter: 0; batch classifier loss: 0.075689; batch adversarial loss: 0.475168\n",
      "epoch 52; iter: 0; batch classifier loss: 0.132588; batch adversarial loss: 0.431961\n",
      "epoch 53; iter: 0; batch classifier loss: 0.118013; batch adversarial loss: 0.422429\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114263; batch adversarial loss: 0.410373\n",
      "epoch 55; iter: 0; batch classifier loss: 0.157003; batch adversarial loss: 0.499532\n",
      "epoch 56; iter: 0; batch classifier loss: 0.133358; batch adversarial loss: 0.444088\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079854; batch adversarial loss: 0.513122\n",
      "epoch 58; iter: 0; batch classifier loss: 0.114534; batch adversarial loss: 0.465307\n",
      "epoch 59; iter: 0; batch classifier loss: 0.078301; batch adversarial loss: 0.429917\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101921; batch adversarial loss: 0.364810\n",
      "epoch 61; iter: 0; batch classifier loss: 0.110641; batch adversarial loss: 0.508329\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101550; batch adversarial loss: 0.448517\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103401; batch adversarial loss: 0.445081\n",
      "epoch 64; iter: 0; batch classifier loss: 0.061032; batch adversarial loss: 0.370255\n",
      "epoch 65; iter: 0; batch classifier loss: 0.090163; batch adversarial loss: 0.470715\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068665; batch adversarial loss: 0.430033\n",
      "epoch 67; iter: 0; batch classifier loss: 0.074753; batch adversarial loss: 0.382908\n",
      "epoch 68; iter: 0; batch classifier loss: 0.069550; batch adversarial loss: 0.530810\n",
      "epoch 69; iter: 0; batch classifier loss: 0.144966; batch adversarial loss: 0.457608\n",
      "epoch 70; iter: 0; batch classifier loss: 0.087340; batch adversarial loss: 0.424801\n",
      "epoch 71; iter: 0; batch classifier loss: 0.121889; batch adversarial loss: 0.455186\n",
      "epoch 72; iter: 0; batch classifier loss: 0.068069; batch adversarial loss: 0.417214\n",
      "epoch 73; iter: 0; batch classifier loss: 0.064579; batch adversarial loss: 0.432484\n",
      "epoch 74; iter: 0; batch classifier loss: 0.048004; batch adversarial loss: 0.393196\n",
      "epoch 75; iter: 0; batch classifier loss: 0.054900; batch adversarial loss: 0.462095\n",
      "epoch 76; iter: 0; batch classifier loss: 0.053406; batch adversarial loss: 0.395471\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065956; batch adversarial loss: 0.468371\n",
      "epoch 78; iter: 0; batch classifier loss: 0.102999; batch adversarial loss: 0.436445\n",
      "epoch 79; iter: 0; batch classifier loss: 0.095997; batch adversarial loss: 0.563205\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084787; batch adversarial loss: 0.391563\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076138; batch adversarial loss: 0.461194\n",
      "epoch 82; iter: 0; batch classifier loss: 0.123599; batch adversarial loss: 0.398641\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074566; batch adversarial loss: 0.495218\n",
      "epoch 84; iter: 0; batch classifier loss: 0.117524; batch adversarial loss: 0.563714\n",
      "epoch 85; iter: 0; batch classifier loss: 0.057758; batch adversarial loss: 0.416790\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069786; batch adversarial loss: 0.444745\n",
      "epoch 87; iter: 0; batch classifier loss: 0.092384; batch adversarial loss: 0.501359\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069975; batch adversarial loss: 0.425833\n",
      "epoch 89; iter: 0; batch classifier loss: 0.095653; batch adversarial loss: 0.442497\n",
      "epoch 90; iter: 0; batch classifier loss: 0.105988; batch adversarial loss: 0.483478\n",
      "epoch 91; iter: 0; batch classifier loss: 0.090831; batch adversarial loss: 0.379974\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041962; batch adversarial loss: 0.427872\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054397; batch adversarial loss: 0.484935\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062478; batch adversarial loss: 0.453574\n",
      "epoch 95; iter: 0; batch classifier loss: 0.086221; batch adversarial loss: 0.374605\n",
      "epoch 96; iter: 0; batch classifier loss: 0.029774; batch adversarial loss: 0.361438\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077765; batch adversarial loss: 0.449928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.034491; batch adversarial loss: 0.456226\n",
      "epoch 99; iter: 0; batch classifier loss: 0.090276; batch adversarial loss: 0.550539\n",
      "epoch 100; iter: 0; batch classifier loss: 0.097824; batch adversarial loss: 0.488929\n",
      "epoch 101; iter: 0; batch classifier loss: 0.072512; batch adversarial loss: 0.454869\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034919; batch adversarial loss: 0.492768\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059144; batch adversarial loss: 0.434278\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050398; batch adversarial loss: 0.456633\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052035; batch adversarial loss: 0.381517\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047206; batch adversarial loss: 0.521431\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056538; batch adversarial loss: 0.427575\n",
      "epoch 108; iter: 0; batch classifier loss: 0.072429; batch adversarial loss: 0.470757\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038188; batch adversarial loss: 0.540818\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054955; batch adversarial loss: 0.500855\n",
      "epoch 111; iter: 0; batch classifier loss: 0.071300; batch adversarial loss: 0.438759\n",
      "epoch 112; iter: 0; batch classifier loss: 0.070455; batch adversarial loss: 0.396191\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056794; batch adversarial loss: 0.395119\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050971; batch adversarial loss: 0.344308\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060997; batch adversarial loss: 0.435005\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051846; batch adversarial loss: 0.341145\n",
      "epoch 117; iter: 0; batch classifier loss: 0.073867; batch adversarial loss: 0.438085\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032995; batch adversarial loss: 0.356228\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070334; batch adversarial loss: 0.376202\n",
      "epoch 120; iter: 0; batch classifier loss: 0.084060; batch adversarial loss: 0.418983\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057675; batch adversarial loss: 0.417501\n",
      "epoch 122; iter: 0; batch classifier loss: 0.069232; batch adversarial loss: 0.305470\n",
      "epoch 123; iter: 0; batch classifier loss: 0.094061; batch adversarial loss: 0.451462\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057331; batch adversarial loss: 0.432256\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057343; batch adversarial loss: 0.476286\n",
      "epoch 126; iter: 0; batch classifier loss: 0.069766; batch adversarial loss: 0.442184\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043299; batch adversarial loss: 0.424116\n",
      "epoch 128; iter: 0; batch classifier loss: 0.072928; batch adversarial loss: 0.419633\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033464; batch adversarial loss: 0.423610\n",
      "epoch 130; iter: 0; batch classifier loss: 0.079551; batch adversarial loss: 0.480812\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046957; batch adversarial loss: 0.558807\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047388; batch adversarial loss: 0.441171\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048661; batch adversarial loss: 0.444535\n",
      "epoch 134; iter: 0; batch classifier loss: 0.055884; batch adversarial loss: 0.394509\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060133; batch adversarial loss: 0.459485\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056248; batch adversarial loss: 0.443324\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046850; batch adversarial loss: 0.416993\n",
      "epoch 138; iter: 0; batch classifier loss: 0.055278; batch adversarial loss: 0.429603\n",
      "epoch 139; iter: 0; batch classifier loss: 0.053432; batch adversarial loss: 0.446791\n",
      "epoch 140; iter: 0; batch classifier loss: 0.061817; batch adversarial loss: 0.410852\n",
      "epoch 141; iter: 0; batch classifier loss: 0.082260; batch adversarial loss: 0.376760\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033600; batch adversarial loss: 0.422029\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036370; batch adversarial loss: 0.456277\n",
      "epoch 144; iter: 0; batch classifier loss: 0.085202; batch adversarial loss: 0.428524\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046189; batch adversarial loss: 0.389315\n",
      "epoch 146; iter: 0; batch classifier loss: 0.050507; batch adversarial loss: 0.460938\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034787; batch adversarial loss: 0.455459\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049068; batch adversarial loss: 0.372956\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044620; batch adversarial loss: 0.454982\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041226; batch adversarial loss: 0.438050\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048435; batch adversarial loss: 0.494740\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045814; batch adversarial loss: 0.485379\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048525; batch adversarial loss: 0.493281\n",
      "epoch 154; iter: 0; batch classifier loss: 0.045656; batch adversarial loss: 0.415301\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046752; batch adversarial loss: 0.507288\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019955; batch adversarial loss: 0.486599\n",
      "epoch 157; iter: 0; batch classifier loss: 0.060443; batch adversarial loss: 0.453848\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031113; batch adversarial loss: 0.508312\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041052; batch adversarial loss: 0.485871\n",
      "epoch 160; iter: 0; batch classifier loss: 0.048814; batch adversarial loss: 0.412602\n",
      "epoch 161; iter: 0; batch classifier loss: 0.054759; batch adversarial loss: 0.331096\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046695; batch adversarial loss: 0.427097\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029052; batch adversarial loss: 0.449980\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030374; batch adversarial loss: 0.422889\n",
      "epoch 165; iter: 0; batch classifier loss: 0.047341; batch adversarial loss: 0.422334\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032736; batch adversarial loss: 0.417653\n",
      "epoch 167; iter: 0; batch classifier loss: 0.055729; batch adversarial loss: 0.430664\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019183; batch adversarial loss: 0.447988\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023943; batch adversarial loss: 0.410910\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023898; batch adversarial loss: 0.412763\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034098; batch adversarial loss: 0.415887\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024763; batch adversarial loss: 0.434954\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035629; batch adversarial loss: 0.467986\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024879; batch adversarial loss: 0.442298\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030011; batch adversarial loss: 0.468880\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020868; batch adversarial loss: 0.372239\n",
      "epoch 177; iter: 0; batch classifier loss: 0.047550; batch adversarial loss: 0.344909\n",
      "epoch 178; iter: 0; batch classifier loss: 0.051819; batch adversarial loss: 0.529503\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035512; batch adversarial loss: 0.553110\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034599; batch adversarial loss: 0.440439\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021938; batch adversarial loss: 0.453773\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027185; batch adversarial loss: 0.440574\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031026; batch adversarial loss: 0.464140\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020510; batch adversarial loss: 0.440684\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020221; batch adversarial loss: 0.458111\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016830; batch adversarial loss: 0.519319\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011689; batch adversarial loss: 0.616666\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041113; batch adversarial loss: 0.415557\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006754; batch adversarial loss: 0.514367\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050173; batch adversarial loss: 0.531262\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024051; batch adversarial loss: 0.487337\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024423; batch adversarial loss: 0.492645\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037534; batch adversarial loss: 0.556624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.025015; batch adversarial loss: 0.408135\n",
      "epoch 195; iter: 0; batch classifier loss: 0.079231; batch adversarial loss: 0.588701\n",
      "epoch 196; iter: 0; batch classifier loss: 0.105105; batch adversarial loss: 0.615266\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017540; batch adversarial loss: 0.462794\n",
      "epoch 198; iter: 0; batch classifier loss: 0.064013; batch adversarial loss: 0.583024\n",
      "epoch 199; iter: 0; batch classifier loss: 0.075179; batch adversarial loss: 0.525617\n",
      "epoch 0; iter: 0; batch classifier loss: 0.756905; batch adversarial loss: 0.640228\n",
      "epoch 1; iter: 0; batch classifier loss: 0.431804; batch adversarial loss: 0.592318\n",
      "epoch 2; iter: 0; batch classifier loss: 0.343956; batch adversarial loss: 0.582575\n",
      "epoch 3; iter: 0; batch classifier loss: 0.275844; batch adversarial loss: 0.562726\n",
      "epoch 4; iter: 0; batch classifier loss: 0.366419; batch adversarial loss: 0.576471\n",
      "epoch 5; iter: 0; batch classifier loss: 0.374604; batch adversarial loss: 0.516511\n",
      "epoch 6; iter: 0; batch classifier loss: 0.355381; batch adversarial loss: 0.526622\n",
      "epoch 7; iter: 0; batch classifier loss: 0.403774; batch adversarial loss: 0.503192\n",
      "epoch 8; iter: 0; batch classifier loss: 0.279114; batch adversarial loss: 0.497287\n",
      "epoch 9; iter: 0; batch classifier loss: 0.279354; batch adversarial loss: 0.480415\n",
      "epoch 10; iter: 0; batch classifier loss: 0.244060; batch adversarial loss: 0.485026\n",
      "epoch 11; iter: 0; batch classifier loss: 0.265423; batch adversarial loss: 0.472488\n",
      "epoch 12; iter: 0; batch classifier loss: 0.240135; batch adversarial loss: 0.516445\n",
      "epoch 13; iter: 0; batch classifier loss: 0.217343; batch adversarial loss: 0.509807\n",
      "epoch 14; iter: 0; batch classifier loss: 0.189002; batch adversarial loss: 0.575048\n",
      "epoch 15; iter: 0; batch classifier loss: 0.230198; batch adversarial loss: 0.531553\n",
      "epoch 16; iter: 0; batch classifier loss: 0.187304; batch adversarial loss: 0.500966\n",
      "epoch 17; iter: 0; batch classifier loss: 0.259858; batch adversarial loss: 0.506136\n",
      "epoch 18; iter: 0; batch classifier loss: 0.196153; batch adversarial loss: 0.445632\n",
      "epoch 19; iter: 0; batch classifier loss: 0.228716; batch adversarial loss: 0.444665\n",
      "epoch 20; iter: 0; batch classifier loss: 0.268973; batch adversarial loss: 0.475615\n",
      "epoch 21; iter: 0; batch classifier loss: 0.320755; batch adversarial loss: 0.516272\n",
      "epoch 22; iter: 0; batch classifier loss: 0.355210; batch adversarial loss: 0.521113\n",
      "epoch 23; iter: 0; batch classifier loss: 0.379969; batch adversarial loss: 0.483111\n",
      "epoch 24; iter: 0; batch classifier loss: 0.396479; batch adversarial loss: 0.497888\n",
      "epoch 25; iter: 0; batch classifier loss: 0.247816; batch adversarial loss: 0.519712\n",
      "epoch 26; iter: 0; batch classifier loss: 0.152831; batch adversarial loss: 0.546200\n",
      "epoch 27; iter: 0; batch classifier loss: 0.113894; batch adversarial loss: 0.481064\n",
      "epoch 28; iter: 0; batch classifier loss: 0.136122; batch adversarial loss: 0.426914\n",
      "epoch 29; iter: 0; batch classifier loss: 0.133125; batch adversarial loss: 0.390238\n",
      "epoch 30; iter: 0; batch classifier loss: 0.120916; batch adversarial loss: 0.525417\n",
      "epoch 31; iter: 0; batch classifier loss: 0.130970; batch adversarial loss: 0.439071\n",
      "epoch 32; iter: 0; batch classifier loss: 0.156240; batch adversarial loss: 0.479072\n",
      "epoch 33; iter: 0; batch classifier loss: 0.098362; batch adversarial loss: 0.462604\n",
      "epoch 34; iter: 0; batch classifier loss: 0.089504; batch adversarial loss: 0.508974\n",
      "epoch 35; iter: 0; batch classifier loss: 0.100975; batch adversarial loss: 0.489868\n",
      "epoch 36; iter: 0; batch classifier loss: 0.087956; batch adversarial loss: 0.420936\n",
      "epoch 37; iter: 0; batch classifier loss: 0.102655; batch adversarial loss: 0.453789\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127032; batch adversarial loss: 0.439958\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126943; batch adversarial loss: 0.448355\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091402; batch adversarial loss: 0.509059\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098293; batch adversarial loss: 0.367512\n",
      "epoch 42; iter: 0; batch classifier loss: 0.092291; batch adversarial loss: 0.454831\n",
      "epoch 43; iter: 0; batch classifier loss: 0.103101; batch adversarial loss: 0.464454\n",
      "epoch 44; iter: 0; batch classifier loss: 0.117694; batch adversarial loss: 0.478997\n",
      "epoch 45; iter: 0; batch classifier loss: 0.074397; batch adversarial loss: 0.524279\n",
      "epoch 46; iter: 0; batch classifier loss: 0.061387; batch adversarial loss: 0.460207\n",
      "epoch 47; iter: 0; batch classifier loss: 0.077758; batch adversarial loss: 0.445511\n",
      "epoch 48; iter: 0; batch classifier loss: 0.095917; batch adversarial loss: 0.420795\n",
      "epoch 49; iter: 0; batch classifier loss: 0.077160; batch adversarial loss: 0.505156\n",
      "epoch 50; iter: 0; batch classifier loss: 0.104404; batch adversarial loss: 0.436946\n",
      "epoch 51; iter: 0; batch classifier loss: 0.061771; batch adversarial loss: 0.491486\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111643; batch adversarial loss: 0.482999\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095334; batch adversarial loss: 0.477283\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095570; batch adversarial loss: 0.523786\n",
      "epoch 55; iter: 0; batch classifier loss: 0.102841; batch adversarial loss: 0.506008\n",
      "epoch 56; iter: 0; batch classifier loss: 0.070050; batch adversarial loss: 0.464706\n",
      "epoch 57; iter: 0; batch classifier loss: 0.080830; batch adversarial loss: 0.417103\n",
      "epoch 58; iter: 0; batch classifier loss: 0.140166; batch adversarial loss: 0.447819\n",
      "epoch 59; iter: 0; batch classifier loss: 0.094013; batch adversarial loss: 0.447386\n",
      "epoch 60; iter: 0; batch classifier loss: 0.150754; batch adversarial loss: 0.535114\n",
      "epoch 61; iter: 0; batch classifier loss: 0.045550; batch adversarial loss: 0.488623\n",
      "epoch 62; iter: 0; batch classifier loss: 0.127884; batch adversarial loss: 0.501972\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085769; batch adversarial loss: 0.475438\n",
      "epoch 64; iter: 0; batch classifier loss: 0.093401; batch adversarial loss: 0.409711\n",
      "epoch 65; iter: 0; batch classifier loss: 0.059135; batch adversarial loss: 0.473446\n",
      "epoch 66; iter: 0; batch classifier loss: 0.047819; batch adversarial loss: 0.527119\n",
      "epoch 67; iter: 0; batch classifier loss: 0.035672; batch adversarial loss: 0.498982\n",
      "epoch 68; iter: 0; batch classifier loss: 0.093188; batch adversarial loss: 0.479355\n",
      "epoch 69; iter: 0; batch classifier loss: 0.048416; batch adversarial loss: 0.419930\n",
      "epoch 70; iter: 0; batch classifier loss: 0.075429; batch adversarial loss: 0.395184\n",
      "epoch 71; iter: 0; batch classifier loss: 0.072756; batch adversarial loss: 0.523438\n",
      "epoch 72; iter: 0; batch classifier loss: 0.068588; batch adversarial loss: 0.468109\n",
      "epoch 73; iter: 0; batch classifier loss: 0.060646; batch adversarial loss: 0.534545\n",
      "epoch 74; iter: 0; batch classifier loss: 0.087024; batch adversarial loss: 0.450649\n",
      "epoch 75; iter: 0; batch classifier loss: 0.064461; batch adversarial loss: 0.458304\n",
      "epoch 76; iter: 0; batch classifier loss: 0.098236; batch adversarial loss: 0.497411\n",
      "epoch 77; iter: 0; batch classifier loss: 0.098073; batch adversarial loss: 0.470181\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074250; batch adversarial loss: 0.461540\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072774; batch adversarial loss: 0.535882\n",
      "epoch 80; iter: 0; batch classifier loss: 0.080454; batch adversarial loss: 0.449117\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057917; batch adversarial loss: 0.443782\n",
      "epoch 82; iter: 0; batch classifier loss: 0.086066; batch adversarial loss: 0.484685\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064111; batch adversarial loss: 0.491033\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046038; batch adversarial loss: 0.495134\n",
      "epoch 85; iter: 0; batch classifier loss: 0.029016; batch adversarial loss: 0.384448\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040484; batch adversarial loss: 0.430666\n",
      "epoch 87; iter: 0; batch classifier loss: 0.139441; batch adversarial loss: 0.443951\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076672; batch adversarial loss: 0.376159\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047499; batch adversarial loss: 0.652292\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057086; batch adversarial loss: 0.444070\n",
      "epoch 91; iter: 0; batch classifier loss: 0.065086; batch adversarial loss: 0.471762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.081334; batch adversarial loss: 0.551535\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066653; batch adversarial loss: 0.528783\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046015; batch adversarial loss: 0.521027\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048485; batch adversarial loss: 0.444232\n",
      "epoch 96; iter: 0; batch classifier loss: 0.034796; batch adversarial loss: 0.416032\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057860; batch adversarial loss: 0.406627\n",
      "epoch 98; iter: 0; batch classifier loss: 0.029106; batch adversarial loss: 0.450900\n",
      "epoch 99; iter: 0; batch classifier loss: 0.060218; batch adversarial loss: 0.382802\n",
      "epoch 100; iter: 0; batch classifier loss: 0.078273; batch adversarial loss: 0.492100\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049105; batch adversarial loss: 0.410272\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050634; batch adversarial loss: 0.546913\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043955; batch adversarial loss: 0.461506\n",
      "epoch 104; iter: 0; batch classifier loss: 0.040406; batch adversarial loss: 0.440610\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044557; batch adversarial loss: 0.500730\n",
      "epoch 106; iter: 0; batch classifier loss: 0.028819; batch adversarial loss: 0.362924\n",
      "epoch 107; iter: 0; batch classifier loss: 0.054178; batch adversarial loss: 0.426060\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043711; batch adversarial loss: 0.379377\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050897; batch adversarial loss: 0.344445\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049603; batch adversarial loss: 0.501792\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061241; batch adversarial loss: 0.448313\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043950; batch adversarial loss: 0.517312\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054931; batch adversarial loss: 0.485360\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033177; batch adversarial loss: 0.423372\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022315; batch adversarial loss: 0.458014\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033855; batch adversarial loss: 0.470789\n",
      "epoch 117; iter: 0; batch classifier loss: 0.024995; batch adversarial loss: 0.476400\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060894; batch adversarial loss: 0.353534\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055108; batch adversarial loss: 0.461647\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031719; batch adversarial loss: 0.496122\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045558; batch adversarial loss: 0.510514\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040518; batch adversarial loss: 0.449972\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040500; batch adversarial loss: 0.470669\n",
      "epoch 124; iter: 0; batch classifier loss: 0.053279; batch adversarial loss: 0.557295\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030624; batch adversarial loss: 0.462368\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051165; batch adversarial loss: 0.421038\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047485; batch adversarial loss: 0.451042\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039471; batch adversarial loss: 0.346775\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025998; batch adversarial loss: 0.451555\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026374; batch adversarial loss: 0.419712\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042528; batch adversarial loss: 0.404307\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051824; batch adversarial loss: 0.436160\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035762; batch adversarial loss: 0.497551\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024565; batch adversarial loss: 0.387780\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037915; batch adversarial loss: 0.496619\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038339; batch adversarial loss: 0.293528\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038924; batch adversarial loss: 0.455291\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045755; batch adversarial loss: 0.410426\n",
      "epoch 139; iter: 0; batch classifier loss: 0.059186; batch adversarial loss: 0.469417\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022534; batch adversarial loss: 0.539379\n",
      "epoch 141; iter: 0; batch classifier loss: 0.058326; batch adversarial loss: 0.510337\n",
      "epoch 142; iter: 0; batch classifier loss: 0.131619; batch adversarial loss: 0.461845\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016132; batch adversarial loss: 0.477745\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017665; batch adversarial loss: 0.447329\n",
      "epoch 145; iter: 0; batch classifier loss: 0.053540; batch adversarial loss: 0.395610\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048194; batch adversarial loss: 0.455535\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039706; batch adversarial loss: 0.534899\n",
      "epoch 148; iter: 0; batch classifier loss: 0.009440; batch adversarial loss: 0.514124\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023068; batch adversarial loss: 0.473047\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025869; batch adversarial loss: 0.478478\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020237; batch adversarial loss: 0.451190\n",
      "epoch 152; iter: 0; batch classifier loss: 0.050146; batch adversarial loss: 0.399866\n",
      "epoch 153; iter: 0; batch classifier loss: 0.057900; batch adversarial loss: 0.466042\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021123; batch adversarial loss: 0.541892\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027690; batch adversarial loss: 0.430886\n",
      "epoch 156; iter: 0; batch classifier loss: 0.054458; batch adversarial loss: 0.490959\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024221; batch adversarial loss: 0.521973\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018670; batch adversarial loss: 0.403223\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018749; batch adversarial loss: 0.464302\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021069; batch adversarial loss: 0.429463\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009276; batch adversarial loss: 0.409937\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027249; batch adversarial loss: 0.472260\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007771; batch adversarial loss: 0.470612\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023208; batch adversarial loss: 0.513586\n",
      "epoch 165; iter: 0; batch classifier loss: 0.052499; batch adversarial loss: 0.438355\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012248; batch adversarial loss: 0.496228\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012387; batch adversarial loss: 0.496936\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030288; batch adversarial loss: 0.434047\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020761; batch adversarial loss: 0.557493\n",
      "epoch 170; iter: 0; batch classifier loss: 0.059233; batch adversarial loss: 0.382712\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015426; batch adversarial loss: 0.491562\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009560; batch adversarial loss: 0.499785\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028512; batch adversarial loss: 0.429990\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030072; batch adversarial loss: 0.574387\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041029; batch adversarial loss: 0.507186\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019183; batch adversarial loss: 0.490767\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026733; batch adversarial loss: 0.488848\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023472; batch adversarial loss: 0.414999\n",
      "epoch 179; iter: 0; batch classifier loss: 0.049263; batch adversarial loss: 0.496203\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023327; batch adversarial loss: 0.434092\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027142; batch adversarial loss: 0.458353\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014481; batch adversarial loss: 0.456522\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010633; batch adversarial loss: 0.421327\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017751; batch adversarial loss: 0.477959\n",
      "epoch 185; iter: 0; batch classifier loss: 0.004898; batch adversarial loss: 0.470525\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025440; batch adversarial loss: 0.502122\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035210; batch adversarial loss: 0.457190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.033636; batch adversarial loss: 0.513554\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020846; batch adversarial loss: 0.423616\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013862; batch adversarial loss: 0.360856\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033817; batch adversarial loss: 0.464130\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014107; batch adversarial loss: 0.444724\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034650; batch adversarial loss: 0.408129\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016145; batch adversarial loss: 0.458784\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015420; batch adversarial loss: 0.516091\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013502; batch adversarial loss: 0.467915\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019141; batch adversarial loss: 0.433424\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022799; batch adversarial loss: 0.439402\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026103; batch adversarial loss: 0.461569\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690934; batch adversarial loss: 0.610780\n",
      "epoch 1; iter: 0; batch classifier loss: 0.388112; batch adversarial loss: 0.610757\n",
      "epoch 2; iter: 0; batch classifier loss: 0.355978; batch adversarial loss: 0.615467\n",
      "epoch 3; iter: 0; batch classifier loss: 0.385843; batch adversarial loss: 0.579552\n",
      "epoch 4; iter: 0; batch classifier loss: 0.300024; batch adversarial loss: 0.570773\n",
      "epoch 5; iter: 0; batch classifier loss: 0.320821; batch adversarial loss: 0.608687\n",
      "epoch 6; iter: 0; batch classifier loss: 0.265382; batch adversarial loss: 0.587489\n",
      "epoch 7; iter: 0; batch classifier loss: 0.258540; batch adversarial loss: 0.564297\n",
      "epoch 8; iter: 0; batch classifier loss: 0.257821; batch adversarial loss: 0.537889\n",
      "epoch 9; iter: 0; batch classifier loss: 0.283207; batch adversarial loss: 0.503107\n",
      "epoch 10; iter: 0; batch classifier loss: 0.303211; batch adversarial loss: 0.516782\n",
      "epoch 11; iter: 0; batch classifier loss: 0.332842; batch adversarial loss: 0.598257\n",
      "epoch 12; iter: 0; batch classifier loss: 0.516888; batch adversarial loss: 0.554175\n",
      "epoch 13; iter: 0; batch classifier loss: 0.394074; batch adversarial loss: 0.586980\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499270; batch adversarial loss: 0.480810\n",
      "epoch 15; iter: 0; batch classifier loss: 0.517998; batch adversarial loss: 0.507755\n",
      "epoch 16; iter: 0; batch classifier loss: 0.308251; batch adversarial loss: 0.444262\n",
      "epoch 17; iter: 0; batch classifier loss: 0.209317; batch adversarial loss: 0.468801\n",
      "epoch 18; iter: 0; batch classifier loss: 0.194603; batch adversarial loss: 0.505943\n",
      "epoch 19; iter: 0; batch classifier loss: 0.197932; batch adversarial loss: 0.459305\n",
      "epoch 20; iter: 0; batch classifier loss: 0.197145; batch adversarial loss: 0.433130\n",
      "epoch 21; iter: 0; batch classifier loss: 0.136550; batch adversarial loss: 0.509346\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206273; batch adversarial loss: 0.479522\n",
      "epoch 23; iter: 0; batch classifier loss: 0.152983; batch adversarial loss: 0.484533\n",
      "epoch 24; iter: 0; batch classifier loss: 0.166905; batch adversarial loss: 0.519053\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148892; batch adversarial loss: 0.458348\n",
      "epoch 26; iter: 0; batch classifier loss: 0.169157; batch adversarial loss: 0.430701\n",
      "epoch 27; iter: 0; batch classifier loss: 0.126979; batch adversarial loss: 0.398466\n",
      "epoch 28; iter: 0; batch classifier loss: 0.157699; batch adversarial loss: 0.464588\n",
      "epoch 29; iter: 0; batch classifier loss: 0.133260; batch adversarial loss: 0.487720\n",
      "epoch 30; iter: 0; batch classifier loss: 0.119265; batch adversarial loss: 0.471546\n",
      "epoch 31; iter: 0; batch classifier loss: 0.132277; batch adversarial loss: 0.438738\n",
      "epoch 32; iter: 0; batch classifier loss: 0.106093; batch adversarial loss: 0.484970\n",
      "epoch 33; iter: 0; batch classifier loss: 0.141697; batch adversarial loss: 0.485455\n",
      "epoch 34; iter: 0; batch classifier loss: 0.162146; batch adversarial loss: 0.442399\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130818; batch adversarial loss: 0.465103\n",
      "epoch 36; iter: 0; batch classifier loss: 0.176773; batch adversarial loss: 0.392867\n",
      "epoch 37; iter: 0; batch classifier loss: 0.114085; batch adversarial loss: 0.416763\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126208; batch adversarial loss: 0.432730\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107225; batch adversarial loss: 0.477123\n",
      "epoch 40; iter: 0; batch classifier loss: 0.102158; batch adversarial loss: 0.385942\n",
      "epoch 41; iter: 0; batch classifier loss: 0.133840; batch adversarial loss: 0.550981\n",
      "epoch 42; iter: 0; batch classifier loss: 0.143213; batch adversarial loss: 0.359771\n",
      "epoch 43; iter: 0; batch classifier loss: 0.082427; batch adversarial loss: 0.449911\n",
      "epoch 44; iter: 0; batch classifier loss: 0.161518; batch adversarial loss: 0.427678\n",
      "epoch 45; iter: 0; batch classifier loss: 0.126082; batch adversarial loss: 0.400192\n",
      "epoch 46; iter: 0; batch classifier loss: 0.105386; batch adversarial loss: 0.442222\n",
      "epoch 47; iter: 0; batch classifier loss: 0.089506; batch adversarial loss: 0.417379\n",
      "epoch 48; iter: 0; batch classifier loss: 0.067787; batch adversarial loss: 0.513169\n",
      "epoch 49; iter: 0; batch classifier loss: 0.064948; batch adversarial loss: 0.432178\n",
      "epoch 50; iter: 0; batch classifier loss: 0.063260; batch adversarial loss: 0.558870\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098242; batch adversarial loss: 0.429193\n",
      "epoch 52; iter: 0; batch classifier loss: 0.105071; batch adversarial loss: 0.372119\n",
      "epoch 53; iter: 0; batch classifier loss: 0.100188; batch adversarial loss: 0.512658\n",
      "epoch 54; iter: 0; batch classifier loss: 0.149959; batch adversarial loss: 0.587626\n",
      "epoch 55; iter: 0; batch classifier loss: 0.134582; batch adversarial loss: 0.418886\n",
      "epoch 56; iter: 0; batch classifier loss: 0.160220; batch adversarial loss: 0.405119\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082567; batch adversarial loss: 0.503184\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093540; batch adversarial loss: 0.397462\n",
      "epoch 59; iter: 0; batch classifier loss: 0.120041; batch adversarial loss: 0.512420\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065028; batch adversarial loss: 0.469712\n",
      "epoch 61; iter: 0; batch classifier loss: 0.107711; batch adversarial loss: 0.504646\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080719; batch adversarial loss: 0.475184\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116206; batch adversarial loss: 0.388943\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083168; batch adversarial loss: 0.448850\n",
      "epoch 65; iter: 0; batch classifier loss: 0.108751; batch adversarial loss: 0.419479\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089327; batch adversarial loss: 0.508062\n",
      "epoch 67; iter: 0; batch classifier loss: 0.099319; batch adversarial loss: 0.451525\n",
      "epoch 68; iter: 0; batch classifier loss: 0.106465; batch adversarial loss: 0.523695\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084678; batch adversarial loss: 0.498589\n",
      "epoch 70; iter: 0; batch classifier loss: 0.111314; batch adversarial loss: 0.381260\n",
      "epoch 71; iter: 0; batch classifier loss: 0.199835; batch adversarial loss: 0.476236\n",
      "epoch 72; iter: 0; batch classifier loss: 0.101434; batch adversarial loss: 0.402839\n",
      "epoch 73; iter: 0; batch classifier loss: 0.115018; batch adversarial loss: 0.486883\n",
      "epoch 74; iter: 0; batch classifier loss: 0.130530; batch adversarial loss: 0.465309\n",
      "epoch 75; iter: 0; batch classifier loss: 0.151415; batch adversarial loss: 0.500970\n",
      "epoch 76; iter: 0; batch classifier loss: 0.115982; batch adversarial loss: 0.451261\n",
      "epoch 77; iter: 0; batch classifier loss: 0.086700; batch adversarial loss: 0.560844\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090968; batch adversarial loss: 0.507250\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082125; batch adversarial loss: 0.678840\n",
      "epoch 80; iter: 0; batch classifier loss: 0.137749; batch adversarial loss: 0.444140\n",
      "epoch 81; iter: 0; batch classifier loss: 0.093676; batch adversarial loss: 0.433175\n",
      "epoch 82; iter: 0; batch classifier loss: 0.101021; batch adversarial loss: 0.486567\n",
      "epoch 83; iter: 0; batch classifier loss: 0.107747; batch adversarial loss: 0.425888\n",
      "epoch 84; iter: 0; batch classifier loss: 0.089498; batch adversarial loss: 0.520240\n",
      "epoch 85; iter: 0; batch classifier loss: 0.137901; batch adversarial loss: 0.474083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.084133; batch adversarial loss: 0.344968\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072422; batch adversarial loss: 0.429356\n",
      "epoch 88; iter: 0; batch classifier loss: 0.150855; batch adversarial loss: 0.391155\n",
      "epoch 89; iter: 0; batch classifier loss: 0.139964; batch adversarial loss: 0.492513\n",
      "epoch 90; iter: 0; batch classifier loss: 0.072643; batch adversarial loss: 0.469242\n",
      "epoch 91; iter: 0; batch classifier loss: 0.088495; batch adversarial loss: 0.394112\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040126; batch adversarial loss: 0.485419\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069204; batch adversarial loss: 0.391875\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033739; batch adversarial loss: 0.400817\n",
      "epoch 95; iter: 0; batch classifier loss: 0.097184; batch adversarial loss: 0.419631\n",
      "epoch 96; iter: 0; batch classifier loss: 0.101101; batch adversarial loss: 0.453029\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039363; batch adversarial loss: 0.498582\n",
      "epoch 98; iter: 0; batch classifier loss: 0.028802; batch adversarial loss: 0.567320\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061653; batch adversarial loss: 0.378028\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055919; batch adversarial loss: 0.462631\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050236; batch adversarial loss: 0.453330\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041257; batch adversarial loss: 0.460048\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057325; batch adversarial loss: 0.462189\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056606; batch adversarial loss: 0.572073\n",
      "epoch 105; iter: 0; batch classifier loss: 0.077250; batch adversarial loss: 0.425478\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051299; batch adversarial loss: 0.432534\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044481; batch adversarial loss: 0.468484\n",
      "epoch 108; iter: 0; batch classifier loss: 0.068052; batch adversarial loss: 0.581433\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042877; batch adversarial loss: 0.527698\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039513; batch adversarial loss: 0.532060\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043390; batch adversarial loss: 0.488475\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037260; batch adversarial loss: 0.479167\n",
      "epoch 113; iter: 0; batch classifier loss: 0.076898; batch adversarial loss: 0.409833\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048700; batch adversarial loss: 0.443644\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049465; batch adversarial loss: 0.436321\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044100; batch adversarial loss: 0.468710\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034673; batch adversarial loss: 0.448876\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025931; batch adversarial loss: 0.371380\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023105; batch adversarial loss: 0.446854\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038360; batch adversarial loss: 0.420393\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058654; batch adversarial loss: 0.416094\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040057; batch adversarial loss: 0.380364\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042204; batch adversarial loss: 0.485258\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051043; batch adversarial loss: 0.405949\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042168; batch adversarial loss: 0.465242\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052929; batch adversarial loss: 0.356381\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035603; batch adversarial loss: 0.434388\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036260; batch adversarial loss: 0.457870\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040695; batch adversarial loss: 0.530888\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017861; batch adversarial loss: 0.421374\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046269; batch adversarial loss: 0.461102\n",
      "epoch 132; iter: 0; batch classifier loss: 0.067369; batch adversarial loss: 0.521272\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051468; batch adversarial loss: 0.414673\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053608; batch adversarial loss: 0.407131\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027375; batch adversarial loss: 0.349512\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016267; batch adversarial loss: 0.419042\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052356; batch adversarial loss: 0.431248\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029637; batch adversarial loss: 0.533774\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040237; batch adversarial loss: 0.443094\n",
      "epoch 140; iter: 0; batch classifier loss: 0.009785; batch adversarial loss: 0.438433\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035188; batch adversarial loss: 0.436257\n",
      "epoch 142; iter: 0; batch classifier loss: 0.038073; batch adversarial loss: 0.466351\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032673; batch adversarial loss: 0.442868\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037529; batch adversarial loss: 0.439919\n",
      "epoch 145; iter: 0; batch classifier loss: 0.010001; batch adversarial loss: 0.453666\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017298; batch adversarial loss: 0.405766\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027583; batch adversarial loss: 0.502678\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037290; batch adversarial loss: 0.363585\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028626; batch adversarial loss: 0.378950\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018885; batch adversarial loss: 0.393849\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014372; batch adversarial loss: 0.477620\n",
      "epoch 152; iter: 0; batch classifier loss: 0.046705; batch adversarial loss: 0.389899\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020000; batch adversarial loss: 0.404244\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024042; batch adversarial loss: 0.474395\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032314; batch adversarial loss: 0.509200\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014625; batch adversarial loss: 0.508522\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024142; batch adversarial loss: 0.488277\n",
      "epoch 158; iter: 0; batch classifier loss: 0.053460; batch adversarial loss: 0.432958\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032247; batch adversarial loss: 0.465115\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008485; batch adversarial loss: 0.519787\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024349; batch adversarial loss: 0.530889\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036824; batch adversarial loss: 0.392191\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017786; batch adversarial loss: 0.459605\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030124; batch adversarial loss: 0.405857\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024058; batch adversarial loss: 0.604849\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014327; batch adversarial loss: 0.453411\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019748; batch adversarial loss: 0.383279\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021450; batch adversarial loss: 0.474526\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026253; batch adversarial loss: 0.408978\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017484; batch adversarial loss: 0.324128\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005714; batch adversarial loss: 0.444672\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040790; batch adversarial loss: 0.516005\n",
      "epoch 173; iter: 0; batch classifier loss: 0.043664; batch adversarial loss: 0.453465\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020740; batch adversarial loss: 0.470249\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032042; batch adversarial loss: 0.367929\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018736; batch adversarial loss: 0.418172\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025347; batch adversarial loss: 0.416067\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013559; batch adversarial loss: 0.450371\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037380; batch adversarial loss: 0.471534\n",
      "epoch 180; iter: 0; batch classifier loss: 0.004306; batch adversarial loss: 0.457836\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014650; batch adversarial loss: 0.429403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.046030; batch adversarial loss: 0.445241\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036830; batch adversarial loss: 0.483595\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015673; batch adversarial loss: 0.394939\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023550; batch adversarial loss: 0.501273\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019205; batch adversarial loss: 0.626276\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029046; batch adversarial loss: 0.471623\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022910; batch adversarial loss: 0.440360\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026362; batch adversarial loss: 0.469898\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014061; batch adversarial loss: 0.486165\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009459; batch adversarial loss: 0.459053\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025290; batch adversarial loss: 0.450938\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012226; batch adversarial loss: 0.516455\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018667; batch adversarial loss: 0.433087\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026725; batch adversarial loss: 0.410812\n",
      "epoch 196; iter: 0; batch classifier loss: 0.066079; batch adversarial loss: 0.510451\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007177; batch adversarial loss: 0.436396\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018781; batch adversarial loss: 0.456767\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012311; batch adversarial loss: 0.444919\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671943; batch adversarial loss: 0.705866\n",
      "epoch 1; iter: 0; batch classifier loss: 0.417363; batch adversarial loss: 0.686329\n",
      "epoch 2; iter: 0; batch classifier loss: 0.448754; batch adversarial loss: 0.633798\n",
      "epoch 3; iter: 0; batch classifier loss: 0.379377; batch adversarial loss: 0.602259\n",
      "epoch 4; iter: 0; batch classifier loss: 0.310635; batch adversarial loss: 0.573943\n",
      "epoch 5; iter: 0; batch classifier loss: 0.310954; batch adversarial loss: 0.564416\n",
      "epoch 6; iter: 0; batch classifier loss: 0.268128; batch adversarial loss: 0.514089\n",
      "epoch 7; iter: 0; batch classifier loss: 0.264685; batch adversarial loss: 0.538713\n",
      "epoch 8; iter: 0; batch classifier loss: 0.262270; batch adversarial loss: 0.535555\n",
      "epoch 9; iter: 0; batch classifier loss: 0.252930; batch adversarial loss: 0.479008\n",
      "epoch 10; iter: 0; batch classifier loss: 0.304560; batch adversarial loss: 0.485963\n",
      "epoch 11; iter: 0; batch classifier loss: 0.187526; batch adversarial loss: 0.518279\n",
      "epoch 12; iter: 0; batch classifier loss: 0.171532; batch adversarial loss: 0.513210\n",
      "epoch 13; iter: 0; batch classifier loss: 0.196510; batch adversarial loss: 0.459161\n",
      "epoch 14; iter: 0; batch classifier loss: 0.148788; batch adversarial loss: 0.490747\n",
      "epoch 15; iter: 0; batch classifier loss: 0.199703; batch adversarial loss: 0.477532\n",
      "epoch 16; iter: 0; batch classifier loss: 0.155180; batch adversarial loss: 0.481904\n",
      "epoch 17; iter: 0; batch classifier loss: 0.154765; batch adversarial loss: 0.410614\n",
      "epoch 18; iter: 0; batch classifier loss: 0.152273; batch adversarial loss: 0.497552\n",
      "epoch 19; iter: 0; batch classifier loss: 0.111855; batch adversarial loss: 0.444542\n",
      "epoch 20; iter: 0; batch classifier loss: 0.140939; batch adversarial loss: 0.472015\n",
      "epoch 21; iter: 0; batch classifier loss: 0.163638; batch adversarial loss: 0.489611\n",
      "epoch 22; iter: 0; batch classifier loss: 0.155177; batch adversarial loss: 0.551222\n",
      "epoch 23; iter: 0; batch classifier loss: 0.189900; batch adversarial loss: 0.483044\n",
      "epoch 24; iter: 0; batch classifier loss: 0.145713; batch adversarial loss: 0.496644\n",
      "epoch 25; iter: 0; batch classifier loss: 0.152683; batch adversarial loss: 0.515193\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176078; batch adversarial loss: 0.502041\n",
      "epoch 27; iter: 0; batch classifier loss: 0.153110; batch adversarial loss: 0.558620\n",
      "epoch 28; iter: 0; batch classifier loss: 0.168903; batch adversarial loss: 0.516776\n",
      "epoch 29; iter: 0; batch classifier loss: 0.255225; batch adversarial loss: 0.566703\n",
      "epoch 30; iter: 0; batch classifier loss: 0.222456; batch adversarial loss: 0.439558\n",
      "epoch 31; iter: 0; batch classifier loss: 0.214122; batch adversarial loss: 0.538296\n",
      "epoch 32; iter: 0; batch classifier loss: 0.220683; batch adversarial loss: 0.495783\n",
      "epoch 33; iter: 0; batch classifier loss: 0.213123; batch adversarial loss: 0.532380\n",
      "epoch 34; iter: 0; batch classifier loss: 0.299277; batch adversarial loss: 0.561695\n",
      "epoch 35; iter: 0; batch classifier loss: 0.260748; batch adversarial loss: 0.563142\n",
      "epoch 36; iter: 0; batch classifier loss: 0.117285; batch adversarial loss: 0.521332\n",
      "epoch 37; iter: 0; batch classifier loss: 0.118525; batch adversarial loss: 0.434758\n",
      "epoch 38; iter: 0; batch classifier loss: 0.085104; batch adversarial loss: 0.458121\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129647; batch adversarial loss: 0.479830\n",
      "epoch 40; iter: 0; batch classifier loss: 0.119830; batch adversarial loss: 0.385766\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098087; batch adversarial loss: 0.557174\n",
      "epoch 42; iter: 0; batch classifier loss: 0.092820; batch adversarial loss: 0.562364\n",
      "epoch 43; iter: 0; batch classifier loss: 0.083350; batch adversarial loss: 0.529518\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085774; batch adversarial loss: 0.469099\n",
      "epoch 45; iter: 0; batch classifier loss: 0.094228; batch adversarial loss: 0.404662\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102880; batch adversarial loss: 0.525080\n",
      "epoch 47; iter: 0; batch classifier loss: 0.070612; batch adversarial loss: 0.411950\n",
      "epoch 48; iter: 0; batch classifier loss: 0.121738; batch adversarial loss: 0.497687\n",
      "epoch 49; iter: 0; batch classifier loss: 0.106027; batch adversarial loss: 0.448716\n",
      "epoch 50; iter: 0; batch classifier loss: 0.075789; batch adversarial loss: 0.439614\n",
      "epoch 51; iter: 0; batch classifier loss: 0.107102; batch adversarial loss: 0.432738\n",
      "epoch 52; iter: 0; batch classifier loss: 0.083737; batch adversarial loss: 0.485589\n",
      "epoch 53; iter: 0; batch classifier loss: 0.089245; batch adversarial loss: 0.400972\n",
      "epoch 54; iter: 0; batch classifier loss: 0.063577; batch adversarial loss: 0.516171\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122000; batch adversarial loss: 0.404871\n",
      "epoch 56; iter: 0; batch classifier loss: 0.075770; batch adversarial loss: 0.553310\n",
      "epoch 57; iter: 0; batch classifier loss: 0.075565; batch adversarial loss: 0.485957\n",
      "epoch 58; iter: 0; batch classifier loss: 0.052866; batch adversarial loss: 0.383399\n",
      "epoch 59; iter: 0; batch classifier loss: 0.101696; batch adversarial loss: 0.416078\n",
      "epoch 60; iter: 0; batch classifier loss: 0.089445; batch adversarial loss: 0.463558\n",
      "epoch 61; iter: 0; batch classifier loss: 0.073881; batch adversarial loss: 0.419449\n",
      "epoch 62; iter: 0; batch classifier loss: 0.165853; batch adversarial loss: 0.496217\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098881; batch adversarial loss: 0.419147\n",
      "epoch 64; iter: 0; batch classifier loss: 0.091314; batch adversarial loss: 0.503145\n",
      "epoch 65; iter: 0; batch classifier loss: 0.086250; batch adversarial loss: 0.434694\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086202; batch adversarial loss: 0.374351\n",
      "epoch 67; iter: 0; batch classifier loss: 0.114606; batch adversarial loss: 0.474108\n",
      "epoch 68; iter: 0; batch classifier loss: 0.073985; batch adversarial loss: 0.412684\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071614; batch adversarial loss: 0.489656\n",
      "epoch 70; iter: 0; batch classifier loss: 0.088214; batch adversarial loss: 0.393670\n",
      "epoch 71; iter: 0; batch classifier loss: 0.091262; batch adversarial loss: 0.432750\n",
      "epoch 72; iter: 0; batch classifier loss: 0.140810; batch adversarial loss: 0.440069\n",
      "epoch 73; iter: 0; batch classifier loss: 0.051681; batch adversarial loss: 0.585800\n",
      "epoch 74; iter: 0; batch classifier loss: 0.107153; batch adversarial loss: 0.356306\n",
      "epoch 75; iter: 0; batch classifier loss: 0.060536; batch adversarial loss: 0.454276\n",
      "epoch 76; iter: 0; batch classifier loss: 0.078658; batch adversarial loss: 0.450626\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074981; batch adversarial loss: 0.385368\n",
      "epoch 78; iter: 0; batch classifier loss: 0.104421; batch adversarial loss: 0.467989\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085683; batch adversarial loss: 0.433730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.082571; batch adversarial loss: 0.433445\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074679; batch adversarial loss: 0.544552\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060566; batch adversarial loss: 0.349472\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054884; batch adversarial loss: 0.284996\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065970; batch adversarial loss: 0.429598\n",
      "epoch 85; iter: 0; batch classifier loss: 0.094853; batch adversarial loss: 0.429006\n",
      "epoch 86; iter: 0; batch classifier loss: 0.077719; batch adversarial loss: 0.541134\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062759; batch adversarial loss: 0.471859\n",
      "epoch 88; iter: 0; batch classifier loss: 0.089676; batch adversarial loss: 0.491568\n",
      "epoch 89; iter: 0; batch classifier loss: 0.064549; batch adversarial loss: 0.364481\n",
      "epoch 90; iter: 0; batch classifier loss: 0.080297; batch adversarial loss: 0.462038\n",
      "epoch 91; iter: 0; batch classifier loss: 0.054497; batch adversarial loss: 0.436699\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079953; batch adversarial loss: 0.446005\n",
      "epoch 93; iter: 0; batch classifier loss: 0.068843; batch adversarial loss: 0.452814\n",
      "epoch 94; iter: 0; batch classifier loss: 0.110092; batch adversarial loss: 0.380793\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073398; batch adversarial loss: 0.408993\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059690; batch adversarial loss: 0.576404\n",
      "epoch 97; iter: 0; batch classifier loss: 0.033334; batch adversarial loss: 0.487527\n",
      "epoch 98; iter: 0; batch classifier loss: 0.040220; batch adversarial loss: 0.342372\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040575; batch adversarial loss: 0.499198\n",
      "epoch 100; iter: 0; batch classifier loss: 0.071121; batch adversarial loss: 0.439122\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050143; batch adversarial loss: 0.468271\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043224; batch adversarial loss: 0.484693\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058365; batch adversarial loss: 0.561829\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038836; batch adversarial loss: 0.487292\n",
      "epoch 105; iter: 0; batch classifier loss: 0.011159; batch adversarial loss: 0.529454\n",
      "epoch 106; iter: 0; batch classifier loss: 0.024522; batch adversarial loss: 0.419909\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051043; batch adversarial loss: 0.409755\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038099; batch adversarial loss: 0.446514\n",
      "epoch 109; iter: 0; batch classifier loss: 0.092926; batch adversarial loss: 0.441001\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038085; batch adversarial loss: 0.429562\n",
      "epoch 111; iter: 0; batch classifier loss: 0.073650; batch adversarial loss: 0.443340\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046569; batch adversarial loss: 0.484304\n",
      "epoch 113; iter: 0; batch classifier loss: 0.065533; batch adversarial loss: 0.431781\n",
      "epoch 114; iter: 0; batch classifier loss: 0.014366; batch adversarial loss: 0.420273\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032462; batch adversarial loss: 0.391715\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021683; batch adversarial loss: 0.483020\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047604; batch adversarial loss: 0.457614\n",
      "epoch 118; iter: 0; batch classifier loss: 0.022899; batch adversarial loss: 0.437403\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047833; batch adversarial loss: 0.413360\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051919; batch adversarial loss: 0.428995\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028038; batch adversarial loss: 0.516257\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038045; batch adversarial loss: 0.520957\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037932; batch adversarial loss: 0.376833\n",
      "epoch 124; iter: 0; batch classifier loss: 0.013029; batch adversarial loss: 0.427476\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025635; batch adversarial loss: 0.516484\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025361; batch adversarial loss: 0.402097\n",
      "epoch 127; iter: 0; batch classifier loss: 0.011170; batch adversarial loss: 0.446964\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023348; batch adversarial loss: 0.436469\n",
      "epoch 129; iter: 0; batch classifier loss: 0.012099; batch adversarial loss: 0.502624\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026948; batch adversarial loss: 0.456392\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021672; batch adversarial loss: 0.487558\n",
      "epoch 132; iter: 0; batch classifier loss: 0.061290; batch adversarial loss: 0.420075\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019511; batch adversarial loss: 0.377134\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032895; batch adversarial loss: 0.533236\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027531; batch adversarial loss: 0.452246\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023921; batch adversarial loss: 0.433754\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023004; batch adversarial loss: 0.473654\n",
      "epoch 138; iter: 0; batch classifier loss: 0.006080; batch adversarial loss: 0.498330\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015450; batch adversarial loss: 0.433874\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048600; batch adversarial loss: 0.361834\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021252; batch adversarial loss: 0.519148\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031332; batch adversarial loss: 0.505324\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022146; batch adversarial loss: 0.446339\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024308; batch adversarial loss: 0.546320\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018415; batch adversarial loss: 0.455115\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032078; batch adversarial loss: 0.408798\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024711; batch adversarial loss: 0.436125\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023966; batch adversarial loss: 0.576863\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032194; batch adversarial loss: 0.404531\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052147; batch adversarial loss: 0.486408\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018045; batch adversarial loss: 0.468989\n",
      "epoch 152; iter: 0; batch classifier loss: 0.047332; batch adversarial loss: 0.488780\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023998; batch adversarial loss: 0.453840\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013022; batch adversarial loss: 0.423222\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018215; batch adversarial loss: 0.447408\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013968; batch adversarial loss: 0.364342\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006359; batch adversarial loss: 0.469123\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037011; batch adversarial loss: 0.518728\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014201; batch adversarial loss: 0.447877\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013930; batch adversarial loss: 0.389563\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028333; batch adversarial loss: 0.400836\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015934; batch adversarial loss: 0.397923\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030482; batch adversarial loss: 0.390954\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031525; batch adversarial loss: 0.529618\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011186; batch adversarial loss: 0.480699\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011030; batch adversarial loss: 0.457066\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024638; batch adversarial loss: 0.575969\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008323; batch adversarial loss: 0.480933\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013062; batch adversarial loss: 0.445812\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009058; batch adversarial loss: 0.452292\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021811; batch adversarial loss: 0.517380\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023778; batch adversarial loss: 0.442659\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023158; batch adversarial loss: 0.564515\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008109; batch adversarial loss: 0.414588\n",
      "epoch 175; iter: 0; batch classifier loss: 0.005537; batch adversarial loss: 0.547696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.010813; batch adversarial loss: 0.437288\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010406; batch adversarial loss: 0.496391\n",
      "epoch 178; iter: 0; batch classifier loss: 0.053381; batch adversarial loss: 0.470873\n",
      "epoch 179; iter: 0; batch classifier loss: 0.050383; batch adversarial loss: 0.525233\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008564; batch adversarial loss: 0.439201\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009653; batch adversarial loss: 0.499158\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021077; batch adversarial loss: 0.495540\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010411; batch adversarial loss: 0.448788\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015702; batch adversarial loss: 0.474122\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023660; batch adversarial loss: 0.521810\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005529; batch adversarial loss: 0.427694\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013798; batch adversarial loss: 0.432626\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011592; batch adversarial loss: 0.424301\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012796; batch adversarial loss: 0.550310\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007345; batch adversarial loss: 0.435190\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029971; batch adversarial loss: 0.503658\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013377; batch adversarial loss: 0.471941\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022375; batch adversarial loss: 0.509672\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009371; batch adversarial loss: 0.453305\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011037; batch adversarial loss: 0.450090\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011220; batch adversarial loss: 0.471124\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012621; batch adversarial loss: 0.473918\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009810; batch adversarial loss: 0.484552\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024774; batch adversarial loss: 0.462217\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698356; batch adversarial loss: 0.654104\n",
      "epoch 1; iter: 0; batch classifier loss: 0.461292; batch adversarial loss: 0.648404\n",
      "epoch 2; iter: 0; batch classifier loss: 0.344704; batch adversarial loss: 0.612269\n",
      "epoch 3; iter: 0; batch classifier loss: 0.392248; batch adversarial loss: 0.585687\n",
      "epoch 4; iter: 0; batch classifier loss: 0.337229; batch adversarial loss: 0.560307\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313926; batch adversarial loss: 0.550614\n",
      "epoch 6; iter: 0; batch classifier loss: 0.345683; batch adversarial loss: 0.529508\n",
      "epoch 7; iter: 0; batch classifier loss: 0.257686; batch adversarial loss: 0.545940\n",
      "epoch 8; iter: 0; batch classifier loss: 0.242177; batch adversarial loss: 0.475704\n",
      "epoch 9; iter: 0; batch classifier loss: 0.223869; batch adversarial loss: 0.488847\n",
      "epoch 10; iter: 0; batch classifier loss: 0.196485; batch adversarial loss: 0.489290\n",
      "epoch 11; iter: 0; batch classifier loss: 0.213746; batch adversarial loss: 0.452813\n",
      "epoch 12; iter: 0; batch classifier loss: 0.257895; batch adversarial loss: 0.439671\n",
      "epoch 13; iter: 0; batch classifier loss: 0.190923; batch adversarial loss: 0.514785\n",
      "epoch 14; iter: 0; batch classifier loss: 0.223674; batch adversarial loss: 0.441700\n",
      "epoch 15; iter: 0; batch classifier loss: 0.205920; batch adversarial loss: 0.468788\n",
      "epoch 16; iter: 0; batch classifier loss: 0.161427; batch adversarial loss: 0.523517\n",
      "epoch 17; iter: 0; batch classifier loss: 0.210684; batch adversarial loss: 0.481855\n",
      "epoch 18; iter: 0; batch classifier loss: 0.157541; batch adversarial loss: 0.433871\n",
      "epoch 19; iter: 0; batch classifier loss: 0.135429; batch adversarial loss: 0.482836\n",
      "epoch 20; iter: 0; batch classifier loss: 0.160953; batch adversarial loss: 0.559650\n",
      "epoch 21; iter: 0; batch classifier loss: 0.190647; batch adversarial loss: 0.539975\n",
      "epoch 22; iter: 0; batch classifier loss: 0.150957; batch adversarial loss: 0.456797\n",
      "epoch 23; iter: 0; batch classifier loss: 0.167201; batch adversarial loss: 0.510152\n",
      "epoch 24; iter: 0; batch classifier loss: 0.141777; batch adversarial loss: 0.448953\n",
      "epoch 25; iter: 0; batch classifier loss: 0.145799; batch adversarial loss: 0.502131\n",
      "epoch 26; iter: 0; batch classifier loss: 0.163450; batch adversarial loss: 0.517374\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171615; batch adversarial loss: 0.588965\n",
      "epoch 28; iter: 0; batch classifier loss: 0.138986; batch adversarial loss: 0.463818\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210196; batch adversarial loss: 0.533884\n",
      "epoch 30; iter: 0; batch classifier loss: 0.158892; batch adversarial loss: 0.501248\n",
      "epoch 31; iter: 0; batch classifier loss: 0.270146; batch adversarial loss: 0.580204\n",
      "epoch 32; iter: 0; batch classifier loss: 0.259918; batch adversarial loss: 0.448501\n",
      "epoch 33; iter: 0; batch classifier loss: 0.344752; batch adversarial loss: 0.392850\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233657; batch adversarial loss: 0.427501\n",
      "epoch 35; iter: 0; batch classifier loss: 0.144919; batch adversarial loss: 0.488803\n",
      "epoch 36; iter: 0; batch classifier loss: 0.097730; batch adversarial loss: 0.441879\n",
      "epoch 37; iter: 0; batch classifier loss: 0.098597; batch adversarial loss: 0.515463\n",
      "epoch 38; iter: 0; batch classifier loss: 0.098103; batch adversarial loss: 0.410716\n",
      "epoch 39; iter: 0; batch classifier loss: 0.068443; batch adversarial loss: 0.425178\n",
      "epoch 40; iter: 0; batch classifier loss: 0.075098; batch adversarial loss: 0.471647\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111006; batch adversarial loss: 0.487346\n",
      "epoch 42; iter: 0; batch classifier loss: 0.107573; batch adversarial loss: 0.530619\n",
      "epoch 43; iter: 0; batch classifier loss: 0.119934; batch adversarial loss: 0.472103\n",
      "epoch 44; iter: 0; batch classifier loss: 0.074177; batch adversarial loss: 0.459863\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097380; batch adversarial loss: 0.480295\n",
      "epoch 46; iter: 0; batch classifier loss: 0.093563; batch adversarial loss: 0.452202\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112052; batch adversarial loss: 0.421826\n",
      "epoch 48; iter: 0; batch classifier loss: 0.041898; batch adversarial loss: 0.581160\n",
      "epoch 49; iter: 0; batch classifier loss: 0.051137; batch adversarial loss: 0.456011\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084577; batch adversarial loss: 0.497467\n",
      "epoch 51; iter: 0; batch classifier loss: 0.090407; batch adversarial loss: 0.458795\n",
      "epoch 52; iter: 0; batch classifier loss: 0.175446; batch adversarial loss: 0.423991\n",
      "epoch 53; iter: 0; batch classifier loss: 0.121887; batch adversarial loss: 0.493487\n",
      "epoch 54; iter: 0; batch classifier loss: 0.109547; batch adversarial loss: 0.545307\n",
      "epoch 55; iter: 0; batch classifier loss: 0.121312; batch adversarial loss: 0.493527\n",
      "epoch 56; iter: 0; batch classifier loss: 0.130715; batch adversarial loss: 0.474106\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112951; batch adversarial loss: 0.489900\n",
      "epoch 58; iter: 0; batch classifier loss: 0.121213; batch adversarial loss: 0.490344\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072277; batch adversarial loss: 0.445494\n",
      "epoch 60; iter: 0; batch classifier loss: 0.120584; batch adversarial loss: 0.479720\n",
      "epoch 61; iter: 0; batch classifier loss: 0.095038; batch adversarial loss: 0.430370\n",
      "epoch 62; iter: 0; batch classifier loss: 0.067813; batch adversarial loss: 0.461131\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124007; batch adversarial loss: 0.525889\n",
      "epoch 64; iter: 0; batch classifier loss: 0.109827; batch adversarial loss: 0.407714\n",
      "epoch 65; iter: 0; batch classifier loss: 0.101636; batch adversarial loss: 0.471884\n",
      "epoch 66; iter: 0; batch classifier loss: 0.137577; batch adversarial loss: 0.566953\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056345; batch adversarial loss: 0.534140\n",
      "epoch 68; iter: 0; batch classifier loss: 0.088443; batch adversarial loss: 0.486968\n",
      "epoch 69; iter: 0; batch classifier loss: 0.058353; batch adversarial loss: 0.506093\n",
      "epoch 70; iter: 0; batch classifier loss: 0.133820; batch adversarial loss: 0.438614\n",
      "epoch 71; iter: 0; batch classifier loss: 0.133606; batch adversarial loss: 0.398203\n",
      "epoch 72; iter: 0; batch classifier loss: 0.101446; batch adversarial loss: 0.397360\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067594; batch adversarial loss: 0.519947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.091279; batch adversarial loss: 0.440450\n",
      "epoch 75; iter: 0; batch classifier loss: 0.105403; batch adversarial loss: 0.437769\n",
      "epoch 76; iter: 0; batch classifier loss: 0.090489; batch adversarial loss: 0.490348\n",
      "epoch 77; iter: 0; batch classifier loss: 0.098516; batch adversarial loss: 0.458054\n",
      "epoch 78; iter: 0; batch classifier loss: 0.106939; batch adversarial loss: 0.420182\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057018; batch adversarial loss: 0.402028\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084191; batch adversarial loss: 0.505150\n",
      "epoch 81; iter: 0; batch classifier loss: 0.102432; batch adversarial loss: 0.500598\n",
      "epoch 82; iter: 0; batch classifier loss: 0.125293; batch adversarial loss: 0.488580\n",
      "epoch 83; iter: 0; batch classifier loss: 0.111948; batch adversarial loss: 0.604486\n",
      "epoch 84; iter: 0; batch classifier loss: 0.090642; batch adversarial loss: 0.459052\n",
      "epoch 85; iter: 0; batch classifier loss: 0.108368; batch adversarial loss: 0.510331\n",
      "epoch 86; iter: 0; batch classifier loss: 0.104598; batch adversarial loss: 0.488236\n",
      "epoch 87; iter: 0; batch classifier loss: 0.077412; batch adversarial loss: 0.498022\n",
      "epoch 88; iter: 0; batch classifier loss: 0.086675; batch adversarial loss: 0.443295\n",
      "epoch 89; iter: 0; batch classifier loss: 0.077049; batch adversarial loss: 0.517906\n",
      "epoch 90; iter: 0; batch classifier loss: 0.150818; batch adversarial loss: 0.424373\n",
      "epoch 91; iter: 0; batch classifier loss: 0.114376; batch adversarial loss: 0.470476\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048980; batch adversarial loss: 0.491721\n",
      "epoch 93; iter: 0; batch classifier loss: 0.074174; batch adversarial loss: 0.515401\n",
      "epoch 94; iter: 0; batch classifier loss: 0.094781; batch adversarial loss: 0.398463\n",
      "epoch 95; iter: 0; batch classifier loss: 0.103830; batch adversarial loss: 0.416543\n",
      "epoch 96; iter: 0; batch classifier loss: 0.125428; batch adversarial loss: 0.396253\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044351; batch adversarial loss: 0.403523\n",
      "epoch 98; iter: 0; batch classifier loss: 0.089407; batch adversarial loss: 0.506038\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062437; batch adversarial loss: 0.424715\n",
      "epoch 100; iter: 0; batch classifier loss: 0.089619; batch adversarial loss: 0.492269\n",
      "epoch 101; iter: 0; batch classifier loss: 0.082559; batch adversarial loss: 0.447337\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063061; batch adversarial loss: 0.421218\n",
      "epoch 103; iter: 0; batch classifier loss: 0.082628; batch adversarial loss: 0.491123\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034333; batch adversarial loss: 0.517246\n",
      "epoch 105; iter: 0; batch classifier loss: 0.073618; batch adversarial loss: 0.528010\n",
      "epoch 106; iter: 0; batch classifier loss: 0.029375; batch adversarial loss: 0.505166\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037971; batch adversarial loss: 0.500348\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064412; batch adversarial loss: 0.530662\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046063; batch adversarial loss: 0.550353\n",
      "epoch 110; iter: 0; batch classifier loss: 0.093774; batch adversarial loss: 0.394687\n",
      "epoch 111; iter: 0; batch classifier loss: 0.077295; batch adversarial loss: 0.556467\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046140; batch adversarial loss: 0.351524\n",
      "epoch 113; iter: 0; batch classifier loss: 0.030104; batch adversarial loss: 0.515257\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035435; batch adversarial loss: 0.400769\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052888; batch adversarial loss: 0.523118\n",
      "epoch 116; iter: 0; batch classifier loss: 0.101386; batch adversarial loss: 0.556273\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037772; batch adversarial loss: 0.516096\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037702; batch adversarial loss: 0.482523\n",
      "epoch 119; iter: 0; batch classifier loss: 0.081164; batch adversarial loss: 0.366724\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020795; batch adversarial loss: 0.532304\n",
      "epoch 121; iter: 0; batch classifier loss: 0.093539; batch adversarial loss: 0.429805\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024261; batch adversarial loss: 0.537006\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040181; batch adversarial loss: 0.464094\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032273; batch adversarial loss: 0.439339\n",
      "epoch 125; iter: 0; batch classifier loss: 0.073022; batch adversarial loss: 0.424378\n",
      "epoch 126; iter: 0; batch classifier loss: 0.066910; batch adversarial loss: 0.472260\n",
      "epoch 127; iter: 0; batch classifier loss: 0.057281; batch adversarial loss: 0.494712\n",
      "epoch 128; iter: 0; batch classifier loss: 0.015635; batch adversarial loss: 0.488181\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022122; batch adversarial loss: 0.513007\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048951; batch adversarial loss: 0.453609\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029639; batch adversarial loss: 0.441308\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028973; batch adversarial loss: 0.479360\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037895; batch adversarial loss: 0.416722\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038847; batch adversarial loss: 0.375205\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041451; batch adversarial loss: 0.513846\n",
      "epoch 136; iter: 0; batch classifier loss: 0.065877; batch adversarial loss: 0.497899\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032303; batch adversarial loss: 0.451801\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044203; batch adversarial loss: 0.476189\n",
      "epoch 139; iter: 0; batch classifier loss: 0.072435; batch adversarial loss: 0.393005\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040226; batch adversarial loss: 0.500989\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020513; batch adversarial loss: 0.568583\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017880; batch adversarial loss: 0.556553\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053877; batch adversarial loss: 0.377393\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019293; batch adversarial loss: 0.552060\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020671; batch adversarial loss: 0.483178\n",
      "epoch 146; iter: 0; batch classifier loss: 0.077567; batch adversarial loss: 0.487648\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050339; batch adversarial loss: 0.546136\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026202; batch adversarial loss: 0.468965\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023503; batch adversarial loss: 0.577350\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036749; batch adversarial loss: 0.467533\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014888; batch adversarial loss: 0.399320\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028266; batch adversarial loss: 0.513828\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018506; batch adversarial loss: 0.403032\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030480; batch adversarial loss: 0.428384\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022516; batch adversarial loss: 0.512340\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031124; batch adversarial loss: 0.557684\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035394; batch adversarial loss: 0.449892\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023279; batch adversarial loss: 0.455926\n",
      "epoch 159; iter: 0; batch classifier loss: 0.047944; batch adversarial loss: 0.466102\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015356; batch adversarial loss: 0.567127\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029245; batch adversarial loss: 0.498940\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021339; batch adversarial loss: 0.424161\n",
      "epoch 163; iter: 0; batch classifier loss: 0.031031; batch adversarial loss: 0.447282\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010188; batch adversarial loss: 0.570653\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018416; batch adversarial loss: 0.456402\n",
      "epoch 166; iter: 0; batch classifier loss: 0.051177; batch adversarial loss: 0.535411\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036526; batch adversarial loss: 0.467220\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018334; batch adversarial loss: 0.459886\n",
      "epoch 169; iter: 0; batch classifier loss: 0.042259; batch adversarial loss: 0.426901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.029882; batch adversarial loss: 0.391746\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036193; batch adversarial loss: 0.556116\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035890; batch adversarial loss: 0.468911\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016624; batch adversarial loss: 0.525204\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020281; batch adversarial loss: 0.459034\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018904; batch adversarial loss: 0.401584\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016126; batch adversarial loss: 0.433826\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010074; batch adversarial loss: 0.535399\n",
      "epoch 178; iter: 0; batch classifier loss: 0.055955; batch adversarial loss: 0.531114\n",
      "epoch 179; iter: 0; batch classifier loss: 0.063352; batch adversarial loss: 0.529661\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021860; batch adversarial loss: 0.446825\n",
      "epoch 181; iter: 0; batch classifier loss: 0.045966; batch adversarial loss: 0.442614\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041454; batch adversarial loss: 0.478151\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013933; batch adversarial loss: 0.486466\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012199; batch adversarial loss: 0.453267\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010595; batch adversarial loss: 0.507079\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029852; batch adversarial loss: 0.415314\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032645; batch adversarial loss: 0.498341\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011995; batch adversarial loss: 0.462519\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007510; batch adversarial loss: 0.536719\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036158; batch adversarial loss: 0.468040\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017172; batch adversarial loss: 0.399896\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005262; batch adversarial loss: 0.448467\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016018; batch adversarial loss: 0.518838\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032729; batch adversarial loss: 0.483641\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021343; batch adversarial loss: 0.462869\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027928; batch adversarial loss: 0.574512\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029399; batch adversarial loss: 0.479423\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015799; batch adversarial loss: 0.400646\n",
      "epoch 199; iter: 0; batch classifier loss: 0.039515; batch adversarial loss: 0.442558\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711339; batch adversarial loss: 0.696693\n",
      "epoch 1; iter: 0; batch classifier loss: 0.444175; batch adversarial loss: 0.706144\n",
      "epoch 2; iter: 0; batch classifier loss: 0.394502; batch adversarial loss: 0.654132\n",
      "epoch 3; iter: 0; batch classifier loss: 0.358932; batch adversarial loss: 0.652902\n",
      "epoch 4; iter: 0; batch classifier loss: 0.444291; batch adversarial loss: 0.556879\n",
      "epoch 5; iter: 0; batch classifier loss: 0.275225; batch adversarial loss: 0.599476\n",
      "epoch 6; iter: 0; batch classifier loss: 0.270262; batch adversarial loss: 0.525799\n",
      "epoch 7; iter: 0; batch classifier loss: 0.290821; batch adversarial loss: 0.550368\n",
      "epoch 8; iter: 0; batch classifier loss: 0.239092; batch adversarial loss: 0.525005\n",
      "epoch 9; iter: 0; batch classifier loss: 0.295831; batch adversarial loss: 0.495376\n",
      "epoch 10; iter: 0; batch classifier loss: 0.232002; batch adversarial loss: 0.454642\n",
      "epoch 11; iter: 0; batch classifier loss: 0.293643; batch adversarial loss: 0.490541\n",
      "epoch 12; iter: 0; batch classifier loss: 0.314452; batch adversarial loss: 0.467053\n",
      "epoch 13; iter: 0; batch classifier loss: 0.160798; batch adversarial loss: 0.468190\n",
      "epoch 14; iter: 0; batch classifier loss: 0.169294; batch adversarial loss: 0.476962\n",
      "epoch 15; iter: 0; batch classifier loss: 0.196390; batch adversarial loss: 0.451435\n",
      "epoch 16; iter: 0; batch classifier loss: 0.143972; batch adversarial loss: 0.474176\n",
      "epoch 17; iter: 0; batch classifier loss: 0.115205; batch adversarial loss: 0.436509\n",
      "epoch 18; iter: 0; batch classifier loss: 0.177409; batch adversarial loss: 0.493775\n",
      "epoch 19; iter: 0; batch classifier loss: 0.181204; batch adversarial loss: 0.469549\n",
      "epoch 20; iter: 0; batch classifier loss: 0.163228; batch adversarial loss: 0.434192\n",
      "epoch 21; iter: 0; batch classifier loss: 0.145389; batch adversarial loss: 0.435895\n",
      "epoch 22; iter: 0; batch classifier loss: 0.157597; batch adversarial loss: 0.535122\n",
      "epoch 23; iter: 0; batch classifier loss: 0.208808; batch adversarial loss: 0.483603\n",
      "epoch 24; iter: 0; batch classifier loss: 0.144603; batch adversarial loss: 0.507750\n",
      "epoch 25; iter: 0; batch classifier loss: 0.170156; batch adversarial loss: 0.527322\n",
      "epoch 26; iter: 0; batch classifier loss: 0.148436; batch adversarial loss: 0.496409\n",
      "epoch 27; iter: 0; batch classifier loss: 0.239728; batch adversarial loss: 0.570040\n",
      "epoch 28; iter: 0; batch classifier loss: 0.150776; batch adversarial loss: 0.510412\n",
      "epoch 29; iter: 0; batch classifier loss: 0.239781; batch adversarial loss: 0.550681\n",
      "epoch 30; iter: 0; batch classifier loss: 0.187712; batch adversarial loss: 0.498564\n",
      "epoch 31; iter: 0; batch classifier loss: 0.189072; batch adversarial loss: 0.528692\n",
      "epoch 32; iter: 0; batch classifier loss: 0.241797; batch adversarial loss: 0.508217\n",
      "epoch 33; iter: 0; batch classifier loss: 0.249672; batch adversarial loss: 0.487662\n",
      "epoch 34; iter: 0; batch classifier loss: 0.206457; batch adversarial loss: 0.409807\n",
      "epoch 35; iter: 0; batch classifier loss: 0.116183; batch adversarial loss: 0.427341\n",
      "epoch 36; iter: 0; batch classifier loss: 0.166346; batch adversarial loss: 0.518947\n",
      "epoch 37; iter: 0; batch classifier loss: 0.212275; batch adversarial loss: 0.503084\n",
      "epoch 38; iter: 0; batch classifier loss: 0.221321; batch adversarial loss: 0.469183\n",
      "epoch 39; iter: 0; batch classifier loss: 0.234369; batch adversarial loss: 0.487261\n",
      "epoch 40; iter: 0; batch classifier loss: 0.235412; batch adversarial loss: 0.448082\n",
      "epoch 41; iter: 0; batch classifier loss: 0.164474; batch adversarial loss: 0.433691\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103038; batch adversarial loss: 0.474605\n",
      "epoch 43; iter: 0; batch classifier loss: 0.079810; batch adversarial loss: 0.472637\n",
      "epoch 44; iter: 0; batch classifier loss: 0.042352; batch adversarial loss: 0.458171\n",
      "epoch 45; iter: 0; batch classifier loss: 0.112220; batch adversarial loss: 0.458833\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103248; batch adversarial loss: 0.426286\n",
      "epoch 47; iter: 0; batch classifier loss: 0.097878; batch adversarial loss: 0.435062\n",
      "epoch 48; iter: 0; batch classifier loss: 0.078112; batch adversarial loss: 0.555296\n",
      "epoch 49; iter: 0; batch classifier loss: 0.065208; batch adversarial loss: 0.370597\n",
      "epoch 50; iter: 0; batch classifier loss: 0.067047; batch adversarial loss: 0.538546\n",
      "epoch 51; iter: 0; batch classifier loss: 0.072660; batch adversarial loss: 0.486348\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089653; batch adversarial loss: 0.418269\n",
      "epoch 53; iter: 0; batch classifier loss: 0.081561; batch adversarial loss: 0.450101\n",
      "epoch 54; iter: 0; batch classifier loss: 0.040691; batch adversarial loss: 0.502252\n",
      "epoch 55; iter: 0; batch classifier loss: 0.060467; batch adversarial loss: 0.468301\n",
      "epoch 56; iter: 0; batch classifier loss: 0.117066; batch adversarial loss: 0.418931\n",
      "epoch 57; iter: 0; batch classifier loss: 0.048033; batch adversarial loss: 0.479411\n",
      "epoch 58; iter: 0; batch classifier loss: 0.074106; batch adversarial loss: 0.599190\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105319; batch adversarial loss: 0.416771\n",
      "epoch 60; iter: 0; batch classifier loss: 0.080943; batch adversarial loss: 0.408720\n",
      "epoch 61; iter: 0; batch classifier loss: 0.086445; batch adversarial loss: 0.505550\n",
      "epoch 62; iter: 0; batch classifier loss: 0.043801; batch adversarial loss: 0.418336\n",
      "epoch 63; iter: 0; batch classifier loss: 0.044206; batch adversarial loss: 0.645706\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080523; batch adversarial loss: 0.426330\n",
      "epoch 65; iter: 0; batch classifier loss: 0.060186; batch adversarial loss: 0.486207\n",
      "epoch 66; iter: 0; batch classifier loss: 0.057120; batch adversarial loss: 0.537854\n",
      "epoch 67; iter: 0; batch classifier loss: 0.068567; batch adversarial loss: 0.500209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.066554; batch adversarial loss: 0.403013\n",
      "epoch 69; iter: 0; batch classifier loss: 0.111882; batch adversarial loss: 0.541119\n",
      "epoch 70; iter: 0; batch classifier loss: 0.084840; batch adversarial loss: 0.395025\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078877; batch adversarial loss: 0.493871\n",
      "epoch 72; iter: 0; batch classifier loss: 0.128864; batch adversarial loss: 0.480050\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062998; batch adversarial loss: 0.526834\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069785; batch adversarial loss: 0.367475\n",
      "epoch 75; iter: 0; batch classifier loss: 0.087240; batch adversarial loss: 0.361450\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063675; batch adversarial loss: 0.542275\n",
      "epoch 77; iter: 0; batch classifier loss: 0.040374; batch adversarial loss: 0.465074\n",
      "epoch 78; iter: 0; batch classifier loss: 0.058751; batch adversarial loss: 0.475521\n",
      "epoch 79; iter: 0; batch classifier loss: 0.037166; batch adversarial loss: 0.477933\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061096; batch adversarial loss: 0.429550\n",
      "epoch 81; iter: 0; batch classifier loss: 0.027758; batch adversarial loss: 0.500716\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073408; batch adversarial loss: 0.437914\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063917; batch adversarial loss: 0.458024\n",
      "epoch 84; iter: 0; batch classifier loss: 0.057455; batch adversarial loss: 0.535719\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052843; batch adversarial loss: 0.432202\n",
      "epoch 86; iter: 0; batch classifier loss: 0.060803; batch adversarial loss: 0.364768\n",
      "epoch 87; iter: 0; batch classifier loss: 0.052349; batch adversarial loss: 0.515388\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058214; batch adversarial loss: 0.512108\n",
      "epoch 89; iter: 0; batch classifier loss: 0.031786; batch adversarial loss: 0.478404\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047492; batch adversarial loss: 0.495631\n",
      "epoch 91; iter: 0; batch classifier loss: 0.072094; batch adversarial loss: 0.402652\n",
      "epoch 92; iter: 0; batch classifier loss: 0.100436; batch adversarial loss: 0.459957\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050853; batch adversarial loss: 0.447461\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050373; batch adversarial loss: 0.480966\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077751; batch adversarial loss: 0.424422\n",
      "epoch 96; iter: 0; batch classifier loss: 0.032841; batch adversarial loss: 0.488715\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066942; batch adversarial loss: 0.477448\n",
      "epoch 98; iter: 0; batch classifier loss: 0.032063; batch adversarial loss: 0.403438\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073395; batch adversarial loss: 0.524442\n",
      "epoch 100; iter: 0; batch classifier loss: 0.021430; batch adversarial loss: 0.484340\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058684; batch adversarial loss: 0.414103\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046487; batch adversarial loss: 0.489982\n",
      "epoch 103; iter: 0; batch classifier loss: 0.030670; batch adversarial loss: 0.465466\n",
      "epoch 104; iter: 0; batch classifier loss: 0.079058; batch adversarial loss: 0.483944\n",
      "epoch 105; iter: 0; batch classifier loss: 0.087545; batch adversarial loss: 0.456177\n",
      "epoch 106; iter: 0; batch classifier loss: 0.070985; batch adversarial loss: 0.435067\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038517; batch adversarial loss: 0.517774\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039299; batch adversarial loss: 0.482204\n",
      "epoch 109; iter: 0; batch classifier loss: 0.020469; batch adversarial loss: 0.450172\n",
      "epoch 110; iter: 0; batch classifier loss: 0.108802; batch adversarial loss: 0.477341\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051058; batch adversarial loss: 0.489450\n",
      "epoch 112; iter: 0; batch classifier loss: 0.020021; batch adversarial loss: 0.461152\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027173; batch adversarial loss: 0.521919\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027937; batch adversarial loss: 0.477179\n",
      "epoch 115; iter: 0; batch classifier loss: 0.091940; batch adversarial loss: 0.434919\n",
      "epoch 116; iter: 0; batch classifier loss: 0.019662; batch adversarial loss: 0.524940\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044592; batch adversarial loss: 0.468184\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047611; batch adversarial loss: 0.396768\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037564; batch adversarial loss: 0.580951\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020075; batch adversarial loss: 0.432085\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047129; batch adversarial loss: 0.479395\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026838; batch adversarial loss: 0.471196\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036428; batch adversarial loss: 0.535280\n",
      "epoch 124; iter: 0; batch classifier loss: 0.081659; batch adversarial loss: 0.480741\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050656; batch adversarial loss: 0.485760\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017731; batch adversarial loss: 0.496711\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045771; batch adversarial loss: 0.514062\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041417; batch adversarial loss: 0.464730\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051096; batch adversarial loss: 0.414199\n",
      "epoch 130; iter: 0; batch classifier loss: 0.054881; batch adversarial loss: 0.510673\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040453; batch adversarial loss: 0.410115\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038665; batch adversarial loss: 0.504081\n",
      "epoch 133; iter: 0; batch classifier loss: 0.069000; batch adversarial loss: 0.475242\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048780; batch adversarial loss: 0.416158\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033775; batch adversarial loss: 0.447754\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047184; batch adversarial loss: 0.356067\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027531; batch adversarial loss: 0.440407\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032761; batch adversarial loss: 0.533756\n",
      "epoch 139; iter: 0; batch classifier loss: 0.070675; batch adversarial loss: 0.469289\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050415; batch adversarial loss: 0.571421\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018406; batch adversarial loss: 0.463613\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040984; batch adversarial loss: 0.456410\n",
      "epoch 143; iter: 0; batch classifier loss: 0.012540; batch adversarial loss: 0.428527\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032087; batch adversarial loss: 0.481199\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019594; batch adversarial loss: 0.540456\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020061; batch adversarial loss: 0.474161\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044694; batch adversarial loss: 0.454572\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022530; batch adversarial loss: 0.423088\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015088; batch adversarial loss: 0.427861\n",
      "epoch 150; iter: 0; batch classifier loss: 0.056784; batch adversarial loss: 0.435519\n",
      "epoch 151; iter: 0; batch classifier loss: 0.052277; batch adversarial loss: 0.436106\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026033; batch adversarial loss: 0.410859\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019892; batch adversarial loss: 0.395082\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044967; batch adversarial loss: 0.358062\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012498; batch adversarial loss: 0.474299\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011213; batch adversarial loss: 0.369809\n",
      "epoch 157; iter: 0; batch classifier loss: 0.048846; batch adversarial loss: 0.459051\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034671; batch adversarial loss: 0.459307\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035315; batch adversarial loss: 0.480112\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015080; batch adversarial loss: 0.461259\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014843; batch adversarial loss: 0.410196\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025455; batch adversarial loss: 0.495774\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023813; batch adversarial loss: 0.437004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.011758; batch adversarial loss: 0.451613\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032440; batch adversarial loss: 0.435053\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012147; batch adversarial loss: 0.492637\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035572; batch adversarial loss: 0.466422\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011489; batch adversarial loss: 0.472367\n",
      "epoch 169; iter: 0; batch classifier loss: 0.039692; batch adversarial loss: 0.393788\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028408; batch adversarial loss: 0.478517\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014471; batch adversarial loss: 0.353254\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026331; batch adversarial loss: 0.502462\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040500; batch adversarial loss: 0.436374\n",
      "epoch 174; iter: 0; batch classifier loss: 0.044154; batch adversarial loss: 0.451218\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013961; batch adversarial loss: 0.568939\n",
      "epoch 176; iter: 0; batch classifier loss: 0.036965; batch adversarial loss: 0.423442\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034863; batch adversarial loss: 0.392507\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019295; batch adversarial loss: 0.395987\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033517; batch adversarial loss: 0.465255\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019259; batch adversarial loss: 0.427067\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013865; batch adversarial loss: 0.403990\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009434; batch adversarial loss: 0.512476\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032501; batch adversarial loss: 0.458596\n",
      "epoch 184; iter: 0; batch classifier loss: 0.042271; batch adversarial loss: 0.494449\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015638; batch adversarial loss: 0.446734\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021971; batch adversarial loss: 0.462169\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022310; batch adversarial loss: 0.410377\n",
      "epoch 188; iter: 0; batch classifier loss: 0.052032; batch adversarial loss: 0.430062\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015526; batch adversarial loss: 0.387941\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014501; batch adversarial loss: 0.488740\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016271; batch adversarial loss: 0.488198\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033156; batch adversarial loss: 0.384877\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014716; batch adversarial loss: 0.466688\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011912; batch adversarial loss: 0.457775\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016271; batch adversarial loss: 0.456091\n",
      "epoch 196; iter: 0; batch classifier loss: 0.054140; batch adversarial loss: 0.474170\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020894; batch adversarial loss: 0.410346\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002424; batch adversarial loss: 0.543548\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024077; batch adversarial loss: 0.479292\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704296; batch adversarial loss: 0.746895\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433076; batch adversarial loss: 0.710588\n",
      "epoch 2; iter: 0; batch classifier loss: 0.439285; batch adversarial loss: 0.675740\n",
      "epoch 3; iter: 0; batch classifier loss: 0.360684; batch adversarial loss: 0.643188\n",
      "epoch 4; iter: 0; batch classifier loss: 0.399127; batch adversarial loss: 0.633663\n",
      "epoch 5; iter: 0; batch classifier loss: 0.279847; batch adversarial loss: 0.592370\n",
      "epoch 6; iter: 0; batch classifier loss: 0.401293; batch adversarial loss: 0.547163\n",
      "epoch 7; iter: 0; batch classifier loss: 0.257576; batch adversarial loss: 0.552101\n",
      "epoch 8; iter: 0; batch classifier loss: 0.281665; batch adversarial loss: 0.500995\n",
      "epoch 9; iter: 0; batch classifier loss: 0.307605; batch adversarial loss: 0.498609\n",
      "epoch 10; iter: 0; batch classifier loss: 0.313633; batch adversarial loss: 0.483261\n",
      "epoch 11; iter: 0; batch classifier loss: 0.257576; batch adversarial loss: 0.490402\n",
      "epoch 12; iter: 0; batch classifier loss: 0.171497; batch adversarial loss: 0.457988\n",
      "epoch 13; iter: 0; batch classifier loss: 0.217398; batch adversarial loss: 0.440172\n",
      "epoch 14; iter: 0; batch classifier loss: 0.232067; batch adversarial loss: 0.475973\n",
      "epoch 15; iter: 0; batch classifier loss: 0.190011; batch adversarial loss: 0.483879\n",
      "epoch 16; iter: 0; batch classifier loss: 0.256970; batch adversarial loss: 0.435719\n",
      "epoch 17; iter: 0; batch classifier loss: 0.196695; batch adversarial loss: 0.447919\n",
      "epoch 18; iter: 0; batch classifier loss: 0.181655; batch adversarial loss: 0.465706\n",
      "epoch 19; iter: 0; batch classifier loss: 0.169470; batch adversarial loss: 0.481655\n",
      "epoch 20; iter: 0; batch classifier loss: 0.146336; batch adversarial loss: 0.492501\n",
      "epoch 21; iter: 0; batch classifier loss: 0.205060; batch adversarial loss: 0.522775\n",
      "epoch 22; iter: 0; batch classifier loss: 0.169774; batch adversarial loss: 0.478246\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203984; batch adversarial loss: 0.416933\n",
      "epoch 24; iter: 0; batch classifier loss: 0.196965; batch adversarial loss: 0.462983\n",
      "epoch 25; iter: 0; batch classifier loss: 0.197954; batch adversarial loss: 0.511956\n",
      "epoch 26; iter: 0; batch classifier loss: 0.217844; batch adversarial loss: 0.547516\n",
      "epoch 27; iter: 0; batch classifier loss: 0.177584; batch adversarial loss: 0.447640\n",
      "epoch 28; iter: 0; batch classifier loss: 0.241701; batch adversarial loss: 0.472322\n",
      "epoch 29; iter: 0; batch classifier loss: 0.267373; batch adversarial loss: 0.455279\n",
      "epoch 30; iter: 0; batch classifier loss: 0.230591; batch adversarial loss: 0.439581\n",
      "epoch 31; iter: 0; batch classifier loss: 0.429656; batch adversarial loss: 0.479340\n",
      "epoch 32; iter: 0; batch classifier loss: 0.275131; batch adversarial loss: 0.404092\n",
      "epoch 33; iter: 0; batch classifier loss: 0.124796; batch adversarial loss: 0.501267\n",
      "epoch 34; iter: 0; batch classifier loss: 0.110902; batch adversarial loss: 0.464715\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125753; batch adversarial loss: 0.403699\n",
      "epoch 36; iter: 0; batch classifier loss: 0.129890; batch adversarial loss: 0.429826\n",
      "epoch 37; iter: 0; batch classifier loss: 0.115846; batch adversarial loss: 0.382236\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107255; batch adversarial loss: 0.456511\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118665; batch adversarial loss: 0.480704\n",
      "epoch 40; iter: 0; batch classifier loss: 0.109850; batch adversarial loss: 0.518214\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142013; batch adversarial loss: 0.422867\n",
      "epoch 42; iter: 0; batch classifier loss: 0.078130; batch adversarial loss: 0.417149\n",
      "epoch 43; iter: 0; batch classifier loss: 0.114478; batch adversarial loss: 0.442048\n",
      "epoch 44; iter: 0; batch classifier loss: 0.100582; batch adversarial loss: 0.518986\n",
      "epoch 45; iter: 0; batch classifier loss: 0.090598; batch adversarial loss: 0.359562\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102723; batch adversarial loss: 0.453258\n",
      "epoch 47; iter: 0; batch classifier loss: 0.060697; batch adversarial loss: 0.482241\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100322; batch adversarial loss: 0.468303\n",
      "epoch 49; iter: 0; batch classifier loss: 0.115802; batch adversarial loss: 0.402658\n",
      "epoch 50; iter: 0; batch classifier loss: 0.081407; batch adversarial loss: 0.506741\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100043; batch adversarial loss: 0.442114\n",
      "epoch 52; iter: 0; batch classifier loss: 0.094110; batch adversarial loss: 0.455667\n",
      "epoch 53; iter: 0; batch classifier loss: 0.066369; batch adversarial loss: 0.378787\n",
      "epoch 54; iter: 0; batch classifier loss: 0.081388; batch adversarial loss: 0.377741\n",
      "epoch 55; iter: 0; batch classifier loss: 0.067476; batch adversarial loss: 0.435169\n",
      "epoch 56; iter: 0; batch classifier loss: 0.117721; batch adversarial loss: 0.375807\n",
      "epoch 57; iter: 0; batch classifier loss: 0.121328; batch adversarial loss: 0.355024\n",
      "epoch 58; iter: 0; batch classifier loss: 0.122234; batch adversarial loss: 0.489484\n",
      "epoch 59; iter: 0; batch classifier loss: 0.141456; batch adversarial loss: 0.417397\n",
      "epoch 60; iter: 0; batch classifier loss: 0.108102; batch adversarial loss: 0.495823\n",
      "epoch 61; iter: 0; batch classifier loss: 0.076607; batch adversarial loss: 0.438434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.063628; batch adversarial loss: 0.500251\n",
      "epoch 63; iter: 0; batch classifier loss: 0.055118; batch adversarial loss: 0.482633\n",
      "epoch 64; iter: 0; batch classifier loss: 0.058916; batch adversarial loss: 0.487790\n",
      "epoch 65; iter: 0; batch classifier loss: 0.072362; batch adversarial loss: 0.496542\n",
      "epoch 66; iter: 0; batch classifier loss: 0.059498; batch adversarial loss: 0.440896\n",
      "epoch 67; iter: 0; batch classifier loss: 0.058737; batch adversarial loss: 0.570510\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071470; batch adversarial loss: 0.561202\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078803; batch adversarial loss: 0.443325\n",
      "epoch 70; iter: 0; batch classifier loss: 0.093402; batch adversarial loss: 0.415669\n",
      "epoch 71; iter: 0; batch classifier loss: 0.036689; batch adversarial loss: 0.481160\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071456; batch adversarial loss: 0.486162\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079848; batch adversarial loss: 0.484374\n",
      "epoch 74; iter: 0; batch classifier loss: 0.099710; batch adversarial loss: 0.402962\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069210; batch adversarial loss: 0.494098\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055694; batch adversarial loss: 0.439964\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065665; batch adversarial loss: 0.423800\n",
      "epoch 78; iter: 0; batch classifier loss: 0.060607; batch adversarial loss: 0.490354\n",
      "epoch 79; iter: 0; batch classifier loss: 0.039257; batch adversarial loss: 0.442108\n",
      "epoch 80; iter: 0; batch classifier loss: 0.051420; batch adversarial loss: 0.368297\n",
      "epoch 81; iter: 0; batch classifier loss: 0.091193; batch adversarial loss: 0.429773\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074232; batch adversarial loss: 0.390842\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062312; batch adversarial loss: 0.425289\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065628; batch adversarial loss: 0.423912\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059477; batch adversarial loss: 0.516911\n",
      "epoch 86; iter: 0; batch classifier loss: 0.097895; batch adversarial loss: 0.426264\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062995; batch adversarial loss: 0.594018\n",
      "epoch 88; iter: 0; batch classifier loss: 0.068760; batch adversarial loss: 0.455246\n",
      "epoch 89; iter: 0; batch classifier loss: 0.070788; batch adversarial loss: 0.445113\n",
      "epoch 90; iter: 0; batch classifier loss: 0.069438; batch adversarial loss: 0.505822\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071429; batch adversarial loss: 0.429966\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043092; batch adversarial loss: 0.426467\n",
      "epoch 93; iter: 0; batch classifier loss: 0.040419; batch adversarial loss: 0.543636\n",
      "epoch 94; iter: 0; batch classifier loss: 0.177036; batch adversarial loss: 0.457176\n",
      "epoch 95; iter: 0; batch classifier loss: 0.049486; batch adversarial loss: 0.475835\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051443; batch adversarial loss: 0.456132\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063818; batch adversarial loss: 0.498275\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067109; batch adversarial loss: 0.439731\n",
      "epoch 99; iter: 0; batch classifier loss: 0.066111; batch adversarial loss: 0.449740\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065083; batch adversarial loss: 0.445149\n",
      "epoch 101; iter: 0; batch classifier loss: 0.076589; batch adversarial loss: 0.448824\n",
      "epoch 102; iter: 0; batch classifier loss: 0.101329; batch adversarial loss: 0.465886\n",
      "epoch 103; iter: 0; batch classifier loss: 0.051469; batch adversarial loss: 0.431516\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044464; batch adversarial loss: 0.466187\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055895; batch adversarial loss: 0.395950\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040157; batch adversarial loss: 0.450586\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028624; batch adversarial loss: 0.407277\n",
      "epoch 108; iter: 0; batch classifier loss: 0.074823; batch adversarial loss: 0.451556\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046304; batch adversarial loss: 0.449052\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060800; batch adversarial loss: 0.360840\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053124; batch adversarial loss: 0.488968\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037321; batch adversarial loss: 0.443475\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033839; batch adversarial loss: 0.492834\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049088; batch adversarial loss: 0.389560\n",
      "epoch 115; iter: 0; batch classifier loss: 0.013518; batch adversarial loss: 0.388972\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032138; batch adversarial loss: 0.536568\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048244; batch adversarial loss: 0.515218\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041660; batch adversarial loss: 0.546410\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036730; batch adversarial loss: 0.470662\n",
      "epoch 120; iter: 0; batch classifier loss: 0.069192; batch adversarial loss: 0.453490\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052769; batch adversarial loss: 0.566139\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052929; batch adversarial loss: 0.592322\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044887; batch adversarial loss: 0.348663\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044716; batch adversarial loss: 0.367358\n",
      "epoch 125; iter: 0; batch classifier loss: 0.063039; batch adversarial loss: 0.489570\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033880; batch adversarial loss: 0.473367\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040788; batch adversarial loss: 0.413347\n",
      "epoch 128; iter: 0; batch classifier loss: 0.084493; batch adversarial loss: 0.426224\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018697; batch adversarial loss: 0.430994\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024674; batch adversarial loss: 0.475800\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027847; batch adversarial loss: 0.426064\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029761; batch adversarial loss: 0.559156\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034890; batch adversarial loss: 0.397282\n",
      "epoch 134; iter: 0; batch classifier loss: 0.064042; batch adversarial loss: 0.438691\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047049; batch adversarial loss: 0.405079\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040605; batch adversarial loss: 0.519500\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028060; batch adversarial loss: 0.452935\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028052; batch adversarial loss: 0.411300\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020966; batch adversarial loss: 0.427271\n",
      "epoch 140; iter: 0; batch classifier loss: 0.058282; batch adversarial loss: 0.422922\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017915; batch adversarial loss: 0.528299\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043058; batch adversarial loss: 0.487909\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034948; batch adversarial loss: 0.499532\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023298; batch adversarial loss: 0.441626\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015871; batch adversarial loss: 0.443751\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022755; batch adversarial loss: 0.449361\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019530; batch adversarial loss: 0.485346\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023353; batch adversarial loss: 0.396525\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035010; batch adversarial loss: 0.393447\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019339; batch adversarial loss: 0.536086\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037086; batch adversarial loss: 0.434825\n",
      "epoch 152; iter: 0; batch classifier loss: 0.056418; batch adversarial loss: 0.460535\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040218; batch adversarial loss: 0.371643\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030540; batch adversarial loss: 0.387622\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027958; batch adversarial loss: 0.510644\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023317; batch adversarial loss: 0.348965\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035947; batch adversarial loss: 0.400251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.021595; batch adversarial loss: 0.569125\n",
      "epoch 159; iter: 0; batch classifier loss: 0.044336; batch adversarial loss: 0.493245\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033426; batch adversarial loss: 0.449881\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013847; batch adversarial loss: 0.470111\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026898; batch adversarial loss: 0.409286\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037780; batch adversarial loss: 0.459757\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017147; batch adversarial loss: 0.323844\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025419; batch adversarial loss: 0.450205\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028349; batch adversarial loss: 0.473256\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035820; batch adversarial loss: 0.501781\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018770; batch adversarial loss: 0.457089\n",
      "epoch 169; iter: 0; batch classifier loss: 0.054199; batch adversarial loss: 0.470958\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025002; batch adversarial loss: 0.433541\n",
      "epoch 171; iter: 0; batch classifier loss: 0.041584; batch adversarial loss: 0.421543\n",
      "epoch 172; iter: 0; batch classifier loss: 0.055342; batch adversarial loss: 0.392261\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042993; batch adversarial loss: 0.435179\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025908; batch adversarial loss: 0.493589\n",
      "epoch 175; iter: 0; batch classifier loss: 0.046901; batch adversarial loss: 0.428937\n",
      "epoch 176; iter: 0; batch classifier loss: 0.038031; batch adversarial loss: 0.400540\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029420; batch adversarial loss: 0.463649\n",
      "epoch 178; iter: 0; batch classifier loss: 0.047074; batch adversarial loss: 0.448002\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017699; batch adversarial loss: 0.489508\n",
      "epoch 180; iter: 0; batch classifier loss: 0.042605; batch adversarial loss: 0.422747\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026734; batch adversarial loss: 0.527951\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030396; batch adversarial loss: 0.472138\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018906; batch adversarial loss: 0.459724\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030705; batch adversarial loss: 0.372612\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022682; batch adversarial loss: 0.307742\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007157; batch adversarial loss: 0.472834\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019223; batch adversarial loss: 0.449201\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032668; batch adversarial loss: 0.468943\n",
      "epoch 189; iter: 0; batch classifier loss: 0.042819; batch adversarial loss: 0.406708\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014165; batch adversarial loss: 0.345441\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015961; batch adversarial loss: 0.448758\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024429; batch adversarial loss: 0.513671\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026985; batch adversarial loss: 0.470244\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026185; batch adversarial loss: 0.379424\n",
      "epoch 195; iter: 0; batch classifier loss: 0.038457; batch adversarial loss: 0.499923\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013589; batch adversarial loss: 0.420306\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022772; batch adversarial loss: 0.419757\n",
      "epoch 198; iter: 0; batch classifier loss: 0.033269; batch adversarial loss: 0.469828\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032213; batch adversarial loss: 0.517685\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696818; batch adversarial loss: 0.734346\n",
      "epoch 1; iter: 0; batch classifier loss: 0.502637; batch adversarial loss: 0.685388\n",
      "epoch 2; iter: 0; batch classifier loss: 0.422935; batch adversarial loss: 0.638983\n",
      "epoch 3; iter: 0; batch classifier loss: 0.398542; batch adversarial loss: 0.608878\n",
      "epoch 4; iter: 0; batch classifier loss: 0.408271; batch adversarial loss: 0.607699\n",
      "epoch 5; iter: 0; batch classifier loss: 0.460645; batch adversarial loss: 0.579604\n",
      "epoch 6; iter: 0; batch classifier loss: 0.328102; batch adversarial loss: 0.589729\n",
      "epoch 7; iter: 0; batch classifier loss: 0.402876; batch adversarial loss: 0.543701\n",
      "epoch 8; iter: 0; batch classifier loss: 0.376999; batch adversarial loss: 0.572391\n",
      "epoch 9; iter: 0; batch classifier loss: 0.340345; batch adversarial loss: 0.550120\n",
      "epoch 10; iter: 0; batch classifier loss: 0.379763; batch adversarial loss: 0.567711\n",
      "epoch 11; iter: 0; batch classifier loss: 0.280129; batch adversarial loss: 0.531457\n",
      "epoch 12; iter: 0; batch classifier loss: 0.349567; batch adversarial loss: 0.524812\n",
      "epoch 13; iter: 0; batch classifier loss: 0.317675; batch adversarial loss: 0.517561\n",
      "epoch 14; iter: 0; batch classifier loss: 0.372708; batch adversarial loss: 0.488195\n",
      "epoch 15; iter: 0; batch classifier loss: 0.297134; batch adversarial loss: 0.452883\n",
      "epoch 16; iter: 0; batch classifier loss: 0.323813; batch adversarial loss: 0.535135\n",
      "epoch 17; iter: 0; batch classifier loss: 0.418499; batch adversarial loss: 0.503597\n",
      "epoch 18; iter: 0; batch classifier loss: 0.337845; batch adversarial loss: 0.497305\n",
      "epoch 19; iter: 0; batch classifier loss: 0.298435; batch adversarial loss: 0.467140\n",
      "epoch 20; iter: 0; batch classifier loss: 0.294791; batch adversarial loss: 0.485614\n",
      "epoch 21; iter: 0; batch classifier loss: 0.369017; batch adversarial loss: 0.429089\n",
      "epoch 22; iter: 0; batch classifier loss: 0.313050; batch adversarial loss: 0.495675\n",
      "epoch 23; iter: 0; batch classifier loss: 0.247256; batch adversarial loss: 0.508150\n",
      "epoch 24; iter: 0; batch classifier loss: 0.251913; batch adversarial loss: 0.594729\n",
      "epoch 25; iter: 0; batch classifier loss: 0.262229; batch adversarial loss: 0.559602\n",
      "epoch 26; iter: 0; batch classifier loss: 0.209738; batch adversarial loss: 0.457037\n",
      "epoch 27; iter: 0; batch classifier loss: 0.304000; batch adversarial loss: 0.417965\n",
      "epoch 28; iter: 0; batch classifier loss: 0.262496; batch adversarial loss: 0.494954\n",
      "epoch 29; iter: 0; batch classifier loss: 0.249316; batch adversarial loss: 0.475158\n",
      "epoch 30; iter: 0; batch classifier loss: 0.223811; batch adversarial loss: 0.464729\n",
      "epoch 31; iter: 0; batch classifier loss: 0.254404; batch adversarial loss: 0.455441\n",
      "epoch 32; iter: 0; batch classifier loss: 0.228585; batch adversarial loss: 0.518764\n",
      "epoch 33; iter: 0; batch classifier loss: 0.278022; batch adversarial loss: 0.419980\n",
      "epoch 34; iter: 0; batch classifier loss: 0.182618; batch adversarial loss: 0.525653\n",
      "epoch 35; iter: 0; batch classifier loss: 0.267415; batch adversarial loss: 0.467631\n",
      "epoch 36; iter: 0; batch classifier loss: 0.192380; batch adversarial loss: 0.452579\n",
      "epoch 37; iter: 0; batch classifier loss: 0.232062; batch adversarial loss: 0.503803\n",
      "epoch 38; iter: 0; batch classifier loss: 0.229312; batch adversarial loss: 0.414673\n",
      "epoch 39; iter: 0; batch classifier loss: 0.142338; batch adversarial loss: 0.477686\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154650; batch adversarial loss: 0.496544\n",
      "epoch 41; iter: 0; batch classifier loss: 0.204865; batch adversarial loss: 0.382646\n",
      "epoch 42; iter: 0; batch classifier loss: 0.232994; batch adversarial loss: 0.505294\n",
      "epoch 43; iter: 0; batch classifier loss: 0.285431; batch adversarial loss: 0.440178\n",
      "epoch 44; iter: 0; batch classifier loss: 0.174848; batch adversarial loss: 0.507609\n",
      "epoch 45; iter: 0; batch classifier loss: 0.202694; batch adversarial loss: 0.463518\n",
      "epoch 46; iter: 0; batch classifier loss: 0.226606; batch adversarial loss: 0.534340\n",
      "epoch 47; iter: 0; batch classifier loss: 0.233414; batch adversarial loss: 0.380037\n",
      "epoch 48; iter: 0; batch classifier loss: 0.231643; batch adversarial loss: 0.472342\n",
      "epoch 49; iter: 0; batch classifier loss: 0.171176; batch adversarial loss: 0.543069\n",
      "epoch 50; iter: 0; batch classifier loss: 0.143930; batch adversarial loss: 0.554705\n",
      "epoch 51; iter: 0; batch classifier loss: 0.178399; batch adversarial loss: 0.413632\n",
      "epoch 52; iter: 0; batch classifier loss: 0.210433; batch adversarial loss: 0.531164\n",
      "epoch 53; iter: 0; batch classifier loss: 0.176781; batch adversarial loss: 0.460597\n",
      "epoch 54; iter: 0; batch classifier loss: 0.225372; batch adversarial loss: 0.457608\n",
      "epoch 55; iter: 0; batch classifier loss: 0.183555; batch adversarial loss: 0.542276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.101594; batch adversarial loss: 0.494030\n",
      "epoch 57; iter: 0; batch classifier loss: 0.184742; batch adversarial loss: 0.447729\n",
      "epoch 58; iter: 0; batch classifier loss: 0.262752; batch adversarial loss: 0.494970\n",
      "epoch 59; iter: 0; batch classifier loss: 0.101373; batch adversarial loss: 0.374513\n",
      "epoch 60; iter: 0; batch classifier loss: 0.151165; batch adversarial loss: 0.482276\n",
      "epoch 61; iter: 0; batch classifier loss: 0.173716; batch adversarial loss: 0.471943\n",
      "epoch 62; iter: 0; batch classifier loss: 0.181147; batch adversarial loss: 0.555964\n",
      "epoch 63; iter: 0; batch classifier loss: 0.127937; batch adversarial loss: 0.421033\n",
      "epoch 64; iter: 0; batch classifier loss: 0.204707; batch adversarial loss: 0.373622\n",
      "epoch 65; iter: 0; batch classifier loss: 0.180167; batch adversarial loss: 0.485632\n",
      "epoch 66; iter: 0; batch classifier loss: 0.235886; batch adversarial loss: 0.398041\n",
      "epoch 67; iter: 0; batch classifier loss: 0.178705; batch adversarial loss: 0.470660\n",
      "epoch 68; iter: 0; batch classifier loss: 0.203044; batch adversarial loss: 0.447262\n",
      "epoch 69; iter: 0; batch classifier loss: 0.226150; batch adversarial loss: 0.531923\n",
      "epoch 70; iter: 0; batch classifier loss: 0.210334; batch adversarial loss: 0.434442\n",
      "epoch 71; iter: 0; batch classifier loss: 0.280252; batch adversarial loss: 0.459131\n",
      "epoch 72; iter: 0; batch classifier loss: 0.181985; batch adversarial loss: 0.579859\n",
      "epoch 73; iter: 0; batch classifier loss: 0.157350; batch adversarial loss: 0.592075\n",
      "epoch 74; iter: 0; batch classifier loss: 0.116893; batch adversarial loss: 0.518954\n",
      "epoch 75; iter: 0; batch classifier loss: 0.313429; batch adversarial loss: 0.423119\n",
      "epoch 76; iter: 0; batch classifier loss: 0.157297; batch adversarial loss: 0.494310\n",
      "epoch 77; iter: 0; batch classifier loss: 0.136460; batch adversarial loss: 0.421017\n",
      "epoch 78; iter: 0; batch classifier loss: 0.192154; batch adversarial loss: 0.398303\n",
      "epoch 79; iter: 0; batch classifier loss: 0.235322; batch adversarial loss: 0.446306\n",
      "epoch 80; iter: 0; batch classifier loss: 0.277094; batch adversarial loss: 0.458525\n",
      "epoch 81; iter: 0; batch classifier loss: 0.152471; batch adversarial loss: 0.494514\n",
      "epoch 82; iter: 0; batch classifier loss: 0.101677; batch adversarial loss: 0.531533\n",
      "epoch 83; iter: 0; batch classifier loss: 0.101670; batch adversarial loss: 0.348108\n",
      "epoch 84; iter: 0; batch classifier loss: 0.093413; batch adversarial loss: 0.443085\n",
      "epoch 85; iter: 0; batch classifier loss: 0.109682; batch adversarial loss: 0.399628\n",
      "epoch 86; iter: 0; batch classifier loss: 0.116865; batch adversarial loss: 0.334999\n",
      "epoch 87; iter: 0; batch classifier loss: 0.089749; batch adversarial loss: 0.417380\n",
      "epoch 88; iter: 0; batch classifier loss: 0.072425; batch adversarial loss: 0.507251\n",
      "epoch 89; iter: 0; batch classifier loss: 0.079860; batch adversarial loss: 0.489483\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075388; batch adversarial loss: 0.415428\n",
      "epoch 91; iter: 0; batch classifier loss: 0.069012; batch adversarial loss: 0.417318\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077972; batch adversarial loss: 0.523666\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072585; batch adversarial loss: 0.401483\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053257; batch adversarial loss: 0.490578\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055725; batch adversarial loss: 0.502248\n",
      "epoch 96; iter: 0; batch classifier loss: 0.077992; batch adversarial loss: 0.466466\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069313; batch adversarial loss: 0.408195\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048123; batch adversarial loss: 0.383753\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055615; batch adversarial loss: 0.449279\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055493; batch adversarial loss: 0.371950\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056561; batch adversarial loss: 0.455019\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049054; batch adversarial loss: 0.465832\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050145; batch adversarial loss: 0.483626\n",
      "epoch 104; iter: 0; batch classifier loss: 0.049561; batch adversarial loss: 0.468261\n",
      "epoch 105; iter: 0; batch classifier loss: 0.072467; batch adversarial loss: 0.422566\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051921; batch adversarial loss: 0.424428\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035198; batch adversarial loss: 0.350617\n",
      "epoch 108; iter: 0; batch classifier loss: 0.050773; batch adversarial loss: 0.432137\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033577; batch adversarial loss: 0.462214\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036419; batch adversarial loss: 0.462187\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052061; batch adversarial loss: 0.380775\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057979; batch adversarial loss: 0.388215\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028950; batch adversarial loss: 0.432060\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047512; batch adversarial loss: 0.407934\n",
      "epoch 115; iter: 0; batch classifier loss: 0.014473; batch adversarial loss: 0.411509\n",
      "epoch 116; iter: 0; batch classifier loss: 0.020062; batch adversarial loss: 0.496577\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056623; batch adversarial loss: 0.440951\n",
      "epoch 118; iter: 0; batch classifier loss: 0.058297; batch adversarial loss: 0.409542\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051895; batch adversarial loss: 0.479772\n",
      "epoch 120; iter: 0; batch classifier loss: 0.026675; batch adversarial loss: 0.454632\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045992; batch adversarial loss: 0.413290\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040188; batch adversarial loss: 0.440327\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014076; batch adversarial loss: 0.584436\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033395; batch adversarial loss: 0.454769\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040483; batch adversarial loss: 0.412506\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021415; batch adversarial loss: 0.499889\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032005; batch adversarial loss: 0.438720\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031987; batch adversarial loss: 0.497540\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023824; batch adversarial loss: 0.472546\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038876; batch adversarial loss: 0.407050\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035515; batch adversarial loss: 0.371413\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026412; batch adversarial loss: 0.437211\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026403; batch adversarial loss: 0.411408\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038142; batch adversarial loss: 0.478184\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011374; batch adversarial loss: 0.542472\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018448; batch adversarial loss: 0.358443\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043191; batch adversarial loss: 0.475077\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027056; batch adversarial loss: 0.453820\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031231; batch adversarial loss: 0.366625\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025487; batch adversarial loss: 0.456160\n",
      "epoch 141; iter: 0; batch classifier loss: 0.012809; batch adversarial loss: 0.512918\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013244; batch adversarial loss: 0.389549\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011308; batch adversarial loss: 0.524259\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014813; batch adversarial loss: 0.369639\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038452; batch adversarial loss: 0.379636\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019476; batch adversarial loss: 0.473303\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014503; batch adversarial loss: 0.521929\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011502; batch adversarial loss: 0.362473\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030752; batch adversarial loss: 0.401200\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021699; batch adversarial loss: 0.385752\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029762; batch adversarial loss: 0.488680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.016975; batch adversarial loss: 0.486454\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017514; batch adversarial loss: 0.388080\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013390; batch adversarial loss: 0.517303\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019191; batch adversarial loss: 0.479680\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013407; batch adversarial loss: 0.443734\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023237; batch adversarial loss: 0.446375\n",
      "epoch 158; iter: 0; batch classifier loss: 0.006384; batch adversarial loss: 0.501385\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034177; batch adversarial loss: 0.541437\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012223; batch adversarial loss: 0.372084\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014148; batch adversarial loss: 0.441590\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021029; batch adversarial loss: 0.434832\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029376; batch adversarial loss: 0.488726\n",
      "epoch 164; iter: 0; batch classifier loss: 0.041088; batch adversarial loss: 0.515159\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018304; batch adversarial loss: 0.549992\n",
      "epoch 166; iter: 0; batch classifier loss: 0.049140; batch adversarial loss: 0.534453\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013215; batch adversarial loss: 0.467075\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019905; batch adversarial loss: 0.428352\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010789; batch adversarial loss: 0.416029\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022280; batch adversarial loss: 0.533920\n",
      "epoch 171; iter: 0; batch classifier loss: 0.058691; batch adversarial loss: 0.426821\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022339; batch adversarial loss: 0.462576\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019528; batch adversarial loss: 0.371194\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011595; batch adversarial loss: 0.344841\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020285; batch adversarial loss: 0.547653\n",
      "epoch 176; iter: 0; batch classifier loss: 0.004267; batch adversarial loss: 0.451514\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020485; batch adversarial loss: 0.462302\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010265; batch adversarial loss: 0.491018\n",
      "epoch 179; iter: 0; batch classifier loss: 0.048371; batch adversarial loss: 0.411911\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011923; batch adversarial loss: 0.475635\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011663; batch adversarial loss: 0.505674\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009465; batch adversarial loss: 0.404552\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039790; batch adversarial loss: 0.452526\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018268; batch adversarial loss: 0.496682\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027623; batch adversarial loss: 0.471101\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011027; batch adversarial loss: 0.490006\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005260; batch adversarial loss: 0.520094\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012095; batch adversarial loss: 0.469568\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018962; batch adversarial loss: 0.455644\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025293; batch adversarial loss: 0.341035\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009201; batch adversarial loss: 0.517743\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022116; batch adversarial loss: 0.457718\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009451; batch adversarial loss: 0.419840\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015677; batch adversarial loss: 0.404985\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011072; batch adversarial loss: 0.441854\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019011; batch adversarial loss: 0.442341\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011278; batch adversarial loss: 0.485226\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021208; batch adversarial loss: 0.446514\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019911; batch adversarial loss: 0.313175\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680233; batch adversarial loss: 0.669487\n",
      "epoch 1; iter: 0; batch classifier loss: 0.499940; batch adversarial loss: 0.653313\n",
      "epoch 2; iter: 0; batch classifier loss: 0.564610; batch adversarial loss: 0.614946\n",
      "epoch 3; iter: 0; batch classifier loss: 0.535594; batch adversarial loss: 0.625903\n",
      "epoch 4; iter: 0; batch classifier loss: 0.464981; batch adversarial loss: 0.588848\n",
      "epoch 5; iter: 0; batch classifier loss: 0.511738; batch adversarial loss: 0.620839\n",
      "epoch 6; iter: 0; batch classifier loss: 0.453029; batch adversarial loss: 0.579169\n",
      "epoch 7; iter: 0; batch classifier loss: 0.408038; batch adversarial loss: 0.592312\n",
      "epoch 8; iter: 0; batch classifier loss: 0.359649; batch adversarial loss: 0.589027\n",
      "epoch 9; iter: 0; batch classifier loss: 0.404666; batch adversarial loss: 0.571638\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386266; batch adversarial loss: 0.557153\n",
      "epoch 11; iter: 0; batch classifier loss: 0.365439; batch adversarial loss: 0.526289\n",
      "epoch 12; iter: 0; batch classifier loss: 0.427756; batch adversarial loss: 0.438792\n",
      "epoch 13; iter: 0; batch classifier loss: 0.465351; batch adversarial loss: 0.487333\n",
      "epoch 14; iter: 0; batch classifier loss: 0.301893; batch adversarial loss: 0.502751\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364167; batch adversarial loss: 0.496543\n",
      "epoch 16; iter: 0; batch classifier loss: 0.343375; batch adversarial loss: 0.473015\n",
      "epoch 17; iter: 0; batch classifier loss: 0.337860; batch adversarial loss: 0.466522\n",
      "epoch 18; iter: 0; batch classifier loss: 0.345415; batch adversarial loss: 0.501860\n",
      "epoch 19; iter: 0; batch classifier loss: 0.302755; batch adversarial loss: 0.536084\n",
      "epoch 20; iter: 0; batch classifier loss: 0.307322; batch adversarial loss: 0.535747\n",
      "epoch 21; iter: 0; batch classifier loss: 0.229608; batch adversarial loss: 0.538101\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226515; batch adversarial loss: 0.496889\n",
      "epoch 23; iter: 0; batch classifier loss: 0.306680; batch adversarial loss: 0.529913\n",
      "epoch 24; iter: 0; batch classifier loss: 0.233152; batch adversarial loss: 0.530343\n",
      "epoch 25; iter: 0; batch classifier loss: 0.217685; batch adversarial loss: 0.538346\n",
      "epoch 26; iter: 0; batch classifier loss: 0.247991; batch adversarial loss: 0.511266\n",
      "epoch 27; iter: 0; batch classifier loss: 0.299585; batch adversarial loss: 0.511389\n",
      "epoch 28; iter: 0; batch classifier loss: 0.271776; batch adversarial loss: 0.497362\n",
      "epoch 29; iter: 0; batch classifier loss: 0.196587; batch adversarial loss: 0.434084\n",
      "epoch 30; iter: 0; batch classifier loss: 0.315026; batch adversarial loss: 0.481100\n",
      "epoch 31; iter: 0; batch classifier loss: 0.244191; batch adversarial loss: 0.494926\n",
      "epoch 32; iter: 0; batch classifier loss: 0.244308; batch adversarial loss: 0.522352\n",
      "epoch 33; iter: 0; batch classifier loss: 0.238609; batch adversarial loss: 0.513882\n",
      "epoch 34; iter: 0; batch classifier loss: 0.196759; batch adversarial loss: 0.422723\n",
      "epoch 35; iter: 0; batch classifier loss: 0.228039; batch adversarial loss: 0.433455\n",
      "epoch 36; iter: 0; batch classifier loss: 0.245391; batch adversarial loss: 0.404052\n",
      "epoch 37; iter: 0; batch classifier loss: 0.217253; batch adversarial loss: 0.490952\n",
      "epoch 38; iter: 0; batch classifier loss: 0.256227; batch adversarial loss: 0.451768\n",
      "epoch 39; iter: 0; batch classifier loss: 0.254256; batch adversarial loss: 0.425468\n",
      "epoch 40; iter: 0; batch classifier loss: 0.270629; batch adversarial loss: 0.473448\n",
      "epoch 41; iter: 0; batch classifier loss: 0.197702; batch adversarial loss: 0.535070\n",
      "epoch 42; iter: 0; batch classifier loss: 0.243381; batch adversarial loss: 0.448447\n",
      "epoch 43; iter: 0; batch classifier loss: 0.284107; batch adversarial loss: 0.344306\n",
      "epoch 44; iter: 0; batch classifier loss: 0.246963; batch adversarial loss: 0.473458\n",
      "epoch 45; iter: 0; batch classifier loss: 0.287770; batch adversarial loss: 0.403017\n",
      "epoch 46; iter: 0; batch classifier loss: 0.191298; batch adversarial loss: 0.460272\n",
      "epoch 47; iter: 0; batch classifier loss: 0.259196; batch adversarial loss: 0.459431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.245541; batch adversarial loss: 0.434847\n",
      "epoch 49; iter: 0; batch classifier loss: 0.179663; batch adversarial loss: 0.541253\n",
      "epoch 50; iter: 0; batch classifier loss: 0.252487; batch adversarial loss: 0.399285\n",
      "epoch 51; iter: 0; batch classifier loss: 0.128002; batch adversarial loss: 0.446173\n",
      "epoch 52; iter: 0; batch classifier loss: 0.199112; batch adversarial loss: 0.517813\n",
      "epoch 53; iter: 0; batch classifier loss: 0.236713; batch adversarial loss: 0.412095\n",
      "epoch 54; iter: 0; batch classifier loss: 0.158142; batch adversarial loss: 0.410343\n",
      "epoch 55; iter: 0; batch classifier loss: 0.159781; batch adversarial loss: 0.386214\n",
      "epoch 56; iter: 0; batch classifier loss: 0.150280; batch adversarial loss: 0.374962\n",
      "epoch 57; iter: 0; batch classifier loss: 0.159789; batch adversarial loss: 0.482669\n",
      "epoch 58; iter: 0; batch classifier loss: 0.264396; batch adversarial loss: 0.434340\n",
      "epoch 59; iter: 0; batch classifier loss: 0.121306; batch adversarial loss: 0.457966\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115254; batch adversarial loss: 0.424622\n",
      "epoch 61; iter: 0; batch classifier loss: 0.163749; batch adversarial loss: 0.449147\n",
      "epoch 62; iter: 0; batch classifier loss: 0.187860; batch adversarial loss: 0.482260\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070744; batch adversarial loss: 0.484253\n",
      "epoch 64; iter: 0; batch classifier loss: 0.214874; batch adversarial loss: 0.420856\n",
      "epoch 65; iter: 0; batch classifier loss: 0.187322; batch adversarial loss: 0.581918\n",
      "epoch 66; iter: 0; batch classifier loss: 0.179225; batch adversarial loss: 0.459121\n",
      "epoch 67; iter: 0; batch classifier loss: 0.205866; batch adversarial loss: 0.556546\n",
      "epoch 68; iter: 0; batch classifier loss: 0.252998; batch adversarial loss: 0.592225\n",
      "epoch 69; iter: 0; batch classifier loss: 0.226441; batch adversarial loss: 0.397888\n",
      "epoch 70; iter: 0; batch classifier loss: 0.194604; batch adversarial loss: 0.482866\n",
      "epoch 71; iter: 0; batch classifier loss: 0.213684; batch adversarial loss: 0.385210\n",
      "epoch 72; iter: 0; batch classifier loss: 0.182372; batch adversarial loss: 0.398027\n",
      "epoch 73; iter: 0; batch classifier loss: 0.157437; batch adversarial loss: 0.348298\n",
      "epoch 74; iter: 0; batch classifier loss: 0.140624; batch adversarial loss: 0.434410\n",
      "epoch 75; iter: 0; batch classifier loss: 0.147501; batch adversarial loss: 0.508028\n",
      "epoch 76; iter: 0; batch classifier loss: 0.145676; batch adversarial loss: 0.432765\n",
      "epoch 77; iter: 0; batch classifier loss: 0.216735; batch adversarial loss: 0.410135\n",
      "epoch 78; iter: 0; batch classifier loss: 0.233837; batch adversarial loss: 0.434709\n",
      "epoch 79; iter: 0; batch classifier loss: 0.155130; batch adversarial loss: 0.494964\n",
      "epoch 80; iter: 0; batch classifier loss: 0.184921; batch adversarial loss: 0.507123\n",
      "epoch 81; iter: 0; batch classifier loss: 0.237172; batch adversarial loss: 0.410982\n",
      "epoch 82; iter: 0; batch classifier loss: 0.129091; batch adversarial loss: 0.421066\n",
      "epoch 83; iter: 0; batch classifier loss: 0.128633; batch adversarial loss: 0.506272\n",
      "epoch 84; iter: 0; batch classifier loss: 0.114188; batch adversarial loss: 0.430144\n",
      "epoch 85; iter: 0; batch classifier loss: 0.170100; batch adversarial loss: 0.459413\n",
      "epoch 86; iter: 0; batch classifier loss: 0.159623; batch adversarial loss: 0.397990\n",
      "epoch 87; iter: 0; batch classifier loss: 0.183689; batch adversarial loss: 0.542065\n",
      "epoch 88; iter: 0; batch classifier loss: 0.147176; batch adversarial loss: 0.556649\n",
      "epoch 89; iter: 0; batch classifier loss: 0.165070; batch adversarial loss: 0.484278\n",
      "epoch 90; iter: 0; batch classifier loss: 0.227692; batch adversarial loss: 0.350742\n",
      "epoch 91; iter: 0; batch classifier loss: 0.205051; batch adversarial loss: 0.470395\n",
      "epoch 92; iter: 0; batch classifier loss: 0.158194; batch adversarial loss: 0.470373\n",
      "epoch 93; iter: 0; batch classifier loss: 0.185741; batch adversarial loss: 0.461277\n",
      "epoch 94; iter: 0; batch classifier loss: 0.205957; batch adversarial loss: 0.495178\n",
      "epoch 95; iter: 0; batch classifier loss: 0.160500; batch adversarial loss: 0.458651\n",
      "epoch 96; iter: 0; batch classifier loss: 0.152910; batch adversarial loss: 0.421535\n",
      "epoch 97; iter: 0; batch classifier loss: 0.185197; batch adversarial loss: 0.421437\n",
      "epoch 98; iter: 0; batch classifier loss: 0.174068; batch adversarial loss: 0.397918\n",
      "epoch 99; iter: 0; batch classifier loss: 0.152517; batch adversarial loss: 0.568995\n",
      "epoch 100; iter: 0; batch classifier loss: 0.153989; batch adversarial loss: 0.385032\n",
      "epoch 101; iter: 0; batch classifier loss: 0.241336; batch adversarial loss: 0.409908\n",
      "epoch 102; iter: 0; batch classifier loss: 0.179080; batch adversarial loss: 0.423487\n",
      "epoch 103; iter: 0; batch classifier loss: 0.185664; batch adversarial loss: 0.518417\n",
      "epoch 104; iter: 0; batch classifier loss: 0.197133; batch adversarial loss: 0.495189\n",
      "epoch 105; iter: 0; batch classifier loss: 0.188622; batch adversarial loss: 0.457367\n",
      "epoch 106; iter: 0; batch classifier loss: 0.172745; batch adversarial loss: 0.484616\n",
      "epoch 107; iter: 0; batch classifier loss: 0.148912; batch adversarial loss: 0.373548\n",
      "epoch 108; iter: 0; batch classifier loss: 0.183128; batch adversarial loss: 0.468982\n",
      "epoch 109; iter: 0; batch classifier loss: 0.079417; batch adversarial loss: 0.481619\n",
      "epoch 110; iter: 0; batch classifier loss: 0.119320; batch adversarial loss: 0.567195\n",
      "epoch 111; iter: 0; batch classifier loss: 0.090433; batch adversarial loss: 0.494079\n",
      "epoch 112; iter: 0; batch classifier loss: 0.103658; batch adversarial loss: 0.481057\n",
      "epoch 113; iter: 0; batch classifier loss: 0.092821; batch adversarial loss: 0.421484\n",
      "epoch 114; iter: 0; batch classifier loss: 0.085375; batch adversarial loss: 0.467710\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057481; batch adversarial loss: 0.519875\n",
      "epoch 116; iter: 0; batch classifier loss: 0.087496; batch adversarial loss: 0.339527\n",
      "epoch 117; iter: 0; batch classifier loss: 0.115777; batch adversarial loss: 0.437801\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050922; batch adversarial loss: 0.438934\n",
      "epoch 119; iter: 0; batch classifier loss: 0.098720; batch adversarial loss: 0.425900\n",
      "epoch 120; iter: 0; batch classifier loss: 0.073990; batch adversarial loss: 0.417541\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047432; batch adversarial loss: 0.417792\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033638; batch adversarial loss: 0.566643\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043187; batch adversarial loss: 0.517887\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030310; batch adversarial loss: 0.463694\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057083; batch adversarial loss: 0.380770\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035693; batch adversarial loss: 0.539286\n",
      "epoch 127; iter: 0; batch classifier loss: 0.018859; batch adversarial loss: 0.413065\n",
      "epoch 128; iter: 0; batch classifier loss: 0.048398; batch adversarial loss: 0.526701\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045842; batch adversarial loss: 0.344936\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038135; batch adversarial loss: 0.522039\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047109; batch adversarial loss: 0.398011\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038794; batch adversarial loss: 0.367771\n",
      "epoch 133; iter: 0; batch classifier loss: 0.062957; batch adversarial loss: 0.473891\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023196; batch adversarial loss: 0.423074\n",
      "epoch 135; iter: 0; batch classifier loss: 0.056858; batch adversarial loss: 0.511966\n",
      "epoch 136; iter: 0; batch classifier loss: 0.045615; batch adversarial loss: 0.396383\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040055; batch adversarial loss: 0.354026\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026161; batch adversarial loss: 0.441248\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032769; batch adversarial loss: 0.433144\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024488; batch adversarial loss: 0.546072\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037967; batch adversarial loss: 0.450362\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039252; batch adversarial loss: 0.345132\n",
      "epoch 143; iter: 0; batch classifier loss: 0.045139; batch adversarial loss: 0.539867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.033334; batch adversarial loss: 0.507599\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035253; batch adversarial loss: 0.495703\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011036; batch adversarial loss: 0.434273\n",
      "epoch 147; iter: 0; batch classifier loss: 0.007256; batch adversarial loss: 0.456656\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018131; batch adversarial loss: 0.541050\n",
      "epoch 149; iter: 0; batch classifier loss: 0.047697; batch adversarial loss: 0.537309\n",
      "epoch 150; iter: 0; batch classifier loss: 0.008739; batch adversarial loss: 0.469679\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035898; batch adversarial loss: 0.593195\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022897; batch adversarial loss: 0.417665\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030649; batch adversarial loss: 0.403364\n",
      "epoch 154; iter: 0; batch classifier loss: 0.007368; batch adversarial loss: 0.503911\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026423; batch adversarial loss: 0.442231\n",
      "epoch 156; iter: 0; batch classifier loss: 0.003634; batch adversarial loss: 0.475729\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029543; batch adversarial loss: 0.454484\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024932; batch adversarial loss: 0.461921\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026577; batch adversarial loss: 0.432854\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017558; batch adversarial loss: 0.452512\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014109; batch adversarial loss: 0.442408\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042065; batch adversarial loss: 0.511435\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014414; batch adversarial loss: 0.542848\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011332; batch adversarial loss: 0.460016\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018013; batch adversarial loss: 0.493665\n",
      "epoch 166; iter: 0; batch classifier loss: 0.008234; batch adversarial loss: 0.574523\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033765; batch adversarial loss: 0.512160\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009695; batch adversarial loss: 0.442285\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015294; batch adversarial loss: 0.460506\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017792; batch adversarial loss: 0.420400\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009668; batch adversarial loss: 0.530934\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009950; batch adversarial loss: 0.403425\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028194; batch adversarial loss: 0.412656\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017741; batch adversarial loss: 0.409153\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032334; batch adversarial loss: 0.442605\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018627; batch adversarial loss: 0.421173\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012788; batch adversarial loss: 0.425097\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022281; batch adversarial loss: 0.415803\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016408; batch adversarial loss: 0.560560\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016479; batch adversarial loss: 0.491335\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013575; batch adversarial loss: 0.418614\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015984; batch adversarial loss: 0.477537\n",
      "epoch 183; iter: 0; batch classifier loss: 0.070674; batch adversarial loss: 0.418189\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017797; batch adversarial loss: 0.462210\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014080; batch adversarial loss: 0.523631\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006067; batch adversarial loss: 0.447422\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030592; batch adversarial loss: 0.525621\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016641; batch adversarial loss: 0.475462\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009233; batch adversarial loss: 0.526931\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008483; batch adversarial loss: 0.367368\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008362; batch adversarial loss: 0.423239\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008398; batch adversarial loss: 0.443368\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023776; batch adversarial loss: 0.431791\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012045; batch adversarial loss: 0.420289\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006509; batch adversarial loss: 0.471579\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016775; batch adversarial loss: 0.429563\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014436; batch adversarial loss: 0.470318\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016978; batch adversarial loss: 0.484574\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019692; batch adversarial loss: 0.460815\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709215; batch adversarial loss: 0.544729\n",
      "epoch 1; iter: 0; batch classifier loss: 0.429305; batch adversarial loss: 0.591180\n",
      "epoch 2; iter: 0; batch classifier loss: 0.449755; batch adversarial loss: 0.578940\n",
      "epoch 3; iter: 0; batch classifier loss: 0.373705; batch adversarial loss: 0.623873\n",
      "epoch 4; iter: 0; batch classifier loss: 0.334428; batch adversarial loss: 0.636578\n",
      "epoch 5; iter: 0; batch classifier loss: 0.357260; batch adversarial loss: 0.536123\n",
      "epoch 6; iter: 0; batch classifier loss: 0.303344; batch adversarial loss: 0.568203\n",
      "epoch 7; iter: 0; batch classifier loss: 0.354490; batch adversarial loss: 0.549525\n",
      "epoch 8; iter: 0; batch classifier loss: 0.318758; batch adversarial loss: 0.623972\n",
      "epoch 9; iter: 0; batch classifier loss: 0.359288; batch adversarial loss: 0.540146\n",
      "epoch 10; iter: 0; batch classifier loss: 0.403449; batch adversarial loss: 0.560966\n",
      "epoch 11; iter: 0; batch classifier loss: 0.430213; batch adversarial loss: 0.578466\n",
      "epoch 12; iter: 0; batch classifier loss: 0.378780; batch adversarial loss: 0.536880\n",
      "epoch 13; iter: 0; batch classifier loss: 0.551271; batch adversarial loss: 0.493457\n",
      "epoch 14; iter: 0; batch classifier loss: 0.461919; batch adversarial loss: 0.491316\n",
      "epoch 15; iter: 0; batch classifier loss: 0.288291; batch adversarial loss: 0.551792\n",
      "epoch 16; iter: 0; batch classifier loss: 0.312104; batch adversarial loss: 0.475016\n",
      "epoch 17; iter: 0; batch classifier loss: 0.313592; batch adversarial loss: 0.467720\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246641; batch adversarial loss: 0.490800\n",
      "epoch 19; iter: 0; batch classifier loss: 0.192952; batch adversarial loss: 0.461641\n",
      "epoch 20; iter: 0; batch classifier loss: 0.194511; batch adversarial loss: 0.493183\n",
      "epoch 21; iter: 0; batch classifier loss: 0.236644; batch adversarial loss: 0.474309\n",
      "epoch 22; iter: 0; batch classifier loss: 0.130223; batch adversarial loss: 0.535297\n",
      "epoch 23; iter: 0; batch classifier loss: 0.142807; batch adversarial loss: 0.452594\n",
      "epoch 24; iter: 0; batch classifier loss: 0.201687; batch adversarial loss: 0.426666\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148648; batch adversarial loss: 0.539721\n",
      "epoch 26; iter: 0; batch classifier loss: 0.150531; batch adversarial loss: 0.474897\n",
      "epoch 27; iter: 0; batch classifier loss: 0.143776; batch adversarial loss: 0.406194\n",
      "epoch 28; iter: 0; batch classifier loss: 0.110235; batch adversarial loss: 0.422819\n",
      "epoch 29; iter: 0; batch classifier loss: 0.133570; batch adversarial loss: 0.486244\n",
      "epoch 30; iter: 0; batch classifier loss: 0.078506; batch adversarial loss: 0.445543\n",
      "epoch 31; iter: 0; batch classifier loss: 0.155037; batch adversarial loss: 0.453220\n",
      "epoch 32; iter: 0; batch classifier loss: 0.198056; batch adversarial loss: 0.514826\n",
      "epoch 33; iter: 0; batch classifier loss: 0.119802; batch adversarial loss: 0.446968\n",
      "epoch 34; iter: 0; batch classifier loss: 0.137107; batch adversarial loss: 0.474194\n",
      "epoch 35; iter: 0; batch classifier loss: 0.147667; batch adversarial loss: 0.516762\n",
      "epoch 36; iter: 0; batch classifier loss: 0.185845; batch adversarial loss: 0.473159\n",
      "epoch 37; iter: 0; batch classifier loss: 0.191749; batch adversarial loss: 0.391571\n",
      "epoch 38; iter: 0; batch classifier loss: 0.151579; batch adversarial loss: 0.429505\n",
      "epoch 39; iter: 0; batch classifier loss: 0.124980; batch adversarial loss: 0.464943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.129777; batch adversarial loss: 0.413644\n",
      "epoch 41; iter: 0; batch classifier loss: 0.133958; batch adversarial loss: 0.444030\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131194; batch adversarial loss: 0.417541\n",
      "epoch 43; iter: 0; batch classifier loss: 0.131675; batch adversarial loss: 0.532691\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098584; batch adversarial loss: 0.510380\n",
      "epoch 45; iter: 0; batch classifier loss: 0.152541; batch adversarial loss: 0.451393\n",
      "epoch 46; iter: 0; batch classifier loss: 0.118806; batch adversarial loss: 0.483237\n",
      "epoch 47; iter: 0; batch classifier loss: 0.180385; batch adversarial loss: 0.472749\n",
      "epoch 48; iter: 0; batch classifier loss: 0.140207; batch adversarial loss: 0.465570\n",
      "epoch 49; iter: 0; batch classifier loss: 0.175100; batch adversarial loss: 0.454330\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129297; batch adversarial loss: 0.493362\n",
      "epoch 51; iter: 0; batch classifier loss: 0.120406; batch adversarial loss: 0.495710\n",
      "epoch 52; iter: 0; batch classifier loss: 0.237646; batch adversarial loss: 0.465227\n",
      "epoch 53; iter: 0; batch classifier loss: 0.155379; batch adversarial loss: 0.404953\n",
      "epoch 54; iter: 0; batch classifier loss: 0.181603; batch adversarial loss: 0.486031\n",
      "epoch 55; iter: 0; batch classifier loss: 0.155814; batch adversarial loss: 0.410595\n",
      "epoch 56; iter: 0; batch classifier loss: 0.176034; batch adversarial loss: 0.401284\n",
      "epoch 57; iter: 0; batch classifier loss: 0.164223; batch adversarial loss: 0.458203\n",
      "epoch 58; iter: 0; batch classifier loss: 0.165591; batch adversarial loss: 0.506131\n",
      "epoch 59; iter: 0; batch classifier loss: 0.148106; batch adversarial loss: 0.402391\n",
      "epoch 60; iter: 0; batch classifier loss: 0.203540; batch adversarial loss: 0.434986\n",
      "epoch 61; iter: 0; batch classifier loss: 0.184717; batch adversarial loss: 0.469429\n",
      "epoch 62; iter: 0; batch classifier loss: 0.178061; batch adversarial loss: 0.497185\n",
      "epoch 63; iter: 0; batch classifier loss: 0.187063; batch adversarial loss: 0.507203\n",
      "epoch 64; iter: 0; batch classifier loss: 0.146593; batch adversarial loss: 0.459993\n",
      "epoch 65; iter: 0; batch classifier loss: 0.179654; batch adversarial loss: 0.482405\n",
      "epoch 66; iter: 0; batch classifier loss: 0.146463; batch adversarial loss: 0.506112\n",
      "epoch 67; iter: 0; batch classifier loss: 0.220611; batch adversarial loss: 0.459066\n",
      "epoch 68; iter: 0; batch classifier loss: 0.173786; batch adversarial loss: 0.472353\n",
      "epoch 69; iter: 0; batch classifier loss: 0.141533; batch adversarial loss: 0.458196\n",
      "epoch 70; iter: 0; batch classifier loss: 0.161572; batch adversarial loss: 0.412062\n",
      "epoch 71; iter: 0; batch classifier loss: 0.179962; batch adversarial loss: 0.564605\n",
      "epoch 72; iter: 0; batch classifier loss: 0.186324; batch adversarial loss: 0.434879\n",
      "epoch 73; iter: 0; batch classifier loss: 0.246740; batch adversarial loss: 0.412013\n",
      "epoch 74; iter: 0; batch classifier loss: 0.155651; batch adversarial loss: 0.459343\n",
      "epoch 75; iter: 0; batch classifier loss: 0.231304; batch adversarial loss: 0.435820\n",
      "epoch 76; iter: 0; batch classifier loss: 0.109278; batch adversarial loss: 0.435085\n",
      "epoch 77; iter: 0; batch classifier loss: 0.132327; batch adversarial loss: 0.422392\n",
      "epoch 78; iter: 0; batch classifier loss: 0.248405; batch adversarial loss: 0.531399\n",
      "epoch 79; iter: 0; batch classifier loss: 0.196988; batch adversarial loss: 0.483303\n",
      "epoch 80; iter: 0; batch classifier loss: 0.123007; batch adversarial loss: 0.470756\n",
      "epoch 81; iter: 0; batch classifier loss: 0.156581; batch adversarial loss: 0.507309\n",
      "epoch 82; iter: 0; batch classifier loss: 0.187294; batch adversarial loss: 0.483176\n",
      "epoch 83; iter: 0; batch classifier loss: 0.224426; batch adversarial loss: 0.424413\n",
      "epoch 84; iter: 0; batch classifier loss: 0.166902; batch adversarial loss: 0.587833\n",
      "epoch 85; iter: 0; batch classifier loss: 0.174228; batch adversarial loss: 0.470939\n",
      "epoch 86; iter: 0; batch classifier loss: 0.189006; batch adversarial loss: 0.376152\n",
      "epoch 87; iter: 0; batch classifier loss: 0.215610; batch adversarial loss: 0.506365\n",
      "epoch 88; iter: 0; batch classifier loss: 0.163183; batch adversarial loss: 0.505979\n",
      "epoch 89; iter: 0; batch classifier loss: 0.158859; batch adversarial loss: 0.423372\n",
      "epoch 90; iter: 0; batch classifier loss: 0.144421; batch adversarial loss: 0.436725\n",
      "epoch 91; iter: 0; batch classifier loss: 0.162005; batch adversarial loss: 0.506754\n",
      "epoch 92; iter: 0; batch classifier loss: 0.144439; batch adversarial loss: 0.518133\n",
      "epoch 93; iter: 0; batch classifier loss: 0.161182; batch adversarial loss: 0.495633\n",
      "epoch 94; iter: 0; batch classifier loss: 0.227760; batch adversarial loss: 0.434608\n",
      "epoch 95; iter: 0; batch classifier loss: 0.117469; batch adversarial loss: 0.577605\n",
      "epoch 96; iter: 0; batch classifier loss: 0.143335; batch adversarial loss: 0.459313\n",
      "epoch 97; iter: 0; batch classifier loss: 0.183625; batch adversarial loss: 0.447593\n",
      "epoch 98; iter: 0; batch classifier loss: 0.193385; batch adversarial loss: 0.423619\n",
      "epoch 99; iter: 0; batch classifier loss: 0.215399; batch adversarial loss: 0.447136\n",
      "epoch 100; iter: 0; batch classifier loss: 0.112701; batch adversarial loss: 0.506416\n",
      "epoch 101; iter: 0; batch classifier loss: 0.191434; batch adversarial loss: 0.458924\n",
      "epoch 102; iter: 0; batch classifier loss: 0.141802; batch adversarial loss: 0.388256\n",
      "epoch 103; iter: 0; batch classifier loss: 0.085631; batch adversarial loss: 0.542620\n",
      "epoch 104; iter: 0; batch classifier loss: 0.148965; batch adversarial loss: 0.483214\n",
      "epoch 105; iter: 0; batch classifier loss: 0.155711; batch adversarial loss: 0.506046\n",
      "epoch 106; iter: 0; batch classifier loss: 0.224337; batch adversarial loss: 0.423118\n",
      "epoch 107; iter: 0; batch classifier loss: 0.123126; batch adversarial loss: 0.422536\n",
      "epoch 108; iter: 0; batch classifier loss: 0.214085; batch adversarial loss: 0.459418\n",
      "epoch 109; iter: 0; batch classifier loss: 0.150645; batch adversarial loss: 0.506511\n",
      "epoch 110; iter: 0; batch classifier loss: 0.193031; batch adversarial loss: 0.423173\n",
      "epoch 111; iter: 0; batch classifier loss: 0.213822; batch adversarial loss: 0.435414\n",
      "epoch 112; iter: 0; batch classifier loss: 0.240074; batch adversarial loss: 0.435716\n",
      "epoch 113; iter: 0; batch classifier loss: 0.137112; batch adversarial loss: 0.506500\n",
      "epoch 114; iter: 0; batch classifier loss: 0.126787; batch adversarial loss: 0.482571\n",
      "epoch 115; iter: 0; batch classifier loss: 0.124235; batch adversarial loss: 0.447543\n",
      "epoch 116; iter: 0; batch classifier loss: 0.140706; batch adversarial loss: 0.458363\n",
      "epoch 117; iter: 0; batch classifier loss: 0.183204; batch adversarial loss: 0.446368\n",
      "epoch 118; iter: 0; batch classifier loss: 0.106691; batch adversarial loss: 0.446351\n",
      "epoch 119; iter: 0; batch classifier loss: 0.208002; batch adversarial loss: 0.447296\n",
      "epoch 120; iter: 0; batch classifier loss: 0.143466; batch adversarial loss: 0.483444\n",
      "epoch 121; iter: 0; batch classifier loss: 0.225300; batch adversarial loss: 0.446618\n",
      "epoch 122; iter: 0; batch classifier loss: 0.167406; batch adversarial loss: 0.459563\n",
      "epoch 123; iter: 0; batch classifier loss: 0.165565; batch adversarial loss: 0.541550\n",
      "epoch 124; iter: 0; batch classifier loss: 0.102295; batch adversarial loss: 0.471811\n",
      "epoch 125; iter: 0; batch classifier loss: 0.123728; batch adversarial loss: 0.494111\n",
      "epoch 126; iter: 0; batch classifier loss: 0.147066; batch adversarial loss: 0.447514\n",
      "epoch 127; iter: 0; batch classifier loss: 0.129154; batch adversarial loss: 0.625156\n",
      "epoch 128; iter: 0; batch classifier loss: 0.145600; batch adversarial loss: 0.376803\n",
      "epoch 129; iter: 0; batch classifier loss: 0.139098; batch adversarial loss: 0.457935\n",
      "epoch 130; iter: 0; batch classifier loss: 0.185524; batch adversarial loss: 0.495487\n",
      "epoch 131; iter: 0; batch classifier loss: 0.175270; batch adversarial loss: 0.376352\n",
      "epoch 132; iter: 0; batch classifier loss: 0.182999; batch adversarial loss: 0.519398\n",
      "epoch 133; iter: 0; batch classifier loss: 0.100064; batch adversarial loss: 0.481753\n",
      "epoch 134; iter: 0; batch classifier loss: 0.162640; batch adversarial loss: 0.578467\n",
      "epoch 135; iter: 0; batch classifier loss: 0.158714; batch adversarial loss: 0.400988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.135694; batch adversarial loss: 0.460565\n",
      "epoch 137; iter: 0; batch classifier loss: 0.123635; batch adversarial loss: 0.421740\n",
      "epoch 138; iter: 0; batch classifier loss: 0.079409; batch adversarial loss: 0.613402\n",
      "epoch 139; iter: 0; batch classifier loss: 0.117930; batch adversarial loss: 0.528321\n",
      "epoch 140; iter: 0; batch classifier loss: 0.129242; batch adversarial loss: 0.495936\n",
      "epoch 141; iter: 0; batch classifier loss: 0.101499; batch adversarial loss: 0.516973\n",
      "epoch 142; iter: 0; batch classifier loss: 0.127869; batch adversarial loss: 0.422323\n",
      "epoch 143; iter: 0; batch classifier loss: 0.124645; batch adversarial loss: 0.459183\n",
      "epoch 144; iter: 0; batch classifier loss: 0.042058; batch adversarial loss: 0.468850\n",
      "epoch 145; iter: 0; batch classifier loss: 0.094810; batch adversarial loss: 0.501521\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051816; batch adversarial loss: 0.515598\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043096; batch adversarial loss: 0.470768\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024177; batch adversarial loss: 0.539819\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036744; batch adversarial loss: 0.515042\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029017; batch adversarial loss: 0.409155\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038467; batch adversarial loss: 0.512589\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044974; batch adversarial loss: 0.508421\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018750; batch adversarial loss: 0.581946\n",
      "epoch 154; iter: 0; batch classifier loss: 0.066002; batch adversarial loss: 0.432603\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044108; batch adversarial loss: 0.455072\n",
      "epoch 156; iter: 0; batch classifier loss: 0.065671; batch adversarial loss: 0.474748\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036574; batch adversarial loss: 0.372334\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018879; batch adversarial loss: 0.518470\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038670; batch adversarial loss: 0.443119\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026091; batch adversarial loss: 0.437147\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028359; batch adversarial loss: 0.509195\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026439; batch adversarial loss: 0.458509\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027201; batch adversarial loss: 0.401356\n",
      "epoch 164; iter: 0; batch classifier loss: 0.067912; batch adversarial loss: 0.446677\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048093; batch adversarial loss: 0.480117\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021892; batch adversarial loss: 0.464767\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025024; batch adversarial loss: 0.508860\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029325; batch adversarial loss: 0.510392\n",
      "epoch 169; iter: 0; batch classifier loss: 0.054973; batch adversarial loss: 0.460669\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037377; batch adversarial loss: 0.450667\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017343; batch adversarial loss: 0.389863\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012758; batch adversarial loss: 0.449506\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027653; batch adversarial loss: 0.363995\n",
      "epoch 174; iter: 0; batch classifier loss: 0.044363; batch adversarial loss: 0.441170\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010281; batch adversarial loss: 0.504642\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035509; batch adversarial loss: 0.466059\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033714; batch adversarial loss: 0.380534\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018610; batch adversarial loss: 0.460015\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011623; batch adversarial loss: 0.440007\n",
      "epoch 180; iter: 0; batch classifier loss: 0.043828; batch adversarial loss: 0.548350\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021461; batch adversarial loss: 0.507790\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014924; batch adversarial loss: 0.609141\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013189; batch adversarial loss: 0.563658\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007303; batch adversarial loss: 0.515557\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022677; batch adversarial loss: 0.443478\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037495; batch adversarial loss: 0.397916\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016951; batch adversarial loss: 0.417989\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027306; batch adversarial loss: 0.510498\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016591; batch adversarial loss: 0.443613\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031972; batch adversarial loss: 0.391851\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013685; batch adversarial loss: 0.438468\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018913; batch adversarial loss: 0.518084\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009371; batch adversarial loss: 0.445622\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019041; batch adversarial loss: 0.384932\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015328; batch adversarial loss: 0.454871\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010302; batch adversarial loss: 0.492301\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011248; batch adversarial loss: 0.487271\n",
      "epoch 198; iter: 0; batch classifier loss: 0.050978; batch adversarial loss: 0.497687\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027034; batch adversarial loss: 0.501995\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704463; batch adversarial loss: 1.078155\n",
      "epoch 1; iter: 0; batch classifier loss: 0.646083; batch adversarial loss: 1.233181\n",
      "epoch 2; iter: 0; batch classifier loss: 0.880400; batch adversarial loss: 1.243079\n",
      "epoch 3; iter: 0; batch classifier loss: 0.843859; batch adversarial loss: 1.156304\n",
      "epoch 4; iter: 0; batch classifier loss: 0.962768; batch adversarial loss: 1.024130\n",
      "epoch 5; iter: 0; batch classifier loss: 1.049464; batch adversarial loss: 0.934998\n",
      "epoch 6; iter: 0; batch classifier loss: 0.931301; batch adversarial loss: 0.849899\n",
      "epoch 7; iter: 0; batch classifier loss: 1.072024; batch adversarial loss: 0.764684\n",
      "epoch 8; iter: 0; batch classifier loss: 0.990655; batch adversarial loss: 0.682755\n",
      "epoch 9; iter: 0; batch classifier loss: 0.765397; batch adversarial loss: 0.654960\n",
      "epoch 10; iter: 0; batch classifier loss: 0.706138; batch adversarial loss: 0.633599\n",
      "epoch 11; iter: 0; batch classifier loss: 0.626433; batch adversarial loss: 0.577281\n",
      "epoch 12; iter: 0; batch classifier loss: 0.276149; batch adversarial loss: 0.563003\n",
      "epoch 13; iter: 0; batch classifier loss: 0.329948; batch adversarial loss: 0.537069\n",
      "epoch 14; iter: 0; batch classifier loss: 0.247618; batch adversarial loss: 0.501660\n",
      "epoch 15; iter: 0; batch classifier loss: 0.200587; batch adversarial loss: 0.540790\n",
      "epoch 16; iter: 0; batch classifier loss: 0.156498; batch adversarial loss: 0.475035\n",
      "epoch 17; iter: 0; batch classifier loss: 0.191462; batch adversarial loss: 0.542260\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237708; batch adversarial loss: 0.494640\n",
      "epoch 19; iter: 0; batch classifier loss: 0.260108; batch adversarial loss: 0.474980\n",
      "epoch 20; iter: 0; batch classifier loss: 0.310739; batch adversarial loss: 0.487002\n",
      "epoch 21; iter: 0; batch classifier loss: 0.200144; batch adversarial loss: 0.501090\n",
      "epoch 22; iter: 0; batch classifier loss: 0.196507; batch adversarial loss: 0.486830\n",
      "epoch 23; iter: 0; batch classifier loss: 0.153370; batch adversarial loss: 0.522714\n",
      "epoch 24; iter: 0; batch classifier loss: 0.150416; batch adversarial loss: 0.411520\n",
      "epoch 25; iter: 0; batch classifier loss: 0.181432; batch adversarial loss: 0.503732\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194085; batch adversarial loss: 0.406449\n",
      "epoch 27; iter: 0; batch classifier loss: 0.081297; batch adversarial loss: 0.505214\n",
      "epoch 28; iter: 0; batch classifier loss: 0.129578; batch adversarial loss: 0.411683\n",
      "epoch 29; iter: 0; batch classifier loss: 0.109336; batch adversarial loss: 0.486741\n",
      "epoch 30; iter: 0; batch classifier loss: 0.103324; batch adversarial loss: 0.420801\n",
      "epoch 31; iter: 0; batch classifier loss: 0.102824; batch adversarial loss: 0.496832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.070955; batch adversarial loss: 0.401133\n",
      "epoch 33; iter: 0; batch classifier loss: 0.086771; batch adversarial loss: 0.499871\n",
      "epoch 34; iter: 0; batch classifier loss: 0.110601; batch adversarial loss: 0.397118\n",
      "epoch 35; iter: 0; batch classifier loss: 0.127146; batch adversarial loss: 0.469916\n",
      "epoch 36; iter: 0; batch classifier loss: 0.111926; batch adversarial loss: 0.467462\n",
      "epoch 37; iter: 0; batch classifier loss: 0.080831; batch adversarial loss: 0.451289\n",
      "epoch 38; iter: 0; batch classifier loss: 0.087646; batch adversarial loss: 0.408347\n",
      "epoch 39; iter: 0; batch classifier loss: 0.059026; batch adversarial loss: 0.514686\n",
      "epoch 40; iter: 0; batch classifier loss: 0.074280; batch adversarial loss: 0.444202\n",
      "epoch 41; iter: 0; batch classifier loss: 0.070260; batch adversarial loss: 0.518232\n",
      "epoch 42; iter: 0; batch classifier loss: 0.080228; batch adversarial loss: 0.545163\n",
      "epoch 43; iter: 0; batch classifier loss: 0.085743; batch adversarial loss: 0.344616\n",
      "epoch 44; iter: 0; batch classifier loss: 0.054136; batch adversarial loss: 0.376896\n",
      "epoch 45; iter: 0; batch classifier loss: 0.069435; batch adversarial loss: 0.443201\n",
      "epoch 46; iter: 0; batch classifier loss: 0.053264; batch adversarial loss: 0.423153\n",
      "epoch 47; iter: 0; batch classifier loss: 0.125043; batch adversarial loss: 0.529372\n",
      "epoch 48; iter: 0; batch classifier loss: 0.044662; batch adversarial loss: 0.362811\n",
      "epoch 49; iter: 0; batch classifier loss: 0.073215; batch adversarial loss: 0.417054\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083761; batch adversarial loss: 0.461493\n",
      "epoch 51; iter: 0; batch classifier loss: 0.066100; batch adversarial loss: 0.434330\n",
      "epoch 52; iter: 0; batch classifier loss: 0.064237; batch adversarial loss: 0.382939\n",
      "epoch 53; iter: 0; batch classifier loss: 0.049268; batch adversarial loss: 0.420831\n",
      "epoch 54; iter: 0; batch classifier loss: 0.039815; batch adversarial loss: 0.491256\n",
      "epoch 55; iter: 0; batch classifier loss: 0.043238; batch adversarial loss: 0.430604\n",
      "epoch 56; iter: 0; batch classifier loss: 0.060136; batch adversarial loss: 0.403317\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061641; batch adversarial loss: 0.425354\n",
      "epoch 58; iter: 0; batch classifier loss: 0.061847; batch adversarial loss: 0.476652\n",
      "epoch 59; iter: 0; batch classifier loss: 0.040037; batch adversarial loss: 0.389844\n",
      "epoch 60; iter: 0; batch classifier loss: 0.051105; batch adversarial loss: 0.327559\n",
      "epoch 61; iter: 0; batch classifier loss: 0.023690; batch adversarial loss: 0.441282\n",
      "epoch 62; iter: 0; batch classifier loss: 0.044539; batch adversarial loss: 0.457176\n",
      "epoch 63; iter: 0; batch classifier loss: 0.036586; batch adversarial loss: 0.525648\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073416; batch adversarial loss: 0.424289\n",
      "epoch 65; iter: 0; batch classifier loss: 0.052521; batch adversarial loss: 0.530562\n",
      "epoch 66; iter: 0; batch classifier loss: 0.029742; batch adversarial loss: 0.437611\n",
      "epoch 67; iter: 0; batch classifier loss: 0.035425; batch adversarial loss: 0.372005\n",
      "epoch 68; iter: 0; batch classifier loss: 0.029143; batch adversarial loss: 0.417508\n",
      "epoch 69; iter: 0; batch classifier loss: 0.051872; batch adversarial loss: 0.467255\n",
      "epoch 70; iter: 0; batch classifier loss: 0.038309; batch adversarial loss: 0.400306\n",
      "epoch 71; iter: 0; batch classifier loss: 0.077299; batch adversarial loss: 0.457659\n",
      "epoch 72; iter: 0; batch classifier loss: 0.034186; batch adversarial loss: 0.431828\n",
      "epoch 73; iter: 0; batch classifier loss: 0.038768; batch adversarial loss: 0.473075\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064099; batch adversarial loss: 0.368661\n",
      "epoch 75; iter: 0; batch classifier loss: 0.041669; batch adversarial loss: 0.504557\n",
      "epoch 76; iter: 0; batch classifier loss: 0.048373; batch adversarial loss: 0.472342\n",
      "epoch 77; iter: 0; batch classifier loss: 0.061321; batch adversarial loss: 0.379435\n",
      "epoch 78; iter: 0; batch classifier loss: 0.045572; batch adversarial loss: 0.457754\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057498; batch adversarial loss: 0.458886\n",
      "epoch 80; iter: 0; batch classifier loss: 0.057108; batch adversarial loss: 0.444218\n",
      "epoch 81; iter: 0; batch classifier loss: 0.038891; batch adversarial loss: 0.407118\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063683; batch adversarial loss: 0.512542\n",
      "epoch 83; iter: 0; batch classifier loss: 0.042773; batch adversarial loss: 0.469882\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048797; batch adversarial loss: 0.411155\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046418; batch adversarial loss: 0.449515\n",
      "epoch 86; iter: 0; batch classifier loss: 0.029640; batch adversarial loss: 0.532113\n",
      "epoch 87; iter: 0; batch classifier loss: 0.037803; batch adversarial loss: 0.416126\n",
      "epoch 88; iter: 0; batch classifier loss: 0.098498; batch adversarial loss: 0.493569\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054191; batch adversarial loss: 0.377516\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065598; batch adversarial loss: 0.409105\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048207; batch adversarial loss: 0.504082\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043612; batch adversarial loss: 0.386222\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077605; batch adversarial loss: 0.450054\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053668; batch adversarial loss: 0.400131\n",
      "epoch 95; iter: 0; batch classifier loss: 0.022416; batch adversarial loss: 0.387571\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065016; batch adversarial loss: 0.359534\n",
      "epoch 97; iter: 0; batch classifier loss: 0.021229; batch adversarial loss: 0.402758\n",
      "epoch 98; iter: 0; batch classifier loss: 0.031482; batch adversarial loss: 0.362949\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042824; batch adversarial loss: 0.440126\n",
      "epoch 100; iter: 0; batch classifier loss: 0.052920; batch adversarial loss: 0.420850\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046701; batch adversarial loss: 0.444005\n",
      "epoch 102; iter: 0; batch classifier loss: 0.069896; batch adversarial loss: 0.486233\n",
      "epoch 103; iter: 0; batch classifier loss: 0.077471; batch adversarial loss: 0.516107\n",
      "epoch 104; iter: 0; batch classifier loss: 0.085053; batch adversarial loss: 0.426701\n",
      "epoch 105; iter: 0; batch classifier loss: 0.026350; batch adversarial loss: 0.418672\n",
      "epoch 106; iter: 0; batch classifier loss: 0.022376; batch adversarial loss: 0.368978\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049875; batch adversarial loss: 0.444142\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043956; batch adversarial loss: 0.424817\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042982; batch adversarial loss: 0.445825\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047775; batch adversarial loss: 0.419527\n",
      "epoch 111; iter: 0; batch classifier loss: 0.071150; batch adversarial loss: 0.388288\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025123; batch adversarial loss: 0.391524\n",
      "epoch 113; iter: 0; batch classifier loss: 0.094953; batch adversarial loss: 0.544983\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026079; batch adversarial loss: 0.404936\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024376; batch adversarial loss: 0.382521\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045005; batch adversarial loss: 0.409210\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035153; batch adversarial loss: 0.329150\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041517; batch adversarial loss: 0.314014\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038627; batch adversarial loss: 0.452634\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022970; batch adversarial loss: 0.444380\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053077; batch adversarial loss: 0.477585\n",
      "epoch 122; iter: 0; batch classifier loss: 0.063137; batch adversarial loss: 0.467925\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035872; batch adversarial loss: 0.362692\n",
      "epoch 124; iter: 0; batch classifier loss: 0.034904; batch adversarial loss: 0.399020\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041963; batch adversarial loss: 0.470577\n",
      "epoch 126; iter: 0; batch classifier loss: 0.067417; batch adversarial loss: 0.515347\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051536; batch adversarial loss: 0.457087\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036220; batch adversarial loss: 0.420371\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028477; batch adversarial loss: 0.437080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.022251; batch adversarial loss: 0.406023\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040616; batch adversarial loss: 0.540761\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044666; batch adversarial loss: 0.473866\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054050; batch adversarial loss: 0.386366\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019082; batch adversarial loss: 0.494254\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029272; batch adversarial loss: 0.482785\n",
      "epoch 136; iter: 0; batch classifier loss: 0.076253; batch adversarial loss: 0.401061\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046717; batch adversarial loss: 0.386755\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056068; batch adversarial loss: 0.467093\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035544; batch adversarial loss: 0.462690\n",
      "epoch 140; iter: 0; batch classifier loss: 0.055066; batch adversarial loss: 0.406098\n",
      "epoch 141; iter: 0; batch classifier loss: 0.060253; batch adversarial loss: 0.365985\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017783; batch adversarial loss: 0.470348\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039163; batch adversarial loss: 0.438231\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021221; batch adversarial loss: 0.434158\n",
      "epoch 145; iter: 0; batch classifier loss: 0.061441; batch adversarial loss: 0.386543\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020338; batch adversarial loss: 0.421291\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038664; batch adversarial loss: 0.364161\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040838; batch adversarial loss: 0.394132\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020483; batch adversarial loss: 0.390760\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025956; batch adversarial loss: 0.496624\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017620; batch adversarial loss: 0.363030\n",
      "epoch 152; iter: 0; batch classifier loss: 0.058443; batch adversarial loss: 0.402526\n",
      "epoch 153; iter: 0; batch classifier loss: 0.045583; batch adversarial loss: 0.388987\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029676; batch adversarial loss: 0.445435\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033414; batch adversarial loss: 0.447279\n",
      "epoch 156; iter: 0; batch classifier loss: 0.053536; batch adversarial loss: 0.504216\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039764; batch adversarial loss: 0.376775\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040076; batch adversarial loss: 0.396553\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036938; batch adversarial loss: 0.495059\n",
      "epoch 160; iter: 0; batch classifier loss: 0.054078; batch adversarial loss: 0.338223\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027081; batch adversarial loss: 0.546423\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034059; batch adversarial loss: 0.498754\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022867; batch adversarial loss: 0.443522\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034832; batch adversarial loss: 0.361325\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023960; batch adversarial loss: 0.408266\n",
      "epoch 166; iter: 0; batch classifier loss: 0.044356; batch adversarial loss: 0.392545\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024596; batch adversarial loss: 0.476193\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045647; batch adversarial loss: 0.375793\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038874; batch adversarial loss: 0.384581\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033914; batch adversarial loss: 0.377268\n",
      "epoch 171; iter: 0; batch classifier loss: 0.050217; batch adversarial loss: 0.421449\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030254; batch adversarial loss: 0.427303\n",
      "epoch 173; iter: 0; batch classifier loss: 0.049589; batch adversarial loss: 0.413168\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029664; batch adversarial loss: 0.485463\n",
      "epoch 175; iter: 0; batch classifier loss: 0.045233; batch adversarial loss: 0.435582\n",
      "epoch 176; iter: 0; batch classifier loss: 0.071704; batch adversarial loss: 0.421618\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024260; batch adversarial loss: 0.495814\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038892; batch adversarial loss: 0.356611\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027975; batch adversarial loss: 0.404604\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026627; batch adversarial loss: 0.331766\n",
      "epoch 181; iter: 0; batch classifier loss: 0.055277; batch adversarial loss: 0.447769\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023063; batch adversarial loss: 0.479348\n",
      "epoch 183; iter: 0; batch classifier loss: 0.057088; batch adversarial loss: 0.438380\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022087; batch adversarial loss: 0.416062\n",
      "epoch 185; iter: 0; batch classifier loss: 0.053633; batch adversarial loss: 0.447799\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032831; batch adversarial loss: 0.530104\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025705; batch adversarial loss: 0.358416\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041577; batch adversarial loss: 0.368710\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035690; batch adversarial loss: 0.432385\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050739; batch adversarial loss: 0.423290\n",
      "epoch 191; iter: 0; batch classifier loss: 0.057649; batch adversarial loss: 0.534471\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036356; batch adversarial loss: 0.342410\n",
      "epoch 193; iter: 0; batch classifier loss: 0.048093; batch adversarial loss: 0.485495\n",
      "epoch 194; iter: 0; batch classifier loss: 0.037571; batch adversarial loss: 0.438067\n",
      "epoch 195; iter: 0; batch classifier loss: 0.046063; batch adversarial loss: 0.439746\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028415; batch adversarial loss: 0.479351\n",
      "epoch 197; iter: 0; batch classifier loss: 0.042617; batch adversarial loss: 0.467834\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029400; batch adversarial loss: 0.397898\n",
      "epoch 199; iter: 0; batch classifier loss: 0.071109; batch adversarial loss: 0.429648\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717050; batch adversarial loss: 0.779313\n",
      "epoch 1; iter: 0; batch classifier loss: 0.468159; batch adversarial loss: 0.732749\n",
      "epoch 2; iter: 0; batch classifier loss: 0.403156; batch adversarial loss: 0.686506\n",
      "epoch 3; iter: 0; batch classifier loss: 0.411514; batch adversarial loss: 0.659979\n",
      "epoch 4; iter: 0; batch classifier loss: 0.349847; batch adversarial loss: 0.623894\n",
      "epoch 5; iter: 0; batch classifier loss: 0.450314; batch adversarial loss: 0.597580\n",
      "epoch 6; iter: 0; batch classifier loss: 0.365509; batch adversarial loss: 0.580417\n",
      "epoch 7; iter: 0; batch classifier loss: 0.311647; batch adversarial loss: 0.558450\n",
      "epoch 8; iter: 0; batch classifier loss: 0.218610; batch adversarial loss: 0.574180\n",
      "epoch 9; iter: 0; batch classifier loss: 0.287113; batch adversarial loss: 0.494651\n",
      "epoch 10; iter: 0; batch classifier loss: 0.259404; batch adversarial loss: 0.531605\n",
      "epoch 11; iter: 0; batch classifier loss: 0.283612; batch adversarial loss: 0.457231\n",
      "epoch 12; iter: 0; batch classifier loss: 0.252198; batch adversarial loss: 0.502108\n",
      "epoch 13; iter: 0; batch classifier loss: 0.276428; batch adversarial loss: 0.498800\n",
      "epoch 14; iter: 0; batch classifier loss: 0.186790; batch adversarial loss: 0.543307\n",
      "epoch 15; iter: 0; batch classifier loss: 0.207533; batch adversarial loss: 0.497520\n",
      "epoch 16; iter: 0; batch classifier loss: 0.189042; batch adversarial loss: 0.473206\n",
      "epoch 17; iter: 0; batch classifier loss: 0.273261; batch adversarial loss: 0.501618\n",
      "epoch 18; iter: 0; batch classifier loss: 0.297542; batch adversarial loss: 0.542156\n",
      "epoch 19; iter: 0; batch classifier loss: 0.375599; batch adversarial loss: 0.512652\n",
      "epoch 20; iter: 0; batch classifier loss: 0.319919; batch adversarial loss: 0.436665\n",
      "epoch 21; iter: 0; batch classifier loss: 0.450203; batch adversarial loss: 0.475245\n",
      "epoch 22; iter: 0; batch classifier loss: 0.332098; batch adversarial loss: 0.512279\n",
      "epoch 23; iter: 0; batch classifier loss: 0.212784; batch adversarial loss: 0.462450\n",
      "epoch 24; iter: 0; batch classifier loss: 0.209403; batch adversarial loss: 0.454205\n",
      "epoch 25; iter: 0; batch classifier loss: 0.232707; batch adversarial loss: 0.471970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.207103; batch adversarial loss: 0.520246\n",
      "epoch 27; iter: 0; batch classifier loss: 0.186565; batch adversarial loss: 0.486460\n",
      "epoch 28; iter: 0; batch classifier loss: 0.168482; batch adversarial loss: 0.458401\n",
      "epoch 29; iter: 0; batch classifier loss: 0.132858; batch adversarial loss: 0.561463\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162151; batch adversarial loss: 0.459993\n",
      "epoch 31; iter: 0; batch classifier loss: 0.145704; batch adversarial loss: 0.465951\n",
      "epoch 32; iter: 0; batch classifier loss: 0.161303; batch adversarial loss: 0.428913\n",
      "epoch 33; iter: 0; batch classifier loss: 0.176672; batch adversarial loss: 0.463783\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142564; batch adversarial loss: 0.464645\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153225; batch adversarial loss: 0.513171\n",
      "epoch 36; iter: 0; batch classifier loss: 0.139569; batch adversarial loss: 0.484752\n",
      "epoch 37; iter: 0; batch classifier loss: 0.152529; batch adversarial loss: 0.341512\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148810; batch adversarial loss: 0.560647\n",
      "epoch 39; iter: 0; batch classifier loss: 0.152679; batch adversarial loss: 0.395816\n",
      "epoch 40; iter: 0; batch classifier loss: 0.106945; batch adversarial loss: 0.496477\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109394; batch adversarial loss: 0.429568\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111777; batch adversarial loss: 0.421669\n",
      "epoch 43; iter: 0; batch classifier loss: 0.118896; batch adversarial loss: 0.567519\n",
      "epoch 44; iter: 0; batch classifier loss: 0.129840; batch adversarial loss: 0.513931\n",
      "epoch 45; iter: 0; batch classifier loss: 0.110200; batch adversarial loss: 0.467056\n",
      "epoch 46; iter: 0; batch classifier loss: 0.101687; batch adversarial loss: 0.481871\n",
      "epoch 47; iter: 0; batch classifier loss: 0.094192; batch adversarial loss: 0.478447\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099580; batch adversarial loss: 0.463155\n",
      "epoch 49; iter: 0; batch classifier loss: 0.277243; batch adversarial loss: 0.425091\n",
      "epoch 50; iter: 0; batch classifier loss: 0.139916; batch adversarial loss: 0.426722\n",
      "epoch 51; iter: 0; batch classifier loss: 0.091388; batch adversarial loss: 0.476903\n",
      "epoch 52; iter: 0; batch classifier loss: 0.080948; batch adversarial loss: 0.440614\n",
      "epoch 53; iter: 0; batch classifier loss: 0.102314; batch adversarial loss: 0.467719\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099516; batch adversarial loss: 0.365072\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083806; batch adversarial loss: 0.438166\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101309; batch adversarial loss: 0.468460\n",
      "epoch 57; iter: 0; batch classifier loss: 0.040130; batch adversarial loss: 0.408129\n",
      "epoch 58; iter: 0; batch classifier loss: 0.045125; batch adversarial loss: 0.579936\n",
      "epoch 59; iter: 0; batch classifier loss: 0.093845; batch adversarial loss: 0.459007\n",
      "epoch 60; iter: 0; batch classifier loss: 0.112240; batch adversarial loss: 0.538141\n",
      "epoch 61; iter: 0; batch classifier loss: 0.117688; batch adversarial loss: 0.402782\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093101; batch adversarial loss: 0.497782\n",
      "epoch 63; iter: 0; batch classifier loss: 0.086420; batch adversarial loss: 0.431624\n",
      "epoch 64; iter: 0; batch classifier loss: 0.115716; batch adversarial loss: 0.381049\n",
      "epoch 65; iter: 0; batch classifier loss: 0.054238; batch adversarial loss: 0.523581\n",
      "epoch 66; iter: 0; batch classifier loss: 0.081106; batch adversarial loss: 0.573735\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096103; batch adversarial loss: 0.397948\n",
      "epoch 68; iter: 0; batch classifier loss: 0.057898; batch adversarial loss: 0.524110\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061988; batch adversarial loss: 0.493812\n",
      "epoch 70; iter: 0; batch classifier loss: 0.051833; batch adversarial loss: 0.404884\n",
      "epoch 71; iter: 0; batch classifier loss: 0.085631; batch adversarial loss: 0.436726\n",
      "epoch 72; iter: 0; batch classifier loss: 0.046989; batch adversarial loss: 0.482499\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055024; batch adversarial loss: 0.538036\n",
      "epoch 74; iter: 0; batch classifier loss: 0.062193; batch adversarial loss: 0.452271\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059693; batch adversarial loss: 0.429737\n",
      "epoch 76; iter: 0; batch classifier loss: 0.123980; batch adversarial loss: 0.432400\n",
      "epoch 77; iter: 0; batch classifier loss: 0.041634; batch adversarial loss: 0.554674\n",
      "epoch 78; iter: 0; batch classifier loss: 0.040034; batch adversarial loss: 0.439554\n",
      "epoch 79; iter: 0; batch classifier loss: 0.107179; batch adversarial loss: 0.440968\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070211; batch adversarial loss: 0.459183\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057121; batch adversarial loss: 0.426652\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067014; batch adversarial loss: 0.433274\n",
      "epoch 83; iter: 0; batch classifier loss: 0.046367; batch adversarial loss: 0.464943\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045977; batch adversarial loss: 0.469799\n",
      "epoch 85; iter: 0; batch classifier loss: 0.072833; batch adversarial loss: 0.552382\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070346; batch adversarial loss: 0.511047\n",
      "epoch 87; iter: 0; batch classifier loss: 0.063424; batch adversarial loss: 0.379855\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040608; batch adversarial loss: 0.545362\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050806; batch adversarial loss: 0.354401\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053254; batch adversarial loss: 0.430707\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039277; batch adversarial loss: 0.481863\n",
      "epoch 92; iter: 0; batch classifier loss: 0.028917; batch adversarial loss: 0.490286\n",
      "epoch 93; iter: 0; batch classifier loss: 0.017477; batch adversarial loss: 0.618799\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050460; batch adversarial loss: 0.524038\n",
      "epoch 95; iter: 0; batch classifier loss: 0.059727; batch adversarial loss: 0.526708\n",
      "epoch 96; iter: 0; batch classifier loss: 0.067147; batch adversarial loss: 0.522042\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070718; batch adversarial loss: 0.369319\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036538; batch adversarial loss: 0.624107\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062524; batch adversarial loss: 0.546663\n",
      "epoch 100; iter: 0; batch classifier loss: 0.031639; batch adversarial loss: 0.474341\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049184; batch adversarial loss: 0.385101\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037940; batch adversarial loss: 0.446214\n",
      "epoch 103; iter: 0; batch classifier loss: 0.023667; batch adversarial loss: 0.524046\n",
      "epoch 104; iter: 0; batch classifier loss: 0.030436; batch adversarial loss: 0.465697\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034009; batch adversarial loss: 0.527380\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056160; batch adversarial loss: 0.392644\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041559; batch adversarial loss: 0.457917\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053385; batch adversarial loss: 0.496136\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058923; batch adversarial loss: 0.476205\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044910; batch adversarial loss: 0.447964\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036149; batch adversarial loss: 0.459010\n",
      "epoch 112; iter: 0; batch classifier loss: 0.062260; batch adversarial loss: 0.428917\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040757; batch adversarial loss: 0.444370\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049707; batch adversarial loss: 0.512627\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063594; batch adversarial loss: 0.385504\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034771; batch adversarial loss: 0.513415\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060407; batch adversarial loss: 0.419204\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026512; batch adversarial loss: 0.402221\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033732; batch adversarial loss: 0.406116\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022183; batch adversarial loss: 0.554074\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046879; batch adversarial loss: 0.487188\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041501; batch adversarial loss: 0.440031\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043483; batch adversarial loss: 0.532970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.066741; batch adversarial loss: 0.444915\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029304; batch adversarial loss: 0.453138\n",
      "epoch 126; iter: 0; batch classifier loss: 0.059090; batch adversarial loss: 0.438517\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029986; batch adversarial loss: 0.485305\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047788; batch adversarial loss: 0.414407\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041566; batch adversarial loss: 0.568517\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030451; batch adversarial loss: 0.438562\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027489; batch adversarial loss: 0.446427\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022925; batch adversarial loss: 0.567161\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041251; batch adversarial loss: 0.453032\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034162; batch adversarial loss: 0.478007\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023625; batch adversarial loss: 0.454816\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029459; batch adversarial loss: 0.450597\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043300; batch adversarial loss: 0.458908\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027213; batch adversarial loss: 0.507543\n",
      "epoch 139; iter: 0; batch classifier loss: 0.048531; batch adversarial loss: 0.493995\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052024; batch adversarial loss: 0.467739\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029660; batch adversarial loss: 0.482955\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039138; batch adversarial loss: 0.399711\n",
      "epoch 143; iter: 0; batch classifier loss: 0.056349; batch adversarial loss: 0.571052\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019743; batch adversarial loss: 0.491613\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025103; batch adversarial loss: 0.489690\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030135; batch adversarial loss: 0.446311\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040489; batch adversarial loss: 0.565080\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028643; batch adversarial loss: 0.436246\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022258; batch adversarial loss: 0.529928\n",
      "epoch 150; iter: 0; batch classifier loss: 0.005874; batch adversarial loss: 0.488965\n",
      "epoch 151; iter: 0; batch classifier loss: 0.049226; batch adversarial loss: 0.397971\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028862; batch adversarial loss: 0.425703\n",
      "epoch 153; iter: 0; batch classifier loss: 0.053291; batch adversarial loss: 0.359079\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023097; batch adversarial loss: 0.421787\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046394; batch adversarial loss: 0.504993\n",
      "epoch 156; iter: 0; batch classifier loss: 0.091643; batch adversarial loss: 0.510279\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047020; batch adversarial loss: 0.559489\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047697; batch adversarial loss: 0.427250\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034557; batch adversarial loss: 0.515002\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018229; batch adversarial loss: 0.440746\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025294; batch adversarial loss: 0.457681\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015177; batch adversarial loss: 0.417185\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025513; batch adversarial loss: 0.468327\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019322; batch adversarial loss: 0.521406\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035135; batch adversarial loss: 0.445582\n",
      "epoch 166; iter: 0; batch classifier loss: 0.048342; batch adversarial loss: 0.451087\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016715; batch adversarial loss: 0.417668\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019965; batch adversarial loss: 0.438527\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017411; batch adversarial loss: 0.565086\n",
      "epoch 170; iter: 0; batch classifier loss: 0.042596; batch adversarial loss: 0.452548\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022088; batch adversarial loss: 0.483619\n",
      "epoch 172; iter: 0; batch classifier loss: 0.050140; batch adversarial loss: 0.442744\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025848; batch adversarial loss: 0.485337\n",
      "epoch 174; iter: 0; batch classifier loss: 0.053868; batch adversarial loss: 0.486507\n",
      "epoch 175; iter: 0; batch classifier loss: 0.072056; batch adversarial loss: 0.445634\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008778; batch adversarial loss: 0.366096\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038294; batch adversarial loss: 0.380974\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031552; batch adversarial loss: 0.486629\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020438; batch adversarial loss: 0.452610\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015388; batch adversarial loss: 0.459589\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025915; batch adversarial loss: 0.492248\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029060; batch adversarial loss: 0.539923\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032626; batch adversarial loss: 0.424048\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019726; batch adversarial loss: 0.393497\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026708; batch adversarial loss: 0.539595\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025227; batch adversarial loss: 0.471721\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028236; batch adversarial loss: 0.462055\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012097; batch adversarial loss: 0.485978\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027907; batch adversarial loss: 0.418352\n",
      "epoch 190; iter: 0; batch classifier loss: 0.081898; batch adversarial loss: 0.452794\n",
      "epoch 191; iter: 0; batch classifier loss: 0.059248; batch adversarial loss: 0.422540\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026145; batch adversarial loss: 0.515527\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015725; batch adversarial loss: 0.441180\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014737; batch adversarial loss: 0.367057\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037926; batch adversarial loss: 0.367758\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037298; batch adversarial loss: 0.466417\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018780; batch adversarial loss: 0.564307\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030287; batch adversarial loss: 0.506315\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019329; batch adversarial loss: 0.471527\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687898; batch adversarial loss: 0.719106\n",
      "epoch 1; iter: 0; batch classifier loss: 0.523503; batch adversarial loss: 0.679041\n",
      "epoch 2; iter: 0; batch classifier loss: 0.458360; batch adversarial loss: 0.620111\n",
      "epoch 3; iter: 0; batch classifier loss: 0.370741; batch adversarial loss: 0.602874\n",
      "epoch 4; iter: 0; batch classifier loss: 0.345841; batch adversarial loss: 0.575888\n",
      "epoch 5; iter: 0; batch classifier loss: 0.296773; batch adversarial loss: 0.556523\n",
      "epoch 6; iter: 0; batch classifier loss: 0.313082; batch adversarial loss: 0.550546\n",
      "epoch 7; iter: 0; batch classifier loss: 0.390075; batch adversarial loss: 0.526676\n",
      "epoch 8; iter: 0; batch classifier loss: 0.287526; batch adversarial loss: 0.549046\n",
      "epoch 9; iter: 0; batch classifier loss: 0.339964; batch adversarial loss: 0.513577\n",
      "epoch 10; iter: 0; batch classifier loss: 0.281088; batch adversarial loss: 0.523328\n",
      "epoch 11; iter: 0; batch classifier loss: 0.291945; batch adversarial loss: 0.527262\n",
      "epoch 12; iter: 0; batch classifier loss: 0.253307; batch adversarial loss: 0.517401\n",
      "epoch 13; iter: 0; batch classifier loss: 0.384370; batch adversarial loss: 0.457633\n",
      "epoch 14; iter: 0; batch classifier loss: 0.328567; batch adversarial loss: 0.515694\n",
      "epoch 15; iter: 0; batch classifier loss: 0.283728; batch adversarial loss: 0.561411\n",
      "epoch 16; iter: 0; batch classifier loss: 0.250965; batch adversarial loss: 0.558678\n",
      "epoch 17; iter: 0; batch classifier loss: 0.272457; batch adversarial loss: 0.510859\n",
      "epoch 18; iter: 0; batch classifier loss: 0.287617; batch adversarial loss: 0.520546\n",
      "epoch 19; iter: 0; batch classifier loss: 0.281450; batch adversarial loss: 0.505991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.202553; batch adversarial loss: 0.536260\n",
      "epoch 21; iter: 0; batch classifier loss: 0.252239; batch adversarial loss: 0.444663\n",
      "epoch 22; iter: 0; batch classifier loss: 0.324836; batch adversarial loss: 0.506061\n",
      "epoch 23; iter: 0; batch classifier loss: 0.224566; batch adversarial loss: 0.419159\n",
      "epoch 24; iter: 0; batch classifier loss: 0.263970; batch adversarial loss: 0.507725\n",
      "epoch 25; iter: 0; batch classifier loss: 0.211219; batch adversarial loss: 0.411665\n",
      "epoch 26; iter: 0; batch classifier loss: 0.320106; batch adversarial loss: 0.433770\n",
      "epoch 27; iter: 0; batch classifier loss: 0.286569; batch adversarial loss: 0.497690\n",
      "epoch 28; iter: 0; batch classifier loss: 0.323513; batch adversarial loss: 0.400604\n",
      "epoch 29; iter: 0; batch classifier loss: 0.254554; batch adversarial loss: 0.457299\n",
      "epoch 30; iter: 0; batch classifier loss: 0.262694; batch adversarial loss: 0.547333\n",
      "epoch 31; iter: 0; batch classifier loss: 0.224874; batch adversarial loss: 0.434177\n",
      "epoch 32; iter: 0; batch classifier loss: 0.252339; batch adversarial loss: 0.421004\n",
      "epoch 33; iter: 0; batch classifier loss: 0.202860; batch adversarial loss: 0.469045\n",
      "epoch 34; iter: 0; batch classifier loss: 0.202815; batch adversarial loss: 0.591716\n",
      "epoch 35; iter: 0; batch classifier loss: 0.201815; batch adversarial loss: 0.496918\n",
      "epoch 36; iter: 0; batch classifier loss: 0.340610; batch adversarial loss: 0.470540\n",
      "epoch 37; iter: 0; batch classifier loss: 0.218077; batch adversarial loss: 0.505490\n",
      "epoch 38; iter: 0; batch classifier loss: 0.201559; batch adversarial loss: 0.520604\n",
      "epoch 39; iter: 0; batch classifier loss: 0.204172; batch adversarial loss: 0.500223\n",
      "epoch 40; iter: 0; batch classifier loss: 0.231874; batch adversarial loss: 0.444206\n",
      "epoch 41; iter: 0; batch classifier loss: 0.218105; batch adversarial loss: 0.577934\n",
      "epoch 42; iter: 0; batch classifier loss: 0.264795; batch adversarial loss: 0.308149\n",
      "epoch 43; iter: 0; batch classifier loss: 0.230096; batch adversarial loss: 0.510904\n",
      "epoch 44; iter: 0; batch classifier loss: 0.321702; batch adversarial loss: 0.407960\n",
      "epoch 45; iter: 0; batch classifier loss: 0.279697; batch adversarial loss: 0.460420\n",
      "epoch 46; iter: 0; batch classifier loss: 0.263369; batch adversarial loss: 0.333124\n",
      "epoch 47; iter: 0; batch classifier loss: 0.236449; batch adversarial loss: 0.497812\n",
      "epoch 48; iter: 0; batch classifier loss: 0.281069; batch adversarial loss: 0.422238\n",
      "epoch 49; iter: 0; batch classifier loss: 0.285954; batch adversarial loss: 0.497200\n",
      "epoch 50; iter: 0; batch classifier loss: 0.234937; batch adversarial loss: 0.339293\n",
      "epoch 51; iter: 0; batch classifier loss: 0.293083; batch adversarial loss: 0.483984\n",
      "epoch 52; iter: 0; batch classifier loss: 0.312920; batch adversarial loss: 0.351311\n",
      "epoch 53; iter: 0; batch classifier loss: 0.139175; batch adversarial loss: 0.482638\n",
      "epoch 54; iter: 0; batch classifier loss: 0.146584; batch adversarial loss: 0.384333\n",
      "epoch 55; iter: 0; batch classifier loss: 0.118086; batch adversarial loss: 0.430291\n",
      "epoch 56; iter: 0; batch classifier loss: 0.074406; batch adversarial loss: 0.471682\n",
      "epoch 57; iter: 0; batch classifier loss: 0.121192; batch adversarial loss: 0.458389\n",
      "epoch 58; iter: 0; batch classifier loss: 0.112094; batch adversarial loss: 0.503930\n",
      "epoch 59; iter: 0; batch classifier loss: 0.206910; batch adversarial loss: 0.455643\n",
      "epoch 60; iter: 0; batch classifier loss: 0.210254; batch adversarial loss: 0.495845\n",
      "epoch 61; iter: 0; batch classifier loss: 0.229865; batch adversarial loss: 0.384334\n",
      "epoch 62; iter: 0; batch classifier loss: 0.187137; batch adversarial loss: 0.473604\n",
      "epoch 63; iter: 0; batch classifier loss: 0.227310; batch adversarial loss: 0.459925\n",
      "epoch 64; iter: 0; batch classifier loss: 0.193490; batch adversarial loss: 0.422355\n",
      "epoch 65; iter: 0; batch classifier loss: 0.116718; batch adversarial loss: 0.470321\n",
      "epoch 66; iter: 0; batch classifier loss: 0.196693; batch adversarial loss: 0.486184\n",
      "epoch 67; iter: 0; batch classifier loss: 0.293932; batch adversarial loss: 0.421750\n",
      "epoch 68; iter: 0; batch classifier loss: 0.206589; batch adversarial loss: 0.433866\n",
      "epoch 69; iter: 0; batch classifier loss: 0.220915; batch adversarial loss: 0.434385\n",
      "epoch 70; iter: 0; batch classifier loss: 0.195644; batch adversarial loss: 0.495906\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089040; batch adversarial loss: 0.471336\n",
      "epoch 72; iter: 0; batch classifier loss: 0.098385; batch adversarial loss: 0.357597\n",
      "epoch 73; iter: 0; batch classifier loss: 0.128564; batch adversarial loss: 0.492436\n",
      "epoch 74; iter: 0; batch classifier loss: 0.087281; batch adversarial loss: 0.471224\n",
      "epoch 75; iter: 0; batch classifier loss: 0.101428; batch adversarial loss: 0.445455\n",
      "epoch 76; iter: 0; batch classifier loss: 0.137898; batch adversarial loss: 0.429295\n",
      "epoch 77; iter: 0; batch classifier loss: 0.179503; batch adversarial loss: 0.425063\n",
      "epoch 78; iter: 0; batch classifier loss: 0.128985; batch adversarial loss: 0.504649\n",
      "epoch 79; iter: 0; batch classifier loss: 0.142565; batch adversarial loss: 0.461166\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067985; batch adversarial loss: 0.404424\n",
      "epoch 81; iter: 0; batch classifier loss: 0.078871; batch adversarial loss: 0.425999\n",
      "epoch 82; iter: 0; batch classifier loss: 0.119077; batch adversarial loss: 0.408289\n",
      "epoch 83; iter: 0; batch classifier loss: 0.090290; batch adversarial loss: 0.473623\n",
      "epoch 84; iter: 0; batch classifier loss: 0.108064; batch adversarial loss: 0.457443\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070011; batch adversarial loss: 0.440216\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067868; batch adversarial loss: 0.405935\n",
      "epoch 87; iter: 0; batch classifier loss: 0.085953; batch adversarial loss: 0.546884\n",
      "epoch 88; iter: 0; batch classifier loss: 0.077519; batch adversarial loss: 0.525429\n",
      "epoch 89; iter: 0; batch classifier loss: 0.099984; batch adversarial loss: 0.421090\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087141; batch adversarial loss: 0.350512\n",
      "epoch 91; iter: 0; batch classifier loss: 0.053782; batch adversarial loss: 0.468139\n",
      "epoch 92; iter: 0; batch classifier loss: 0.085849; batch adversarial loss: 0.481012\n",
      "epoch 93; iter: 0; batch classifier loss: 0.076350; batch adversarial loss: 0.438318\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046217; batch adversarial loss: 0.495671\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060365; batch adversarial loss: 0.487102\n",
      "epoch 96; iter: 0; batch classifier loss: 0.054913; batch adversarial loss: 0.420931\n",
      "epoch 97; iter: 0; batch classifier loss: 0.103871; batch adversarial loss: 0.431881\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052106; batch adversarial loss: 0.424604\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071467; batch adversarial loss: 0.444766\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060756; batch adversarial loss: 0.440961\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048327; batch adversarial loss: 0.471709\n",
      "epoch 102; iter: 0; batch classifier loss: 0.061553; batch adversarial loss: 0.591008\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040878; batch adversarial loss: 0.449348\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038088; batch adversarial loss: 0.453844\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040325; batch adversarial loss: 0.469731\n",
      "epoch 106; iter: 0; batch classifier loss: 0.075889; batch adversarial loss: 0.364697\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044514; batch adversarial loss: 0.404050\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064513; batch adversarial loss: 0.537559\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043535; batch adversarial loss: 0.417394\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027169; batch adversarial loss: 0.455192\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031403; batch adversarial loss: 0.438084\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037958; batch adversarial loss: 0.573221\n",
      "epoch 113; iter: 0; batch classifier loss: 0.032376; batch adversarial loss: 0.479549\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060014; batch adversarial loss: 0.365534\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033563; batch adversarial loss: 0.464797\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039734; batch adversarial loss: 0.410821\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025067; batch adversarial loss: 0.376191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.019593; batch adversarial loss: 0.433010\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046660; batch adversarial loss: 0.418749\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053736; batch adversarial loss: 0.490782\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045333; batch adversarial loss: 0.559835\n",
      "epoch 122; iter: 0; batch classifier loss: 0.019685; batch adversarial loss: 0.465206\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035197; batch adversarial loss: 0.391042\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030679; batch adversarial loss: 0.425964\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040321; batch adversarial loss: 0.475123\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055696; batch adversarial loss: 0.414966\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021719; batch adversarial loss: 0.410205\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041667; batch adversarial loss: 0.414715\n",
      "epoch 129; iter: 0; batch classifier loss: 0.008969; batch adversarial loss: 0.511623\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024148; batch adversarial loss: 0.308595\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035182; batch adversarial loss: 0.402729\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031456; batch adversarial loss: 0.399261\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035680; batch adversarial loss: 0.441167\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024292; batch adversarial loss: 0.454579\n",
      "epoch 135; iter: 0; batch classifier loss: 0.008262; batch adversarial loss: 0.485449\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029053; batch adversarial loss: 0.441230\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031926; batch adversarial loss: 0.368605\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016873; batch adversarial loss: 0.371862\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017669; batch adversarial loss: 0.447837\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030342; batch adversarial loss: 0.410871\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016828; batch adversarial loss: 0.477595\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025261; batch adversarial loss: 0.402071\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013468; batch adversarial loss: 0.443481\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029021; batch adversarial loss: 0.386971\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016777; batch adversarial loss: 0.440141\n",
      "epoch 146; iter: 0; batch classifier loss: 0.009247; batch adversarial loss: 0.453054\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026219; batch adversarial loss: 0.422074\n",
      "epoch 148; iter: 0; batch classifier loss: 0.044259; batch adversarial loss: 0.445480\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025931; batch adversarial loss: 0.399599\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023438; batch adversarial loss: 0.384166\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019258; batch adversarial loss: 0.499152\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018433; batch adversarial loss: 0.503847\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015636; batch adversarial loss: 0.388650\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025858; batch adversarial loss: 0.425814\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020896; batch adversarial loss: 0.380575\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019324; batch adversarial loss: 0.377062\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011012; batch adversarial loss: 0.430413\n",
      "epoch 158; iter: 0; batch classifier loss: 0.004180; batch adversarial loss: 0.436012\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018989; batch adversarial loss: 0.492457\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024952; batch adversarial loss: 0.405299\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026540; batch adversarial loss: 0.381261\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011225; batch adversarial loss: 0.429322\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015710; batch adversarial loss: 0.444138\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012006; batch adversarial loss: 0.501145\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014028; batch adversarial loss: 0.367153\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022039; batch adversarial loss: 0.541236\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015723; batch adversarial loss: 0.490855\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023224; batch adversarial loss: 0.552448\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023085; batch adversarial loss: 0.403960\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025973; batch adversarial loss: 0.368886\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020691; batch adversarial loss: 0.438716\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010564; batch adversarial loss: 0.429105\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019952; batch adversarial loss: 0.456496\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020900; batch adversarial loss: 0.337801\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022860; batch adversarial loss: 0.411052\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011167; batch adversarial loss: 0.436904\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010038; batch adversarial loss: 0.540378\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011105; batch adversarial loss: 0.496557\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013019; batch adversarial loss: 0.485297\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013828; batch adversarial loss: 0.356278\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015548; batch adversarial loss: 0.564124\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017781; batch adversarial loss: 0.474063\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010013; batch adversarial loss: 0.517487\n",
      "epoch 184; iter: 0; batch classifier loss: 0.005371; batch adversarial loss: 0.546584\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011859; batch adversarial loss: 0.477322\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013329; batch adversarial loss: 0.577612\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023558; batch adversarial loss: 0.383640\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023176; batch adversarial loss: 0.395446\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035152; batch adversarial loss: 0.443719\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033466; batch adversarial loss: 0.353296\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016398; batch adversarial loss: 0.413697\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006309; batch adversarial loss: 0.521669\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007245; batch adversarial loss: 0.449452\n",
      "epoch 194; iter: 0; batch classifier loss: 0.046737; batch adversarial loss: 0.374365\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013204; batch adversarial loss: 0.390237\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004161; batch adversarial loss: 0.426934\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022075; batch adversarial loss: 0.433371\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007793; batch adversarial loss: 0.480437\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022238; batch adversarial loss: 0.553578\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686843; batch adversarial loss: 0.478108\n",
      "epoch 1; iter: 0; batch classifier loss: 0.487649; batch adversarial loss: 0.586782\n",
      "epoch 2; iter: 0; batch classifier loss: 0.469591; batch adversarial loss: 0.619077\n",
      "epoch 3; iter: 0; batch classifier loss: 0.430894; batch adversarial loss: 0.592984\n",
      "epoch 4; iter: 0; batch classifier loss: 0.382058; batch adversarial loss: 0.523122\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343781; batch adversarial loss: 0.536528\n",
      "epoch 6; iter: 0; batch classifier loss: 0.368876; batch adversarial loss: 0.608306\n",
      "epoch 7; iter: 0; batch classifier loss: 0.379390; batch adversarial loss: 0.532885\n",
      "epoch 8; iter: 0; batch classifier loss: 0.302620; batch adversarial loss: 0.633384\n",
      "epoch 9; iter: 0; batch classifier loss: 0.304301; batch adversarial loss: 0.503056\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358164; batch adversarial loss: 0.583386\n",
      "epoch 11; iter: 0; batch classifier loss: 0.344266; batch adversarial loss: 0.571217\n",
      "epoch 12; iter: 0; batch classifier loss: 0.305058; batch adversarial loss: 0.602905\n",
      "epoch 13; iter: 0; batch classifier loss: 0.342160; batch adversarial loss: 0.537815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.249909; batch adversarial loss: 0.529624\n",
      "epoch 15; iter: 0; batch classifier loss: 0.454678; batch adversarial loss: 0.524241\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503417; batch adversarial loss: 0.605222\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512106; batch adversarial loss: 0.484681\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246157; batch adversarial loss: 0.571774\n",
      "epoch 19; iter: 0; batch classifier loss: 0.176367; batch adversarial loss: 0.450724\n",
      "epoch 20; iter: 0; batch classifier loss: 0.223892; batch adversarial loss: 0.502527\n",
      "epoch 21; iter: 0; batch classifier loss: 0.165363; batch adversarial loss: 0.491764\n",
      "epoch 22; iter: 0; batch classifier loss: 0.128020; batch adversarial loss: 0.467181\n",
      "epoch 23; iter: 0; batch classifier loss: 0.163308; batch adversarial loss: 0.448399\n",
      "epoch 24; iter: 0; batch classifier loss: 0.148641; batch adversarial loss: 0.494628\n",
      "epoch 25; iter: 0; batch classifier loss: 0.159092; batch adversarial loss: 0.523263\n",
      "epoch 26; iter: 0; batch classifier loss: 0.147329; batch adversarial loss: 0.427535\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152363; batch adversarial loss: 0.387604\n",
      "epoch 28; iter: 0; batch classifier loss: 0.144367; batch adversarial loss: 0.498701\n",
      "epoch 29; iter: 0; batch classifier loss: 0.151984; batch adversarial loss: 0.437197\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144425; batch adversarial loss: 0.466839\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141147; batch adversarial loss: 0.505185\n",
      "epoch 32; iter: 0; batch classifier loss: 0.094269; batch adversarial loss: 0.483976\n",
      "epoch 33; iter: 0; batch classifier loss: 0.100494; batch adversarial loss: 0.483628\n",
      "epoch 34; iter: 0; batch classifier loss: 0.144389; batch adversarial loss: 0.436601\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130493; batch adversarial loss: 0.376252\n",
      "epoch 36; iter: 0; batch classifier loss: 0.119703; batch adversarial loss: 0.443774\n",
      "epoch 37; iter: 0; batch classifier loss: 0.099401; batch adversarial loss: 0.507214\n",
      "epoch 38; iter: 0; batch classifier loss: 0.097136; batch adversarial loss: 0.458574\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126948; batch adversarial loss: 0.429212\n",
      "epoch 40; iter: 0; batch classifier loss: 0.088872; batch adversarial loss: 0.473949\n",
      "epoch 41; iter: 0; batch classifier loss: 0.097811; batch adversarial loss: 0.510978\n",
      "epoch 42; iter: 0; batch classifier loss: 0.099697; batch adversarial loss: 0.373046\n",
      "epoch 43; iter: 0; batch classifier loss: 0.070632; batch adversarial loss: 0.495096\n",
      "epoch 44; iter: 0; batch classifier loss: 0.122092; batch adversarial loss: 0.508836\n",
      "epoch 45; iter: 0; batch classifier loss: 0.160326; batch adversarial loss: 0.495828\n",
      "epoch 46; iter: 0; batch classifier loss: 0.060084; batch adversarial loss: 0.524231\n",
      "epoch 47; iter: 0; batch classifier loss: 0.142641; batch adversarial loss: 0.471251\n",
      "epoch 48; iter: 0; batch classifier loss: 0.076837; batch adversarial loss: 0.482909\n",
      "epoch 49; iter: 0; batch classifier loss: 0.108303; batch adversarial loss: 0.498237\n",
      "epoch 50; iter: 0; batch classifier loss: 0.109523; batch adversarial loss: 0.524828\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096407; batch adversarial loss: 0.541694\n",
      "epoch 52; iter: 0; batch classifier loss: 0.061924; batch adversarial loss: 0.545269\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098506; batch adversarial loss: 0.358449\n",
      "epoch 54; iter: 0; batch classifier loss: 0.060866; batch adversarial loss: 0.456782\n",
      "epoch 55; iter: 0; batch classifier loss: 0.075470; batch adversarial loss: 0.452932\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102510; batch adversarial loss: 0.389070\n",
      "epoch 57; iter: 0; batch classifier loss: 0.097597; batch adversarial loss: 0.482588\n",
      "epoch 58; iter: 0; batch classifier loss: 0.086353; batch adversarial loss: 0.437649\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087092; batch adversarial loss: 0.485792\n",
      "epoch 60; iter: 0; batch classifier loss: 0.085891; batch adversarial loss: 0.513756\n",
      "epoch 61; iter: 0; batch classifier loss: 0.101569; batch adversarial loss: 0.453992\n",
      "epoch 62; iter: 0; batch classifier loss: 0.042197; batch adversarial loss: 0.412323\n",
      "epoch 63; iter: 0; batch classifier loss: 0.066931; batch adversarial loss: 0.387302\n",
      "epoch 64; iter: 0; batch classifier loss: 0.059627; batch adversarial loss: 0.407369\n",
      "epoch 65; iter: 0; batch classifier loss: 0.114280; batch adversarial loss: 0.389925\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073558; batch adversarial loss: 0.449375\n",
      "epoch 67; iter: 0; batch classifier loss: 0.084284; batch adversarial loss: 0.448764\n",
      "epoch 68; iter: 0; batch classifier loss: 0.104052; batch adversarial loss: 0.438910\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061907; batch adversarial loss: 0.476517\n",
      "epoch 70; iter: 0; batch classifier loss: 0.075343; batch adversarial loss: 0.474359\n",
      "epoch 71; iter: 0; batch classifier loss: 0.093727; batch adversarial loss: 0.427006\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077657; batch adversarial loss: 0.459517\n",
      "epoch 73; iter: 0; batch classifier loss: 0.088360; batch adversarial loss: 0.457405\n",
      "epoch 74; iter: 0; batch classifier loss: 0.035210; batch adversarial loss: 0.489061\n",
      "epoch 75; iter: 0; batch classifier loss: 0.113511; batch adversarial loss: 0.473860\n",
      "epoch 76; iter: 0; batch classifier loss: 0.079011; batch adversarial loss: 0.567704\n",
      "epoch 77; iter: 0; batch classifier loss: 0.125111; batch adversarial loss: 0.512567\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079293; batch adversarial loss: 0.443022\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067111; batch adversarial loss: 0.504843\n",
      "epoch 80; iter: 0; batch classifier loss: 0.030031; batch adversarial loss: 0.411390\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096466; batch adversarial loss: 0.438070\n",
      "epoch 82; iter: 0; batch classifier loss: 0.087914; batch adversarial loss: 0.447980\n",
      "epoch 83; iter: 0; batch classifier loss: 0.093389; batch adversarial loss: 0.435027\n",
      "epoch 84; iter: 0; batch classifier loss: 0.040297; batch adversarial loss: 0.497049\n",
      "epoch 85; iter: 0; batch classifier loss: 0.098495; batch adversarial loss: 0.482265\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053731; batch adversarial loss: 0.483270\n",
      "epoch 87; iter: 0; batch classifier loss: 0.077413; batch adversarial loss: 0.402507\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064783; batch adversarial loss: 0.481586\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047924; batch adversarial loss: 0.460212\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060323; batch adversarial loss: 0.500100\n",
      "epoch 91; iter: 0; batch classifier loss: 0.079893; batch adversarial loss: 0.457932\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065494; batch adversarial loss: 0.389467\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065657; batch adversarial loss: 0.559607\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050387; batch adversarial loss: 0.403678\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039754; batch adversarial loss: 0.546937\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061201; batch adversarial loss: 0.450474\n",
      "epoch 97; iter: 0; batch classifier loss: 0.086460; batch adversarial loss: 0.409797\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045461; batch adversarial loss: 0.430262\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045880; batch adversarial loss: 0.410558\n",
      "epoch 100; iter: 0; batch classifier loss: 0.088187; batch adversarial loss: 0.472784\n",
      "epoch 101; iter: 0; batch classifier loss: 0.019018; batch adversarial loss: 0.455987\n",
      "epoch 102; iter: 0; batch classifier loss: 0.026569; batch adversarial loss: 0.458563\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063219; batch adversarial loss: 0.415202\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038259; batch adversarial loss: 0.447172\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030319; batch adversarial loss: 0.503056\n",
      "epoch 106; iter: 0; batch classifier loss: 0.075054; batch adversarial loss: 0.521528\n",
      "epoch 107; iter: 0; batch classifier loss: 0.080159; batch adversarial loss: 0.377986\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030866; batch adversarial loss: 0.431282\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034632; batch adversarial loss: 0.472876\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048069; batch adversarial loss: 0.429768\n",
      "epoch 111; iter: 0; batch classifier loss: 0.023911; batch adversarial loss: 0.541757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.052385; batch adversarial loss: 0.473782\n",
      "epoch 113; iter: 0; batch classifier loss: 0.087327; batch adversarial loss: 0.409986\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068948; batch adversarial loss: 0.368804\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047626; batch adversarial loss: 0.451882\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048351; batch adversarial loss: 0.457391\n",
      "epoch 117; iter: 0; batch classifier loss: 0.069076; batch adversarial loss: 0.490201\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045644; batch adversarial loss: 0.465545\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025203; batch adversarial loss: 0.508720\n",
      "epoch 120; iter: 0; batch classifier loss: 0.018467; batch adversarial loss: 0.449553\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049150; batch adversarial loss: 0.481310\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033946; batch adversarial loss: 0.459989\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039381; batch adversarial loss: 0.467426\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019381; batch adversarial loss: 0.404392\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017206; batch adversarial loss: 0.396383\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022105; batch adversarial loss: 0.588992\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031167; batch adversarial loss: 0.468830\n",
      "epoch 128; iter: 0; batch classifier loss: 0.048208; batch adversarial loss: 0.458437\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038469; batch adversarial loss: 0.385894\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017372; batch adversarial loss: 0.493852\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020595; batch adversarial loss: 0.440046\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035161; batch adversarial loss: 0.438747\n",
      "epoch 133; iter: 0; batch classifier loss: 0.017863; batch adversarial loss: 0.517425\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029946; batch adversarial loss: 0.500233\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026273; batch adversarial loss: 0.480491\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046941; batch adversarial loss: 0.472845\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040626; batch adversarial loss: 0.376607\n",
      "epoch 138; iter: 0; batch classifier loss: 0.071839; batch adversarial loss: 0.488115\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044614; batch adversarial loss: 0.557684\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050320; batch adversarial loss: 0.432357\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031846; batch adversarial loss: 0.480608\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014136; batch adversarial loss: 0.507512\n",
      "epoch 143; iter: 0; batch classifier loss: 0.048325; batch adversarial loss: 0.462732\n",
      "epoch 144; iter: 0; batch classifier loss: 0.043448; batch adversarial loss: 0.510682\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023241; batch adversarial loss: 0.425496\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020019; batch adversarial loss: 0.503826\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025787; batch adversarial loss: 0.449739\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026203; batch adversarial loss: 0.398149\n",
      "epoch 149; iter: 0; batch classifier loss: 0.007383; batch adversarial loss: 0.374032\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041980; batch adversarial loss: 0.399234\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037378; batch adversarial loss: 0.512684\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040563; batch adversarial loss: 0.367306\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016273; batch adversarial loss: 0.495105\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052239; batch adversarial loss: 0.541585\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033188; batch adversarial loss: 0.501162\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050525; batch adversarial loss: 0.352105\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034327; batch adversarial loss: 0.486351\n",
      "epoch 158; iter: 0; batch classifier loss: 0.006584; batch adversarial loss: 0.492079\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042542; batch adversarial loss: 0.536762\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017459; batch adversarial loss: 0.520890\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017033; batch adversarial loss: 0.411885\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012744; batch adversarial loss: 0.532986\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021697; batch adversarial loss: 0.418807\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031602; batch adversarial loss: 0.402463\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014129; batch adversarial loss: 0.448314\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018907; batch adversarial loss: 0.490871\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016695; batch adversarial loss: 0.453710\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023172; batch adversarial loss: 0.427481\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037716; batch adversarial loss: 0.510615\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024854; batch adversarial loss: 0.458004\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014888; batch adversarial loss: 0.466174\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011035; batch adversarial loss: 0.464597\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030718; batch adversarial loss: 0.426358\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012918; batch adversarial loss: 0.401912\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031631; batch adversarial loss: 0.424474\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024812; batch adversarial loss: 0.381013\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027272; batch adversarial loss: 0.526367\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032137; batch adversarial loss: 0.464169\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021087; batch adversarial loss: 0.454299\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037071; batch adversarial loss: 0.464120\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012450; batch adversarial loss: 0.459127\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014530; batch adversarial loss: 0.495563\n",
      "epoch 183; iter: 0; batch classifier loss: 0.041540; batch adversarial loss: 0.443069\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036509; batch adversarial loss: 0.532847\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017557; batch adversarial loss: 0.361166\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013350; batch adversarial loss: 0.446809\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012347; batch adversarial loss: 0.447260\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006135; batch adversarial loss: 0.489956\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004547; batch adversarial loss: 0.468551\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007244; batch adversarial loss: 0.515013\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012046; batch adversarial loss: 0.579914\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022965; batch adversarial loss: 0.567123\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005633; batch adversarial loss: 0.549816\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014088; batch adversarial loss: 0.412950\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004574; batch adversarial loss: 0.416647\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026649; batch adversarial loss: 0.521813\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017590; batch adversarial loss: 0.489684\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018248; batch adversarial loss: 0.456906\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024976; batch adversarial loss: 0.496217\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704659; batch adversarial loss: 0.658678\n",
      "epoch 1; iter: 0; batch classifier loss: 0.542039; batch adversarial loss: 0.642101\n",
      "epoch 2; iter: 0; batch classifier loss: 0.412254; batch adversarial loss: 0.654630\n",
      "epoch 3; iter: 0; batch classifier loss: 0.395051; batch adversarial loss: 0.608900\n",
      "epoch 4; iter: 0; batch classifier loss: 0.420189; batch adversarial loss: 0.636261\n",
      "epoch 5; iter: 0; batch classifier loss: 0.572081; batch adversarial loss: 0.589661\n",
      "epoch 6; iter: 0; batch classifier loss: 0.463891; batch adversarial loss: 0.602003\n",
      "epoch 7; iter: 0; batch classifier loss: 0.508788; batch adversarial loss: 0.598864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.497392; batch adversarial loss: 0.539974\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488179; batch adversarial loss: 0.503931\n",
      "epoch 10; iter: 0; batch classifier loss: 0.406831; batch adversarial loss: 0.554170\n",
      "epoch 11; iter: 0; batch classifier loss: 0.332883; batch adversarial loss: 0.542728\n",
      "epoch 12; iter: 0; batch classifier loss: 0.399751; batch adversarial loss: 0.525904\n",
      "epoch 13; iter: 0; batch classifier loss: 0.431235; batch adversarial loss: 0.474011\n",
      "epoch 14; iter: 0; batch classifier loss: 0.373817; batch adversarial loss: 0.509225\n",
      "epoch 15; iter: 0; batch classifier loss: 0.343702; batch adversarial loss: 0.506366\n",
      "epoch 16; iter: 0; batch classifier loss: 0.354834; batch adversarial loss: 0.516740\n",
      "epoch 17; iter: 0; batch classifier loss: 0.354879; batch adversarial loss: 0.569896\n",
      "epoch 18; iter: 0; batch classifier loss: 0.308673; batch adversarial loss: 0.534421\n",
      "epoch 19; iter: 0; batch classifier loss: 0.259195; batch adversarial loss: 0.521983\n",
      "epoch 20; iter: 0; batch classifier loss: 0.384744; batch adversarial loss: 0.439838\n",
      "epoch 21; iter: 0; batch classifier loss: 0.275391; batch adversarial loss: 0.456466\n",
      "epoch 22; iter: 0; batch classifier loss: 0.283569; batch adversarial loss: 0.474505\n",
      "epoch 23; iter: 0; batch classifier loss: 0.246400; batch adversarial loss: 0.448418\n",
      "epoch 24; iter: 0; batch classifier loss: 0.326853; batch adversarial loss: 0.485704\n",
      "epoch 25; iter: 0; batch classifier loss: 0.254636; batch adversarial loss: 0.455834\n",
      "epoch 26; iter: 0; batch classifier loss: 0.261096; batch adversarial loss: 0.411785\n",
      "epoch 27; iter: 0; batch classifier loss: 0.251483; batch adversarial loss: 0.433026\n",
      "epoch 28; iter: 0; batch classifier loss: 0.191109; batch adversarial loss: 0.566689\n",
      "epoch 29; iter: 0; batch classifier loss: 0.231685; batch adversarial loss: 0.481752\n",
      "epoch 30; iter: 0; batch classifier loss: 0.255946; batch adversarial loss: 0.431241\n",
      "epoch 31; iter: 0; batch classifier loss: 0.220302; batch adversarial loss: 0.459078\n",
      "epoch 32; iter: 0; batch classifier loss: 0.214630; batch adversarial loss: 0.436615\n",
      "epoch 33; iter: 0; batch classifier loss: 0.209314; batch adversarial loss: 0.476978\n",
      "epoch 34; iter: 0; batch classifier loss: 0.261038; batch adversarial loss: 0.392375\n",
      "epoch 35; iter: 0; batch classifier loss: 0.245036; batch adversarial loss: 0.481657\n",
      "epoch 36; iter: 0; batch classifier loss: 0.288043; batch adversarial loss: 0.476640\n",
      "epoch 37; iter: 0; batch classifier loss: 0.217889; batch adversarial loss: 0.406173\n",
      "epoch 38; iter: 0; batch classifier loss: 0.221154; batch adversarial loss: 0.447045\n",
      "epoch 39; iter: 0; batch classifier loss: 0.331858; batch adversarial loss: 0.534719\n",
      "epoch 40; iter: 0; batch classifier loss: 0.189318; batch adversarial loss: 0.463448\n",
      "epoch 41; iter: 0; batch classifier loss: 0.281740; batch adversarial loss: 0.429325\n",
      "epoch 42; iter: 0; batch classifier loss: 0.197730; batch adversarial loss: 0.442423\n",
      "epoch 43; iter: 0; batch classifier loss: 0.318677; batch adversarial loss: 0.491673\n",
      "epoch 44; iter: 0; batch classifier loss: 0.227346; batch adversarial loss: 0.443537\n",
      "epoch 45; iter: 0; batch classifier loss: 0.262086; batch adversarial loss: 0.522620\n",
      "epoch 46; iter: 0; batch classifier loss: 0.255963; batch adversarial loss: 0.448747\n",
      "epoch 47; iter: 0; batch classifier loss: 0.223801; batch adversarial loss: 0.412790\n",
      "epoch 48; iter: 0; batch classifier loss: 0.239747; batch adversarial loss: 0.473018\n",
      "epoch 49; iter: 0; batch classifier loss: 0.222952; batch adversarial loss: 0.517879\n",
      "epoch 50; iter: 0; batch classifier loss: 0.228902; batch adversarial loss: 0.424864\n",
      "epoch 51; iter: 0; batch classifier loss: 0.275932; batch adversarial loss: 0.509494\n",
      "epoch 52; iter: 0; batch classifier loss: 0.252148; batch adversarial loss: 0.459433\n",
      "epoch 53; iter: 0; batch classifier loss: 0.221354; batch adversarial loss: 0.482022\n",
      "epoch 54; iter: 0; batch classifier loss: 0.333054; batch adversarial loss: 0.293593\n",
      "epoch 55; iter: 0; batch classifier loss: 0.245183; batch adversarial loss: 0.386686\n",
      "epoch 56; iter: 0; batch classifier loss: 0.217076; batch adversarial loss: 0.541465\n",
      "epoch 57; iter: 0; batch classifier loss: 0.213155; batch adversarial loss: 0.447362\n",
      "epoch 58; iter: 0; batch classifier loss: 0.178373; batch adversarial loss: 0.505363\n",
      "epoch 59; iter: 0; batch classifier loss: 0.334545; batch adversarial loss: 0.447234\n",
      "epoch 60; iter: 0; batch classifier loss: 0.121062; batch adversarial loss: 0.447358\n",
      "epoch 61; iter: 0; batch classifier loss: 0.191812; batch adversarial loss: 0.520393\n",
      "epoch 62; iter: 0; batch classifier loss: 0.290796; batch adversarial loss: 0.422130\n",
      "epoch 63; iter: 0; batch classifier loss: 0.195744; batch adversarial loss: 0.495434\n",
      "epoch 64; iter: 0; batch classifier loss: 0.202589; batch adversarial loss: 0.399987\n",
      "epoch 65; iter: 0; batch classifier loss: 0.175407; batch adversarial loss: 0.532097\n",
      "epoch 66; iter: 0; batch classifier loss: 0.237464; batch adversarial loss: 0.421927\n",
      "epoch 67; iter: 0; batch classifier loss: 0.244506; batch adversarial loss: 0.507182\n",
      "epoch 68; iter: 0; batch classifier loss: 0.124377; batch adversarial loss: 0.470444\n",
      "epoch 69; iter: 0; batch classifier loss: 0.108603; batch adversarial loss: 0.471352\n",
      "epoch 70; iter: 0; batch classifier loss: 0.136296; batch adversarial loss: 0.521740\n",
      "epoch 71; iter: 0; batch classifier loss: 0.184713; batch adversarial loss: 0.395910\n",
      "epoch 72; iter: 0; batch classifier loss: 0.183961; batch adversarial loss: 0.459480\n",
      "epoch 73; iter: 0; batch classifier loss: 0.203036; batch adversarial loss: 0.433588\n",
      "epoch 74; iter: 0; batch classifier loss: 0.170270; batch adversarial loss: 0.493325\n",
      "epoch 75; iter: 0; batch classifier loss: 0.199230; batch adversarial loss: 0.446401\n",
      "epoch 76; iter: 0; batch classifier loss: 0.187774; batch adversarial loss: 0.460902\n",
      "epoch 77; iter: 0; batch classifier loss: 0.224310; batch adversarial loss: 0.506488\n",
      "epoch 78; iter: 0; batch classifier loss: 0.215483; batch adversarial loss: 0.448121\n",
      "epoch 79; iter: 0; batch classifier loss: 0.151511; batch adversarial loss: 0.398951\n",
      "epoch 80; iter: 0; batch classifier loss: 0.290378; batch adversarial loss: 0.436363\n",
      "epoch 81; iter: 0; batch classifier loss: 0.251950; batch adversarial loss: 0.435235\n",
      "epoch 82; iter: 0; batch classifier loss: 0.273170; batch adversarial loss: 0.482996\n",
      "epoch 83; iter: 0; batch classifier loss: 0.262366; batch adversarial loss: 0.374547\n",
      "epoch 84; iter: 0; batch classifier loss: 0.182209; batch adversarial loss: 0.519259\n",
      "epoch 85; iter: 0; batch classifier loss: 0.204451; batch adversarial loss: 0.446988\n",
      "epoch 86; iter: 0; batch classifier loss: 0.219285; batch adversarial loss: 0.482984\n",
      "epoch 87; iter: 0; batch classifier loss: 0.089867; batch adversarial loss: 0.543503\n",
      "epoch 88; iter: 0; batch classifier loss: 0.200651; batch adversarial loss: 0.499027\n",
      "epoch 89; iter: 0; batch classifier loss: 0.268913; batch adversarial loss: 0.481649\n",
      "epoch 90; iter: 0; batch classifier loss: 0.257919; batch adversarial loss: 0.470371\n",
      "epoch 91; iter: 0; batch classifier loss: 0.143800; batch adversarial loss: 0.422991\n",
      "epoch 92; iter: 0; batch classifier loss: 0.195029; batch adversarial loss: 0.422630\n",
      "epoch 93; iter: 0; batch classifier loss: 0.256358; batch adversarial loss: 0.385544\n",
      "epoch 94; iter: 0; batch classifier loss: 0.294251; batch adversarial loss: 0.495306\n",
      "epoch 95; iter: 0; batch classifier loss: 0.181035; batch adversarial loss: 0.519303\n",
      "epoch 96; iter: 0; batch classifier loss: 0.154285; batch adversarial loss: 0.458348\n",
      "epoch 97; iter: 0; batch classifier loss: 0.159337; batch adversarial loss: 0.494549\n",
      "epoch 98; iter: 0; batch classifier loss: 0.257299; batch adversarial loss: 0.543861\n",
      "epoch 99; iter: 0; batch classifier loss: 0.212422; batch adversarial loss: 0.446036\n",
      "epoch 100; iter: 0; batch classifier loss: 0.267999; batch adversarial loss: 0.470487\n",
      "epoch 101; iter: 0; batch classifier loss: 0.201457; batch adversarial loss: 0.458552\n",
      "epoch 102; iter: 0; batch classifier loss: 0.221469; batch adversarial loss: 0.532043\n",
      "epoch 103; iter: 0; batch classifier loss: 0.077505; batch adversarial loss: 0.370864\n",
      "epoch 104; iter: 0; batch classifier loss: 0.076286; batch adversarial loss: 0.543525\n",
      "epoch 105; iter: 0; batch classifier loss: 0.092561; batch adversarial loss: 0.456664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.051294; batch adversarial loss: 0.362431\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037335; batch adversarial loss: 0.454853\n",
      "epoch 108; iter: 0; batch classifier loss: 0.068413; batch adversarial loss: 0.496673\n",
      "epoch 109; iter: 0; batch classifier loss: 0.025988; batch adversarial loss: 0.397984\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025266; batch adversarial loss: 0.439957\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045377; batch adversarial loss: 0.393808\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045103; batch adversarial loss: 0.518801\n",
      "epoch 113; iter: 0; batch classifier loss: 0.032494; batch adversarial loss: 0.370114\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060574; batch adversarial loss: 0.522605\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057370; batch adversarial loss: 0.406655\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030224; batch adversarial loss: 0.376470\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033833; batch adversarial loss: 0.360777\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060907; batch adversarial loss: 0.464831\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070399; batch adversarial loss: 0.420435\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030987; batch adversarial loss: 0.518539\n",
      "epoch 121; iter: 0; batch classifier loss: 0.070905; batch adversarial loss: 0.516728\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046770; batch adversarial loss: 0.373128\n",
      "epoch 123; iter: 0; batch classifier loss: 0.078934; batch adversarial loss: 0.480171\n",
      "epoch 124; iter: 0; batch classifier loss: 0.075680; batch adversarial loss: 0.452928\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061300; batch adversarial loss: 0.408665\n",
      "epoch 126; iter: 0; batch classifier loss: 0.077120; batch adversarial loss: 0.366992\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045070; batch adversarial loss: 0.434129\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047062; batch adversarial loss: 0.483932\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040415; batch adversarial loss: 0.455628\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044693; batch adversarial loss: 0.472713\n",
      "epoch 131; iter: 0; batch classifier loss: 0.084172; batch adversarial loss: 0.380601\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057438; batch adversarial loss: 0.521131\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055290; batch adversarial loss: 0.421414\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040797; batch adversarial loss: 0.454790\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057807; batch adversarial loss: 0.389631\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027028; batch adversarial loss: 0.480885\n",
      "epoch 137; iter: 0; batch classifier loss: 0.060464; batch adversarial loss: 0.435288\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048126; batch adversarial loss: 0.360713\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040826; batch adversarial loss: 0.429619\n",
      "epoch 140; iter: 0; batch classifier loss: 0.069094; batch adversarial loss: 0.489631\n",
      "epoch 141; iter: 0; batch classifier loss: 0.077842; batch adversarial loss: 0.500827\n",
      "epoch 142; iter: 0; batch classifier loss: 0.046740; batch adversarial loss: 0.350364\n",
      "epoch 143; iter: 0; batch classifier loss: 0.094722; batch adversarial loss: 0.470845\n",
      "epoch 144; iter: 0; batch classifier loss: 0.043249; batch adversarial loss: 0.450443\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035651; batch adversarial loss: 0.402742\n",
      "epoch 146; iter: 0; batch classifier loss: 0.059374; batch adversarial loss: 0.441831\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041833; batch adversarial loss: 0.371374\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043881; batch adversarial loss: 0.404982\n",
      "epoch 149; iter: 0; batch classifier loss: 0.066682; batch adversarial loss: 0.409537\n",
      "epoch 150; iter: 0; batch classifier loss: 0.062668; batch adversarial loss: 0.469103\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044996; batch adversarial loss: 0.386072\n",
      "epoch 152; iter: 0; batch classifier loss: 0.049379; batch adversarial loss: 0.469232\n",
      "epoch 153; iter: 0; batch classifier loss: 0.059285; batch adversarial loss: 0.463963\n",
      "epoch 154; iter: 0; batch classifier loss: 0.042703; batch adversarial loss: 0.487818\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023723; batch adversarial loss: 0.433570\n",
      "epoch 156; iter: 0; batch classifier loss: 0.046023; batch adversarial loss: 0.365121\n",
      "epoch 157; iter: 0; batch classifier loss: 0.085788; batch adversarial loss: 0.524365\n",
      "epoch 158; iter: 0; batch classifier loss: 0.055520; batch adversarial loss: 0.480040\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039595; batch adversarial loss: 0.440858\n",
      "epoch 160; iter: 0; batch classifier loss: 0.038096; batch adversarial loss: 0.455449\n",
      "epoch 161; iter: 0; batch classifier loss: 0.069894; batch adversarial loss: 0.494508\n",
      "epoch 162; iter: 0; batch classifier loss: 0.054201; batch adversarial loss: 0.409982\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029700; batch adversarial loss: 0.376088\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023687; batch adversarial loss: 0.401650\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025314; batch adversarial loss: 0.457003\n",
      "epoch 166; iter: 0; batch classifier loss: 0.052273; batch adversarial loss: 0.422451\n",
      "epoch 167; iter: 0; batch classifier loss: 0.040342; batch adversarial loss: 0.399019\n",
      "epoch 168; iter: 0; batch classifier loss: 0.107648; batch adversarial loss: 0.557987\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043620; batch adversarial loss: 0.373078\n",
      "epoch 170; iter: 0; batch classifier loss: 0.071080; batch adversarial loss: 0.417204\n",
      "epoch 171; iter: 0; batch classifier loss: 0.070660; batch adversarial loss: 0.430516\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040530; batch adversarial loss: 0.370858\n",
      "epoch 173; iter: 0; batch classifier loss: 0.049654; batch adversarial loss: 0.473632\n",
      "epoch 174; iter: 0; batch classifier loss: 0.055722; batch adversarial loss: 0.465551\n",
      "epoch 175; iter: 0; batch classifier loss: 0.046632; batch adversarial loss: 0.427598\n",
      "epoch 176; iter: 0; batch classifier loss: 0.047407; batch adversarial loss: 0.442554\n",
      "epoch 177; iter: 0; batch classifier loss: 0.040346; batch adversarial loss: 0.473508\n",
      "epoch 178; iter: 0; batch classifier loss: 0.051643; batch adversarial loss: 0.424080\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044828; batch adversarial loss: 0.379099\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040325; batch adversarial loss: 0.403827\n",
      "epoch 181; iter: 0; batch classifier loss: 0.053713; batch adversarial loss: 0.363685\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042573; batch adversarial loss: 0.572215\n",
      "epoch 183; iter: 0; batch classifier loss: 0.041186; batch adversarial loss: 0.418255\n",
      "epoch 184; iter: 0; batch classifier loss: 0.053106; batch adversarial loss: 0.399215\n",
      "epoch 185; iter: 0; batch classifier loss: 0.058289; batch adversarial loss: 0.447536\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041682; batch adversarial loss: 0.429171\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026719; batch adversarial loss: 0.379061\n",
      "epoch 188; iter: 0; batch classifier loss: 0.080238; batch adversarial loss: 0.424622\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034828; batch adversarial loss: 0.448764\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033245; batch adversarial loss: 0.452339\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033505; batch adversarial loss: 0.402796\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033309; batch adversarial loss: 0.281062\n",
      "epoch 193; iter: 0; batch classifier loss: 0.043437; batch adversarial loss: 0.388513\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032587; batch adversarial loss: 0.400555\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018763; batch adversarial loss: 0.415442\n",
      "epoch 196; iter: 0; batch classifier loss: 0.035206; batch adversarial loss: 0.491415\n",
      "epoch 197; iter: 0; batch classifier loss: 0.060166; batch adversarial loss: 0.415851\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032656; batch adversarial loss: 0.464919\n",
      "epoch 199; iter: 0; batch classifier loss: 0.069651; batch adversarial loss: 0.378379\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699909; batch adversarial loss: 0.579721\n",
      "epoch 1; iter: 0; batch classifier loss: 0.519268; batch adversarial loss: 0.634458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.555822; batch adversarial loss: 0.576244\n",
      "epoch 3; iter: 0; batch classifier loss: 0.385870; batch adversarial loss: 0.623758\n",
      "epoch 4; iter: 0; batch classifier loss: 0.443781; batch adversarial loss: 0.610247\n",
      "epoch 5; iter: 0; batch classifier loss: 0.478753; batch adversarial loss: 0.599082\n",
      "epoch 6; iter: 0; batch classifier loss: 0.496398; batch adversarial loss: 0.600372\n",
      "epoch 7; iter: 0; batch classifier loss: 0.499891; batch adversarial loss: 0.588411\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523818; batch adversarial loss: 0.581958\n",
      "epoch 9; iter: 0; batch classifier loss: 0.486439; batch adversarial loss: 0.512122\n",
      "epoch 10; iter: 0; batch classifier loss: 0.470592; batch adversarial loss: 0.547588\n",
      "epoch 11; iter: 0; batch classifier loss: 0.341118; batch adversarial loss: 0.505305\n",
      "epoch 12; iter: 0; batch classifier loss: 0.350741; batch adversarial loss: 0.495694\n",
      "epoch 13; iter: 0; batch classifier loss: 0.261017; batch adversarial loss: 0.460622\n",
      "epoch 14; iter: 0; batch classifier loss: 0.328567; batch adversarial loss: 0.446623\n",
      "epoch 15; iter: 0; batch classifier loss: 0.324207; batch adversarial loss: 0.533287\n",
      "epoch 16; iter: 0; batch classifier loss: 0.288347; batch adversarial loss: 0.473275\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241385; batch adversarial loss: 0.538939\n",
      "epoch 18; iter: 0; batch classifier loss: 0.238227; batch adversarial loss: 0.436850\n",
      "epoch 19; iter: 0; batch classifier loss: 0.229769; batch adversarial loss: 0.464520\n",
      "epoch 20; iter: 0; batch classifier loss: 0.224678; batch adversarial loss: 0.455262\n",
      "epoch 21; iter: 0; batch classifier loss: 0.242266; batch adversarial loss: 0.484814\n",
      "epoch 22; iter: 0; batch classifier loss: 0.185908; batch adversarial loss: 0.491147\n",
      "epoch 23; iter: 0; batch classifier loss: 0.222828; batch adversarial loss: 0.483229\n",
      "epoch 24; iter: 0; batch classifier loss: 0.238901; batch adversarial loss: 0.403032\n",
      "epoch 25; iter: 0; batch classifier loss: 0.152209; batch adversarial loss: 0.505904\n",
      "epoch 26; iter: 0; batch classifier loss: 0.198715; batch adversarial loss: 0.416053\n",
      "epoch 27; iter: 0; batch classifier loss: 0.196186; batch adversarial loss: 0.472302\n",
      "epoch 28; iter: 0; batch classifier loss: 0.175821; batch adversarial loss: 0.399788\n",
      "epoch 29; iter: 0; batch classifier loss: 0.177686; batch adversarial loss: 0.501804\n",
      "epoch 30; iter: 0; batch classifier loss: 0.168172; batch adversarial loss: 0.505064\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156228; batch adversarial loss: 0.440561\n",
      "epoch 32; iter: 0; batch classifier loss: 0.213313; batch adversarial loss: 0.497560\n",
      "epoch 33; iter: 0; batch classifier loss: 0.151291; batch adversarial loss: 0.462330\n",
      "epoch 34; iter: 0; batch classifier loss: 0.128615; batch adversarial loss: 0.550292\n",
      "epoch 35; iter: 0; batch classifier loss: 0.205866; batch adversarial loss: 0.484145\n",
      "epoch 36; iter: 0; batch classifier loss: 0.156264; batch adversarial loss: 0.446369\n",
      "epoch 37; iter: 0; batch classifier loss: 0.140537; batch adversarial loss: 0.504946\n",
      "epoch 38; iter: 0; batch classifier loss: 0.169979; batch adversarial loss: 0.475334\n",
      "epoch 39; iter: 0; batch classifier loss: 0.232988; batch adversarial loss: 0.395783\n",
      "epoch 40; iter: 0; batch classifier loss: 0.170499; batch adversarial loss: 0.405164\n",
      "epoch 41; iter: 0; batch classifier loss: 0.164833; batch adversarial loss: 0.586912\n",
      "epoch 42; iter: 0; batch classifier loss: 0.190726; batch adversarial loss: 0.529858\n",
      "epoch 43; iter: 0; batch classifier loss: 0.176614; batch adversarial loss: 0.540320\n",
      "epoch 44; iter: 0; batch classifier loss: 0.126359; batch adversarial loss: 0.462931\n",
      "epoch 45; iter: 0; batch classifier loss: 0.147395; batch adversarial loss: 0.465270\n",
      "epoch 46; iter: 0; batch classifier loss: 0.189066; batch adversarial loss: 0.487784\n",
      "epoch 47; iter: 0; batch classifier loss: 0.231752; batch adversarial loss: 0.452225\n",
      "epoch 48; iter: 0; batch classifier loss: 0.120433; batch adversarial loss: 0.492255\n",
      "epoch 49; iter: 0; batch classifier loss: 0.185735; batch adversarial loss: 0.546236\n",
      "epoch 50; iter: 0; batch classifier loss: 0.190936; batch adversarial loss: 0.536114\n",
      "epoch 51; iter: 0; batch classifier loss: 0.183758; batch adversarial loss: 0.501282\n",
      "epoch 52; iter: 0; batch classifier loss: 0.201189; batch adversarial loss: 0.497660\n",
      "epoch 53; iter: 0; batch classifier loss: 0.236087; batch adversarial loss: 0.446068\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112933; batch adversarial loss: 0.459380\n",
      "epoch 55; iter: 0; batch classifier loss: 0.232598; batch adversarial loss: 0.439395\n",
      "epoch 56; iter: 0; batch classifier loss: 0.163199; batch adversarial loss: 0.516011\n",
      "epoch 57; iter: 0; batch classifier loss: 0.140572; batch adversarial loss: 0.479856\n",
      "epoch 58; iter: 0; batch classifier loss: 0.240534; batch adversarial loss: 0.488492\n",
      "epoch 59; iter: 0; batch classifier loss: 0.183808; batch adversarial loss: 0.512054\n",
      "epoch 60; iter: 0; batch classifier loss: 0.155884; batch adversarial loss: 0.449527\n",
      "epoch 61; iter: 0; batch classifier loss: 0.208987; batch adversarial loss: 0.489356\n",
      "epoch 62; iter: 0; batch classifier loss: 0.186340; batch adversarial loss: 0.510219\n",
      "epoch 63; iter: 0; batch classifier loss: 0.184516; batch adversarial loss: 0.386798\n",
      "epoch 64; iter: 0; batch classifier loss: 0.196429; batch adversarial loss: 0.437402\n",
      "epoch 65; iter: 0; batch classifier loss: 0.147175; batch adversarial loss: 0.546801\n",
      "epoch 66; iter: 0; batch classifier loss: 0.255075; batch adversarial loss: 0.466478\n",
      "epoch 67; iter: 0; batch classifier loss: 0.211297; batch adversarial loss: 0.423318\n",
      "epoch 68; iter: 0; batch classifier loss: 0.211304; batch adversarial loss: 0.458331\n",
      "epoch 69; iter: 0; batch classifier loss: 0.152556; batch adversarial loss: 0.504968\n",
      "epoch 70; iter: 0; batch classifier loss: 0.181311; batch adversarial loss: 0.445339\n",
      "epoch 71; iter: 0; batch classifier loss: 0.267860; batch adversarial loss: 0.541880\n",
      "epoch 72; iter: 0; batch classifier loss: 0.234160; batch adversarial loss: 0.530833\n",
      "epoch 73; iter: 0; batch classifier loss: 0.240261; batch adversarial loss: 0.457347\n",
      "epoch 74; iter: 0; batch classifier loss: 0.219552; batch adversarial loss: 0.458176\n",
      "epoch 75; iter: 0; batch classifier loss: 0.246053; batch adversarial loss: 0.518342\n",
      "epoch 76; iter: 0; batch classifier loss: 0.157041; batch adversarial loss: 0.459513\n",
      "epoch 77; iter: 0; batch classifier loss: 0.252520; batch adversarial loss: 0.494947\n",
      "epoch 78; iter: 0; batch classifier loss: 0.206959; batch adversarial loss: 0.411715\n",
      "epoch 79; iter: 0; batch classifier loss: 0.190392; batch adversarial loss: 0.527519\n",
      "epoch 80; iter: 0; batch classifier loss: 0.222234; batch adversarial loss: 0.408692\n",
      "epoch 81; iter: 0; batch classifier loss: 0.182599; batch adversarial loss: 0.518473\n",
      "epoch 82; iter: 0; batch classifier loss: 0.266237; batch adversarial loss: 0.482830\n",
      "epoch 83; iter: 0; batch classifier loss: 0.212591; batch adversarial loss: 0.468969\n",
      "epoch 84; iter: 0; batch classifier loss: 0.234253; batch adversarial loss: 0.446712\n",
      "epoch 85; iter: 0; batch classifier loss: 0.267643; batch adversarial loss: 0.521205\n",
      "epoch 86; iter: 0; batch classifier loss: 0.176531; batch adversarial loss: 0.506763\n",
      "epoch 87; iter: 0; batch classifier loss: 0.272133; batch adversarial loss: 0.447087\n",
      "epoch 88; iter: 0; batch classifier loss: 0.230913; batch adversarial loss: 0.483350\n",
      "epoch 89; iter: 0; batch classifier loss: 0.214437; batch adversarial loss: 0.422573\n",
      "epoch 90; iter: 0; batch classifier loss: 0.174300; batch adversarial loss: 0.518751\n",
      "epoch 91; iter: 0; batch classifier loss: 0.193636; batch adversarial loss: 0.482266\n",
      "epoch 92; iter: 0; batch classifier loss: 0.231775; batch adversarial loss: 0.459261\n",
      "epoch 93; iter: 0; batch classifier loss: 0.209595; batch adversarial loss: 0.435226\n",
      "epoch 94; iter: 0; batch classifier loss: 0.248506; batch adversarial loss: 0.459729\n",
      "epoch 95; iter: 0; batch classifier loss: 0.207134; batch adversarial loss: 0.471267\n",
      "epoch 96; iter: 0; batch classifier loss: 0.182338; batch adversarial loss: 0.470962\n",
      "epoch 97; iter: 0; batch classifier loss: 0.221418; batch adversarial loss: 0.530643\n",
      "epoch 98; iter: 0; batch classifier loss: 0.178399; batch adversarial loss: 0.387176\n",
      "epoch 99; iter: 0; batch classifier loss: 0.244980; batch adversarial loss: 0.387329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.179876; batch adversarial loss: 0.459460\n",
      "epoch 101; iter: 0; batch classifier loss: 0.191178; batch adversarial loss: 0.387245\n",
      "epoch 102; iter: 0; batch classifier loss: 0.195349; batch adversarial loss: 0.446719\n",
      "epoch 103; iter: 0; batch classifier loss: 0.273887; batch adversarial loss: 0.327989\n",
      "epoch 104; iter: 0; batch classifier loss: 0.220738; batch adversarial loss: 0.495895\n",
      "epoch 105; iter: 0; batch classifier loss: 0.187148; batch adversarial loss: 0.446152\n",
      "epoch 106; iter: 0; batch classifier loss: 0.134437; batch adversarial loss: 0.422651\n",
      "epoch 107; iter: 0; batch classifier loss: 0.201974; batch adversarial loss: 0.519175\n",
      "epoch 108; iter: 0; batch classifier loss: 0.198592; batch adversarial loss: 0.423746\n",
      "epoch 109; iter: 0; batch classifier loss: 0.149408; batch adversarial loss: 0.386623\n",
      "epoch 110; iter: 0; batch classifier loss: 0.157270; batch adversarial loss: 0.422557\n",
      "epoch 111; iter: 0; batch classifier loss: 0.149748; batch adversarial loss: 0.509507\n",
      "epoch 112; iter: 0; batch classifier loss: 0.176284; batch adversarial loss: 0.447977\n",
      "epoch 113; iter: 0; batch classifier loss: 0.280847; batch adversarial loss: 0.410740\n",
      "epoch 114; iter: 0; batch classifier loss: 0.171872; batch adversarial loss: 0.566709\n",
      "epoch 115; iter: 0; batch classifier loss: 0.210451; batch adversarial loss: 0.508381\n",
      "epoch 116; iter: 0; batch classifier loss: 0.199352; batch adversarial loss: 0.529949\n",
      "epoch 117; iter: 0; batch classifier loss: 0.216330; batch adversarial loss: 0.422472\n",
      "epoch 118; iter: 0; batch classifier loss: 0.166556; batch adversarial loss: 0.493492\n",
      "epoch 119; iter: 0; batch classifier loss: 0.149830; batch adversarial loss: 0.447441\n",
      "epoch 120; iter: 0; batch classifier loss: 0.187236; batch adversarial loss: 0.421619\n",
      "epoch 121; iter: 0; batch classifier loss: 0.217995; batch adversarial loss: 0.458829\n",
      "epoch 122; iter: 0; batch classifier loss: 0.222019; batch adversarial loss: 0.493826\n",
      "epoch 123; iter: 0; batch classifier loss: 0.167062; batch adversarial loss: 0.482913\n",
      "epoch 124; iter: 0; batch classifier loss: 0.174929; batch adversarial loss: 0.432975\n",
      "epoch 125; iter: 0; batch classifier loss: 0.166927; batch adversarial loss: 0.479089\n",
      "epoch 126; iter: 0; batch classifier loss: 0.155877; batch adversarial loss: 0.473171\n",
      "epoch 127; iter: 0; batch classifier loss: 0.172961; batch adversarial loss: 0.455667\n",
      "epoch 128; iter: 0; batch classifier loss: 0.164166; batch adversarial loss: 0.544628\n",
      "epoch 129; iter: 0; batch classifier loss: 0.169310; batch adversarial loss: 0.506226\n",
      "epoch 130; iter: 0; batch classifier loss: 0.118063; batch adversarial loss: 0.537773\n",
      "epoch 131; iter: 0; batch classifier loss: 0.119718; batch adversarial loss: 0.551709\n",
      "epoch 132; iter: 0; batch classifier loss: 0.123224; batch adversarial loss: 0.447141\n",
      "epoch 133; iter: 0; batch classifier loss: 0.089679; batch adversarial loss: 0.454718\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069751; batch adversarial loss: 0.400105\n",
      "epoch 135; iter: 0; batch classifier loss: 0.061842; batch adversarial loss: 0.415866\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049583; batch adversarial loss: 0.425164\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052628; batch adversarial loss: 0.392617\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039284; batch adversarial loss: 0.461780\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051532; batch adversarial loss: 0.532938\n",
      "epoch 140; iter: 0; batch classifier loss: 0.057951; batch adversarial loss: 0.523461\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045046; batch adversarial loss: 0.378773\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043859; batch adversarial loss: 0.404552\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032639; batch adversarial loss: 0.515344\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049760; batch adversarial loss: 0.519950\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030111; batch adversarial loss: 0.456607\n",
      "epoch 146; iter: 0; batch classifier loss: 0.050566; batch adversarial loss: 0.388890\n",
      "epoch 147; iter: 0; batch classifier loss: 0.047202; batch adversarial loss: 0.497498\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022983; batch adversarial loss: 0.388061\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020449; batch adversarial loss: 0.407697\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035506; batch adversarial loss: 0.423726\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020162; batch adversarial loss: 0.408320\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017485; batch adversarial loss: 0.403191\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021961; batch adversarial loss: 0.414154\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021530; batch adversarial loss: 0.483287\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033763; batch adversarial loss: 0.435510\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023739; batch adversarial loss: 0.476586\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011487; batch adversarial loss: 0.473653\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029356; batch adversarial loss: 0.358168\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022456; batch adversarial loss: 0.333761\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024104; batch adversarial loss: 0.478551\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036377; batch adversarial loss: 0.491841\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022273; batch adversarial loss: 0.502308\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025330; batch adversarial loss: 0.536286\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016621; batch adversarial loss: 0.459371\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009308; batch adversarial loss: 0.482131\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020752; batch adversarial loss: 0.482930\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023283; batch adversarial loss: 0.507649\n",
      "epoch 168; iter: 0; batch classifier loss: 0.039272; batch adversarial loss: 0.458488\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033190; batch adversarial loss: 0.333419\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024039; batch adversarial loss: 0.494301\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020687; batch adversarial loss: 0.452715\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026402; batch adversarial loss: 0.509187\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025919; batch adversarial loss: 0.488574\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026936; batch adversarial loss: 0.471712\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038340; batch adversarial loss: 0.465220\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025228; batch adversarial loss: 0.394234\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022283; batch adversarial loss: 0.443617\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016341; batch adversarial loss: 0.460545\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038491; batch adversarial loss: 0.426555\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012468; batch adversarial loss: 0.363093\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020437; batch adversarial loss: 0.469429\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015623; batch adversarial loss: 0.484770\n",
      "epoch 183; iter: 0; batch classifier loss: 0.037698; batch adversarial loss: 0.371435\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025610; batch adversarial loss: 0.497193\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007341; batch adversarial loss: 0.382176\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027557; batch adversarial loss: 0.505713\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019999; batch adversarial loss: 0.452832\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013103; batch adversarial loss: 0.475890\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013472; batch adversarial loss: 0.506292\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020319; batch adversarial loss: 0.424694\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020509; batch adversarial loss: 0.487312\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014044; batch adversarial loss: 0.394326\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018243; batch adversarial loss: 0.507551\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018602; batch adversarial loss: 0.446516\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021710; batch adversarial loss: 0.507578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.039913; batch adversarial loss: 0.479111\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012407; batch adversarial loss: 0.389809\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007219; batch adversarial loss: 0.566980\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020398; batch adversarial loss: 0.382923\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711604; batch adversarial loss: 0.846406\n",
      "epoch 1; iter: 0; batch classifier loss: 0.609409; batch adversarial loss: 0.875089\n",
      "epoch 2; iter: 0; batch classifier loss: 0.771694; batch adversarial loss: 0.867333\n",
      "epoch 3; iter: 0; batch classifier loss: 0.914723; batch adversarial loss: 0.795394\n",
      "epoch 4; iter: 0; batch classifier loss: 0.881469; batch adversarial loss: 0.728787\n",
      "epoch 5; iter: 0; batch classifier loss: 0.713836; batch adversarial loss: 0.665989\n",
      "epoch 6; iter: 0; batch classifier loss: 0.586053; batch adversarial loss: 0.587047\n",
      "epoch 7; iter: 0; batch classifier loss: 0.411129; batch adversarial loss: 0.564684\n",
      "epoch 8; iter: 0; batch classifier loss: 0.378500; batch adversarial loss: 0.501333\n",
      "epoch 9; iter: 0; batch classifier loss: 0.340790; batch adversarial loss: 0.515440\n",
      "epoch 10; iter: 0; batch classifier loss: 0.350319; batch adversarial loss: 0.542183\n",
      "epoch 11; iter: 0; batch classifier loss: 0.399904; batch adversarial loss: 0.573872\n",
      "epoch 12; iter: 0; batch classifier loss: 0.293386; batch adversarial loss: 0.528527\n",
      "epoch 13; iter: 0; batch classifier loss: 0.323663; batch adversarial loss: 0.542319\n",
      "epoch 14; iter: 0; batch classifier loss: 0.304950; batch adversarial loss: 0.492400\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302751; batch adversarial loss: 0.433378\n",
      "epoch 16; iter: 0; batch classifier loss: 0.249044; batch adversarial loss: 0.541663\n",
      "epoch 17; iter: 0; batch classifier loss: 0.260681; batch adversarial loss: 0.501140\n",
      "epoch 18; iter: 0; batch classifier loss: 0.213771; batch adversarial loss: 0.480294\n",
      "epoch 19; iter: 0; batch classifier loss: 0.243322; batch adversarial loss: 0.525947\n",
      "epoch 20; iter: 0; batch classifier loss: 0.284719; batch adversarial loss: 0.500638\n",
      "epoch 21; iter: 0; batch classifier loss: 0.222203; batch adversarial loss: 0.457967\n",
      "epoch 22; iter: 0; batch classifier loss: 0.232347; batch adversarial loss: 0.500472\n",
      "epoch 23; iter: 0; batch classifier loss: 0.255891; batch adversarial loss: 0.474924\n",
      "epoch 24; iter: 0; batch classifier loss: 0.200707; batch adversarial loss: 0.418695\n",
      "epoch 25; iter: 0; batch classifier loss: 0.175517; batch adversarial loss: 0.470103\n",
      "epoch 26; iter: 0; batch classifier loss: 0.185510; batch adversarial loss: 0.435364\n",
      "epoch 27; iter: 0; batch classifier loss: 0.193438; batch adversarial loss: 0.428946\n",
      "epoch 28; iter: 0; batch classifier loss: 0.164173; batch adversarial loss: 0.452320\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197299; batch adversarial loss: 0.441391\n",
      "epoch 30; iter: 0; batch classifier loss: 0.191269; batch adversarial loss: 0.488536\n",
      "epoch 31; iter: 0; batch classifier loss: 0.126766; batch adversarial loss: 0.491230\n",
      "epoch 32; iter: 0; batch classifier loss: 0.136469; batch adversarial loss: 0.423858\n",
      "epoch 33; iter: 0; batch classifier loss: 0.108074; batch adversarial loss: 0.465992\n",
      "epoch 34; iter: 0; batch classifier loss: 0.128708; batch adversarial loss: 0.528707\n",
      "epoch 35; iter: 0; batch classifier loss: 0.152972; batch adversarial loss: 0.449787\n",
      "epoch 36; iter: 0; batch classifier loss: 0.139463; batch adversarial loss: 0.359370\n",
      "epoch 37; iter: 0; batch classifier loss: 0.122130; batch adversarial loss: 0.454777\n",
      "epoch 38; iter: 0; batch classifier loss: 0.120009; batch adversarial loss: 0.546263\n",
      "epoch 39; iter: 0; batch classifier loss: 0.136502; batch adversarial loss: 0.395758\n",
      "epoch 40; iter: 0; batch classifier loss: 0.125247; batch adversarial loss: 0.503647\n",
      "epoch 41; iter: 0; batch classifier loss: 0.093020; batch adversarial loss: 0.470597\n",
      "epoch 42; iter: 0; batch classifier loss: 0.119708; batch adversarial loss: 0.488807\n",
      "epoch 43; iter: 0; batch classifier loss: 0.121215; batch adversarial loss: 0.546115\n",
      "epoch 44; iter: 0; batch classifier loss: 0.104605; batch adversarial loss: 0.457136\n",
      "epoch 45; iter: 0; batch classifier loss: 0.082755; batch adversarial loss: 0.490221\n",
      "epoch 46; iter: 0; batch classifier loss: 0.088943; batch adversarial loss: 0.483387\n",
      "epoch 47; iter: 0; batch classifier loss: 0.117376; batch adversarial loss: 0.439117\n",
      "epoch 48; iter: 0; batch classifier loss: 0.149838; batch adversarial loss: 0.422107\n",
      "epoch 49; iter: 0; batch classifier loss: 0.106178; batch adversarial loss: 0.375832\n",
      "epoch 50; iter: 0; batch classifier loss: 0.128628; batch adversarial loss: 0.506613\n",
      "epoch 51; iter: 0; batch classifier loss: 0.105072; batch adversarial loss: 0.416114\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112240; batch adversarial loss: 0.492811\n",
      "epoch 53; iter: 0; batch classifier loss: 0.092004; batch adversarial loss: 0.482172\n",
      "epoch 54; iter: 0; batch classifier loss: 0.081626; batch adversarial loss: 0.470904\n",
      "epoch 55; iter: 0; batch classifier loss: 0.097205; batch adversarial loss: 0.398300\n",
      "epoch 56; iter: 0; batch classifier loss: 0.115027; batch adversarial loss: 0.423248\n",
      "epoch 57; iter: 0; batch classifier loss: 0.109483; batch adversarial loss: 0.410087\n",
      "epoch 58; iter: 0; batch classifier loss: 0.070234; batch adversarial loss: 0.480085\n",
      "epoch 59; iter: 0; batch classifier loss: 0.068434; batch adversarial loss: 0.406645\n",
      "epoch 60; iter: 0; batch classifier loss: 0.127428; batch adversarial loss: 0.478142\n",
      "epoch 61; iter: 0; batch classifier loss: 0.096704; batch adversarial loss: 0.561152\n",
      "epoch 62; iter: 0; batch classifier loss: 0.088729; batch adversarial loss: 0.385233\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128460; batch adversarial loss: 0.445954\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072874; batch adversarial loss: 0.423574\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082513; batch adversarial loss: 0.531616\n",
      "epoch 66; iter: 0; batch classifier loss: 0.063549; batch adversarial loss: 0.522214\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088290; batch adversarial loss: 0.473776\n",
      "epoch 68; iter: 0; batch classifier loss: 0.052781; batch adversarial loss: 0.502924\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095432; batch adversarial loss: 0.490415\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079606; batch adversarial loss: 0.450573\n",
      "epoch 71; iter: 0; batch classifier loss: 0.077646; batch adversarial loss: 0.459917\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085922; batch adversarial loss: 0.474370\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067958; batch adversarial loss: 0.487868\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054123; batch adversarial loss: 0.483366\n",
      "epoch 75; iter: 0; batch classifier loss: 0.082927; batch adversarial loss: 0.517116\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066217; batch adversarial loss: 0.408027\n",
      "epoch 77; iter: 0; batch classifier loss: 0.079043; batch adversarial loss: 0.581485\n",
      "epoch 78; iter: 0; batch classifier loss: 0.033073; batch adversarial loss: 0.393789\n",
      "epoch 79; iter: 0; batch classifier loss: 0.104943; batch adversarial loss: 0.337719\n",
      "epoch 80; iter: 0; batch classifier loss: 0.040819; batch adversarial loss: 0.378051\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081391; batch adversarial loss: 0.516297\n",
      "epoch 82; iter: 0; batch classifier loss: 0.045187; batch adversarial loss: 0.438626\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072585; batch adversarial loss: 0.434681\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055257; batch adversarial loss: 0.415459\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064380; batch adversarial loss: 0.427012\n",
      "epoch 86; iter: 0; batch classifier loss: 0.109405; batch adversarial loss: 0.383516\n",
      "epoch 87; iter: 0; batch classifier loss: 0.118566; batch adversarial loss: 0.443176\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055900; batch adversarial loss: 0.454101\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052465; batch adversarial loss: 0.465170\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061005; batch adversarial loss: 0.469915\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062921; batch adversarial loss: 0.451885\n",
      "epoch 92; iter: 0; batch classifier loss: 0.028243; batch adversarial loss: 0.486120\n",
      "epoch 93; iter: 0; batch classifier loss: 0.104446; batch adversarial loss: 0.417702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.069813; batch adversarial loss: 0.446865\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052985; batch adversarial loss: 0.436272\n",
      "epoch 96; iter: 0; batch classifier loss: 0.111738; batch adversarial loss: 0.394817\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048389; batch adversarial loss: 0.424008\n",
      "epoch 98; iter: 0; batch classifier loss: 0.029170; batch adversarial loss: 0.463759\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052028; batch adversarial loss: 0.421370\n",
      "epoch 100; iter: 0; batch classifier loss: 0.068690; batch adversarial loss: 0.488597\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046729; batch adversarial loss: 0.441950\n",
      "epoch 102; iter: 0; batch classifier loss: 0.035830; batch adversarial loss: 0.404284\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072602; batch adversarial loss: 0.319796\n",
      "epoch 104; iter: 0; batch classifier loss: 0.009965; batch adversarial loss: 0.561313\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030598; batch adversarial loss: 0.514615\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032800; batch adversarial loss: 0.450213\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051324; batch adversarial loss: 0.406636\n",
      "epoch 108; iter: 0; batch classifier loss: 0.034837; batch adversarial loss: 0.444232\n",
      "epoch 109; iter: 0; batch classifier loss: 0.022861; batch adversarial loss: 0.380629\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028418; batch adversarial loss: 0.436807\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028672; batch adversarial loss: 0.541515\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031059; batch adversarial loss: 0.412511\n",
      "epoch 113; iter: 0; batch classifier loss: 0.065691; batch adversarial loss: 0.387604\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029438; batch adversarial loss: 0.450387\n",
      "epoch 115; iter: 0; batch classifier loss: 0.030421; batch adversarial loss: 0.359660\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021079; batch adversarial loss: 0.426328\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048847; batch adversarial loss: 0.405285\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045670; batch adversarial loss: 0.535236\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041669; batch adversarial loss: 0.482366\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025410; batch adversarial loss: 0.548482\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025570; batch adversarial loss: 0.516859\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032637; batch adversarial loss: 0.467744\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024406; batch adversarial loss: 0.518473\n",
      "epoch 124; iter: 0; batch classifier loss: 0.034883; batch adversarial loss: 0.428025\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037652; batch adversarial loss: 0.438221\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020976; batch adversarial loss: 0.458459\n",
      "epoch 127; iter: 0; batch classifier loss: 0.062837; batch adversarial loss: 0.446630\n",
      "epoch 128; iter: 0; batch classifier loss: 0.068638; batch adversarial loss: 0.531917\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033510; batch adversarial loss: 0.569010\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026697; batch adversarial loss: 0.442692\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032232; batch adversarial loss: 0.419964\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031983; batch adversarial loss: 0.507883\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015315; batch adversarial loss: 0.474063\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027514; batch adversarial loss: 0.495129\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046051; batch adversarial loss: 0.436821\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038852; batch adversarial loss: 0.459816\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015765; batch adversarial loss: 0.486730\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031902; batch adversarial loss: 0.486676\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032886; batch adversarial loss: 0.408460\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018395; batch adversarial loss: 0.360778\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017448; batch adversarial loss: 0.418857\n",
      "epoch 142; iter: 0; batch classifier loss: 0.010264; batch adversarial loss: 0.419404\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034262; batch adversarial loss: 0.503945\n",
      "epoch 144; iter: 0; batch classifier loss: 0.007624; batch adversarial loss: 0.414629\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025781; batch adversarial loss: 0.488291\n",
      "epoch 146; iter: 0; batch classifier loss: 0.012882; batch adversarial loss: 0.463345\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020371; batch adversarial loss: 0.440898\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016845; batch adversarial loss: 0.434756\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025471; batch adversarial loss: 0.413259\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016910; batch adversarial loss: 0.414798\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024459; batch adversarial loss: 0.496555\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008774; batch adversarial loss: 0.472101\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025242; batch adversarial loss: 0.522748\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021369; batch adversarial loss: 0.504226\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017732; batch adversarial loss: 0.478356\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021030; batch adversarial loss: 0.425862\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037459; batch adversarial loss: 0.461511\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028945; batch adversarial loss: 0.477199\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039945; batch adversarial loss: 0.448776\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009861; batch adversarial loss: 0.376828\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028334; batch adversarial loss: 0.453257\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018888; batch adversarial loss: 0.506823\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016827; batch adversarial loss: 0.408491\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019690; batch adversarial loss: 0.513192\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012352; batch adversarial loss: 0.368316\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007446; batch adversarial loss: 0.398403\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012352; batch adversarial loss: 0.531664\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015854; batch adversarial loss: 0.551036\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010320; batch adversarial loss: 0.387152\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032211; batch adversarial loss: 0.528760\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013627; batch adversarial loss: 0.404870\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018788; batch adversarial loss: 0.504963\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011414; batch adversarial loss: 0.516364\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021845; batch adversarial loss: 0.327530\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014658; batch adversarial loss: 0.480903\n",
      "epoch 176; iter: 0; batch classifier loss: 0.004415; batch adversarial loss: 0.459815\n",
      "epoch 177; iter: 0; batch classifier loss: 0.003849; batch adversarial loss: 0.474962\n",
      "epoch 178; iter: 0; batch classifier loss: 0.004526; batch adversarial loss: 0.471076\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021096; batch adversarial loss: 0.472899\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023303; batch adversarial loss: 0.423749\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015731; batch adversarial loss: 0.451644\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021627; batch adversarial loss: 0.463816\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020278; batch adversarial loss: 0.543795\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020832; batch adversarial loss: 0.483616\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008146; batch adversarial loss: 0.418220\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007754; batch adversarial loss: 0.409277\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013184; batch adversarial loss: 0.424961\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018413; batch adversarial loss: 0.475980\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014966; batch adversarial loss: 0.404759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.014393; batch adversarial loss: 0.437210\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018737; batch adversarial loss: 0.407183\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013993; batch adversarial loss: 0.534919\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012210; batch adversarial loss: 0.462074\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005607; batch adversarial loss: 0.378265\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013784; batch adversarial loss: 0.383288\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033293; batch adversarial loss: 0.456588\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015277; batch adversarial loss: 0.442270\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019396; batch adversarial loss: 0.498231\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014092; batch adversarial loss: 0.431634\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697388; batch adversarial loss: 0.772833\n",
      "epoch 1; iter: 0; batch classifier loss: 0.391738; batch adversarial loss: 0.714928\n",
      "epoch 2; iter: 0; batch classifier loss: 0.535420; batch adversarial loss: 0.683783\n",
      "epoch 3; iter: 0; batch classifier loss: 0.471317; batch adversarial loss: 0.624948\n",
      "epoch 4; iter: 0; batch classifier loss: 0.342874; batch adversarial loss: 0.610830\n",
      "epoch 5; iter: 0; batch classifier loss: 0.344282; batch adversarial loss: 0.578329\n",
      "epoch 6; iter: 0; batch classifier loss: 0.404121; batch adversarial loss: 0.574574\n",
      "epoch 7; iter: 0; batch classifier loss: 0.390465; batch adversarial loss: 0.571099\n",
      "epoch 8; iter: 0; batch classifier loss: 0.374386; batch adversarial loss: 0.547532\n",
      "epoch 9; iter: 0; batch classifier loss: 0.432432; batch adversarial loss: 0.545010\n",
      "epoch 10; iter: 0; batch classifier loss: 0.405107; batch adversarial loss: 0.536666\n",
      "epoch 11; iter: 0; batch classifier loss: 0.470080; batch adversarial loss: 0.549327\n",
      "epoch 12; iter: 0; batch classifier loss: 0.474189; batch adversarial loss: 0.469610\n",
      "epoch 13; iter: 0; batch classifier loss: 0.363098; batch adversarial loss: 0.511639\n",
      "epoch 14; iter: 0; batch classifier loss: 0.352209; batch adversarial loss: 0.545184\n",
      "epoch 15; iter: 0; batch classifier loss: 0.368438; batch adversarial loss: 0.515432\n",
      "epoch 16; iter: 0; batch classifier loss: 0.362287; batch adversarial loss: 0.515127\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409387; batch adversarial loss: 0.524979\n",
      "epoch 18; iter: 0; batch classifier loss: 0.335661; batch adversarial loss: 0.553929\n",
      "epoch 19; iter: 0; batch classifier loss: 0.322042; batch adversarial loss: 0.433441\n",
      "epoch 20; iter: 0; batch classifier loss: 0.285460; batch adversarial loss: 0.489908\n",
      "epoch 21; iter: 0; batch classifier loss: 0.313442; batch adversarial loss: 0.479777\n",
      "epoch 22; iter: 0; batch classifier loss: 0.294760; batch adversarial loss: 0.495306\n",
      "epoch 23; iter: 0; batch classifier loss: 0.230958; batch adversarial loss: 0.472024\n",
      "epoch 24; iter: 0; batch classifier loss: 0.243326; batch adversarial loss: 0.485318\n",
      "epoch 25; iter: 0; batch classifier loss: 0.232413; batch adversarial loss: 0.509552\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243200; batch adversarial loss: 0.561767\n",
      "epoch 27; iter: 0; batch classifier loss: 0.213186; batch adversarial loss: 0.547323\n",
      "epoch 28; iter: 0; batch classifier loss: 0.232584; batch adversarial loss: 0.483599\n",
      "epoch 29; iter: 0; batch classifier loss: 0.298510; batch adversarial loss: 0.487609\n",
      "epoch 30; iter: 0; batch classifier loss: 0.241259; batch adversarial loss: 0.474016\n",
      "epoch 31; iter: 0; batch classifier loss: 0.296692; batch adversarial loss: 0.444458\n",
      "epoch 32; iter: 0; batch classifier loss: 0.264414; batch adversarial loss: 0.396505\n",
      "epoch 33; iter: 0; batch classifier loss: 0.260302; batch adversarial loss: 0.536394\n",
      "epoch 34; iter: 0; batch classifier loss: 0.279036; batch adversarial loss: 0.456488\n",
      "epoch 35; iter: 0; batch classifier loss: 0.194412; batch adversarial loss: 0.488127\n",
      "epoch 36; iter: 0; batch classifier loss: 0.228649; batch adversarial loss: 0.516065\n",
      "epoch 37; iter: 0; batch classifier loss: 0.205909; batch adversarial loss: 0.502203\n",
      "epoch 38; iter: 0; batch classifier loss: 0.158418; batch adversarial loss: 0.566608\n",
      "epoch 39; iter: 0; batch classifier loss: 0.195457; batch adversarial loss: 0.427449\n",
      "epoch 40; iter: 0; batch classifier loss: 0.165376; batch adversarial loss: 0.488241\n",
      "epoch 41; iter: 0; batch classifier loss: 0.241239; batch adversarial loss: 0.413625\n",
      "epoch 42; iter: 0; batch classifier loss: 0.216239; batch adversarial loss: 0.480391\n",
      "epoch 43; iter: 0; batch classifier loss: 0.211837; batch adversarial loss: 0.438921\n",
      "epoch 44; iter: 0; batch classifier loss: 0.167284; batch adversarial loss: 0.449332\n",
      "epoch 45; iter: 0; batch classifier loss: 0.229394; batch adversarial loss: 0.423696\n",
      "epoch 46; iter: 0; batch classifier loss: 0.266457; batch adversarial loss: 0.460597\n",
      "epoch 47; iter: 0; batch classifier loss: 0.230887; batch adversarial loss: 0.497344\n",
      "epoch 48; iter: 0; batch classifier loss: 0.211303; batch adversarial loss: 0.484218\n",
      "epoch 49; iter: 0; batch classifier loss: 0.190548; batch adversarial loss: 0.528429\n",
      "epoch 50; iter: 0; batch classifier loss: 0.205716; batch adversarial loss: 0.472133\n",
      "epoch 51; iter: 0; batch classifier loss: 0.248985; batch adversarial loss: 0.483962\n",
      "epoch 52; iter: 0; batch classifier loss: 0.146021; batch adversarial loss: 0.507639\n",
      "epoch 53; iter: 0; batch classifier loss: 0.208100; batch adversarial loss: 0.506310\n",
      "epoch 54; iter: 0; batch classifier loss: 0.157436; batch adversarial loss: 0.363508\n",
      "epoch 55; iter: 0; batch classifier loss: 0.169519; batch adversarial loss: 0.495169\n",
      "epoch 56; iter: 0; batch classifier loss: 0.192692; batch adversarial loss: 0.351198\n",
      "epoch 57; iter: 0; batch classifier loss: 0.105974; batch adversarial loss: 0.422621\n",
      "epoch 58; iter: 0; batch classifier loss: 0.104187; batch adversarial loss: 0.434041\n",
      "epoch 59; iter: 0; batch classifier loss: 0.145756; batch adversarial loss: 0.410006\n",
      "epoch 60; iter: 0; batch classifier loss: 0.127494; batch adversarial loss: 0.423500\n",
      "epoch 61; iter: 0; batch classifier loss: 0.117384; batch adversarial loss: 0.431563\n",
      "epoch 62; iter: 0; batch classifier loss: 0.137146; batch adversarial loss: 0.411698\n",
      "epoch 63; iter: 0; batch classifier loss: 0.150242; batch adversarial loss: 0.419242\n",
      "epoch 64; iter: 0; batch classifier loss: 0.077617; batch adversarial loss: 0.445419\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074257; batch adversarial loss: 0.483225\n",
      "epoch 66; iter: 0; batch classifier loss: 0.126411; batch adversarial loss: 0.434076\n",
      "epoch 67; iter: 0; batch classifier loss: 0.120727; batch adversarial loss: 0.480170\n",
      "epoch 68; iter: 0; batch classifier loss: 0.114139; batch adversarial loss: 0.420695\n",
      "epoch 69; iter: 0; batch classifier loss: 0.091953; batch adversarial loss: 0.417334\n",
      "epoch 70; iter: 0; batch classifier loss: 0.105679; batch adversarial loss: 0.448603\n",
      "epoch 71; iter: 0; batch classifier loss: 0.130754; batch adversarial loss: 0.435081\n",
      "epoch 72; iter: 0; batch classifier loss: 0.126075; batch adversarial loss: 0.491973\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074000; batch adversarial loss: 0.468213\n",
      "epoch 74; iter: 0; batch classifier loss: 0.112327; batch adversarial loss: 0.381281\n",
      "epoch 75; iter: 0; batch classifier loss: 0.095853; batch adversarial loss: 0.484817\n",
      "epoch 76; iter: 0; batch classifier loss: 0.168273; batch adversarial loss: 0.424627\n",
      "epoch 77; iter: 0; batch classifier loss: 0.096501; batch adversarial loss: 0.469953\n",
      "epoch 78; iter: 0; batch classifier loss: 0.104139; batch adversarial loss: 0.470790\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072562; batch adversarial loss: 0.551715\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068331; batch adversarial loss: 0.427952\n",
      "epoch 81; iter: 0; batch classifier loss: 0.110360; batch adversarial loss: 0.510660\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071792; batch adversarial loss: 0.424886\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066710; batch adversarial loss: 0.456105\n",
      "epoch 84; iter: 0; batch classifier loss: 0.066845; batch adversarial loss: 0.491478\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056869; batch adversarial loss: 0.414614\n",
      "epoch 86; iter: 0; batch classifier loss: 0.117818; batch adversarial loss: 0.440153\n",
      "epoch 87; iter: 0; batch classifier loss: 0.080562; batch adversarial loss: 0.432415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.091313; batch adversarial loss: 0.399507\n",
      "epoch 89; iter: 0; batch classifier loss: 0.062644; batch adversarial loss: 0.467897\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052145; batch adversarial loss: 0.488586\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059213; batch adversarial loss: 0.480319\n",
      "epoch 92; iter: 0; batch classifier loss: 0.102063; batch adversarial loss: 0.422208\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071773; batch adversarial loss: 0.371123\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042302; batch adversarial loss: 0.510516\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043342; batch adversarial loss: 0.450319\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049593; batch adversarial loss: 0.397633\n",
      "epoch 97; iter: 0; batch classifier loss: 0.022399; batch adversarial loss: 0.490659\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036059; batch adversarial loss: 0.431184\n",
      "epoch 99; iter: 0; batch classifier loss: 0.032849; batch adversarial loss: 0.443834\n",
      "epoch 100; iter: 0; batch classifier loss: 0.031811; batch adversarial loss: 0.535475\n",
      "epoch 101; iter: 0; batch classifier loss: 0.066994; batch adversarial loss: 0.407932\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049591; batch adversarial loss: 0.395081\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044440; batch adversarial loss: 0.468525\n",
      "epoch 104; iter: 0; batch classifier loss: 0.070201; batch adversarial loss: 0.492905\n",
      "epoch 105; iter: 0; batch classifier loss: 0.033064; batch adversarial loss: 0.351080\n",
      "epoch 106; iter: 0; batch classifier loss: 0.048472; batch adversarial loss: 0.482222\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045921; batch adversarial loss: 0.482798\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033113; batch adversarial loss: 0.533085\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054479; batch adversarial loss: 0.526768\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034394; batch adversarial loss: 0.461897\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028664; batch adversarial loss: 0.479660\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026417; batch adversarial loss: 0.431533\n",
      "epoch 113; iter: 0; batch classifier loss: 0.066936; batch adversarial loss: 0.539288\n",
      "epoch 114; iter: 0; batch classifier loss: 0.066569; batch adversarial loss: 0.432976\n",
      "epoch 115; iter: 0; batch classifier loss: 0.026162; batch adversarial loss: 0.449270\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046226; batch adversarial loss: 0.488823\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053965; batch adversarial loss: 0.363208\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030698; batch adversarial loss: 0.356965\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021200; batch adversarial loss: 0.431950\n",
      "epoch 120; iter: 0; batch classifier loss: 0.059348; batch adversarial loss: 0.488537\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037644; batch adversarial loss: 0.431316\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036922; batch adversarial loss: 0.472193\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042676; batch adversarial loss: 0.488159\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031599; batch adversarial loss: 0.418531\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027680; batch adversarial loss: 0.441682\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042006; batch adversarial loss: 0.461553\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023491; batch adversarial loss: 0.466285\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024372; batch adversarial loss: 0.415115\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026564; batch adversarial loss: 0.392821\n",
      "epoch 130; iter: 0; batch classifier loss: 0.064550; batch adversarial loss: 0.529716\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029905; batch adversarial loss: 0.481234\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016565; batch adversarial loss: 0.432828\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018161; batch adversarial loss: 0.490570\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021148; batch adversarial loss: 0.429301\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016414; batch adversarial loss: 0.432167\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019143; batch adversarial loss: 0.457068\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025680; batch adversarial loss: 0.506668\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017589; batch adversarial loss: 0.504958\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022198; batch adversarial loss: 0.444975\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026512; batch adversarial loss: 0.425079\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016272; batch adversarial loss: 0.467249\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020859; batch adversarial loss: 0.429759\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034726; batch adversarial loss: 0.404643\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026300; batch adversarial loss: 0.502639\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016721; batch adversarial loss: 0.499568\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042830; batch adversarial loss: 0.422734\n",
      "epoch 147; iter: 0; batch classifier loss: 0.055010; batch adversarial loss: 0.399578\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013117; batch adversarial loss: 0.408395\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053272; batch adversarial loss: 0.543464\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011774; batch adversarial loss: 0.624003\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038077; batch adversarial loss: 0.441301\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017650; batch adversarial loss: 0.444257\n",
      "epoch 153; iter: 0; batch classifier loss: 0.005842; batch adversarial loss: 0.458691\n",
      "epoch 154; iter: 0; batch classifier loss: 0.009477; batch adversarial loss: 0.434515\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019355; batch adversarial loss: 0.432526\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031685; batch adversarial loss: 0.344327\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013910; batch adversarial loss: 0.465071\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037235; batch adversarial loss: 0.403702\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023965; batch adversarial loss: 0.382673\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029199; batch adversarial loss: 0.477003\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008705; batch adversarial loss: 0.453222\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023839; batch adversarial loss: 0.492024\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012103; batch adversarial loss: 0.441610\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021272; batch adversarial loss: 0.405238\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031378; batch adversarial loss: 0.463168\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013219; batch adversarial loss: 0.433170\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020566; batch adversarial loss: 0.418523\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014104; batch adversarial loss: 0.501078\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021756; batch adversarial loss: 0.472121\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011311; batch adversarial loss: 0.433594\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012769; batch adversarial loss: 0.436450\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034651; batch adversarial loss: 0.451936\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020425; batch adversarial loss: 0.399532\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032901; batch adversarial loss: 0.446686\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040339; batch adversarial loss: 0.340013\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032158; batch adversarial loss: 0.556503\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014411; batch adversarial loss: 0.542450\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019092; batch adversarial loss: 0.507742\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014664; batch adversarial loss: 0.437547\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013021; batch adversarial loss: 0.471288\n",
      "epoch 181; iter: 0; batch classifier loss: 0.042149; batch adversarial loss: 0.413630\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024532; batch adversarial loss: 0.420248\n",
      "epoch 183; iter: 0; batch classifier loss: 0.037815; batch adversarial loss: 0.345509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.026847; batch adversarial loss: 0.483370\n",
      "epoch 185; iter: 0; batch classifier loss: 0.046505; batch adversarial loss: 0.491386\n",
      "epoch 186; iter: 0; batch classifier loss: 0.046228; batch adversarial loss: 0.422990\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014700; batch adversarial loss: 0.408500\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012975; batch adversarial loss: 0.441815\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031480; batch adversarial loss: 0.407190\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018129; batch adversarial loss: 0.495324\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006288; batch adversarial loss: 0.414841\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006484; batch adversarial loss: 0.491773\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019739; batch adversarial loss: 0.549172\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018476; batch adversarial loss: 0.393095\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013174; batch adversarial loss: 0.439721\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012835; batch adversarial loss: 0.389646\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004558; batch adversarial loss: 0.577842\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014689; batch adversarial loss: 0.477358\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005518; batch adversarial loss: 0.395082\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677140; batch adversarial loss: 0.528238\n",
      "epoch 1; iter: 0; batch classifier loss: 0.432599; batch adversarial loss: 0.611698\n",
      "epoch 2; iter: 0; batch classifier loss: 0.427618; batch adversarial loss: 0.549349\n",
      "epoch 3; iter: 0; batch classifier loss: 0.329104; batch adversarial loss: 0.576710\n",
      "epoch 4; iter: 0; batch classifier loss: 0.352654; batch adversarial loss: 0.539958\n",
      "epoch 5; iter: 0; batch classifier loss: 0.351014; batch adversarial loss: 0.546095\n",
      "epoch 6; iter: 0; batch classifier loss: 0.335944; batch adversarial loss: 0.533589\n",
      "epoch 7; iter: 0; batch classifier loss: 0.299697; batch adversarial loss: 0.573442\n",
      "epoch 8; iter: 0; batch classifier loss: 0.378687; batch adversarial loss: 0.519714\n",
      "epoch 9; iter: 0; batch classifier loss: 0.252807; batch adversarial loss: 0.622399\n",
      "epoch 10; iter: 0; batch classifier loss: 0.255843; batch adversarial loss: 0.470202\n",
      "epoch 11; iter: 0; batch classifier loss: 0.334604; batch adversarial loss: 0.548306\n",
      "epoch 12; iter: 0; batch classifier loss: 0.323106; batch adversarial loss: 0.555552\n",
      "epoch 13; iter: 0; batch classifier loss: 0.389845; batch adversarial loss: 0.543420\n",
      "epoch 14; iter: 0; batch classifier loss: 0.307142; batch adversarial loss: 0.456964\n",
      "epoch 15; iter: 0; batch classifier loss: 0.276785; batch adversarial loss: 0.433580\n",
      "epoch 16; iter: 0; batch classifier loss: 0.385611; batch adversarial loss: 0.491237\n",
      "epoch 17; iter: 0; batch classifier loss: 0.375910; batch adversarial loss: 0.484827\n",
      "epoch 18; iter: 0; batch classifier loss: 0.533939; batch adversarial loss: 0.509833\n",
      "epoch 19; iter: 0; batch classifier loss: 0.399955; batch adversarial loss: 0.475473\n",
      "epoch 20; iter: 0; batch classifier loss: 0.248013; batch adversarial loss: 0.476171\n",
      "epoch 21; iter: 0; batch classifier loss: 0.246437; batch adversarial loss: 0.461179\n",
      "epoch 22; iter: 0; batch classifier loss: 0.182435; batch adversarial loss: 0.474893\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171190; batch adversarial loss: 0.438203\n",
      "epoch 24; iter: 0; batch classifier loss: 0.209110; batch adversarial loss: 0.421699\n",
      "epoch 25; iter: 0; batch classifier loss: 0.145272; batch adversarial loss: 0.435818\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165302; batch adversarial loss: 0.447459\n",
      "epoch 27; iter: 0; batch classifier loss: 0.147088; batch adversarial loss: 0.422182\n",
      "epoch 28; iter: 0; batch classifier loss: 0.164528; batch adversarial loss: 0.409978\n",
      "epoch 29; iter: 0; batch classifier loss: 0.206026; batch adversarial loss: 0.505311\n",
      "epoch 30; iter: 0; batch classifier loss: 0.129061; batch adversarial loss: 0.384772\n",
      "epoch 31; iter: 0; batch classifier loss: 0.159363; batch adversarial loss: 0.439191\n",
      "epoch 32; iter: 0; batch classifier loss: 0.137778; batch adversarial loss: 0.444415\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143517; batch adversarial loss: 0.430654\n",
      "epoch 34; iter: 0; batch classifier loss: 0.173900; batch adversarial loss: 0.399694\n",
      "epoch 35; iter: 0; batch classifier loss: 0.082589; batch adversarial loss: 0.454044\n",
      "epoch 36; iter: 0; batch classifier loss: 0.134676; batch adversarial loss: 0.503032\n",
      "epoch 37; iter: 0; batch classifier loss: 0.138521; batch adversarial loss: 0.454724\n",
      "epoch 38; iter: 0; batch classifier loss: 0.077961; batch adversarial loss: 0.449386\n",
      "epoch 39; iter: 0; batch classifier loss: 0.088746; batch adversarial loss: 0.501582\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116824; batch adversarial loss: 0.553350\n",
      "epoch 41; iter: 0; batch classifier loss: 0.076966; batch adversarial loss: 0.467496\n",
      "epoch 42; iter: 0; batch classifier loss: 0.098148; batch adversarial loss: 0.470698\n",
      "epoch 43; iter: 0; batch classifier loss: 0.114733; batch adversarial loss: 0.378529\n",
      "epoch 44; iter: 0; batch classifier loss: 0.113821; batch adversarial loss: 0.378872\n",
      "epoch 45; iter: 0; batch classifier loss: 0.087203; batch adversarial loss: 0.500404\n",
      "epoch 46; iter: 0; batch classifier loss: 0.160426; batch adversarial loss: 0.491132\n",
      "epoch 47; iter: 0; batch classifier loss: 0.129630; batch adversarial loss: 0.421598\n",
      "epoch 48; iter: 0; batch classifier loss: 0.122824; batch adversarial loss: 0.453858\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094373; batch adversarial loss: 0.409363\n",
      "epoch 50; iter: 0; batch classifier loss: 0.099946; batch adversarial loss: 0.498151\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112411; batch adversarial loss: 0.435957\n",
      "epoch 52; iter: 0; batch classifier loss: 0.115040; batch adversarial loss: 0.495069\n",
      "epoch 53; iter: 0; batch classifier loss: 0.170139; batch adversarial loss: 0.364689\n",
      "epoch 54; iter: 0; batch classifier loss: 0.083068; batch adversarial loss: 0.504480\n",
      "epoch 55; iter: 0; batch classifier loss: 0.162766; batch adversarial loss: 0.394857\n",
      "epoch 56; iter: 0; batch classifier loss: 0.126380; batch adversarial loss: 0.427896\n",
      "epoch 57; iter: 0; batch classifier loss: 0.159507; batch adversarial loss: 0.386677\n",
      "epoch 58; iter: 0; batch classifier loss: 0.113297; batch adversarial loss: 0.538894\n",
      "epoch 59; iter: 0; batch classifier loss: 0.109632; batch adversarial loss: 0.546690\n",
      "epoch 60; iter: 0; batch classifier loss: 0.147364; batch adversarial loss: 0.430057\n",
      "epoch 61; iter: 0; batch classifier loss: 0.130233; batch adversarial loss: 0.393585\n",
      "epoch 62; iter: 0; batch classifier loss: 0.113882; batch adversarial loss: 0.388170\n",
      "epoch 63; iter: 0; batch classifier loss: 0.163877; batch adversarial loss: 0.390927\n",
      "epoch 64; iter: 0; batch classifier loss: 0.125306; batch adversarial loss: 0.544423\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075786; batch adversarial loss: 0.563069\n",
      "epoch 66; iter: 0; batch classifier loss: 0.143847; batch adversarial loss: 0.417409\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094446; batch adversarial loss: 0.504689\n",
      "epoch 68; iter: 0; batch classifier loss: 0.185101; batch adversarial loss: 0.461998\n",
      "epoch 69; iter: 0; batch classifier loss: 0.177034; batch adversarial loss: 0.458007\n",
      "epoch 70; iter: 0; batch classifier loss: 0.163406; batch adversarial loss: 0.468241\n",
      "epoch 71; iter: 0; batch classifier loss: 0.162971; batch adversarial loss: 0.495084\n",
      "epoch 72; iter: 0; batch classifier loss: 0.161909; batch adversarial loss: 0.479422\n",
      "epoch 73; iter: 0; batch classifier loss: 0.098363; batch adversarial loss: 0.460774\n",
      "epoch 74; iter: 0; batch classifier loss: 0.216599; batch adversarial loss: 0.566644\n",
      "epoch 75; iter: 0; batch classifier loss: 0.128258; batch adversarial loss: 0.417826\n",
      "epoch 76; iter: 0; batch classifier loss: 0.088721; batch adversarial loss: 0.442362\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104155; batch adversarial loss: 0.412242\n",
      "epoch 78; iter: 0; batch classifier loss: 0.050798; batch adversarial loss: 0.563553\n",
      "epoch 79; iter: 0; batch classifier loss: 0.183464; batch adversarial loss: 0.512646\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088627; batch adversarial loss: 0.475337\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079121; batch adversarial loss: 0.486606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.149252; batch adversarial loss: 0.469145\n",
      "epoch 83; iter: 0; batch classifier loss: 0.176503; batch adversarial loss: 0.430202\n",
      "epoch 84; iter: 0; batch classifier loss: 0.137963; batch adversarial loss: 0.408657\n",
      "epoch 85; iter: 0; batch classifier loss: 0.230680; batch adversarial loss: 0.470558\n",
      "epoch 86; iter: 0; batch classifier loss: 0.114594; batch adversarial loss: 0.482538\n",
      "epoch 87; iter: 0; batch classifier loss: 0.126124; batch adversarial loss: 0.534961\n",
      "epoch 88; iter: 0; batch classifier loss: 0.149880; batch adversarial loss: 0.505801\n",
      "epoch 89; iter: 0; batch classifier loss: 0.168099; batch adversarial loss: 0.471512\n",
      "epoch 90; iter: 0; batch classifier loss: 0.155798; batch adversarial loss: 0.487640\n",
      "epoch 91; iter: 0; batch classifier loss: 0.130567; batch adversarial loss: 0.457848\n",
      "epoch 92; iter: 0; batch classifier loss: 0.156337; batch adversarial loss: 0.467189\n",
      "epoch 93; iter: 0; batch classifier loss: 0.158383; batch adversarial loss: 0.453642\n",
      "epoch 94; iter: 0; batch classifier loss: 0.154849; batch adversarial loss: 0.431835\n",
      "epoch 95; iter: 0; batch classifier loss: 0.114463; batch adversarial loss: 0.533477\n",
      "epoch 96; iter: 0; batch classifier loss: 0.120252; batch adversarial loss: 0.531085\n",
      "epoch 97; iter: 0; batch classifier loss: 0.120684; batch adversarial loss: 0.471718\n",
      "epoch 98; iter: 0; batch classifier loss: 0.155397; batch adversarial loss: 0.460217\n",
      "epoch 99; iter: 0; batch classifier loss: 0.103127; batch adversarial loss: 0.462835\n",
      "epoch 100; iter: 0; batch classifier loss: 0.149428; batch adversarial loss: 0.449505\n",
      "epoch 101; iter: 0; batch classifier loss: 0.119520; batch adversarial loss: 0.393036\n",
      "epoch 102; iter: 0; batch classifier loss: 0.118447; batch adversarial loss: 0.404511\n",
      "epoch 103; iter: 0; batch classifier loss: 0.221770; batch adversarial loss: 0.402400\n",
      "epoch 104; iter: 0; batch classifier loss: 0.158387; batch adversarial loss: 0.451055\n",
      "epoch 105; iter: 0; batch classifier loss: 0.074315; batch adversarial loss: 0.385942\n",
      "epoch 106; iter: 0; batch classifier loss: 0.109979; batch adversarial loss: 0.556910\n",
      "epoch 107; iter: 0; batch classifier loss: 0.133840; batch adversarial loss: 0.405659\n",
      "epoch 108; iter: 0; batch classifier loss: 0.197654; batch adversarial loss: 0.431160\n",
      "epoch 109; iter: 0; batch classifier loss: 0.132321; batch adversarial loss: 0.461799\n",
      "epoch 110; iter: 0; batch classifier loss: 0.085770; batch adversarial loss: 0.487764\n",
      "epoch 111; iter: 0; batch classifier loss: 0.131354; batch adversarial loss: 0.506132\n",
      "epoch 112; iter: 0; batch classifier loss: 0.163112; batch adversarial loss: 0.401964\n",
      "epoch 113; iter: 0; batch classifier loss: 0.104900; batch adversarial loss: 0.475310\n",
      "epoch 114; iter: 0; batch classifier loss: 0.150460; batch adversarial loss: 0.428896\n",
      "epoch 115; iter: 0; batch classifier loss: 0.096728; batch adversarial loss: 0.420491\n",
      "epoch 116; iter: 0; batch classifier loss: 0.113199; batch adversarial loss: 0.495777\n",
      "epoch 117; iter: 0; batch classifier loss: 0.115458; batch adversarial loss: 0.503893\n",
      "epoch 118; iter: 0; batch classifier loss: 0.131125; batch adversarial loss: 0.481735\n",
      "epoch 119; iter: 0; batch classifier loss: 0.092438; batch adversarial loss: 0.445941\n",
      "epoch 120; iter: 0; batch classifier loss: 0.073720; batch adversarial loss: 0.460831\n",
      "epoch 121; iter: 0; batch classifier loss: 0.076691; batch adversarial loss: 0.444049\n",
      "epoch 122; iter: 0; batch classifier loss: 0.108406; batch adversarial loss: 0.458390\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053247; batch adversarial loss: 0.453064\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059112; batch adversarial loss: 0.515825\n",
      "epoch 125; iter: 0; batch classifier loss: 0.070128; batch adversarial loss: 0.554793\n",
      "epoch 126; iter: 0; batch classifier loss: 0.078376; batch adversarial loss: 0.403034\n",
      "epoch 127; iter: 0; batch classifier loss: 0.094743; batch adversarial loss: 0.521219\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052344; batch adversarial loss: 0.523499\n",
      "epoch 129; iter: 0; batch classifier loss: 0.070226; batch adversarial loss: 0.473980\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059419; batch adversarial loss: 0.494357\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048660; batch adversarial loss: 0.490781\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046293; batch adversarial loss: 0.488662\n",
      "epoch 133; iter: 0; batch classifier loss: 0.070530; batch adversarial loss: 0.502886\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036679; batch adversarial loss: 0.369142\n",
      "epoch 135; iter: 0; batch classifier loss: 0.064110; batch adversarial loss: 0.446884\n",
      "epoch 136; iter: 0; batch classifier loss: 0.060116; batch adversarial loss: 0.422819\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044766; batch adversarial loss: 0.424675\n",
      "epoch 138; iter: 0; batch classifier loss: 0.059748; batch adversarial loss: 0.461969\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036171; batch adversarial loss: 0.431693\n",
      "epoch 140; iter: 0; batch classifier loss: 0.064929; batch adversarial loss: 0.466140\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052357; batch adversarial loss: 0.452033\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020674; batch adversarial loss: 0.396280\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039075; batch adversarial loss: 0.424889\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031812; batch adversarial loss: 0.454305\n",
      "epoch 145; iter: 0; batch classifier loss: 0.063133; batch adversarial loss: 0.423861\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032125; batch adversarial loss: 0.450120\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032606; batch adversarial loss: 0.479210\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014688; batch adversarial loss: 0.475796\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035617; batch adversarial loss: 0.462090\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044513; batch adversarial loss: 0.518921\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038121; batch adversarial loss: 0.523378\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045509; batch adversarial loss: 0.482359\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035932; batch adversarial loss: 0.487692\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041010; batch adversarial loss: 0.498208\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031216; batch adversarial loss: 0.433997\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028826; batch adversarial loss: 0.442854\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021058; batch adversarial loss: 0.486958\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011895; batch adversarial loss: 0.561850\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025915; batch adversarial loss: 0.481821\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022098; batch adversarial loss: 0.484560\n",
      "epoch 161; iter: 0; batch classifier loss: 0.041722; batch adversarial loss: 0.513820\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019509; batch adversarial loss: 0.410059\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025381; batch adversarial loss: 0.440925\n",
      "epoch 164; iter: 0; batch classifier loss: 0.055673; batch adversarial loss: 0.443423\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028580; batch adversarial loss: 0.375772\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021040; batch adversarial loss: 0.437250\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026079; batch adversarial loss: 0.523008\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016002; batch adversarial loss: 0.435749\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009057; batch adversarial loss: 0.465145\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037110; batch adversarial loss: 0.440473\n",
      "epoch 171; iter: 0; batch classifier loss: 0.035435; batch adversarial loss: 0.524670\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012001; batch adversarial loss: 0.393550\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021716; batch adversarial loss: 0.397842\n",
      "epoch 174; iter: 0; batch classifier loss: 0.046909; batch adversarial loss: 0.336893\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010162; batch adversarial loss: 0.469145\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008748; batch adversarial loss: 0.397214\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037106; batch adversarial loss: 0.391192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.014460; batch adversarial loss: 0.416201\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022233; batch adversarial loss: 0.547440\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025855; batch adversarial loss: 0.454764\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013610; batch adversarial loss: 0.535668\n",
      "epoch 182; iter: 0; batch classifier loss: 0.003470; batch adversarial loss: 0.483443\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008125; batch adversarial loss: 0.463523\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012566; batch adversarial loss: 0.517544\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006333; batch adversarial loss: 0.492596\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034198; batch adversarial loss: 0.413480\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024109; batch adversarial loss: 0.482359\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017463; batch adversarial loss: 0.473930\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019970; batch adversarial loss: 0.365886\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013310; batch adversarial loss: 0.504479\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016033; batch adversarial loss: 0.488579\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036183; batch adversarial loss: 0.420800\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018131; batch adversarial loss: 0.402533\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009242; batch adversarial loss: 0.401703\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012193; batch adversarial loss: 0.508543\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012104; batch adversarial loss: 0.446163\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006638; batch adversarial loss: 0.348290\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017848; batch adversarial loss: 0.461955\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016482; batch adversarial loss: 0.544982\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722963; batch adversarial loss: 0.813525\n",
      "epoch 1; iter: 0; batch classifier loss: 0.456127; batch adversarial loss: 0.793184\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396931; batch adversarial loss: 0.743749\n",
      "epoch 3; iter: 0; batch classifier loss: 0.456558; batch adversarial loss: 0.691511\n",
      "epoch 4; iter: 0; batch classifier loss: 0.418554; batch adversarial loss: 0.644644\n",
      "epoch 5; iter: 0; batch classifier loss: 0.317481; batch adversarial loss: 0.622798\n",
      "epoch 6; iter: 0; batch classifier loss: 0.259509; batch adversarial loss: 0.608721\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338563; batch adversarial loss: 0.579201\n",
      "epoch 8; iter: 0; batch classifier loss: 0.238624; batch adversarial loss: 0.568765\n",
      "epoch 9; iter: 0; batch classifier loss: 0.412339; batch adversarial loss: 0.555156\n",
      "epoch 10; iter: 0; batch classifier loss: 0.291738; batch adversarial loss: 0.498787\n",
      "epoch 11; iter: 0; batch classifier loss: 0.235242; batch adversarial loss: 0.532004\n",
      "epoch 12; iter: 0; batch classifier loss: 0.247307; batch adversarial loss: 0.479908\n",
      "epoch 13; iter: 0; batch classifier loss: 0.197301; batch adversarial loss: 0.546984\n",
      "epoch 14; iter: 0; batch classifier loss: 0.204580; batch adversarial loss: 0.508899\n",
      "epoch 15; iter: 0; batch classifier loss: 0.194686; batch adversarial loss: 0.453278\n",
      "epoch 16; iter: 0; batch classifier loss: 0.175639; batch adversarial loss: 0.446800\n",
      "epoch 17; iter: 0; batch classifier loss: 0.205763; batch adversarial loss: 0.423198\n",
      "epoch 18; iter: 0; batch classifier loss: 0.189438; batch adversarial loss: 0.457613\n",
      "epoch 19; iter: 0; batch classifier loss: 0.124251; batch adversarial loss: 0.515584\n",
      "epoch 20; iter: 0; batch classifier loss: 0.167594; batch adversarial loss: 0.455046\n",
      "epoch 21; iter: 0; batch classifier loss: 0.150977; batch adversarial loss: 0.452380\n",
      "epoch 22; iter: 0; batch classifier loss: 0.151801; batch adversarial loss: 0.378770\n",
      "epoch 23; iter: 0; batch classifier loss: 0.140999; batch adversarial loss: 0.495925\n",
      "epoch 24; iter: 0; batch classifier loss: 0.178369; batch adversarial loss: 0.510662\n",
      "epoch 25; iter: 0; batch classifier loss: 0.133019; batch adversarial loss: 0.499074\n",
      "epoch 26; iter: 0; batch classifier loss: 0.102342; batch adversarial loss: 0.531827\n",
      "epoch 27; iter: 0; batch classifier loss: 0.116432; batch adversarial loss: 0.442804\n",
      "epoch 28; iter: 0; batch classifier loss: 0.104703; batch adversarial loss: 0.430794\n",
      "epoch 29; iter: 0; batch classifier loss: 0.115103; batch adversarial loss: 0.497085\n",
      "epoch 30; iter: 0; batch classifier loss: 0.114509; batch adversarial loss: 0.566891\n",
      "epoch 31; iter: 0; batch classifier loss: 0.111786; batch adversarial loss: 0.471896\n",
      "epoch 32; iter: 0; batch classifier loss: 0.171845; batch adversarial loss: 0.559578\n",
      "epoch 33; iter: 0; batch classifier loss: 0.178947; batch adversarial loss: 0.373415\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122688; batch adversarial loss: 0.421258\n",
      "epoch 35; iter: 0; batch classifier loss: 0.114718; batch adversarial loss: 0.533890\n",
      "epoch 36; iter: 0; batch classifier loss: 0.135668; batch adversarial loss: 0.487156\n",
      "epoch 37; iter: 0; batch classifier loss: 0.125231; batch adversarial loss: 0.451046\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122955; batch adversarial loss: 0.589746\n",
      "epoch 39; iter: 0; batch classifier loss: 0.103588; batch adversarial loss: 0.494459\n",
      "epoch 40; iter: 0; batch classifier loss: 0.127920; batch adversarial loss: 0.410328\n",
      "epoch 41; iter: 0; batch classifier loss: 0.119862; batch adversarial loss: 0.543855\n",
      "epoch 42; iter: 0; batch classifier loss: 0.061573; batch adversarial loss: 0.511124\n",
      "epoch 43; iter: 0; batch classifier loss: 0.091030; batch adversarial loss: 0.390712\n",
      "epoch 44; iter: 0; batch classifier loss: 0.079053; batch adversarial loss: 0.471546\n",
      "epoch 45; iter: 0; batch classifier loss: 0.119803; batch adversarial loss: 0.540637\n",
      "epoch 46; iter: 0; batch classifier loss: 0.056203; batch adversarial loss: 0.490776\n",
      "epoch 47; iter: 0; batch classifier loss: 0.063178; batch adversarial loss: 0.417312\n",
      "epoch 48; iter: 0; batch classifier loss: 0.073956; batch adversarial loss: 0.490628\n",
      "epoch 49; iter: 0; batch classifier loss: 0.062805; batch adversarial loss: 0.427078\n",
      "epoch 50; iter: 0; batch classifier loss: 0.061097; batch adversarial loss: 0.513792\n",
      "epoch 51; iter: 0; batch classifier loss: 0.059627; batch adversarial loss: 0.573849\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111988; batch adversarial loss: 0.421819\n",
      "epoch 53; iter: 0; batch classifier loss: 0.073691; batch adversarial loss: 0.475821\n",
      "epoch 54; iter: 0; batch classifier loss: 0.070958; batch adversarial loss: 0.501756\n",
      "epoch 55; iter: 0; batch classifier loss: 0.049828; batch adversarial loss: 0.415159\n",
      "epoch 56; iter: 0; batch classifier loss: 0.071712; batch adversarial loss: 0.428128\n",
      "epoch 57; iter: 0; batch classifier loss: 0.057975; batch adversarial loss: 0.533602\n",
      "epoch 58; iter: 0; batch classifier loss: 0.049843; batch adversarial loss: 0.475822\n",
      "epoch 59; iter: 0; batch classifier loss: 0.029688; batch adversarial loss: 0.468941\n",
      "epoch 60; iter: 0; batch classifier loss: 0.082543; batch adversarial loss: 0.424814\n",
      "epoch 61; iter: 0; batch classifier loss: 0.072917; batch adversarial loss: 0.498074\n",
      "epoch 62; iter: 0; batch classifier loss: 0.063321; batch adversarial loss: 0.442921\n",
      "epoch 63; iter: 0; batch classifier loss: 0.042765; batch adversarial loss: 0.483459\n",
      "epoch 64; iter: 0; batch classifier loss: 0.044458; batch adversarial loss: 0.426459\n",
      "epoch 65; iter: 0; batch classifier loss: 0.086194; batch adversarial loss: 0.518196\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078938; batch adversarial loss: 0.460098\n",
      "epoch 67; iter: 0; batch classifier loss: 0.070731; batch adversarial loss: 0.443215\n",
      "epoch 68; iter: 0; batch classifier loss: 0.052037; batch adversarial loss: 0.453314\n",
      "epoch 69; iter: 0; batch classifier loss: 0.035299; batch adversarial loss: 0.525644\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070406; batch adversarial loss: 0.320423\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097457; batch adversarial loss: 0.377146\n",
      "epoch 72; iter: 0; batch classifier loss: 0.033504; batch adversarial loss: 0.626248\n",
      "epoch 73; iter: 0; batch classifier loss: 0.063013; batch adversarial loss: 0.456682\n",
      "epoch 74; iter: 0; batch classifier loss: 0.039165; batch adversarial loss: 0.559943\n",
      "epoch 75; iter: 0; batch classifier loss: 0.065284; batch adversarial loss: 0.433825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.040843; batch adversarial loss: 0.383604\n",
      "epoch 77; iter: 0; batch classifier loss: 0.044369; batch adversarial loss: 0.540637\n",
      "epoch 78; iter: 0; batch classifier loss: 0.039679; batch adversarial loss: 0.471713\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075604; batch adversarial loss: 0.480924\n",
      "epoch 80; iter: 0; batch classifier loss: 0.051824; batch adversarial loss: 0.343988\n",
      "epoch 81; iter: 0; batch classifier loss: 0.048690; batch adversarial loss: 0.465976\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046629; batch adversarial loss: 0.433398\n",
      "epoch 83; iter: 0; batch classifier loss: 0.016817; batch adversarial loss: 0.560287\n",
      "epoch 84; iter: 0; batch classifier loss: 0.042283; batch adversarial loss: 0.417014\n",
      "epoch 85; iter: 0; batch classifier loss: 0.049585; batch adversarial loss: 0.455082\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058725; batch adversarial loss: 0.414176\n",
      "epoch 87; iter: 0; batch classifier loss: 0.037855; batch adversarial loss: 0.564998\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055832; batch adversarial loss: 0.453735\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035027; batch adversarial loss: 0.433622\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050108; batch adversarial loss: 0.418393\n",
      "epoch 91; iter: 0; batch classifier loss: 0.042674; batch adversarial loss: 0.420846\n",
      "epoch 92; iter: 0; batch classifier loss: 0.039693; batch adversarial loss: 0.467798\n",
      "epoch 93; iter: 0; batch classifier loss: 0.035955; batch adversarial loss: 0.471200\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072462; batch adversarial loss: 0.402478\n",
      "epoch 95; iter: 0; batch classifier loss: 0.032979; batch adversarial loss: 0.412932\n",
      "epoch 96; iter: 0; batch classifier loss: 0.013623; batch adversarial loss: 0.570257\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042887; batch adversarial loss: 0.442807\n",
      "epoch 98; iter: 0; batch classifier loss: 0.041527; batch adversarial loss: 0.409933\n",
      "epoch 99; iter: 0; batch classifier loss: 0.030950; batch adversarial loss: 0.395296\n",
      "epoch 100; iter: 0; batch classifier loss: 0.028102; batch adversarial loss: 0.438711\n",
      "epoch 101; iter: 0; batch classifier loss: 0.035677; batch adversarial loss: 0.374597\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057431; batch adversarial loss: 0.449361\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044327; batch adversarial loss: 0.416738\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039121; batch adversarial loss: 0.421790\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029448; batch adversarial loss: 0.405075\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030133; batch adversarial loss: 0.440361\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032142; batch adversarial loss: 0.501497\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070655; batch adversarial loss: 0.478109\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033842; batch adversarial loss: 0.616307\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068207; batch adversarial loss: 0.393051\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041466; batch adversarial loss: 0.555620\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031087; batch adversarial loss: 0.437556\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025297; batch adversarial loss: 0.397083\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049486; batch adversarial loss: 0.404237\n",
      "epoch 115; iter: 0; batch classifier loss: 0.018101; batch adversarial loss: 0.376450\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028712; batch adversarial loss: 0.444195\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051406; batch adversarial loss: 0.477516\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039445; batch adversarial loss: 0.523346\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036382; batch adversarial loss: 0.438720\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032259; batch adversarial loss: 0.468271\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031779; batch adversarial loss: 0.388247\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037233; batch adversarial loss: 0.513891\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041527; batch adversarial loss: 0.452670\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019858; batch adversarial loss: 0.427832\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023722; batch adversarial loss: 0.437816\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029157; batch adversarial loss: 0.437502\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025499; batch adversarial loss: 0.366375\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034820; batch adversarial loss: 0.385224\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016217; batch adversarial loss: 0.469937\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025040; batch adversarial loss: 0.472831\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048241; batch adversarial loss: 0.486223\n",
      "epoch 132; iter: 0; batch classifier loss: 0.080954; batch adversarial loss: 0.468318\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014865; batch adversarial loss: 0.490030\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020828; batch adversarial loss: 0.498965\n",
      "epoch 135; iter: 0; batch classifier loss: 0.010429; batch adversarial loss: 0.536207\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031919; batch adversarial loss: 0.349313\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021692; batch adversarial loss: 0.505390\n",
      "epoch 138; iter: 0; batch classifier loss: 0.050735; batch adversarial loss: 0.432391\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015831; batch adversarial loss: 0.434102\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032573; batch adversarial loss: 0.415154\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035920; batch adversarial loss: 0.495930\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013016; batch adversarial loss: 0.404499\n",
      "epoch 143; iter: 0; batch classifier loss: 0.008812; batch adversarial loss: 0.422579\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038904; batch adversarial loss: 0.485135\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038569; batch adversarial loss: 0.477529\n",
      "epoch 146; iter: 0; batch classifier loss: 0.060255; batch adversarial loss: 0.422993\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050096; batch adversarial loss: 0.427702\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035867; batch adversarial loss: 0.452669\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037122; batch adversarial loss: 0.479850\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035469; batch adversarial loss: 0.417254\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034827; batch adversarial loss: 0.504990\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026737; batch adversarial loss: 0.508525\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019827; batch adversarial loss: 0.431914\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029216; batch adversarial loss: 0.471645\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012057; batch adversarial loss: 0.451405\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021748; batch adversarial loss: 0.439175\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019302; batch adversarial loss: 0.380248\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021301; batch adversarial loss: 0.531726\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013790; batch adversarial loss: 0.454076\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030381; batch adversarial loss: 0.503221\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037739; batch adversarial loss: 0.505974\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007944; batch adversarial loss: 0.432477\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036237; batch adversarial loss: 0.543903\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020472; batch adversarial loss: 0.360168\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031390; batch adversarial loss: 0.459311\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020931; batch adversarial loss: 0.508959\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036600; batch adversarial loss: 0.527391\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022598; batch adversarial loss: 0.437813\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009983; batch adversarial loss: 0.375178\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037256; batch adversarial loss: 0.445962\n",
      "epoch 171; iter: 0; batch classifier loss: 0.054919; batch adversarial loss: 0.398965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.014131; batch adversarial loss: 0.475573\n",
      "epoch 173; iter: 0; batch classifier loss: 0.041689; batch adversarial loss: 0.439058\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027877; batch adversarial loss: 0.440200\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015679; batch adversarial loss: 0.468227\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017423; batch adversarial loss: 0.449387\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033868; batch adversarial loss: 0.468092\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007876; batch adversarial loss: 0.420085\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038831; batch adversarial loss: 0.508880\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030790; batch adversarial loss: 0.457514\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037561; batch adversarial loss: 0.485967\n",
      "epoch 182; iter: 0; batch classifier loss: 0.048687; batch adversarial loss: 0.460288\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011516; batch adversarial loss: 0.463939\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022497; batch adversarial loss: 0.531813\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010410; batch adversarial loss: 0.407535\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012676; batch adversarial loss: 0.457893\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010312; batch adversarial loss: 0.496762\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009410; batch adversarial loss: 0.506621\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015565; batch adversarial loss: 0.440053\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015333; batch adversarial loss: 0.559726\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028741; batch adversarial loss: 0.358777\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014739; batch adversarial loss: 0.388728\n",
      "epoch 193; iter: 0; batch classifier loss: 0.036689; batch adversarial loss: 0.543612\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028169; batch adversarial loss: 0.472241\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024219; batch adversarial loss: 0.609785\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031105; batch adversarial loss: 0.437982\n",
      "epoch 197; iter: 0; batch classifier loss: 0.057686; batch adversarial loss: 0.430417\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015288; batch adversarial loss: 0.455156\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020263; batch adversarial loss: 0.497566\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693978; batch adversarial loss: 1.060707\n",
      "epoch 1; iter: 0; batch classifier loss: 0.779459; batch adversarial loss: 1.275874\n",
      "epoch 2; iter: 0; batch classifier loss: 1.226828; batch adversarial loss: 1.409081\n",
      "epoch 3; iter: 0; batch classifier loss: 1.232152; batch adversarial loss: 1.290315\n",
      "epoch 4; iter: 0; batch classifier loss: 1.063476; batch adversarial loss: 1.084799\n",
      "epoch 5; iter: 0; batch classifier loss: 1.179430; batch adversarial loss: 1.024382\n",
      "epoch 6; iter: 0; batch classifier loss: 1.138913; batch adversarial loss: 0.934351\n",
      "epoch 7; iter: 0; batch classifier loss: 1.050627; batch adversarial loss: 0.838720\n",
      "epoch 8; iter: 0; batch classifier loss: 1.127501; batch adversarial loss: 0.785035\n",
      "epoch 9; iter: 0; batch classifier loss: 0.823326; batch adversarial loss: 0.725522\n",
      "epoch 10; iter: 0; batch classifier loss: 0.884407; batch adversarial loss: 0.666219\n",
      "epoch 11; iter: 0; batch classifier loss: 0.758593; batch adversarial loss: 0.597684\n",
      "epoch 12; iter: 0; batch classifier loss: 0.667803; batch adversarial loss: 0.581021\n",
      "epoch 13; iter: 0; batch classifier loss: 0.594360; batch adversarial loss: 0.520347\n",
      "epoch 14; iter: 0; batch classifier loss: 0.449135; batch adversarial loss: 0.529752\n",
      "epoch 15; iter: 0; batch classifier loss: 0.385966; batch adversarial loss: 0.484135\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296801; batch adversarial loss: 0.560485\n",
      "epoch 17; iter: 0; batch classifier loss: 0.293607; batch adversarial loss: 0.517296\n",
      "epoch 18; iter: 0; batch classifier loss: 0.275671; batch adversarial loss: 0.399358\n",
      "epoch 19; iter: 0; batch classifier loss: 0.221764; batch adversarial loss: 0.524067\n",
      "epoch 20; iter: 0; batch classifier loss: 0.254323; batch adversarial loss: 0.450190\n",
      "epoch 21; iter: 0; batch classifier loss: 0.255643; batch adversarial loss: 0.442847\n",
      "epoch 22; iter: 0; batch classifier loss: 0.218517; batch adversarial loss: 0.460588\n",
      "epoch 23; iter: 0; batch classifier loss: 0.208814; batch adversarial loss: 0.511483\n",
      "epoch 24; iter: 0; batch classifier loss: 0.233356; batch adversarial loss: 0.435715\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215246; batch adversarial loss: 0.483830\n",
      "epoch 26; iter: 0; batch classifier loss: 0.226623; batch adversarial loss: 0.448580\n",
      "epoch 27; iter: 0; batch classifier loss: 0.245159; batch adversarial loss: 0.422491\n",
      "epoch 28; iter: 0; batch classifier loss: 0.241274; batch adversarial loss: 0.435535\n",
      "epoch 29; iter: 0; batch classifier loss: 0.206940; batch adversarial loss: 0.464243\n",
      "epoch 30; iter: 0; batch classifier loss: 0.219088; batch adversarial loss: 0.439029\n",
      "epoch 31; iter: 0; batch classifier loss: 0.151466; batch adversarial loss: 0.500399\n",
      "epoch 32; iter: 0; batch classifier loss: 0.202148; batch adversarial loss: 0.414131\n",
      "epoch 33; iter: 0; batch classifier loss: 0.191089; batch adversarial loss: 0.517240\n",
      "epoch 34; iter: 0; batch classifier loss: 0.254030; batch adversarial loss: 0.458678\n",
      "epoch 35; iter: 0; batch classifier loss: 0.176349; batch adversarial loss: 0.476605\n",
      "epoch 36; iter: 0; batch classifier loss: 0.147336; batch adversarial loss: 0.496984\n",
      "epoch 37; iter: 0; batch classifier loss: 0.264871; batch adversarial loss: 0.449344\n",
      "epoch 38; iter: 0; batch classifier loss: 0.228330; batch adversarial loss: 0.402472\n",
      "epoch 39; iter: 0; batch classifier loss: 0.187155; batch adversarial loss: 0.465053\n",
      "epoch 40; iter: 0; batch classifier loss: 0.193141; batch adversarial loss: 0.505455\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146155; batch adversarial loss: 0.382043\n",
      "epoch 42; iter: 0; batch classifier loss: 0.251646; batch adversarial loss: 0.441705\n",
      "epoch 43; iter: 0; batch classifier loss: 0.209585; batch adversarial loss: 0.453070\n",
      "epoch 44; iter: 0; batch classifier loss: 0.149312; batch adversarial loss: 0.460031\n",
      "epoch 45; iter: 0; batch classifier loss: 0.134591; batch adversarial loss: 0.544197\n",
      "epoch 46; iter: 0; batch classifier loss: 0.168085; batch adversarial loss: 0.546937\n",
      "epoch 47; iter: 0; batch classifier loss: 0.139592; batch adversarial loss: 0.441958\n",
      "epoch 48; iter: 0; batch classifier loss: 0.179234; batch adversarial loss: 0.488744\n",
      "epoch 49; iter: 0; batch classifier loss: 0.142130; batch adversarial loss: 0.459909\n",
      "epoch 50; iter: 0; batch classifier loss: 0.127228; batch adversarial loss: 0.590181\n",
      "epoch 51; iter: 0; batch classifier loss: 0.189953; batch adversarial loss: 0.475470\n",
      "epoch 52; iter: 0; batch classifier loss: 0.202743; batch adversarial loss: 0.459128\n",
      "epoch 53; iter: 0; batch classifier loss: 0.149176; batch adversarial loss: 0.469530\n",
      "epoch 54; iter: 0; batch classifier loss: 0.138924; batch adversarial loss: 0.391912\n",
      "epoch 55; iter: 0; batch classifier loss: 0.165938; batch adversarial loss: 0.533806\n",
      "epoch 56; iter: 0; batch classifier loss: 0.169966; batch adversarial loss: 0.507292\n",
      "epoch 57; iter: 0; batch classifier loss: 0.133266; batch adversarial loss: 0.461067\n",
      "epoch 58; iter: 0; batch classifier loss: 0.160254; batch adversarial loss: 0.439868\n",
      "epoch 59; iter: 0; batch classifier loss: 0.119754; batch adversarial loss: 0.424293\n",
      "epoch 60; iter: 0; batch classifier loss: 0.168579; batch adversarial loss: 0.554107\n",
      "epoch 61; iter: 0; batch classifier loss: 0.177060; batch adversarial loss: 0.442072\n",
      "epoch 62; iter: 0; batch classifier loss: 0.161739; batch adversarial loss: 0.435537\n",
      "epoch 63; iter: 0; batch classifier loss: 0.153051; batch adversarial loss: 0.439375\n",
      "epoch 64; iter: 0; batch classifier loss: 0.207433; batch adversarial loss: 0.440724\n",
      "epoch 65; iter: 0; batch classifier loss: 0.153136; batch adversarial loss: 0.525438\n",
      "epoch 66; iter: 0; batch classifier loss: 0.175121; batch adversarial loss: 0.543249\n",
      "epoch 67; iter: 0; batch classifier loss: 0.197325; batch adversarial loss: 0.406444\n",
      "epoch 68; iter: 0; batch classifier loss: 0.133970; batch adversarial loss: 0.492150\n",
      "epoch 69; iter: 0; batch classifier loss: 0.162957; batch adversarial loss: 0.523338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.148010; batch adversarial loss: 0.460145\n",
      "epoch 71; iter: 0; batch classifier loss: 0.196778; batch adversarial loss: 0.360040\n",
      "epoch 72; iter: 0; batch classifier loss: 0.127325; batch adversarial loss: 0.452192\n",
      "epoch 73; iter: 0; batch classifier loss: 0.136508; batch adversarial loss: 0.432973\n",
      "epoch 74; iter: 0; batch classifier loss: 0.224795; batch adversarial loss: 0.405918\n",
      "epoch 75; iter: 0; batch classifier loss: 0.158811; batch adversarial loss: 0.442053\n",
      "epoch 76; iter: 0; batch classifier loss: 0.105387; batch adversarial loss: 0.523085\n",
      "epoch 77; iter: 0; batch classifier loss: 0.149506; batch adversarial loss: 0.508052\n",
      "epoch 78; iter: 0; batch classifier loss: 0.171647; batch adversarial loss: 0.486424\n",
      "epoch 79; iter: 0; batch classifier loss: 0.134673; batch adversarial loss: 0.430241\n",
      "epoch 80; iter: 0; batch classifier loss: 0.166580; batch adversarial loss: 0.491833\n",
      "epoch 81; iter: 0; batch classifier loss: 0.170356; batch adversarial loss: 0.530463\n",
      "epoch 82; iter: 0; batch classifier loss: 0.165222; batch adversarial loss: 0.436398\n",
      "epoch 83; iter: 0; batch classifier loss: 0.167119; batch adversarial loss: 0.520385\n",
      "epoch 84; iter: 0; batch classifier loss: 0.175108; batch adversarial loss: 0.431943\n",
      "epoch 85; iter: 0; batch classifier loss: 0.165017; batch adversarial loss: 0.478055\n",
      "epoch 86; iter: 0; batch classifier loss: 0.192096; batch adversarial loss: 0.396539\n",
      "epoch 87; iter: 0; batch classifier loss: 0.145469; batch adversarial loss: 0.415404\n",
      "epoch 88; iter: 0; batch classifier loss: 0.197113; batch adversarial loss: 0.440904\n",
      "epoch 89; iter: 0; batch classifier loss: 0.156691; batch adversarial loss: 0.469746\n",
      "epoch 90; iter: 0; batch classifier loss: 0.227848; batch adversarial loss: 0.508799\n",
      "epoch 91; iter: 0; batch classifier loss: 0.185010; batch adversarial loss: 0.513229\n",
      "epoch 92; iter: 0; batch classifier loss: 0.142386; batch adversarial loss: 0.398007\n",
      "epoch 93; iter: 0; batch classifier loss: 0.157779; batch adversarial loss: 0.435687\n",
      "epoch 94; iter: 0; batch classifier loss: 0.202209; batch adversarial loss: 0.541428\n",
      "epoch 95; iter: 0; batch classifier loss: 0.173602; batch adversarial loss: 0.504599\n",
      "epoch 96; iter: 0; batch classifier loss: 0.192315; batch adversarial loss: 0.493600\n",
      "epoch 97; iter: 0; batch classifier loss: 0.197351; batch adversarial loss: 0.423930\n",
      "epoch 98; iter: 0; batch classifier loss: 0.165218; batch adversarial loss: 0.434856\n",
      "epoch 99; iter: 0; batch classifier loss: 0.167112; batch adversarial loss: 0.508374\n",
      "epoch 100; iter: 0; batch classifier loss: 0.200840; batch adversarial loss: 0.397680\n",
      "epoch 101; iter: 0; batch classifier loss: 0.141342; batch adversarial loss: 0.497760\n",
      "epoch 102; iter: 0; batch classifier loss: 0.171811; batch adversarial loss: 0.421343\n",
      "epoch 103; iter: 0; batch classifier loss: 0.168227; batch adversarial loss: 0.482501\n",
      "epoch 104; iter: 0; batch classifier loss: 0.220873; batch adversarial loss: 0.385698\n",
      "epoch 105; iter: 0; batch classifier loss: 0.243280; batch adversarial loss: 0.491533\n",
      "epoch 106; iter: 0; batch classifier loss: 0.222312; batch adversarial loss: 0.460166\n",
      "epoch 107; iter: 0; batch classifier loss: 0.166921; batch adversarial loss: 0.433732\n",
      "epoch 108; iter: 0; batch classifier loss: 0.180099; batch adversarial loss: 0.432210\n",
      "epoch 109; iter: 0; batch classifier loss: 0.130206; batch adversarial loss: 0.435302\n",
      "epoch 110; iter: 0; batch classifier loss: 0.207113; batch adversarial loss: 0.456508\n",
      "epoch 111; iter: 0; batch classifier loss: 0.152326; batch adversarial loss: 0.410968\n",
      "epoch 112; iter: 0; batch classifier loss: 0.131506; batch adversarial loss: 0.509671\n",
      "epoch 113; iter: 0; batch classifier loss: 0.211725; batch adversarial loss: 0.421716\n",
      "epoch 114; iter: 0; batch classifier loss: 0.232927; batch adversarial loss: 0.423719\n",
      "epoch 115; iter: 0; batch classifier loss: 0.170545; batch adversarial loss: 0.470871\n",
      "epoch 116; iter: 0; batch classifier loss: 0.232074; batch adversarial loss: 0.348579\n",
      "epoch 117; iter: 0; batch classifier loss: 0.213268; batch adversarial loss: 0.494542\n",
      "epoch 118; iter: 0; batch classifier loss: 0.264746; batch adversarial loss: 0.470366\n",
      "epoch 119; iter: 0; batch classifier loss: 0.177669; batch adversarial loss: 0.507892\n",
      "epoch 120; iter: 0; batch classifier loss: 0.196693; batch adversarial loss: 0.386490\n",
      "epoch 121; iter: 0; batch classifier loss: 0.247494; batch adversarial loss: 0.434705\n",
      "epoch 122; iter: 0; batch classifier loss: 0.179858; batch adversarial loss: 0.567530\n",
      "epoch 123; iter: 0; batch classifier loss: 0.110334; batch adversarial loss: 0.458411\n",
      "epoch 124; iter: 0; batch classifier loss: 0.135222; batch adversarial loss: 0.409630\n",
      "epoch 125; iter: 0; batch classifier loss: 0.086308; batch adversarial loss: 0.433453\n",
      "epoch 126; iter: 0; batch classifier loss: 0.136536; batch adversarial loss: 0.423727\n",
      "epoch 127; iter: 0; batch classifier loss: 0.187171; batch adversarial loss: 0.487002\n",
      "epoch 128; iter: 0; batch classifier loss: 0.201837; batch adversarial loss: 0.420652\n",
      "epoch 129; iter: 0; batch classifier loss: 0.185556; batch adversarial loss: 0.532924\n",
      "epoch 130; iter: 0; batch classifier loss: 0.209687; batch adversarial loss: 0.460767\n",
      "epoch 131; iter: 0; batch classifier loss: 0.261880; batch adversarial loss: 0.374089\n",
      "epoch 132; iter: 0; batch classifier loss: 0.222955; batch adversarial loss: 0.400625\n",
      "epoch 133; iter: 0; batch classifier loss: 0.215373; batch adversarial loss: 0.519060\n",
      "epoch 134; iter: 0; batch classifier loss: 0.213613; batch adversarial loss: 0.385200\n",
      "epoch 135; iter: 0; batch classifier loss: 0.203771; batch adversarial loss: 0.506695\n",
      "epoch 136; iter: 0; batch classifier loss: 0.171331; batch adversarial loss: 0.435580\n",
      "epoch 137; iter: 0; batch classifier loss: 0.193721; batch adversarial loss: 0.458749\n",
      "epoch 138; iter: 0; batch classifier loss: 0.185970; batch adversarial loss: 0.471588\n",
      "epoch 139; iter: 0; batch classifier loss: 0.196095; batch adversarial loss: 0.470835\n",
      "epoch 140; iter: 0; batch classifier loss: 0.175294; batch adversarial loss: 0.434522\n",
      "epoch 141; iter: 0; batch classifier loss: 0.134284; batch adversarial loss: 0.446667\n",
      "epoch 142; iter: 0; batch classifier loss: 0.217752; batch adversarial loss: 0.471251\n",
      "epoch 143; iter: 0; batch classifier loss: 0.219676; batch adversarial loss: 0.483182\n",
      "epoch 144; iter: 0; batch classifier loss: 0.142318; batch adversarial loss: 0.507001\n",
      "epoch 145; iter: 0; batch classifier loss: 0.263912; batch adversarial loss: 0.422658\n",
      "epoch 146; iter: 0; batch classifier loss: 0.190227; batch adversarial loss: 0.373862\n",
      "epoch 147; iter: 0; batch classifier loss: 0.175512; batch adversarial loss: 0.470768\n",
      "epoch 148; iter: 0; batch classifier loss: 0.216035; batch adversarial loss: 0.434794\n",
      "epoch 149; iter: 0; batch classifier loss: 0.071926; batch adversarial loss: 0.482282\n",
      "epoch 150; iter: 0; batch classifier loss: 0.062813; batch adversarial loss: 0.503937\n",
      "epoch 151; iter: 0; batch classifier loss: 0.053841; batch adversarial loss: 0.516770\n",
      "epoch 152; iter: 0; batch classifier loss: 0.061406; batch adversarial loss: 0.494636\n",
      "epoch 153; iter: 0; batch classifier loss: 0.056307; batch adversarial loss: 0.541583\n",
      "epoch 154; iter: 0; batch classifier loss: 0.090501; batch adversarial loss: 0.435313\n",
      "epoch 155; iter: 0; batch classifier loss: 0.104928; batch adversarial loss: 0.445099\n",
      "epoch 156; iter: 0; batch classifier loss: 0.099191; batch adversarial loss: 0.362851\n",
      "epoch 157; iter: 0; batch classifier loss: 0.086118; batch adversarial loss: 0.487564\n",
      "epoch 158; iter: 0; batch classifier loss: 0.064124; batch adversarial loss: 0.501370\n",
      "epoch 159; iter: 0; batch classifier loss: 0.093852; batch adversarial loss: 0.454078\n",
      "epoch 160; iter: 0; batch classifier loss: 0.092668; batch adversarial loss: 0.397524\n",
      "epoch 161; iter: 0; batch classifier loss: 0.113177; batch adversarial loss: 0.476593\n",
      "epoch 162; iter: 0; batch classifier loss: 0.085648; batch adversarial loss: 0.446146\n",
      "epoch 163; iter: 0; batch classifier loss: 0.052064; batch adversarial loss: 0.419961\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036921; batch adversarial loss: 0.486497\n",
      "epoch 165; iter: 0; batch classifier loss: 0.046247; batch adversarial loss: 0.439765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.046265; batch adversarial loss: 0.427629\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042771; batch adversarial loss: 0.413724\n",
      "epoch 168; iter: 0; batch classifier loss: 0.076962; batch adversarial loss: 0.508576\n",
      "epoch 169; iter: 0; batch classifier loss: 0.055379; batch adversarial loss: 0.491436\n",
      "epoch 170; iter: 0; batch classifier loss: 0.092497; batch adversarial loss: 0.373118\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028921; batch adversarial loss: 0.465263\n",
      "epoch 172; iter: 0; batch classifier loss: 0.043299; batch adversarial loss: 0.435451\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042818; batch adversarial loss: 0.536348\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025433; batch adversarial loss: 0.565772\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018669; batch adversarial loss: 0.499546\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029237; batch adversarial loss: 0.546841\n",
      "epoch 177; iter: 0; batch classifier loss: 0.058869; batch adversarial loss: 0.533139\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025885; batch adversarial loss: 0.547180\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035536; batch adversarial loss: 0.539791\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033960; batch adversarial loss: 0.507935\n",
      "epoch 181; iter: 0; batch classifier loss: 0.040672; batch adversarial loss: 0.399840\n",
      "epoch 182; iter: 0; batch classifier loss: 0.069224; batch adversarial loss: 0.471883\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032617; batch adversarial loss: 0.382858\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027040; batch adversarial loss: 0.425130\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020449; batch adversarial loss: 0.497955\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032311; batch adversarial loss: 0.393149\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027414; batch adversarial loss: 0.509811\n",
      "epoch 188; iter: 0; batch classifier loss: 0.047151; batch adversarial loss: 0.339449\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018260; batch adversarial loss: 0.517105\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009819; batch adversarial loss: 0.486343\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037712; batch adversarial loss: 0.492514\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010138; batch adversarial loss: 0.466185\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026266; batch adversarial loss: 0.473316\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026150; batch adversarial loss: 0.383533\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030619; batch adversarial loss: 0.502285\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021646; batch adversarial loss: 0.534510\n",
      "epoch 197; iter: 0; batch classifier loss: 0.047144; batch adversarial loss: 0.405320\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028256; batch adversarial loss: 0.526252\n",
      "epoch 199; iter: 0; batch classifier loss: 0.038587; batch adversarial loss: 0.513946\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717249; batch adversarial loss: 0.727265\n",
      "epoch 1; iter: 0; batch classifier loss: 0.360367; batch adversarial loss: 0.676385\n",
      "epoch 2; iter: 0; batch classifier loss: 0.378424; batch adversarial loss: 0.631991\n",
      "epoch 3; iter: 0; batch classifier loss: 0.359625; batch adversarial loss: 0.617602\n",
      "epoch 4; iter: 0; batch classifier loss: 0.363622; batch adversarial loss: 0.600173\n",
      "epoch 5; iter: 0; batch classifier loss: 0.272918; batch adversarial loss: 0.578540\n",
      "epoch 6; iter: 0; batch classifier loss: 0.366356; batch adversarial loss: 0.560863\n",
      "epoch 7; iter: 0; batch classifier loss: 0.364590; batch adversarial loss: 0.546375\n",
      "epoch 8; iter: 0; batch classifier loss: 0.370400; batch adversarial loss: 0.582215\n",
      "epoch 9; iter: 0; batch classifier loss: 0.438704; batch adversarial loss: 0.513684\n",
      "epoch 10; iter: 0; batch classifier loss: 0.345686; batch adversarial loss: 0.528951\n",
      "epoch 11; iter: 0; batch classifier loss: 0.453890; batch adversarial loss: 0.521923\n",
      "epoch 12; iter: 0; batch classifier loss: 0.459797; batch adversarial loss: 0.560758\n",
      "epoch 13; iter: 0; batch classifier loss: 0.370806; batch adversarial loss: 0.487467\n",
      "epoch 14; iter: 0; batch classifier loss: 0.345992; batch adversarial loss: 0.503546\n",
      "epoch 15; iter: 0; batch classifier loss: 0.408066; batch adversarial loss: 0.480929\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334708; batch adversarial loss: 0.461804\n",
      "epoch 17; iter: 0; batch classifier loss: 0.359899; batch adversarial loss: 0.467416\n",
      "epoch 18; iter: 0; batch classifier loss: 0.385546; batch adversarial loss: 0.487272\n",
      "epoch 19; iter: 0; batch classifier loss: 0.344435; batch adversarial loss: 0.451638\n",
      "epoch 20; iter: 0; batch classifier loss: 0.338924; batch adversarial loss: 0.515850\n",
      "epoch 21; iter: 0; batch classifier loss: 0.383441; batch adversarial loss: 0.469439\n",
      "epoch 22; iter: 0; batch classifier loss: 0.294188; batch adversarial loss: 0.516824\n",
      "epoch 23; iter: 0; batch classifier loss: 0.192201; batch adversarial loss: 0.513955\n",
      "epoch 24; iter: 0; batch classifier loss: 0.275670; batch adversarial loss: 0.510653\n",
      "epoch 25; iter: 0; batch classifier loss: 0.257928; batch adversarial loss: 0.452021\n",
      "epoch 26; iter: 0; batch classifier loss: 0.268323; batch adversarial loss: 0.416353\n",
      "epoch 27; iter: 0; batch classifier loss: 0.274200; batch adversarial loss: 0.498455\n",
      "epoch 28; iter: 0; batch classifier loss: 0.211404; batch adversarial loss: 0.523492\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209392; batch adversarial loss: 0.416127\n",
      "epoch 30; iter: 0; batch classifier loss: 0.244414; batch adversarial loss: 0.495238\n",
      "epoch 31; iter: 0; batch classifier loss: 0.284837; batch adversarial loss: 0.553671\n",
      "epoch 32; iter: 0; batch classifier loss: 0.270443; batch adversarial loss: 0.485333\n",
      "epoch 33; iter: 0; batch classifier loss: 0.250534; batch adversarial loss: 0.500690\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233232; batch adversarial loss: 0.476945\n",
      "epoch 35; iter: 0; batch classifier loss: 0.232741; batch adversarial loss: 0.440431\n",
      "epoch 36; iter: 0; batch classifier loss: 0.149970; batch adversarial loss: 0.476617\n",
      "epoch 37; iter: 0; batch classifier loss: 0.210002; batch adversarial loss: 0.525330\n",
      "epoch 38; iter: 0; batch classifier loss: 0.271058; batch adversarial loss: 0.437150\n",
      "epoch 39; iter: 0; batch classifier loss: 0.260718; batch adversarial loss: 0.435681\n",
      "epoch 40; iter: 0; batch classifier loss: 0.249932; batch adversarial loss: 0.407030\n",
      "epoch 41; iter: 0; batch classifier loss: 0.225457; batch adversarial loss: 0.518764\n",
      "epoch 42; iter: 0; batch classifier loss: 0.206058; batch adversarial loss: 0.512322\n",
      "epoch 43; iter: 0; batch classifier loss: 0.274761; batch adversarial loss: 0.425433\n",
      "epoch 44; iter: 0; batch classifier loss: 0.265302; batch adversarial loss: 0.436253\n",
      "epoch 45; iter: 0; batch classifier loss: 0.292844; batch adversarial loss: 0.470433\n",
      "epoch 46; iter: 0; batch classifier loss: 0.207814; batch adversarial loss: 0.518537\n",
      "epoch 47; iter: 0; batch classifier loss: 0.199727; batch adversarial loss: 0.542011\n",
      "epoch 48; iter: 0; batch classifier loss: 0.289451; batch adversarial loss: 0.469783\n",
      "epoch 49; iter: 0; batch classifier loss: 0.156563; batch adversarial loss: 0.505603\n",
      "epoch 50; iter: 0; batch classifier loss: 0.106377; batch adversarial loss: 0.482200\n",
      "epoch 51; iter: 0; batch classifier loss: 0.247913; batch adversarial loss: 0.519350\n",
      "epoch 52; iter: 0; batch classifier loss: 0.118090; batch adversarial loss: 0.375234\n",
      "epoch 53; iter: 0; batch classifier loss: 0.186082; batch adversarial loss: 0.363703\n",
      "epoch 54; iter: 0; batch classifier loss: 0.280587; batch adversarial loss: 0.422172\n",
      "epoch 55; iter: 0; batch classifier loss: 0.128621; batch adversarial loss: 0.518647\n",
      "epoch 56; iter: 0; batch classifier loss: 0.135117; batch adversarial loss: 0.373043\n",
      "epoch 57; iter: 0; batch classifier loss: 0.216300; batch adversarial loss: 0.450422\n",
      "epoch 58; iter: 0; batch classifier loss: 0.141339; batch adversarial loss: 0.373296\n",
      "epoch 59; iter: 0; batch classifier loss: 0.146731; batch adversarial loss: 0.570333\n",
      "epoch 60; iter: 0; batch classifier loss: 0.254995; batch adversarial loss: 0.493840\n",
      "epoch 61; iter: 0; batch classifier loss: 0.213091; batch adversarial loss: 0.434553\n",
      "epoch 62; iter: 0; batch classifier loss: 0.119310; batch adversarial loss: 0.471689\n",
      "epoch 63; iter: 0; batch classifier loss: 0.137915; batch adversarial loss: 0.420068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.249338; batch adversarial loss: 0.494750\n",
      "epoch 65; iter: 0; batch classifier loss: 0.144598; batch adversarial loss: 0.507869\n",
      "epoch 66; iter: 0; batch classifier loss: 0.160827; batch adversarial loss: 0.421933\n",
      "epoch 67; iter: 0; batch classifier loss: 0.255647; batch adversarial loss: 0.456619\n",
      "epoch 68; iter: 0; batch classifier loss: 0.200633; batch adversarial loss: 0.507252\n",
      "epoch 69; iter: 0; batch classifier loss: 0.101735; batch adversarial loss: 0.422381\n",
      "epoch 70; iter: 0; batch classifier loss: 0.171091; batch adversarial loss: 0.544121\n",
      "epoch 71; iter: 0; batch classifier loss: 0.205891; batch adversarial loss: 0.471264\n",
      "epoch 72; iter: 0; batch classifier loss: 0.150666; batch adversarial loss: 0.396883\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083557; batch adversarial loss: 0.583254\n",
      "epoch 74; iter: 0; batch classifier loss: 0.072169; batch adversarial loss: 0.461551\n",
      "epoch 75; iter: 0; batch classifier loss: 0.190470; batch adversarial loss: 0.482934\n",
      "epoch 76; iter: 0; batch classifier loss: 0.142857; batch adversarial loss: 0.457484\n",
      "epoch 77; iter: 0; batch classifier loss: 0.204818; batch adversarial loss: 0.408002\n",
      "epoch 78; iter: 0; batch classifier loss: 0.169999; batch adversarial loss: 0.505157\n",
      "epoch 79; iter: 0; batch classifier loss: 0.110274; batch adversarial loss: 0.420546\n",
      "epoch 80; iter: 0; batch classifier loss: 0.116405; batch adversarial loss: 0.421933\n",
      "epoch 81; iter: 0; batch classifier loss: 0.201093; batch adversarial loss: 0.433214\n",
      "epoch 82; iter: 0; batch classifier loss: 0.105695; batch adversarial loss: 0.589068\n",
      "epoch 83; iter: 0; batch classifier loss: 0.218555; batch adversarial loss: 0.531794\n",
      "epoch 84; iter: 0; batch classifier loss: 0.187282; batch adversarial loss: 0.485457\n",
      "epoch 85; iter: 0; batch classifier loss: 0.125795; batch adversarial loss: 0.385347\n",
      "epoch 86; iter: 0; batch classifier loss: 0.155558; batch adversarial loss: 0.569644\n",
      "epoch 87; iter: 0; batch classifier loss: 0.139916; batch adversarial loss: 0.482992\n",
      "epoch 88; iter: 0; batch classifier loss: 0.181681; batch adversarial loss: 0.482047\n",
      "epoch 89; iter: 0; batch classifier loss: 0.170910; batch adversarial loss: 0.510038\n",
      "epoch 90; iter: 0; batch classifier loss: 0.151304; batch adversarial loss: 0.431454\n",
      "epoch 91; iter: 0; batch classifier loss: 0.118506; batch adversarial loss: 0.412236\n",
      "epoch 92; iter: 0; batch classifier loss: 0.166292; batch adversarial loss: 0.424143\n",
      "epoch 93; iter: 0; batch classifier loss: 0.126446; batch adversarial loss: 0.420786\n",
      "epoch 94; iter: 0; batch classifier loss: 0.118387; batch adversarial loss: 0.399062\n",
      "epoch 95; iter: 0; batch classifier loss: 0.104599; batch adversarial loss: 0.357531\n",
      "epoch 96; iter: 0; batch classifier loss: 0.140473; batch adversarial loss: 0.397736\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081537; batch adversarial loss: 0.425959\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079462; batch adversarial loss: 0.480512\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062686; batch adversarial loss: 0.496710\n",
      "epoch 100; iter: 0; batch classifier loss: 0.100001; batch adversarial loss: 0.501564\n",
      "epoch 101; iter: 0; batch classifier loss: 0.076523; batch adversarial loss: 0.385082\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038511; batch adversarial loss: 0.426486\n",
      "epoch 103; iter: 0; batch classifier loss: 0.089027; batch adversarial loss: 0.461557\n",
      "epoch 104; iter: 0; batch classifier loss: 0.078764; batch adversarial loss: 0.545988\n",
      "epoch 105; iter: 0; batch classifier loss: 0.068323; batch adversarial loss: 0.457410\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052556; batch adversarial loss: 0.531115\n",
      "epoch 107; iter: 0; batch classifier loss: 0.078395; batch adversarial loss: 0.512484\n",
      "epoch 108; iter: 0; batch classifier loss: 0.081708; batch adversarial loss: 0.444982\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036104; batch adversarial loss: 0.484569\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031531; batch adversarial loss: 0.471806\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037327; batch adversarial loss: 0.412819\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057666; batch adversarial loss: 0.420133\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035651; batch adversarial loss: 0.425906\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027325; batch adversarial loss: 0.416049\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037333; batch adversarial loss: 0.475870\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052738; batch adversarial loss: 0.451682\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040995; batch adversarial loss: 0.485146\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026658; batch adversarial loss: 0.408610\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031752; batch adversarial loss: 0.457743\n",
      "epoch 120; iter: 0; batch classifier loss: 0.070417; batch adversarial loss: 0.372761\n",
      "epoch 121; iter: 0; batch classifier loss: 0.064578; batch adversarial loss: 0.493173\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037021; batch adversarial loss: 0.416576\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047581; batch adversarial loss: 0.421035\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025319; batch adversarial loss: 0.478549\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043050; batch adversarial loss: 0.387664\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055699; batch adversarial loss: 0.378814\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050998; batch adversarial loss: 0.430948\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027633; batch adversarial loss: 0.479877\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059922; batch adversarial loss: 0.373913\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029604; batch adversarial loss: 0.405848\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046643; batch adversarial loss: 0.421693\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022500; batch adversarial loss: 0.529423\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034452; batch adversarial loss: 0.373644\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048600; batch adversarial loss: 0.486823\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020616; batch adversarial loss: 0.492814\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017254; batch adversarial loss: 0.491627\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020007; batch adversarial loss: 0.404146\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030657; batch adversarial loss: 0.430117\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031916; batch adversarial loss: 0.440077\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019381; batch adversarial loss: 0.448876\n",
      "epoch 141; iter: 0; batch classifier loss: 0.015648; batch adversarial loss: 0.386919\n",
      "epoch 142; iter: 0; batch classifier loss: 0.056421; batch adversarial loss: 0.481096\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031611; batch adversarial loss: 0.444666\n",
      "epoch 144; iter: 0; batch classifier loss: 0.011417; batch adversarial loss: 0.420274\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042731; batch adversarial loss: 0.468067\n",
      "epoch 146; iter: 0; batch classifier loss: 0.014066; batch adversarial loss: 0.480850\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029482; batch adversarial loss: 0.443905\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027636; batch adversarial loss: 0.496118\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024461; batch adversarial loss: 0.477616\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016611; batch adversarial loss: 0.507437\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022044; batch adversarial loss: 0.472664\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024383; batch adversarial loss: 0.405464\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036565; batch adversarial loss: 0.441073\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023676; batch adversarial loss: 0.480843\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029850; batch adversarial loss: 0.327310\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017991; batch adversarial loss: 0.514230\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006680; batch adversarial loss: 0.446673\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025355; batch adversarial loss: 0.446608\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018311; batch adversarial loss: 0.484807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.016889; batch adversarial loss: 0.454577\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033066; batch adversarial loss: 0.425243\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032485; batch adversarial loss: 0.437365\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012952; batch adversarial loss: 0.448347\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009009; batch adversarial loss: 0.504441\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013025; batch adversarial loss: 0.475553\n",
      "epoch 166; iter: 0; batch classifier loss: 0.006443; batch adversarial loss: 0.524634\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016751; batch adversarial loss: 0.467149\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026624; batch adversarial loss: 0.404216\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016976; batch adversarial loss: 0.336491\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030629; batch adversarial loss: 0.426435\n",
      "epoch 171; iter: 0; batch classifier loss: 0.037914; batch adversarial loss: 0.387999\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034574; batch adversarial loss: 0.452180\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015959; batch adversarial loss: 0.397315\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024989; batch adversarial loss: 0.493432\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032694; batch adversarial loss: 0.362630\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015785; batch adversarial loss: 0.391341\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006110; batch adversarial loss: 0.402166\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018007; batch adversarial loss: 0.433765\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033202; batch adversarial loss: 0.422751\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012472; batch adversarial loss: 0.507015\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021718; batch adversarial loss: 0.497382\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016864; batch adversarial loss: 0.437031\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017026; batch adversarial loss: 0.460704\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010230; batch adversarial loss: 0.459209\n",
      "epoch 185; iter: 0; batch classifier loss: 0.003341; batch adversarial loss: 0.402479\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024868; batch adversarial loss: 0.335917\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017902; batch adversarial loss: 0.395669\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015648; batch adversarial loss: 0.379432\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019406; batch adversarial loss: 0.474457\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016874; batch adversarial loss: 0.553379\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018471; batch adversarial loss: 0.393587\n",
      "epoch 192; iter: 0; batch classifier loss: 0.003080; batch adversarial loss: 0.450764\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026879; batch adversarial loss: 0.446830\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008910; batch adversarial loss: 0.413422\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012927; batch adversarial loss: 0.449987\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018788; batch adversarial loss: 0.339505\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007349; batch adversarial loss: 0.507385\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011365; batch adversarial loss: 0.464226\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016523; batch adversarial loss: 0.506713\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718279; batch adversarial loss: 0.491904\n",
      "epoch 1; iter: 0; batch classifier loss: 0.384526; batch adversarial loss: 0.570922\n",
      "epoch 2; iter: 0; batch classifier loss: 0.393139; batch adversarial loss: 0.576333\n",
      "epoch 3; iter: 0; batch classifier loss: 0.345750; batch adversarial loss: 0.618172\n",
      "epoch 4; iter: 0; batch classifier loss: 0.378125; batch adversarial loss: 0.565738\n",
      "epoch 5; iter: 0; batch classifier loss: 0.420901; batch adversarial loss: 0.564391\n",
      "epoch 6; iter: 0; batch classifier loss: 0.396115; batch adversarial loss: 0.674849\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338909; batch adversarial loss: 0.663637\n",
      "epoch 8; iter: 0; batch classifier loss: 0.474152; batch adversarial loss: 0.566834\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571772; batch adversarial loss: 0.579124\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550533; batch adversarial loss: 0.600605\n",
      "epoch 11; iter: 0; batch classifier loss: 0.456328; batch adversarial loss: 0.517770\n",
      "epoch 12; iter: 0; batch classifier loss: 0.380644; batch adversarial loss: 0.542439\n",
      "epoch 13; iter: 0; batch classifier loss: 0.326416; batch adversarial loss: 0.488602\n",
      "epoch 14; iter: 0; batch classifier loss: 0.340686; batch adversarial loss: 0.556641\n",
      "epoch 15; iter: 0; batch classifier loss: 0.277960; batch adversarial loss: 0.454640\n",
      "epoch 16; iter: 0; batch classifier loss: 0.214623; batch adversarial loss: 0.511919\n",
      "epoch 17; iter: 0; batch classifier loss: 0.228360; batch adversarial loss: 0.443456\n",
      "epoch 18; iter: 0; batch classifier loss: 0.172513; batch adversarial loss: 0.486100\n",
      "epoch 19; iter: 0; batch classifier loss: 0.258081; batch adversarial loss: 0.503081\n",
      "epoch 20; iter: 0; batch classifier loss: 0.267338; batch adversarial loss: 0.433362\n",
      "epoch 21; iter: 0; batch classifier loss: 0.171480; batch adversarial loss: 0.446828\n",
      "epoch 22; iter: 0; batch classifier loss: 0.166464; batch adversarial loss: 0.484916\n",
      "epoch 23; iter: 0; batch classifier loss: 0.238263; batch adversarial loss: 0.360301\n",
      "epoch 24; iter: 0; batch classifier loss: 0.160261; batch adversarial loss: 0.443137\n",
      "epoch 25; iter: 0; batch classifier loss: 0.194858; batch adversarial loss: 0.446856\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187000; batch adversarial loss: 0.566673\n",
      "epoch 27; iter: 0; batch classifier loss: 0.132891; batch adversarial loss: 0.481042\n",
      "epoch 28; iter: 0; batch classifier loss: 0.155439; batch adversarial loss: 0.392004\n",
      "epoch 29; iter: 0; batch classifier loss: 0.124162; batch adversarial loss: 0.420204\n",
      "epoch 30; iter: 0; batch classifier loss: 0.137657; batch adversarial loss: 0.516897\n",
      "epoch 31; iter: 0; batch classifier loss: 0.186930; batch adversarial loss: 0.411927\n",
      "epoch 32; iter: 0; batch classifier loss: 0.183339; batch adversarial loss: 0.615570\n",
      "epoch 33; iter: 0; batch classifier loss: 0.161788; batch adversarial loss: 0.448608\n",
      "epoch 34; iter: 0; batch classifier loss: 0.151743; batch adversarial loss: 0.471925\n",
      "epoch 35; iter: 0; batch classifier loss: 0.167083; batch adversarial loss: 0.449797\n",
      "epoch 36; iter: 0; batch classifier loss: 0.113197; batch adversarial loss: 0.491712\n",
      "epoch 37; iter: 0; batch classifier loss: 0.158474; batch adversarial loss: 0.480061\n",
      "epoch 38; iter: 0; batch classifier loss: 0.143801; batch adversarial loss: 0.446646\n",
      "epoch 39; iter: 0; batch classifier loss: 0.133612; batch adversarial loss: 0.397002\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154189; batch adversarial loss: 0.466726\n",
      "epoch 41; iter: 0; batch classifier loss: 0.107044; batch adversarial loss: 0.453156\n",
      "epoch 42; iter: 0; batch classifier loss: 0.155696; batch adversarial loss: 0.428532\n",
      "epoch 43; iter: 0; batch classifier loss: 0.170260; batch adversarial loss: 0.459106\n",
      "epoch 44; iter: 0; batch classifier loss: 0.187457; batch adversarial loss: 0.364417\n",
      "epoch 45; iter: 0; batch classifier loss: 0.168216; batch adversarial loss: 0.378391\n",
      "epoch 46; iter: 0; batch classifier loss: 0.132713; batch adversarial loss: 0.441789\n",
      "epoch 47; iter: 0; batch classifier loss: 0.143500; batch adversarial loss: 0.338989\n",
      "epoch 48; iter: 0; batch classifier loss: 0.069089; batch adversarial loss: 0.388960\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119165; batch adversarial loss: 0.405617\n",
      "epoch 50; iter: 0; batch classifier loss: 0.079897; batch adversarial loss: 0.420787\n",
      "epoch 51; iter: 0; batch classifier loss: 0.101882; batch adversarial loss: 0.407071\n",
      "epoch 52; iter: 0; batch classifier loss: 0.171943; batch adversarial loss: 0.425157\n",
      "epoch 53; iter: 0; batch classifier loss: 0.123315; batch adversarial loss: 0.421364\n",
      "epoch 54; iter: 0; batch classifier loss: 0.131238; batch adversarial loss: 0.421645\n",
      "epoch 55; iter: 0; batch classifier loss: 0.146704; batch adversarial loss: 0.510570\n",
      "epoch 56; iter: 0; batch classifier loss: 0.189320; batch adversarial loss: 0.537224\n",
      "epoch 57; iter: 0; batch classifier loss: 0.137740; batch adversarial loss: 0.492686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.078833; batch adversarial loss: 0.526551\n",
      "epoch 59; iter: 0; batch classifier loss: 0.148799; batch adversarial loss: 0.433224\n",
      "epoch 60; iter: 0; batch classifier loss: 0.145279; batch adversarial loss: 0.546485\n",
      "epoch 61; iter: 0; batch classifier loss: 0.115711; batch adversarial loss: 0.486965\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104731; batch adversarial loss: 0.427841\n",
      "epoch 63; iter: 0; batch classifier loss: 0.122987; batch adversarial loss: 0.436202\n",
      "epoch 64; iter: 0; batch classifier loss: 0.160443; batch adversarial loss: 0.543009\n",
      "epoch 65; iter: 0; batch classifier loss: 0.127366; batch adversarial loss: 0.516736\n",
      "epoch 66; iter: 0; batch classifier loss: 0.151444; batch adversarial loss: 0.436543\n",
      "epoch 67; iter: 0; batch classifier loss: 0.121183; batch adversarial loss: 0.409648\n",
      "epoch 68; iter: 0; batch classifier loss: 0.138535; batch adversarial loss: 0.435259\n",
      "epoch 69; iter: 0; batch classifier loss: 0.111903; batch adversarial loss: 0.500632\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110498; batch adversarial loss: 0.418938\n",
      "epoch 71; iter: 0; batch classifier loss: 0.122415; batch adversarial loss: 0.419207\n",
      "epoch 72; iter: 0; batch classifier loss: 0.167553; batch adversarial loss: 0.411510\n",
      "epoch 73; iter: 0; batch classifier loss: 0.117667; batch adversarial loss: 0.441275\n",
      "epoch 74; iter: 0; batch classifier loss: 0.144726; batch adversarial loss: 0.456090\n",
      "epoch 75; iter: 0; batch classifier loss: 0.128832; batch adversarial loss: 0.522914\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076695; batch adversarial loss: 0.530717\n",
      "epoch 77; iter: 0; batch classifier loss: 0.070941; batch adversarial loss: 0.483388\n",
      "epoch 78; iter: 0; batch classifier loss: 0.129684; batch adversarial loss: 0.438358\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080018; batch adversarial loss: 0.501901\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067006; batch adversarial loss: 0.481375\n",
      "epoch 81; iter: 0; batch classifier loss: 0.097831; batch adversarial loss: 0.429681\n",
      "epoch 82; iter: 0; batch classifier loss: 0.086195; batch adversarial loss: 0.386074\n",
      "epoch 83; iter: 0; batch classifier loss: 0.130061; batch adversarial loss: 0.500372\n",
      "epoch 84; iter: 0; batch classifier loss: 0.088428; batch adversarial loss: 0.472708\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088627; batch adversarial loss: 0.483517\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069559; batch adversarial loss: 0.524862\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076023; batch adversarial loss: 0.456770\n",
      "epoch 88; iter: 0; batch classifier loss: 0.115774; batch adversarial loss: 0.399220\n",
      "epoch 89; iter: 0; batch classifier loss: 0.045288; batch adversarial loss: 0.436933\n",
      "epoch 90; iter: 0; batch classifier loss: 0.091532; batch adversarial loss: 0.368382\n",
      "epoch 91; iter: 0; batch classifier loss: 0.096153; batch adversarial loss: 0.477136\n",
      "epoch 92; iter: 0; batch classifier loss: 0.092522; batch adversarial loss: 0.376791\n",
      "epoch 93; iter: 0; batch classifier loss: 0.081847; batch adversarial loss: 0.491651\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061425; batch adversarial loss: 0.474995\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068958; batch adversarial loss: 0.493266\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055403; batch adversarial loss: 0.517648\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081057; batch adversarial loss: 0.338535\n",
      "epoch 98; iter: 0; batch classifier loss: 0.085919; batch adversarial loss: 0.577460\n",
      "epoch 99; iter: 0; batch classifier loss: 0.080574; batch adversarial loss: 0.501943\n",
      "epoch 100; iter: 0; batch classifier loss: 0.069157; batch adversarial loss: 0.569398\n",
      "epoch 101; iter: 0; batch classifier loss: 0.080392; batch adversarial loss: 0.452674\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055907; batch adversarial loss: 0.546604\n",
      "epoch 103; iter: 0; batch classifier loss: 0.067360; batch adversarial loss: 0.477109\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036533; batch adversarial loss: 0.358764\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044636; batch adversarial loss: 0.377596\n",
      "epoch 106; iter: 0; batch classifier loss: 0.066956; batch adversarial loss: 0.440406\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034274; batch adversarial loss: 0.494175\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059228; batch adversarial loss: 0.465973\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057351; batch adversarial loss: 0.461171\n",
      "epoch 110; iter: 0; batch classifier loss: 0.074485; batch adversarial loss: 0.420222\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064785; batch adversarial loss: 0.472832\n",
      "epoch 112; iter: 0; batch classifier loss: 0.077155; batch adversarial loss: 0.433193\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058881; batch adversarial loss: 0.443615\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057297; batch adversarial loss: 0.380645\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029535; batch adversarial loss: 0.605485\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058297; batch adversarial loss: 0.444977\n",
      "epoch 117; iter: 0; batch classifier loss: 0.092066; batch adversarial loss: 0.419553\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035019; batch adversarial loss: 0.434189\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054311; batch adversarial loss: 0.478003\n",
      "epoch 120; iter: 0; batch classifier loss: 0.052590; batch adversarial loss: 0.479153\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025818; batch adversarial loss: 0.436165\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045193; batch adversarial loss: 0.464595\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030060; batch adversarial loss: 0.473583\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029779; batch adversarial loss: 0.441370\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048606; batch adversarial loss: 0.344702\n",
      "epoch 126; iter: 0; batch classifier loss: 0.015892; batch adversarial loss: 0.420325\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023022; batch adversarial loss: 0.523868\n",
      "epoch 128; iter: 0; batch classifier loss: 0.057015; batch adversarial loss: 0.473144\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031882; batch adversarial loss: 0.472918\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025542; batch adversarial loss: 0.376741\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028208; batch adversarial loss: 0.497102\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053341; batch adversarial loss: 0.436349\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032090; batch adversarial loss: 0.451648\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027797; batch adversarial loss: 0.464241\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023039; batch adversarial loss: 0.413252\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027295; batch adversarial loss: 0.437718\n",
      "epoch 137; iter: 0; batch classifier loss: 0.056524; batch adversarial loss: 0.498004\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026029; batch adversarial loss: 0.526168\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033409; batch adversarial loss: 0.404935\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017014; batch adversarial loss: 0.437196\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031123; batch adversarial loss: 0.394505\n",
      "epoch 142; iter: 0; batch classifier loss: 0.052832; batch adversarial loss: 0.436641\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019769; batch adversarial loss: 0.330115\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012821; batch adversarial loss: 0.436345\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021580; batch adversarial loss: 0.462126\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021639; batch adversarial loss: 0.387910\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017364; batch adversarial loss: 0.594674\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012555; batch adversarial loss: 0.479615\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014702; batch adversarial loss: 0.408572\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015739; batch adversarial loss: 0.393319\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024523; batch adversarial loss: 0.461061\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013273; batch adversarial loss: 0.439977\n",
      "epoch 153; iter: 0; batch classifier loss: 0.006201; batch adversarial loss: 0.489641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.018313; batch adversarial loss: 0.407761\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032200; batch adversarial loss: 0.365305\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021058; batch adversarial loss: 0.401246\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013873; batch adversarial loss: 0.506685\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027246; batch adversarial loss: 0.536178\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035958; batch adversarial loss: 0.486195\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012775; batch adversarial loss: 0.437341\n",
      "epoch 161; iter: 0; batch classifier loss: 0.006452; batch adversarial loss: 0.514883\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018097; batch adversarial loss: 0.522745\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009786; batch adversarial loss: 0.552983\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033419; batch adversarial loss: 0.497029\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018412; batch adversarial loss: 0.404635\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012984; batch adversarial loss: 0.379301\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032034; batch adversarial loss: 0.401553\n",
      "epoch 168; iter: 0; batch classifier loss: 0.051608; batch adversarial loss: 0.421465\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026018; batch adversarial loss: 0.393795\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033860; batch adversarial loss: 0.480036\n",
      "epoch 171; iter: 0; batch classifier loss: 0.045663; batch adversarial loss: 0.476067\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012375; batch adversarial loss: 0.456758\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012697; batch adversarial loss: 0.493311\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033742; batch adversarial loss: 0.445289\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010242; batch adversarial loss: 0.447348\n",
      "epoch 176; iter: 0; batch classifier loss: 0.006518; batch adversarial loss: 0.482993\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013584; batch adversarial loss: 0.501204\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022855; batch adversarial loss: 0.459935\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021022; batch adversarial loss: 0.415700\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035622; batch adversarial loss: 0.451965\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006890; batch adversarial loss: 0.591681\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019767; batch adversarial loss: 0.536819\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010611; batch adversarial loss: 0.506612\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009098; batch adversarial loss: 0.399870\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024730; batch adversarial loss: 0.471014\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027014; batch adversarial loss: 0.483062\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009416; batch adversarial loss: 0.466710\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007347; batch adversarial loss: 0.461198\n",
      "epoch 189; iter: 0; batch classifier loss: 0.005391; batch adversarial loss: 0.459529\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037433; batch adversarial loss: 0.445414\n",
      "epoch 191; iter: 0; batch classifier loss: 0.052338; batch adversarial loss: 0.476806\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011037; batch adversarial loss: 0.420259\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020205; batch adversarial loss: 0.365788\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023608; batch adversarial loss: 0.391653\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014733; batch adversarial loss: 0.466114\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033548; batch adversarial loss: 0.430631\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010515; batch adversarial loss: 0.508753\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011171; batch adversarial loss: 0.496879\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020003; batch adversarial loss: 0.500239\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693474; batch adversarial loss: 0.569843\n",
      "epoch 1; iter: 0; batch classifier loss: 0.415686; batch adversarial loss: 0.546981\n",
      "epoch 2; iter: 0; batch classifier loss: 0.388965; batch adversarial loss: 0.591155\n",
      "epoch 3; iter: 0; batch classifier loss: 0.337911; batch adversarial loss: 0.631004\n",
      "epoch 4; iter: 0; batch classifier loss: 0.358309; batch adversarial loss: 0.511015\n",
      "epoch 5; iter: 0; batch classifier loss: 0.406728; batch adversarial loss: 0.561093\n",
      "epoch 6; iter: 0; batch classifier loss: 0.264839; batch adversarial loss: 0.568203\n",
      "epoch 7; iter: 0; batch classifier loss: 0.256359; batch adversarial loss: 0.581817\n",
      "epoch 8; iter: 0; batch classifier loss: 0.293473; batch adversarial loss: 0.511652\n",
      "epoch 9; iter: 0; batch classifier loss: 0.373206; batch adversarial loss: 0.514342\n",
      "epoch 10; iter: 0; batch classifier loss: 0.409278; batch adversarial loss: 0.573817\n",
      "epoch 11; iter: 0; batch classifier loss: 0.288984; batch adversarial loss: 0.533916\n",
      "epoch 12; iter: 0; batch classifier loss: 0.299659; batch adversarial loss: 0.513705\n",
      "epoch 13; iter: 0; batch classifier loss: 0.285872; batch adversarial loss: 0.469363\n",
      "epoch 14; iter: 0; batch classifier loss: 0.256276; batch adversarial loss: 0.492656\n",
      "epoch 15; iter: 0; batch classifier loss: 0.290442; batch adversarial loss: 0.430074\n",
      "epoch 16; iter: 0; batch classifier loss: 0.295318; batch adversarial loss: 0.484578\n",
      "epoch 17; iter: 0; batch classifier loss: 0.277395; batch adversarial loss: 0.483830\n",
      "epoch 18; iter: 0; batch classifier loss: 0.244144; batch adversarial loss: 0.461505\n",
      "epoch 19; iter: 0; batch classifier loss: 0.256612; batch adversarial loss: 0.454515\n",
      "epoch 20; iter: 0; batch classifier loss: 0.232254; batch adversarial loss: 0.469761\n",
      "epoch 21; iter: 0; batch classifier loss: 0.209040; batch adversarial loss: 0.502818\n",
      "epoch 22; iter: 0; batch classifier loss: 0.228102; batch adversarial loss: 0.454411\n",
      "epoch 23; iter: 0; batch classifier loss: 0.253746; batch adversarial loss: 0.474211\n",
      "epoch 24; iter: 0; batch classifier loss: 0.221127; batch adversarial loss: 0.462717\n",
      "epoch 25; iter: 0; batch classifier loss: 0.149800; batch adversarial loss: 0.480249\n",
      "epoch 26; iter: 0; batch classifier loss: 0.269589; batch adversarial loss: 0.421963\n",
      "epoch 27; iter: 0; batch classifier loss: 0.224292; batch adversarial loss: 0.444903\n",
      "epoch 28; iter: 0; batch classifier loss: 0.228818; batch adversarial loss: 0.450618\n",
      "epoch 29; iter: 0; batch classifier loss: 0.244292; batch adversarial loss: 0.462192\n",
      "epoch 30; iter: 0; batch classifier loss: 0.250878; batch adversarial loss: 0.442895\n",
      "epoch 31; iter: 0; batch classifier loss: 0.244282; batch adversarial loss: 0.478923\n",
      "epoch 32; iter: 0; batch classifier loss: 0.200954; batch adversarial loss: 0.526540\n",
      "epoch 33; iter: 0; batch classifier loss: 0.209018; batch adversarial loss: 0.489773\n",
      "epoch 34; iter: 0; batch classifier loss: 0.274740; batch adversarial loss: 0.424890\n",
      "epoch 35; iter: 0; batch classifier loss: 0.204466; batch adversarial loss: 0.476711\n",
      "epoch 36; iter: 0; batch classifier loss: 0.170161; batch adversarial loss: 0.495584\n",
      "epoch 37; iter: 0; batch classifier loss: 0.234003; batch adversarial loss: 0.516328\n",
      "epoch 38; iter: 0; batch classifier loss: 0.217682; batch adversarial loss: 0.479185\n",
      "epoch 39; iter: 0; batch classifier loss: 0.250330; batch adversarial loss: 0.429552\n",
      "epoch 40; iter: 0; batch classifier loss: 0.219438; batch adversarial loss: 0.409747\n",
      "epoch 41; iter: 0; batch classifier loss: 0.242418; batch adversarial loss: 0.564439\n",
      "epoch 42; iter: 0; batch classifier loss: 0.270816; batch adversarial loss: 0.475768\n",
      "epoch 43; iter: 0; batch classifier loss: 0.181242; batch adversarial loss: 0.538679\n",
      "epoch 44; iter: 0; batch classifier loss: 0.342254; batch adversarial loss: 0.435942\n",
      "epoch 45; iter: 0; batch classifier loss: 0.306413; batch adversarial loss: 0.380246\n",
      "epoch 46; iter: 0; batch classifier loss: 0.211697; batch adversarial loss: 0.450755\n",
      "epoch 47; iter: 0; batch classifier loss: 0.242760; batch adversarial loss: 0.457084\n",
      "epoch 48; iter: 0; batch classifier loss: 0.262849; batch adversarial loss: 0.533888\n",
      "epoch 49; iter: 0; batch classifier loss: 0.256619; batch adversarial loss: 0.482370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.234149; batch adversarial loss: 0.390549\n",
      "epoch 51; iter: 0; batch classifier loss: 0.232995; batch adversarial loss: 0.472567\n",
      "epoch 52; iter: 0; batch classifier loss: 0.372892; batch adversarial loss: 0.400420\n",
      "epoch 53; iter: 0; batch classifier loss: 0.265930; batch adversarial loss: 0.529887\n",
      "epoch 54; iter: 0; batch classifier loss: 0.091711; batch adversarial loss: 0.422983\n",
      "epoch 55; iter: 0; batch classifier loss: 0.130899; batch adversarial loss: 0.545598\n",
      "epoch 56; iter: 0; batch classifier loss: 0.236417; batch adversarial loss: 0.449943\n",
      "epoch 57; iter: 0; batch classifier loss: 0.206704; batch adversarial loss: 0.447039\n",
      "epoch 58; iter: 0; batch classifier loss: 0.210691; batch adversarial loss: 0.421670\n",
      "epoch 59; iter: 0; batch classifier loss: 0.210771; batch adversarial loss: 0.555545\n",
      "epoch 60; iter: 0; batch classifier loss: 0.131930; batch adversarial loss: 0.351329\n",
      "epoch 61; iter: 0; batch classifier loss: 0.242848; batch adversarial loss: 0.434612\n",
      "epoch 62; iter: 0; batch classifier loss: 0.262649; batch adversarial loss: 0.520167\n",
      "epoch 63; iter: 0; batch classifier loss: 0.136131; batch adversarial loss: 0.494153\n",
      "epoch 64; iter: 0; batch classifier loss: 0.245914; batch adversarial loss: 0.469987\n",
      "epoch 65; iter: 0; batch classifier loss: 0.229508; batch adversarial loss: 0.483117\n",
      "epoch 66; iter: 0; batch classifier loss: 0.137457; batch adversarial loss: 0.360230\n",
      "epoch 67; iter: 0; batch classifier loss: 0.156032; batch adversarial loss: 0.542433\n",
      "epoch 68; iter: 0; batch classifier loss: 0.293277; batch adversarial loss: 0.362588\n",
      "epoch 69; iter: 0; batch classifier loss: 0.172982; batch adversarial loss: 0.493913\n",
      "epoch 70; iter: 0; batch classifier loss: 0.180585; batch adversarial loss: 0.470730\n",
      "epoch 71; iter: 0; batch classifier loss: 0.213934; batch adversarial loss: 0.518987\n",
      "epoch 72; iter: 0; batch classifier loss: 0.210380; batch adversarial loss: 0.494443\n",
      "epoch 73; iter: 0; batch classifier loss: 0.222920; batch adversarial loss: 0.447865\n",
      "epoch 74; iter: 0; batch classifier loss: 0.178147; batch adversarial loss: 0.507402\n",
      "epoch 75; iter: 0; batch classifier loss: 0.288072; batch adversarial loss: 0.423639\n",
      "epoch 76; iter: 0; batch classifier loss: 0.255457; batch adversarial loss: 0.362959\n",
      "epoch 77; iter: 0; batch classifier loss: 0.156505; batch adversarial loss: 0.422874\n",
      "epoch 78; iter: 0; batch classifier loss: 0.106894; batch adversarial loss: 0.420693\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082826; batch adversarial loss: 0.456839\n",
      "epoch 80; iter: 0; batch classifier loss: 0.132094; batch adversarial loss: 0.493806\n",
      "epoch 81; iter: 0; batch classifier loss: 0.267306; batch adversarial loss: 0.521334\n",
      "epoch 82; iter: 0; batch classifier loss: 0.249767; batch adversarial loss: 0.516077\n",
      "epoch 83; iter: 0; batch classifier loss: 0.204097; batch adversarial loss: 0.421196\n",
      "epoch 84; iter: 0; batch classifier loss: 0.146052; batch adversarial loss: 0.470161\n",
      "epoch 85; iter: 0; batch classifier loss: 0.290504; batch adversarial loss: 0.446248\n",
      "epoch 86; iter: 0; batch classifier loss: 0.176751; batch adversarial loss: 0.471045\n",
      "epoch 87; iter: 0; batch classifier loss: 0.258994; batch adversarial loss: 0.483249\n",
      "epoch 88; iter: 0; batch classifier loss: 0.228540; batch adversarial loss: 0.434382\n",
      "epoch 89; iter: 0; batch classifier loss: 0.274277; batch adversarial loss: 0.458355\n",
      "epoch 90; iter: 0; batch classifier loss: 0.122320; batch adversarial loss: 0.435737\n",
      "epoch 91; iter: 0; batch classifier loss: 0.165559; batch adversarial loss: 0.529848\n",
      "epoch 92; iter: 0; batch classifier loss: 0.111600; batch adversarial loss: 0.383675\n",
      "epoch 93; iter: 0; batch classifier loss: 0.189532; batch adversarial loss: 0.508507\n",
      "epoch 94; iter: 0; batch classifier loss: 0.166035; batch adversarial loss: 0.495486\n",
      "epoch 95; iter: 0; batch classifier loss: 0.229334; batch adversarial loss: 0.517670\n",
      "epoch 96; iter: 0; batch classifier loss: 0.134710; batch adversarial loss: 0.410890\n",
      "epoch 97; iter: 0; batch classifier loss: 0.226012; batch adversarial loss: 0.433497\n",
      "epoch 98; iter: 0; batch classifier loss: 0.174002; batch adversarial loss: 0.387420\n",
      "epoch 99; iter: 0; batch classifier loss: 0.222425; batch adversarial loss: 0.446754\n",
      "epoch 100; iter: 0; batch classifier loss: 0.199815; batch adversarial loss: 0.433995\n",
      "epoch 101; iter: 0; batch classifier loss: 0.229872; batch adversarial loss: 0.445605\n",
      "epoch 102; iter: 0; batch classifier loss: 0.213962; batch adversarial loss: 0.422227\n",
      "epoch 103; iter: 0; batch classifier loss: 0.194377; batch adversarial loss: 0.350895\n",
      "epoch 104; iter: 0; batch classifier loss: 0.212096; batch adversarial loss: 0.434562\n",
      "epoch 105; iter: 0; batch classifier loss: 0.238157; batch adversarial loss: 0.471341\n",
      "epoch 106; iter: 0; batch classifier loss: 0.191896; batch adversarial loss: 0.459026\n",
      "epoch 107; iter: 0; batch classifier loss: 0.230227; batch adversarial loss: 0.447903\n",
      "epoch 108; iter: 0; batch classifier loss: 0.190591; batch adversarial loss: 0.375791\n",
      "epoch 109; iter: 0; batch classifier loss: 0.208009; batch adversarial loss: 0.434885\n",
      "epoch 110; iter: 0; batch classifier loss: 0.207782; batch adversarial loss: 0.447235\n",
      "epoch 111; iter: 0; batch classifier loss: 0.199957; batch adversarial loss: 0.495286\n",
      "epoch 112; iter: 0; batch classifier loss: 0.213340; batch adversarial loss: 0.471073\n",
      "epoch 113; iter: 0; batch classifier loss: 0.176410; batch adversarial loss: 0.468082\n",
      "epoch 114; iter: 0; batch classifier loss: 0.180924; batch adversarial loss: 0.508405\n",
      "epoch 115; iter: 0; batch classifier loss: 0.204672; batch adversarial loss: 0.483771\n",
      "epoch 116; iter: 0; batch classifier loss: 0.230002; batch adversarial loss: 0.398252\n",
      "epoch 117; iter: 0; batch classifier loss: 0.128484; batch adversarial loss: 0.470153\n",
      "epoch 118; iter: 0; batch classifier loss: 0.126082; batch adversarial loss: 0.470362\n",
      "epoch 119; iter: 0; batch classifier loss: 0.115211; batch adversarial loss: 0.520620\n",
      "epoch 120; iter: 0; batch classifier loss: 0.113254; batch adversarial loss: 0.446896\n",
      "epoch 121; iter: 0; batch classifier loss: 0.134283; batch adversarial loss: 0.454526\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051276; batch adversarial loss: 0.536891\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055500; batch adversarial loss: 0.411629\n",
      "epoch 124; iter: 0; batch classifier loss: 0.086205; batch adversarial loss: 0.426943\n",
      "epoch 125; iter: 0; batch classifier loss: 0.059870; batch adversarial loss: 0.440712\n",
      "epoch 126; iter: 0; batch classifier loss: 0.084983; batch adversarial loss: 0.393933\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033628; batch adversarial loss: 0.499790\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042260; batch adversarial loss: 0.525156\n",
      "epoch 129; iter: 0; batch classifier loss: 0.111423; batch adversarial loss: 0.392942\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056574; batch adversarial loss: 0.510642\n",
      "epoch 131; iter: 0; batch classifier loss: 0.061464; batch adversarial loss: 0.521352\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030459; batch adversarial loss: 0.360107\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023706; batch adversarial loss: 0.552317\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029860; batch adversarial loss: 0.519114\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029702; batch adversarial loss: 0.460940\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050840; batch adversarial loss: 0.428436\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035390; batch adversarial loss: 0.459024\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024672; batch adversarial loss: 0.536187\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044754; batch adversarial loss: 0.354052\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046567; batch adversarial loss: 0.499741\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040869; batch adversarial loss: 0.348112\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040483; batch adversarial loss: 0.421111\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026543; batch adversarial loss: 0.379392\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048771; batch adversarial loss: 0.402575\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019933; batch adversarial loss: 0.424171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.023791; batch adversarial loss: 0.444518\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024098; batch adversarial loss: 0.296677\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019248; batch adversarial loss: 0.434203\n",
      "epoch 149; iter: 0; batch classifier loss: 0.050042; batch adversarial loss: 0.465880\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011255; batch adversarial loss: 0.457960\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019374; batch adversarial loss: 0.482447\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017886; batch adversarial loss: 0.570751\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032383; batch adversarial loss: 0.447985\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052197; batch adversarial loss: 0.476323\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036282; batch adversarial loss: 0.487424\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040522; batch adversarial loss: 0.554892\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012309; batch adversarial loss: 0.423245\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009867; batch adversarial loss: 0.508878\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027275; batch adversarial loss: 0.496325\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016744; batch adversarial loss: 0.479018\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015663; batch adversarial loss: 0.585182\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015082; batch adversarial loss: 0.428228\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017373; batch adversarial loss: 0.394731\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016848; batch adversarial loss: 0.514375\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041471; batch adversarial loss: 0.512344\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027725; batch adversarial loss: 0.505139\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017471; batch adversarial loss: 0.515305\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024962; batch adversarial loss: 0.459754\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027095; batch adversarial loss: 0.423062\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028275; batch adversarial loss: 0.427730\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038205; batch adversarial loss: 0.499179\n",
      "epoch 172; iter: 0; batch classifier loss: 0.038083; batch adversarial loss: 0.465485\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023075; batch adversarial loss: 0.451215\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020650; batch adversarial loss: 0.397008\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014726; batch adversarial loss: 0.374865\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009951; batch adversarial loss: 0.557045\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029624; batch adversarial loss: 0.554345\n",
      "epoch 178; iter: 0; batch classifier loss: 0.003726; batch adversarial loss: 0.540600\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017793; batch adversarial loss: 0.379519\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011528; batch adversarial loss: 0.372677\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012524; batch adversarial loss: 0.482529\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009152; batch adversarial loss: 0.445173\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032456; batch adversarial loss: 0.352687\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015526; batch adversarial loss: 0.468774\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023350; batch adversarial loss: 0.528958\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009834; batch adversarial loss: 0.374005\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024945; batch adversarial loss: 0.469265\n",
      "epoch 188; iter: 0; batch classifier loss: 0.051512; batch adversarial loss: 0.516024\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031996; batch adversarial loss: 0.381556\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019603; batch adversarial loss: 0.393869\n",
      "epoch 191; iter: 0; batch classifier loss: 0.035056; batch adversarial loss: 0.427107\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024629; batch adversarial loss: 0.452198\n",
      "epoch 193; iter: 0; batch classifier loss: 0.033337; batch adversarial loss: 0.389254\n",
      "epoch 194; iter: 0; batch classifier loss: 0.042713; batch adversarial loss: 0.530085\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006613; batch adversarial loss: 0.433896\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022620; batch adversarial loss: 0.411018\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016515; batch adversarial loss: 0.475160\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014878; batch adversarial loss: 0.492835\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014604; batch adversarial loss: 0.425627\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696664; batch adversarial loss: 0.596747\n",
      "epoch 1; iter: 0; batch classifier loss: 0.371440; batch adversarial loss: 0.622581\n",
      "epoch 2; iter: 0; batch classifier loss: 0.388988; batch adversarial loss: 0.573134\n",
      "epoch 3; iter: 0; batch classifier loss: 0.321323; batch adversarial loss: 0.561051\n",
      "epoch 4; iter: 0; batch classifier loss: 0.270215; batch adversarial loss: 0.559597\n",
      "epoch 5; iter: 0; batch classifier loss: 0.317495; batch adversarial loss: 0.551690\n",
      "epoch 6; iter: 0; batch classifier loss: 0.274069; batch adversarial loss: 0.511270\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306265; batch adversarial loss: 0.495026\n",
      "epoch 8; iter: 0; batch classifier loss: 0.253194; batch adversarial loss: 0.528148\n",
      "epoch 9; iter: 0; batch classifier loss: 0.239200; batch adversarial loss: 0.545427\n",
      "epoch 10; iter: 0; batch classifier loss: 0.254245; batch adversarial loss: 0.528081\n",
      "epoch 11; iter: 0; batch classifier loss: 0.261396; batch adversarial loss: 0.501137\n",
      "epoch 12; iter: 0; batch classifier loss: 0.253483; batch adversarial loss: 0.418670\n",
      "epoch 13; iter: 0; batch classifier loss: 0.229729; batch adversarial loss: 0.550864\n",
      "epoch 14; iter: 0; batch classifier loss: 0.183692; batch adversarial loss: 0.506358\n",
      "epoch 15; iter: 0; batch classifier loss: 0.227351; batch adversarial loss: 0.505571\n",
      "epoch 16; iter: 0; batch classifier loss: 0.256825; batch adversarial loss: 0.483602\n",
      "epoch 17; iter: 0; batch classifier loss: 0.286333; batch adversarial loss: 0.556422\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246318; batch adversarial loss: 0.543509\n",
      "epoch 19; iter: 0; batch classifier loss: 0.295396; batch adversarial loss: 0.490259\n",
      "epoch 20; iter: 0; batch classifier loss: 0.409547; batch adversarial loss: 0.537860\n",
      "epoch 21; iter: 0; batch classifier loss: 0.295453; batch adversarial loss: 0.510984\n",
      "epoch 22; iter: 0; batch classifier loss: 0.459609; batch adversarial loss: 0.491427\n",
      "epoch 23; iter: 0; batch classifier loss: 0.339368; batch adversarial loss: 0.544903\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195083; batch adversarial loss: 0.457541\n",
      "epoch 25; iter: 0; batch classifier loss: 0.158358; batch adversarial loss: 0.434226\n",
      "epoch 26; iter: 0; batch classifier loss: 0.167264; batch adversarial loss: 0.431493\n",
      "epoch 27; iter: 0; batch classifier loss: 0.149884; batch adversarial loss: 0.405322\n",
      "epoch 28; iter: 0; batch classifier loss: 0.146865; batch adversarial loss: 0.493656\n",
      "epoch 29; iter: 0; batch classifier loss: 0.109102; batch adversarial loss: 0.489387\n",
      "epoch 30; iter: 0; batch classifier loss: 0.137696; batch adversarial loss: 0.348441\n",
      "epoch 31; iter: 0; batch classifier loss: 0.146355; batch adversarial loss: 0.460278\n",
      "epoch 32; iter: 0; batch classifier loss: 0.164350; batch adversarial loss: 0.504774\n",
      "epoch 33; iter: 0; batch classifier loss: 0.103014; batch adversarial loss: 0.471452\n",
      "epoch 34; iter: 0; batch classifier loss: 0.157766; batch adversarial loss: 0.453940\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130093; batch adversarial loss: 0.369778\n",
      "epoch 36; iter: 0; batch classifier loss: 0.071108; batch adversarial loss: 0.483299\n",
      "epoch 37; iter: 0; batch classifier loss: 0.159937; batch adversarial loss: 0.385152\n",
      "epoch 38; iter: 0; batch classifier loss: 0.118074; batch adversarial loss: 0.476615\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106215; batch adversarial loss: 0.503604\n",
      "epoch 40; iter: 0; batch classifier loss: 0.123939; batch adversarial loss: 0.504300\n",
      "epoch 41; iter: 0; batch classifier loss: 0.099021; batch adversarial loss: 0.390836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.094069; batch adversarial loss: 0.492312\n",
      "epoch 43; iter: 0; batch classifier loss: 0.113761; batch adversarial loss: 0.428364\n",
      "epoch 44; iter: 0; batch classifier loss: 0.067741; batch adversarial loss: 0.438542\n",
      "epoch 45; iter: 0; batch classifier loss: 0.098643; batch adversarial loss: 0.467367\n",
      "epoch 46; iter: 0; batch classifier loss: 0.152587; batch adversarial loss: 0.489357\n",
      "epoch 47; iter: 0; batch classifier loss: 0.118175; batch adversarial loss: 0.386142\n",
      "epoch 48; iter: 0; batch classifier loss: 0.093733; batch adversarial loss: 0.516877\n",
      "epoch 49; iter: 0; batch classifier loss: 0.112529; batch adversarial loss: 0.392894\n",
      "epoch 50; iter: 0; batch classifier loss: 0.178967; batch adversarial loss: 0.417849\n",
      "epoch 51; iter: 0; batch classifier loss: 0.080399; batch adversarial loss: 0.416448\n",
      "epoch 52; iter: 0; batch classifier loss: 0.051764; batch adversarial loss: 0.471294\n",
      "epoch 53; iter: 0; batch classifier loss: 0.075346; batch adversarial loss: 0.467601\n",
      "epoch 54; iter: 0; batch classifier loss: 0.132884; batch adversarial loss: 0.510202\n",
      "epoch 55; iter: 0; batch classifier loss: 0.066584; batch adversarial loss: 0.522025\n",
      "epoch 56; iter: 0; batch classifier loss: 0.123444; batch adversarial loss: 0.366061\n",
      "epoch 57; iter: 0; batch classifier loss: 0.111638; batch adversarial loss: 0.431894\n",
      "epoch 58; iter: 0; batch classifier loss: 0.067090; batch adversarial loss: 0.453025\n",
      "epoch 59; iter: 0; batch classifier loss: 0.107392; batch adversarial loss: 0.421396\n",
      "epoch 60; iter: 0; batch classifier loss: 0.084780; batch adversarial loss: 0.425375\n",
      "epoch 61; iter: 0; batch classifier loss: 0.117040; batch adversarial loss: 0.497600\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101971; batch adversarial loss: 0.424496\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089964; batch adversarial loss: 0.522863\n",
      "epoch 64; iter: 0; batch classifier loss: 0.074316; batch adversarial loss: 0.442746\n",
      "epoch 65; iter: 0; batch classifier loss: 0.114644; batch adversarial loss: 0.508244\n",
      "epoch 66; iter: 0; batch classifier loss: 0.102042; batch adversarial loss: 0.562432\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069028; batch adversarial loss: 0.414343\n",
      "epoch 68; iter: 0; batch classifier loss: 0.089828; batch adversarial loss: 0.556133\n",
      "epoch 69; iter: 0; batch classifier loss: 0.155926; batch adversarial loss: 0.468047\n",
      "epoch 70; iter: 0; batch classifier loss: 0.069332; batch adversarial loss: 0.543329\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082107; batch adversarial loss: 0.411451\n",
      "epoch 72; iter: 0; batch classifier loss: 0.103386; batch adversarial loss: 0.388589\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076457; batch adversarial loss: 0.449835\n",
      "epoch 74; iter: 0; batch classifier loss: 0.115419; batch adversarial loss: 0.374104\n",
      "epoch 75; iter: 0; batch classifier loss: 0.118945; batch adversarial loss: 0.442565\n",
      "epoch 76; iter: 0; batch classifier loss: 0.071260; batch adversarial loss: 0.364465\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104394; batch adversarial loss: 0.400298\n",
      "epoch 78; iter: 0; batch classifier loss: 0.093350; batch adversarial loss: 0.466173\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075733; batch adversarial loss: 0.445104\n",
      "epoch 80; iter: 0; batch classifier loss: 0.089539; batch adversarial loss: 0.467263\n",
      "epoch 81; iter: 0; batch classifier loss: 0.094060; batch adversarial loss: 0.395293\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075414; batch adversarial loss: 0.447594\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056880; batch adversarial loss: 0.456587\n",
      "epoch 84; iter: 0; batch classifier loss: 0.086461; batch adversarial loss: 0.494260\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073853; batch adversarial loss: 0.518673\n",
      "epoch 86; iter: 0; batch classifier loss: 0.107664; batch adversarial loss: 0.356941\n",
      "epoch 87; iter: 0; batch classifier loss: 0.069240; batch adversarial loss: 0.520471\n",
      "epoch 88; iter: 0; batch classifier loss: 0.168552; batch adversarial loss: 0.455604\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074761; batch adversarial loss: 0.458455\n",
      "epoch 90; iter: 0; batch classifier loss: 0.109498; batch adversarial loss: 0.396323\n",
      "epoch 91; iter: 0; batch classifier loss: 0.093906; batch adversarial loss: 0.504654\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070539; batch adversarial loss: 0.441229\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052796; batch adversarial loss: 0.431169\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083404; batch adversarial loss: 0.439212\n",
      "epoch 95; iter: 0; batch classifier loss: 0.069100; batch adversarial loss: 0.433601\n",
      "epoch 96; iter: 0; batch classifier loss: 0.111730; batch adversarial loss: 0.524999\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061385; batch adversarial loss: 0.442405\n",
      "epoch 98; iter: 0; batch classifier loss: 0.066764; batch adversarial loss: 0.411230\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057338; batch adversarial loss: 0.469464\n",
      "epoch 100; iter: 0; batch classifier loss: 0.113106; batch adversarial loss: 0.480886\n",
      "epoch 101; iter: 0; batch classifier loss: 0.074525; batch adversarial loss: 0.482260\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054385; batch adversarial loss: 0.490707\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054084; batch adversarial loss: 0.466693\n",
      "epoch 104; iter: 0; batch classifier loss: 0.064664; batch adversarial loss: 0.514564\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042028; batch adversarial loss: 0.455421\n",
      "epoch 106; iter: 0; batch classifier loss: 0.127299; batch adversarial loss: 0.425614\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047361; batch adversarial loss: 0.353500\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053318; batch adversarial loss: 0.506614\n",
      "epoch 109; iter: 0; batch classifier loss: 0.063224; batch adversarial loss: 0.459987\n",
      "epoch 110; iter: 0; batch classifier loss: 0.089137; batch adversarial loss: 0.435346\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039487; batch adversarial loss: 0.484500\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051109; batch adversarial loss: 0.399788\n",
      "epoch 113; iter: 0; batch classifier loss: 0.074046; batch adversarial loss: 0.376842\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030961; batch adversarial loss: 0.441022\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070082; batch adversarial loss: 0.449158\n",
      "epoch 116; iter: 0; batch classifier loss: 0.061074; batch adversarial loss: 0.425964\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067251; batch adversarial loss: 0.412460\n",
      "epoch 118; iter: 0; batch classifier loss: 0.065741; batch adversarial loss: 0.422846\n",
      "epoch 119; iter: 0; batch classifier loss: 0.086560; batch adversarial loss: 0.442619\n",
      "epoch 120; iter: 0; batch classifier loss: 0.113395; batch adversarial loss: 0.478170\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043857; batch adversarial loss: 0.330329\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033922; batch adversarial loss: 0.467677\n",
      "epoch 123; iter: 0; batch classifier loss: 0.062727; batch adversarial loss: 0.395467\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050829; batch adversarial loss: 0.477676\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036755; batch adversarial loss: 0.500975\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046092; batch adversarial loss: 0.444200\n",
      "epoch 127; iter: 0; batch classifier loss: 0.070574; batch adversarial loss: 0.385098\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031070; batch adversarial loss: 0.500951\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047860; batch adversarial loss: 0.422383\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033209; batch adversarial loss: 0.459836\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029156; batch adversarial loss: 0.563831\n",
      "epoch 132; iter: 0; batch classifier loss: 0.065449; batch adversarial loss: 0.420311\n",
      "epoch 133; iter: 0; batch classifier loss: 0.077067; batch adversarial loss: 0.429819\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022582; batch adversarial loss: 0.433986\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029291; batch adversarial loss: 0.493581\n",
      "epoch 136; iter: 0; batch classifier loss: 0.058163; batch adversarial loss: 0.385155\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046707; batch adversarial loss: 0.412966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.045041; batch adversarial loss: 0.471163\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023364; batch adversarial loss: 0.504300\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025538; batch adversarial loss: 0.522634\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034800; batch adversarial loss: 0.477061\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023587; batch adversarial loss: 0.430186\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029521; batch adversarial loss: 0.425567\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026606; batch adversarial loss: 0.401633\n",
      "epoch 145; iter: 0; batch classifier loss: 0.064425; batch adversarial loss: 0.403875\n",
      "epoch 146; iter: 0; batch classifier loss: 0.012983; batch adversarial loss: 0.368757\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013472; batch adversarial loss: 0.420692\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025608; batch adversarial loss: 0.449031\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042228; batch adversarial loss: 0.518595\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015045; batch adversarial loss: 0.395026\n",
      "epoch 151; iter: 0; batch classifier loss: 0.051120; batch adversarial loss: 0.491033\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026205; batch adversarial loss: 0.460988\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025704; batch adversarial loss: 0.555248\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019617; batch adversarial loss: 0.459311\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040982; batch adversarial loss: 0.490299\n",
      "epoch 156; iter: 0; batch classifier loss: 0.073470; batch adversarial loss: 0.407716\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023297; batch adversarial loss: 0.466900\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017469; batch adversarial loss: 0.462871\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021638; batch adversarial loss: 0.375053\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013795; batch adversarial loss: 0.449548\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037393; batch adversarial loss: 0.462091\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021338; batch adversarial loss: 0.417561\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024410; batch adversarial loss: 0.425428\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020555; batch adversarial loss: 0.464046\n",
      "epoch 165; iter: 0; batch classifier loss: 0.060885; batch adversarial loss: 0.374904\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028562; batch adversarial loss: 0.437011\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018622; batch adversarial loss: 0.432081\n",
      "epoch 168; iter: 0; batch classifier loss: 0.050583; batch adversarial loss: 0.447524\n",
      "epoch 169; iter: 0; batch classifier loss: 0.003179; batch adversarial loss: 0.427634\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032825; batch adversarial loss: 0.382743\n",
      "epoch 171; iter: 0; batch classifier loss: 0.043560; batch adversarial loss: 0.487234\n",
      "epoch 172; iter: 0; batch classifier loss: 0.037441; batch adversarial loss: 0.430291\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022379; batch adversarial loss: 0.451809\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024542; batch adversarial loss: 0.531663\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023060; batch adversarial loss: 0.508042\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037165; batch adversarial loss: 0.491491\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014275; batch adversarial loss: 0.446451\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032089; batch adversarial loss: 0.509894\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020301; batch adversarial loss: 0.522682\n",
      "epoch 180; iter: 0; batch classifier loss: 0.048972; batch adversarial loss: 0.400121\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026964; batch adversarial loss: 0.438646\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032830; batch adversarial loss: 0.529359\n",
      "epoch 183; iter: 0; batch classifier loss: 0.035094; batch adversarial loss: 0.457144\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011808; batch adversarial loss: 0.431640\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032725; batch adversarial loss: 0.448940\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029140; batch adversarial loss: 0.315007\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019859; batch adversarial loss: 0.358946\n",
      "epoch 188; iter: 0; batch classifier loss: 0.036635; batch adversarial loss: 0.473548\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014978; batch adversarial loss: 0.419176\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037667; batch adversarial loss: 0.459321\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024732; batch adversarial loss: 0.490887\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010119; batch adversarial loss: 0.448540\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005036; batch adversarial loss: 0.496303\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023903; batch adversarial loss: 0.491321\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021545; batch adversarial loss: 0.479305\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015889; batch adversarial loss: 0.533693\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011029; batch adversarial loss: 0.465026\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019840; batch adversarial loss: 0.446404\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026441; batch adversarial loss: 0.461959\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724942; batch adversarial loss: 0.878907\n",
      "epoch 1; iter: 0; batch classifier loss: 0.470264; batch adversarial loss: 0.815318\n",
      "epoch 2; iter: 0; batch classifier loss: 0.585025; batch adversarial loss: 0.817020\n",
      "epoch 3; iter: 0; batch classifier loss: 0.841881; batch adversarial loss: 0.776704\n",
      "epoch 4; iter: 0; batch classifier loss: 0.849759; batch adversarial loss: 0.695685\n",
      "epoch 5; iter: 0; batch classifier loss: 0.868249; batch adversarial loss: 0.639141\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532913; batch adversarial loss: 0.599469\n",
      "epoch 7; iter: 0; batch classifier loss: 0.410514; batch adversarial loss: 0.596293\n",
      "epoch 8; iter: 0; batch classifier loss: 0.442121; batch adversarial loss: 0.552008\n",
      "epoch 9; iter: 0; batch classifier loss: 0.383076; batch adversarial loss: 0.571270\n",
      "epoch 10; iter: 0; batch classifier loss: 0.371669; batch adversarial loss: 0.557392\n",
      "epoch 11; iter: 0; batch classifier loss: 0.327478; batch adversarial loss: 0.525632\n",
      "epoch 12; iter: 0; batch classifier loss: 0.362806; batch adversarial loss: 0.533111\n",
      "epoch 13; iter: 0; batch classifier loss: 0.411816; batch adversarial loss: 0.532228\n",
      "epoch 14; iter: 0; batch classifier loss: 0.348815; batch adversarial loss: 0.473737\n",
      "epoch 15; iter: 0; batch classifier loss: 0.351304; batch adversarial loss: 0.480849\n",
      "epoch 16; iter: 0; batch classifier loss: 0.372911; batch adversarial loss: 0.533445\n",
      "epoch 17; iter: 0; batch classifier loss: 0.337822; batch adversarial loss: 0.534572\n",
      "epoch 18; iter: 0; batch classifier loss: 0.338631; batch adversarial loss: 0.518548\n",
      "epoch 19; iter: 0; batch classifier loss: 0.385349; batch adversarial loss: 0.450455\n",
      "epoch 20; iter: 0; batch classifier loss: 0.351330; batch adversarial loss: 0.442876\n",
      "epoch 21; iter: 0; batch classifier loss: 0.339780; batch adversarial loss: 0.524891\n",
      "epoch 22; iter: 0; batch classifier loss: 0.361940; batch adversarial loss: 0.470988\n",
      "epoch 23; iter: 0; batch classifier loss: 0.402863; batch adversarial loss: 0.483656\n",
      "epoch 24; iter: 0; batch classifier loss: 0.413209; batch adversarial loss: 0.497042\n",
      "epoch 25; iter: 0; batch classifier loss: 0.243199; batch adversarial loss: 0.465479\n",
      "epoch 26; iter: 0; batch classifier loss: 0.354281; batch adversarial loss: 0.495491\n",
      "epoch 27; iter: 0; batch classifier loss: 0.356017; batch adversarial loss: 0.375008\n",
      "epoch 28; iter: 0; batch classifier loss: 0.282681; batch adversarial loss: 0.460473\n",
      "epoch 29; iter: 0; batch classifier loss: 0.293620; batch adversarial loss: 0.548030\n",
      "epoch 30; iter: 0; batch classifier loss: 0.341055; batch adversarial loss: 0.426052\n",
      "epoch 31; iter: 0; batch classifier loss: 0.261738; batch adversarial loss: 0.454695\n",
      "epoch 32; iter: 0; batch classifier loss: 0.265726; batch adversarial loss: 0.454567\n",
      "epoch 33; iter: 0; batch classifier loss: 0.242409; batch adversarial loss: 0.482700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.313505; batch adversarial loss: 0.444384\n",
      "epoch 35; iter: 0; batch classifier loss: 0.215135; batch adversarial loss: 0.514781\n",
      "epoch 36; iter: 0; batch classifier loss: 0.227215; batch adversarial loss: 0.510318\n",
      "epoch 37; iter: 0; batch classifier loss: 0.198714; batch adversarial loss: 0.417946\n",
      "epoch 38; iter: 0; batch classifier loss: 0.183427; batch adversarial loss: 0.503458\n",
      "epoch 39; iter: 0; batch classifier loss: 0.207097; batch adversarial loss: 0.535542\n",
      "epoch 40; iter: 0; batch classifier loss: 0.257706; batch adversarial loss: 0.475163\n",
      "epoch 41; iter: 0; batch classifier loss: 0.219676; batch adversarial loss: 0.463679\n",
      "epoch 42; iter: 0; batch classifier loss: 0.221258; batch adversarial loss: 0.496936\n",
      "epoch 43; iter: 0; batch classifier loss: 0.232184; batch adversarial loss: 0.430208\n",
      "epoch 44; iter: 0; batch classifier loss: 0.293255; batch adversarial loss: 0.524606\n",
      "epoch 45; iter: 0; batch classifier loss: 0.234517; batch adversarial loss: 0.477924\n",
      "epoch 46; iter: 0; batch classifier loss: 0.266905; batch adversarial loss: 0.423981\n",
      "epoch 47; iter: 0; batch classifier loss: 0.237987; batch adversarial loss: 0.484887\n",
      "epoch 48; iter: 0; batch classifier loss: 0.310777; batch adversarial loss: 0.402481\n",
      "epoch 49; iter: 0; batch classifier loss: 0.218295; batch adversarial loss: 0.490943\n",
      "epoch 50; iter: 0; batch classifier loss: 0.235576; batch adversarial loss: 0.488386\n",
      "epoch 51; iter: 0; batch classifier loss: 0.222747; batch adversarial loss: 0.468590\n",
      "epoch 52; iter: 0; batch classifier loss: 0.160883; batch adversarial loss: 0.486060\n",
      "epoch 53; iter: 0; batch classifier loss: 0.252145; batch adversarial loss: 0.440120\n",
      "epoch 54; iter: 0; batch classifier loss: 0.205629; batch adversarial loss: 0.514919\n",
      "epoch 55; iter: 0; batch classifier loss: 0.269657; batch adversarial loss: 0.456537\n",
      "epoch 56; iter: 0; batch classifier loss: 0.165037; batch adversarial loss: 0.510620\n",
      "epoch 57; iter: 0; batch classifier loss: 0.250418; batch adversarial loss: 0.464957\n",
      "epoch 58; iter: 0; batch classifier loss: 0.192213; batch adversarial loss: 0.449036\n",
      "epoch 59; iter: 0; batch classifier loss: 0.177782; batch adversarial loss: 0.470501\n",
      "epoch 60; iter: 0; batch classifier loss: 0.246187; batch adversarial loss: 0.436072\n",
      "epoch 61; iter: 0; batch classifier loss: 0.189816; batch adversarial loss: 0.528879\n",
      "epoch 62; iter: 0; batch classifier loss: 0.221452; batch adversarial loss: 0.391095\n",
      "epoch 63; iter: 0; batch classifier loss: 0.237404; batch adversarial loss: 0.496808\n",
      "epoch 64; iter: 0; batch classifier loss: 0.225198; batch adversarial loss: 0.399046\n",
      "epoch 65; iter: 0; batch classifier loss: 0.216320; batch adversarial loss: 0.423636\n",
      "epoch 66; iter: 0; batch classifier loss: 0.200544; batch adversarial loss: 0.435577\n",
      "epoch 67; iter: 0; batch classifier loss: 0.275272; batch adversarial loss: 0.481992\n",
      "epoch 68; iter: 0; batch classifier loss: 0.248465; batch adversarial loss: 0.375540\n",
      "epoch 69; iter: 0; batch classifier loss: 0.150595; batch adversarial loss: 0.544453\n",
      "epoch 70; iter: 0; batch classifier loss: 0.231300; batch adversarial loss: 0.433717\n",
      "epoch 71; iter: 0; batch classifier loss: 0.231885; batch adversarial loss: 0.504824\n",
      "epoch 72; iter: 0; batch classifier loss: 0.224842; batch adversarial loss: 0.505688\n",
      "epoch 73; iter: 0; batch classifier loss: 0.193824; batch adversarial loss: 0.448677\n",
      "epoch 74; iter: 0; batch classifier loss: 0.364261; batch adversarial loss: 0.423073\n",
      "epoch 75; iter: 0; batch classifier loss: 0.188811; batch adversarial loss: 0.423002\n",
      "epoch 76; iter: 0; batch classifier loss: 0.217392; batch adversarial loss: 0.446376\n",
      "epoch 77; iter: 0; batch classifier loss: 0.193026; batch adversarial loss: 0.459476\n",
      "epoch 78; iter: 0; batch classifier loss: 0.255260; batch adversarial loss: 0.386977\n",
      "epoch 79; iter: 0; batch classifier loss: 0.163603; batch adversarial loss: 0.483039\n",
      "epoch 80; iter: 0; batch classifier loss: 0.209100; batch adversarial loss: 0.506911\n",
      "epoch 81; iter: 0; batch classifier loss: 0.225755; batch adversarial loss: 0.398965\n",
      "epoch 82; iter: 0; batch classifier loss: 0.228236; batch adversarial loss: 0.531712\n",
      "epoch 83; iter: 0; batch classifier loss: 0.172668; batch adversarial loss: 0.410091\n",
      "epoch 84; iter: 0; batch classifier loss: 0.179619; batch adversarial loss: 0.531336\n",
      "epoch 85; iter: 0; batch classifier loss: 0.134992; batch adversarial loss: 0.494670\n",
      "epoch 86; iter: 0; batch classifier loss: 0.119875; batch adversarial loss: 0.554127\n",
      "epoch 87; iter: 0; batch classifier loss: 0.160338; batch adversarial loss: 0.436559\n",
      "epoch 88; iter: 0; batch classifier loss: 0.204684; batch adversarial loss: 0.462915\n",
      "epoch 89; iter: 0; batch classifier loss: 0.264610; batch adversarial loss: 0.508186\n",
      "epoch 90; iter: 0; batch classifier loss: 0.150754; batch adversarial loss: 0.483703\n",
      "epoch 91; iter: 0; batch classifier loss: 0.202313; batch adversarial loss: 0.446476\n",
      "epoch 92; iter: 0; batch classifier loss: 0.210267; batch adversarial loss: 0.483382\n",
      "epoch 93; iter: 0; batch classifier loss: 0.164871; batch adversarial loss: 0.435192\n",
      "epoch 94; iter: 0; batch classifier loss: 0.178379; batch adversarial loss: 0.497370\n",
      "epoch 95; iter: 0; batch classifier loss: 0.214948; batch adversarial loss: 0.459008\n",
      "epoch 96; iter: 0; batch classifier loss: 0.207392; batch adversarial loss: 0.374527\n",
      "epoch 97; iter: 0; batch classifier loss: 0.196891; batch adversarial loss: 0.543915\n",
      "epoch 98; iter: 0; batch classifier loss: 0.168708; batch adversarial loss: 0.398462\n",
      "epoch 99; iter: 0; batch classifier loss: 0.229811; batch adversarial loss: 0.558623\n",
      "epoch 100; iter: 0; batch classifier loss: 0.245198; batch adversarial loss: 0.424458\n",
      "epoch 101; iter: 0; batch classifier loss: 0.144794; batch adversarial loss: 0.482667\n",
      "epoch 102; iter: 0; batch classifier loss: 0.166995; batch adversarial loss: 0.446459\n",
      "epoch 103; iter: 0; batch classifier loss: 0.164767; batch adversarial loss: 0.516805\n",
      "epoch 104; iter: 0; batch classifier loss: 0.200953; batch adversarial loss: 0.409096\n",
      "epoch 105; iter: 0; batch classifier loss: 0.169176; batch adversarial loss: 0.481284\n",
      "epoch 106; iter: 0; batch classifier loss: 0.196066; batch adversarial loss: 0.472979\n",
      "epoch 107; iter: 0; batch classifier loss: 0.145830; batch adversarial loss: 0.445366\n",
      "epoch 108; iter: 0; batch classifier loss: 0.139931; batch adversarial loss: 0.420176\n",
      "epoch 109; iter: 0; batch classifier loss: 0.128671; batch adversarial loss: 0.444079\n",
      "epoch 110; iter: 0; batch classifier loss: 0.109550; batch adversarial loss: 0.429613\n",
      "epoch 111; iter: 0; batch classifier loss: 0.090419; batch adversarial loss: 0.457931\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059170; batch adversarial loss: 0.470244\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037232; batch adversarial loss: 0.506940\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049265; batch adversarial loss: 0.560579\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034249; batch adversarial loss: 0.484502\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046894; batch adversarial loss: 0.431176\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046551; batch adversarial loss: 0.405146\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028482; batch adversarial loss: 0.453324\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038903; batch adversarial loss: 0.376998\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041671; batch adversarial loss: 0.478462\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038248; batch adversarial loss: 0.430599\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030232; batch adversarial loss: 0.489634\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030848; batch adversarial loss: 0.401616\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021284; batch adversarial loss: 0.504678\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042049; batch adversarial loss: 0.415585\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040524; batch adversarial loss: 0.514480\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053483; batch adversarial loss: 0.415710\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032670; batch adversarial loss: 0.468483\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033939; batch adversarial loss: 0.448036\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044843; batch adversarial loss: 0.478111\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024805; batch adversarial loss: 0.457823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.024453; batch adversarial loss: 0.433252\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023098; batch adversarial loss: 0.499035\n",
      "epoch 134; iter: 0; batch classifier loss: 0.012756; batch adversarial loss: 0.394888\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014547; batch adversarial loss: 0.461482\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022164; batch adversarial loss: 0.380983\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039086; batch adversarial loss: 0.484335\n",
      "epoch 138; iter: 0; batch classifier loss: 0.043697; batch adversarial loss: 0.508308\n",
      "epoch 139; iter: 0; batch classifier loss: 0.011537; batch adversarial loss: 0.469598\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024771; batch adversarial loss: 0.412754\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042289; batch adversarial loss: 0.406332\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019588; batch adversarial loss: 0.449552\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026836; batch adversarial loss: 0.460123\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025942; batch adversarial loss: 0.483898\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018645; batch adversarial loss: 0.490797\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044378; batch adversarial loss: 0.475110\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038559; batch adversarial loss: 0.395849\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021557; batch adversarial loss: 0.492218\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023666; batch adversarial loss: 0.454627\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018471; batch adversarial loss: 0.376842\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014488; batch adversarial loss: 0.439333\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014076; batch adversarial loss: 0.500534\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023758; batch adversarial loss: 0.443501\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013545; batch adversarial loss: 0.465128\n",
      "epoch 155; iter: 0; batch classifier loss: 0.005388; batch adversarial loss: 0.517370\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018350; batch adversarial loss: 0.393883\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023619; batch adversarial loss: 0.415192\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023955; batch adversarial loss: 0.397241\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021291; batch adversarial loss: 0.413538\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013679; batch adversarial loss: 0.525194\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034058; batch adversarial loss: 0.512799\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011599; batch adversarial loss: 0.475529\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019530; batch adversarial loss: 0.501385\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019838; batch adversarial loss: 0.430827\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020146; batch adversarial loss: 0.464141\n",
      "epoch 166; iter: 0; batch classifier loss: 0.005537; batch adversarial loss: 0.417607\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009588; batch adversarial loss: 0.543428\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023833; batch adversarial loss: 0.535301\n",
      "epoch 169; iter: 0; batch classifier loss: 0.049509; batch adversarial loss: 0.518010\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017812; batch adversarial loss: 0.455704\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019119; batch adversarial loss: 0.428349\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014052; batch adversarial loss: 0.539861\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006716; batch adversarial loss: 0.413570\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030746; batch adversarial loss: 0.472975\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014466; batch adversarial loss: 0.460411\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010762; batch adversarial loss: 0.414382\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034937; batch adversarial loss: 0.451979\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010077; batch adversarial loss: 0.466434\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039586; batch adversarial loss: 0.471525\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015260; batch adversarial loss: 0.465415\n",
      "epoch 181; iter: 0; batch classifier loss: 0.004041; batch adversarial loss: 0.421008\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025817; batch adversarial loss: 0.402187\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024834; batch adversarial loss: 0.529580\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007159; batch adversarial loss: 0.460283\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006202; batch adversarial loss: 0.456588\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013638; batch adversarial loss: 0.449732\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026936; batch adversarial loss: 0.495797\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026110; batch adversarial loss: 0.462684\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013008; batch adversarial loss: 0.379973\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026929; batch adversarial loss: 0.531675\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005748; batch adversarial loss: 0.483546\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012980; batch adversarial loss: 0.496911\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023071; batch adversarial loss: 0.460125\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023169; batch adversarial loss: 0.486116\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037907; batch adversarial loss: 0.421878\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005003; batch adversarial loss: 0.532762\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020490; batch adversarial loss: 0.421594\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007218; batch adversarial loss: 0.453744\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018798; batch adversarial loss: 0.438167\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680944; batch adversarial loss: 0.546791\n",
      "epoch 1; iter: 0; batch classifier loss: 0.430254; batch adversarial loss: 0.576084\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396728; batch adversarial loss: 0.542498\n",
      "epoch 3; iter: 0; batch classifier loss: 0.413330; batch adversarial loss: 0.613109\n",
      "epoch 4; iter: 0; batch classifier loss: 0.357506; batch adversarial loss: 0.583239\n",
      "epoch 5; iter: 0; batch classifier loss: 0.330334; batch adversarial loss: 0.610212\n",
      "epoch 6; iter: 0; batch classifier loss: 0.334552; batch adversarial loss: 0.594408\n",
      "epoch 7; iter: 0; batch classifier loss: 0.293491; batch adversarial loss: 0.560966\n",
      "epoch 8; iter: 0; batch classifier loss: 0.298752; batch adversarial loss: 0.574165\n",
      "epoch 9; iter: 0; batch classifier loss: 0.283228; batch adversarial loss: 0.489658\n",
      "epoch 10; iter: 0; batch classifier loss: 0.210962; batch adversarial loss: 0.509810\n",
      "epoch 11; iter: 0; batch classifier loss: 0.278649; batch adversarial loss: 0.521575\n",
      "epoch 12; iter: 0; batch classifier loss: 0.292295; batch adversarial loss: 0.499859\n",
      "epoch 13; iter: 0; batch classifier loss: 0.249376; batch adversarial loss: 0.508378\n",
      "epoch 14; iter: 0; batch classifier loss: 0.195399; batch adversarial loss: 0.522747\n",
      "epoch 15; iter: 0; batch classifier loss: 0.284580; batch adversarial loss: 0.490673\n",
      "epoch 16; iter: 0; batch classifier loss: 0.247807; batch adversarial loss: 0.445988\n",
      "epoch 17; iter: 0; batch classifier loss: 0.347411; batch adversarial loss: 0.453561\n",
      "epoch 18; iter: 0; batch classifier loss: 0.283934; batch adversarial loss: 0.489406\n",
      "epoch 19; iter: 0; batch classifier loss: 0.410665; batch adversarial loss: 0.590305\n",
      "epoch 20; iter: 0; batch classifier loss: 0.547267; batch adversarial loss: 0.584330\n",
      "epoch 21; iter: 0; batch classifier loss: 0.285263; batch adversarial loss: 0.471166\n",
      "epoch 22; iter: 0; batch classifier loss: 0.299950; batch adversarial loss: 0.428051\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168574; batch adversarial loss: 0.483627\n",
      "epoch 24; iter: 0; batch classifier loss: 0.162559; batch adversarial loss: 0.472822\n",
      "epoch 25; iter: 0; batch classifier loss: 0.107949; batch adversarial loss: 0.499260\n",
      "epoch 26; iter: 0; batch classifier loss: 0.127120; batch adversarial loss: 0.438023\n",
      "epoch 27; iter: 0; batch classifier loss: 0.165550; batch adversarial loss: 0.533383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.205598; batch adversarial loss: 0.462983\n",
      "epoch 29; iter: 0; batch classifier loss: 0.133191; batch adversarial loss: 0.448748\n",
      "epoch 30; iter: 0; batch classifier loss: 0.140346; batch adversarial loss: 0.412434\n",
      "epoch 31; iter: 0; batch classifier loss: 0.131495; batch adversarial loss: 0.413435\n",
      "epoch 32; iter: 0; batch classifier loss: 0.134534; batch adversarial loss: 0.536154\n",
      "epoch 33; iter: 0; batch classifier loss: 0.155890; batch adversarial loss: 0.522700\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148307; batch adversarial loss: 0.516706\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125621; batch adversarial loss: 0.457837\n",
      "epoch 36; iter: 0; batch classifier loss: 0.162492; batch adversarial loss: 0.419380\n",
      "epoch 37; iter: 0; batch classifier loss: 0.095743; batch adversarial loss: 0.469620\n",
      "epoch 38; iter: 0; batch classifier loss: 0.096725; batch adversarial loss: 0.440402\n",
      "epoch 39; iter: 0; batch classifier loss: 0.116069; batch adversarial loss: 0.468143\n",
      "epoch 40; iter: 0; batch classifier loss: 0.092077; batch adversarial loss: 0.425580\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123132; batch adversarial loss: 0.376888\n",
      "epoch 42; iter: 0; batch classifier loss: 0.098497; batch adversarial loss: 0.489084\n",
      "epoch 43; iter: 0; batch classifier loss: 0.113747; batch adversarial loss: 0.415283\n",
      "epoch 44; iter: 0; batch classifier loss: 0.111086; batch adversarial loss: 0.450493\n",
      "epoch 45; iter: 0; batch classifier loss: 0.134471; batch adversarial loss: 0.389563\n",
      "epoch 46; iter: 0; batch classifier loss: 0.093538; batch adversarial loss: 0.476169\n",
      "epoch 47; iter: 0; batch classifier loss: 0.091454; batch adversarial loss: 0.394982\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082850; batch adversarial loss: 0.373751\n",
      "epoch 49; iter: 0; batch classifier loss: 0.089328; batch adversarial loss: 0.548592\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084701; batch adversarial loss: 0.550757\n",
      "epoch 51; iter: 0; batch classifier loss: 0.119257; batch adversarial loss: 0.500371\n",
      "epoch 52; iter: 0; batch classifier loss: 0.079257; batch adversarial loss: 0.407425\n",
      "epoch 53; iter: 0; batch classifier loss: 0.121249; batch adversarial loss: 0.465302\n",
      "epoch 54; iter: 0; batch classifier loss: 0.204284; batch adversarial loss: 0.430897\n",
      "epoch 55; iter: 0; batch classifier loss: 0.064205; batch adversarial loss: 0.448430\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084321; batch adversarial loss: 0.523000\n",
      "epoch 57; iter: 0; batch classifier loss: 0.159352; batch adversarial loss: 0.361014\n",
      "epoch 58; iter: 0; batch classifier loss: 0.107161; batch adversarial loss: 0.468148\n",
      "epoch 59; iter: 0; batch classifier loss: 0.104950; batch adversarial loss: 0.386936\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105148; batch adversarial loss: 0.456952\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093881; batch adversarial loss: 0.419317\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085464; batch adversarial loss: 0.483852\n",
      "epoch 63; iter: 0; batch classifier loss: 0.130546; batch adversarial loss: 0.351878\n",
      "epoch 64; iter: 0; batch classifier loss: 0.105748; batch adversarial loss: 0.549742\n",
      "epoch 65; iter: 0; batch classifier loss: 0.124641; batch adversarial loss: 0.470070\n",
      "epoch 66; iter: 0; batch classifier loss: 0.067687; batch adversarial loss: 0.477003\n",
      "epoch 67; iter: 0; batch classifier loss: 0.164211; batch adversarial loss: 0.485346\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109134; batch adversarial loss: 0.600501\n",
      "epoch 69; iter: 0; batch classifier loss: 0.143005; batch adversarial loss: 0.460524\n",
      "epoch 70; iter: 0; batch classifier loss: 0.141482; batch adversarial loss: 0.465708\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104615; batch adversarial loss: 0.553578\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087357; batch adversarial loss: 0.399803\n",
      "epoch 73; iter: 0; batch classifier loss: 0.174977; batch adversarial loss: 0.489120\n",
      "epoch 74; iter: 0; batch classifier loss: 0.121589; batch adversarial loss: 0.401694\n",
      "epoch 75; iter: 0; batch classifier loss: 0.112368; batch adversarial loss: 0.517237\n",
      "epoch 76; iter: 0; batch classifier loss: 0.158165; batch adversarial loss: 0.399220\n",
      "epoch 77; iter: 0; batch classifier loss: 0.098520; batch adversarial loss: 0.395815\n",
      "epoch 78; iter: 0; batch classifier loss: 0.111377; batch adversarial loss: 0.458056\n",
      "epoch 79; iter: 0; batch classifier loss: 0.159567; batch adversarial loss: 0.472697\n",
      "epoch 80; iter: 0; batch classifier loss: 0.107466; batch adversarial loss: 0.452311\n",
      "epoch 81; iter: 0; batch classifier loss: 0.137467; batch adversarial loss: 0.444993\n",
      "epoch 82; iter: 0; batch classifier loss: 0.139487; batch adversarial loss: 0.383207\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085867; batch adversarial loss: 0.524732\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103055; batch adversarial loss: 0.513986\n",
      "epoch 85; iter: 0; batch classifier loss: 0.095489; batch adversarial loss: 0.494330\n",
      "epoch 86; iter: 0; batch classifier loss: 0.123826; batch adversarial loss: 0.430565\n",
      "epoch 87; iter: 0; batch classifier loss: 0.169437; batch adversarial loss: 0.431845\n",
      "epoch 88; iter: 0; batch classifier loss: 0.172968; batch adversarial loss: 0.495441\n",
      "epoch 89; iter: 0; batch classifier loss: 0.115905; batch adversarial loss: 0.423238\n",
      "epoch 90; iter: 0; batch classifier loss: 0.116936; batch adversarial loss: 0.451594\n",
      "epoch 91; iter: 0; batch classifier loss: 0.149899; batch adversarial loss: 0.419855\n",
      "epoch 92; iter: 0; batch classifier loss: 0.107179; batch adversarial loss: 0.474440\n",
      "epoch 93; iter: 0; batch classifier loss: 0.127496; batch adversarial loss: 0.469268\n",
      "epoch 94; iter: 0; batch classifier loss: 0.160698; batch adversarial loss: 0.335025\n",
      "epoch 95; iter: 0; batch classifier loss: 0.120244; batch adversarial loss: 0.354717\n",
      "epoch 96; iter: 0; batch classifier loss: 0.130365; batch adversarial loss: 0.524422\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062831; batch adversarial loss: 0.468163\n",
      "epoch 98; iter: 0; batch classifier loss: 0.121620; batch adversarial loss: 0.365097\n",
      "epoch 99; iter: 0; batch classifier loss: 0.110248; batch adversarial loss: 0.511190\n",
      "epoch 100; iter: 0; batch classifier loss: 0.149449; batch adversarial loss: 0.424001\n",
      "epoch 101; iter: 0; batch classifier loss: 0.142378; batch adversarial loss: 0.459877\n",
      "epoch 102; iter: 0; batch classifier loss: 0.192574; batch adversarial loss: 0.407390\n",
      "epoch 103; iter: 0; batch classifier loss: 0.114291; batch adversarial loss: 0.589615\n",
      "epoch 104; iter: 0; batch classifier loss: 0.081646; batch adversarial loss: 0.480415\n",
      "epoch 105; iter: 0; batch classifier loss: 0.101318; batch adversarial loss: 0.542614\n",
      "epoch 106; iter: 0; batch classifier loss: 0.125286; batch adversarial loss: 0.518493\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047940; batch adversarial loss: 0.463932\n",
      "epoch 108; iter: 0; batch classifier loss: 0.092722; batch adversarial loss: 0.468582\n",
      "epoch 109; iter: 0; batch classifier loss: 0.068306; batch adversarial loss: 0.391013\n",
      "epoch 110; iter: 0; batch classifier loss: 0.078486; batch adversarial loss: 0.453139\n",
      "epoch 111; iter: 0; batch classifier loss: 0.109123; batch adversarial loss: 0.365263\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075754; batch adversarial loss: 0.445833\n",
      "epoch 113; iter: 0; batch classifier loss: 0.106438; batch adversarial loss: 0.506026\n",
      "epoch 114; iter: 0; batch classifier loss: 0.079590; batch adversarial loss: 0.481257\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047524; batch adversarial loss: 0.534475\n",
      "epoch 116; iter: 0; batch classifier loss: 0.093765; batch adversarial loss: 0.518942\n",
      "epoch 117; iter: 0; batch classifier loss: 0.070759; batch adversarial loss: 0.502157\n",
      "epoch 118; iter: 0; batch classifier loss: 0.079081; batch adversarial loss: 0.413612\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048056; batch adversarial loss: 0.548404\n",
      "epoch 120; iter: 0; batch classifier loss: 0.091921; batch adversarial loss: 0.528306\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036130; batch adversarial loss: 0.537666\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041219; batch adversarial loss: 0.433895\n",
      "epoch 123; iter: 0; batch classifier loss: 0.088305; batch adversarial loss: 0.440258\n",
      "epoch 124; iter: 0; batch classifier loss: 0.103243; batch adversarial loss: 0.466382\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057799; batch adversarial loss: 0.528845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.058729; batch adversarial loss: 0.388092\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048037; batch adversarial loss: 0.369139\n",
      "epoch 128; iter: 0; batch classifier loss: 0.113108; batch adversarial loss: 0.353804\n",
      "epoch 129; iter: 0; batch classifier loss: 0.049815; batch adversarial loss: 0.448048\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026983; batch adversarial loss: 0.466688\n",
      "epoch 131; iter: 0; batch classifier loss: 0.058016; batch adversarial loss: 0.393218\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045387; batch adversarial loss: 0.487608\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053818; batch adversarial loss: 0.507012\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042228; batch adversarial loss: 0.502897\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025077; batch adversarial loss: 0.393070\n",
      "epoch 136; iter: 0; batch classifier loss: 0.059288; batch adversarial loss: 0.432341\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043376; batch adversarial loss: 0.362569\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018912; batch adversarial loss: 0.445105\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032281; batch adversarial loss: 0.513195\n",
      "epoch 140; iter: 0; batch classifier loss: 0.039254; batch adversarial loss: 0.503668\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030332; batch adversarial loss: 0.451398\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018504; batch adversarial loss: 0.468779\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036699; batch adversarial loss: 0.437353\n",
      "epoch 144; iter: 0; batch classifier loss: 0.035537; batch adversarial loss: 0.403886\n",
      "epoch 145; iter: 0; batch classifier loss: 0.050636; batch adversarial loss: 0.485986\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019043; batch adversarial loss: 0.456133\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043629; batch adversarial loss: 0.428417\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042234; batch adversarial loss: 0.531799\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035385; batch adversarial loss: 0.451808\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027041; batch adversarial loss: 0.487644\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024652; batch adversarial loss: 0.496301\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036223; batch adversarial loss: 0.392663\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034062; batch adversarial loss: 0.361140\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044667; batch adversarial loss: 0.457329\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020278; batch adversarial loss: 0.402787\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040019; batch adversarial loss: 0.479328\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026158; batch adversarial loss: 0.543040\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020136; batch adversarial loss: 0.471003\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020809; batch adversarial loss: 0.394765\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018474; batch adversarial loss: 0.542789\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037632; batch adversarial loss: 0.398330\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017359; batch adversarial loss: 0.451337\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032781; batch adversarial loss: 0.454187\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029476; batch adversarial loss: 0.447373\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015454; batch adversarial loss: 0.444550\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012041; batch adversarial loss: 0.440270\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034281; batch adversarial loss: 0.454928\n",
      "epoch 168; iter: 0; batch classifier loss: 0.039389; batch adversarial loss: 0.411278\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027185; batch adversarial loss: 0.414334\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037983; batch adversarial loss: 0.468392\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011735; batch adversarial loss: 0.453824\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006969; batch adversarial loss: 0.469120\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014035; batch adversarial loss: 0.408589\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013071; batch adversarial loss: 0.438861\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013401; batch adversarial loss: 0.387188\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007855; batch adversarial loss: 0.460204\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019917; batch adversarial loss: 0.401249\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028947; batch adversarial loss: 0.537788\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010377; batch adversarial loss: 0.490076\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022034; batch adversarial loss: 0.400532\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022388; batch adversarial loss: 0.409951\n",
      "epoch 182; iter: 0; batch classifier loss: 0.044464; batch adversarial loss: 0.329814\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024263; batch adversarial loss: 0.483241\n",
      "epoch 184; iter: 0; batch classifier loss: 0.046043; batch adversarial loss: 0.515131\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019955; batch adversarial loss: 0.433615\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014934; batch adversarial loss: 0.363411\n",
      "epoch 187; iter: 0; batch classifier loss: 0.051471; batch adversarial loss: 0.472850\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005640; batch adversarial loss: 0.487922\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010905; batch adversarial loss: 0.481571\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007929; batch adversarial loss: 0.456610\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020006; batch adversarial loss: 0.495427\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040989; batch adversarial loss: 0.443433\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009880; batch adversarial loss: 0.401216\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028043; batch adversarial loss: 0.444174\n",
      "epoch 195; iter: 0; batch classifier loss: 0.047754; batch adversarial loss: 0.462381\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015361; batch adversarial loss: 0.432648\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007361; batch adversarial loss: 0.489858\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028874; batch adversarial loss: 0.439810\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017689; batch adversarial loss: 0.481447\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695450; batch adversarial loss: 0.618124\n",
      "epoch 1; iter: 0; batch classifier loss: 0.435325; batch adversarial loss: 0.630717\n",
      "epoch 2; iter: 0; batch classifier loss: 0.409721; batch adversarial loss: 0.571177\n",
      "epoch 3; iter: 0; batch classifier loss: 0.312090; batch adversarial loss: 0.576767\n",
      "epoch 4; iter: 0; batch classifier loss: 0.238734; batch adversarial loss: 0.566824\n",
      "epoch 5; iter: 0; batch classifier loss: 0.267383; batch adversarial loss: 0.527829\n",
      "epoch 6; iter: 0; batch classifier loss: 0.255477; batch adversarial loss: 0.535849\n",
      "epoch 7; iter: 0; batch classifier loss: 0.267875; batch adversarial loss: 0.509524\n",
      "epoch 8; iter: 0; batch classifier loss: 0.238938; batch adversarial loss: 0.562233\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273622; batch adversarial loss: 0.521981\n",
      "epoch 10; iter: 0; batch classifier loss: 0.292488; batch adversarial loss: 0.460871\n",
      "epoch 11; iter: 0; batch classifier loss: 0.242698; batch adversarial loss: 0.470192\n",
      "epoch 12; iter: 0; batch classifier loss: 0.158887; batch adversarial loss: 0.513230\n",
      "epoch 13; iter: 0; batch classifier loss: 0.163253; batch adversarial loss: 0.534220\n",
      "epoch 14; iter: 0; batch classifier loss: 0.278939; batch adversarial loss: 0.488992\n",
      "epoch 15; iter: 0; batch classifier loss: 0.199957; batch adversarial loss: 0.520788\n",
      "epoch 16; iter: 0; batch classifier loss: 0.184521; batch adversarial loss: 0.514269\n",
      "epoch 17; iter: 0; batch classifier loss: 0.196210; batch adversarial loss: 0.508742\n",
      "epoch 18; iter: 0; batch classifier loss: 0.239463; batch adversarial loss: 0.568304\n",
      "epoch 19; iter: 0; batch classifier loss: 0.202840; batch adversarial loss: 0.507412\n",
      "epoch 20; iter: 0; batch classifier loss: 0.183314; batch adversarial loss: 0.505520\n",
      "epoch 21; iter: 0; batch classifier loss: 0.190744; batch adversarial loss: 0.550974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.291529; batch adversarial loss: 0.592300\n",
      "epoch 23; iter: 0; batch classifier loss: 0.327122; batch adversarial loss: 0.526243\n",
      "epoch 24; iter: 0; batch classifier loss: 0.249000; batch adversarial loss: 0.543773\n",
      "epoch 25; iter: 0; batch classifier loss: 0.328014; batch adversarial loss: 0.579538\n",
      "epoch 26; iter: 0; batch classifier loss: 0.258096; batch adversarial loss: 0.518668\n",
      "epoch 27; iter: 0; batch classifier loss: 0.269361; batch adversarial loss: 0.445630\n",
      "epoch 28; iter: 0; batch classifier loss: 0.326447; batch adversarial loss: 0.479381\n",
      "epoch 29; iter: 0; batch classifier loss: 0.254341; batch adversarial loss: 0.502240\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153843; batch adversarial loss: 0.504033\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178274; batch adversarial loss: 0.404625\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140234; batch adversarial loss: 0.409057\n",
      "epoch 33; iter: 0; batch classifier loss: 0.081697; batch adversarial loss: 0.467935\n",
      "epoch 34; iter: 0; batch classifier loss: 0.134947; batch adversarial loss: 0.466441\n",
      "epoch 35; iter: 0; batch classifier loss: 0.147154; batch adversarial loss: 0.392667\n",
      "epoch 36; iter: 0; batch classifier loss: 0.119236; batch adversarial loss: 0.463142\n",
      "epoch 37; iter: 0; batch classifier loss: 0.121153; batch adversarial loss: 0.537839\n",
      "epoch 38; iter: 0; batch classifier loss: 0.076767; batch adversarial loss: 0.460111\n",
      "epoch 39; iter: 0; batch classifier loss: 0.099923; batch adversarial loss: 0.449008\n",
      "epoch 40; iter: 0; batch classifier loss: 0.117131; batch adversarial loss: 0.432102\n",
      "epoch 41; iter: 0; batch classifier loss: 0.177238; batch adversarial loss: 0.432698\n",
      "epoch 42; iter: 0; batch classifier loss: 0.061881; batch adversarial loss: 0.503730\n",
      "epoch 43; iter: 0; batch classifier loss: 0.088667; batch adversarial loss: 0.439919\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098429; batch adversarial loss: 0.524235\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089946; batch adversarial loss: 0.527736\n",
      "epoch 46; iter: 0; batch classifier loss: 0.156329; batch adversarial loss: 0.489583\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100517; batch adversarial loss: 0.420785\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125287; batch adversarial loss: 0.409733\n",
      "epoch 49; iter: 0; batch classifier loss: 0.118878; batch adversarial loss: 0.476015\n",
      "epoch 50; iter: 0; batch classifier loss: 0.142903; batch adversarial loss: 0.379612\n",
      "epoch 51; iter: 0; batch classifier loss: 0.068533; batch adversarial loss: 0.463055\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089596; batch adversarial loss: 0.422911\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084896; batch adversarial loss: 0.417860\n",
      "epoch 54; iter: 0; batch classifier loss: 0.081484; batch adversarial loss: 0.473433\n",
      "epoch 55; iter: 0; batch classifier loss: 0.064777; batch adversarial loss: 0.462561\n",
      "epoch 56; iter: 0; batch classifier loss: 0.087380; batch adversarial loss: 0.458093\n",
      "epoch 57; iter: 0; batch classifier loss: 0.088780; batch adversarial loss: 0.451770\n",
      "epoch 58; iter: 0; batch classifier loss: 0.133853; batch adversarial loss: 0.466388\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090072; batch adversarial loss: 0.456733\n",
      "epoch 60; iter: 0; batch classifier loss: 0.030939; batch adversarial loss: 0.476984\n",
      "epoch 61; iter: 0; batch classifier loss: 0.082706; batch adversarial loss: 0.538899\n",
      "epoch 62; iter: 0; batch classifier loss: 0.096446; batch adversarial loss: 0.490775\n",
      "epoch 63; iter: 0; batch classifier loss: 0.115421; batch adversarial loss: 0.467424\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068998; batch adversarial loss: 0.464982\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077125; batch adversarial loss: 0.458010\n",
      "epoch 66; iter: 0; batch classifier loss: 0.162457; batch adversarial loss: 0.539423\n",
      "epoch 67; iter: 0; batch classifier loss: 0.125569; batch adversarial loss: 0.488962\n",
      "epoch 68; iter: 0; batch classifier loss: 0.100779; batch adversarial loss: 0.517060\n",
      "epoch 69; iter: 0; batch classifier loss: 0.089241; batch adversarial loss: 0.476930\n",
      "epoch 70; iter: 0; batch classifier loss: 0.057293; batch adversarial loss: 0.406605\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067828; batch adversarial loss: 0.452789\n",
      "epoch 72; iter: 0; batch classifier loss: 0.110710; batch adversarial loss: 0.402831\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058166; batch adversarial loss: 0.414124\n",
      "epoch 74; iter: 0; batch classifier loss: 0.100026; batch adversarial loss: 0.516196\n",
      "epoch 75; iter: 0; batch classifier loss: 0.087334; batch adversarial loss: 0.486404\n",
      "epoch 76; iter: 0; batch classifier loss: 0.054121; batch adversarial loss: 0.396621\n",
      "epoch 77; iter: 0; batch classifier loss: 0.061057; batch adversarial loss: 0.393990\n",
      "epoch 78; iter: 0; batch classifier loss: 0.087987; batch adversarial loss: 0.517769\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074333; batch adversarial loss: 0.442795\n",
      "epoch 80; iter: 0; batch classifier loss: 0.135974; batch adversarial loss: 0.402973\n",
      "epoch 81; iter: 0; batch classifier loss: 0.032920; batch adversarial loss: 0.536959\n",
      "epoch 82; iter: 0; batch classifier loss: 0.097494; batch adversarial loss: 0.431807\n",
      "epoch 83; iter: 0; batch classifier loss: 0.076960; batch adversarial loss: 0.536547\n",
      "epoch 84; iter: 0; batch classifier loss: 0.101439; batch adversarial loss: 0.424872\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073135; batch adversarial loss: 0.481643\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076568; batch adversarial loss: 0.648956\n",
      "epoch 87; iter: 0; batch classifier loss: 0.124820; batch adversarial loss: 0.496125\n",
      "epoch 88; iter: 0; batch classifier loss: 0.052157; batch adversarial loss: 0.551817\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050869; batch adversarial loss: 0.527542\n",
      "epoch 90; iter: 0; batch classifier loss: 0.105540; batch adversarial loss: 0.488968\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062081; batch adversarial loss: 0.423002\n",
      "epoch 92; iter: 0; batch classifier loss: 0.075604; batch adversarial loss: 0.446898\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059856; batch adversarial loss: 0.357878\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070699; batch adversarial loss: 0.396839\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045170; batch adversarial loss: 0.387411\n",
      "epoch 96; iter: 0; batch classifier loss: 0.086070; batch adversarial loss: 0.504352\n",
      "epoch 97; iter: 0; batch classifier loss: 0.023482; batch adversarial loss: 0.520434\n",
      "epoch 98; iter: 0; batch classifier loss: 0.084769; batch adversarial loss: 0.457200\n",
      "epoch 99; iter: 0; batch classifier loss: 0.076756; batch adversarial loss: 0.485142\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074771; batch adversarial loss: 0.464137\n",
      "epoch 101; iter: 0; batch classifier loss: 0.128040; batch adversarial loss: 0.463287\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046428; batch adversarial loss: 0.396039\n",
      "epoch 103; iter: 0; batch classifier loss: 0.083583; batch adversarial loss: 0.489930\n",
      "epoch 104; iter: 0; batch classifier loss: 0.052395; batch adversarial loss: 0.570946\n",
      "epoch 105; iter: 0; batch classifier loss: 0.067451; batch adversarial loss: 0.390535\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036253; batch adversarial loss: 0.465100\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046488; batch adversarial loss: 0.467273\n",
      "epoch 108; iter: 0; batch classifier loss: 0.086739; batch adversarial loss: 0.462647\n",
      "epoch 109; iter: 0; batch classifier loss: 0.076324; batch adversarial loss: 0.380343\n",
      "epoch 110; iter: 0; batch classifier loss: 0.024810; batch adversarial loss: 0.523589\n",
      "epoch 111; iter: 0; batch classifier loss: 0.065179; batch adversarial loss: 0.384284\n",
      "epoch 112; iter: 0; batch classifier loss: 0.073492; batch adversarial loss: 0.488878\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049445; batch adversarial loss: 0.467486\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061671; batch adversarial loss: 0.487959\n",
      "epoch 115; iter: 0; batch classifier loss: 0.087359; batch adversarial loss: 0.530415\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050659; batch adversarial loss: 0.394514\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037177; batch adversarial loss: 0.467675\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056200; batch adversarial loss: 0.416669\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055245; batch adversarial loss: 0.453974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.037845; batch adversarial loss: 0.521438\n",
      "epoch 121; iter: 0; batch classifier loss: 0.070289; batch adversarial loss: 0.515185\n",
      "epoch 122; iter: 0; batch classifier loss: 0.068253; batch adversarial loss: 0.445109\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053997; batch adversarial loss: 0.377828\n",
      "epoch 124; iter: 0; batch classifier loss: 0.047776; batch adversarial loss: 0.533801\n",
      "epoch 125; iter: 0; batch classifier loss: 0.070225; batch adversarial loss: 0.420007\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040398; batch adversarial loss: 0.483315\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048341; batch adversarial loss: 0.393391\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031580; batch adversarial loss: 0.405882\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043173; batch adversarial loss: 0.522944\n",
      "epoch 130; iter: 0; batch classifier loss: 0.055541; batch adversarial loss: 0.449666\n",
      "epoch 131; iter: 0; batch classifier loss: 0.059481; batch adversarial loss: 0.505312\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039250; batch adversarial loss: 0.415268\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037310; batch adversarial loss: 0.426260\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054164; batch adversarial loss: 0.427550\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039477; batch adversarial loss: 0.429455\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018870; batch adversarial loss: 0.492102\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036349; batch adversarial loss: 0.588063\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032036; batch adversarial loss: 0.446599\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028923; batch adversarial loss: 0.487488\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023612; batch adversarial loss: 0.400421\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038863; batch adversarial loss: 0.465526\n",
      "epoch 142; iter: 0; batch classifier loss: 0.065060; batch adversarial loss: 0.476631\n",
      "epoch 143; iter: 0; batch classifier loss: 0.063623; batch adversarial loss: 0.583787\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033416; batch adversarial loss: 0.465926\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036405; batch adversarial loss: 0.482894\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042981; batch adversarial loss: 0.350329\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025608; batch adversarial loss: 0.471581\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036408; batch adversarial loss: 0.484892\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036514; batch adversarial loss: 0.525780\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019083; batch adversarial loss: 0.547014\n",
      "epoch 151; iter: 0; batch classifier loss: 0.058545; batch adversarial loss: 0.528686\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025134; batch adversarial loss: 0.400120\n",
      "epoch 153; iter: 0; batch classifier loss: 0.052315; batch adversarial loss: 0.476250\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015869; batch adversarial loss: 0.477450\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025075; batch adversarial loss: 0.488188\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033060; batch adversarial loss: 0.495587\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035284; batch adversarial loss: 0.444119\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028554; batch adversarial loss: 0.444257\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028567; batch adversarial loss: 0.512795\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041641; batch adversarial loss: 0.404391\n",
      "epoch 161; iter: 0; batch classifier loss: 0.045674; batch adversarial loss: 0.475266\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018766; batch adversarial loss: 0.426345\n",
      "epoch 163; iter: 0; batch classifier loss: 0.048912; batch adversarial loss: 0.428798\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031042; batch adversarial loss: 0.601508\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019836; batch adversarial loss: 0.472251\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046532; batch adversarial loss: 0.447163\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022945; batch adversarial loss: 0.494387\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015719; batch adversarial loss: 0.574625\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024968; batch adversarial loss: 0.543700\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040244; batch adversarial loss: 0.408243\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017545; batch adversarial loss: 0.469953\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010615; batch adversarial loss: 0.425148\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029370; batch adversarial loss: 0.489051\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027592; batch adversarial loss: 0.495495\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018620; batch adversarial loss: 0.484488\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032139; batch adversarial loss: 0.430460\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020090; batch adversarial loss: 0.358865\n",
      "epoch 178; iter: 0; batch classifier loss: 0.057827; batch adversarial loss: 0.448167\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026526; batch adversarial loss: 0.429945\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049610; batch adversarial loss: 0.432111\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020953; batch adversarial loss: 0.453779\n",
      "epoch 182; iter: 0; batch classifier loss: 0.071735; batch adversarial loss: 0.443812\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034099; batch adversarial loss: 0.448765\n",
      "epoch 184; iter: 0; batch classifier loss: 0.051715; batch adversarial loss: 0.404746\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032303; batch adversarial loss: 0.482073\n",
      "epoch 186; iter: 0; batch classifier loss: 0.062097; batch adversarial loss: 0.452091\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044982; batch adversarial loss: 0.424091\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033971; batch adversarial loss: 0.372922\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033634; batch adversarial loss: 0.506032\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018796; batch adversarial loss: 0.588270\n",
      "epoch 191; iter: 0; batch classifier loss: 0.039353; batch adversarial loss: 0.454622\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024156; batch adversarial loss: 0.373375\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028072; batch adversarial loss: 0.482458\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021223; batch adversarial loss: 0.485800\n",
      "epoch 195; iter: 0; batch classifier loss: 0.035738; batch adversarial loss: 0.381436\n",
      "epoch 196; iter: 0; batch classifier loss: 0.057088; batch adversarial loss: 0.396622\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024547; batch adversarial loss: 0.492745\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032534; batch adversarial loss: 0.458724\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018634; batch adversarial loss: 0.553307\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677209; batch adversarial loss: 1.077965\n",
      "epoch 1; iter: 0; batch classifier loss: 0.757820; batch adversarial loss: 1.258120\n",
      "epoch 2; iter: 0; batch classifier loss: 1.058832; batch adversarial loss: 1.312948\n",
      "epoch 3; iter: 0; batch classifier loss: 1.045965; batch adversarial loss: 1.134989\n",
      "epoch 4; iter: 0; batch classifier loss: 1.147306; batch adversarial loss: 1.072974\n",
      "epoch 5; iter: 0; batch classifier loss: 1.216205; batch adversarial loss: 1.007830\n",
      "epoch 6; iter: 0; batch classifier loss: 1.237417; batch adversarial loss: 0.916452\n",
      "epoch 7; iter: 0; batch classifier loss: 1.125376; batch adversarial loss: 0.811663\n",
      "epoch 8; iter: 0; batch classifier loss: 1.006867; batch adversarial loss: 0.772956\n",
      "epoch 9; iter: 0; batch classifier loss: 0.937965; batch adversarial loss: 0.711787\n",
      "epoch 10; iter: 0; batch classifier loss: 0.873229; batch adversarial loss: 0.678717\n",
      "epoch 11; iter: 0; batch classifier loss: 0.681539; batch adversarial loss: 0.618437\n",
      "epoch 12; iter: 0; batch classifier loss: 0.630533; batch adversarial loss: 0.542642\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488424; batch adversarial loss: 0.535446\n",
      "epoch 14; iter: 0; batch classifier loss: 0.373013; batch adversarial loss: 0.505797\n",
      "epoch 15; iter: 0; batch classifier loss: 0.313201; batch adversarial loss: 0.484637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.295031; batch adversarial loss: 0.468031\n",
      "epoch 17; iter: 0; batch classifier loss: 0.246940; batch adversarial loss: 0.430650\n",
      "epoch 18; iter: 0; batch classifier loss: 0.189775; batch adversarial loss: 0.525854\n",
      "epoch 19; iter: 0; batch classifier loss: 0.229933; batch adversarial loss: 0.481820\n",
      "epoch 20; iter: 0; batch classifier loss: 0.284772; batch adversarial loss: 0.486087\n",
      "epoch 21; iter: 0; batch classifier loss: 0.232086; batch adversarial loss: 0.440896\n",
      "epoch 22; iter: 0; batch classifier loss: 0.214130; batch adversarial loss: 0.460309\n",
      "epoch 23; iter: 0; batch classifier loss: 0.266794; batch adversarial loss: 0.532071\n",
      "epoch 24; iter: 0; batch classifier loss: 0.207372; batch adversarial loss: 0.449494\n",
      "epoch 25; iter: 0; batch classifier loss: 0.193156; batch adversarial loss: 0.469310\n",
      "epoch 26; iter: 0; batch classifier loss: 0.219564; batch adversarial loss: 0.407810\n",
      "epoch 27; iter: 0; batch classifier loss: 0.177226; batch adversarial loss: 0.517021\n",
      "epoch 28; iter: 0; batch classifier loss: 0.135511; batch adversarial loss: 0.439812\n",
      "epoch 29; iter: 0; batch classifier loss: 0.137070; batch adversarial loss: 0.430299\n",
      "epoch 30; iter: 0; batch classifier loss: 0.185060; batch adversarial loss: 0.434474\n",
      "epoch 31; iter: 0; batch classifier loss: 0.197026; batch adversarial loss: 0.468422\n",
      "epoch 32; iter: 0; batch classifier loss: 0.158296; batch adversarial loss: 0.435529\n",
      "epoch 33; iter: 0; batch classifier loss: 0.168172; batch adversarial loss: 0.423314\n",
      "epoch 34; iter: 0; batch classifier loss: 0.124703; batch adversarial loss: 0.577926\n",
      "epoch 35; iter: 0; batch classifier loss: 0.102856; batch adversarial loss: 0.538021\n",
      "epoch 36; iter: 0; batch classifier loss: 0.189949; batch adversarial loss: 0.474817\n",
      "epoch 37; iter: 0; batch classifier loss: 0.178110; batch adversarial loss: 0.550576\n",
      "epoch 38; iter: 0; batch classifier loss: 0.101236; batch adversarial loss: 0.501961\n",
      "epoch 39; iter: 0; batch classifier loss: 0.158207; batch adversarial loss: 0.426546\n",
      "epoch 40; iter: 0; batch classifier loss: 0.118453; batch adversarial loss: 0.507360\n",
      "epoch 41; iter: 0; batch classifier loss: 0.191475; batch adversarial loss: 0.446359\n",
      "epoch 42; iter: 0; batch classifier loss: 0.174438; batch adversarial loss: 0.472381\n",
      "epoch 43; iter: 0; batch classifier loss: 0.151327; batch adversarial loss: 0.421484\n",
      "epoch 44; iter: 0; batch classifier loss: 0.175006; batch adversarial loss: 0.580652\n",
      "epoch 45; iter: 0; batch classifier loss: 0.152551; batch adversarial loss: 0.371810\n",
      "epoch 46; iter: 0; batch classifier loss: 0.115911; batch adversarial loss: 0.529530\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113152; batch adversarial loss: 0.429191\n",
      "epoch 48; iter: 0; batch classifier loss: 0.156406; batch adversarial loss: 0.520442\n",
      "epoch 49; iter: 0; batch classifier loss: 0.102328; batch adversarial loss: 0.517898\n",
      "epoch 50; iter: 0; batch classifier loss: 0.137542; batch adversarial loss: 0.447647\n",
      "epoch 51; iter: 0; batch classifier loss: 0.095911; batch adversarial loss: 0.458349\n",
      "epoch 52; iter: 0; batch classifier loss: 0.142701; batch adversarial loss: 0.470900\n",
      "epoch 53; iter: 0; batch classifier loss: 0.103774; batch adversarial loss: 0.395716\n",
      "epoch 54; iter: 0; batch classifier loss: 0.162059; batch adversarial loss: 0.467670\n",
      "epoch 55; iter: 0; batch classifier loss: 0.105319; batch adversarial loss: 0.422850\n",
      "epoch 56; iter: 0; batch classifier loss: 0.115941; batch adversarial loss: 0.429917\n",
      "epoch 57; iter: 0; batch classifier loss: 0.100314; batch adversarial loss: 0.420827\n",
      "epoch 58; iter: 0; batch classifier loss: 0.081250; batch adversarial loss: 0.471094\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076430; batch adversarial loss: 0.378958\n",
      "epoch 60; iter: 0; batch classifier loss: 0.064293; batch adversarial loss: 0.450293\n",
      "epoch 61; iter: 0; batch classifier loss: 0.072477; batch adversarial loss: 0.386963\n",
      "epoch 62; iter: 0; batch classifier loss: 0.133875; batch adversarial loss: 0.469547\n",
      "epoch 63; iter: 0; batch classifier loss: 0.084440; batch adversarial loss: 0.476620\n",
      "epoch 64; iter: 0; batch classifier loss: 0.126860; batch adversarial loss: 0.472104\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110367; batch adversarial loss: 0.441687\n",
      "epoch 66; iter: 0; batch classifier loss: 0.106047; batch adversarial loss: 0.454948\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094400; batch adversarial loss: 0.460137\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072797; batch adversarial loss: 0.394681\n",
      "epoch 69; iter: 0; batch classifier loss: 0.057884; batch adversarial loss: 0.438868\n",
      "epoch 70; iter: 0; batch classifier loss: 0.056071; batch adversarial loss: 0.537442\n",
      "epoch 71; iter: 0; batch classifier loss: 0.114931; batch adversarial loss: 0.464549\n",
      "epoch 72; iter: 0; batch classifier loss: 0.125900; batch adversarial loss: 0.464098\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077944; batch adversarial loss: 0.510315\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101249; batch adversarial loss: 0.472380\n",
      "epoch 75; iter: 0; batch classifier loss: 0.144892; batch adversarial loss: 0.369564\n",
      "epoch 76; iter: 0; batch classifier loss: 0.139309; batch adversarial loss: 0.472954\n",
      "epoch 77; iter: 0; batch classifier loss: 0.075069; batch adversarial loss: 0.405788\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075152; batch adversarial loss: 0.404134\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074210; batch adversarial loss: 0.472911\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083751; batch adversarial loss: 0.509800\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065279; batch adversarial loss: 0.447515\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063663; batch adversarial loss: 0.464385\n",
      "epoch 83; iter: 0; batch classifier loss: 0.099258; batch adversarial loss: 0.510675\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062863; batch adversarial loss: 0.416158\n",
      "epoch 85; iter: 0; batch classifier loss: 0.089205; batch adversarial loss: 0.502514\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072892; batch adversarial loss: 0.560437\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068241; batch adversarial loss: 0.467103\n",
      "epoch 88; iter: 0; batch classifier loss: 0.130323; batch adversarial loss: 0.381034\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080773; batch adversarial loss: 0.468059\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063015; batch adversarial loss: 0.388566\n",
      "epoch 91; iter: 0; batch classifier loss: 0.148537; batch adversarial loss: 0.488175\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074414; batch adversarial loss: 0.483844\n",
      "epoch 93; iter: 0; batch classifier loss: 0.089633; batch adversarial loss: 0.415977\n",
      "epoch 94; iter: 0; batch classifier loss: 0.071140; batch adversarial loss: 0.436562\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065967; batch adversarial loss: 0.460772\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037627; batch adversarial loss: 0.369735\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081090; batch adversarial loss: 0.437168\n",
      "epoch 98; iter: 0; batch classifier loss: 0.081655; batch adversarial loss: 0.522586\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045527; batch adversarial loss: 0.441910\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076682; batch adversarial loss: 0.393332\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063915; batch adversarial loss: 0.372178\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067412; batch adversarial loss: 0.417963\n",
      "epoch 103; iter: 0; batch classifier loss: 0.103944; batch adversarial loss: 0.482075\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055262; batch adversarial loss: 0.529637\n",
      "epoch 105; iter: 0; batch classifier loss: 0.073391; batch adversarial loss: 0.421670\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052145; batch adversarial loss: 0.417970\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066723; batch adversarial loss: 0.410483\n",
      "epoch 108; iter: 0; batch classifier loss: 0.086917; batch adversarial loss: 0.510315\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047285; batch adversarial loss: 0.407927\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047959; batch adversarial loss: 0.432273\n",
      "epoch 111; iter: 0; batch classifier loss: 0.065412; batch adversarial loss: 0.451575\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056517; batch adversarial loss: 0.447003\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031187; batch adversarial loss: 0.508932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.035287; batch adversarial loss: 0.457989\n",
      "epoch 115; iter: 0; batch classifier loss: 0.111563; batch adversarial loss: 0.361967\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051554; batch adversarial loss: 0.456461\n",
      "epoch 117; iter: 0; batch classifier loss: 0.087832; batch adversarial loss: 0.381019\n",
      "epoch 118; iter: 0; batch classifier loss: 0.075336; batch adversarial loss: 0.408840\n",
      "epoch 119; iter: 0; batch classifier loss: 0.106816; batch adversarial loss: 0.466525\n",
      "epoch 120; iter: 0; batch classifier loss: 0.059284; batch adversarial loss: 0.427667\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051745; batch adversarial loss: 0.437467\n",
      "epoch 122; iter: 0; batch classifier loss: 0.071099; batch adversarial loss: 0.466147\n",
      "epoch 123; iter: 0; batch classifier loss: 0.075048; batch adversarial loss: 0.520484\n",
      "epoch 124; iter: 0; batch classifier loss: 0.097038; batch adversarial loss: 0.450074\n",
      "epoch 125; iter: 0; batch classifier loss: 0.075141; batch adversarial loss: 0.422677\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046039; batch adversarial loss: 0.578702\n",
      "epoch 127; iter: 0; batch classifier loss: 0.087463; batch adversarial loss: 0.509109\n",
      "epoch 128; iter: 0; batch classifier loss: 0.096038; batch adversarial loss: 0.424590\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027698; batch adversarial loss: 0.490039\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030040; batch adversarial loss: 0.521946\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041072; batch adversarial loss: 0.479031\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038522; batch adversarial loss: 0.460742\n",
      "epoch 133; iter: 0; batch classifier loss: 0.065526; batch adversarial loss: 0.432339\n",
      "epoch 134; iter: 0; batch classifier loss: 0.041365; batch adversarial loss: 0.456329\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033438; batch adversarial loss: 0.401396\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036941; batch adversarial loss: 0.400635\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043067; batch adversarial loss: 0.449002\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033329; batch adversarial loss: 0.448267\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031121; batch adversarial loss: 0.491160\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017111; batch adversarial loss: 0.530555\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034443; batch adversarial loss: 0.388849\n",
      "epoch 142; iter: 0; batch classifier loss: 0.058888; batch adversarial loss: 0.481866\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046467; batch adversarial loss: 0.432047\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032463; batch adversarial loss: 0.430693\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030460; batch adversarial loss: 0.482455\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052726; batch adversarial loss: 0.497704\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021207; batch adversarial loss: 0.507947\n",
      "epoch 148; iter: 0; batch classifier loss: 0.044843; batch adversarial loss: 0.471428\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038754; batch adversarial loss: 0.435724\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033233; batch adversarial loss: 0.584364\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021172; batch adversarial loss: 0.440991\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024881; batch adversarial loss: 0.423240\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038026; batch adversarial loss: 0.429695\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032949; batch adversarial loss: 0.463406\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035091; batch adversarial loss: 0.494047\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013704; batch adversarial loss: 0.503380\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020881; batch adversarial loss: 0.542243\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018355; batch adversarial loss: 0.401935\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041595; batch adversarial loss: 0.457508\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035160; batch adversarial loss: 0.560075\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043394; batch adversarial loss: 0.398812\n",
      "epoch 162; iter: 0; batch classifier loss: 0.047149; batch adversarial loss: 0.429166\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015850; batch adversarial loss: 0.472561\n",
      "epoch 164; iter: 0; batch classifier loss: 0.046355; batch adversarial loss: 0.395285\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012911; batch adversarial loss: 0.365072\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014419; batch adversarial loss: 0.466549\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021470; batch adversarial loss: 0.424068\n",
      "epoch 168; iter: 0; batch classifier loss: 0.043817; batch adversarial loss: 0.492697\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009856; batch adversarial loss: 0.355633\n",
      "epoch 170; iter: 0; batch classifier loss: 0.052275; batch adversarial loss: 0.457766\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029104; batch adversarial loss: 0.357215\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015162; batch adversarial loss: 0.520462\n",
      "epoch 173; iter: 0; batch classifier loss: 0.003798; batch adversarial loss: 0.581205\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033917; batch adversarial loss: 0.477593\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042847; batch adversarial loss: 0.398245\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020378; batch adversarial loss: 0.389327\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019788; batch adversarial loss: 0.474656\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024859; batch adversarial loss: 0.424447\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027095; batch adversarial loss: 0.496518\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014886; batch adversarial loss: 0.401766\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020677; batch adversarial loss: 0.479054\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018107; batch adversarial loss: 0.431275\n",
      "epoch 183; iter: 0; batch classifier loss: 0.064561; batch adversarial loss: 0.482535\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021460; batch adversarial loss: 0.458398\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032784; batch adversarial loss: 0.421434\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011440; batch adversarial loss: 0.460450\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005673; batch adversarial loss: 0.488413\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021723; batch adversarial loss: 0.487766\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018463; batch adversarial loss: 0.375099\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032663; batch adversarial loss: 0.403633\n",
      "epoch 191; iter: 0; batch classifier loss: 0.040329; batch adversarial loss: 0.501750\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016252; batch adversarial loss: 0.424073\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027397; batch adversarial loss: 0.466627\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028466; batch adversarial loss: 0.412532\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009461; batch adversarial loss: 0.390307\n",
      "epoch 196; iter: 0; batch classifier loss: 0.003279; batch adversarial loss: 0.402041\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006048; batch adversarial loss: 0.436783\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007007; batch adversarial loss: 0.480966\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014397; batch adversarial loss: 0.477642\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700133; batch adversarial loss: 0.605483\n",
      "epoch 1; iter: 0; batch classifier loss: 0.416504; batch adversarial loss: 0.618989\n",
      "epoch 2; iter: 0; batch classifier loss: 0.365689; batch adversarial loss: 0.614676\n",
      "epoch 3; iter: 0; batch classifier loss: 0.444216; batch adversarial loss: 0.587807\n",
      "epoch 4; iter: 0; batch classifier loss: 0.362254; batch adversarial loss: 0.577313\n",
      "epoch 5; iter: 0; batch classifier loss: 0.386026; batch adversarial loss: 0.573240\n",
      "epoch 6; iter: 0; batch classifier loss: 0.246844; batch adversarial loss: 0.520131\n",
      "epoch 7; iter: 0; batch classifier loss: 0.277332; batch adversarial loss: 0.559272\n",
      "epoch 8; iter: 0; batch classifier loss: 0.219868; batch adversarial loss: 0.520334\n",
      "epoch 9; iter: 0; batch classifier loss: 0.226093; batch adversarial loss: 0.547028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.256859; batch adversarial loss: 0.495850\n",
      "epoch 11; iter: 0; batch classifier loss: 0.251960; batch adversarial loss: 0.538010\n",
      "epoch 12; iter: 0; batch classifier loss: 0.258442; batch adversarial loss: 0.573667\n",
      "epoch 13; iter: 0; batch classifier loss: 0.226023; batch adversarial loss: 0.458564\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263633; batch adversarial loss: 0.493930\n",
      "epoch 15; iter: 0; batch classifier loss: 0.277426; batch adversarial loss: 0.590460\n",
      "epoch 16; iter: 0; batch classifier loss: 0.265719; batch adversarial loss: 0.579923\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262027; batch adversarial loss: 0.570580\n",
      "epoch 18; iter: 0; batch classifier loss: 0.191141; batch adversarial loss: 0.444630\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261213; batch adversarial loss: 0.573998\n",
      "epoch 20; iter: 0; batch classifier loss: 0.282195; batch adversarial loss: 0.523152\n",
      "epoch 21; iter: 0; batch classifier loss: 0.307437; batch adversarial loss: 0.467574\n",
      "epoch 22; iter: 0; batch classifier loss: 0.424220; batch adversarial loss: 0.519851\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477028; batch adversarial loss: 0.528343\n",
      "epoch 24; iter: 0; batch classifier loss: 0.259002; batch adversarial loss: 0.568713\n",
      "epoch 25; iter: 0; batch classifier loss: 0.170892; batch adversarial loss: 0.542696\n",
      "epoch 26; iter: 0; batch classifier loss: 0.200422; batch adversarial loss: 0.429700\n",
      "epoch 27; iter: 0; batch classifier loss: 0.139266; batch adversarial loss: 0.511910\n",
      "epoch 28; iter: 0; batch classifier loss: 0.163724; batch adversarial loss: 0.511167\n",
      "epoch 29; iter: 0; batch classifier loss: 0.139423; batch adversarial loss: 0.406872\n",
      "epoch 30; iter: 0; batch classifier loss: 0.146207; batch adversarial loss: 0.467808\n",
      "epoch 31; iter: 0; batch classifier loss: 0.120278; batch adversarial loss: 0.526286\n",
      "epoch 32; iter: 0; batch classifier loss: 0.089187; batch adversarial loss: 0.461999\n",
      "epoch 33; iter: 0; batch classifier loss: 0.129277; batch adversarial loss: 0.600623\n",
      "epoch 34; iter: 0; batch classifier loss: 0.130346; batch adversarial loss: 0.437972\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122615; batch adversarial loss: 0.399722\n",
      "epoch 36; iter: 0; batch classifier loss: 0.100103; batch adversarial loss: 0.420810\n",
      "epoch 37; iter: 0; batch classifier loss: 0.095849; batch adversarial loss: 0.443547\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107554; batch adversarial loss: 0.422017\n",
      "epoch 39; iter: 0; batch classifier loss: 0.103924; batch adversarial loss: 0.523332\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103535; batch adversarial loss: 0.555890\n",
      "epoch 41; iter: 0; batch classifier loss: 0.085114; batch adversarial loss: 0.500212\n",
      "epoch 42; iter: 0; batch classifier loss: 0.087205; batch adversarial loss: 0.545224\n",
      "epoch 43; iter: 0; batch classifier loss: 0.105904; batch adversarial loss: 0.565950\n",
      "epoch 44; iter: 0; batch classifier loss: 0.077052; batch adversarial loss: 0.488135\n",
      "epoch 45; iter: 0; batch classifier loss: 0.145252; batch adversarial loss: 0.449841\n",
      "epoch 46; iter: 0; batch classifier loss: 0.109469; batch adversarial loss: 0.529098\n",
      "epoch 47; iter: 0; batch classifier loss: 0.088168; batch adversarial loss: 0.452132\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082666; batch adversarial loss: 0.388583\n",
      "epoch 49; iter: 0; batch classifier loss: 0.076103; batch adversarial loss: 0.492428\n",
      "epoch 50; iter: 0; batch classifier loss: 0.120493; batch adversarial loss: 0.575597\n",
      "epoch 51; iter: 0; batch classifier loss: 0.131556; batch adversarial loss: 0.513150\n",
      "epoch 52; iter: 0; batch classifier loss: 0.090251; batch adversarial loss: 0.495307\n",
      "epoch 53; iter: 0; batch classifier loss: 0.137465; batch adversarial loss: 0.479527\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127892; batch adversarial loss: 0.403398\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083718; batch adversarial loss: 0.502866\n",
      "epoch 56; iter: 0; batch classifier loss: 0.139370; batch adversarial loss: 0.499668\n",
      "epoch 57; iter: 0; batch classifier loss: 0.130570; batch adversarial loss: 0.448299\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090094; batch adversarial loss: 0.486025\n",
      "epoch 59; iter: 0; batch classifier loss: 0.154524; batch adversarial loss: 0.448997\n",
      "epoch 60; iter: 0; batch classifier loss: 0.132049; batch adversarial loss: 0.560390\n",
      "epoch 61; iter: 0; batch classifier loss: 0.055924; batch adversarial loss: 0.532841\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101283; batch adversarial loss: 0.375967\n",
      "epoch 63; iter: 0; batch classifier loss: 0.138688; batch adversarial loss: 0.431092\n",
      "epoch 64; iter: 0; batch classifier loss: 0.116667; batch adversarial loss: 0.452642\n",
      "epoch 65; iter: 0; batch classifier loss: 0.149194; batch adversarial loss: 0.465390\n",
      "epoch 66; iter: 0; batch classifier loss: 0.077933; batch adversarial loss: 0.517902\n",
      "epoch 67; iter: 0; batch classifier loss: 0.142714; batch adversarial loss: 0.491179\n",
      "epoch 68; iter: 0; batch classifier loss: 0.092734; batch adversarial loss: 0.483979\n",
      "epoch 69; iter: 0; batch classifier loss: 0.098139; batch adversarial loss: 0.503979\n",
      "epoch 70; iter: 0; batch classifier loss: 0.080359; batch adversarial loss: 0.531969\n",
      "epoch 71; iter: 0; batch classifier loss: 0.100933; batch adversarial loss: 0.482842\n",
      "epoch 72; iter: 0; batch classifier loss: 0.145510; batch adversarial loss: 0.412039\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101855; batch adversarial loss: 0.429135\n",
      "epoch 74; iter: 0; batch classifier loss: 0.109042; batch adversarial loss: 0.519412\n",
      "epoch 75; iter: 0; batch classifier loss: 0.105089; batch adversarial loss: 0.400522\n",
      "epoch 76; iter: 0; batch classifier loss: 0.115714; batch adversarial loss: 0.430311\n",
      "epoch 77; iter: 0; batch classifier loss: 0.115213; batch adversarial loss: 0.387582\n",
      "epoch 78; iter: 0; batch classifier loss: 0.157492; batch adversarial loss: 0.465716\n",
      "epoch 79; iter: 0; batch classifier loss: 0.144232; batch adversarial loss: 0.469720\n",
      "epoch 80; iter: 0; batch classifier loss: 0.134655; batch adversarial loss: 0.490839\n",
      "epoch 81; iter: 0; batch classifier loss: 0.089636; batch adversarial loss: 0.542179\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091963; batch adversarial loss: 0.447536\n",
      "epoch 83; iter: 0; batch classifier loss: 0.104219; batch adversarial loss: 0.536429\n",
      "epoch 84; iter: 0; batch classifier loss: 0.113051; batch adversarial loss: 0.469687\n",
      "epoch 85; iter: 0; batch classifier loss: 0.159985; batch adversarial loss: 0.481377\n",
      "epoch 86; iter: 0; batch classifier loss: 0.098304; batch adversarial loss: 0.419475\n",
      "epoch 87; iter: 0; batch classifier loss: 0.088261; batch adversarial loss: 0.355921\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059132; batch adversarial loss: 0.465377\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081555; batch adversarial loss: 0.492079\n",
      "epoch 90; iter: 0; batch classifier loss: 0.164789; batch adversarial loss: 0.397323\n",
      "epoch 91; iter: 0; batch classifier loss: 0.105795; batch adversarial loss: 0.473526\n",
      "epoch 92; iter: 0; batch classifier loss: 0.083230; batch adversarial loss: 0.486498\n",
      "epoch 93; iter: 0; batch classifier loss: 0.100445; batch adversarial loss: 0.429897\n",
      "epoch 94; iter: 0; batch classifier loss: 0.119709; batch adversarial loss: 0.537067\n",
      "epoch 95; iter: 0; batch classifier loss: 0.069057; batch adversarial loss: 0.555483\n",
      "epoch 96; iter: 0; batch classifier loss: 0.090492; batch adversarial loss: 0.420426\n",
      "epoch 97; iter: 0; batch classifier loss: 0.078069; batch adversarial loss: 0.538722\n",
      "epoch 98; iter: 0; batch classifier loss: 0.105639; batch adversarial loss: 0.373173\n",
      "epoch 99; iter: 0; batch classifier loss: 0.138462; batch adversarial loss: 0.536262\n",
      "epoch 100; iter: 0; batch classifier loss: 0.063579; batch adversarial loss: 0.521903\n",
      "epoch 101; iter: 0; batch classifier loss: 0.095456; batch adversarial loss: 0.486760\n",
      "epoch 102; iter: 0; batch classifier loss: 0.112321; batch adversarial loss: 0.568167\n",
      "epoch 103; iter: 0; batch classifier loss: 0.134517; batch adversarial loss: 0.495112\n",
      "epoch 104; iter: 0; batch classifier loss: 0.113728; batch adversarial loss: 0.402580\n",
      "epoch 105; iter: 0; batch classifier loss: 0.096216; batch adversarial loss: 0.483714\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055443; batch adversarial loss: 0.496184\n",
      "epoch 107; iter: 0; batch classifier loss: 0.124591; batch adversarial loss: 0.448668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.109100; batch adversarial loss: 0.416572\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058599; batch adversarial loss: 0.404337\n",
      "epoch 110; iter: 0; batch classifier loss: 0.070646; batch adversarial loss: 0.414332\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055142; batch adversarial loss: 0.363668\n",
      "epoch 112; iter: 0; batch classifier loss: 0.066533; batch adversarial loss: 0.458045\n",
      "epoch 113; iter: 0; batch classifier loss: 0.070849; batch adversarial loss: 0.385338\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056188; batch adversarial loss: 0.483560\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046684; batch adversarial loss: 0.512202\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059037; batch adversarial loss: 0.380973\n",
      "epoch 117; iter: 0; batch classifier loss: 0.086208; batch adversarial loss: 0.570689\n",
      "epoch 118; iter: 0; batch classifier loss: 0.064514; batch adversarial loss: 0.454797\n",
      "epoch 119; iter: 0; batch classifier loss: 0.062223; batch adversarial loss: 0.460696\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057646; batch adversarial loss: 0.382959\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043903; batch adversarial loss: 0.465273\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036540; batch adversarial loss: 0.508220\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033534; batch adversarial loss: 0.461226\n",
      "epoch 124; iter: 0; batch classifier loss: 0.062426; batch adversarial loss: 0.492407\n",
      "epoch 125; iter: 0; batch classifier loss: 0.059573; batch adversarial loss: 0.395699\n",
      "epoch 126; iter: 0; batch classifier loss: 0.069845; batch adversarial loss: 0.429270\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029673; batch adversarial loss: 0.509621\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063731; batch adversarial loss: 0.453399\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042730; batch adversarial loss: 0.387779\n",
      "epoch 130; iter: 0; batch classifier loss: 0.071413; batch adversarial loss: 0.528439\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048229; batch adversarial loss: 0.476203\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033647; batch adversarial loss: 0.482270\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037431; batch adversarial loss: 0.512518\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042603; batch adversarial loss: 0.514909\n",
      "epoch 135; iter: 0; batch classifier loss: 0.077817; batch adversarial loss: 0.495249\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031561; batch adversarial loss: 0.445289\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046575; batch adversarial loss: 0.417327\n",
      "epoch 138; iter: 0; batch classifier loss: 0.059461; batch adversarial loss: 0.504002\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025552; batch adversarial loss: 0.462405\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033082; batch adversarial loss: 0.421208\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023658; batch adversarial loss: 0.479361\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028923; batch adversarial loss: 0.451831\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031515; batch adversarial loss: 0.530227\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038129; batch adversarial loss: 0.489014\n",
      "epoch 145; iter: 0; batch classifier loss: 0.118556; batch adversarial loss: 0.477801\n",
      "epoch 146; iter: 0; batch classifier loss: 0.036185; batch adversarial loss: 0.401601\n",
      "epoch 147; iter: 0; batch classifier loss: 0.049437; batch adversarial loss: 0.420191\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032544; batch adversarial loss: 0.521747\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025520; batch adversarial loss: 0.451480\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039432; batch adversarial loss: 0.434729\n",
      "epoch 151; iter: 0; batch classifier loss: 0.057704; batch adversarial loss: 0.442463\n",
      "epoch 152; iter: 0; batch classifier loss: 0.081829; batch adversarial loss: 0.463127\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014860; batch adversarial loss: 0.434973\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017964; batch adversarial loss: 0.400096\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044692; batch adversarial loss: 0.522890\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029154; batch adversarial loss: 0.489356\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037203; batch adversarial loss: 0.515978\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035695; batch adversarial loss: 0.459292\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023902; batch adversarial loss: 0.570073\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032090; batch adversarial loss: 0.391030\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039905; batch adversarial loss: 0.554568\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040499; batch adversarial loss: 0.437792\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028541; batch adversarial loss: 0.466642\n",
      "epoch 164; iter: 0; batch classifier loss: 0.044661; batch adversarial loss: 0.469852\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026361; batch adversarial loss: 0.505063\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033589; batch adversarial loss: 0.420981\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027254; batch adversarial loss: 0.464368\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029060; batch adversarial loss: 0.384890\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017908; batch adversarial loss: 0.525783\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026164; batch adversarial loss: 0.483814\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026973; batch adversarial loss: 0.577258\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022535; batch adversarial loss: 0.430827\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023454; batch adversarial loss: 0.533180\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014981; batch adversarial loss: 0.465350\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018545; batch adversarial loss: 0.478966\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039824; batch adversarial loss: 0.477373\n",
      "epoch 177; iter: 0; batch classifier loss: 0.043294; batch adversarial loss: 0.474263\n",
      "epoch 178; iter: 0; batch classifier loss: 0.042265; batch adversarial loss: 0.414775\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035327; batch adversarial loss: 0.573103\n",
      "epoch 180; iter: 0; batch classifier loss: 0.044968; batch adversarial loss: 0.475327\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025281; batch adversarial loss: 0.471312\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030170; batch adversarial loss: 0.460178\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027568; batch adversarial loss: 0.509027\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038174; batch adversarial loss: 0.463777\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032453; batch adversarial loss: 0.424207\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027395; batch adversarial loss: 0.440492\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024197; batch adversarial loss: 0.483942\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015566; batch adversarial loss: 0.581025\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015869; batch adversarial loss: 0.585397\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022736; batch adversarial loss: 0.505716\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022180; batch adversarial loss: 0.397719\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037733; batch adversarial loss: 0.405100\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012112; batch adversarial loss: 0.432465\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020204; batch adversarial loss: 0.543198\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019045; batch adversarial loss: 0.520902\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013587; batch adversarial loss: 0.424166\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010615; batch adversarial loss: 0.449250\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010642; batch adversarial loss: 0.435030\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025608; batch adversarial loss: 0.514565\n",
      "epoch 0; iter: 0; batch classifier loss: 0.661153; batch adversarial loss: 0.719631\n",
      "epoch 1; iter: 0; batch classifier loss: 0.471152; batch adversarial loss: 0.681584\n",
      "epoch 2; iter: 0; batch classifier loss: 0.390433; batch adversarial loss: 0.646945\n",
      "epoch 3; iter: 0; batch classifier loss: 0.336306; batch adversarial loss: 0.602472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.284885; batch adversarial loss: 0.577504\n",
      "epoch 5; iter: 0; batch classifier loss: 0.373396; batch adversarial loss: 0.548936\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315384; batch adversarial loss: 0.504201\n",
      "epoch 7; iter: 0; batch classifier loss: 0.303716; batch adversarial loss: 0.487045\n",
      "epoch 8; iter: 0; batch classifier loss: 0.350174; batch adversarial loss: 0.545359\n",
      "epoch 9; iter: 0; batch classifier loss: 0.230403; batch adversarial loss: 0.492848\n",
      "epoch 10; iter: 0; batch classifier loss: 0.178804; batch adversarial loss: 0.503033\n",
      "epoch 11; iter: 0; batch classifier loss: 0.225905; batch adversarial loss: 0.508651\n",
      "epoch 12; iter: 0; batch classifier loss: 0.232592; batch adversarial loss: 0.470467\n",
      "epoch 13; iter: 0; batch classifier loss: 0.166202; batch adversarial loss: 0.510350\n",
      "epoch 14; iter: 0; batch classifier loss: 0.211739; batch adversarial loss: 0.469826\n",
      "epoch 15; iter: 0; batch classifier loss: 0.261578; batch adversarial loss: 0.456377\n",
      "epoch 16; iter: 0; batch classifier loss: 0.159515; batch adversarial loss: 0.466165\n",
      "epoch 17; iter: 0; batch classifier loss: 0.150736; batch adversarial loss: 0.478340\n",
      "epoch 18; iter: 0; batch classifier loss: 0.140909; batch adversarial loss: 0.417543\n",
      "epoch 19; iter: 0; batch classifier loss: 0.204721; batch adversarial loss: 0.534080\n",
      "epoch 20; iter: 0; batch classifier loss: 0.287754; batch adversarial loss: 0.536095\n",
      "epoch 21; iter: 0; batch classifier loss: 0.223046; batch adversarial loss: 0.355989\n",
      "epoch 22; iter: 0; batch classifier loss: 0.262729; batch adversarial loss: 0.485636\n",
      "epoch 23; iter: 0; batch classifier loss: 0.400910; batch adversarial loss: 0.496199\n",
      "epoch 24; iter: 0; batch classifier loss: 0.372620; batch adversarial loss: 0.523104\n",
      "epoch 25; iter: 0; batch classifier loss: 0.257074; batch adversarial loss: 0.522364\n",
      "epoch 26; iter: 0; batch classifier loss: 0.213645; batch adversarial loss: 0.442162\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140939; batch adversarial loss: 0.431659\n",
      "epoch 28; iter: 0; batch classifier loss: 0.141580; batch adversarial loss: 0.535854\n",
      "epoch 29; iter: 0; batch classifier loss: 0.152801; batch adversarial loss: 0.483502\n",
      "epoch 30; iter: 0; batch classifier loss: 0.117607; batch adversarial loss: 0.478972\n",
      "epoch 31; iter: 0; batch classifier loss: 0.111731; batch adversarial loss: 0.524080\n",
      "epoch 32; iter: 0; batch classifier loss: 0.076509; batch adversarial loss: 0.516072\n",
      "epoch 33; iter: 0; batch classifier loss: 0.141588; batch adversarial loss: 0.421570\n",
      "epoch 34; iter: 0; batch classifier loss: 0.104562; batch adversarial loss: 0.399242\n",
      "epoch 35; iter: 0; batch classifier loss: 0.111250; batch adversarial loss: 0.389534\n",
      "epoch 36; iter: 0; batch classifier loss: 0.086379; batch adversarial loss: 0.511794\n",
      "epoch 37; iter: 0; batch classifier loss: 0.133689; batch adversarial loss: 0.477217\n",
      "epoch 38; iter: 0; batch classifier loss: 0.101043; batch adversarial loss: 0.417518\n",
      "epoch 39; iter: 0; batch classifier loss: 0.086118; batch adversarial loss: 0.420221\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103846; batch adversarial loss: 0.501253\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104736; batch adversarial loss: 0.427866\n",
      "epoch 42; iter: 0; batch classifier loss: 0.067628; batch adversarial loss: 0.423245\n",
      "epoch 43; iter: 0; batch classifier loss: 0.132863; batch adversarial loss: 0.505836\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097323; batch adversarial loss: 0.431227\n",
      "epoch 45; iter: 0; batch classifier loss: 0.115178; batch adversarial loss: 0.383671\n",
      "epoch 46; iter: 0; batch classifier loss: 0.084578; batch adversarial loss: 0.523047\n",
      "epoch 47; iter: 0; batch classifier loss: 0.093803; batch adversarial loss: 0.426845\n",
      "epoch 48; iter: 0; batch classifier loss: 0.102939; batch adversarial loss: 0.411547\n",
      "epoch 49; iter: 0; batch classifier loss: 0.071503; batch adversarial loss: 0.516565\n",
      "epoch 50; iter: 0; batch classifier loss: 0.035897; batch adversarial loss: 0.460286\n",
      "epoch 51; iter: 0; batch classifier loss: 0.102764; batch adversarial loss: 0.519978\n",
      "epoch 52; iter: 0; batch classifier loss: 0.064546; batch adversarial loss: 0.496527\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076641; batch adversarial loss: 0.514232\n",
      "epoch 54; iter: 0; batch classifier loss: 0.119724; batch adversarial loss: 0.412272\n",
      "epoch 55; iter: 0; batch classifier loss: 0.120554; batch adversarial loss: 0.499220\n",
      "epoch 56; iter: 0; batch classifier loss: 0.117477; batch adversarial loss: 0.469669\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106733; batch adversarial loss: 0.363128\n",
      "epoch 58; iter: 0; batch classifier loss: 0.066130; batch adversarial loss: 0.463085\n",
      "epoch 59; iter: 0; batch classifier loss: 0.054719; batch adversarial loss: 0.511838\n",
      "epoch 60; iter: 0; batch classifier loss: 0.124366; batch adversarial loss: 0.475055\n",
      "epoch 61; iter: 0; batch classifier loss: 0.053404; batch adversarial loss: 0.491560\n",
      "epoch 62; iter: 0; batch classifier loss: 0.066223; batch adversarial loss: 0.478344\n",
      "epoch 63; iter: 0; batch classifier loss: 0.068073; batch adversarial loss: 0.437045\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072992; batch adversarial loss: 0.464596\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073200; batch adversarial loss: 0.488876\n",
      "epoch 66; iter: 0; batch classifier loss: 0.057946; batch adversarial loss: 0.486959\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094204; batch adversarial loss: 0.576301\n",
      "epoch 68; iter: 0; batch classifier loss: 0.045361; batch adversarial loss: 0.505953\n",
      "epoch 69; iter: 0; batch classifier loss: 0.056309; batch adversarial loss: 0.540164\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091376; batch adversarial loss: 0.350661\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078055; batch adversarial loss: 0.505705\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064234; batch adversarial loss: 0.436237\n",
      "epoch 73; iter: 0; batch classifier loss: 0.052731; batch adversarial loss: 0.397928\n",
      "epoch 74; iter: 0; batch classifier loss: 0.098264; batch adversarial loss: 0.451977\n",
      "epoch 75; iter: 0; batch classifier loss: 0.070364; batch adversarial loss: 0.481462\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075364; batch adversarial loss: 0.489590\n",
      "epoch 77; iter: 0; batch classifier loss: 0.052426; batch adversarial loss: 0.416753\n",
      "epoch 78; iter: 0; batch classifier loss: 0.050539; batch adversarial loss: 0.417632\n",
      "epoch 79; iter: 0; batch classifier loss: 0.079125; batch adversarial loss: 0.351537\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056471; batch adversarial loss: 0.464050\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074465; batch adversarial loss: 0.435143\n",
      "epoch 82; iter: 0; batch classifier loss: 0.049451; batch adversarial loss: 0.440117\n",
      "epoch 83; iter: 0; batch classifier loss: 0.050465; batch adversarial loss: 0.495597\n",
      "epoch 84; iter: 0; batch classifier loss: 0.092236; batch adversarial loss: 0.425698\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073420; batch adversarial loss: 0.479779\n",
      "epoch 86; iter: 0; batch classifier loss: 0.044525; batch adversarial loss: 0.459858\n",
      "epoch 87; iter: 0; batch classifier loss: 0.037467; batch adversarial loss: 0.441546\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055825; batch adversarial loss: 0.377702\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063108; batch adversarial loss: 0.528088\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053190; batch adversarial loss: 0.436265\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077029; batch adversarial loss: 0.375724\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063565; batch adversarial loss: 0.460338\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071148; batch adversarial loss: 0.495235\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041336; batch adversarial loss: 0.477347\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064327; batch adversarial loss: 0.351973\n",
      "epoch 96; iter: 0; batch classifier loss: 0.028479; batch adversarial loss: 0.476256\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073292; batch adversarial loss: 0.467186\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079149; batch adversarial loss: 0.404978\n",
      "epoch 99; iter: 0; batch classifier loss: 0.036834; batch adversarial loss: 0.470703\n",
      "epoch 100; iter: 0; batch classifier loss: 0.041716; batch adversarial loss: 0.473968\n",
      "epoch 101; iter: 0; batch classifier loss: 0.100805; batch adversarial loss: 0.486207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.016574; batch adversarial loss: 0.520126\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071082; batch adversarial loss: 0.519680\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056228; batch adversarial loss: 0.472777\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036933; batch adversarial loss: 0.523584\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030975; batch adversarial loss: 0.392358\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048560; batch adversarial loss: 0.433200\n",
      "epoch 108; iter: 0; batch classifier loss: 0.019405; batch adversarial loss: 0.430130\n",
      "epoch 109; iter: 0; batch classifier loss: 0.024328; batch adversarial loss: 0.452412\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047753; batch adversarial loss: 0.383140\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040840; batch adversarial loss: 0.385214\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024159; batch adversarial loss: 0.453176\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033171; batch adversarial loss: 0.506574\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059098; batch adversarial loss: 0.540344\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031929; batch adversarial loss: 0.462679\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027899; batch adversarial loss: 0.528748\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034903; batch adversarial loss: 0.405128\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041543; batch adversarial loss: 0.453791\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034830; batch adversarial loss: 0.479955\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031116; batch adversarial loss: 0.448431\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037890; batch adversarial loss: 0.346718\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025035; batch adversarial loss: 0.451879\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040864; batch adversarial loss: 0.418808\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024134; batch adversarial loss: 0.465720\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023941; batch adversarial loss: 0.343620\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048119; batch adversarial loss: 0.503032\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030276; batch adversarial loss: 0.475980\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043815; batch adversarial loss: 0.403750\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025159; batch adversarial loss: 0.397719\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030569; batch adversarial loss: 0.462753\n",
      "epoch 131; iter: 0; batch classifier loss: 0.010522; batch adversarial loss: 0.451617\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032986; batch adversarial loss: 0.404190\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040922; batch adversarial loss: 0.425649\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051964; batch adversarial loss: 0.406265\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035540; batch adversarial loss: 0.380308\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043295; batch adversarial loss: 0.553061\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029713; batch adversarial loss: 0.534339\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014081; batch adversarial loss: 0.501323\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015525; batch adversarial loss: 0.401092\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018896; batch adversarial loss: 0.537521\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024308; batch adversarial loss: 0.437020\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029442; batch adversarial loss: 0.489078\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051767; batch adversarial loss: 0.530758\n",
      "epoch 144; iter: 0; batch classifier loss: 0.011452; batch adversarial loss: 0.443383\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029741; batch adversarial loss: 0.539003\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027402; batch adversarial loss: 0.451265\n",
      "epoch 147; iter: 0; batch classifier loss: 0.009859; batch adversarial loss: 0.459114\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018820; batch adversarial loss: 0.473230\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038749; batch adversarial loss: 0.410745\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025271; batch adversarial loss: 0.372089\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034817; batch adversarial loss: 0.426054\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036616; batch adversarial loss: 0.399169\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028094; batch adversarial loss: 0.507857\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016130; batch adversarial loss: 0.477683\n",
      "epoch 155; iter: 0; batch classifier loss: 0.056386; batch adversarial loss: 0.457390\n",
      "epoch 156; iter: 0; batch classifier loss: 0.047930; batch adversarial loss: 0.443979\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017849; batch adversarial loss: 0.480317\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027296; batch adversarial loss: 0.491873\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025012; batch adversarial loss: 0.443884\n",
      "epoch 160; iter: 0; batch classifier loss: 0.056450; batch adversarial loss: 0.489501\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014359; batch adversarial loss: 0.376095\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015056; batch adversarial loss: 0.322644\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042544; batch adversarial loss: 0.409880\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021358; batch adversarial loss: 0.463728\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018069; batch adversarial loss: 0.448075\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013853; batch adversarial loss: 0.490531\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007548; batch adversarial loss: 0.498801\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009932; batch adversarial loss: 0.445240\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035262; batch adversarial loss: 0.508006\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008582; batch adversarial loss: 0.371578\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018209; batch adversarial loss: 0.416921\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023035; batch adversarial loss: 0.441853\n",
      "epoch 173; iter: 0; batch classifier loss: 0.004893; batch adversarial loss: 0.415877\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029574; batch adversarial loss: 0.502123\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034090; batch adversarial loss: 0.472295\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014304; batch adversarial loss: 0.545508\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012845; batch adversarial loss: 0.432236\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018247; batch adversarial loss: 0.430861\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034939; batch adversarial loss: 0.474855\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007917; batch adversarial loss: 0.450184\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023663; batch adversarial loss: 0.400665\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016091; batch adversarial loss: 0.504604\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010647; batch adversarial loss: 0.441484\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023084; batch adversarial loss: 0.561213\n",
      "epoch 185; iter: 0; batch classifier loss: 0.056458; batch adversarial loss: 0.439563\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020345; batch adversarial loss: 0.402785\n",
      "epoch 187; iter: 0; batch classifier loss: 0.038475; batch adversarial loss: 0.416718\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026170; batch adversarial loss: 0.548252\n",
      "epoch 189; iter: 0; batch classifier loss: 0.093380; batch adversarial loss: 0.408294\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013543; batch adversarial loss: 0.351102\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015638; batch adversarial loss: 0.374475\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015437; batch adversarial loss: 0.473981\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019141; batch adversarial loss: 0.503389\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034663; batch adversarial loss: 0.514468\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010827; batch adversarial loss: 0.466195\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006976; batch adversarial loss: 0.431065\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008609; batch adversarial loss: 0.433627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.008772; batch adversarial loss: 0.453139\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006535; batch adversarial loss: 0.544664\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677030; batch adversarial loss: 0.923147\n",
      "epoch 1; iter: 0; batch classifier loss: 0.688782; batch adversarial loss: 0.979832\n",
      "epoch 2; iter: 0; batch classifier loss: 0.962492; batch adversarial loss: 1.105094\n",
      "epoch 3; iter: 0; batch classifier loss: 1.007166; batch adversarial loss: 1.002461\n",
      "epoch 4; iter: 0; batch classifier loss: 0.915910; batch adversarial loss: 0.889874\n",
      "epoch 5; iter: 0; batch classifier loss: 0.813003; batch adversarial loss: 0.764679\n",
      "epoch 6; iter: 0; batch classifier loss: 0.701284; batch adversarial loss: 0.726495\n",
      "epoch 7; iter: 0; batch classifier loss: 0.712698; batch adversarial loss: 0.706809\n",
      "epoch 8; iter: 0; batch classifier loss: 0.663458; batch adversarial loss: 0.631087\n",
      "epoch 9; iter: 0; batch classifier loss: 0.486172; batch adversarial loss: 0.619812\n",
      "epoch 10; iter: 0; batch classifier loss: 0.421480; batch adversarial loss: 0.556745\n",
      "epoch 11; iter: 0; batch classifier loss: 0.363607; batch adversarial loss: 0.532872\n",
      "epoch 12; iter: 0; batch classifier loss: 0.335700; batch adversarial loss: 0.596748\n",
      "epoch 13; iter: 0; batch classifier loss: 0.274831; batch adversarial loss: 0.490710\n",
      "epoch 14; iter: 0; batch classifier loss: 0.328324; batch adversarial loss: 0.506919\n",
      "epoch 15; iter: 0; batch classifier loss: 0.225193; batch adversarial loss: 0.498888\n",
      "epoch 16; iter: 0; batch classifier loss: 0.251685; batch adversarial loss: 0.562542\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221387; batch adversarial loss: 0.467214\n",
      "epoch 18; iter: 0; batch classifier loss: 0.266039; batch adversarial loss: 0.524893\n",
      "epoch 19; iter: 0; batch classifier loss: 0.191150; batch adversarial loss: 0.519230\n",
      "epoch 20; iter: 0; batch classifier loss: 0.232845; batch adversarial loss: 0.462645\n",
      "epoch 21; iter: 0; batch classifier loss: 0.204555; batch adversarial loss: 0.470924\n",
      "epoch 22; iter: 0; batch classifier loss: 0.174347; batch adversarial loss: 0.414936\n",
      "epoch 23; iter: 0; batch classifier loss: 0.193577; batch adversarial loss: 0.414178\n",
      "epoch 24; iter: 0; batch classifier loss: 0.138104; batch adversarial loss: 0.503565\n",
      "epoch 25; iter: 0; batch classifier loss: 0.152855; batch adversarial loss: 0.467598\n",
      "epoch 26; iter: 0; batch classifier loss: 0.159847; batch adversarial loss: 0.596398\n",
      "epoch 27; iter: 0; batch classifier loss: 0.160802; batch adversarial loss: 0.413526\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179463; batch adversarial loss: 0.497516\n",
      "epoch 29; iter: 0; batch classifier loss: 0.112167; batch adversarial loss: 0.567107\n",
      "epoch 30; iter: 0; batch classifier loss: 0.183208; batch adversarial loss: 0.447537\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166289; batch adversarial loss: 0.501484\n",
      "epoch 32; iter: 0; batch classifier loss: 0.133733; batch adversarial loss: 0.487204\n",
      "epoch 33; iter: 0; batch classifier loss: 0.174741; batch adversarial loss: 0.429821\n",
      "epoch 34; iter: 0; batch classifier loss: 0.146724; batch adversarial loss: 0.567319\n",
      "epoch 35; iter: 0; batch classifier loss: 0.175153; batch adversarial loss: 0.504600\n",
      "epoch 36; iter: 0; batch classifier loss: 0.162067; batch adversarial loss: 0.540477\n",
      "epoch 37; iter: 0; batch classifier loss: 0.120104; batch adversarial loss: 0.459329\n",
      "epoch 38; iter: 0; batch classifier loss: 0.141125; batch adversarial loss: 0.498443\n",
      "epoch 39; iter: 0; batch classifier loss: 0.182943; batch adversarial loss: 0.532539\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154682; batch adversarial loss: 0.451410\n",
      "epoch 41; iter: 0; batch classifier loss: 0.196562; batch adversarial loss: 0.358467\n",
      "epoch 42; iter: 0; batch classifier loss: 0.100347; batch adversarial loss: 0.508488\n",
      "epoch 43; iter: 0; batch classifier loss: 0.132455; batch adversarial loss: 0.400835\n",
      "epoch 44; iter: 0; batch classifier loss: 0.130996; batch adversarial loss: 0.463222\n",
      "epoch 45; iter: 0; batch classifier loss: 0.167429; batch adversarial loss: 0.443295\n",
      "epoch 46; iter: 0; batch classifier loss: 0.134625; batch adversarial loss: 0.465524\n",
      "epoch 47; iter: 0; batch classifier loss: 0.132203; batch adversarial loss: 0.475548\n",
      "epoch 48; iter: 0; batch classifier loss: 0.134874; batch adversarial loss: 0.535292\n",
      "epoch 49; iter: 0; batch classifier loss: 0.141519; batch adversarial loss: 0.434958\n",
      "epoch 50; iter: 0; batch classifier loss: 0.133792; batch adversarial loss: 0.396462\n",
      "epoch 51; iter: 0; batch classifier loss: 0.091286; batch adversarial loss: 0.517292\n",
      "epoch 52; iter: 0; batch classifier loss: 0.149763; batch adversarial loss: 0.345826\n",
      "epoch 53; iter: 0; batch classifier loss: 0.146710; batch adversarial loss: 0.478059\n",
      "epoch 54; iter: 0; batch classifier loss: 0.147005; batch adversarial loss: 0.398068\n",
      "epoch 55; iter: 0; batch classifier loss: 0.137114; batch adversarial loss: 0.392079\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101116; batch adversarial loss: 0.409608\n",
      "epoch 57; iter: 0; batch classifier loss: 0.135023; batch adversarial loss: 0.518292\n",
      "epoch 58; iter: 0; batch classifier loss: 0.113422; batch adversarial loss: 0.389105\n",
      "epoch 59; iter: 0; batch classifier loss: 0.129732; batch adversarial loss: 0.359951\n",
      "epoch 60; iter: 0; batch classifier loss: 0.119303; batch adversarial loss: 0.424617\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113608; batch adversarial loss: 0.532534\n",
      "epoch 62; iter: 0; batch classifier loss: 0.099369; batch adversarial loss: 0.441530\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124983; batch adversarial loss: 0.426191\n",
      "epoch 64; iter: 0; batch classifier loss: 0.108494; batch adversarial loss: 0.490550\n",
      "epoch 65; iter: 0; batch classifier loss: 0.119879; batch adversarial loss: 0.530732\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078014; batch adversarial loss: 0.506018\n",
      "epoch 67; iter: 0; batch classifier loss: 0.124989; batch adversarial loss: 0.457188\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084345; batch adversarial loss: 0.425175\n",
      "epoch 69; iter: 0; batch classifier loss: 0.115868; batch adversarial loss: 0.497420\n",
      "epoch 70; iter: 0; batch classifier loss: 0.115039; batch adversarial loss: 0.477734\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099668; batch adversarial loss: 0.408716\n",
      "epoch 72; iter: 0; batch classifier loss: 0.116179; batch adversarial loss: 0.436327\n",
      "epoch 73; iter: 0; batch classifier loss: 0.135994; batch adversarial loss: 0.449635\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101752; batch adversarial loss: 0.420994\n",
      "epoch 75; iter: 0; batch classifier loss: 0.147311; batch adversarial loss: 0.412435\n",
      "epoch 76; iter: 0; batch classifier loss: 0.148223; batch adversarial loss: 0.555218\n",
      "epoch 77; iter: 0; batch classifier loss: 0.152894; batch adversarial loss: 0.438844\n",
      "epoch 78; iter: 0; batch classifier loss: 0.112506; batch adversarial loss: 0.472900\n",
      "epoch 79; iter: 0; batch classifier loss: 0.088138; batch adversarial loss: 0.416583\n",
      "epoch 80; iter: 0; batch classifier loss: 0.080972; batch adversarial loss: 0.443115\n",
      "epoch 81; iter: 0; batch classifier loss: 0.072339; batch adversarial loss: 0.438434\n",
      "epoch 82; iter: 0; batch classifier loss: 0.126780; batch adversarial loss: 0.452326\n",
      "epoch 83; iter: 0; batch classifier loss: 0.105479; batch adversarial loss: 0.478697\n",
      "epoch 84; iter: 0; batch classifier loss: 0.111661; batch adversarial loss: 0.569330\n",
      "epoch 85; iter: 0; batch classifier loss: 0.107396; batch adversarial loss: 0.424162\n",
      "epoch 86; iter: 0; batch classifier loss: 0.140376; batch adversarial loss: 0.483342\n",
      "epoch 87; iter: 0; batch classifier loss: 0.119092; batch adversarial loss: 0.499789\n",
      "epoch 88; iter: 0; batch classifier loss: 0.122647; batch adversarial loss: 0.488220\n",
      "epoch 89; iter: 0; batch classifier loss: 0.111721; batch adversarial loss: 0.451970\n",
      "epoch 90; iter: 0; batch classifier loss: 0.102139; batch adversarial loss: 0.543652\n",
      "epoch 91; iter: 0; batch classifier loss: 0.103678; batch adversarial loss: 0.450052\n",
      "epoch 92; iter: 0; batch classifier loss: 0.117277; batch adversarial loss: 0.465443\n",
      "epoch 93; iter: 0; batch classifier loss: 0.151261; batch adversarial loss: 0.423037\n",
      "epoch 94; iter: 0; batch classifier loss: 0.140451; batch adversarial loss: 0.427510\n",
      "epoch 95; iter: 0; batch classifier loss: 0.127058; batch adversarial loss: 0.441513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.134411; batch adversarial loss: 0.472745\n",
      "epoch 97; iter: 0; batch classifier loss: 0.121786; batch adversarial loss: 0.432691\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079698; batch adversarial loss: 0.413025\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063635; batch adversarial loss: 0.421786\n",
      "epoch 100; iter: 0; batch classifier loss: 0.143238; batch adversarial loss: 0.502676\n",
      "epoch 101; iter: 0; batch classifier loss: 0.094983; batch adversarial loss: 0.556751\n",
      "epoch 102; iter: 0; batch classifier loss: 0.091990; batch adversarial loss: 0.419540\n",
      "epoch 103; iter: 0; batch classifier loss: 0.141499; batch adversarial loss: 0.470574\n",
      "epoch 104; iter: 0; batch classifier loss: 0.079422; batch adversarial loss: 0.477786\n",
      "epoch 105; iter: 0; batch classifier loss: 0.069388; batch adversarial loss: 0.515913\n",
      "epoch 106; iter: 0; batch classifier loss: 0.094311; batch adversarial loss: 0.485339\n",
      "epoch 107; iter: 0; batch classifier loss: 0.139555; batch adversarial loss: 0.552671\n",
      "epoch 108; iter: 0; batch classifier loss: 0.087244; batch adversarial loss: 0.436351\n",
      "epoch 109; iter: 0; batch classifier loss: 0.107346; batch adversarial loss: 0.441578\n",
      "epoch 110; iter: 0; batch classifier loss: 0.113830; batch adversarial loss: 0.483099\n",
      "epoch 111; iter: 0; batch classifier loss: 0.100931; batch adversarial loss: 0.530765\n",
      "epoch 112; iter: 0; batch classifier loss: 0.096666; batch adversarial loss: 0.465290\n",
      "epoch 113; iter: 0; batch classifier loss: 0.194767; batch adversarial loss: 0.333522\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080770; batch adversarial loss: 0.432591\n",
      "epoch 115; iter: 0; batch classifier loss: 0.086252; batch adversarial loss: 0.399361\n",
      "epoch 116; iter: 0; batch classifier loss: 0.141396; batch adversarial loss: 0.421280\n",
      "epoch 117; iter: 0; batch classifier loss: 0.158816; batch adversarial loss: 0.396436\n",
      "epoch 118; iter: 0; batch classifier loss: 0.101002; batch adversarial loss: 0.525836\n",
      "epoch 119; iter: 0; batch classifier loss: 0.087417; batch adversarial loss: 0.458199\n",
      "epoch 120; iter: 0; batch classifier loss: 0.073079; batch adversarial loss: 0.465577\n",
      "epoch 121; iter: 0; batch classifier loss: 0.124455; batch adversarial loss: 0.383384\n",
      "epoch 122; iter: 0; batch classifier loss: 0.055968; batch adversarial loss: 0.472560\n",
      "epoch 123; iter: 0; batch classifier loss: 0.173970; batch adversarial loss: 0.432878\n",
      "epoch 124; iter: 0; batch classifier loss: 0.182363; batch adversarial loss: 0.455501\n",
      "epoch 125; iter: 0; batch classifier loss: 0.083248; batch adversarial loss: 0.426379\n",
      "epoch 126; iter: 0; batch classifier loss: 0.152392; batch adversarial loss: 0.622552\n",
      "epoch 127; iter: 0; batch classifier loss: 0.169450; batch adversarial loss: 0.481495\n",
      "epoch 128; iter: 0; batch classifier loss: 0.210051; batch adversarial loss: 0.431203\n",
      "epoch 129; iter: 0; batch classifier loss: 0.220044; batch adversarial loss: 0.509546\n",
      "epoch 130; iter: 0; batch classifier loss: 0.163525; batch adversarial loss: 0.482647\n",
      "epoch 131; iter: 0; batch classifier loss: 0.181877; batch adversarial loss: 0.539882\n",
      "epoch 132; iter: 0; batch classifier loss: 0.183668; batch adversarial loss: 0.420628\n",
      "epoch 133; iter: 0; batch classifier loss: 0.250819; batch adversarial loss: 0.407347\n",
      "epoch 134; iter: 0; batch classifier loss: 0.221300; batch adversarial loss: 0.395999\n",
      "epoch 135; iter: 0; batch classifier loss: 0.244909; batch adversarial loss: 0.419654\n",
      "epoch 136; iter: 0; batch classifier loss: 0.296248; batch adversarial loss: 0.507578\n",
      "epoch 137; iter: 0; batch classifier loss: 0.189208; batch adversarial loss: 0.411285\n",
      "epoch 138; iter: 0; batch classifier loss: 0.220966; batch adversarial loss: 0.471123\n",
      "epoch 139; iter: 0; batch classifier loss: 0.256490; batch adversarial loss: 0.483183\n",
      "epoch 140; iter: 0; batch classifier loss: 0.247301; batch adversarial loss: 0.410815\n",
      "epoch 141; iter: 0; batch classifier loss: 0.317403; batch adversarial loss: 0.422257\n",
      "epoch 142; iter: 0; batch classifier loss: 0.062009; batch adversarial loss: 0.422221\n",
      "epoch 143; iter: 0; batch classifier loss: 0.104910; batch adversarial loss: 0.508342\n",
      "epoch 144; iter: 0; batch classifier loss: 0.171572; batch adversarial loss: 0.458462\n",
      "epoch 145; iter: 0; batch classifier loss: 0.227301; batch adversarial loss: 0.434525\n",
      "epoch 146; iter: 0; batch classifier loss: 0.191378; batch adversarial loss: 0.471797\n",
      "epoch 147; iter: 0; batch classifier loss: 0.211004; batch adversarial loss: 0.458829\n",
      "epoch 148; iter: 0; batch classifier loss: 0.159493; batch adversarial loss: 0.433973\n",
      "epoch 149; iter: 0; batch classifier loss: 0.170527; batch adversarial loss: 0.644313\n",
      "epoch 150; iter: 0; batch classifier loss: 0.099159; batch adversarial loss: 0.422615\n",
      "epoch 151; iter: 0; batch classifier loss: 0.171265; batch adversarial loss: 0.398315\n",
      "epoch 152; iter: 0; batch classifier loss: 0.256087; batch adversarial loss: 0.383810\n",
      "epoch 153; iter: 0; batch classifier loss: 0.218762; batch adversarial loss: 0.522417\n",
      "epoch 154; iter: 0; batch classifier loss: 0.209359; batch adversarial loss: 0.533251\n",
      "epoch 155; iter: 0; batch classifier loss: 0.169766; batch adversarial loss: 0.520369\n",
      "epoch 156; iter: 0; batch classifier loss: 0.265492; batch adversarial loss: 0.458725\n",
      "epoch 157; iter: 0; batch classifier loss: 0.101880; batch adversarial loss: 0.507535\n",
      "epoch 158; iter: 0; batch classifier loss: 0.043957; batch adversarial loss: 0.418354\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037542; batch adversarial loss: 0.480875\n",
      "epoch 160; iter: 0; batch classifier loss: 0.056636; batch adversarial loss: 0.382399\n",
      "epoch 161; iter: 0; batch classifier loss: 0.053861; batch adversarial loss: 0.492093\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036004; batch adversarial loss: 0.428579\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037568; batch adversarial loss: 0.500027\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035614; batch adversarial loss: 0.404856\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041777; batch adversarial loss: 0.462348\n",
      "epoch 166; iter: 0; batch classifier loss: 0.088816; batch adversarial loss: 0.484231\n",
      "epoch 167; iter: 0; batch classifier loss: 0.083568; batch adversarial loss: 0.388068\n",
      "epoch 168; iter: 0; batch classifier loss: 0.044254; batch adversarial loss: 0.380967\n",
      "epoch 169; iter: 0; batch classifier loss: 0.065337; batch adversarial loss: 0.485797\n",
      "epoch 170; iter: 0; batch classifier loss: 0.077872; batch adversarial loss: 0.449547\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030469; batch adversarial loss: 0.395563\n",
      "epoch 172; iter: 0; batch classifier loss: 0.057984; batch adversarial loss: 0.471331\n",
      "epoch 173; iter: 0; batch classifier loss: 0.069963; batch adversarial loss: 0.402479\n",
      "epoch 174; iter: 0; batch classifier loss: 0.073377; batch adversarial loss: 0.493862\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032343; batch adversarial loss: 0.463254\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032553; batch adversarial loss: 0.432475\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042361; batch adversarial loss: 0.466396\n",
      "epoch 178; iter: 0; batch classifier loss: 0.093461; batch adversarial loss: 0.510886\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032219; batch adversarial loss: 0.530693\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021053; batch adversarial loss: 0.401635\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037151; batch adversarial loss: 0.369502\n",
      "epoch 182; iter: 0; batch classifier loss: 0.057208; batch adversarial loss: 0.391505\n",
      "epoch 183; iter: 0; batch classifier loss: 0.048576; batch adversarial loss: 0.444318\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025036; batch adversarial loss: 0.383859\n",
      "epoch 185; iter: 0; batch classifier loss: 0.049203; batch adversarial loss: 0.402658\n",
      "epoch 186; iter: 0; batch classifier loss: 0.053358; batch adversarial loss: 0.430911\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040082; batch adversarial loss: 0.447948\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034507; batch adversarial loss: 0.409470\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032827; batch adversarial loss: 0.395643\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040279; batch adversarial loss: 0.528642\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028903; batch adversarial loss: 0.404213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.046932; batch adversarial loss: 0.491809\n",
      "epoch 193; iter: 0; batch classifier loss: 0.055986; batch adversarial loss: 0.573334\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025504; batch adversarial loss: 0.489179\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018399; batch adversarial loss: 0.374106\n",
      "epoch 196; iter: 0; batch classifier loss: 0.106972; batch adversarial loss: 0.386253\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026620; batch adversarial loss: 0.395892\n",
      "epoch 198; iter: 0; batch classifier loss: 0.056111; batch adversarial loss: 0.499685\n",
      "epoch 199; iter: 0; batch classifier loss: 0.065696; batch adversarial loss: 0.420587\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698484; batch adversarial loss: 0.768247\n",
      "epoch 1; iter: 0; batch classifier loss: 0.458016; batch adversarial loss: 0.741927\n",
      "epoch 2; iter: 0; batch classifier loss: 0.484788; batch adversarial loss: 0.710398\n",
      "epoch 3; iter: 0; batch classifier loss: 0.612258; batch adversarial loss: 0.654879\n",
      "epoch 4; iter: 0; batch classifier loss: 0.379969; batch adversarial loss: 0.598814\n",
      "epoch 5; iter: 0; batch classifier loss: 0.437752; batch adversarial loss: 0.584305\n",
      "epoch 6; iter: 0; batch classifier loss: 0.328429; batch adversarial loss: 0.569492\n",
      "epoch 7; iter: 0; batch classifier loss: 0.366355; batch adversarial loss: 0.566087\n",
      "epoch 8; iter: 0; batch classifier loss: 0.255852; batch adversarial loss: 0.564315\n",
      "epoch 9; iter: 0; batch classifier loss: 0.270188; batch adversarial loss: 0.512474\n",
      "epoch 10; iter: 0; batch classifier loss: 0.305903; batch adversarial loss: 0.564818\n",
      "epoch 11; iter: 0; batch classifier loss: 0.311421; batch adversarial loss: 0.507918\n",
      "epoch 12; iter: 0; batch classifier loss: 0.346142; batch adversarial loss: 0.526883\n",
      "epoch 13; iter: 0; batch classifier loss: 0.354651; batch adversarial loss: 0.572829\n",
      "epoch 14; iter: 0; batch classifier loss: 0.402592; batch adversarial loss: 0.528926\n",
      "epoch 15; iter: 0; batch classifier loss: 0.343528; batch adversarial loss: 0.558526\n",
      "epoch 16; iter: 0; batch classifier loss: 0.293237; batch adversarial loss: 0.535355\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349393; batch adversarial loss: 0.525797\n",
      "epoch 18; iter: 0; batch classifier loss: 0.384920; batch adversarial loss: 0.406237\n",
      "epoch 19; iter: 0; batch classifier loss: 0.347484; batch adversarial loss: 0.550866\n",
      "epoch 20; iter: 0; batch classifier loss: 0.381788; batch adversarial loss: 0.465299\n",
      "epoch 21; iter: 0; batch classifier loss: 0.275685; batch adversarial loss: 0.508259\n",
      "epoch 22; iter: 0; batch classifier loss: 0.220552; batch adversarial loss: 0.513153\n",
      "epoch 23; iter: 0; batch classifier loss: 0.258280; batch adversarial loss: 0.455219\n",
      "epoch 24; iter: 0; batch classifier loss: 0.230403; batch adversarial loss: 0.431610\n",
      "epoch 25; iter: 0; batch classifier loss: 0.282245; batch adversarial loss: 0.404746\n",
      "epoch 26; iter: 0; batch classifier loss: 0.258930; batch adversarial loss: 0.493759\n",
      "epoch 27; iter: 0; batch classifier loss: 0.227980; batch adversarial loss: 0.417824\n",
      "epoch 28; iter: 0; batch classifier loss: 0.200403; batch adversarial loss: 0.461529\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197559; batch adversarial loss: 0.519122\n",
      "epoch 30; iter: 0; batch classifier loss: 0.229304; batch adversarial loss: 0.442966\n",
      "epoch 31; iter: 0; batch classifier loss: 0.231011; batch adversarial loss: 0.401665\n",
      "epoch 32; iter: 0; batch classifier loss: 0.179274; batch adversarial loss: 0.533194\n",
      "epoch 33; iter: 0; batch classifier loss: 0.212898; batch adversarial loss: 0.480216\n",
      "epoch 34; iter: 0; batch classifier loss: 0.177184; batch adversarial loss: 0.442788\n",
      "epoch 35; iter: 0; batch classifier loss: 0.261594; batch adversarial loss: 0.396334\n",
      "epoch 36; iter: 0; batch classifier loss: 0.209453; batch adversarial loss: 0.444457\n",
      "epoch 37; iter: 0; batch classifier loss: 0.186225; batch adversarial loss: 0.470970\n",
      "epoch 38; iter: 0; batch classifier loss: 0.214972; batch adversarial loss: 0.427139\n",
      "epoch 39; iter: 0; batch classifier loss: 0.160724; batch adversarial loss: 0.428287\n",
      "epoch 40; iter: 0; batch classifier loss: 0.167825; batch adversarial loss: 0.444759\n",
      "epoch 41; iter: 0; batch classifier loss: 0.166909; batch adversarial loss: 0.405113\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200970; batch adversarial loss: 0.404647\n",
      "epoch 43; iter: 0; batch classifier loss: 0.214836; batch adversarial loss: 0.413229\n",
      "epoch 44; iter: 0; batch classifier loss: 0.190827; batch adversarial loss: 0.456169\n",
      "epoch 45; iter: 0; batch classifier loss: 0.165316; batch adversarial loss: 0.500239\n",
      "epoch 46; iter: 0; batch classifier loss: 0.189108; batch adversarial loss: 0.494410\n",
      "epoch 47; iter: 0; batch classifier loss: 0.186567; batch adversarial loss: 0.521279\n",
      "epoch 48; iter: 0; batch classifier loss: 0.103252; batch adversarial loss: 0.517793\n",
      "epoch 49; iter: 0; batch classifier loss: 0.120462; batch adversarial loss: 0.417748\n",
      "epoch 50; iter: 0; batch classifier loss: 0.141699; batch adversarial loss: 0.507977\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122376; batch adversarial loss: 0.375144\n",
      "epoch 52; iter: 0; batch classifier loss: 0.113023; batch adversarial loss: 0.486407\n",
      "epoch 53; iter: 0; batch classifier loss: 0.186008; batch adversarial loss: 0.420054\n",
      "epoch 54; iter: 0; batch classifier loss: 0.107688; batch adversarial loss: 0.410683\n",
      "epoch 55; iter: 0; batch classifier loss: 0.106031; batch adversarial loss: 0.437628\n",
      "epoch 56; iter: 0; batch classifier loss: 0.149822; batch adversarial loss: 0.455936\n",
      "epoch 57; iter: 0; batch classifier loss: 0.116686; batch adversarial loss: 0.412423\n",
      "epoch 58; iter: 0; batch classifier loss: 0.158705; batch adversarial loss: 0.373674\n",
      "epoch 59; iter: 0; batch classifier loss: 0.149217; batch adversarial loss: 0.435908\n",
      "epoch 60; iter: 0; batch classifier loss: 0.113166; batch adversarial loss: 0.513752\n",
      "epoch 61; iter: 0; batch classifier loss: 0.198399; batch adversarial loss: 0.448322\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085549; batch adversarial loss: 0.443173\n",
      "epoch 63; iter: 0; batch classifier loss: 0.119030; batch adversarial loss: 0.447906\n",
      "epoch 64; iter: 0; batch classifier loss: 0.134301; batch adversarial loss: 0.479458\n",
      "epoch 65; iter: 0; batch classifier loss: 0.102975; batch adversarial loss: 0.471076\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062489; batch adversarial loss: 0.380258\n",
      "epoch 67; iter: 0; batch classifier loss: 0.081514; batch adversarial loss: 0.438986\n",
      "epoch 68; iter: 0; batch classifier loss: 0.157920; batch adversarial loss: 0.465623\n",
      "epoch 69; iter: 0; batch classifier loss: 0.123307; batch adversarial loss: 0.438489\n",
      "epoch 70; iter: 0; batch classifier loss: 0.059468; batch adversarial loss: 0.416817\n",
      "epoch 71; iter: 0; batch classifier loss: 0.034302; batch adversarial loss: 0.400952\n",
      "epoch 72; iter: 0; batch classifier loss: 0.084961; batch adversarial loss: 0.540469\n",
      "epoch 73; iter: 0; batch classifier loss: 0.030515; batch adversarial loss: 0.387215\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082878; batch adversarial loss: 0.480561\n",
      "epoch 75; iter: 0; batch classifier loss: 0.082341; batch adversarial loss: 0.478429\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103926; batch adversarial loss: 0.545458\n",
      "epoch 77; iter: 0; batch classifier loss: 0.058814; batch adversarial loss: 0.495131\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062271; batch adversarial loss: 0.429600\n",
      "epoch 79; iter: 0; batch classifier loss: 0.059526; batch adversarial loss: 0.469864\n",
      "epoch 80; iter: 0; batch classifier loss: 0.108940; batch adversarial loss: 0.507013\n",
      "epoch 81; iter: 0; batch classifier loss: 0.091041; batch adversarial loss: 0.458904\n",
      "epoch 82; iter: 0; batch classifier loss: 0.111084; batch adversarial loss: 0.450972\n",
      "epoch 83; iter: 0; batch classifier loss: 0.052125; batch adversarial loss: 0.438946\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046743; batch adversarial loss: 0.438563\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060572; batch adversarial loss: 0.413712\n",
      "epoch 86; iter: 0; batch classifier loss: 0.055881; batch adversarial loss: 0.517623\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047742; batch adversarial loss: 0.483966\n",
      "epoch 88; iter: 0; batch classifier loss: 0.044168; batch adversarial loss: 0.387669\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075345; batch adversarial loss: 0.389074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.074063; batch adversarial loss: 0.429678\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043459; batch adversarial loss: 0.469079\n",
      "epoch 92; iter: 0; batch classifier loss: 0.034398; batch adversarial loss: 0.529810\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063929; batch adversarial loss: 0.527763\n",
      "epoch 94; iter: 0; batch classifier loss: 0.024408; batch adversarial loss: 0.489579\n",
      "epoch 95; iter: 0; batch classifier loss: 0.099419; batch adversarial loss: 0.394994\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051454; batch adversarial loss: 0.396363\n",
      "epoch 97; iter: 0; batch classifier loss: 0.068466; batch adversarial loss: 0.412853\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047248; batch adversarial loss: 0.434693\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042987; batch adversarial loss: 0.526128\n",
      "epoch 100; iter: 0; batch classifier loss: 0.031167; batch adversarial loss: 0.407231\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047164; batch adversarial loss: 0.512108\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048420; batch adversarial loss: 0.393313\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035581; batch adversarial loss: 0.505711\n",
      "epoch 104; iter: 0; batch classifier loss: 0.032612; batch adversarial loss: 0.520252\n",
      "epoch 105; iter: 0; batch classifier loss: 0.033409; batch adversarial loss: 0.502480\n",
      "epoch 106; iter: 0; batch classifier loss: 0.022927; batch adversarial loss: 0.459794\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063927; batch adversarial loss: 0.446173\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048720; batch adversarial loss: 0.421156\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027612; batch adversarial loss: 0.452199\n",
      "epoch 110; iter: 0; batch classifier loss: 0.017064; batch adversarial loss: 0.562727\n",
      "epoch 111; iter: 0; batch classifier loss: 0.017776; batch adversarial loss: 0.400474\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032899; batch adversarial loss: 0.365675\n",
      "epoch 113; iter: 0; batch classifier loss: 0.032086; batch adversarial loss: 0.405702\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030180; batch adversarial loss: 0.508938\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032477; batch adversarial loss: 0.493678\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033471; batch adversarial loss: 0.435944\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028721; batch adversarial loss: 0.420949\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039698; batch adversarial loss: 0.383070\n",
      "epoch 119; iter: 0; batch classifier loss: 0.064401; batch adversarial loss: 0.481328\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031846; batch adversarial loss: 0.475741\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021113; batch adversarial loss: 0.426512\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043443; batch adversarial loss: 0.499631\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033493; batch adversarial loss: 0.471354\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020921; batch adversarial loss: 0.396989\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044156; batch adversarial loss: 0.475257\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029178; batch adversarial loss: 0.388286\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026564; batch adversarial loss: 0.442820\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024778; batch adversarial loss: 0.441409\n",
      "epoch 129; iter: 0; batch classifier loss: 0.015982; batch adversarial loss: 0.534167\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038808; batch adversarial loss: 0.513718\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025850; batch adversarial loss: 0.334720\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030640; batch adversarial loss: 0.487857\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014676; batch adversarial loss: 0.479138\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028845; batch adversarial loss: 0.415347\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016052; batch adversarial loss: 0.490146\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037816; batch adversarial loss: 0.408094\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027347; batch adversarial loss: 0.489615\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026021; batch adversarial loss: 0.513802\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009821; batch adversarial loss: 0.404622\n",
      "epoch 140; iter: 0; batch classifier loss: 0.043913; batch adversarial loss: 0.527603\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024182; batch adversarial loss: 0.553398\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016757; batch adversarial loss: 0.379727\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031259; batch adversarial loss: 0.492957\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021535; batch adversarial loss: 0.543297\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028142; batch adversarial loss: 0.407369\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021011; batch adversarial loss: 0.336871\n",
      "epoch 147; iter: 0; batch classifier loss: 0.012684; batch adversarial loss: 0.517705\n",
      "epoch 148; iter: 0; batch classifier loss: 0.006364; batch adversarial loss: 0.423143\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031148; batch adversarial loss: 0.374651\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019043; batch adversarial loss: 0.452366\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008453; batch adversarial loss: 0.553533\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032613; batch adversarial loss: 0.437531\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026999; batch adversarial loss: 0.471396\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014648; batch adversarial loss: 0.543212\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024042; batch adversarial loss: 0.511648\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023080; batch adversarial loss: 0.475756\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039822; batch adversarial loss: 0.419993\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035265; batch adversarial loss: 0.544416\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030894; batch adversarial loss: 0.418887\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031404; batch adversarial loss: 0.445473\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016395; batch adversarial loss: 0.424780\n",
      "epoch 162; iter: 0; batch classifier loss: 0.058374; batch adversarial loss: 0.477370\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021908; batch adversarial loss: 0.481197\n",
      "epoch 164; iter: 0; batch classifier loss: 0.003741; batch adversarial loss: 0.479249\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022682; batch adversarial loss: 0.441980\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012801; batch adversarial loss: 0.504835\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023772; batch adversarial loss: 0.453023\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013171; batch adversarial loss: 0.427466\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007547; batch adversarial loss: 0.397927\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012476; batch adversarial loss: 0.414102\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025076; batch adversarial loss: 0.440499\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008825; batch adversarial loss: 0.529675\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017234; batch adversarial loss: 0.425226\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018703; batch adversarial loss: 0.490404\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012899; batch adversarial loss: 0.480985\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007227; batch adversarial loss: 0.445292\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011141; batch adversarial loss: 0.532842\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019827; batch adversarial loss: 0.391637\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021394; batch adversarial loss: 0.469929\n",
      "epoch 180; iter: 0; batch classifier loss: 0.042354; batch adversarial loss: 0.449660\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011229; batch adversarial loss: 0.450289\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023742; batch adversarial loss: 0.484230\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015828; batch adversarial loss: 0.412897\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017197; batch adversarial loss: 0.533744\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007868; batch adversarial loss: 0.394499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.018836; batch adversarial loss: 0.366000\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008976; batch adversarial loss: 0.469212\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018435; batch adversarial loss: 0.444058\n",
      "epoch 189; iter: 0; batch classifier loss: 0.076234; batch adversarial loss: 0.409516\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022865; batch adversarial loss: 0.468454\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008364; batch adversarial loss: 0.530525\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011655; batch adversarial loss: 0.497421\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021092; batch adversarial loss: 0.450604\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007565; batch adversarial loss: 0.508242\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009264; batch adversarial loss: 0.421951\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030936; batch adversarial loss: 0.446983\n",
      "epoch 197; iter: 0; batch classifier loss: 0.003813; batch adversarial loss: 0.429632\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014951; batch adversarial loss: 0.430933\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023401; batch adversarial loss: 0.473429\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690965; batch adversarial loss: 0.881807\n",
      "epoch 1; iter: 0; batch classifier loss: 0.551111; batch adversarial loss: 0.870375\n",
      "epoch 2; iter: 0; batch classifier loss: 0.819539; batch adversarial loss: 0.893234\n",
      "epoch 3; iter: 0; batch classifier loss: 0.843486; batch adversarial loss: 0.804230\n",
      "epoch 4; iter: 0; batch classifier loss: 0.818411; batch adversarial loss: 0.733724\n",
      "epoch 5; iter: 0; batch classifier loss: 0.811369; batch adversarial loss: 0.663814\n",
      "epoch 6; iter: 0; batch classifier loss: 0.594622; batch adversarial loss: 0.605194\n",
      "epoch 7; iter: 0; batch classifier loss: 0.351897; batch adversarial loss: 0.586735\n",
      "epoch 8; iter: 0; batch classifier loss: 0.380355; batch adversarial loss: 0.529272\n",
      "epoch 9; iter: 0; batch classifier loss: 0.405148; batch adversarial loss: 0.524807\n",
      "epoch 10; iter: 0; batch classifier loss: 0.310338; batch adversarial loss: 0.518815\n",
      "epoch 11; iter: 0; batch classifier loss: 0.328731; batch adversarial loss: 0.569382\n",
      "epoch 12; iter: 0; batch classifier loss: 0.390880; batch adversarial loss: 0.513135\n",
      "epoch 13; iter: 0; batch classifier loss: 0.308100; batch adversarial loss: 0.500959\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368507; batch adversarial loss: 0.466521\n",
      "epoch 15; iter: 0; batch classifier loss: 0.285091; batch adversarial loss: 0.527830\n",
      "epoch 16; iter: 0; batch classifier loss: 0.319227; batch adversarial loss: 0.515762\n",
      "epoch 17; iter: 0; batch classifier loss: 0.254857; batch adversarial loss: 0.489424\n",
      "epoch 18; iter: 0; batch classifier loss: 0.240877; batch adversarial loss: 0.575343\n",
      "epoch 19; iter: 0; batch classifier loss: 0.267995; batch adversarial loss: 0.497966\n",
      "epoch 20; iter: 0; batch classifier loss: 0.280537; batch adversarial loss: 0.457337\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258404; batch adversarial loss: 0.491874\n",
      "epoch 22; iter: 0; batch classifier loss: 0.283814; batch adversarial loss: 0.480742\n",
      "epoch 23; iter: 0; batch classifier loss: 0.284869; batch adversarial loss: 0.470828\n",
      "epoch 24; iter: 0; batch classifier loss: 0.281155; batch adversarial loss: 0.433465\n",
      "epoch 25; iter: 0; batch classifier loss: 0.279403; batch adversarial loss: 0.524306\n",
      "epoch 26; iter: 0; batch classifier loss: 0.221207; batch adversarial loss: 0.439813\n",
      "epoch 27; iter: 0; batch classifier loss: 0.285843; batch adversarial loss: 0.389984\n",
      "epoch 28; iter: 0; batch classifier loss: 0.243329; batch adversarial loss: 0.450382\n",
      "epoch 29; iter: 0; batch classifier loss: 0.289423; batch adversarial loss: 0.434498\n",
      "epoch 30; iter: 0; batch classifier loss: 0.212846; batch adversarial loss: 0.552310\n",
      "epoch 31; iter: 0; batch classifier loss: 0.204001; batch adversarial loss: 0.557937\n",
      "epoch 32; iter: 0; batch classifier loss: 0.267248; batch adversarial loss: 0.392201\n",
      "epoch 33; iter: 0; batch classifier loss: 0.200123; batch adversarial loss: 0.460315\n",
      "epoch 34; iter: 0; batch classifier loss: 0.223810; batch adversarial loss: 0.499611\n",
      "epoch 35; iter: 0; batch classifier loss: 0.251079; batch adversarial loss: 0.455568\n",
      "epoch 36; iter: 0; batch classifier loss: 0.259938; batch adversarial loss: 0.426051\n",
      "epoch 37; iter: 0; batch classifier loss: 0.256672; batch adversarial loss: 0.455817\n",
      "epoch 38; iter: 0; batch classifier loss: 0.209656; batch adversarial loss: 0.396354\n",
      "epoch 39; iter: 0; batch classifier loss: 0.293858; batch adversarial loss: 0.460637\n",
      "epoch 40; iter: 0; batch classifier loss: 0.231623; batch adversarial loss: 0.469347\n",
      "epoch 41; iter: 0; batch classifier loss: 0.198147; batch adversarial loss: 0.571231\n",
      "epoch 42; iter: 0; batch classifier loss: 0.288783; batch adversarial loss: 0.444958\n",
      "epoch 43; iter: 0; batch classifier loss: 0.277829; batch adversarial loss: 0.483755\n",
      "epoch 44; iter: 0; batch classifier loss: 0.199359; batch adversarial loss: 0.417790\n",
      "epoch 45; iter: 0; batch classifier loss: 0.197292; batch adversarial loss: 0.491049\n",
      "epoch 46; iter: 0; batch classifier loss: 0.211100; batch adversarial loss: 0.483217\n",
      "epoch 47; iter: 0; batch classifier loss: 0.247758; batch adversarial loss: 0.407833\n",
      "epoch 48; iter: 0; batch classifier loss: 0.235923; batch adversarial loss: 0.377571\n",
      "epoch 49; iter: 0; batch classifier loss: 0.269604; batch adversarial loss: 0.434168\n",
      "epoch 50; iter: 0; batch classifier loss: 0.183681; batch adversarial loss: 0.542461\n",
      "epoch 51; iter: 0; batch classifier loss: 0.214505; batch adversarial loss: 0.398557\n",
      "epoch 52; iter: 0; batch classifier loss: 0.193767; batch adversarial loss: 0.462036\n",
      "epoch 53; iter: 0; batch classifier loss: 0.254626; batch adversarial loss: 0.496983\n",
      "epoch 54; iter: 0; batch classifier loss: 0.174997; batch adversarial loss: 0.472798\n",
      "epoch 55; iter: 0; batch classifier loss: 0.291806; batch adversarial loss: 0.430789\n",
      "epoch 56; iter: 0; batch classifier loss: 0.273385; batch adversarial loss: 0.416816\n",
      "epoch 57; iter: 0; batch classifier loss: 0.232694; batch adversarial loss: 0.448995\n",
      "epoch 58; iter: 0; batch classifier loss: 0.240669; batch adversarial loss: 0.481279\n",
      "epoch 59; iter: 0; batch classifier loss: 0.262564; batch adversarial loss: 0.513143\n",
      "epoch 60; iter: 0; batch classifier loss: 0.178236; batch adversarial loss: 0.437870\n",
      "epoch 61; iter: 0; batch classifier loss: 0.241841; batch adversarial loss: 0.458180\n",
      "epoch 62; iter: 0; batch classifier loss: 0.232476; batch adversarial loss: 0.470433\n",
      "epoch 63; iter: 0; batch classifier loss: 0.236767; batch adversarial loss: 0.377416\n",
      "epoch 64; iter: 0; batch classifier loss: 0.248165; batch adversarial loss: 0.376481\n",
      "epoch 65; iter: 0; batch classifier loss: 0.241619; batch adversarial loss: 0.471613\n",
      "epoch 66; iter: 0; batch classifier loss: 0.226955; batch adversarial loss: 0.472434\n",
      "epoch 67; iter: 0; batch classifier loss: 0.197618; batch adversarial loss: 0.471216\n",
      "epoch 68; iter: 0; batch classifier loss: 0.237022; batch adversarial loss: 0.411015\n",
      "epoch 69; iter: 0; batch classifier loss: 0.276122; batch adversarial loss: 0.389046\n",
      "epoch 70; iter: 0; batch classifier loss: 0.193879; batch adversarial loss: 0.470814\n",
      "epoch 71; iter: 0; batch classifier loss: 0.244265; batch adversarial loss: 0.495442\n",
      "epoch 72; iter: 0; batch classifier loss: 0.230265; batch adversarial loss: 0.398690\n",
      "epoch 73; iter: 0; batch classifier loss: 0.240303; batch adversarial loss: 0.483104\n",
      "epoch 74; iter: 0; batch classifier loss: 0.296045; batch adversarial loss: 0.482691\n",
      "epoch 75; iter: 0; batch classifier loss: 0.210001; batch adversarial loss: 0.530383\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070643; batch adversarial loss: 0.496089\n",
      "epoch 77; iter: 0; batch classifier loss: 0.115198; batch adversarial loss: 0.482497\n",
      "epoch 78; iter: 0; batch classifier loss: 0.253605; batch adversarial loss: 0.446575\n",
      "epoch 79; iter: 0; batch classifier loss: 0.252784; batch adversarial loss: 0.461144\n",
      "epoch 80; iter: 0; batch classifier loss: 0.215673; batch adversarial loss: 0.531577\n",
      "epoch 81; iter: 0; batch classifier loss: 0.265691; batch adversarial loss: 0.412959\n",
      "epoch 82; iter: 0; batch classifier loss: 0.228287; batch adversarial loss: 0.387606\n",
      "epoch 83; iter: 0; batch classifier loss: 0.231726; batch adversarial loss: 0.434683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.285434; batch adversarial loss: 0.399113\n",
      "epoch 85; iter: 0; batch classifier loss: 0.098666; batch adversarial loss: 0.530487\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081912; batch adversarial loss: 0.442061\n",
      "epoch 87; iter: 0; batch classifier loss: 0.108096; batch adversarial loss: 0.466698\n",
      "epoch 88; iter: 0; batch classifier loss: 0.109599; batch adversarial loss: 0.418872\n",
      "epoch 89; iter: 0; batch classifier loss: 0.134518; batch adversarial loss: 0.466018\n",
      "epoch 90; iter: 0; batch classifier loss: 0.105863; batch adversarial loss: 0.503921\n",
      "epoch 91; iter: 0; batch classifier loss: 0.141694; batch adversarial loss: 0.422425\n",
      "epoch 92; iter: 0; batch classifier loss: 0.117433; batch adversarial loss: 0.418728\n",
      "epoch 93; iter: 0; batch classifier loss: 0.182569; batch adversarial loss: 0.498717\n",
      "epoch 94; iter: 0; batch classifier loss: 0.118829; batch adversarial loss: 0.509989\n",
      "epoch 95; iter: 0; batch classifier loss: 0.148996; batch adversarial loss: 0.429566\n",
      "epoch 96; iter: 0; batch classifier loss: 0.142343; batch adversarial loss: 0.517855\n",
      "epoch 97; iter: 0; batch classifier loss: 0.109618; batch adversarial loss: 0.506251\n",
      "epoch 98; iter: 0; batch classifier loss: 0.106281; batch adversarial loss: 0.481590\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065440; batch adversarial loss: 0.504315\n",
      "epoch 100; iter: 0; batch classifier loss: 0.091020; batch adversarial loss: 0.371313\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070900; batch adversarial loss: 0.452639\n",
      "epoch 102; iter: 0; batch classifier loss: 0.061035; batch adversarial loss: 0.491410\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045495; batch adversarial loss: 0.565441\n",
      "epoch 104; iter: 0; batch classifier loss: 0.082224; batch adversarial loss: 0.488603\n",
      "epoch 105; iter: 0; batch classifier loss: 0.079384; batch adversarial loss: 0.466030\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044949; batch adversarial loss: 0.561563\n",
      "epoch 107; iter: 0; batch classifier loss: 0.085897; batch adversarial loss: 0.513559\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046841; batch adversarial loss: 0.410055\n",
      "epoch 109; iter: 0; batch classifier loss: 0.116771; batch adversarial loss: 0.467599\n",
      "epoch 110; iter: 0; batch classifier loss: 0.071926; batch adversarial loss: 0.395200\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057169; batch adversarial loss: 0.517150\n",
      "epoch 112; iter: 0; batch classifier loss: 0.095442; batch adversarial loss: 0.433821\n",
      "epoch 113; iter: 0; batch classifier loss: 0.024929; batch adversarial loss: 0.471591\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054283; batch adversarial loss: 0.451694\n",
      "epoch 115; iter: 0; batch classifier loss: 0.055202; batch adversarial loss: 0.504209\n",
      "epoch 116; iter: 0; batch classifier loss: 0.078350; batch adversarial loss: 0.385795\n",
      "epoch 117; iter: 0; batch classifier loss: 0.024318; batch adversarial loss: 0.545199\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056318; batch adversarial loss: 0.407777\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023578; batch adversarial loss: 0.414811\n",
      "epoch 120; iter: 0; batch classifier loss: 0.070196; batch adversarial loss: 0.369748\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048137; batch adversarial loss: 0.557962\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052865; batch adversarial loss: 0.430786\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050624; batch adversarial loss: 0.349278\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023971; batch adversarial loss: 0.488034\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049754; batch adversarial loss: 0.479670\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033509; batch adversarial loss: 0.549372\n",
      "epoch 127; iter: 0; batch classifier loss: 0.052418; batch adversarial loss: 0.391893\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042569; batch adversarial loss: 0.308242\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043462; batch adversarial loss: 0.478333\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024289; batch adversarial loss: 0.382999\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054384; batch adversarial loss: 0.508469\n",
      "epoch 132; iter: 0; batch classifier loss: 0.018072; batch adversarial loss: 0.455401\n",
      "epoch 133; iter: 0; batch classifier loss: 0.050256; batch adversarial loss: 0.522265\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038284; batch adversarial loss: 0.486231\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035031; batch adversarial loss: 0.559989\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032991; batch adversarial loss: 0.478546\n",
      "epoch 137; iter: 0; batch classifier loss: 0.009878; batch adversarial loss: 0.479835\n",
      "epoch 138; iter: 0; batch classifier loss: 0.063001; batch adversarial loss: 0.443556\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035788; batch adversarial loss: 0.475572\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045550; batch adversarial loss: 0.481409\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046554; batch adversarial loss: 0.431701\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036130; batch adversarial loss: 0.424350\n",
      "epoch 143; iter: 0; batch classifier loss: 0.045674; batch adversarial loss: 0.456659\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028632; batch adversarial loss: 0.501382\n",
      "epoch 145; iter: 0; batch classifier loss: 0.057466; batch adversarial loss: 0.406991\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045441; batch adversarial loss: 0.467490\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039340; batch adversarial loss: 0.441107\n",
      "epoch 148; iter: 0; batch classifier loss: 0.007515; batch adversarial loss: 0.591824\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039981; batch adversarial loss: 0.400350\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010097; batch adversarial loss: 0.452037\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030249; batch adversarial loss: 0.430818\n",
      "epoch 152; iter: 0; batch classifier loss: 0.046425; batch adversarial loss: 0.358867\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026071; batch adversarial loss: 0.530810\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019325; batch adversarial loss: 0.429078\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031779; batch adversarial loss: 0.362302\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038933; batch adversarial loss: 0.546639\n",
      "epoch 157; iter: 0; batch classifier loss: 0.066975; batch adversarial loss: 0.487755\n",
      "epoch 158; iter: 0; batch classifier loss: 0.066323; batch adversarial loss: 0.424338\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033239; batch adversarial loss: 0.358600\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009331; batch adversarial loss: 0.508699\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032957; batch adversarial loss: 0.445809\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012549; batch adversarial loss: 0.397984\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036790; batch adversarial loss: 0.495226\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015191; batch adversarial loss: 0.490753\n",
      "epoch 165; iter: 0; batch classifier loss: 0.045788; batch adversarial loss: 0.439004\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016202; batch adversarial loss: 0.525972\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019438; batch adversarial loss: 0.463663\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029493; batch adversarial loss: 0.375706\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015291; batch adversarial loss: 0.469049\n",
      "epoch 170; iter: 0; batch classifier loss: 0.006269; batch adversarial loss: 0.388659\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012405; batch adversarial loss: 0.519171\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027092; batch adversarial loss: 0.425646\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037956; batch adversarial loss: 0.449544\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018507; batch adversarial loss: 0.452233\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017080; batch adversarial loss: 0.467873\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010456; batch adversarial loss: 0.422528\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015255; batch adversarial loss: 0.461379\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014123; batch adversarial loss: 0.496048\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031839; batch adversarial loss: 0.476257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.009430; batch adversarial loss: 0.453816\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037100; batch adversarial loss: 0.500736\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025522; batch adversarial loss: 0.431282\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005720; batch adversarial loss: 0.493990\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012100; batch adversarial loss: 0.549454\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024487; batch adversarial loss: 0.479230\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006855; batch adversarial loss: 0.474717\n",
      "epoch 187; iter: 0; batch classifier loss: 0.045925; batch adversarial loss: 0.467660\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018433; batch adversarial loss: 0.587151\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020636; batch adversarial loss: 0.418665\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013564; batch adversarial loss: 0.465470\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029983; batch adversarial loss: 0.410880\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017487; batch adversarial loss: 0.471528\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016299; batch adversarial loss: 0.592814\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025130; batch adversarial loss: 0.418406\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014351; batch adversarial loss: 0.492046\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010952; batch adversarial loss: 0.473405\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014310; batch adversarial loss: 0.449622\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009673; batch adversarial loss: 0.463715\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015618; batch adversarial loss: 0.527461\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714996; batch adversarial loss: 0.762029\n",
      "epoch 1; iter: 0; batch classifier loss: 0.550983; batch adversarial loss: 0.702385\n",
      "epoch 2; iter: 0; batch classifier loss: 0.619676; batch adversarial loss: 0.681286\n",
      "epoch 3; iter: 0; batch classifier loss: 0.519374; batch adversarial loss: 0.589036\n",
      "epoch 4; iter: 0; batch classifier loss: 0.382003; batch adversarial loss: 0.590224\n",
      "epoch 5; iter: 0; batch classifier loss: 0.396155; batch adversarial loss: 0.581950\n",
      "epoch 6; iter: 0; batch classifier loss: 0.337563; batch adversarial loss: 0.570562\n",
      "epoch 7; iter: 0; batch classifier loss: 0.337071; batch adversarial loss: 0.541233\n",
      "epoch 8; iter: 0; batch classifier loss: 0.339488; batch adversarial loss: 0.544783\n",
      "epoch 9; iter: 0; batch classifier loss: 0.267924; batch adversarial loss: 0.546081\n",
      "epoch 10; iter: 0; batch classifier loss: 0.325104; batch adversarial loss: 0.512845\n",
      "epoch 11; iter: 0; batch classifier loss: 0.260155; batch adversarial loss: 0.521063\n",
      "epoch 12; iter: 0; batch classifier loss: 0.354036; batch adversarial loss: 0.540731\n",
      "epoch 13; iter: 0; batch classifier loss: 0.253891; batch adversarial loss: 0.507450\n",
      "epoch 14; iter: 0; batch classifier loss: 0.277947; batch adversarial loss: 0.470161\n",
      "epoch 15; iter: 0; batch classifier loss: 0.326894; batch adversarial loss: 0.529626\n",
      "epoch 16; iter: 0; batch classifier loss: 0.262822; batch adversarial loss: 0.506838\n",
      "epoch 17; iter: 0; batch classifier loss: 0.239233; batch adversarial loss: 0.447234\n",
      "epoch 18; iter: 0; batch classifier loss: 0.227543; batch adversarial loss: 0.471912\n",
      "epoch 19; iter: 0; batch classifier loss: 0.264828; batch adversarial loss: 0.469575\n",
      "epoch 20; iter: 0; batch classifier loss: 0.241643; batch adversarial loss: 0.501912\n",
      "epoch 21; iter: 0; batch classifier loss: 0.172406; batch adversarial loss: 0.469003\n",
      "epoch 22; iter: 0; batch classifier loss: 0.185998; batch adversarial loss: 0.599821\n",
      "epoch 23; iter: 0; batch classifier loss: 0.243290; batch adversarial loss: 0.496155\n",
      "epoch 24; iter: 0; batch classifier loss: 0.215456; batch adversarial loss: 0.524177\n",
      "epoch 25; iter: 0; batch classifier loss: 0.217843; batch adversarial loss: 0.509059\n",
      "epoch 26; iter: 0; batch classifier loss: 0.168209; batch adversarial loss: 0.496127\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178952; batch adversarial loss: 0.508177\n",
      "epoch 28; iter: 0; batch classifier loss: 0.236956; batch adversarial loss: 0.435363\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182111; batch adversarial loss: 0.483104\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153072; batch adversarial loss: 0.405335\n",
      "epoch 31; iter: 0; batch classifier loss: 0.157542; batch adversarial loss: 0.492753\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181969; batch adversarial loss: 0.502959\n",
      "epoch 33; iter: 0; batch classifier loss: 0.156853; batch adversarial loss: 0.516672\n",
      "epoch 34; iter: 0; batch classifier loss: 0.168899; batch adversarial loss: 0.426875\n",
      "epoch 35; iter: 0; batch classifier loss: 0.173326; batch adversarial loss: 0.498881\n",
      "epoch 36; iter: 0; batch classifier loss: 0.204686; batch adversarial loss: 0.420954\n",
      "epoch 37; iter: 0; batch classifier loss: 0.155457; batch adversarial loss: 0.406344\n",
      "epoch 38; iter: 0; batch classifier loss: 0.207264; batch adversarial loss: 0.499483\n",
      "epoch 39; iter: 0; batch classifier loss: 0.227391; batch adversarial loss: 0.536348\n",
      "epoch 40; iter: 0; batch classifier loss: 0.158773; batch adversarial loss: 0.497171\n",
      "epoch 41; iter: 0; batch classifier loss: 0.240714; batch adversarial loss: 0.454830\n",
      "epoch 42; iter: 0; batch classifier loss: 0.149043; batch adversarial loss: 0.524985\n",
      "epoch 43; iter: 0; batch classifier loss: 0.156176; batch adversarial loss: 0.480902\n",
      "epoch 44; iter: 0; batch classifier loss: 0.208469; batch adversarial loss: 0.494476\n",
      "epoch 45; iter: 0; batch classifier loss: 0.150544; batch adversarial loss: 0.532221\n",
      "epoch 46; iter: 0; batch classifier loss: 0.121982; batch adversarial loss: 0.483905\n",
      "epoch 47; iter: 0; batch classifier loss: 0.134076; batch adversarial loss: 0.521616\n",
      "epoch 48; iter: 0; batch classifier loss: 0.111515; batch adversarial loss: 0.445740\n",
      "epoch 49; iter: 0; batch classifier loss: 0.169027; batch adversarial loss: 0.400846\n",
      "epoch 50; iter: 0; batch classifier loss: 0.093171; batch adversarial loss: 0.436845\n",
      "epoch 51; iter: 0; batch classifier loss: 0.145691; batch adversarial loss: 0.517770\n",
      "epoch 52; iter: 0; batch classifier loss: 0.154085; batch adversarial loss: 0.454533\n",
      "epoch 53; iter: 0; batch classifier loss: 0.110288; batch adversarial loss: 0.426090\n",
      "epoch 54; iter: 0; batch classifier loss: 0.084244; batch adversarial loss: 0.496677\n",
      "epoch 55; iter: 0; batch classifier loss: 0.148822; batch adversarial loss: 0.426179\n",
      "epoch 56; iter: 0; batch classifier loss: 0.134427; batch adversarial loss: 0.596822\n",
      "epoch 57; iter: 0; batch classifier loss: 0.119624; batch adversarial loss: 0.420568\n",
      "epoch 58; iter: 0; batch classifier loss: 0.076425; batch adversarial loss: 0.488127\n",
      "epoch 59; iter: 0; batch classifier loss: 0.118221; batch adversarial loss: 0.473448\n",
      "epoch 60; iter: 0; batch classifier loss: 0.119576; batch adversarial loss: 0.449617\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099656; batch adversarial loss: 0.517707\n",
      "epoch 62; iter: 0; batch classifier loss: 0.121204; batch adversarial loss: 0.453926\n",
      "epoch 63; iter: 0; batch classifier loss: 0.108000; batch adversarial loss: 0.413508\n",
      "epoch 64; iter: 0; batch classifier loss: 0.094173; batch adversarial loss: 0.487067\n",
      "epoch 65; iter: 0; batch classifier loss: 0.086672; batch adversarial loss: 0.465518\n",
      "epoch 66; iter: 0; batch classifier loss: 0.111502; batch adversarial loss: 0.469108\n",
      "epoch 67; iter: 0; batch classifier loss: 0.084248; batch adversarial loss: 0.476109\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082159; batch adversarial loss: 0.467617\n",
      "epoch 69; iter: 0; batch classifier loss: 0.093461; batch adversarial loss: 0.536941\n",
      "epoch 70; iter: 0; batch classifier loss: 0.087647; batch adversarial loss: 0.422795\n",
      "epoch 71; iter: 0; batch classifier loss: 0.113774; batch adversarial loss: 0.491077\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074049; batch adversarial loss: 0.474045\n",
      "epoch 73; iter: 0; batch classifier loss: 0.098497; batch adversarial loss: 0.465728\n",
      "epoch 74; iter: 0; batch classifier loss: 0.087781; batch adversarial loss: 0.459186\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077478; batch adversarial loss: 0.470278\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058599; batch adversarial loss: 0.469255\n",
      "epoch 77; iter: 0; batch classifier loss: 0.088781; batch adversarial loss: 0.458051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.042575; batch adversarial loss: 0.456387\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085798; batch adversarial loss: 0.472265\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067909; batch adversarial loss: 0.479638\n",
      "epoch 81; iter: 0; batch classifier loss: 0.102873; batch adversarial loss: 0.415142\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053952; batch adversarial loss: 0.471635\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063655; batch adversarial loss: 0.484152\n",
      "epoch 84; iter: 0; batch classifier loss: 0.032486; batch adversarial loss: 0.394032\n",
      "epoch 85; iter: 0; batch classifier loss: 0.082816; batch adversarial loss: 0.470343\n",
      "epoch 86; iter: 0; batch classifier loss: 0.045114; batch adversarial loss: 0.591215\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068834; batch adversarial loss: 0.388599\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056289; batch adversarial loss: 0.470357\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054197; batch adversarial loss: 0.536776\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053581; batch adversarial loss: 0.471810\n",
      "epoch 91; iter: 0; batch classifier loss: 0.044250; batch adversarial loss: 0.420449\n",
      "epoch 92; iter: 0; batch classifier loss: 0.036857; batch adversarial loss: 0.365562\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061498; batch adversarial loss: 0.394065\n",
      "epoch 94; iter: 0; batch classifier loss: 0.028318; batch adversarial loss: 0.436900\n",
      "epoch 95; iter: 0; batch classifier loss: 0.072008; batch adversarial loss: 0.509329\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070917; batch adversarial loss: 0.388246\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052923; batch adversarial loss: 0.492218\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044621; batch adversarial loss: 0.442390\n",
      "epoch 99; iter: 0; batch classifier loss: 0.022919; batch adversarial loss: 0.481314\n",
      "epoch 100; iter: 0; batch classifier loss: 0.042301; batch adversarial loss: 0.525096\n",
      "epoch 101; iter: 0; batch classifier loss: 0.023299; batch adversarial loss: 0.399772\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049613; batch adversarial loss: 0.389430\n",
      "epoch 103; iter: 0; batch classifier loss: 0.021844; batch adversarial loss: 0.499948\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060541; batch adversarial loss: 0.450141\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036143; batch adversarial loss: 0.496668\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042190; batch adversarial loss: 0.471687\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046109; batch adversarial loss: 0.411305\n",
      "epoch 108; iter: 0; batch classifier loss: 0.021441; batch adversarial loss: 0.461923\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050975; batch adversarial loss: 0.389071\n",
      "epoch 110; iter: 0; batch classifier loss: 0.029255; batch adversarial loss: 0.395912\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043832; batch adversarial loss: 0.466101\n",
      "epoch 112; iter: 0; batch classifier loss: 0.068796; batch adversarial loss: 0.470470\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033868; batch adversarial loss: 0.504337\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068502; batch adversarial loss: 0.422457\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046309; batch adversarial loss: 0.494215\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024315; batch adversarial loss: 0.572086\n",
      "epoch 117; iter: 0; batch classifier loss: 0.013863; batch adversarial loss: 0.421404\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036403; batch adversarial loss: 0.459940\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059974; batch adversarial loss: 0.454544\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049787; batch adversarial loss: 0.359621\n",
      "epoch 121; iter: 0; batch classifier loss: 0.020157; batch adversarial loss: 0.486383\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046721; batch adversarial loss: 0.462100\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023718; batch adversarial loss: 0.473171\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023356; batch adversarial loss: 0.494186\n",
      "epoch 125; iter: 0; batch classifier loss: 0.077387; batch adversarial loss: 0.433743\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030424; batch adversarial loss: 0.464354\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029553; batch adversarial loss: 0.452895\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041764; batch adversarial loss: 0.442313\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026872; batch adversarial loss: 0.377674\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033309; batch adversarial loss: 0.487381\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045630; batch adversarial loss: 0.508184\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023308; batch adversarial loss: 0.332555\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033443; batch adversarial loss: 0.548453\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015372; batch adversarial loss: 0.407335\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033151; batch adversarial loss: 0.462344\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024076; batch adversarial loss: 0.459010\n",
      "epoch 137; iter: 0; batch classifier loss: 0.016315; batch adversarial loss: 0.493036\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018774; batch adversarial loss: 0.446692\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010973; batch adversarial loss: 0.450597\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030435; batch adversarial loss: 0.357333\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018288; batch adversarial loss: 0.412270\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021010; batch adversarial loss: 0.396378\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013225; batch adversarial loss: 0.407216\n",
      "epoch 144; iter: 0; batch classifier loss: 0.010252; batch adversarial loss: 0.509628\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018273; batch adversarial loss: 0.550983\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016563; batch adversarial loss: 0.419380\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015932; batch adversarial loss: 0.409112\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038531; batch adversarial loss: 0.450565\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038390; batch adversarial loss: 0.450285\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016964; batch adversarial loss: 0.406166\n",
      "epoch 151; iter: 0; batch classifier loss: 0.005506; batch adversarial loss: 0.470171\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030818; batch adversarial loss: 0.387787\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029114; batch adversarial loss: 0.441973\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016013; batch adversarial loss: 0.397642\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033954; batch adversarial loss: 0.560264\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018722; batch adversarial loss: 0.533790\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023325; batch adversarial loss: 0.433091\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011445; batch adversarial loss: 0.521014\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032521; batch adversarial loss: 0.423483\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010175; batch adversarial loss: 0.421851\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031328; batch adversarial loss: 0.454787\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016503; batch adversarial loss: 0.475583\n",
      "epoch 163; iter: 0; batch classifier loss: 0.005915; batch adversarial loss: 0.466495\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018127; batch adversarial loss: 0.412414\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022176; batch adversarial loss: 0.468550\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015962; batch adversarial loss: 0.426420\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017604; batch adversarial loss: 0.538520\n",
      "epoch 168; iter: 0; batch classifier loss: 0.066266; batch adversarial loss: 0.477561\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017979; batch adversarial loss: 0.474983\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016395; batch adversarial loss: 0.423312\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008773; batch adversarial loss: 0.426755\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008710; batch adversarial loss: 0.457927\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035332; batch adversarial loss: 0.423207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.017169; batch adversarial loss: 0.405024\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006339; batch adversarial loss: 0.393582\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012807; batch adversarial loss: 0.448233\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017694; batch adversarial loss: 0.384006\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018719; batch adversarial loss: 0.348460\n",
      "epoch 179; iter: 0; batch classifier loss: 0.005554; batch adversarial loss: 0.404083\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021029; batch adversarial loss: 0.467798\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022010; batch adversarial loss: 0.497214\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014977; batch adversarial loss: 0.430625\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009912; batch adversarial loss: 0.431737\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008892; batch adversarial loss: 0.418146\n",
      "epoch 185; iter: 0; batch classifier loss: 0.053400; batch adversarial loss: 0.444733\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024222; batch adversarial loss: 0.581970\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016285; batch adversarial loss: 0.376667\n",
      "epoch 188; iter: 0; batch classifier loss: 0.038264; batch adversarial loss: 0.408008\n",
      "epoch 189; iter: 0; batch classifier loss: 0.053408; batch adversarial loss: 0.387836\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040943; batch adversarial loss: 0.458105\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020727; batch adversarial loss: 0.423149\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014941; batch adversarial loss: 0.508992\n",
      "epoch 193; iter: 0; batch classifier loss: 0.003900; batch adversarial loss: 0.499450\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018901; batch adversarial loss: 0.446588\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004635; batch adversarial loss: 0.441725\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010133; batch adversarial loss: 0.445823\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011424; batch adversarial loss: 0.498358\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014108; batch adversarial loss: 0.421335\n",
      "epoch 199; iter: 0; batch classifier loss: 0.034916; batch adversarial loss: 0.525621\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680073; batch adversarial loss: 0.725257\n",
      "epoch 1; iter: 0; batch classifier loss: 0.481398; batch adversarial loss: 0.667937\n",
      "epoch 2; iter: 0; batch classifier loss: 0.431516; batch adversarial loss: 0.638488\n",
      "epoch 3; iter: 0; batch classifier loss: 0.384472; batch adversarial loss: 0.624163\n",
      "epoch 4; iter: 0; batch classifier loss: 0.401840; batch adversarial loss: 0.580060\n",
      "epoch 5; iter: 0; batch classifier loss: 0.356811; batch adversarial loss: 0.578433\n",
      "epoch 6; iter: 0; batch classifier loss: 0.368039; batch adversarial loss: 0.549482\n",
      "epoch 7; iter: 0; batch classifier loss: 0.356527; batch adversarial loss: 0.580580\n",
      "epoch 8; iter: 0; batch classifier loss: 0.418577; batch adversarial loss: 0.579618\n",
      "epoch 9; iter: 0; batch classifier loss: 0.346736; batch adversarial loss: 0.556510\n",
      "epoch 10; iter: 0; batch classifier loss: 0.333715; batch adversarial loss: 0.528942\n",
      "epoch 11; iter: 0; batch classifier loss: 0.360801; batch adversarial loss: 0.544543\n",
      "epoch 12; iter: 0; batch classifier loss: 0.382714; batch adversarial loss: 0.535406\n",
      "epoch 13; iter: 0; batch classifier loss: 0.380394; batch adversarial loss: 0.516935\n",
      "epoch 14; iter: 0; batch classifier loss: 0.262895; batch adversarial loss: 0.517234\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364506; batch adversarial loss: 0.503605\n",
      "epoch 16; iter: 0; batch classifier loss: 0.288242; batch adversarial loss: 0.519709\n",
      "epoch 17; iter: 0; batch classifier loss: 0.371619; batch adversarial loss: 0.454829\n",
      "epoch 18; iter: 0; batch classifier loss: 0.371469; batch adversarial loss: 0.501953\n",
      "epoch 19; iter: 0; batch classifier loss: 0.234403; batch adversarial loss: 0.468352\n",
      "epoch 20; iter: 0; batch classifier loss: 0.278561; batch adversarial loss: 0.445666\n",
      "epoch 21; iter: 0; batch classifier loss: 0.282536; batch adversarial loss: 0.442402\n",
      "epoch 22; iter: 0; batch classifier loss: 0.286193; batch adversarial loss: 0.455690\n",
      "epoch 23; iter: 0; batch classifier loss: 0.250836; batch adversarial loss: 0.490544\n",
      "epoch 24; iter: 0; batch classifier loss: 0.253526; batch adversarial loss: 0.463104\n",
      "epoch 25; iter: 0; batch classifier loss: 0.170864; batch adversarial loss: 0.436632\n",
      "epoch 26; iter: 0; batch classifier loss: 0.233432; batch adversarial loss: 0.407325\n",
      "epoch 27; iter: 0; batch classifier loss: 0.213348; batch adversarial loss: 0.471735\n",
      "epoch 28; iter: 0; batch classifier loss: 0.200828; batch adversarial loss: 0.518903\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180371; batch adversarial loss: 0.486068\n",
      "epoch 30; iter: 0; batch classifier loss: 0.199941; batch adversarial loss: 0.520828\n",
      "epoch 31; iter: 0; batch classifier loss: 0.231805; batch adversarial loss: 0.410365\n",
      "epoch 32; iter: 0; batch classifier loss: 0.171568; batch adversarial loss: 0.506893\n",
      "epoch 33; iter: 0; batch classifier loss: 0.212330; batch adversarial loss: 0.507979\n",
      "epoch 34; iter: 0; batch classifier loss: 0.209136; batch adversarial loss: 0.478277\n",
      "epoch 35; iter: 0; batch classifier loss: 0.202212; batch adversarial loss: 0.453582\n",
      "epoch 36; iter: 0; batch classifier loss: 0.159430; batch adversarial loss: 0.442474\n",
      "epoch 37; iter: 0; batch classifier loss: 0.205435; batch adversarial loss: 0.523468\n",
      "epoch 38; iter: 0; batch classifier loss: 0.228895; batch adversarial loss: 0.475482\n",
      "epoch 39; iter: 0; batch classifier loss: 0.231372; batch adversarial loss: 0.449360\n",
      "epoch 40; iter: 0; batch classifier loss: 0.214469; batch adversarial loss: 0.469861\n",
      "epoch 41; iter: 0; batch classifier loss: 0.207487; batch adversarial loss: 0.473472\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200983; batch adversarial loss: 0.482946\n",
      "epoch 43; iter: 0; batch classifier loss: 0.173163; batch adversarial loss: 0.509833\n",
      "epoch 44; iter: 0; batch classifier loss: 0.244598; batch adversarial loss: 0.392880\n",
      "epoch 45; iter: 0; batch classifier loss: 0.195177; batch adversarial loss: 0.479162\n",
      "epoch 46; iter: 0; batch classifier loss: 0.268522; batch adversarial loss: 0.493560\n",
      "epoch 47; iter: 0; batch classifier loss: 0.242897; batch adversarial loss: 0.469982\n",
      "epoch 48; iter: 0; batch classifier loss: 0.194147; batch adversarial loss: 0.516975\n",
      "epoch 49; iter: 0; batch classifier loss: 0.238830; batch adversarial loss: 0.471267\n",
      "epoch 50; iter: 0; batch classifier loss: 0.206696; batch adversarial loss: 0.517695\n",
      "epoch 51; iter: 0; batch classifier loss: 0.171385; batch adversarial loss: 0.458840\n",
      "epoch 52; iter: 0; batch classifier loss: 0.237824; batch adversarial loss: 0.469426\n",
      "epoch 53; iter: 0; batch classifier loss: 0.257486; batch adversarial loss: 0.447391\n",
      "epoch 54; iter: 0; batch classifier loss: 0.121538; batch adversarial loss: 0.482387\n",
      "epoch 55; iter: 0; batch classifier loss: 0.160634; batch adversarial loss: 0.434704\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102115; batch adversarial loss: 0.444380\n",
      "epoch 57; iter: 0; batch classifier loss: 0.190489; batch adversarial loss: 0.519336\n",
      "epoch 58; iter: 0; batch classifier loss: 0.138837; batch adversarial loss: 0.471022\n",
      "epoch 59; iter: 0; batch classifier loss: 0.149098; batch adversarial loss: 0.507626\n",
      "epoch 60; iter: 0; batch classifier loss: 0.179253; batch adversarial loss: 0.517368\n",
      "epoch 61; iter: 0; batch classifier loss: 0.184294; batch adversarial loss: 0.480274\n",
      "epoch 62; iter: 0; batch classifier loss: 0.178959; batch adversarial loss: 0.422570\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128282; batch adversarial loss: 0.546520\n",
      "epoch 64; iter: 0; batch classifier loss: 0.123030; batch adversarial loss: 0.434664\n",
      "epoch 65; iter: 0; batch classifier loss: 0.189055; batch adversarial loss: 0.432943\n",
      "epoch 66; iter: 0; batch classifier loss: 0.178679; batch adversarial loss: 0.482521\n",
      "epoch 67; iter: 0; batch classifier loss: 0.164053; batch adversarial loss: 0.483593\n",
      "epoch 68; iter: 0; batch classifier loss: 0.208382; batch adversarial loss: 0.400307\n",
      "epoch 69; iter: 0; batch classifier loss: 0.186547; batch adversarial loss: 0.447671\n",
      "epoch 70; iter: 0; batch classifier loss: 0.167900; batch adversarial loss: 0.483343\n",
      "epoch 71; iter: 0; batch classifier loss: 0.229684; batch adversarial loss: 0.470283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.197029; batch adversarial loss: 0.460613\n",
      "epoch 73; iter: 0; batch classifier loss: 0.137764; batch adversarial loss: 0.457956\n",
      "epoch 74; iter: 0; batch classifier loss: 0.216600; batch adversarial loss: 0.374397\n",
      "epoch 75; iter: 0; batch classifier loss: 0.275116; batch adversarial loss: 0.494148\n",
      "epoch 76; iter: 0; batch classifier loss: 0.196957; batch adversarial loss: 0.506717\n",
      "epoch 77; iter: 0; batch classifier loss: 0.151622; batch adversarial loss: 0.434331\n",
      "epoch 78; iter: 0; batch classifier loss: 0.106205; batch adversarial loss: 0.506443\n",
      "epoch 79; iter: 0; batch classifier loss: 0.104209; batch adversarial loss: 0.506658\n",
      "epoch 80; iter: 0; batch classifier loss: 0.126863; batch adversarial loss: 0.506784\n",
      "epoch 81; iter: 0; batch classifier loss: 0.126517; batch adversarial loss: 0.493708\n",
      "epoch 82; iter: 0; batch classifier loss: 0.093195; batch adversarial loss: 0.461337\n",
      "epoch 83; iter: 0; batch classifier loss: 0.077943; batch adversarial loss: 0.384381\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067235; batch adversarial loss: 0.496263\n",
      "epoch 85; iter: 0; batch classifier loss: 0.069015; batch adversarial loss: 0.431598\n",
      "epoch 86; iter: 0; batch classifier loss: 0.110049; batch adversarial loss: 0.384710\n",
      "epoch 87; iter: 0; batch classifier loss: 0.096267; batch adversarial loss: 0.485104\n",
      "epoch 88; iter: 0; batch classifier loss: 0.107764; batch adversarial loss: 0.432846\n",
      "epoch 89; iter: 0; batch classifier loss: 0.119992; batch adversarial loss: 0.498348\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057373; batch adversarial loss: 0.468831\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081725; batch adversarial loss: 0.371540\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079358; batch adversarial loss: 0.396408\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051342; batch adversarial loss: 0.525215\n",
      "epoch 94; iter: 0; batch classifier loss: 0.065587; batch adversarial loss: 0.456391\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080916; batch adversarial loss: 0.395238\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065364; batch adversarial loss: 0.498689\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049244; batch adversarial loss: 0.530041\n",
      "epoch 98; iter: 0; batch classifier loss: 0.064109; batch adversarial loss: 0.502785\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044318; batch adversarial loss: 0.510179\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046849; batch adversarial loss: 0.445364\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063499; batch adversarial loss: 0.450114\n",
      "epoch 102; iter: 0; batch classifier loss: 0.072483; batch adversarial loss: 0.469611\n",
      "epoch 103; iter: 0; batch classifier loss: 0.026396; batch adversarial loss: 0.421036\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061256; batch adversarial loss: 0.408973\n",
      "epoch 105; iter: 0; batch classifier loss: 0.032292; batch adversarial loss: 0.460950\n",
      "epoch 106; iter: 0; batch classifier loss: 0.038647; batch adversarial loss: 0.448594\n",
      "epoch 107; iter: 0; batch classifier loss: 0.043672; batch adversarial loss: 0.451644\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028125; batch adversarial loss: 0.460813\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044688; batch adversarial loss: 0.477223\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028493; batch adversarial loss: 0.541397\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052640; batch adversarial loss: 0.603856\n",
      "epoch 112; iter: 0; batch classifier loss: 0.028805; batch adversarial loss: 0.425237\n",
      "epoch 113; iter: 0; batch classifier loss: 0.014959; batch adversarial loss: 0.524902\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072034; batch adversarial loss: 0.546008\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044873; batch adversarial loss: 0.477289\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030965; batch adversarial loss: 0.431538\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043733; batch adversarial loss: 0.366026\n",
      "epoch 118; iter: 0; batch classifier loss: 0.034996; batch adversarial loss: 0.455107\n",
      "epoch 119; iter: 0; batch classifier loss: 0.024962; batch adversarial loss: 0.494977\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032959; batch adversarial loss: 0.438296\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028188; batch adversarial loss: 0.457634\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043940; batch adversarial loss: 0.518119\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038331; batch adversarial loss: 0.549159\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039627; batch adversarial loss: 0.537991\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026821; batch adversarial loss: 0.474405\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056588; batch adversarial loss: 0.590603\n",
      "epoch 127; iter: 0; batch classifier loss: 0.014043; batch adversarial loss: 0.481939\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049120; batch adversarial loss: 0.517301\n",
      "epoch 129; iter: 0; batch classifier loss: 0.082121; batch adversarial loss: 0.484670\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056301; batch adversarial loss: 0.512035\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040196; batch adversarial loss: 0.466977\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019862; batch adversarial loss: 0.465668\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021991; batch adversarial loss: 0.425688\n",
      "epoch 134; iter: 0; batch classifier loss: 0.071808; batch adversarial loss: 0.362365\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021231; batch adversarial loss: 0.430253\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023678; batch adversarial loss: 0.484865\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023930; batch adversarial loss: 0.484717\n",
      "epoch 138; iter: 0; batch classifier loss: 0.015825; batch adversarial loss: 0.514150\n",
      "epoch 139; iter: 0; batch classifier loss: 0.027218; batch adversarial loss: 0.496508\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036249; batch adversarial loss: 0.479833\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021669; batch adversarial loss: 0.494593\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018224; batch adversarial loss: 0.451283\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050487; batch adversarial loss: 0.446821\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029215; batch adversarial loss: 0.484767\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031387; batch adversarial loss: 0.434522\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024574; batch adversarial loss: 0.351317\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021299; batch adversarial loss: 0.434486\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012331; batch adversarial loss: 0.409746\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026590; batch adversarial loss: 0.411132\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030357; batch adversarial loss: 0.368572\n",
      "epoch 151; iter: 0; batch classifier loss: 0.004334; batch adversarial loss: 0.391692\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029283; batch adversarial loss: 0.351186\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010268; batch adversarial loss: 0.490865\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010277; batch adversarial loss: 0.418930\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017738; batch adversarial loss: 0.534430\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021155; batch adversarial loss: 0.379029\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009834; batch adversarial loss: 0.418891\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021763; batch adversarial loss: 0.409113\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015525; batch adversarial loss: 0.427467\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015764; batch adversarial loss: 0.405051\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012543; batch adversarial loss: 0.459430\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013323; batch adversarial loss: 0.436374\n",
      "epoch 163; iter: 0; batch classifier loss: 0.046393; batch adversarial loss: 0.389791\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018714; batch adversarial loss: 0.426747\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009750; batch adversarial loss: 0.530386\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007955; batch adversarial loss: 0.463422\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010141; batch adversarial loss: 0.432950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.013670; batch adversarial loss: 0.481738\n",
      "epoch 169; iter: 0; batch classifier loss: 0.056859; batch adversarial loss: 0.396146\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035505; batch adversarial loss: 0.473518\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021761; batch adversarial loss: 0.424234\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013611; batch adversarial loss: 0.288350\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006840; batch adversarial loss: 0.471232\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020946; batch adversarial loss: 0.373273\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022338; batch adversarial loss: 0.471624\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019505; batch adversarial loss: 0.481914\n",
      "epoch 177; iter: 0; batch classifier loss: 0.005390; batch adversarial loss: 0.451881\n",
      "epoch 178; iter: 0; batch classifier loss: 0.046615; batch adversarial loss: 0.486486\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006261; batch adversarial loss: 0.447911\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019132; batch adversarial loss: 0.609615\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015693; batch adversarial loss: 0.374548\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017317; batch adversarial loss: 0.405173\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017863; batch adversarial loss: 0.494476\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004898; batch adversarial loss: 0.467723\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006592; batch adversarial loss: 0.480895\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005427; batch adversarial loss: 0.492085\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008419; batch adversarial loss: 0.382742\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012385; batch adversarial loss: 0.444074\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025230; batch adversarial loss: 0.407696\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005483; batch adversarial loss: 0.588053\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030220; batch adversarial loss: 0.467211\n",
      "epoch 192; iter: 0; batch classifier loss: 0.038547; batch adversarial loss: 0.428536\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014497; batch adversarial loss: 0.424142\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039087; batch adversarial loss: 0.417010\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008194; batch adversarial loss: 0.503641\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016132; batch adversarial loss: 0.424213\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008689; batch adversarial loss: 0.513292\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022064; batch adversarial loss: 0.477851\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018671; batch adversarial loss: 0.456618\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706585; batch adversarial loss: 0.793118\n",
      "epoch 1; iter: 0; batch classifier loss: 0.509904; batch adversarial loss: 0.755362\n",
      "epoch 2; iter: 0; batch classifier loss: 0.503518; batch adversarial loss: 0.717568\n",
      "epoch 3; iter: 0; batch classifier loss: 0.732295; batch adversarial loss: 0.673562\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537754; batch adversarial loss: 0.614684\n",
      "epoch 5; iter: 0; batch classifier loss: 0.513355; batch adversarial loss: 0.591772\n",
      "epoch 6; iter: 0; batch classifier loss: 0.434977; batch adversarial loss: 0.563513\n",
      "epoch 7; iter: 0; batch classifier loss: 0.356870; batch adversarial loss: 0.577275\n",
      "epoch 8; iter: 0; batch classifier loss: 0.381510; batch adversarial loss: 0.548071\n",
      "epoch 9; iter: 0; batch classifier loss: 0.344192; batch adversarial loss: 0.537111\n",
      "epoch 10; iter: 0; batch classifier loss: 0.345551; batch adversarial loss: 0.531505\n",
      "epoch 11; iter: 0; batch classifier loss: 0.372976; batch adversarial loss: 0.473520\n",
      "epoch 12; iter: 0; batch classifier loss: 0.437682; batch adversarial loss: 0.523626\n",
      "epoch 13; iter: 0; batch classifier loss: 0.369376; batch adversarial loss: 0.521039\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389291; batch adversarial loss: 0.488014\n",
      "epoch 15; iter: 0; batch classifier loss: 0.405962; batch adversarial loss: 0.505764\n",
      "epoch 16; iter: 0; batch classifier loss: 0.346926; batch adversarial loss: 0.547400\n",
      "epoch 17; iter: 0; batch classifier loss: 0.395858; batch adversarial loss: 0.448117\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466653; batch adversarial loss: 0.434357\n",
      "epoch 19; iter: 0; batch classifier loss: 0.335225; batch adversarial loss: 0.476364\n",
      "epoch 20; iter: 0; batch classifier loss: 0.355025; batch adversarial loss: 0.477030\n",
      "epoch 21; iter: 0; batch classifier loss: 0.368902; batch adversarial loss: 0.491892\n",
      "epoch 22; iter: 0; batch classifier loss: 0.323802; batch adversarial loss: 0.441133\n",
      "epoch 23; iter: 0; batch classifier loss: 0.292652; batch adversarial loss: 0.462801\n",
      "epoch 24; iter: 0; batch classifier loss: 0.357130; batch adversarial loss: 0.398626\n",
      "epoch 25; iter: 0; batch classifier loss: 0.279531; batch adversarial loss: 0.506873\n",
      "epoch 26; iter: 0; batch classifier loss: 0.276884; batch adversarial loss: 0.484979\n",
      "epoch 27; iter: 0; batch classifier loss: 0.319148; batch adversarial loss: 0.447547\n",
      "epoch 28; iter: 0; batch classifier loss: 0.291665; batch adversarial loss: 0.460008\n",
      "epoch 29; iter: 0; batch classifier loss: 0.192821; batch adversarial loss: 0.440920\n",
      "epoch 30; iter: 0; batch classifier loss: 0.285579; batch adversarial loss: 0.460839\n",
      "epoch 31; iter: 0; batch classifier loss: 0.244430; batch adversarial loss: 0.453356\n",
      "epoch 32; iter: 0; batch classifier loss: 0.266059; batch adversarial loss: 0.383483\n",
      "epoch 33; iter: 0; batch classifier loss: 0.245207; batch adversarial loss: 0.468865\n",
      "epoch 34; iter: 0; batch classifier loss: 0.218476; batch adversarial loss: 0.519073\n",
      "epoch 35; iter: 0; batch classifier loss: 0.205303; batch adversarial loss: 0.525573\n",
      "epoch 36; iter: 0; batch classifier loss: 0.250090; batch adversarial loss: 0.406388\n",
      "epoch 37; iter: 0; batch classifier loss: 0.219970; batch adversarial loss: 0.474952\n",
      "epoch 38; iter: 0; batch classifier loss: 0.232995; batch adversarial loss: 0.441224\n",
      "epoch 39; iter: 0; batch classifier loss: 0.211692; batch adversarial loss: 0.455562\n",
      "epoch 40; iter: 0; batch classifier loss: 0.260698; batch adversarial loss: 0.402181\n",
      "epoch 41; iter: 0; batch classifier loss: 0.209553; batch adversarial loss: 0.476678\n",
      "epoch 42; iter: 0; batch classifier loss: 0.230357; batch adversarial loss: 0.567008\n",
      "epoch 43; iter: 0; batch classifier loss: 0.229032; batch adversarial loss: 0.478491\n",
      "epoch 44; iter: 0; batch classifier loss: 0.170496; batch adversarial loss: 0.459753\n",
      "epoch 45; iter: 0; batch classifier loss: 0.207297; batch adversarial loss: 0.483825\n",
      "epoch 46; iter: 0; batch classifier loss: 0.208681; batch adversarial loss: 0.420104\n",
      "epoch 47; iter: 0; batch classifier loss: 0.219502; batch adversarial loss: 0.447387\n",
      "epoch 48; iter: 0; batch classifier loss: 0.218807; batch adversarial loss: 0.437549\n",
      "epoch 49; iter: 0; batch classifier loss: 0.224207; batch adversarial loss: 0.474894\n",
      "epoch 50; iter: 0; batch classifier loss: 0.221298; batch adversarial loss: 0.484988\n",
      "epoch 51; iter: 0; batch classifier loss: 0.241020; batch adversarial loss: 0.385025\n",
      "epoch 52; iter: 0; batch classifier loss: 0.191565; batch adversarial loss: 0.534907\n",
      "epoch 53; iter: 0; batch classifier loss: 0.243037; batch adversarial loss: 0.457310\n",
      "epoch 54; iter: 0; batch classifier loss: 0.191244; batch adversarial loss: 0.423609\n",
      "epoch 55; iter: 0; batch classifier loss: 0.191794; batch adversarial loss: 0.468579\n",
      "epoch 56; iter: 0; batch classifier loss: 0.218436; batch adversarial loss: 0.509003\n",
      "epoch 57; iter: 0; batch classifier loss: 0.235266; batch adversarial loss: 0.483372\n",
      "epoch 58; iter: 0; batch classifier loss: 0.237310; batch adversarial loss: 0.448743\n",
      "epoch 59; iter: 0; batch classifier loss: 0.181816; batch adversarial loss: 0.518545\n",
      "epoch 60; iter: 0; batch classifier loss: 0.180289; batch adversarial loss: 0.348882\n",
      "epoch 61; iter: 0; batch classifier loss: 0.193047; batch adversarial loss: 0.433791\n",
      "epoch 62; iter: 0; batch classifier loss: 0.175975; batch adversarial loss: 0.482491\n",
      "epoch 63; iter: 0; batch classifier loss: 0.186818; batch adversarial loss: 0.372260\n",
      "epoch 64; iter: 0; batch classifier loss: 0.227761; batch adversarial loss: 0.433967\n",
      "epoch 65; iter: 0; batch classifier loss: 0.153029; batch adversarial loss: 0.483284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.192792; batch adversarial loss: 0.507886\n",
      "epoch 67; iter: 0; batch classifier loss: 0.173580; batch adversarial loss: 0.397523\n",
      "epoch 68; iter: 0; batch classifier loss: 0.161995; batch adversarial loss: 0.495422\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073571; batch adversarial loss: 0.455293\n",
      "epoch 70; iter: 0; batch classifier loss: 0.134679; batch adversarial loss: 0.429264\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089080; batch adversarial loss: 0.434418\n",
      "epoch 72; iter: 0; batch classifier loss: 0.104611; batch adversarial loss: 0.431913\n",
      "epoch 73; iter: 0; batch classifier loss: 0.111971; batch adversarial loss: 0.463533\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076449; batch adversarial loss: 0.405876\n",
      "epoch 75; iter: 0; batch classifier loss: 0.111292; batch adversarial loss: 0.398218\n",
      "epoch 76; iter: 0; batch classifier loss: 0.157235; batch adversarial loss: 0.459549\n",
      "epoch 77; iter: 0; batch classifier loss: 0.082456; batch adversarial loss: 0.432788\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075126; batch adversarial loss: 0.481168\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085552; batch adversarial loss: 0.461455\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061177; batch adversarial loss: 0.545611\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065468; batch adversarial loss: 0.477019\n",
      "epoch 82; iter: 0; batch classifier loss: 0.079151; batch adversarial loss: 0.397104\n",
      "epoch 83; iter: 0; batch classifier loss: 0.110078; batch adversarial loss: 0.366546\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070719; batch adversarial loss: 0.470334\n",
      "epoch 85; iter: 0; batch classifier loss: 0.095496; batch adversarial loss: 0.390376\n",
      "epoch 86; iter: 0; batch classifier loss: 0.109805; batch adversarial loss: 0.429094\n",
      "epoch 87; iter: 0; batch classifier loss: 0.088646; batch adversarial loss: 0.409097\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062217; batch adversarial loss: 0.421155\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063402; batch adversarial loss: 0.430193\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045966; batch adversarial loss: 0.439906\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043891; batch adversarial loss: 0.450822\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040767; batch adversarial loss: 0.404074\n",
      "epoch 93; iter: 0; batch classifier loss: 0.073032; batch adversarial loss: 0.467707\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051894; batch adversarial loss: 0.466421\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038377; batch adversarial loss: 0.424971\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082717; batch adversarial loss: 0.384846\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069344; batch adversarial loss: 0.492553\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046139; batch adversarial loss: 0.602672\n",
      "epoch 99; iter: 0; batch classifier loss: 0.022159; batch adversarial loss: 0.524109\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038726; batch adversarial loss: 0.497102\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042213; batch adversarial loss: 0.512093\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034455; batch adversarial loss: 0.544448\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041841; batch adversarial loss: 0.395510\n",
      "epoch 104; iter: 0; batch classifier loss: 0.021694; batch adversarial loss: 0.437441\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057613; batch adversarial loss: 0.429463\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036464; batch adversarial loss: 0.459561\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027760; batch adversarial loss: 0.506335\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031017; batch adversarial loss: 0.446236\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053748; batch adversarial loss: 0.430622\n",
      "epoch 110; iter: 0; batch classifier loss: 0.075376; batch adversarial loss: 0.404633\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032977; batch adversarial loss: 0.464079\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057791; batch adversarial loss: 0.409211\n",
      "epoch 113; iter: 0; batch classifier loss: 0.010070; batch adversarial loss: 0.467859\n",
      "epoch 114; iter: 0; batch classifier loss: 0.020387; batch adversarial loss: 0.508091\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036882; batch adversarial loss: 0.441664\n",
      "epoch 116; iter: 0; batch classifier loss: 0.049923; batch adversarial loss: 0.545979\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026375; batch adversarial loss: 0.425335\n",
      "epoch 118; iter: 0; batch classifier loss: 0.020917; batch adversarial loss: 0.411541\n",
      "epoch 119; iter: 0; batch classifier loss: 0.061749; batch adversarial loss: 0.426992\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053285; batch adversarial loss: 0.463236\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039143; batch adversarial loss: 0.425039\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017647; batch adversarial loss: 0.466959\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032361; batch adversarial loss: 0.413425\n",
      "epoch 124; iter: 0; batch classifier loss: 0.049954; batch adversarial loss: 0.467300\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022520; batch adversarial loss: 0.531440\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022242; batch adversarial loss: 0.468233\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029936; batch adversarial loss: 0.458634\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043103; batch adversarial loss: 0.430427\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023133; batch adversarial loss: 0.431411\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023496; batch adversarial loss: 0.399695\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021338; batch adversarial loss: 0.497545\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032589; batch adversarial loss: 0.434058\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028797; batch adversarial loss: 0.599494\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038984; batch adversarial loss: 0.499375\n",
      "epoch 135; iter: 0; batch classifier loss: 0.066627; batch adversarial loss: 0.555158\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043251; batch adversarial loss: 0.421827\n",
      "epoch 137; iter: 0; batch classifier loss: 0.072281; batch adversarial loss: 0.522656\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034515; batch adversarial loss: 0.430212\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019157; batch adversarial loss: 0.370196\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020474; batch adversarial loss: 0.450143\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031701; batch adversarial loss: 0.553147\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026431; batch adversarial loss: 0.509917\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018593; batch adversarial loss: 0.516565\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020878; batch adversarial loss: 0.365958\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026966; batch adversarial loss: 0.456962\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017866; batch adversarial loss: 0.439988\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033552; batch adversarial loss: 0.417360\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017001; batch adversarial loss: 0.449703\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024340; batch adversarial loss: 0.466321\n",
      "epoch 150; iter: 0; batch classifier loss: 0.055786; batch adversarial loss: 0.477297\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010676; batch adversarial loss: 0.387553\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022045; batch adversarial loss: 0.435287\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023716; batch adversarial loss: 0.400281\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021950; batch adversarial loss: 0.402295\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018733; batch adversarial loss: 0.407920\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013406; batch adversarial loss: 0.447947\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017644; batch adversarial loss: 0.466059\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037037; batch adversarial loss: 0.377038\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017313; batch adversarial loss: 0.348470\n",
      "epoch 160; iter: 0; batch classifier loss: 0.066668; batch adversarial loss: 0.451017\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014283; batch adversarial loss: 0.537186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.030651; batch adversarial loss: 0.421318\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019741; batch adversarial loss: 0.384328\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034441; batch adversarial loss: 0.550744\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016770; batch adversarial loss: 0.482619\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017689; batch adversarial loss: 0.389100\n",
      "epoch 167; iter: 0; batch classifier loss: 0.089743; batch adversarial loss: 0.444089\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008150; batch adversarial loss: 0.550549\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017411; batch adversarial loss: 0.601922\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013074; batch adversarial loss: 0.463517\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014169; batch adversarial loss: 0.381580\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025885; batch adversarial loss: 0.470405\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035922; batch adversarial loss: 0.470046\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040795; batch adversarial loss: 0.481407\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013531; batch adversarial loss: 0.568286\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031072; batch adversarial loss: 0.441500\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017082; batch adversarial loss: 0.553521\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006231; batch adversarial loss: 0.485110\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027039; batch adversarial loss: 0.381943\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012534; batch adversarial loss: 0.388162\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008414; batch adversarial loss: 0.317178\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011505; batch adversarial loss: 0.351841\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027833; batch adversarial loss: 0.438467\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010491; batch adversarial loss: 0.508308\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007073; batch adversarial loss: 0.441471\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006541; batch adversarial loss: 0.426828\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013641; batch adversarial loss: 0.575348\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013163; batch adversarial loss: 0.441000\n",
      "epoch 189; iter: 0; batch classifier loss: 0.039349; batch adversarial loss: 0.491986\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024912; batch adversarial loss: 0.421443\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007497; batch adversarial loss: 0.435199\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006437; batch adversarial loss: 0.494766\n",
      "epoch 193; iter: 0; batch classifier loss: 0.003871; batch adversarial loss: 0.535435\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015170; batch adversarial loss: 0.409422\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017784; batch adversarial loss: 0.351630\n",
      "epoch 196; iter: 0; batch classifier loss: 0.050319; batch adversarial loss: 0.444092\n",
      "epoch 197; iter: 0; batch classifier loss: 0.003200; batch adversarial loss: 0.490129\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031334; batch adversarial loss: 0.490686\n",
      "epoch 199; iter: 0; batch classifier loss: 0.036816; batch adversarial loss: 0.398109\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668592; batch adversarial loss: 0.679151\n",
      "epoch 1; iter: 0; batch classifier loss: 0.496152; batch adversarial loss: 0.651279\n",
      "epoch 2; iter: 0; batch classifier loss: 0.461272; batch adversarial loss: 0.592612\n",
      "epoch 3; iter: 0; batch classifier loss: 0.469218; batch adversarial loss: 0.602760\n",
      "epoch 4; iter: 0; batch classifier loss: 0.483004; batch adversarial loss: 0.559289\n",
      "epoch 5; iter: 0; batch classifier loss: 0.383792; batch adversarial loss: 0.532888\n",
      "epoch 6; iter: 0; batch classifier loss: 0.333015; batch adversarial loss: 0.529870\n",
      "epoch 7; iter: 0; batch classifier loss: 0.292415; batch adversarial loss: 0.546187\n",
      "epoch 8; iter: 0; batch classifier loss: 0.359641; batch adversarial loss: 0.481027\n",
      "epoch 9; iter: 0; batch classifier loss: 0.281637; batch adversarial loss: 0.505006\n",
      "epoch 10; iter: 0; batch classifier loss: 0.315716; batch adversarial loss: 0.520199\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273312; batch adversarial loss: 0.549632\n",
      "epoch 12; iter: 0; batch classifier loss: 0.209760; batch adversarial loss: 0.530523\n",
      "epoch 13; iter: 0; batch classifier loss: 0.268481; batch adversarial loss: 0.516779\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274895; batch adversarial loss: 0.511625\n",
      "epoch 15; iter: 0; batch classifier loss: 0.288153; batch adversarial loss: 0.428526\n",
      "epoch 16; iter: 0; batch classifier loss: 0.265945; batch adversarial loss: 0.416141\n",
      "epoch 17; iter: 0; batch classifier loss: 0.179991; batch adversarial loss: 0.467430\n",
      "epoch 18; iter: 0; batch classifier loss: 0.240782; batch adversarial loss: 0.508732\n",
      "epoch 19; iter: 0; batch classifier loss: 0.125860; batch adversarial loss: 0.554206\n",
      "epoch 20; iter: 0; batch classifier loss: 0.177070; batch adversarial loss: 0.436659\n",
      "epoch 21; iter: 0; batch classifier loss: 0.208437; batch adversarial loss: 0.449355\n",
      "epoch 22; iter: 0; batch classifier loss: 0.176304; batch adversarial loss: 0.415018\n",
      "epoch 23; iter: 0; batch classifier loss: 0.132574; batch adversarial loss: 0.593194\n",
      "epoch 24; iter: 0; batch classifier loss: 0.118098; batch adversarial loss: 0.455705\n",
      "epoch 25; iter: 0; batch classifier loss: 0.122052; batch adversarial loss: 0.463505\n",
      "epoch 26; iter: 0; batch classifier loss: 0.123750; batch adversarial loss: 0.500277\n",
      "epoch 27; iter: 0; batch classifier loss: 0.132667; batch adversarial loss: 0.505508\n",
      "epoch 28; iter: 0; batch classifier loss: 0.156304; batch adversarial loss: 0.498618\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179533; batch adversarial loss: 0.522601\n",
      "epoch 30; iter: 0; batch classifier loss: 0.177274; batch adversarial loss: 0.423938\n",
      "epoch 31; iter: 0; batch classifier loss: 0.131175; batch adversarial loss: 0.542648\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146809; batch adversarial loss: 0.570875\n",
      "epoch 33; iter: 0; batch classifier loss: 0.153301; batch adversarial loss: 0.407069\n",
      "epoch 34; iter: 0; batch classifier loss: 0.163997; batch adversarial loss: 0.472532\n",
      "epoch 35; iter: 0; batch classifier loss: 0.150402; batch adversarial loss: 0.525281\n",
      "epoch 36; iter: 0; batch classifier loss: 0.194440; batch adversarial loss: 0.456724\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132275; batch adversarial loss: 0.452395\n",
      "epoch 38; iter: 0; batch classifier loss: 0.188205; batch adversarial loss: 0.395396\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125660; batch adversarial loss: 0.432033\n",
      "epoch 40; iter: 0; batch classifier loss: 0.243860; batch adversarial loss: 0.411884\n",
      "epoch 41; iter: 0; batch classifier loss: 0.138916; batch adversarial loss: 0.510856\n",
      "epoch 42; iter: 0; batch classifier loss: 0.127362; batch adversarial loss: 0.414674\n",
      "epoch 43; iter: 0; batch classifier loss: 0.163766; batch adversarial loss: 0.480175\n",
      "epoch 44; iter: 0; batch classifier loss: 0.188038; batch adversarial loss: 0.478348\n",
      "epoch 45; iter: 0; batch classifier loss: 0.112385; batch adversarial loss: 0.520072\n",
      "epoch 46; iter: 0; batch classifier loss: 0.180666; batch adversarial loss: 0.434070\n",
      "epoch 47; iter: 0; batch classifier loss: 0.132393; batch adversarial loss: 0.562775\n",
      "epoch 48; iter: 0; batch classifier loss: 0.177964; batch adversarial loss: 0.471847\n",
      "epoch 49; iter: 0; batch classifier loss: 0.145511; batch adversarial loss: 0.535211\n",
      "epoch 50; iter: 0; batch classifier loss: 0.151011; batch adversarial loss: 0.422550\n",
      "epoch 51; iter: 0; batch classifier loss: 0.134670; batch adversarial loss: 0.450830\n",
      "epoch 52; iter: 0; batch classifier loss: 0.193857; batch adversarial loss: 0.493343\n",
      "epoch 53; iter: 0; batch classifier loss: 0.154376; batch adversarial loss: 0.477185\n",
      "epoch 54; iter: 0; batch classifier loss: 0.152076; batch adversarial loss: 0.548903\n",
      "epoch 55; iter: 0; batch classifier loss: 0.203931; batch adversarial loss: 0.470012\n",
      "epoch 56; iter: 0; batch classifier loss: 0.183875; batch adversarial loss: 0.472146\n",
      "epoch 57; iter: 0; batch classifier loss: 0.167284; batch adversarial loss: 0.470243\n",
      "epoch 58; iter: 0; batch classifier loss: 0.170789; batch adversarial loss: 0.490850\n",
      "epoch 59; iter: 0; batch classifier loss: 0.219817; batch adversarial loss: 0.426499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.215540; batch adversarial loss: 0.388711\n",
      "epoch 61; iter: 0; batch classifier loss: 0.201510; batch adversarial loss: 0.395917\n",
      "epoch 62; iter: 0; batch classifier loss: 0.188390; batch adversarial loss: 0.422206\n",
      "epoch 63; iter: 0; batch classifier loss: 0.219696; batch adversarial loss: 0.400608\n",
      "epoch 64; iter: 0; batch classifier loss: 0.182698; batch adversarial loss: 0.506191\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110161; batch adversarial loss: 0.420243\n",
      "epoch 66; iter: 0; batch classifier loss: 0.220941; batch adversarial loss: 0.396688\n",
      "epoch 67; iter: 0; batch classifier loss: 0.221450; batch adversarial loss: 0.472443\n",
      "epoch 68; iter: 0; batch classifier loss: 0.169723; batch adversarial loss: 0.508426\n",
      "epoch 69; iter: 0; batch classifier loss: 0.198292; batch adversarial loss: 0.409874\n",
      "epoch 70; iter: 0; batch classifier loss: 0.311515; batch adversarial loss: 0.384921\n",
      "epoch 71; iter: 0; batch classifier loss: 0.225825; batch adversarial loss: 0.458136\n",
      "epoch 72; iter: 0; batch classifier loss: 0.110837; batch adversarial loss: 0.542346\n",
      "epoch 73; iter: 0; batch classifier loss: 0.137651; batch adversarial loss: 0.533983\n",
      "epoch 74; iter: 0; batch classifier loss: 0.154569; batch adversarial loss: 0.497177\n",
      "epoch 75; iter: 0; batch classifier loss: 0.131671; batch adversarial loss: 0.540169\n",
      "epoch 76; iter: 0; batch classifier loss: 0.258489; batch adversarial loss: 0.541590\n",
      "epoch 77; iter: 0; batch classifier loss: 0.191332; batch adversarial loss: 0.399602\n",
      "epoch 78; iter: 0; batch classifier loss: 0.215427; batch adversarial loss: 0.410734\n",
      "epoch 79; iter: 0; batch classifier loss: 0.220779; batch adversarial loss: 0.370756\n",
      "epoch 80; iter: 0; batch classifier loss: 0.240107; batch adversarial loss: 0.358242\n",
      "epoch 81; iter: 0; batch classifier loss: 0.288473; batch adversarial loss: 0.444973\n",
      "epoch 82; iter: 0; batch classifier loss: 0.217335; batch adversarial loss: 0.521839\n",
      "epoch 83; iter: 0; batch classifier loss: 0.151580; batch adversarial loss: 0.460829\n",
      "epoch 84; iter: 0; batch classifier loss: 0.178120; batch adversarial loss: 0.433179\n",
      "epoch 85; iter: 0; batch classifier loss: 0.205119; batch adversarial loss: 0.347998\n",
      "epoch 86; iter: 0; batch classifier loss: 0.128141; batch adversarial loss: 0.460000\n",
      "epoch 87; iter: 0; batch classifier loss: 0.178918; batch adversarial loss: 0.426401\n",
      "epoch 88; iter: 0; batch classifier loss: 0.135382; batch adversarial loss: 0.533933\n",
      "epoch 89; iter: 0; batch classifier loss: 0.171831; batch adversarial loss: 0.397292\n",
      "epoch 90; iter: 0; batch classifier loss: 0.151437; batch adversarial loss: 0.409263\n",
      "epoch 91; iter: 0; batch classifier loss: 0.154796; batch adversarial loss: 0.434389\n",
      "epoch 92; iter: 0; batch classifier loss: 0.262568; batch adversarial loss: 0.418942\n",
      "epoch 93; iter: 0; batch classifier loss: 0.238326; batch adversarial loss: 0.433481\n",
      "epoch 94; iter: 0; batch classifier loss: 0.143145; batch adversarial loss: 0.532630\n",
      "epoch 95; iter: 0; batch classifier loss: 0.176388; batch adversarial loss: 0.470106\n",
      "epoch 96; iter: 0; batch classifier loss: 0.137137; batch adversarial loss: 0.509201\n",
      "epoch 97; iter: 0; batch classifier loss: 0.142161; batch adversarial loss: 0.507912\n",
      "epoch 98; iter: 0; batch classifier loss: 0.206151; batch adversarial loss: 0.471938\n",
      "epoch 99; iter: 0; batch classifier loss: 0.196320; batch adversarial loss: 0.435622\n",
      "epoch 100; iter: 0; batch classifier loss: 0.135287; batch adversarial loss: 0.508716\n",
      "epoch 101; iter: 0; batch classifier loss: 0.264197; batch adversarial loss: 0.409884\n",
      "epoch 102; iter: 0; batch classifier loss: 0.182934; batch adversarial loss: 0.383158\n",
      "epoch 103; iter: 0; batch classifier loss: 0.210416; batch adversarial loss: 0.471236\n",
      "epoch 104; iter: 0; batch classifier loss: 0.211060; batch adversarial loss: 0.473006\n",
      "epoch 105; iter: 0; batch classifier loss: 0.218690; batch adversarial loss: 0.469767\n",
      "epoch 106; iter: 0; batch classifier loss: 0.203170; batch adversarial loss: 0.384471\n",
      "epoch 107; iter: 0; batch classifier loss: 0.152482; batch adversarial loss: 0.460585\n",
      "epoch 108; iter: 0; batch classifier loss: 0.186295; batch adversarial loss: 0.435344\n",
      "epoch 109; iter: 0; batch classifier loss: 0.158393; batch adversarial loss: 0.445967\n",
      "epoch 110; iter: 0; batch classifier loss: 0.159278; batch adversarial loss: 0.496995\n",
      "epoch 111; iter: 0; batch classifier loss: 0.208659; batch adversarial loss: 0.533389\n",
      "epoch 112; iter: 0; batch classifier loss: 0.138425; batch adversarial loss: 0.471949\n",
      "epoch 113; iter: 0; batch classifier loss: 0.147941; batch adversarial loss: 0.395716\n",
      "epoch 114; iter: 0; batch classifier loss: 0.185515; batch adversarial loss: 0.482921\n",
      "epoch 115; iter: 0; batch classifier loss: 0.178663; batch adversarial loss: 0.408149\n",
      "epoch 116; iter: 0; batch classifier loss: 0.193747; batch adversarial loss: 0.421826\n",
      "epoch 117; iter: 0; batch classifier loss: 0.188456; batch adversarial loss: 0.445930\n",
      "epoch 118; iter: 0; batch classifier loss: 0.189419; batch adversarial loss: 0.396027\n",
      "epoch 119; iter: 0; batch classifier loss: 0.124030; batch adversarial loss: 0.508110\n",
      "epoch 120; iter: 0; batch classifier loss: 0.136191; batch adversarial loss: 0.460628\n",
      "epoch 121; iter: 0; batch classifier loss: 0.179736; batch adversarial loss: 0.532364\n",
      "epoch 122; iter: 0; batch classifier loss: 0.215851; batch adversarial loss: 0.423177\n",
      "epoch 123; iter: 0; batch classifier loss: 0.169780; batch adversarial loss: 0.544778\n",
      "epoch 124; iter: 0; batch classifier loss: 0.224681; batch adversarial loss: 0.483541\n",
      "epoch 125; iter: 0; batch classifier loss: 0.135954; batch adversarial loss: 0.408967\n",
      "epoch 126; iter: 0; batch classifier loss: 0.184329; batch adversarial loss: 0.506292\n",
      "epoch 127; iter: 0; batch classifier loss: 0.135939; batch adversarial loss: 0.508140\n",
      "epoch 128; iter: 0; batch classifier loss: 0.194191; batch adversarial loss: 0.396659\n",
      "epoch 129; iter: 0; batch classifier loss: 0.141534; batch adversarial loss: 0.407596\n",
      "epoch 130; iter: 0; batch classifier loss: 0.225379; batch adversarial loss: 0.407493\n",
      "epoch 131; iter: 0; batch classifier loss: 0.278145; batch adversarial loss: 0.323418\n",
      "epoch 132; iter: 0; batch classifier loss: 0.134944; batch adversarial loss: 0.532497\n",
      "epoch 133; iter: 0; batch classifier loss: 0.204231; batch adversarial loss: 0.370092\n",
      "epoch 134; iter: 0; batch classifier loss: 0.112509; batch adversarial loss: 0.419805\n",
      "epoch 135; iter: 0; batch classifier loss: 0.217984; batch adversarial loss: 0.462338\n",
      "epoch 136; iter: 0; batch classifier loss: 0.195111; batch adversarial loss: 0.409082\n",
      "epoch 137; iter: 0; batch classifier loss: 0.138987; batch adversarial loss: 0.434917\n",
      "epoch 138; iter: 0; batch classifier loss: 0.176656; batch adversarial loss: 0.449472\n",
      "epoch 139; iter: 0; batch classifier loss: 0.182610; batch adversarial loss: 0.421977\n",
      "epoch 140; iter: 0; batch classifier loss: 0.108800; batch adversarial loss: 0.521537\n",
      "epoch 141; iter: 0; batch classifier loss: 0.151379; batch adversarial loss: 0.430518\n",
      "epoch 142; iter: 0; batch classifier loss: 0.157086; batch adversarial loss: 0.369793\n",
      "epoch 143; iter: 0; batch classifier loss: 0.100896; batch adversarial loss: 0.551594\n",
      "epoch 144; iter: 0; batch classifier loss: 0.071585; batch adversarial loss: 0.439786\n",
      "epoch 145; iter: 0; batch classifier loss: 0.059905; batch adversarial loss: 0.476372\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032953; batch adversarial loss: 0.419842\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032485; batch adversarial loss: 0.504138\n",
      "epoch 148; iter: 0; batch classifier loss: 0.070758; batch adversarial loss: 0.578381\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036023; batch adversarial loss: 0.629030\n",
      "epoch 150; iter: 0; batch classifier loss: 0.049925; batch adversarial loss: 0.447833\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055273; batch adversarial loss: 0.411391\n",
      "epoch 152; iter: 0; batch classifier loss: 0.052634; batch adversarial loss: 0.476723\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018421; batch adversarial loss: 0.407966\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036446; batch adversarial loss: 0.494109\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035218; batch adversarial loss: 0.481428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.040654; batch adversarial loss: 0.404563\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035015; batch adversarial loss: 0.485855\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036272; batch adversarial loss: 0.525080\n",
      "epoch 159; iter: 0; batch classifier loss: 0.067335; batch adversarial loss: 0.430225\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012909; batch adversarial loss: 0.415399\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029670; batch adversarial loss: 0.389978\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022100; batch adversarial loss: 0.392725\n",
      "epoch 163; iter: 0; batch classifier loss: 0.031359; batch adversarial loss: 0.422377\n",
      "epoch 164; iter: 0; batch classifier loss: 0.044859; batch adversarial loss: 0.483883\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009153; batch adversarial loss: 0.565353\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020762; batch adversarial loss: 0.469585\n",
      "epoch 167; iter: 0; batch classifier loss: 0.063547; batch adversarial loss: 0.336369\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040581; batch adversarial loss: 0.367746\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025658; batch adversarial loss: 0.428352\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029436; batch adversarial loss: 0.385170\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026064; batch adversarial loss: 0.437656\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018674; batch adversarial loss: 0.456156\n",
      "epoch 173; iter: 0; batch classifier loss: 0.059014; batch adversarial loss: 0.447876\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014649; batch adversarial loss: 0.461743\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022352; batch adversarial loss: 0.318807\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021626; batch adversarial loss: 0.410084\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029086; batch adversarial loss: 0.424524\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026320; batch adversarial loss: 0.392326\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014431; batch adversarial loss: 0.429779\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027136; batch adversarial loss: 0.409262\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023592; batch adversarial loss: 0.445629\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015367; batch adversarial loss: 0.439245\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011815; batch adversarial loss: 0.519864\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022014; batch adversarial loss: 0.489937\n",
      "epoch 185; iter: 0; batch classifier loss: 0.055817; batch adversarial loss: 0.526160\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040229; batch adversarial loss: 0.497002\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020168; batch adversarial loss: 0.479557\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020727; batch adversarial loss: 0.418057\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010624; batch adversarial loss: 0.321510\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009338; batch adversarial loss: 0.470771\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006969; batch adversarial loss: 0.416043\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010283; batch adversarial loss: 0.418442\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009115; batch adversarial loss: 0.464046\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014575; batch adversarial loss: 0.429532\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012557; batch adversarial loss: 0.472140\n",
      "epoch 196; iter: 0; batch classifier loss: 0.034372; batch adversarial loss: 0.471919\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023426; batch adversarial loss: 0.462269\n",
      "epoch 198; iter: 0; batch classifier loss: 0.049372; batch adversarial loss: 0.350606\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006033; batch adversarial loss: 0.463896\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730392; batch adversarial loss: 0.590132\n",
      "epoch 1; iter: 0; batch classifier loss: 0.538899; batch adversarial loss: 0.598700\n",
      "epoch 2; iter: 0; batch classifier loss: 0.433607; batch adversarial loss: 0.590938\n",
      "epoch 3; iter: 0; batch classifier loss: 0.299097; batch adversarial loss: 0.565587\n",
      "epoch 4; iter: 0; batch classifier loss: 0.318632; batch adversarial loss: 0.558198\n",
      "epoch 5; iter: 0; batch classifier loss: 0.374014; batch adversarial loss: 0.525153\n",
      "epoch 6; iter: 0; batch classifier loss: 0.260337; batch adversarial loss: 0.541530\n",
      "epoch 7; iter: 0; batch classifier loss: 0.218154; batch adversarial loss: 0.523879\n",
      "epoch 8; iter: 0; batch classifier loss: 0.230394; batch adversarial loss: 0.465737\n",
      "epoch 9; iter: 0; batch classifier loss: 0.224752; batch adversarial loss: 0.516867\n",
      "epoch 10; iter: 0; batch classifier loss: 0.289353; batch adversarial loss: 0.572056\n",
      "epoch 11; iter: 0; batch classifier loss: 0.255295; batch adversarial loss: 0.447039\n",
      "epoch 12; iter: 0; batch classifier loss: 0.228448; batch adversarial loss: 0.505990\n",
      "epoch 13; iter: 0; batch classifier loss: 0.223926; batch adversarial loss: 0.433661\n",
      "epoch 14; iter: 0; batch classifier loss: 0.239931; batch adversarial loss: 0.493578\n",
      "epoch 15; iter: 0; batch classifier loss: 0.286750; batch adversarial loss: 0.517456\n",
      "epoch 16; iter: 0; batch classifier loss: 0.234082; batch adversarial loss: 0.524641\n",
      "epoch 17; iter: 0; batch classifier loss: 0.240268; batch adversarial loss: 0.526168\n",
      "epoch 18; iter: 0; batch classifier loss: 0.194085; batch adversarial loss: 0.490402\n",
      "epoch 19; iter: 0; batch classifier loss: 0.227760; batch adversarial loss: 0.501081\n",
      "epoch 20; iter: 0; batch classifier loss: 0.230589; batch adversarial loss: 0.495039\n",
      "epoch 21; iter: 0; batch classifier loss: 0.295860; batch adversarial loss: 0.556253\n",
      "epoch 22; iter: 0; batch classifier loss: 0.187796; batch adversarial loss: 0.541390\n",
      "epoch 23; iter: 0; batch classifier loss: 0.231762; batch adversarial loss: 0.487292\n",
      "epoch 24; iter: 0; batch classifier loss: 0.329532; batch adversarial loss: 0.485632\n",
      "epoch 25; iter: 0; batch classifier loss: 0.381430; batch adversarial loss: 0.555894\n",
      "epoch 26; iter: 0; batch classifier loss: 0.283625; batch adversarial loss: 0.481315\n",
      "epoch 27; iter: 0; batch classifier loss: 0.179202; batch adversarial loss: 0.477806\n",
      "epoch 28; iter: 0; batch classifier loss: 0.120108; batch adversarial loss: 0.487462\n",
      "epoch 29; iter: 0; batch classifier loss: 0.159957; batch adversarial loss: 0.460186\n",
      "epoch 30; iter: 0; batch classifier loss: 0.111188; batch adversarial loss: 0.530671\n",
      "epoch 31; iter: 0; batch classifier loss: 0.108679; batch adversarial loss: 0.376200\n",
      "epoch 32; iter: 0; batch classifier loss: 0.098569; batch adversarial loss: 0.503056\n",
      "epoch 33; iter: 0; batch classifier loss: 0.135889; batch adversarial loss: 0.421738\n",
      "epoch 34; iter: 0; batch classifier loss: 0.138039; batch adversarial loss: 0.455294\n",
      "epoch 35; iter: 0; batch classifier loss: 0.098192; batch adversarial loss: 0.507754\n",
      "epoch 36; iter: 0; batch classifier loss: 0.105532; batch adversarial loss: 0.559524\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113360; batch adversarial loss: 0.442111\n",
      "epoch 38; iter: 0; batch classifier loss: 0.100612; batch adversarial loss: 0.424141\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118747; batch adversarial loss: 0.513665\n",
      "epoch 40; iter: 0; batch classifier loss: 0.123935; batch adversarial loss: 0.385141\n",
      "epoch 41; iter: 0; batch classifier loss: 0.075410; batch adversarial loss: 0.438755\n",
      "epoch 42; iter: 0; batch classifier loss: 0.073964; batch adversarial loss: 0.523217\n",
      "epoch 43; iter: 0; batch classifier loss: 0.063155; batch adversarial loss: 0.402931\n",
      "epoch 44; iter: 0; batch classifier loss: 0.096336; batch adversarial loss: 0.512612\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103811; batch adversarial loss: 0.465464\n",
      "epoch 46; iter: 0; batch classifier loss: 0.066192; batch adversarial loss: 0.374643\n",
      "epoch 47; iter: 0; batch classifier loss: 0.094398; batch adversarial loss: 0.393491\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092940; batch adversarial loss: 0.440138\n",
      "epoch 49; iter: 0; batch classifier loss: 0.084366; batch adversarial loss: 0.458059\n",
      "epoch 50; iter: 0; batch classifier loss: 0.097695; batch adversarial loss: 0.451525\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092479; batch adversarial loss: 0.389021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.059969; batch adversarial loss: 0.443831\n",
      "epoch 53; iter: 0; batch classifier loss: 0.057437; batch adversarial loss: 0.503800\n",
      "epoch 54; iter: 0; batch classifier loss: 0.091259; batch adversarial loss: 0.461837\n",
      "epoch 55; iter: 0; batch classifier loss: 0.063752; batch adversarial loss: 0.449766\n",
      "epoch 56; iter: 0; batch classifier loss: 0.089410; batch adversarial loss: 0.434978\n",
      "epoch 57; iter: 0; batch classifier loss: 0.077875; batch adversarial loss: 0.491652\n",
      "epoch 58; iter: 0; batch classifier loss: 0.059992; batch adversarial loss: 0.479371\n",
      "epoch 59; iter: 0; batch classifier loss: 0.050244; batch adversarial loss: 0.430148\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087581; batch adversarial loss: 0.394254\n",
      "epoch 61; iter: 0; batch classifier loss: 0.075186; batch adversarial loss: 0.521890\n",
      "epoch 62; iter: 0; batch classifier loss: 0.074428; batch adversarial loss: 0.477223\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089115; batch adversarial loss: 0.443078\n",
      "epoch 64; iter: 0; batch classifier loss: 0.064438; batch adversarial loss: 0.418707\n",
      "epoch 65; iter: 0; batch classifier loss: 0.063986; batch adversarial loss: 0.469829\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068273; batch adversarial loss: 0.411648\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095804; batch adversarial loss: 0.474124\n",
      "epoch 68; iter: 0; batch classifier loss: 0.052270; batch adversarial loss: 0.476196\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084106; batch adversarial loss: 0.454423\n",
      "epoch 70; iter: 0; batch classifier loss: 0.074073; batch adversarial loss: 0.538596\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079020; batch adversarial loss: 0.521079\n",
      "epoch 72; iter: 0; batch classifier loss: 0.069001; batch adversarial loss: 0.457888\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081451; batch adversarial loss: 0.452516\n",
      "epoch 74; iter: 0; batch classifier loss: 0.055167; batch adversarial loss: 0.521590\n",
      "epoch 75; iter: 0; batch classifier loss: 0.040299; batch adversarial loss: 0.433249\n",
      "epoch 76; iter: 0; batch classifier loss: 0.079335; batch adversarial loss: 0.522813\n",
      "epoch 77; iter: 0; batch classifier loss: 0.054650; batch adversarial loss: 0.535643\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072897; batch adversarial loss: 0.417966\n",
      "epoch 79; iter: 0; batch classifier loss: 0.043182; batch adversarial loss: 0.508493\n",
      "epoch 80; iter: 0; batch classifier loss: 0.038471; batch adversarial loss: 0.427765\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064198; batch adversarial loss: 0.513044\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061936; batch adversarial loss: 0.563384\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073584; batch adversarial loss: 0.428591\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047981; batch adversarial loss: 0.534992\n",
      "epoch 85; iter: 0; batch classifier loss: 0.049600; batch adversarial loss: 0.362772\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054198; batch adversarial loss: 0.481872\n",
      "epoch 87; iter: 0; batch classifier loss: 0.122618; batch adversarial loss: 0.527104\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062545; batch adversarial loss: 0.551205\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074488; batch adversarial loss: 0.412582\n",
      "epoch 90; iter: 0; batch classifier loss: 0.043114; batch adversarial loss: 0.527629\n",
      "epoch 91; iter: 0; batch classifier loss: 0.031270; batch adversarial loss: 0.447345\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043514; batch adversarial loss: 0.449951\n",
      "epoch 93; iter: 0; batch classifier loss: 0.021593; batch adversarial loss: 0.463403\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039804; batch adversarial loss: 0.470374\n",
      "epoch 95; iter: 0; batch classifier loss: 0.082073; batch adversarial loss: 0.434464\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036084; batch adversarial loss: 0.373020\n",
      "epoch 97; iter: 0; batch classifier loss: 0.058922; batch adversarial loss: 0.393706\n",
      "epoch 98; iter: 0; batch classifier loss: 0.076350; batch adversarial loss: 0.487762\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061732; batch adversarial loss: 0.429373\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074470; batch adversarial loss: 0.579850\n",
      "epoch 101; iter: 0; batch classifier loss: 0.094948; batch adversarial loss: 0.585481\n",
      "epoch 102; iter: 0; batch classifier loss: 0.098288; batch adversarial loss: 0.536031\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071475; batch adversarial loss: 0.507497\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046324; batch adversarial loss: 0.425771\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045741; batch adversarial loss: 0.575303\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044541; batch adversarial loss: 0.475697\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041965; batch adversarial loss: 0.410271\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040510; batch adversarial loss: 0.367781\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026279; batch adversarial loss: 0.476452\n",
      "epoch 110; iter: 0; batch classifier loss: 0.024678; batch adversarial loss: 0.462700\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060670; batch adversarial loss: 0.467647\n",
      "epoch 112; iter: 0; batch classifier loss: 0.021063; batch adversarial loss: 0.624672\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040575; batch adversarial loss: 0.413914\n",
      "epoch 114; iter: 0; batch classifier loss: 0.064165; batch adversarial loss: 0.393822\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034697; batch adversarial loss: 0.394373\n",
      "epoch 116; iter: 0; batch classifier loss: 0.031853; batch adversarial loss: 0.514935\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030718; batch adversarial loss: 0.440005\n",
      "epoch 118; iter: 0; batch classifier loss: 0.087342; batch adversarial loss: 0.408051\n",
      "epoch 119; iter: 0; batch classifier loss: 0.013201; batch adversarial loss: 0.428667\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030276; batch adversarial loss: 0.359780\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030978; batch adversarial loss: 0.493166\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021443; batch adversarial loss: 0.519708\n",
      "epoch 123; iter: 0; batch classifier loss: 0.069455; batch adversarial loss: 0.554499\n",
      "epoch 124; iter: 0; batch classifier loss: 0.060834; batch adversarial loss: 0.413720\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053948; batch adversarial loss: 0.481909\n",
      "epoch 126; iter: 0; batch classifier loss: 0.013590; batch adversarial loss: 0.527810\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048791; batch adversarial loss: 0.486796\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056874; batch adversarial loss: 0.459788\n",
      "epoch 129; iter: 0; batch classifier loss: 0.061727; batch adversarial loss: 0.407657\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034367; batch adversarial loss: 0.518332\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030002; batch adversarial loss: 0.496560\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020030; batch adversarial loss: 0.463009\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014284; batch adversarial loss: 0.388492\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022103; batch adversarial loss: 0.436110\n",
      "epoch 135; iter: 0; batch classifier loss: 0.048456; batch adversarial loss: 0.467424\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018607; batch adversarial loss: 0.456436\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042791; batch adversarial loss: 0.408627\n",
      "epoch 138; iter: 0; batch classifier loss: 0.047428; batch adversarial loss: 0.396624\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031546; batch adversarial loss: 0.436493\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017199; batch adversarial loss: 0.455833\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045099; batch adversarial loss: 0.385087\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035670; batch adversarial loss: 0.401441\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028613; batch adversarial loss: 0.506038\n",
      "epoch 144; iter: 0; batch classifier loss: 0.065963; batch adversarial loss: 0.400761\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039796; batch adversarial loss: 0.476774\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032809; batch adversarial loss: 0.463033\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030829; batch adversarial loss: 0.498474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.030794; batch adversarial loss: 0.392069\n",
      "epoch 149; iter: 0; batch classifier loss: 0.049680; batch adversarial loss: 0.461095\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019232; batch adversarial loss: 0.488346\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017461; batch adversarial loss: 0.454235\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031019; batch adversarial loss: 0.351718\n",
      "epoch 153; iter: 0; batch classifier loss: 0.033357; batch adversarial loss: 0.525662\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035941; batch adversarial loss: 0.510583\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049773; batch adversarial loss: 0.384138\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011959; batch adversarial loss: 0.482940\n",
      "epoch 157; iter: 0; batch classifier loss: 0.043734; batch adversarial loss: 0.369070\n",
      "epoch 158; iter: 0; batch classifier loss: 0.061649; batch adversarial loss: 0.448860\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014954; batch adversarial loss: 0.379772\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023775; batch adversarial loss: 0.432102\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010700; batch adversarial loss: 0.460890\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023140; batch adversarial loss: 0.460865\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030049; batch adversarial loss: 0.508276\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033362; batch adversarial loss: 0.437234\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040204; batch adversarial loss: 0.557829\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014966; batch adversarial loss: 0.600188\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028138; batch adversarial loss: 0.554846\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034323; batch adversarial loss: 0.466305\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031195; batch adversarial loss: 0.499490\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011850; batch adversarial loss: 0.411099\n",
      "epoch 171; iter: 0; batch classifier loss: 0.058418; batch adversarial loss: 0.519456\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006836; batch adversarial loss: 0.391598\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021293; batch adversarial loss: 0.451204\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041946; batch adversarial loss: 0.414316\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007569; batch adversarial loss: 0.466259\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030099; batch adversarial loss: 0.403169\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010884; batch adversarial loss: 0.506166\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028645; batch adversarial loss: 0.445026\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017302; batch adversarial loss: 0.393294\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034064; batch adversarial loss: 0.519768\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027745; batch adversarial loss: 0.403049\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022897; batch adversarial loss: 0.541253\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030636; batch adversarial loss: 0.416699\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025372; batch adversarial loss: 0.509054\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036999; batch adversarial loss: 0.370626\n",
      "epoch 186; iter: 0; batch classifier loss: 0.051330; batch adversarial loss: 0.516953\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030240; batch adversarial loss: 0.410829\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027238; batch adversarial loss: 0.523515\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041076; batch adversarial loss: 0.404775\n",
      "epoch 190; iter: 0; batch classifier loss: 0.044260; batch adversarial loss: 0.500538\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021396; batch adversarial loss: 0.425921\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018268; batch adversarial loss: 0.453662\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031939; batch adversarial loss: 0.413296\n",
      "epoch 194; iter: 0; batch classifier loss: 0.029719; batch adversarial loss: 0.430390\n",
      "epoch 195; iter: 0; batch classifier loss: 0.069839; batch adversarial loss: 0.469123\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023380; batch adversarial loss: 0.494617\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020575; batch adversarial loss: 0.459393\n",
      "epoch 198; iter: 0; batch classifier loss: 0.043220; batch adversarial loss: 0.430411\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023117; batch adversarial loss: 0.445471\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714519; batch adversarial loss: 0.759869\n",
      "epoch 1; iter: 0; batch classifier loss: 0.442524; batch adversarial loss: 0.726614\n",
      "epoch 2; iter: 0; batch classifier loss: 0.398165; batch adversarial loss: 0.688435\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393458; batch adversarial loss: 0.688784\n",
      "epoch 4; iter: 0; batch classifier loss: 0.337261; batch adversarial loss: 0.641922\n",
      "epoch 5; iter: 0; batch classifier loss: 0.335165; batch adversarial loss: 0.592912\n",
      "epoch 6; iter: 0; batch classifier loss: 0.292927; batch adversarial loss: 0.576668\n",
      "epoch 7; iter: 0; batch classifier loss: 0.309670; batch adversarial loss: 0.553559\n",
      "epoch 8; iter: 0; batch classifier loss: 0.289046; batch adversarial loss: 0.528662\n",
      "epoch 9; iter: 0; batch classifier loss: 0.260413; batch adversarial loss: 0.509711\n",
      "epoch 10; iter: 0; batch classifier loss: 0.228755; batch adversarial loss: 0.451272\n",
      "epoch 11; iter: 0; batch classifier loss: 0.323758; batch adversarial loss: 0.453553\n",
      "epoch 12; iter: 0; batch classifier loss: 0.233398; batch adversarial loss: 0.445250\n",
      "epoch 13; iter: 0; batch classifier loss: 0.213211; batch adversarial loss: 0.406659\n",
      "epoch 14; iter: 0; batch classifier loss: 0.217810; batch adversarial loss: 0.417491\n",
      "epoch 15; iter: 0; batch classifier loss: 0.248171; batch adversarial loss: 0.391123\n",
      "epoch 16; iter: 0; batch classifier loss: 0.173003; batch adversarial loss: 0.451663\n",
      "epoch 17; iter: 0; batch classifier loss: 0.253347; batch adversarial loss: 0.438843\n",
      "epoch 18; iter: 0; batch classifier loss: 0.189531; batch adversarial loss: 0.374722\n",
      "epoch 19; iter: 0; batch classifier loss: 0.203090; batch adversarial loss: 0.420761\n",
      "epoch 20; iter: 0; batch classifier loss: 0.282660; batch adversarial loss: 0.422023\n",
      "epoch 21; iter: 0; batch classifier loss: 0.212888; batch adversarial loss: 0.414989\n",
      "epoch 22; iter: 0; batch classifier loss: 0.194658; batch adversarial loss: 0.473604\n",
      "epoch 23; iter: 0; batch classifier loss: 0.147795; batch adversarial loss: 0.429733\n",
      "epoch 24; iter: 0; batch classifier loss: 0.186418; batch adversarial loss: 0.376449\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174688; batch adversarial loss: 0.498050\n",
      "epoch 26; iter: 0; batch classifier loss: 0.152349; batch adversarial loss: 0.393924\n",
      "epoch 27; iter: 0; batch classifier loss: 0.155579; batch adversarial loss: 0.344930\n",
      "epoch 28; iter: 0; batch classifier loss: 0.148734; batch adversarial loss: 0.393551\n",
      "epoch 29; iter: 0; batch classifier loss: 0.199221; batch adversarial loss: 0.396684\n",
      "epoch 30; iter: 0; batch classifier loss: 0.159556; batch adversarial loss: 0.382029\n",
      "epoch 31; iter: 0; batch classifier loss: 0.130944; batch adversarial loss: 0.437384\n",
      "epoch 32; iter: 0; batch classifier loss: 0.142079; batch adversarial loss: 0.427942\n",
      "epoch 33; iter: 0; batch classifier loss: 0.126565; batch adversarial loss: 0.376626\n",
      "epoch 34; iter: 0; batch classifier loss: 0.120639; batch adversarial loss: 0.389296\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153007; batch adversarial loss: 0.395265\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126208; batch adversarial loss: 0.398808\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111988; batch adversarial loss: 0.364157\n",
      "epoch 38; iter: 0; batch classifier loss: 0.121434; batch adversarial loss: 0.359553\n",
      "epoch 39; iter: 0; batch classifier loss: 0.081279; batch adversarial loss: 0.357423\n",
      "epoch 40; iter: 0; batch classifier loss: 0.120689; batch adversarial loss: 0.467001\n",
      "epoch 41; iter: 0; batch classifier loss: 0.132279; batch adversarial loss: 0.427533\n",
      "epoch 42; iter: 0; batch classifier loss: 0.093209; batch adversarial loss: 0.479640\n",
      "epoch 43; iter: 0; batch classifier loss: 0.118563; batch adversarial loss: 0.404027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.152336; batch adversarial loss: 0.535118\n",
      "epoch 45; iter: 0; batch classifier loss: 0.096311; batch adversarial loss: 0.392677\n",
      "epoch 46; iter: 0; batch classifier loss: 0.111846; batch adversarial loss: 0.391765\n",
      "epoch 47; iter: 0; batch classifier loss: 0.161187; batch adversarial loss: 0.429230\n",
      "epoch 48; iter: 0; batch classifier loss: 0.118710; batch adversarial loss: 0.376690\n",
      "epoch 49; iter: 0; batch classifier loss: 0.075579; batch adversarial loss: 0.384583\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108114; batch adversarial loss: 0.411153\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081707; batch adversarial loss: 0.384302\n",
      "epoch 52; iter: 0; batch classifier loss: 0.086904; batch adversarial loss: 0.481121\n",
      "epoch 53; iter: 0; batch classifier loss: 0.087296; batch adversarial loss: 0.471923\n",
      "epoch 54; iter: 0; batch classifier loss: 0.113364; batch adversarial loss: 0.449073\n",
      "epoch 55; iter: 0; batch classifier loss: 0.085366; batch adversarial loss: 0.446920\n",
      "epoch 56; iter: 0; batch classifier loss: 0.123793; batch adversarial loss: 0.513369\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082029; batch adversarial loss: 0.425736\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097374; batch adversarial loss: 0.425005\n",
      "epoch 59; iter: 0; batch classifier loss: 0.121444; batch adversarial loss: 0.425842\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070321; batch adversarial loss: 0.458646\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103119; batch adversarial loss: 0.353663\n",
      "epoch 62; iter: 0; batch classifier loss: 0.133832; batch adversarial loss: 0.415024\n",
      "epoch 63; iter: 0; batch classifier loss: 0.087220; batch adversarial loss: 0.431638\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070774; batch adversarial loss: 0.414631\n",
      "epoch 65; iter: 0; batch classifier loss: 0.097756; batch adversarial loss: 0.476355\n",
      "epoch 66; iter: 0; batch classifier loss: 0.079150; batch adversarial loss: 0.445502\n",
      "epoch 67; iter: 0; batch classifier loss: 0.085170; batch adversarial loss: 0.438955\n",
      "epoch 68; iter: 0; batch classifier loss: 0.068042; batch adversarial loss: 0.406110\n",
      "epoch 69; iter: 0; batch classifier loss: 0.089367; batch adversarial loss: 0.480140\n",
      "epoch 70; iter: 0; batch classifier loss: 0.096396; batch adversarial loss: 0.470375\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099642; batch adversarial loss: 0.466116\n",
      "epoch 72; iter: 0; batch classifier loss: 0.102611; batch adversarial loss: 0.432380\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062682; batch adversarial loss: 0.424157\n",
      "epoch 74; iter: 0; batch classifier loss: 0.078203; batch adversarial loss: 0.391459\n",
      "epoch 75; iter: 0; batch classifier loss: 0.048699; batch adversarial loss: 0.487140\n",
      "epoch 76; iter: 0; batch classifier loss: 0.078245; batch adversarial loss: 0.386750\n",
      "epoch 77; iter: 0; batch classifier loss: 0.053149; batch adversarial loss: 0.435797\n",
      "epoch 78; iter: 0; batch classifier loss: 0.058826; batch adversarial loss: 0.436007\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070222; batch adversarial loss: 0.423060\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053151; batch adversarial loss: 0.419341\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068547; batch adversarial loss: 0.392309\n",
      "epoch 82; iter: 0; batch classifier loss: 0.057069; batch adversarial loss: 0.437145\n",
      "epoch 83; iter: 0; batch classifier loss: 0.091102; batch adversarial loss: 0.421256\n",
      "epoch 84; iter: 0; batch classifier loss: 0.054617; batch adversarial loss: 0.431262\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083961; batch adversarial loss: 0.444849\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065075; batch adversarial loss: 0.452331\n",
      "epoch 87; iter: 0; batch classifier loss: 0.045659; batch adversarial loss: 0.400029\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042319; batch adversarial loss: 0.510132\n",
      "epoch 89; iter: 0; batch classifier loss: 0.077817; batch adversarial loss: 0.528420\n",
      "epoch 90; iter: 0; batch classifier loss: 0.043193; batch adversarial loss: 0.510798\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050853; batch adversarial loss: 0.451524\n",
      "epoch 92; iter: 0; batch classifier loss: 0.067171; batch adversarial loss: 0.508760\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041982; batch adversarial loss: 0.362934\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046970; batch adversarial loss: 0.395427\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073320; batch adversarial loss: 0.431614\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044189; batch adversarial loss: 0.425235\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066595; batch adversarial loss: 0.374698\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044916; batch adversarial loss: 0.379688\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063267; batch adversarial loss: 0.409601\n",
      "epoch 100; iter: 0; batch classifier loss: 0.041742; batch adversarial loss: 0.362164\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049608; batch adversarial loss: 0.396461\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027832; batch adversarial loss: 0.395096\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044234; batch adversarial loss: 0.412616\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041751; batch adversarial loss: 0.425348\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030843; batch adversarial loss: 0.331900\n",
      "epoch 106; iter: 0; batch classifier loss: 0.076641; batch adversarial loss: 0.409848\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036600; batch adversarial loss: 0.425355\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024818; batch adversarial loss: 0.420177\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033831; batch adversarial loss: 0.379539\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023210; batch adversarial loss: 0.456553\n",
      "epoch 111; iter: 0; batch classifier loss: 0.021641; batch adversarial loss: 0.456171\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037944; batch adversarial loss: 0.353321\n",
      "epoch 113; iter: 0; batch classifier loss: 0.022744; batch adversarial loss: 0.435748\n",
      "epoch 114; iter: 0; batch classifier loss: 0.023479; batch adversarial loss: 0.460900\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022583; batch adversarial loss: 0.539730\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024592; batch adversarial loss: 0.456381\n",
      "epoch 117; iter: 0; batch classifier loss: 0.057675; batch adversarial loss: 0.434275\n",
      "epoch 118; iter: 0; batch classifier loss: 0.015333; batch adversarial loss: 0.406852\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026035; batch adversarial loss: 0.380796\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049881; batch adversarial loss: 0.553415\n",
      "epoch 121; iter: 0; batch classifier loss: 0.017949; batch adversarial loss: 0.449221\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028756; batch adversarial loss: 0.451293\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019648; batch adversarial loss: 0.460476\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029887; batch adversarial loss: 0.432270\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017316; batch adversarial loss: 0.523878\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056361; batch adversarial loss: 0.449527\n",
      "epoch 127; iter: 0; batch classifier loss: 0.010101; batch adversarial loss: 0.420503\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019433; batch adversarial loss: 0.525835\n",
      "epoch 129; iter: 0; batch classifier loss: 0.077968; batch adversarial loss: 0.640419\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025326; batch adversarial loss: 0.435530\n",
      "epoch 131; iter: 0; batch classifier loss: 0.061224; batch adversarial loss: 0.503429\n",
      "epoch 132; iter: 0; batch classifier loss: 0.080560; batch adversarial loss: 0.526064\n",
      "epoch 133; iter: 0; batch classifier loss: 0.118276; batch adversarial loss: 0.696411\n",
      "epoch 134; iter: 0; batch classifier loss: 0.067984; batch adversarial loss: 0.667622\n",
      "epoch 135; iter: 0; batch classifier loss: 0.099871; batch adversarial loss: 0.611764\n",
      "epoch 136; iter: 0; batch classifier loss: 0.094427; batch adversarial loss: 0.538956\n",
      "epoch 137; iter: 0; batch classifier loss: 0.166940; batch adversarial loss: 0.745928\n",
      "epoch 138; iter: 0; batch classifier loss: 0.103135; batch adversarial loss: 0.566767\n",
      "epoch 139; iter: 0; batch classifier loss: 0.129963; batch adversarial loss: 0.636915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.171302; batch adversarial loss: 0.620706\n",
      "epoch 141; iter: 0; batch classifier loss: 0.174834; batch adversarial loss: 0.696113\n",
      "epoch 142; iter: 0; batch classifier loss: 0.215737; batch adversarial loss: 0.742404\n",
      "epoch 143; iter: 0; batch classifier loss: 0.221068; batch adversarial loss: 0.686727\n",
      "epoch 144; iter: 0; batch classifier loss: 0.282956; batch adversarial loss: 0.929458\n",
      "epoch 145; iter: 0; batch classifier loss: 0.167110; batch adversarial loss: 0.602390\n",
      "epoch 146; iter: 0; batch classifier loss: 0.293830; batch adversarial loss: 0.879088\n",
      "epoch 147; iter: 0; batch classifier loss: 0.177253; batch adversarial loss: 0.598152\n",
      "epoch 148; iter: 0; batch classifier loss: 0.105309; batch adversarial loss: 0.582685\n",
      "epoch 149; iter: 0; batch classifier loss: 0.249523; batch adversarial loss: 0.785332\n",
      "epoch 150; iter: 0; batch classifier loss: 0.178955; batch adversarial loss: 0.654687\n",
      "epoch 151; iter: 0; batch classifier loss: 0.111210; batch adversarial loss: 0.512268\n",
      "epoch 152; iter: 0; batch classifier loss: 0.206868; batch adversarial loss: 0.727464\n",
      "epoch 153; iter: 0; batch classifier loss: 0.222220; batch adversarial loss: 0.682195\n",
      "epoch 154; iter: 0; batch classifier loss: 0.122508; batch adversarial loss: 0.485172\n",
      "epoch 155; iter: 0; batch classifier loss: 0.205280; batch adversarial loss: 0.667033\n",
      "epoch 156; iter: 0; batch classifier loss: 0.223723; batch adversarial loss: 0.605451\n",
      "epoch 157; iter: 0; batch classifier loss: 0.177809; batch adversarial loss: 0.591824\n",
      "epoch 158; iter: 0; batch classifier loss: 0.142457; batch adversarial loss: 0.546715\n",
      "epoch 159; iter: 0; batch classifier loss: 0.211732; batch adversarial loss: 0.634193\n",
      "epoch 160; iter: 0; batch classifier loss: 0.058914; batch adversarial loss: 0.371394\n",
      "epoch 161; iter: 0; batch classifier loss: 0.138097; batch adversarial loss: 0.519983\n",
      "epoch 162; iter: 0; batch classifier loss: 0.180939; batch adversarial loss: 0.572434\n",
      "epoch 163; iter: 0; batch classifier loss: 0.148004; batch adversarial loss: 0.534317\n",
      "epoch 164; iter: 0; batch classifier loss: 0.166580; batch adversarial loss: 0.559602\n",
      "epoch 165; iter: 0; batch classifier loss: 0.108257; batch adversarial loss: 0.524187\n",
      "epoch 166; iter: 0; batch classifier loss: 0.133133; batch adversarial loss: 0.511011\n",
      "epoch 167; iter: 0; batch classifier loss: 0.127644; batch adversarial loss: 0.552702\n",
      "epoch 168; iter: 0; batch classifier loss: 0.165395; batch adversarial loss: 0.539829\n",
      "epoch 169; iter: 0; batch classifier loss: 0.132252; batch adversarial loss: 0.519187\n",
      "epoch 170; iter: 0; batch classifier loss: 0.112397; batch adversarial loss: 0.549472\n",
      "epoch 171; iter: 0; batch classifier loss: 0.143694; batch adversarial loss: 0.475211\n",
      "epoch 172; iter: 0; batch classifier loss: 0.193937; batch adversarial loss: 0.657039\n",
      "epoch 173; iter: 0; batch classifier loss: 0.106609; batch adversarial loss: 0.474894\n",
      "epoch 174; iter: 0; batch classifier loss: 0.167476; batch adversarial loss: 0.477026\n",
      "epoch 175; iter: 0; batch classifier loss: 0.122899; batch adversarial loss: 0.518011\n",
      "epoch 176; iter: 0; batch classifier loss: 0.112434; batch adversarial loss: 0.454302\n",
      "epoch 177; iter: 0; batch classifier loss: 0.149275; batch adversarial loss: 0.501607\n",
      "epoch 178; iter: 0; batch classifier loss: 0.098608; batch adversarial loss: 0.360051\n",
      "epoch 179; iter: 0; batch classifier loss: 0.184648; batch adversarial loss: 0.531447\n",
      "epoch 180; iter: 0; batch classifier loss: 0.146028; batch adversarial loss: 0.525180\n",
      "epoch 181; iter: 0; batch classifier loss: 0.090875; batch adversarial loss: 0.461363\n",
      "epoch 182; iter: 0; batch classifier loss: 0.094759; batch adversarial loss: 0.507441\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027244; batch adversarial loss: 0.418844\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027583; batch adversarial loss: 0.566744\n",
      "epoch 185; iter: 0; batch classifier loss: 0.059133; batch adversarial loss: 0.430388\n",
      "epoch 186; iter: 0; batch classifier loss: 0.067834; batch adversarial loss: 0.454226\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020389; batch adversarial loss: 0.387519\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032397; batch adversarial loss: 0.528725\n",
      "epoch 189; iter: 0; batch classifier loss: 0.066058; batch adversarial loss: 0.465658\n",
      "epoch 190; iter: 0; batch classifier loss: 0.080371; batch adversarial loss: 0.476430\n",
      "epoch 191; iter: 0; batch classifier loss: 0.039879; batch adversarial loss: 0.481572\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031507; batch adversarial loss: 0.406487\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019114; batch adversarial loss: 0.396429\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041403; batch adversarial loss: 0.473402\n",
      "epoch 195; iter: 0; batch classifier loss: 0.065419; batch adversarial loss: 0.427273\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026453; batch adversarial loss: 0.428757\n",
      "epoch 197; iter: 0; batch classifier loss: 0.058925; batch adversarial loss: 0.390137\n",
      "epoch 198; iter: 0; batch classifier loss: 0.048600; batch adversarial loss: 0.533809\n",
      "epoch 199; iter: 0; batch classifier loss: 0.057629; batch adversarial loss: 0.453718\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691715; batch adversarial loss: 0.568320\n",
      "epoch 1; iter: 0; batch classifier loss: 0.500984; batch adversarial loss: 0.589742\n",
      "epoch 2; iter: 0; batch classifier loss: 0.432194; batch adversarial loss: 0.623368\n",
      "epoch 3; iter: 0; batch classifier loss: 0.371425; batch adversarial loss: 0.591464\n",
      "epoch 4; iter: 0; batch classifier loss: 0.330180; batch adversarial loss: 0.685453\n",
      "epoch 5; iter: 0; batch classifier loss: 0.400990; batch adversarial loss: 0.580323\n",
      "epoch 6; iter: 0; batch classifier loss: 0.394765; batch adversarial loss: 0.593228\n",
      "epoch 7; iter: 0; batch classifier loss: 0.511019; batch adversarial loss: 0.570776\n",
      "epoch 8; iter: 0; batch classifier loss: 0.583892; batch adversarial loss: 0.589811\n",
      "epoch 9; iter: 0; batch classifier loss: 0.443156; batch adversarial loss: 0.566077\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511219; batch adversarial loss: 0.571703\n",
      "epoch 11; iter: 0; batch classifier loss: 0.358622; batch adversarial loss: 0.513018\n",
      "epoch 12; iter: 0; batch classifier loss: 0.302029; batch adversarial loss: 0.465694\n",
      "epoch 13; iter: 0; batch classifier loss: 0.310395; batch adversarial loss: 0.459678\n",
      "epoch 14; iter: 0; batch classifier loss: 0.259004; batch adversarial loss: 0.513501\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274537; batch adversarial loss: 0.529595\n",
      "epoch 16; iter: 0; batch classifier loss: 0.244943; batch adversarial loss: 0.452204\n",
      "epoch 17; iter: 0; batch classifier loss: 0.173267; batch adversarial loss: 0.467559\n",
      "epoch 18; iter: 0; batch classifier loss: 0.263730; batch adversarial loss: 0.521541\n",
      "epoch 19; iter: 0; batch classifier loss: 0.186324; batch adversarial loss: 0.496938\n",
      "epoch 20; iter: 0; batch classifier loss: 0.216304; batch adversarial loss: 0.511004\n",
      "epoch 21; iter: 0; batch classifier loss: 0.200676; batch adversarial loss: 0.506254\n",
      "epoch 22; iter: 0; batch classifier loss: 0.247946; batch adversarial loss: 0.479029\n",
      "epoch 23; iter: 0; batch classifier loss: 0.173943; batch adversarial loss: 0.465178\n",
      "epoch 24; iter: 0; batch classifier loss: 0.178028; batch adversarial loss: 0.451674\n",
      "epoch 25; iter: 0; batch classifier loss: 0.151811; batch adversarial loss: 0.431937\n",
      "epoch 26; iter: 0; batch classifier loss: 0.198780; batch adversarial loss: 0.483453\n",
      "epoch 27; iter: 0; batch classifier loss: 0.206403; batch adversarial loss: 0.434305\n",
      "epoch 28; iter: 0; batch classifier loss: 0.188144; batch adversarial loss: 0.398052\n",
      "epoch 29; iter: 0; batch classifier loss: 0.146341; batch adversarial loss: 0.403382\n",
      "epoch 30; iter: 0; batch classifier loss: 0.181086; batch adversarial loss: 0.471353\n",
      "epoch 31; iter: 0; batch classifier loss: 0.121886; batch adversarial loss: 0.514479\n",
      "epoch 32; iter: 0; batch classifier loss: 0.102977; batch adversarial loss: 0.502649\n",
      "epoch 33; iter: 0; batch classifier loss: 0.133018; batch adversarial loss: 0.443735\n",
      "epoch 34; iter: 0; batch classifier loss: 0.105154; batch adversarial loss: 0.363529\n",
      "epoch 35; iter: 0; batch classifier loss: 0.105282; batch adversarial loss: 0.533497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.169603; batch adversarial loss: 0.467960\n",
      "epoch 37; iter: 0; batch classifier loss: 0.126190; batch adversarial loss: 0.452742\n",
      "epoch 38; iter: 0; batch classifier loss: 0.142904; batch adversarial loss: 0.462300\n",
      "epoch 39; iter: 0; batch classifier loss: 0.138757; batch adversarial loss: 0.432883\n",
      "epoch 40; iter: 0; batch classifier loss: 0.129025; batch adversarial loss: 0.441765\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135113; batch adversarial loss: 0.485062\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106153; batch adversarial loss: 0.469012\n",
      "epoch 43; iter: 0; batch classifier loss: 0.167782; batch adversarial loss: 0.445254\n",
      "epoch 44; iter: 0; batch classifier loss: 0.141579; batch adversarial loss: 0.393767\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104079; batch adversarial loss: 0.479035\n",
      "epoch 46; iter: 0; batch classifier loss: 0.070282; batch adversarial loss: 0.454610\n",
      "epoch 47; iter: 0; batch classifier loss: 0.139948; batch adversarial loss: 0.466812\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092328; batch adversarial loss: 0.440164\n",
      "epoch 49; iter: 0; batch classifier loss: 0.077131; batch adversarial loss: 0.489742\n",
      "epoch 50; iter: 0; batch classifier loss: 0.117507; batch adversarial loss: 0.481538\n",
      "epoch 51; iter: 0; batch classifier loss: 0.093512; batch adversarial loss: 0.516473\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103509; batch adversarial loss: 0.507953\n",
      "epoch 53; iter: 0; batch classifier loss: 0.123478; batch adversarial loss: 0.534730\n",
      "epoch 54; iter: 0; batch classifier loss: 0.093951; batch adversarial loss: 0.478888\n",
      "epoch 55; iter: 0; batch classifier loss: 0.121707; batch adversarial loss: 0.431166\n",
      "epoch 56; iter: 0; batch classifier loss: 0.089971; batch adversarial loss: 0.442984\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072011; batch adversarial loss: 0.489379\n",
      "epoch 58; iter: 0; batch classifier loss: 0.118603; batch adversarial loss: 0.388091\n",
      "epoch 59; iter: 0; batch classifier loss: 0.144791; batch adversarial loss: 0.528047\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086478; batch adversarial loss: 0.494222\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093386; batch adversarial loss: 0.437683\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087885; batch adversarial loss: 0.333413\n",
      "epoch 63; iter: 0; batch classifier loss: 0.148558; batch adversarial loss: 0.472688\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082950; batch adversarial loss: 0.386143\n",
      "epoch 65; iter: 0; batch classifier loss: 0.047480; batch adversarial loss: 0.443368\n",
      "epoch 66; iter: 0; batch classifier loss: 0.131540; batch adversarial loss: 0.477634\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087006; batch adversarial loss: 0.441637\n",
      "epoch 68; iter: 0; batch classifier loss: 0.052721; batch adversarial loss: 0.493635\n",
      "epoch 69; iter: 0; batch classifier loss: 0.044529; batch adversarial loss: 0.540169\n",
      "epoch 70; iter: 0; batch classifier loss: 0.088870; batch adversarial loss: 0.397856\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071363; batch adversarial loss: 0.440777\n",
      "epoch 72; iter: 0; batch classifier loss: 0.151618; batch adversarial loss: 0.423205\n",
      "epoch 73; iter: 0; batch classifier loss: 0.073398; batch adversarial loss: 0.447320\n",
      "epoch 74; iter: 0; batch classifier loss: 0.104425; batch adversarial loss: 0.426239\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077227; batch adversarial loss: 0.407844\n",
      "epoch 76; iter: 0; batch classifier loss: 0.092157; batch adversarial loss: 0.489601\n",
      "epoch 77; iter: 0; batch classifier loss: 0.150276; batch adversarial loss: 0.393750\n",
      "epoch 78; iter: 0; batch classifier loss: 0.126100; batch adversarial loss: 0.423444\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074308; batch adversarial loss: 0.501081\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078145; batch adversarial loss: 0.463087\n",
      "epoch 81; iter: 0; batch classifier loss: 0.090382; batch adversarial loss: 0.415725\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071281; batch adversarial loss: 0.475685\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064581; batch adversarial loss: 0.503357\n",
      "epoch 84; iter: 0; batch classifier loss: 0.044270; batch adversarial loss: 0.430739\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059201; batch adversarial loss: 0.519694\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062164; batch adversarial loss: 0.417981\n",
      "epoch 87; iter: 0; batch classifier loss: 0.120926; batch adversarial loss: 0.416523\n",
      "epoch 88; iter: 0; batch classifier loss: 0.115159; batch adversarial loss: 0.457419\n",
      "epoch 89; iter: 0; batch classifier loss: 0.040928; batch adversarial loss: 0.451648\n",
      "epoch 90; iter: 0; batch classifier loss: 0.071965; batch adversarial loss: 0.500505\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063651; batch adversarial loss: 0.523127\n",
      "epoch 92; iter: 0; batch classifier loss: 0.078331; batch adversarial loss: 0.403533\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044775; batch adversarial loss: 0.471926\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067333; batch adversarial loss: 0.522356\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046178; batch adversarial loss: 0.528284\n",
      "epoch 96; iter: 0; batch classifier loss: 0.039500; batch adversarial loss: 0.439731\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060837; batch adversarial loss: 0.466681\n",
      "epoch 98; iter: 0; batch classifier loss: 0.088792; batch adversarial loss: 0.488723\n",
      "epoch 99; iter: 0; batch classifier loss: 0.068990; batch adversarial loss: 0.513280\n",
      "epoch 100; iter: 0; batch classifier loss: 0.072349; batch adversarial loss: 0.537485\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050647; batch adversarial loss: 0.485819\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058146; batch adversarial loss: 0.409964\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037599; batch adversarial loss: 0.438020\n",
      "epoch 104; iter: 0; batch classifier loss: 0.087453; batch adversarial loss: 0.460671\n",
      "epoch 105; iter: 0; batch classifier loss: 0.074379; batch adversarial loss: 0.524926\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049422; batch adversarial loss: 0.472401\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046231; batch adversarial loss: 0.499474\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045496; batch adversarial loss: 0.542853\n",
      "epoch 109; iter: 0; batch classifier loss: 0.035182; batch adversarial loss: 0.397215\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057809; batch adversarial loss: 0.474713\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041172; batch adversarial loss: 0.427665\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044558; batch adversarial loss: 0.483845\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059859; batch adversarial loss: 0.452577\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042145; batch adversarial loss: 0.535586\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040336; batch adversarial loss: 0.398137\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068860; batch adversarial loss: 0.450904\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043879; batch adversarial loss: 0.433045\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040632; batch adversarial loss: 0.437320\n",
      "epoch 119; iter: 0; batch classifier loss: 0.091712; batch adversarial loss: 0.485892\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053001; batch adversarial loss: 0.440428\n",
      "epoch 121; iter: 0; batch classifier loss: 0.072061; batch adversarial loss: 0.397095\n",
      "epoch 122; iter: 0; batch classifier loss: 0.075435; batch adversarial loss: 0.453515\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034822; batch adversarial loss: 0.453883\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032269; batch adversarial loss: 0.506037\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057199; batch adversarial loss: 0.385303\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035568; batch adversarial loss: 0.437368\n",
      "epoch 127; iter: 0; batch classifier loss: 0.096781; batch adversarial loss: 0.422074\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030083; batch adversarial loss: 0.549304\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021361; batch adversarial loss: 0.455076\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021219; batch adversarial loss: 0.413221\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049231; batch adversarial loss: 0.513516\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051241; batch adversarial loss: 0.490660\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038405; batch adversarial loss: 0.393815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.060445; batch adversarial loss: 0.514677\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026144; batch adversarial loss: 0.464306\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038447; batch adversarial loss: 0.493019\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041340; batch adversarial loss: 0.419309\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032962; batch adversarial loss: 0.492767\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034992; batch adversarial loss: 0.453069\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035871; batch adversarial loss: 0.419459\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045360; batch adversarial loss: 0.518589\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039027; batch adversarial loss: 0.436126\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011937; batch adversarial loss: 0.443677\n",
      "epoch 144; iter: 0; batch classifier loss: 0.059076; batch adversarial loss: 0.455549\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036489; batch adversarial loss: 0.558276\n",
      "epoch 146; iter: 0; batch classifier loss: 0.072242; batch adversarial loss: 0.420064\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036182; batch adversarial loss: 0.468389\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031090; batch adversarial loss: 0.430416\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030042; batch adversarial loss: 0.515612\n",
      "epoch 150; iter: 0; batch classifier loss: 0.058690; batch adversarial loss: 0.461257\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044772; batch adversarial loss: 0.414998\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032970; batch adversarial loss: 0.477099\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013441; batch adversarial loss: 0.458585\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029796; batch adversarial loss: 0.461287\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013004; batch adversarial loss: 0.401089\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025583; batch adversarial loss: 0.481998\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035099; batch adversarial loss: 0.417250\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011452; batch adversarial loss: 0.515338\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041605; batch adversarial loss: 0.441126\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027675; batch adversarial loss: 0.484791\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032131; batch adversarial loss: 0.451131\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040323; batch adversarial loss: 0.423786\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022863; batch adversarial loss: 0.574918\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025775; batch adversarial loss: 0.436593\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033375; batch adversarial loss: 0.497495\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032971; batch adversarial loss: 0.434730\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023740; batch adversarial loss: 0.434658\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013456; batch adversarial loss: 0.427001\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023185; batch adversarial loss: 0.468674\n",
      "epoch 170; iter: 0; batch classifier loss: 0.061102; batch adversarial loss: 0.508689\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020713; batch adversarial loss: 0.454012\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023640; batch adversarial loss: 0.416503\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042231; batch adversarial loss: 0.546094\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020098; batch adversarial loss: 0.593981\n",
      "epoch 175; iter: 0; batch classifier loss: 0.071311; batch adversarial loss: 0.501128\n",
      "epoch 176; iter: 0; batch classifier loss: 0.036064; batch adversarial loss: 0.497032\n",
      "epoch 177; iter: 0; batch classifier loss: 0.040277; batch adversarial loss: 0.460619\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027327; batch adversarial loss: 0.492233\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031183; batch adversarial loss: 0.457256\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030377; batch adversarial loss: 0.402867\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023279; batch adversarial loss: 0.634134\n",
      "epoch 182; iter: 0; batch classifier loss: 0.044863; batch adversarial loss: 0.435470\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025411; batch adversarial loss: 0.444686\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028070; batch adversarial loss: 0.524481\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014136; batch adversarial loss: 0.554612\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031269; batch adversarial loss: 0.454658\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021901; batch adversarial loss: 0.462348\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035931; batch adversarial loss: 0.551691\n",
      "epoch 189; iter: 0; batch classifier loss: 0.053060; batch adversarial loss: 0.481415\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011219; batch adversarial loss: 0.472265\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036644; batch adversarial loss: 0.422011\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027042; batch adversarial loss: 0.350853\n",
      "epoch 193; iter: 0; batch classifier loss: 0.047141; batch adversarial loss: 0.444940\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014632; batch adversarial loss: 0.390636\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028272; batch adversarial loss: 0.423617\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023896; batch adversarial loss: 0.368569\n",
      "epoch 197; iter: 0; batch classifier loss: 0.030518; batch adversarial loss: 0.385950\n",
      "epoch 198; iter: 0; batch classifier loss: 0.058725; batch adversarial loss: 0.362930\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010562; batch adversarial loss: 0.450982\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699931; batch adversarial loss: 0.824253\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595159; batch adversarial loss: 0.786442\n",
      "epoch 2; iter: 0; batch classifier loss: 0.665336; batch adversarial loss: 0.737539\n",
      "epoch 3; iter: 0; batch classifier loss: 0.786512; batch adversarial loss: 0.713945\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601351; batch adversarial loss: 0.618103\n",
      "epoch 5; iter: 0; batch classifier loss: 0.346049; batch adversarial loss: 0.613502\n",
      "epoch 6; iter: 0; batch classifier loss: 0.346874; batch adversarial loss: 0.558075\n",
      "epoch 7; iter: 0; batch classifier loss: 0.327327; batch adversarial loss: 0.591839\n",
      "epoch 8; iter: 0; batch classifier loss: 0.336377; batch adversarial loss: 0.559330\n",
      "epoch 9; iter: 0; batch classifier loss: 0.340557; batch adversarial loss: 0.539183\n",
      "epoch 10; iter: 0; batch classifier loss: 0.346592; batch adversarial loss: 0.571226\n",
      "epoch 11; iter: 0; batch classifier loss: 0.320273; batch adversarial loss: 0.548751\n",
      "epoch 12; iter: 0; batch classifier loss: 0.344210; batch adversarial loss: 0.462791\n",
      "epoch 13; iter: 0; batch classifier loss: 0.263822; batch adversarial loss: 0.458691\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302134; batch adversarial loss: 0.458454\n",
      "epoch 15; iter: 0; batch classifier loss: 0.232764; batch adversarial loss: 0.466498\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281446; batch adversarial loss: 0.537093\n",
      "epoch 17; iter: 0; batch classifier loss: 0.245921; batch adversarial loss: 0.551491\n",
      "epoch 18; iter: 0; batch classifier loss: 0.271214; batch adversarial loss: 0.448387\n",
      "epoch 19; iter: 0; batch classifier loss: 0.210343; batch adversarial loss: 0.486246\n",
      "epoch 20; iter: 0; batch classifier loss: 0.196439; batch adversarial loss: 0.469882\n",
      "epoch 21; iter: 0; batch classifier loss: 0.274763; batch adversarial loss: 0.559444\n",
      "epoch 22; iter: 0; batch classifier loss: 0.259745; batch adversarial loss: 0.449209\n",
      "epoch 23; iter: 0; batch classifier loss: 0.167032; batch adversarial loss: 0.480151\n",
      "epoch 24; iter: 0; batch classifier loss: 0.183890; batch adversarial loss: 0.523995\n",
      "epoch 25; iter: 0; batch classifier loss: 0.138899; batch adversarial loss: 0.490747\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181886; batch adversarial loss: 0.482527\n",
      "epoch 27; iter: 0; batch classifier loss: 0.126788; batch adversarial loss: 0.485422\n",
      "epoch 28; iter: 0; batch classifier loss: 0.163385; batch adversarial loss: 0.530224\n",
      "epoch 29; iter: 0; batch classifier loss: 0.143486; batch adversarial loss: 0.475508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.159520; batch adversarial loss: 0.412055\n",
      "epoch 31; iter: 0; batch classifier loss: 0.147418; batch adversarial loss: 0.458694\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146006; batch adversarial loss: 0.410402\n",
      "epoch 33; iter: 0; batch classifier loss: 0.103679; batch adversarial loss: 0.521621\n",
      "epoch 34; iter: 0; batch classifier loss: 0.110087; batch adversarial loss: 0.441383\n",
      "epoch 35; iter: 0; batch classifier loss: 0.093932; batch adversarial loss: 0.577937\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109015; batch adversarial loss: 0.490128\n",
      "epoch 37; iter: 0; batch classifier loss: 0.112199; batch adversarial loss: 0.549556\n",
      "epoch 38; iter: 0; batch classifier loss: 0.136839; batch adversarial loss: 0.616269\n",
      "epoch 39; iter: 0; batch classifier loss: 0.092169; batch adversarial loss: 0.444191\n",
      "epoch 40; iter: 0; batch classifier loss: 0.064627; batch adversarial loss: 0.491078\n",
      "epoch 41; iter: 0; batch classifier loss: 0.086093; batch adversarial loss: 0.495033\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105148; batch adversarial loss: 0.483563\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089510; batch adversarial loss: 0.388600\n",
      "epoch 44; iter: 0; batch classifier loss: 0.075467; batch adversarial loss: 0.473684\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089377; batch adversarial loss: 0.436361\n",
      "epoch 46; iter: 0; batch classifier loss: 0.095189; batch adversarial loss: 0.434764\n",
      "epoch 47; iter: 0; batch classifier loss: 0.121306; batch adversarial loss: 0.499534\n",
      "epoch 48; iter: 0; batch classifier loss: 0.116755; batch adversarial loss: 0.496279\n",
      "epoch 49; iter: 0; batch classifier loss: 0.084400; batch adversarial loss: 0.394036\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096429; batch adversarial loss: 0.484094\n",
      "epoch 51; iter: 0; batch classifier loss: 0.086253; batch adversarial loss: 0.456497\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071896; batch adversarial loss: 0.389218\n",
      "epoch 53; iter: 0; batch classifier loss: 0.089636; batch adversarial loss: 0.413013\n",
      "epoch 54; iter: 0; batch classifier loss: 0.088873; batch adversarial loss: 0.481322\n",
      "epoch 55; iter: 0; batch classifier loss: 0.054355; batch adversarial loss: 0.506399\n",
      "epoch 56; iter: 0; batch classifier loss: 0.058292; batch adversarial loss: 0.552087\n",
      "epoch 57; iter: 0; batch classifier loss: 0.070681; batch adversarial loss: 0.610138\n",
      "epoch 58; iter: 0; batch classifier loss: 0.081928; batch adversarial loss: 0.507534\n",
      "epoch 59; iter: 0; batch classifier loss: 0.062507; batch adversarial loss: 0.438782\n",
      "epoch 60; iter: 0; batch classifier loss: 0.088058; batch adversarial loss: 0.451277\n",
      "epoch 61; iter: 0; batch classifier loss: 0.060424; batch adversarial loss: 0.425230\n",
      "epoch 62; iter: 0; batch classifier loss: 0.051975; batch adversarial loss: 0.593051\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079296; batch adversarial loss: 0.580857\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066395; batch adversarial loss: 0.548378\n",
      "epoch 65; iter: 0; batch classifier loss: 0.057870; batch adversarial loss: 0.440987\n",
      "epoch 66; iter: 0; batch classifier loss: 0.054230; batch adversarial loss: 0.492541\n",
      "epoch 67; iter: 0; batch classifier loss: 0.071482; batch adversarial loss: 0.405747\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059378; batch adversarial loss: 0.383724\n",
      "epoch 69; iter: 0; batch classifier loss: 0.049945; batch adversarial loss: 0.495550\n",
      "epoch 70; iter: 0; batch classifier loss: 0.053941; batch adversarial loss: 0.392354\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089058; batch adversarial loss: 0.508195\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080666; batch adversarial loss: 0.450485\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077063; batch adversarial loss: 0.448952\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063865; batch adversarial loss: 0.455688\n",
      "epoch 75; iter: 0; batch classifier loss: 0.043076; batch adversarial loss: 0.434024\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065938; batch adversarial loss: 0.504052\n",
      "epoch 77; iter: 0; batch classifier loss: 0.073467; batch adversarial loss: 0.438996\n",
      "epoch 78; iter: 0; batch classifier loss: 0.049987; batch adversarial loss: 0.523844\n",
      "epoch 79; iter: 0; batch classifier loss: 0.051138; batch adversarial loss: 0.449915\n",
      "epoch 80; iter: 0; batch classifier loss: 0.042462; batch adversarial loss: 0.513660\n",
      "epoch 81; iter: 0; batch classifier loss: 0.046201; batch adversarial loss: 0.463387\n",
      "epoch 82; iter: 0; batch classifier loss: 0.037923; batch adversarial loss: 0.425087\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072663; batch adversarial loss: 0.444368\n",
      "epoch 84; iter: 0; batch classifier loss: 0.015010; batch adversarial loss: 0.380898\n",
      "epoch 85; iter: 0; batch classifier loss: 0.042075; batch adversarial loss: 0.419461\n",
      "epoch 86; iter: 0; batch classifier loss: 0.034605; batch adversarial loss: 0.515274\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048200; batch adversarial loss: 0.387338\n",
      "epoch 88; iter: 0; batch classifier loss: 0.039660; batch adversarial loss: 0.412786\n",
      "epoch 89; iter: 0; batch classifier loss: 0.055279; batch adversarial loss: 0.477540\n",
      "epoch 90; iter: 0; batch classifier loss: 0.035040; batch adversarial loss: 0.464106\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074712; batch adversarial loss: 0.373091\n",
      "epoch 92; iter: 0; batch classifier loss: 0.093598; batch adversarial loss: 0.505816\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041039; batch adversarial loss: 0.425897\n",
      "epoch 94; iter: 0; batch classifier loss: 0.037478; batch adversarial loss: 0.479993\n",
      "epoch 95; iter: 0; batch classifier loss: 0.016728; batch adversarial loss: 0.496751\n",
      "epoch 96; iter: 0; batch classifier loss: 0.060114; batch adversarial loss: 0.445402\n",
      "epoch 97; iter: 0; batch classifier loss: 0.085778; batch adversarial loss: 0.417336\n",
      "epoch 98; iter: 0; batch classifier loss: 0.022835; batch adversarial loss: 0.502917\n",
      "epoch 99; iter: 0; batch classifier loss: 0.030185; batch adversarial loss: 0.438619\n",
      "epoch 100; iter: 0; batch classifier loss: 0.020015; batch adversarial loss: 0.427268\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041287; batch adversarial loss: 0.413367\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031432; batch adversarial loss: 0.445078\n",
      "epoch 103; iter: 0; batch classifier loss: 0.023018; batch adversarial loss: 0.494492\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045028; batch adversarial loss: 0.369016\n",
      "epoch 105; iter: 0; batch classifier loss: 0.070639; batch adversarial loss: 0.528559\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031847; batch adversarial loss: 0.438218\n",
      "epoch 107; iter: 0; batch classifier loss: 0.020592; batch adversarial loss: 0.487295\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024532; batch adversarial loss: 0.437208\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029853; batch adversarial loss: 0.419403\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052151; batch adversarial loss: 0.466877\n",
      "epoch 111; iter: 0; batch classifier loss: 0.018456; batch adversarial loss: 0.468282\n",
      "epoch 112; iter: 0; batch classifier loss: 0.021192; batch adversarial loss: 0.473237\n",
      "epoch 113; iter: 0; batch classifier loss: 0.013464; batch adversarial loss: 0.585356\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026227; batch adversarial loss: 0.380389\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024666; batch adversarial loss: 0.486842\n",
      "epoch 116; iter: 0; batch classifier loss: 0.065042; batch adversarial loss: 0.421085\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039834; batch adversarial loss: 0.420081\n",
      "epoch 118; iter: 0; batch classifier loss: 0.018733; batch adversarial loss: 0.465361\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022160; batch adversarial loss: 0.432492\n",
      "epoch 120; iter: 0; batch classifier loss: 0.012831; batch adversarial loss: 0.517440\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031304; batch adversarial loss: 0.359222\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015185; batch adversarial loss: 0.426148\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019520; batch adversarial loss: 0.426427\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022834; batch adversarial loss: 0.432792\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017538; batch adversarial loss: 0.406768\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017120; batch adversarial loss: 0.440896\n",
      "epoch 127; iter: 0; batch classifier loss: 0.011099; batch adversarial loss: 0.411744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.023480; batch adversarial loss: 0.419909\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048596; batch adversarial loss: 0.383406\n",
      "epoch 130; iter: 0; batch classifier loss: 0.013670; batch adversarial loss: 0.467596\n",
      "epoch 131; iter: 0; batch classifier loss: 0.011342; batch adversarial loss: 0.552503\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044161; batch adversarial loss: 0.489072\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018529; batch adversarial loss: 0.497747\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042921; batch adversarial loss: 0.416698\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033310; batch adversarial loss: 0.479148\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031441; batch adversarial loss: 0.421713\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012693; batch adversarial loss: 0.515245\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017708; batch adversarial loss: 0.497301\n",
      "epoch 139; iter: 0; batch classifier loss: 0.008258; batch adversarial loss: 0.397413\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038129; batch adversarial loss: 0.460092\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028179; batch adversarial loss: 0.526883\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048988; batch adversarial loss: 0.500286\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026404; batch adversarial loss: 0.401655\n",
      "epoch 144; iter: 0; batch classifier loss: 0.010546; batch adversarial loss: 0.548614\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020123; batch adversarial loss: 0.398065\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018824; batch adversarial loss: 0.474162\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025776; batch adversarial loss: 0.537889\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018060; batch adversarial loss: 0.462749\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018025; batch adversarial loss: 0.469314\n",
      "epoch 150; iter: 0; batch classifier loss: 0.009811; batch adversarial loss: 0.470573\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035184; batch adversarial loss: 0.419178\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032214; batch adversarial loss: 0.400707\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024273; batch adversarial loss: 0.410496\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034479; batch adversarial loss: 0.464607\n",
      "epoch 155; iter: 0; batch classifier loss: 0.007310; batch adversarial loss: 0.439845\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014167; batch adversarial loss: 0.465804\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035167; batch adversarial loss: 0.470522\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015560; batch adversarial loss: 0.494559\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011222; batch adversarial loss: 0.402378\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008822; batch adversarial loss: 0.416518\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014928; batch adversarial loss: 0.435664\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013042; batch adversarial loss: 0.469823\n",
      "epoch 163; iter: 0; batch classifier loss: 0.003931; batch adversarial loss: 0.467576\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026790; batch adversarial loss: 0.537299\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020702; batch adversarial loss: 0.395965\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020383; batch adversarial loss: 0.386951\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010585; batch adversarial loss: 0.386113\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014274; batch adversarial loss: 0.473569\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011177; batch adversarial loss: 0.439737\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013296; batch adversarial loss: 0.585106\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018968; batch adversarial loss: 0.454634\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014394; batch adversarial loss: 0.513266\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006057; batch adversarial loss: 0.442109\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008115; batch adversarial loss: 0.396473\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015663; batch adversarial loss: 0.421955\n",
      "epoch 176; iter: 0; batch classifier loss: 0.005402; batch adversarial loss: 0.448680\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008262; batch adversarial loss: 0.467530\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028910; batch adversarial loss: 0.407187\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019691; batch adversarial loss: 0.508691\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007775; batch adversarial loss: 0.450905\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009604; batch adversarial loss: 0.492086\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034278; batch adversarial loss: 0.385724\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014241; batch adversarial loss: 0.508231\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014641; batch adversarial loss: 0.402902\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017420; batch adversarial loss: 0.456542\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006288; batch adversarial loss: 0.534822\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018753; batch adversarial loss: 0.444088\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016197; batch adversarial loss: 0.497463\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028654; batch adversarial loss: 0.448709\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009040; batch adversarial loss: 0.479097\n",
      "epoch 191; iter: 0; batch classifier loss: 0.003435; batch adversarial loss: 0.513495\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018980; batch adversarial loss: 0.409617\n",
      "epoch 193; iter: 0; batch classifier loss: 0.002808; batch adversarial loss: 0.394908\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017205; batch adversarial loss: 0.448476\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006840; batch adversarial loss: 0.408069\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016750; batch adversarial loss: 0.446462\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012090; batch adversarial loss: 0.445386\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026765; batch adversarial loss: 0.440136\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014514; batch adversarial loss: 0.391951\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692823; batch adversarial loss: 0.786825\n",
      "epoch 1; iter: 0; batch classifier loss: 0.438174; batch adversarial loss: 0.737889\n",
      "epoch 2; iter: 0; batch classifier loss: 0.348244; batch adversarial loss: 0.706952\n",
      "epoch 3; iter: 0; batch classifier loss: 0.337767; batch adversarial loss: 0.672958\n",
      "epoch 4; iter: 0; batch classifier loss: 0.382377; batch adversarial loss: 0.638527\n",
      "epoch 5; iter: 0; batch classifier loss: 0.320181; batch adversarial loss: 0.613975\n",
      "epoch 6; iter: 0; batch classifier loss: 0.389095; batch adversarial loss: 0.555916\n",
      "epoch 7; iter: 0; batch classifier loss: 0.279383; batch adversarial loss: 0.554296\n",
      "epoch 8; iter: 0; batch classifier loss: 0.308504; batch adversarial loss: 0.551522\n",
      "epoch 9; iter: 0; batch classifier loss: 0.266916; batch adversarial loss: 0.528893\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264216; batch adversarial loss: 0.472914\n",
      "epoch 11; iter: 0; batch classifier loss: 0.263513; batch adversarial loss: 0.459320\n",
      "epoch 12; iter: 0; batch classifier loss: 0.257513; batch adversarial loss: 0.464364\n",
      "epoch 13; iter: 0; batch classifier loss: 0.309680; batch adversarial loss: 0.419019\n",
      "epoch 14; iter: 0; batch classifier loss: 0.262754; batch adversarial loss: 0.443127\n",
      "epoch 15; iter: 0; batch classifier loss: 0.228438; batch adversarial loss: 0.416088\n",
      "epoch 16; iter: 0; batch classifier loss: 0.157681; batch adversarial loss: 0.418335\n",
      "epoch 17; iter: 0; batch classifier loss: 0.196535; batch adversarial loss: 0.376177\n",
      "epoch 18; iter: 0; batch classifier loss: 0.201059; batch adversarial loss: 0.421712\n",
      "epoch 19; iter: 0; batch classifier loss: 0.179744; batch adversarial loss: 0.419163\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222268; batch adversarial loss: 0.442044\n",
      "epoch 21; iter: 0; batch classifier loss: 0.178727; batch adversarial loss: 0.328860\n",
      "epoch 22; iter: 0; batch classifier loss: 0.171474; batch adversarial loss: 0.422651\n",
      "epoch 23; iter: 0; batch classifier loss: 0.182362; batch adversarial loss: 0.431820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.208605; batch adversarial loss: 0.437519\n",
      "epoch 25; iter: 0; batch classifier loss: 0.240943; batch adversarial loss: 0.344614\n",
      "epoch 26; iter: 0; batch classifier loss: 0.233502; batch adversarial loss: 0.456493\n",
      "epoch 27; iter: 0; batch classifier loss: 0.189386; batch adversarial loss: 0.434969\n",
      "epoch 28; iter: 0; batch classifier loss: 0.150873; batch adversarial loss: 0.375495\n",
      "epoch 29; iter: 0; batch classifier loss: 0.154437; batch adversarial loss: 0.438356\n",
      "epoch 30; iter: 0; batch classifier loss: 0.125819; batch adversarial loss: 0.460762\n",
      "epoch 31; iter: 0; batch classifier loss: 0.175819; batch adversarial loss: 0.393304\n",
      "epoch 32; iter: 0; batch classifier loss: 0.153995; batch adversarial loss: 0.442493\n",
      "epoch 33; iter: 0; batch classifier loss: 0.101263; batch adversarial loss: 0.378858\n",
      "epoch 34; iter: 0; batch classifier loss: 0.127215; batch adversarial loss: 0.347339\n",
      "epoch 35; iter: 0; batch classifier loss: 0.111301; batch adversarial loss: 0.386675\n",
      "epoch 36; iter: 0; batch classifier loss: 0.183247; batch adversarial loss: 0.364626\n",
      "epoch 37; iter: 0; batch classifier loss: 0.100778; batch adversarial loss: 0.409977\n",
      "epoch 38; iter: 0; batch classifier loss: 0.134408; batch adversarial loss: 0.417648\n",
      "epoch 39; iter: 0; batch classifier loss: 0.123288; batch adversarial loss: 0.462323\n",
      "epoch 40; iter: 0; batch classifier loss: 0.087104; batch adversarial loss: 0.409063\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104704; batch adversarial loss: 0.342704\n",
      "epoch 42; iter: 0; batch classifier loss: 0.104660; batch adversarial loss: 0.373856\n",
      "epoch 43; iter: 0; batch classifier loss: 0.105945; batch adversarial loss: 0.312004\n",
      "epoch 44; iter: 0; batch classifier loss: 0.108149; batch adversarial loss: 0.382631\n",
      "epoch 45; iter: 0; batch classifier loss: 0.083198; batch adversarial loss: 0.395681\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103957; batch adversarial loss: 0.369997\n",
      "epoch 47; iter: 0; batch classifier loss: 0.181334; batch adversarial loss: 0.368154\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129981; batch adversarial loss: 0.424381\n",
      "epoch 49; iter: 0; batch classifier loss: 0.112628; batch adversarial loss: 0.435509\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108431; batch adversarial loss: 0.398861\n",
      "epoch 51; iter: 0; batch classifier loss: 0.137529; batch adversarial loss: 0.433415\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112523; batch adversarial loss: 0.385284\n",
      "epoch 53; iter: 0; batch classifier loss: 0.080610; batch adversarial loss: 0.532437\n",
      "epoch 54; iter: 0; batch classifier loss: 0.085370; batch adversarial loss: 0.403853\n",
      "epoch 55; iter: 0; batch classifier loss: 0.110279; batch adversarial loss: 0.413020\n",
      "epoch 56; iter: 0; batch classifier loss: 0.064096; batch adversarial loss: 0.408365\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079549; batch adversarial loss: 0.490833\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078596; batch adversarial loss: 0.463069\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070458; batch adversarial loss: 0.424369\n",
      "epoch 60; iter: 0; batch classifier loss: 0.060615; batch adversarial loss: 0.433214\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087717; batch adversarial loss: 0.431322\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083772; batch adversarial loss: 0.452616\n",
      "epoch 63; iter: 0; batch classifier loss: 0.117373; batch adversarial loss: 0.473702\n",
      "epoch 64; iter: 0; batch classifier loss: 0.069679; batch adversarial loss: 0.344682\n",
      "epoch 65; iter: 0; batch classifier loss: 0.076711; batch adversarial loss: 0.489695\n",
      "epoch 66; iter: 0; batch classifier loss: 0.099416; batch adversarial loss: 0.469425\n",
      "epoch 67; iter: 0; batch classifier loss: 0.128183; batch adversarial loss: 0.488042\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072338; batch adversarial loss: 0.403873\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070915; batch adversarial loss: 0.369073\n",
      "epoch 70; iter: 0; batch classifier loss: 0.050010; batch adversarial loss: 0.313789\n",
      "epoch 71; iter: 0; batch classifier loss: 0.049469; batch adversarial loss: 0.408195\n",
      "epoch 72; iter: 0; batch classifier loss: 0.096054; batch adversarial loss: 0.377766\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068209; batch adversarial loss: 0.401795\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081809; batch adversarial loss: 0.430805\n",
      "epoch 75; iter: 0; batch classifier loss: 0.048662; batch adversarial loss: 0.426162\n",
      "epoch 76; iter: 0; batch classifier loss: 0.109312; batch adversarial loss: 0.416534\n",
      "epoch 77; iter: 0; batch classifier loss: 0.099571; batch adversarial loss: 0.461767\n",
      "epoch 78; iter: 0; batch classifier loss: 0.065572; batch adversarial loss: 0.431767\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099484; batch adversarial loss: 0.387328\n",
      "epoch 80; iter: 0; batch classifier loss: 0.081320; batch adversarial loss: 0.462974\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068552; batch adversarial loss: 0.391500\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062155; batch adversarial loss: 0.430241\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079673; batch adversarial loss: 0.446585\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065177; batch adversarial loss: 0.464355\n",
      "epoch 85; iter: 0; batch classifier loss: 0.071877; batch adversarial loss: 0.368853\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089632; batch adversarial loss: 0.384356\n",
      "epoch 87; iter: 0; batch classifier loss: 0.070665; batch adversarial loss: 0.446702\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051085; batch adversarial loss: 0.399400\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078153; batch adversarial loss: 0.386288\n",
      "epoch 90; iter: 0; batch classifier loss: 0.071462; batch adversarial loss: 0.388015\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060074; batch adversarial loss: 0.350263\n",
      "epoch 92; iter: 0; batch classifier loss: 0.101648; batch adversarial loss: 0.421424\n",
      "epoch 93; iter: 0; batch classifier loss: 0.091189; batch adversarial loss: 0.341647\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056326; batch adversarial loss: 0.338278\n",
      "epoch 95; iter: 0; batch classifier loss: 0.061677; batch adversarial loss: 0.426688\n",
      "epoch 96; iter: 0; batch classifier loss: 0.076151; batch adversarial loss: 0.502929\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073045; batch adversarial loss: 0.382956\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074402; batch adversarial loss: 0.405822\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058781; batch adversarial loss: 0.443963\n",
      "epoch 100; iter: 0; batch classifier loss: 0.073418; batch adversarial loss: 0.395794\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075757; batch adversarial loss: 0.352272\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036122; batch adversarial loss: 0.291990\n",
      "epoch 103; iter: 0; batch classifier loss: 0.081731; batch adversarial loss: 0.434276\n",
      "epoch 104; iter: 0; batch classifier loss: 0.040974; batch adversarial loss: 0.408095\n",
      "epoch 105; iter: 0; batch classifier loss: 0.070342; batch adversarial loss: 0.403589\n",
      "epoch 106; iter: 0; batch classifier loss: 0.066910; batch adversarial loss: 0.465786\n",
      "epoch 107; iter: 0; batch classifier loss: 0.080372; batch adversarial loss: 0.363552\n",
      "epoch 108; iter: 0; batch classifier loss: 0.074427; batch adversarial loss: 0.512146\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044748; batch adversarial loss: 0.449881\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064691; batch adversarial loss: 0.442961\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044655; batch adversarial loss: 0.368279\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043443; batch adversarial loss: 0.458020\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041012; batch adversarial loss: 0.405471\n",
      "epoch 114; iter: 0; batch classifier loss: 0.058858; batch adversarial loss: 0.350827\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040311; batch adversarial loss: 0.412631\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044413; batch adversarial loss: 0.502274\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051288; batch adversarial loss: 0.377124\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040298; batch adversarial loss: 0.382406\n",
      "epoch 119; iter: 0; batch classifier loss: 0.086254; batch adversarial loss: 0.430284\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028814; batch adversarial loss: 0.460677\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023451; batch adversarial loss: 0.406711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.034161; batch adversarial loss: 0.383635\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047552; batch adversarial loss: 0.466945\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036838; batch adversarial loss: 0.447632\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061927; batch adversarial loss: 0.545768\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039240; batch adversarial loss: 0.442297\n",
      "epoch 127; iter: 0; batch classifier loss: 0.049398; batch adversarial loss: 0.441809\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044952; batch adversarial loss: 0.386526\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039527; batch adversarial loss: 0.520626\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027470; batch adversarial loss: 0.502818\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039241; batch adversarial loss: 0.398484\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051710; batch adversarial loss: 0.390351\n",
      "epoch 133; iter: 0; batch classifier loss: 0.074172; batch adversarial loss: 0.389157\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038789; batch adversarial loss: 0.475243\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028858; batch adversarial loss: 0.489821\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030361; batch adversarial loss: 0.417779\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040110; batch adversarial loss: 0.345324\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039061; batch adversarial loss: 0.368962\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043101; batch adversarial loss: 0.422023\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031920; batch adversarial loss: 0.476485\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019228; batch adversarial loss: 0.427188\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024902; batch adversarial loss: 0.594312\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026875; batch adversarial loss: 0.439507\n",
      "epoch 144; iter: 0; batch classifier loss: 0.015006; batch adversarial loss: 0.517379\n",
      "epoch 145; iter: 0; batch classifier loss: 0.055541; batch adversarial loss: 0.368719\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020229; batch adversarial loss: 0.437115\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042630; batch adversarial loss: 0.377733\n",
      "epoch 148; iter: 0; batch classifier loss: 0.010463; batch adversarial loss: 0.512379\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023651; batch adversarial loss: 0.463072\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035287; batch adversarial loss: 0.463692\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032662; batch adversarial loss: 0.389762\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016403; batch adversarial loss: 0.467628\n",
      "epoch 153; iter: 0; batch classifier loss: 0.043149; batch adversarial loss: 0.448204\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029078; batch adversarial loss: 0.485408\n",
      "epoch 155; iter: 0; batch classifier loss: 0.053632; batch adversarial loss: 0.567795\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017559; batch adversarial loss: 0.419013\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028330; batch adversarial loss: 0.424374\n",
      "epoch 158; iter: 0; batch classifier loss: 0.055931; batch adversarial loss: 0.532807\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037676; batch adversarial loss: 0.527287\n",
      "epoch 160; iter: 0; batch classifier loss: 0.102726; batch adversarial loss: 0.695841\n",
      "epoch 161; iter: 0; batch classifier loss: 0.118134; batch adversarial loss: 0.778315\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038005; batch adversarial loss: 0.479678\n",
      "epoch 163; iter: 0; batch classifier loss: 0.127100; batch adversarial loss: 0.669727\n",
      "epoch 164; iter: 0; batch classifier loss: 0.070176; batch adversarial loss: 0.617467\n",
      "epoch 165; iter: 0; batch classifier loss: 0.077154; batch adversarial loss: 0.518544\n",
      "epoch 166; iter: 0; batch classifier loss: 0.108669; batch adversarial loss: 0.600283\n",
      "epoch 167; iter: 0; batch classifier loss: 0.127853; batch adversarial loss: 0.660991\n",
      "epoch 168; iter: 0; batch classifier loss: 0.095697; batch adversarial loss: 0.566026\n",
      "epoch 169; iter: 0; batch classifier loss: 0.191971; batch adversarial loss: 0.726437\n",
      "epoch 170; iter: 0; batch classifier loss: 0.119945; batch adversarial loss: 0.538017\n",
      "epoch 171; iter: 0; batch classifier loss: 0.149098; batch adversarial loss: 0.640238\n",
      "epoch 172; iter: 0; batch classifier loss: 0.248544; batch adversarial loss: 0.812623\n",
      "epoch 173; iter: 0; batch classifier loss: 0.113199; batch adversarial loss: 0.514327\n",
      "epoch 174; iter: 0; batch classifier loss: 0.255995; batch adversarial loss: 0.894915\n",
      "epoch 175; iter: 0; batch classifier loss: 0.086917; batch adversarial loss: 0.472721\n",
      "epoch 176; iter: 0; batch classifier loss: 0.242278; batch adversarial loss: 0.839628\n",
      "epoch 177; iter: 0; batch classifier loss: 0.113018; batch adversarial loss: 0.501504\n",
      "epoch 178; iter: 0; batch classifier loss: 0.106053; batch adversarial loss: 0.549419\n",
      "epoch 179; iter: 0; batch classifier loss: 0.223457; batch adversarial loss: 0.631571\n",
      "epoch 180; iter: 0; batch classifier loss: 0.252876; batch adversarial loss: 0.836374\n",
      "epoch 181; iter: 0; batch classifier loss: 0.233691; batch adversarial loss: 0.660887\n",
      "epoch 182; iter: 0; batch classifier loss: 0.200757; batch adversarial loss: 0.647139\n",
      "epoch 183; iter: 0; batch classifier loss: 0.138391; batch adversarial loss: 0.545687\n",
      "epoch 184; iter: 0; batch classifier loss: 0.118958; batch adversarial loss: 0.513536\n",
      "epoch 185; iter: 0; batch classifier loss: 0.203891; batch adversarial loss: 0.549929\n",
      "epoch 186; iter: 0; batch classifier loss: 0.118793; batch adversarial loss: 0.573278\n",
      "epoch 187; iter: 0; batch classifier loss: 0.137457; batch adversarial loss: 0.481163\n",
      "epoch 188; iter: 0; batch classifier loss: 0.139442; batch adversarial loss: 0.609538\n",
      "epoch 189; iter: 0; batch classifier loss: 0.216069; batch adversarial loss: 0.715452\n",
      "epoch 190; iter: 0; batch classifier loss: 0.204192; batch adversarial loss: 0.533844\n",
      "epoch 191; iter: 0; batch classifier loss: 0.117926; batch adversarial loss: 0.550630\n",
      "epoch 192; iter: 0; batch classifier loss: 0.136665; batch adversarial loss: 0.598652\n",
      "epoch 193; iter: 0; batch classifier loss: 0.126140; batch adversarial loss: 0.579188\n",
      "epoch 194; iter: 0; batch classifier loss: 0.132585; batch adversarial loss: 0.613324\n",
      "epoch 195; iter: 0; batch classifier loss: 0.152485; batch adversarial loss: 0.580534\n",
      "epoch 196; iter: 0; batch classifier loss: 0.168650; batch adversarial loss: 0.543392\n",
      "epoch 197; iter: 0; batch classifier loss: 0.176457; batch adversarial loss: 0.570957\n",
      "epoch 198; iter: 0; batch classifier loss: 0.160756; batch adversarial loss: 0.584590\n",
      "epoch 199; iter: 0; batch classifier loss: 0.167289; batch adversarial loss: 0.600761\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677078; batch adversarial loss: 0.653165\n",
      "epoch 1; iter: 0; batch classifier loss: 0.477036; batch adversarial loss: 0.621251\n",
      "epoch 2; iter: 0; batch classifier loss: 0.444340; batch adversarial loss: 0.606888\n",
      "epoch 3; iter: 0; batch classifier loss: 0.499887; batch adversarial loss: 0.579952\n",
      "epoch 4; iter: 0; batch classifier loss: 0.384908; batch adversarial loss: 0.618805\n",
      "epoch 5; iter: 0; batch classifier loss: 0.431699; batch adversarial loss: 0.599835\n",
      "epoch 6; iter: 0; batch classifier loss: 0.419072; batch adversarial loss: 0.602048\n",
      "epoch 7; iter: 0; batch classifier loss: 0.378687; batch adversarial loss: 0.579224\n",
      "epoch 8; iter: 0; batch classifier loss: 0.343204; batch adversarial loss: 0.583132\n",
      "epoch 9; iter: 0; batch classifier loss: 0.384506; batch adversarial loss: 0.534500\n",
      "epoch 10; iter: 0; batch classifier loss: 0.404135; batch adversarial loss: 0.505700\n",
      "epoch 11; iter: 0; batch classifier loss: 0.299085; batch adversarial loss: 0.589957\n",
      "epoch 12; iter: 0; batch classifier loss: 0.314888; batch adversarial loss: 0.517077\n",
      "epoch 13; iter: 0; batch classifier loss: 0.367011; batch adversarial loss: 0.503797\n",
      "epoch 14; iter: 0; batch classifier loss: 0.286829; batch adversarial loss: 0.454701\n",
      "epoch 15; iter: 0; batch classifier loss: 0.352688; batch adversarial loss: 0.457564\n",
      "epoch 16; iter: 0; batch classifier loss: 0.276740; batch adversarial loss: 0.485791\n",
      "epoch 17; iter: 0; batch classifier loss: 0.299891; batch adversarial loss: 0.550023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.339871; batch adversarial loss: 0.530522\n",
      "epoch 19; iter: 0; batch classifier loss: 0.248821; batch adversarial loss: 0.526572\n",
      "epoch 20; iter: 0; batch classifier loss: 0.285155; batch adversarial loss: 0.451189\n",
      "epoch 21; iter: 0; batch classifier loss: 0.256543; batch adversarial loss: 0.454503\n",
      "epoch 22; iter: 0; batch classifier loss: 0.287353; batch adversarial loss: 0.484661\n",
      "epoch 23; iter: 0; batch classifier loss: 0.264121; batch adversarial loss: 0.432712\n",
      "epoch 24; iter: 0; batch classifier loss: 0.274455; batch adversarial loss: 0.394941\n",
      "epoch 25; iter: 0; batch classifier loss: 0.253442; batch adversarial loss: 0.391945\n",
      "epoch 26; iter: 0; batch classifier loss: 0.249105; batch adversarial loss: 0.440146\n",
      "epoch 27; iter: 0; batch classifier loss: 0.274703; batch adversarial loss: 0.473283\n",
      "epoch 28; iter: 0; batch classifier loss: 0.243326; batch adversarial loss: 0.556267\n",
      "epoch 29; iter: 0; batch classifier loss: 0.257442; batch adversarial loss: 0.476920\n",
      "epoch 30; iter: 0; batch classifier loss: 0.223969; batch adversarial loss: 0.536834\n",
      "epoch 31; iter: 0; batch classifier loss: 0.223427; batch adversarial loss: 0.421942\n",
      "epoch 32; iter: 0; batch classifier loss: 0.348553; batch adversarial loss: 0.457980\n",
      "epoch 33; iter: 0; batch classifier loss: 0.279921; batch adversarial loss: 0.449588\n",
      "epoch 34; iter: 0; batch classifier loss: 0.219531; batch adversarial loss: 0.541143\n",
      "epoch 35; iter: 0; batch classifier loss: 0.234894; batch adversarial loss: 0.467834\n",
      "epoch 36; iter: 0; batch classifier loss: 0.251429; batch adversarial loss: 0.490854\n",
      "epoch 37; iter: 0; batch classifier loss: 0.248729; batch adversarial loss: 0.502200\n",
      "epoch 38; iter: 0; batch classifier loss: 0.201234; batch adversarial loss: 0.514468\n",
      "epoch 39; iter: 0; batch classifier loss: 0.295796; batch adversarial loss: 0.476690\n",
      "epoch 40; iter: 0; batch classifier loss: 0.192297; batch adversarial loss: 0.463861\n",
      "epoch 41; iter: 0; batch classifier loss: 0.311202; batch adversarial loss: 0.450163\n",
      "epoch 42; iter: 0; batch classifier loss: 0.216447; batch adversarial loss: 0.519453\n",
      "epoch 43; iter: 0; batch classifier loss: 0.213702; batch adversarial loss: 0.470761\n",
      "epoch 44; iter: 0; batch classifier loss: 0.210127; batch adversarial loss: 0.470990\n",
      "epoch 45; iter: 0; batch classifier loss: 0.170031; batch adversarial loss: 0.530135\n",
      "epoch 46; iter: 0; batch classifier loss: 0.266341; batch adversarial loss: 0.505617\n",
      "epoch 47; iter: 0; batch classifier loss: 0.156617; batch adversarial loss: 0.435445\n",
      "epoch 48; iter: 0; batch classifier loss: 0.235737; batch adversarial loss: 0.387970\n",
      "epoch 49; iter: 0; batch classifier loss: 0.125108; batch adversarial loss: 0.458494\n",
      "epoch 50; iter: 0; batch classifier loss: 0.138545; batch adversarial loss: 0.481683\n",
      "epoch 51; iter: 0; batch classifier loss: 0.144846; batch adversarial loss: 0.432846\n",
      "epoch 52; iter: 0; batch classifier loss: 0.185173; batch adversarial loss: 0.458580\n",
      "epoch 53; iter: 0; batch classifier loss: 0.225723; batch adversarial loss: 0.468629\n",
      "epoch 54; iter: 0; batch classifier loss: 0.259980; batch adversarial loss: 0.436576\n",
      "epoch 55; iter: 0; batch classifier loss: 0.116308; batch adversarial loss: 0.531561\n",
      "epoch 56; iter: 0; batch classifier loss: 0.132308; batch adversarial loss: 0.481470\n",
      "epoch 57; iter: 0; batch classifier loss: 0.312674; batch adversarial loss: 0.471860\n",
      "epoch 58; iter: 0; batch classifier loss: 0.117164; batch adversarial loss: 0.567743\n",
      "epoch 59; iter: 0; batch classifier loss: 0.128882; batch adversarial loss: 0.396288\n",
      "epoch 60; iter: 0; batch classifier loss: 0.206399; batch adversarial loss: 0.471160\n",
      "epoch 61; iter: 0; batch classifier loss: 0.152189; batch adversarial loss: 0.325482\n",
      "epoch 62; iter: 0; batch classifier loss: 0.170986; batch adversarial loss: 0.421360\n",
      "epoch 63; iter: 0; batch classifier loss: 0.252103; batch adversarial loss: 0.458586\n",
      "epoch 64; iter: 0; batch classifier loss: 0.247809; batch adversarial loss: 0.423129\n",
      "epoch 65; iter: 0; batch classifier loss: 0.137305; batch adversarial loss: 0.470682\n",
      "epoch 66; iter: 0; batch classifier loss: 0.148471; batch adversarial loss: 0.371841\n",
      "epoch 67; iter: 0; batch classifier loss: 0.237480; batch adversarial loss: 0.373089\n",
      "epoch 68; iter: 0; batch classifier loss: 0.123305; batch adversarial loss: 0.507296\n",
      "epoch 69; iter: 0; batch classifier loss: 0.147607; batch adversarial loss: 0.566821\n",
      "epoch 70; iter: 0; batch classifier loss: 0.224097; batch adversarial loss: 0.446352\n",
      "epoch 71; iter: 0; batch classifier loss: 0.141708; batch adversarial loss: 0.568285\n",
      "epoch 72; iter: 0; batch classifier loss: 0.156489; batch adversarial loss: 0.446369\n",
      "epoch 73; iter: 0; batch classifier loss: 0.235992; batch adversarial loss: 0.409600\n",
      "epoch 74; iter: 0; batch classifier loss: 0.198363; batch adversarial loss: 0.398101\n",
      "epoch 75; iter: 0; batch classifier loss: 0.166062; batch adversarial loss: 0.471359\n",
      "epoch 76; iter: 0; batch classifier loss: 0.223518; batch adversarial loss: 0.446598\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108636; batch adversarial loss: 0.457782\n",
      "epoch 78; iter: 0; batch classifier loss: 0.063205; batch adversarial loss: 0.383232\n",
      "epoch 79; iter: 0; batch classifier loss: 0.084115; batch adversarial loss: 0.465226\n",
      "epoch 80; iter: 0; batch classifier loss: 0.063895; batch adversarial loss: 0.465706\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096209; batch adversarial loss: 0.451635\n",
      "epoch 82; iter: 0; batch classifier loss: 0.048209; batch adversarial loss: 0.426181\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066707; batch adversarial loss: 0.448006\n",
      "epoch 84; iter: 0; batch classifier loss: 0.114620; batch adversarial loss: 0.483291\n",
      "epoch 85; iter: 0; batch classifier loss: 0.108581; batch adversarial loss: 0.475797\n",
      "epoch 86; iter: 0; batch classifier loss: 0.055899; batch adversarial loss: 0.528592\n",
      "epoch 87; iter: 0; batch classifier loss: 0.098258; batch adversarial loss: 0.393203\n",
      "epoch 88; iter: 0; batch classifier loss: 0.105705; batch adversarial loss: 0.420666\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058022; batch adversarial loss: 0.392788\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061945; batch adversarial loss: 0.436569\n",
      "epoch 91; iter: 0; batch classifier loss: 0.049823; batch adversarial loss: 0.457237\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041722; batch adversarial loss: 0.474059\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077354; batch adversarial loss: 0.460282\n",
      "epoch 94; iter: 0; batch classifier loss: 0.060950; batch adversarial loss: 0.409248\n",
      "epoch 95; iter: 0; batch classifier loss: 0.069626; batch adversarial loss: 0.422829\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051318; batch adversarial loss: 0.440768\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061809; batch adversarial loss: 0.492348\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049929; batch adversarial loss: 0.474105\n",
      "epoch 99; iter: 0; batch classifier loss: 0.031686; batch adversarial loss: 0.474576\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035956; batch adversarial loss: 0.574238\n",
      "epoch 101; iter: 0; batch classifier loss: 0.036748; batch adversarial loss: 0.473739\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055235; batch adversarial loss: 0.459200\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055502; batch adversarial loss: 0.484160\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066262; batch adversarial loss: 0.491243\n",
      "epoch 105; iter: 0; batch classifier loss: 0.097438; batch adversarial loss: 0.449226\n",
      "epoch 106; iter: 0; batch classifier loss: 0.085938; batch adversarial loss: 0.460089\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044214; batch adversarial loss: 0.436089\n",
      "epoch 108; iter: 0; batch classifier loss: 0.078454; batch adversarial loss: 0.442669\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059709; batch adversarial loss: 0.490967\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026263; batch adversarial loss: 0.370786\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039189; batch adversarial loss: 0.517805\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042885; batch adversarial loss: 0.497882\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049961; batch adversarial loss: 0.438494\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056857; batch adversarial loss: 0.443097\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050023; batch adversarial loss: 0.437418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.029372; batch adversarial loss: 0.441274\n",
      "epoch 117; iter: 0; batch classifier loss: 0.076286; batch adversarial loss: 0.395128\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049567; batch adversarial loss: 0.439921\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034331; batch adversarial loss: 0.432480\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044841; batch adversarial loss: 0.474461\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046979; batch adversarial loss: 0.342036\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038220; batch adversarial loss: 0.547257\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041901; batch adversarial loss: 0.411430\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039054; batch adversarial loss: 0.558137\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022913; batch adversarial loss: 0.514973\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036535; batch adversarial loss: 0.462191\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060622; batch adversarial loss: 0.549107\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036369; batch adversarial loss: 0.469202\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024576; batch adversarial loss: 0.341816\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022692; batch adversarial loss: 0.486502\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026731; batch adversarial loss: 0.470434\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015690; batch adversarial loss: 0.436920\n",
      "epoch 133; iter: 0; batch classifier loss: 0.058776; batch adversarial loss: 0.360569\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023821; batch adversarial loss: 0.489314\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033702; batch adversarial loss: 0.467226\n",
      "epoch 136; iter: 0; batch classifier loss: 0.062196; batch adversarial loss: 0.500898\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031274; batch adversarial loss: 0.542887\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020184; batch adversarial loss: 0.461703\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014309; batch adversarial loss: 0.445491\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027067; batch adversarial loss: 0.431966\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033755; batch adversarial loss: 0.459757\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025892; batch adversarial loss: 0.504359\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016691; batch adversarial loss: 0.465749\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033737; batch adversarial loss: 0.456244\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045646; batch adversarial loss: 0.378780\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022144; batch adversarial loss: 0.438557\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011694; batch adversarial loss: 0.388061\n",
      "epoch 148; iter: 0; batch classifier loss: 0.056791; batch adversarial loss: 0.332519\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021376; batch adversarial loss: 0.498622\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024944; batch adversarial loss: 0.476524\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015875; batch adversarial loss: 0.570130\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017156; batch adversarial loss: 0.452029\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034652; batch adversarial loss: 0.446182\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038195; batch adversarial loss: 0.451436\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023489; batch adversarial loss: 0.442456\n",
      "epoch 156; iter: 0; batch classifier loss: 0.006377; batch adversarial loss: 0.427883\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018892; batch adversarial loss: 0.463625\n",
      "epoch 158; iter: 0; batch classifier loss: 0.062349; batch adversarial loss: 0.486250\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014323; batch adversarial loss: 0.484871\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037370; batch adversarial loss: 0.405281\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012498; batch adversarial loss: 0.557083\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009176; batch adversarial loss: 0.421994\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037681; batch adversarial loss: 0.564573\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011981; batch adversarial loss: 0.478047\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012565; batch adversarial loss: 0.437029\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018265; batch adversarial loss: 0.526865\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020957; batch adversarial loss: 0.427666\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027563; batch adversarial loss: 0.452402\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015359; batch adversarial loss: 0.497484\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029605; batch adversarial loss: 0.464816\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038653; batch adversarial loss: 0.497720\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033848; batch adversarial loss: 0.445808\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014616; batch adversarial loss: 0.444374\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035746; batch adversarial loss: 0.383278\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028423; batch adversarial loss: 0.481920\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009744; batch adversarial loss: 0.420534\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012968; batch adversarial loss: 0.475692\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005742; batch adversarial loss: 0.467524\n",
      "epoch 179; iter: 0; batch classifier loss: 0.042162; batch adversarial loss: 0.451434\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011007; batch adversarial loss: 0.558790\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008821; batch adversarial loss: 0.399369\n",
      "epoch 182; iter: 0; batch classifier loss: 0.045082; batch adversarial loss: 0.428262\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020428; batch adversarial loss: 0.556009\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010719; batch adversarial loss: 0.420864\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026643; batch adversarial loss: 0.535517\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026051; batch adversarial loss: 0.432809\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029944; batch adversarial loss: 0.413924\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011335; batch adversarial loss: 0.467318\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007287; batch adversarial loss: 0.493954\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023507; batch adversarial loss: 0.517829\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022697; batch adversarial loss: 0.487090\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012840; batch adversarial loss: 0.378322\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005748; batch adversarial loss: 0.361610\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022120; batch adversarial loss: 0.530333\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005998; batch adversarial loss: 0.499302\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018826; batch adversarial loss: 0.524051\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014163; batch adversarial loss: 0.430341\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013150; batch adversarial loss: 0.504230\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020435; batch adversarial loss: 0.415227\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706773; batch adversarial loss: 0.653239\n",
      "epoch 1; iter: 0; batch classifier loss: 0.491632; batch adversarial loss: 0.638817\n",
      "epoch 2; iter: 0; batch classifier loss: 0.324468; batch adversarial loss: 0.599059\n",
      "epoch 3; iter: 0; batch classifier loss: 0.294380; batch adversarial loss: 0.556150\n",
      "epoch 4; iter: 0; batch classifier loss: 0.275007; batch adversarial loss: 0.563921\n",
      "epoch 5; iter: 0; batch classifier loss: 0.292237; batch adversarial loss: 0.568444\n",
      "epoch 6; iter: 0; batch classifier loss: 0.218978; batch adversarial loss: 0.555113\n",
      "epoch 7; iter: 0; batch classifier loss: 0.248169; batch adversarial loss: 0.480888\n",
      "epoch 8; iter: 0; batch classifier loss: 0.276582; batch adversarial loss: 0.549084\n",
      "epoch 9; iter: 0; batch classifier loss: 0.278005; batch adversarial loss: 0.561435\n",
      "epoch 10; iter: 0; batch classifier loss: 0.263424; batch adversarial loss: 0.494895\n",
      "epoch 11; iter: 0; batch classifier loss: 0.248557; batch adversarial loss: 0.489625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.252118; batch adversarial loss: 0.456749\n",
      "epoch 13; iter: 0; batch classifier loss: 0.380008; batch adversarial loss: 0.572432\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249990; batch adversarial loss: 0.511673\n",
      "epoch 15; iter: 0; batch classifier loss: 0.410516; batch adversarial loss: 0.490037\n",
      "epoch 16; iter: 0; batch classifier loss: 0.447090; batch adversarial loss: 0.575291\n",
      "epoch 17; iter: 0; batch classifier loss: 0.579200; batch adversarial loss: 0.545495\n",
      "epoch 18; iter: 0; batch classifier loss: 0.449690; batch adversarial loss: 0.435655\n",
      "epoch 19; iter: 0; batch classifier loss: 0.335766; batch adversarial loss: 0.475385\n",
      "epoch 20; iter: 0; batch classifier loss: 0.256625; batch adversarial loss: 0.444429\n",
      "epoch 21; iter: 0; batch classifier loss: 0.183430; batch adversarial loss: 0.481446\n",
      "epoch 22; iter: 0; batch classifier loss: 0.211871; batch adversarial loss: 0.529999\n",
      "epoch 23; iter: 0; batch classifier loss: 0.165280; batch adversarial loss: 0.371266\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192283; batch adversarial loss: 0.439162\n",
      "epoch 25; iter: 0; batch classifier loss: 0.125255; batch adversarial loss: 0.451683\n",
      "epoch 26; iter: 0; batch classifier loss: 0.158241; batch adversarial loss: 0.465842\n",
      "epoch 27; iter: 0; batch classifier loss: 0.127176; batch adversarial loss: 0.403353\n",
      "epoch 28; iter: 0; batch classifier loss: 0.157394; batch adversarial loss: 0.519874\n",
      "epoch 29; iter: 0; batch classifier loss: 0.143793; batch adversarial loss: 0.443736\n",
      "epoch 30; iter: 0; batch classifier loss: 0.168333; batch adversarial loss: 0.503557\n",
      "epoch 31; iter: 0; batch classifier loss: 0.172231; batch adversarial loss: 0.402556\n",
      "epoch 32; iter: 0; batch classifier loss: 0.083153; batch adversarial loss: 0.498191\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123683; batch adversarial loss: 0.445954\n",
      "epoch 34; iter: 0; batch classifier loss: 0.134814; batch adversarial loss: 0.455067\n",
      "epoch 35; iter: 0; batch classifier loss: 0.075729; batch adversarial loss: 0.522748\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120694; batch adversarial loss: 0.457635\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111425; batch adversarial loss: 0.548435\n",
      "epoch 38; iter: 0; batch classifier loss: 0.104652; batch adversarial loss: 0.461593\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113438; batch adversarial loss: 0.429985\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103086; batch adversarial loss: 0.440085\n",
      "epoch 41; iter: 0; batch classifier loss: 0.102227; batch adversarial loss: 0.431610\n",
      "epoch 42; iter: 0; batch classifier loss: 0.126846; batch adversarial loss: 0.478459\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117330; batch adversarial loss: 0.397016\n",
      "epoch 44; iter: 0; batch classifier loss: 0.100320; batch adversarial loss: 0.500500\n",
      "epoch 45; iter: 0; batch classifier loss: 0.131773; batch adversarial loss: 0.414236\n",
      "epoch 46; iter: 0; batch classifier loss: 0.119153; batch adversarial loss: 0.438248\n",
      "epoch 47; iter: 0; batch classifier loss: 0.107698; batch adversarial loss: 0.374463\n",
      "epoch 48; iter: 0; batch classifier loss: 0.094477; batch adversarial loss: 0.448594\n",
      "epoch 49; iter: 0; batch classifier loss: 0.091862; batch adversarial loss: 0.522709\n",
      "epoch 50; iter: 0; batch classifier loss: 0.054603; batch adversarial loss: 0.534809\n",
      "epoch 51; iter: 0; batch classifier loss: 0.058559; batch adversarial loss: 0.498612\n",
      "epoch 52; iter: 0; batch classifier loss: 0.129548; batch adversarial loss: 0.400751\n",
      "epoch 53; iter: 0; batch classifier loss: 0.130368; batch adversarial loss: 0.440193\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096478; batch adversarial loss: 0.399471\n",
      "epoch 55; iter: 0; batch classifier loss: 0.102094; batch adversarial loss: 0.432169\n",
      "epoch 56; iter: 0; batch classifier loss: 0.153376; batch adversarial loss: 0.470881\n",
      "epoch 57; iter: 0; batch classifier loss: 0.070726; batch adversarial loss: 0.462234\n",
      "epoch 58; iter: 0; batch classifier loss: 0.120348; batch adversarial loss: 0.387110\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082634; batch adversarial loss: 0.529230\n",
      "epoch 60; iter: 0; batch classifier loss: 0.071866; batch adversarial loss: 0.398901\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088721; batch adversarial loss: 0.490094\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082746; batch adversarial loss: 0.402088\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097946; batch adversarial loss: 0.384884\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070694; batch adversarial loss: 0.381350\n",
      "epoch 65; iter: 0; batch classifier loss: 0.123625; batch adversarial loss: 0.332894\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070057; batch adversarial loss: 0.479239\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082994; batch adversarial loss: 0.460965\n",
      "epoch 68; iter: 0; batch classifier loss: 0.050657; batch adversarial loss: 0.456763\n",
      "epoch 69; iter: 0; batch classifier loss: 0.066494; batch adversarial loss: 0.431101\n",
      "epoch 70; iter: 0; batch classifier loss: 0.047702; batch adversarial loss: 0.430004\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104836; batch adversarial loss: 0.493840\n",
      "epoch 72; iter: 0; batch classifier loss: 0.089133; batch adversarial loss: 0.491418\n",
      "epoch 73; iter: 0; batch classifier loss: 0.106839; batch adversarial loss: 0.561608\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075476; batch adversarial loss: 0.509486\n",
      "epoch 75; iter: 0; batch classifier loss: 0.084469; batch adversarial loss: 0.466114\n",
      "epoch 76; iter: 0; batch classifier loss: 0.116226; batch adversarial loss: 0.459625\n",
      "epoch 77; iter: 0; batch classifier loss: 0.096981; batch adversarial loss: 0.492476\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056896; batch adversarial loss: 0.497895\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082716; batch adversarial loss: 0.378154\n",
      "epoch 80; iter: 0; batch classifier loss: 0.039147; batch adversarial loss: 0.621166\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076932; batch adversarial loss: 0.515304\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056609; batch adversarial loss: 0.442416\n",
      "epoch 83; iter: 0; batch classifier loss: 0.099911; batch adversarial loss: 0.418021\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068203; batch adversarial loss: 0.497648\n",
      "epoch 85; iter: 0; batch classifier loss: 0.037370; batch adversarial loss: 0.380923\n",
      "epoch 86; iter: 0; batch classifier loss: 0.039935; batch adversarial loss: 0.405554\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042495; batch adversarial loss: 0.428421\n",
      "epoch 88; iter: 0; batch classifier loss: 0.038900; batch adversarial loss: 0.446834\n",
      "epoch 89; iter: 0; batch classifier loss: 0.084834; batch adversarial loss: 0.435818\n",
      "epoch 90; iter: 0; batch classifier loss: 0.046220; batch adversarial loss: 0.496629\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047077; batch adversarial loss: 0.496709\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050918; batch adversarial loss: 0.402991\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058945; batch adversarial loss: 0.396068\n",
      "epoch 94; iter: 0; batch classifier loss: 0.035294; batch adversarial loss: 0.467501\n",
      "epoch 95; iter: 0; batch classifier loss: 0.075624; batch adversarial loss: 0.464625\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063247; batch adversarial loss: 0.504811\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063123; batch adversarial loss: 0.458414\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056392; batch adversarial loss: 0.437210\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053903; batch adversarial loss: 0.377289\n",
      "epoch 100; iter: 0; batch classifier loss: 0.077427; batch adversarial loss: 0.398335\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047778; batch adversarial loss: 0.442188\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079680; batch adversarial loss: 0.450531\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071976; batch adversarial loss: 0.456714\n",
      "epoch 104; iter: 0; batch classifier loss: 0.022755; batch adversarial loss: 0.435798\n",
      "epoch 105; iter: 0; batch classifier loss: 0.032073; batch adversarial loss: 0.441608\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063358; batch adversarial loss: 0.499968\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059786; batch adversarial loss: 0.482010\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043652; batch adversarial loss: 0.490516\n",
      "epoch 109; iter: 0; batch classifier loss: 0.031979; batch adversarial loss: 0.539132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.099544; batch adversarial loss: 0.378870\n",
      "epoch 111; iter: 0; batch classifier loss: 0.067171; batch adversarial loss: 0.509078\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047032; batch adversarial loss: 0.491673\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042442; batch adversarial loss: 0.430913\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048122; batch adversarial loss: 0.392978\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034470; batch adversarial loss: 0.396453\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056301; batch adversarial loss: 0.366134\n",
      "epoch 117; iter: 0; batch classifier loss: 0.081136; batch adversarial loss: 0.541304\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042299; batch adversarial loss: 0.501067\n",
      "epoch 119; iter: 0; batch classifier loss: 0.076846; batch adversarial loss: 0.426892\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043920; batch adversarial loss: 0.378494\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037211; batch adversarial loss: 0.435632\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034229; batch adversarial loss: 0.468783\n",
      "epoch 123; iter: 0; batch classifier loss: 0.018937; batch adversarial loss: 0.451280\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027280; batch adversarial loss: 0.399565\n",
      "epoch 125; iter: 0; batch classifier loss: 0.055787; batch adversarial loss: 0.521036\n",
      "epoch 126; iter: 0; batch classifier loss: 0.060286; batch adversarial loss: 0.508910\n",
      "epoch 127; iter: 0; batch classifier loss: 0.067813; batch adversarial loss: 0.409722\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035069; batch adversarial loss: 0.444940\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043681; batch adversarial loss: 0.410441\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042596; batch adversarial loss: 0.488437\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034546; batch adversarial loss: 0.390416\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014825; batch adversarial loss: 0.444046\n",
      "epoch 133; iter: 0; batch classifier loss: 0.016516; batch adversarial loss: 0.453279\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043215; batch adversarial loss: 0.480386\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014846; batch adversarial loss: 0.461342\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025701; batch adversarial loss: 0.481978\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034511; batch adversarial loss: 0.456993\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013506; batch adversarial loss: 0.590115\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038507; batch adversarial loss: 0.377865\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031601; batch adversarial loss: 0.642043\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016972; batch adversarial loss: 0.457039\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031940; batch adversarial loss: 0.438256\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030593; batch adversarial loss: 0.464234\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013168; batch adversarial loss: 0.442161\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023718; batch adversarial loss: 0.410559\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030602; batch adversarial loss: 0.460958\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023831; batch adversarial loss: 0.417916\n",
      "epoch 148; iter: 0; batch classifier loss: 0.065327; batch adversarial loss: 0.461365\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023822; batch adversarial loss: 0.401069\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020731; batch adversarial loss: 0.549581\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042904; batch adversarial loss: 0.395780\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025228; batch adversarial loss: 0.412397\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010236; batch adversarial loss: 0.573892\n",
      "epoch 154; iter: 0; batch classifier loss: 0.055658; batch adversarial loss: 0.528617\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014225; batch adversarial loss: 0.587176\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023711; batch adversarial loss: 0.394907\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009394; batch adversarial loss: 0.513886\n",
      "epoch 158; iter: 0; batch classifier loss: 0.073942; batch adversarial loss: 0.450303\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036715; batch adversarial loss: 0.415170\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031307; batch adversarial loss: 0.431967\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026409; batch adversarial loss: 0.474942\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036095; batch adversarial loss: 0.419905\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024630; batch adversarial loss: 0.533852\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022991; batch adversarial loss: 0.422392\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031729; batch adversarial loss: 0.484149\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019673; batch adversarial loss: 0.484145\n",
      "epoch 167; iter: 0; batch classifier loss: 0.038757; batch adversarial loss: 0.459820\n",
      "epoch 168; iter: 0; batch classifier loss: 0.004905; batch adversarial loss: 0.422123\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024913; batch adversarial loss: 0.518554\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024945; batch adversarial loss: 0.428529\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031421; batch adversarial loss: 0.385200\n",
      "epoch 172; iter: 0; batch classifier loss: 0.051774; batch adversarial loss: 0.433989\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016184; batch adversarial loss: 0.399421\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010464; batch adversarial loss: 0.480901\n",
      "epoch 175; iter: 0; batch classifier loss: 0.062446; batch adversarial loss: 0.451357\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012955; batch adversarial loss: 0.466114\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010205; batch adversarial loss: 0.431462\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005224; batch adversarial loss: 0.395728\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010140; batch adversarial loss: 0.414670\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009260; batch adversarial loss: 0.475956\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015902; batch adversarial loss: 0.435112\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021348; batch adversarial loss: 0.383397\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016334; batch adversarial loss: 0.366768\n",
      "epoch 184; iter: 0; batch classifier loss: 0.064680; batch adversarial loss: 0.385329\n",
      "epoch 185; iter: 0; batch classifier loss: 0.048108; batch adversarial loss: 0.384621\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033460; batch adversarial loss: 0.471060\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012424; batch adversarial loss: 0.481655\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025680; batch adversarial loss: 0.500093\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019695; batch adversarial loss: 0.447255\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011362; batch adversarial loss: 0.563091\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019359; batch adversarial loss: 0.412744\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018075; batch adversarial loss: 0.420348\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009127; batch adversarial loss: 0.439951\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032739; batch adversarial loss: 0.462981\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018716; batch adversarial loss: 0.511025\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022913; batch adversarial loss: 0.472454\n",
      "epoch 197; iter: 0; batch classifier loss: 0.046490; batch adversarial loss: 0.428550\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013176; batch adversarial loss: 0.458385\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032769; batch adversarial loss: 0.494657\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689139; batch adversarial loss: 0.663399\n",
      "epoch 1; iter: 0; batch classifier loss: 0.469681; batch adversarial loss: 0.664941\n",
      "epoch 2; iter: 0; batch classifier loss: 0.350444; batch adversarial loss: 0.643585\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393121; batch adversarial loss: 0.576983\n",
      "epoch 4; iter: 0; batch classifier loss: 0.378869; batch adversarial loss: 0.578550\n",
      "epoch 5; iter: 0; batch classifier loss: 0.298839; batch adversarial loss: 0.545406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.279453; batch adversarial loss: 0.578615\n",
      "epoch 7; iter: 0; batch classifier loss: 0.314239; batch adversarial loss: 0.508697\n",
      "epoch 8; iter: 0; batch classifier loss: 0.265046; batch adversarial loss: 0.493206\n",
      "epoch 9; iter: 0; batch classifier loss: 0.247622; batch adversarial loss: 0.518148\n",
      "epoch 10; iter: 0; batch classifier loss: 0.202154; batch adversarial loss: 0.458463\n",
      "epoch 11; iter: 0; batch classifier loss: 0.233792; batch adversarial loss: 0.477392\n",
      "epoch 12; iter: 0; batch classifier loss: 0.263283; batch adversarial loss: 0.459759\n",
      "epoch 13; iter: 0; batch classifier loss: 0.247813; batch adversarial loss: 0.529482\n",
      "epoch 14; iter: 0; batch classifier loss: 0.238861; batch adversarial loss: 0.456456\n",
      "epoch 15; iter: 0; batch classifier loss: 0.167088; batch adversarial loss: 0.452155\n",
      "epoch 16; iter: 0; batch classifier loss: 0.210905; batch adversarial loss: 0.470916\n",
      "epoch 17; iter: 0; batch classifier loss: 0.159045; batch adversarial loss: 0.415687\n",
      "epoch 18; iter: 0; batch classifier loss: 0.204830; batch adversarial loss: 0.440400\n",
      "epoch 19; iter: 0; batch classifier loss: 0.178295; batch adversarial loss: 0.456224\n",
      "epoch 20; iter: 0; batch classifier loss: 0.207657; batch adversarial loss: 0.508096\n",
      "epoch 21; iter: 0; batch classifier loss: 0.117061; batch adversarial loss: 0.421685\n",
      "epoch 22; iter: 0; batch classifier loss: 0.116336; batch adversarial loss: 0.429956\n",
      "epoch 23; iter: 0; batch classifier loss: 0.191599; batch adversarial loss: 0.504215\n",
      "epoch 24; iter: 0; batch classifier loss: 0.187462; batch adversarial loss: 0.542073\n",
      "epoch 25; iter: 0; batch classifier loss: 0.136249; batch adversarial loss: 0.374021\n",
      "epoch 26; iter: 0; batch classifier loss: 0.237003; batch adversarial loss: 0.460812\n",
      "epoch 27; iter: 0; batch classifier loss: 0.237001; batch adversarial loss: 0.490313\n",
      "epoch 28; iter: 0; batch classifier loss: 0.161401; batch adversarial loss: 0.441498\n",
      "epoch 29; iter: 0; batch classifier loss: 0.205376; batch adversarial loss: 0.525053\n",
      "epoch 30; iter: 0; batch classifier loss: 0.285778; batch adversarial loss: 0.568836\n",
      "epoch 31; iter: 0; batch classifier loss: 0.208658; batch adversarial loss: 0.476578\n",
      "epoch 32; iter: 0; batch classifier loss: 0.215655; batch adversarial loss: 0.525513\n",
      "epoch 33; iter: 0; batch classifier loss: 0.323468; batch adversarial loss: 0.487874\n",
      "epoch 34; iter: 0; batch classifier loss: 0.314583; batch adversarial loss: 0.428537\n",
      "epoch 35; iter: 0; batch classifier loss: 0.195707; batch adversarial loss: 0.503096\n",
      "epoch 36; iter: 0; batch classifier loss: 0.155937; batch adversarial loss: 0.465129\n",
      "epoch 37; iter: 0; batch classifier loss: 0.138949; batch adversarial loss: 0.403334\n",
      "epoch 38; iter: 0; batch classifier loss: 0.152218; batch adversarial loss: 0.475962\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131907; batch adversarial loss: 0.380504\n",
      "epoch 40; iter: 0; batch classifier loss: 0.151303; batch adversarial loss: 0.492734\n",
      "epoch 41; iter: 0; batch classifier loss: 0.100567; batch adversarial loss: 0.411028\n",
      "epoch 42; iter: 0; batch classifier loss: 0.089408; batch adversarial loss: 0.443245\n",
      "epoch 43; iter: 0; batch classifier loss: 0.121036; batch adversarial loss: 0.496419\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085587; batch adversarial loss: 0.396690\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124132; batch adversarial loss: 0.438169\n",
      "epoch 46; iter: 0; batch classifier loss: 0.082923; batch adversarial loss: 0.460363\n",
      "epoch 47; iter: 0; batch classifier loss: 0.149234; batch adversarial loss: 0.369730\n",
      "epoch 48; iter: 0; batch classifier loss: 0.058267; batch adversarial loss: 0.452401\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074855; batch adversarial loss: 0.458825\n",
      "epoch 50; iter: 0; batch classifier loss: 0.114222; batch adversarial loss: 0.511734\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073953; batch adversarial loss: 0.499212\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093748; batch adversarial loss: 0.411513\n",
      "epoch 53; iter: 0; batch classifier loss: 0.081339; batch adversarial loss: 0.473349\n",
      "epoch 54; iter: 0; batch classifier loss: 0.137000; batch adversarial loss: 0.380591\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101548; batch adversarial loss: 0.477927\n",
      "epoch 56; iter: 0; batch classifier loss: 0.061915; batch adversarial loss: 0.465171\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086805; batch adversarial loss: 0.432030\n",
      "epoch 58; iter: 0; batch classifier loss: 0.048190; batch adversarial loss: 0.561193\n",
      "epoch 59; iter: 0; batch classifier loss: 0.064333; batch adversarial loss: 0.506073\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115045; batch adversarial loss: 0.490841\n",
      "epoch 61; iter: 0; batch classifier loss: 0.086112; batch adversarial loss: 0.442274\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094756; batch adversarial loss: 0.375054\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099157; batch adversarial loss: 0.465433\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073388; batch adversarial loss: 0.504755\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073809; batch adversarial loss: 0.391391\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075463; batch adversarial loss: 0.459530\n",
      "epoch 67; iter: 0; batch classifier loss: 0.071256; batch adversarial loss: 0.470683\n",
      "epoch 68; iter: 0; batch classifier loss: 0.064535; batch adversarial loss: 0.364168\n",
      "epoch 69; iter: 0; batch classifier loss: 0.059205; batch adversarial loss: 0.427461\n",
      "epoch 70; iter: 0; batch classifier loss: 0.071864; batch adversarial loss: 0.450292\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104307; batch adversarial loss: 0.388458\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071288; batch adversarial loss: 0.510178\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068758; batch adversarial loss: 0.618265\n",
      "epoch 74; iter: 0; batch classifier loss: 0.058874; batch adversarial loss: 0.540419\n",
      "epoch 75; iter: 0; batch classifier loss: 0.098384; batch adversarial loss: 0.409368\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086779; batch adversarial loss: 0.503984\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050388; batch adversarial loss: 0.427338\n",
      "epoch 78; iter: 0; batch classifier loss: 0.046108; batch adversarial loss: 0.463583\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053674; batch adversarial loss: 0.345353\n",
      "epoch 80; iter: 0; batch classifier loss: 0.123717; batch adversarial loss: 0.531298\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120249; batch adversarial loss: 0.411807\n",
      "epoch 82; iter: 0; batch classifier loss: 0.089512; batch adversarial loss: 0.446614\n",
      "epoch 83; iter: 0; batch classifier loss: 0.040900; batch adversarial loss: 0.426174\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059448; batch adversarial loss: 0.466242\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075663; batch adversarial loss: 0.391528\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070067; batch adversarial loss: 0.456260\n",
      "epoch 87; iter: 0; batch classifier loss: 0.080782; batch adversarial loss: 0.432663\n",
      "epoch 88; iter: 0; batch classifier loss: 0.074196; batch adversarial loss: 0.543052\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035529; batch adversarial loss: 0.427543\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060965; batch adversarial loss: 0.499935\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067297; batch adversarial loss: 0.456317\n",
      "epoch 92; iter: 0; batch classifier loss: 0.073494; batch adversarial loss: 0.382696\n",
      "epoch 93; iter: 0; batch classifier loss: 0.088147; batch adversarial loss: 0.326941\n",
      "epoch 94; iter: 0; batch classifier loss: 0.037296; batch adversarial loss: 0.458088\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055946; batch adversarial loss: 0.415463\n",
      "epoch 96; iter: 0; batch classifier loss: 0.069395; batch adversarial loss: 0.470349\n",
      "epoch 97; iter: 0; batch classifier loss: 0.017733; batch adversarial loss: 0.469283\n",
      "epoch 98; iter: 0; batch classifier loss: 0.070780; batch adversarial loss: 0.542939\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078017; batch adversarial loss: 0.428717\n",
      "epoch 100; iter: 0; batch classifier loss: 0.099546; batch adversarial loss: 0.444576\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047999; batch adversarial loss: 0.427601\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044764; batch adversarial loss: 0.389585\n",
      "epoch 103; iter: 0; batch classifier loss: 0.104467; batch adversarial loss: 0.473788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.053480; batch adversarial loss: 0.508757\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042462; batch adversarial loss: 0.447144\n",
      "epoch 106; iter: 0; batch classifier loss: 0.093783; batch adversarial loss: 0.438349\n",
      "epoch 107; iter: 0; batch classifier loss: 0.057254; batch adversarial loss: 0.367282\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037319; batch adversarial loss: 0.480330\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026664; batch adversarial loss: 0.464408\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041921; batch adversarial loss: 0.517569\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044112; batch adversarial loss: 0.441005\n",
      "epoch 112; iter: 0; batch classifier loss: 0.067126; batch adversarial loss: 0.436872\n",
      "epoch 113; iter: 0; batch classifier loss: 0.022432; batch adversarial loss: 0.456120\n",
      "epoch 114; iter: 0; batch classifier loss: 0.063866; batch adversarial loss: 0.443315\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045932; batch adversarial loss: 0.533947\n",
      "epoch 116; iter: 0; batch classifier loss: 0.066184; batch adversarial loss: 0.516894\n",
      "epoch 117; iter: 0; batch classifier loss: 0.021533; batch adversarial loss: 0.469622\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054489; batch adversarial loss: 0.412719\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060590; batch adversarial loss: 0.438751\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037043; batch adversarial loss: 0.367900\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050767; batch adversarial loss: 0.405713\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050054; batch adversarial loss: 0.481990\n",
      "epoch 123; iter: 0; batch classifier loss: 0.058610; batch adversarial loss: 0.459327\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036764; batch adversarial loss: 0.478886\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044447; batch adversarial loss: 0.479316\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043344; batch adversarial loss: 0.460972\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019409; batch adversarial loss: 0.520204\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034424; batch adversarial loss: 0.546032\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046429; batch adversarial loss: 0.447034\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035005; batch adversarial loss: 0.507786\n",
      "epoch 131; iter: 0; batch classifier loss: 0.062884; batch adversarial loss: 0.367415\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044231; batch adversarial loss: 0.491551\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022510; batch adversarial loss: 0.512010\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016149; batch adversarial loss: 0.472252\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024165; batch adversarial loss: 0.353010\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023574; batch adversarial loss: 0.412902\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017010; batch adversarial loss: 0.364213\n",
      "epoch 138; iter: 0; batch classifier loss: 0.012789; batch adversarial loss: 0.485650\n",
      "epoch 139; iter: 0; batch classifier loss: 0.066561; batch adversarial loss: 0.526674\n",
      "epoch 140; iter: 0; batch classifier loss: 0.008157; batch adversarial loss: 0.446939\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018771; batch adversarial loss: 0.431662\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037913; batch adversarial loss: 0.477847\n",
      "epoch 143; iter: 0; batch classifier loss: 0.065533; batch adversarial loss: 0.403325\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020919; batch adversarial loss: 0.502483\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016255; batch adversarial loss: 0.401692\n",
      "epoch 146; iter: 0; batch classifier loss: 0.082226; batch adversarial loss: 0.446107\n",
      "epoch 147; iter: 0; batch classifier loss: 0.059724; batch adversarial loss: 0.470300\n",
      "epoch 148; iter: 0; batch classifier loss: 0.051333; batch adversarial loss: 0.417471\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014657; batch adversarial loss: 0.427420\n",
      "epoch 150; iter: 0; batch classifier loss: 0.077771; batch adversarial loss: 0.445138\n",
      "epoch 151; iter: 0; batch classifier loss: 0.062758; batch adversarial loss: 0.435441\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034540; batch adversarial loss: 0.454569\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023477; batch adversarial loss: 0.387688\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032901; batch adversarial loss: 0.531201\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032120; batch adversarial loss: 0.428194\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017538; batch adversarial loss: 0.427498\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014602; batch adversarial loss: 0.472598\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028215; batch adversarial loss: 0.489655\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017743; batch adversarial loss: 0.401298\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028611; batch adversarial loss: 0.432389\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021948; batch adversarial loss: 0.477989\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025319; batch adversarial loss: 0.350306\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023035; batch adversarial loss: 0.414197\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018772; batch adversarial loss: 0.486570\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018579; batch adversarial loss: 0.464858\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024548; batch adversarial loss: 0.374858\n",
      "epoch 167; iter: 0; batch classifier loss: 0.060615; batch adversarial loss: 0.469334\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023618; batch adversarial loss: 0.428126\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012674; batch adversarial loss: 0.370146\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031034; batch adversarial loss: 0.398645\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021543; batch adversarial loss: 0.537452\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027572; batch adversarial loss: 0.445377\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026172; batch adversarial loss: 0.375311\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040755; batch adversarial loss: 0.426157\n",
      "epoch 175; iter: 0; batch classifier loss: 0.045255; batch adversarial loss: 0.427741\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024413; batch adversarial loss: 0.403499\n",
      "epoch 177; iter: 0; batch classifier loss: 0.044419; batch adversarial loss: 0.465005\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023368; batch adversarial loss: 0.391721\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029508; batch adversarial loss: 0.400576\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034068; batch adversarial loss: 0.485404\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033677; batch adversarial loss: 0.444675\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027140; batch adversarial loss: 0.470990\n",
      "epoch 183; iter: 0; batch classifier loss: 0.044053; batch adversarial loss: 0.452942\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027323; batch adversarial loss: 0.428756\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033038; batch adversarial loss: 0.512829\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010696; batch adversarial loss: 0.379052\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028189; batch adversarial loss: 0.399648\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014406; batch adversarial loss: 0.446447\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004793; batch adversarial loss: 0.523112\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009347; batch adversarial loss: 0.494598\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021723; batch adversarial loss: 0.526963\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036517; batch adversarial loss: 0.497725\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018337; batch adversarial loss: 0.446730\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036934; batch adversarial loss: 0.605391\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023848; batch adversarial loss: 0.465349\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011509; batch adversarial loss: 0.418641\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016656; batch adversarial loss: 0.397130\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002972; batch adversarial loss: 0.419555\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013845; batch adversarial loss: 0.448097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.693135; batch adversarial loss: 0.756099\n",
      "epoch 1; iter: 0; batch classifier loss: 0.459919; batch adversarial loss: 0.694781\n",
      "epoch 2; iter: 0; batch classifier loss: 0.416203; batch adversarial loss: 0.672894\n",
      "epoch 3; iter: 0; batch classifier loss: 0.319874; batch adversarial loss: 0.674354\n",
      "epoch 4; iter: 0; batch classifier loss: 0.304365; batch adversarial loss: 0.609523\n",
      "epoch 5; iter: 0; batch classifier loss: 0.329522; batch adversarial loss: 0.584910\n",
      "epoch 6; iter: 0; batch classifier loss: 0.401814; batch adversarial loss: 0.543087\n",
      "epoch 7; iter: 0; batch classifier loss: 0.276791; batch adversarial loss: 0.561434\n",
      "epoch 8; iter: 0; batch classifier loss: 0.282194; batch adversarial loss: 0.523553\n",
      "epoch 9; iter: 0; batch classifier loss: 0.192398; batch adversarial loss: 0.531821\n",
      "epoch 10; iter: 0; batch classifier loss: 0.278423; batch adversarial loss: 0.510068\n",
      "epoch 11; iter: 0; batch classifier loss: 0.249266; batch adversarial loss: 0.440891\n",
      "epoch 12; iter: 0; batch classifier loss: 0.230650; batch adversarial loss: 0.517839\n",
      "epoch 13; iter: 0; batch classifier loss: 0.154009; batch adversarial loss: 0.452844\n",
      "epoch 14; iter: 0; batch classifier loss: 0.223186; batch adversarial loss: 0.484696\n",
      "epoch 15; iter: 0; batch classifier loss: 0.252445; batch adversarial loss: 0.405155\n",
      "epoch 16; iter: 0; batch classifier loss: 0.209955; batch adversarial loss: 0.411712\n",
      "epoch 17; iter: 0; batch classifier loss: 0.141352; batch adversarial loss: 0.433817\n",
      "epoch 18; iter: 0; batch classifier loss: 0.189129; batch adversarial loss: 0.439638\n",
      "epoch 19; iter: 0; batch classifier loss: 0.214515; batch adversarial loss: 0.417466\n",
      "epoch 20; iter: 0; batch classifier loss: 0.211908; batch adversarial loss: 0.423589\n",
      "epoch 21; iter: 0; batch classifier loss: 0.177912; batch adversarial loss: 0.407595\n",
      "epoch 22; iter: 0; batch classifier loss: 0.194707; batch adversarial loss: 0.443712\n",
      "epoch 23; iter: 0; batch classifier loss: 0.126793; batch adversarial loss: 0.407395\n",
      "epoch 24; iter: 0; batch classifier loss: 0.204667; batch adversarial loss: 0.406410\n",
      "epoch 25; iter: 0; batch classifier loss: 0.138827; batch adversarial loss: 0.378182\n",
      "epoch 26; iter: 0; batch classifier loss: 0.167739; batch adversarial loss: 0.428650\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159982; batch adversarial loss: 0.377861\n",
      "epoch 28; iter: 0; batch classifier loss: 0.155274; batch adversarial loss: 0.456643\n",
      "epoch 29; iter: 0; batch classifier loss: 0.154766; batch adversarial loss: 0.389209\n",
      "epoch 30; iter: 0; batch classifier loss: 0.188179; batch adversarial loss: 0.399754\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156000; batch adversarial loss: 0.416911\n",
      "epoch 32; iter: 0; batch classifier loss: 0.156662; batch adversarial loss: 0.429109\n",
      "epoch 33; iter: 0; batch classifier loss: 0.158215; batch adversarial loss: 0.463183\n",
      "epoch 34; iter: 0; batch classifier loss: 0.152681; batch adversarial loss: 0.424545\n",
      "epoch 35; iter: 0; batch classifier loss: 0.135528; batch adversarial loss: 0.429347\n",
      "epoch 36; iter: 0; batch classifier loss: 0.121633; batch adversarial loss: 0.450449\n",
      "epoch 37; iter: 0; batch classifier loss: 0.120555; batch adversarial loss: 0.420478\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148068; batch adversarial loss: 0.401996\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118780; batch adversarial loss: 0.393871\n",
      "epoch 40; iter: 0; batch classifier loss: 0.148059; batch adversarial loss: 0.451469\n",
      "epoch 41; iter: 0; batch classifier loss: 0.094635; batch adversarial loss: 0.474145\n",
      "epoch 42; iter: 0; batch classifier loss: 0.129598; batch adversarial loss: 0.410963\n",
      "epoch 43; iter: 0; batch classifier loss: 0.093795; batch adversarial loss: 0.420702\n",
      "epoch 44; iter: 0; batch classifier loss: 0.116410; batch adversarial loss: 0.468566\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091335; batch adversarial loss: 0.478470\n",
      "epoch 46; iter: 0; batch classifier loss: 0.109072; batch adversarial loss: 0.456703\n",
      "epoch 47; iter: 0; batch classifier loss: 0.098303; batch adversarial loss: 0.388811\n",
      "epoch 48; iter: 0; batch classifier loss: 0.096486; batch adversarial loss: 0.419288\n",
      "epoch 49; iter: 0; batch classifier loss: 0.091490; batch adversarial loss: 0.458803\n",
      "epoch 50; iter: 0; batch classifier loss: 0.114720; batch adversarial loss: 0.366406\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092729; batch adversarial loss: 0.391521\n",
      "epoch 52; iter: 0; batch classifier loss: 0.075759; batch adversarial loss: 0.459853\n",
      "epoch 53; iter: 0; batch classifier loss: 0.087103; batch adversarial loss: 0.420362\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122890; batch adversarial loss: 0.413145\n",
      "epoch 55; iter: 0; batch classifier loss: 0.078398; batch adversarial loss: 0.409440\n",
      "epoch 56; iter: 0; batch classifier loss: 0.085425; batch adversarial loss: 0.363361\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090552; batch adversarial loss: 0.335100\n",
      "epoch 58; iter: 0; batch classifier loss: 0.099039; batch adversarial loss: 0.468823\n",
      "epoch 59; iter: 0; batch classifier loss: 0.125762; batch adversarial loss: 0.369545\n",
      "epoch 60; iter: 0; batch classifier loss: 0.092073; batch adversarial loss: 0.498395\n",
      "epoch 61; iter: 0; batch classifier loss: 0.115720; batch adversarial loss: 0.379343\n",
      "epoch 62; iter: 0; batch classifier loss: 0.067595; batch adversarial loss: 0.472134\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088912; batch adversarial loss: 0.324963\n",
      "epoch 64; iter: 0; batch classifier loss: 0.092878; batch adversarial loss: 0.486926\n",
      "epoch 65; iter: 0; batch classifier loss: 0.096460; batch adversarial loss: 0.448741\n",
      "epoch 66; iter: 0; batch classifier loss: 0.101587; batch adversarial loss: 0.396533\n",
      "epoch 67; iter: 0; batch classifier loss: 0.076804; batch adversarial loss: 0.407819\n",
      "epoch 68; iter: 0; batch classifier loss: 0.067937; batch adversarial loss: 0.308233\n",
      "epoch 69; iter: 0; batch classifier loss: 0.066144; batch adversarial loss: 0.466037\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067477; batch adversarial loss: 0.395066\n",
      "epoch 71; iter: 0; batch classifier loss: 0.065152; batch adversarial loss: 0.434315\n",
      "epoch 72; iter: 0; batch classifier loss: 0.060880; batch adversarial loss: 0.332321\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075844; batch adversarial loss: 0.457713\n",
      "epoch 74; iter: 0; batch classifier loss: 0.093668; batch adversarial loss: 0.498874\n",
      "epoch 75; iter: 0; batch classifier loss: 0.113251; batch adversarial loss: 0.359824\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049854; batch adversarial loss: 0.460476\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045118; batch adversarial loss: 0.329036\n",
      "epoch 78; iter: 0; batch classifier loss: 0.131457; batch adversarial loss: 0.402760\n",
      "epoch 79; iter: 0; batch classifier loss: 0.078651; batch adversarial loss: 0.434055\n",
      "epoch 80; iter: 0; batch classifier loss: 0.069460; batch adversarial loss: 0.374464\n",
      "epoch 81; iter: 0; batch classifier loss: 0.059028; batch adversarial loss: 0.426749\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083026; batch adversarial loss: 0.409925\n",
      "epoch 83; iter: 0; batch classifier loss: 0.077805; batch adversarial loss: 0.515502\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080238; batch adversarial loss: 0.445046\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058643; batch adversarial loss: 0.459536\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069640; batch adversarial loss: 0.483226\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079746; batch adversarial loss: 0.410434\n",
      "epoch 88; iter: 0; batch classifier loss: 0.061914; batch adversarial loss: 0.403657\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075626; batch adversarial loss: 0.427959\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047453; batch adversarial loss: 0.394979\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063131; batch adversarial loss: 0.371246\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041091; batch adversarial loss: 0.443308\n",
      "epoch 93; iter: 0; batch classifier loss: 0.027151; batch adversarial loss: 0.394482\n",
      "epoch 94; iter: 0; batch classifier loss: 0.045597; batch adversarial loss: 0.399298\n",
      "epoch 95; iter: 0; batch classifier loss: 0.093833; batch adversarial loss: 0.455022\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049515; batch adversarial loss: 0.421815\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052743; batch adversarial loss: 0.499959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.028000; batch adversarial loss: 0.393352\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056017; batch adversarial loss: 0.419937\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060876; batch adversarial loss: 0.447920\n",
      "epoch 101; iter: 0; batch classifier loss: 0.024893; batch adversarial loss: 0.466818\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058006; batch adversarial loss: 0.385202\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045196; batch adversarial loss: 0.545450\n",
      "epoch 104; iter: 0; batch classifier loss: 0.080358; batch adversarial loss: 0.473720\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041302; batch adversarial loss: 0.414829\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057039; batch adversarial loss: 0.437320\n",
      "epoch 107; iter: 0; batch classifier loss: 0.029050; batch adversarial loss: 0.412424\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049865; batch adversarial loss: 0.469354\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044606; batch adversarial loss: 0.412065\n",
      "epoch 110; iter: 0; batch classifier loss: 0.022980; batch adversarial loss: 0.446918\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059086; batch adversarial loss: 0.468490\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031935; batch adversarial loss: 0.404455\n",
      "epoch 113; iter: 0; batch classifier loss: 0.032632; batch adversarial loss: 0.475841\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036304; batch adversarial loss: 0.434115\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022974; batch adversarial loss: 0.417829\n",
      "epoch 116; iter: 0; batch classifier loss: 0.011598; batch adversarial loss: 0.416893\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042568; batch adversarial loss: 0.393922\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033453; batch adversarial loss: 0.432684\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020973; batch adversarial loss: 0.513331\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044313; batch adversarial loss: 0.453169\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033585; batch adversarial loss: 0.366318\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041876; batch adversarial loss: 0.467076\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031301; batch adversarial loss: 0.460387\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050489; batch adversarial loss: 0.543957\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027936; batch adversarial loss: 0.443590\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043815; batch adversarial loss: 0.439033\n",
      "epoch 127; iter: 0; batch classifier loss: 0.013412; batch adversarial loss: 0.392081\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022166; batch adversarial loss: 0.547134\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041728; batch adversarial loss: 0.550505\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038374; batch adversarial loss: 0.431258\n",
      "epoch 131; iter: 0; batch classifier loss: 0.086320; batch adversarial loss: 0.521701\n",
      "epoch 132; iter: 0; batch classifier loss: 0.074527; batch adversarial loss: 0.650949\n",
      "epoch 133; iter: 0; batch classifier loss: 0.100888; batch adversarial loss: 0.655224\n",
      "epoch 134; iter: 0; batch classifier loss: 0.088860; batch adversarial loss: 0.599452\n",
      "epoch 135; iter: 0; batch classifier loss: 0.145162; batch adversarial loss: 0.637864\n",
      "epoch 136; iter: 0; batch classifier loss: 0.160444; batch adversarial loss: 0.560335\n",
      "epoch 137; iter: 0; batch classifier loss: 0.079942; batch adversarial loss: 0.587132\n",
      "epoch 138; iter: 0; batch classifier loss: 0.130110; batch adversarial loss: 0.517995\n",
      "epoch 139; iter: 0; batch classifier loss: 0.203884; batch adversarial loss: 0.807250\n",
      "epoch 140; iter: 0; batch classifier loss: 0.104710; batch adversarial loss: 0.562692\n",
      "epoch 141; iter: 0; batch classifier loss: 0.096283; batch adversarial loss: 0.491281\n",
      "epoch 142; iter: 0; batch classifier loss: 0.166080; batch adversarial loss: 0.555001\n",
      "epoch 143; iter: 0; batch classifier loss: 0.181709; batch adversarial loss: 0.630162\n",
      "epoch 144; iter: 0; batch classifier loss: 0.117950; batch adversarial loss: 0.566610\n",
      "epoch 145; iter: 0; batch classifier loss: 0.170691; batch adversarial loss: 0.650117\n",
      "epoch 146; iter: 0; batch classifier loss: 0.118093; batch adversarial loss: 0.472889\n",
      "epoch 147; iter: 0; batch classifier loss: 0.141949; batch adversarial loss: 0.567447\n",
      "epoch 148; iter: 0; batch classifier loss: 0.141482; batch adversarial loss: 0.511119\n",
      "epoch 149; iter: 0; batch classifier loss: 0.137374; batch adversarial loss: 0.657954\n",
      "epoch 150; iter: 0; batch classifier loss: 0.202249; batch adversarial loss: 0.706012\n",
      "epoch 151; iter: 0; batch classifier loss: 0.209900; batch adversarial loss: 0.656412\n",
      "epoch 152; iter: 0; batch classifier loss: 0.111776; batch adversarial loss: 0.424439\n",
      "epoch 153; iter: 0; batch classifier loss: 0.194030; batch adversarial loss: 0.541215\n",
      "epoch 154; iter: 0; batch classifier loss: 0.106780; batch adversarial loss: 0.505395\n",
      "epoch 155; iter: 0; batch classifier loss: 0.138138; batch adversarial loss: 0.463255\n",
      "epoch 156; iter: 0; batch classifier loss: 0.185129; batch adversarial loss: 0.560314\n",
      "epoch 157; iter: 0; batch classifier loss: 0.110696; batch adversarial loss: 0.508061\n",
      "epoch 158; iter: 0; batch classifier loss: 0.106580; batch adversarial loss: 0.449533\n",
      "epoch 159; iter: 0; batch classifier loss: 0.114394; batch adversarial loss: 0.524099\n",
      "epoch 160; iter: 0; batch classifier loss: 0.131699; batch adversarial loss: 0.544495\n",
      "epoch 161; iter: 0; batch classifier loss: 0.101870; batch adversarial loss: 0.529823\n",
      "epoch 162; iter: 0; batch classifier loss: 0.214013; batch adversarial loss: 0.540127\n",
      "epoch 163; iter: 0; batch classifier loss: 0.151208; batch adversarial loss: 0.521989\n",
      "epoch 164; iter: 0; batch classifier loss: 0.187332; batch adversarial loss: 0.577971\n",
      "epoch 165; iter: 0; batch classifier loss: 0.071058; batch adversarial loss: 0.545262\n",
      "epoch 166; iter: 0; batch classifier loss: 0.133459; batch adversarial loss: 0.518673\n",
      "epoch 167; iter: 0; batch classifier loss: 0.138220; batch adversarial loss: 0.543329\n",
      "epoch 168; iter: 0; batch classifier loss: 0.139496; batch adversarial loss: 0.498099\n",
      "epoch 169; iter: 0; batch classifier loss: 0.106064; batch adversarial loss: 0.377206\n",
      "epoch 170; iter: 0; batch classifier loss: 0.076190; batch adversarial loss: 0.469857\n",
      "epoch 171; iter: 0; batch classifier loss: 0.089782; batch adversarial loss: 0.436076\n",
      "epoch 172; iter: 0; batch classifier loss: 0.106136; batch adversarial loss: 0.470962\n",
      "epoch 173; iter: 0; batch classifier loss: 0.080123; batch adversarial loss: 0.368117\n",
      "epoch 174; iter: 0; batch classifier loss: 0.102533; batch adversarial loss: 0.497453\n",
      "epoch 175; iter: 0; batch classifier loss: 0.111789; batch adversarial loss: 0.462986\n",
      "epoch 176; iter: 0; batch classifier loss: 0.101423; batch adversarial loss: 0.385833\n",
      "epoch 177; iter: 0; batch classifier loss: 0.083474; batch adversarial loss: 0.543959\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039948; batch adversarial loss: 0.418951\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025875; batch adversarial loss: 0.410456\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035180; batch adversarial loss: 0.417624\n",
      "epoch 181; iter: 0; batch classifier loss: 0.043358; batch adversarial loss: 0.440870\n",
      "epoch 182; iter: 0; batch classifier loss: 0.054252; batch adversarial loss: 0.470493\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016738; batch adversarial loss: 0.356822\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025854; batch adversarial loss: 0.427596\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024529; batch adversarial loss: 0.428161\n",
      "epoch 186; iter: 0; batch classifier loss: 0.048228; batch adversarial loss: 0.432140\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034075; batch adversarial loss: 0.427109\n",
      "epoch 188; iter: 0; batch classifier loss: 0.045714; batch adversarial loss: 0.488682\n",
      "epoch 189; iter: 0; batch classifier loss: 0.057444; batch adversarial loss: 0.474038\n",
      "epoch 190; iter: 0; batch classifier loss: 0.055973; batch adversarial loss: 0.427548\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037882; batch adversarial loss: 0.417622\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035275; batch adversarial loss: 0.498524\n",
      "epoch 193; iter: 0; batch classifier loss: 0.082969; batch adversarial loss: 0.526183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.064593; batch adversarial loss: 0.447049\n",
      "epoch 195; iter: 0; batch classifier loss: 0.060042; batch adversarial loss: 0.446908\n",
      "epoch 196; iter: 0; batch classifier loss: 0.091207; batch adversarial loss: 0.428518\n",
      "epoch 197; iter: 0; batch classifier loss: 0.090409; batch adversarial loss: 0.397462\n",
      "epoch 198; iter: 0; batch classifier loss: 0.081594; batch adversarial loss: 0.466673\n",
      "epoch 199; iter: 0; batch classifier loss: 0.042552; batch adversarial loss: 0.450046\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698212; batch adversarial loss: 0.686926\n",
      "epoch 1; iter: 0; batch classifier loss: 0.467649; batch adversarial loss: 0.675912\n",
      "epoch 2; iter: 0; batch classifier loss: 0.420536; batch adversarial loss: 0.628044\n",
      "epoch 3; iter: 0; batch classifier loss: 0.427440; batch adversarial loss: 0.606477\n",
      "epoch 4; iter: 0; batch classifier loss: 0.346135; batch adversarial loss: 0.545965\n",
      "epoch 5; iter: 0; batch classifier loss: 0.325909; batch adversarial loss: 0.562660\n",
      "epoch 6; iter: 0; batch classifier loss: 0.275576; batch adversarial loss: 0.538015\n",
      "epoch 7; iter: 0; batch classifier loss: 0.299653; batch adversarial loss: 0.537003\n",
      "epoch 8; iter: 0; batch classifier loss: 0.277042; batch adversarial loss: 0.525644\n",
      "epoch 9; iter: 0; batch classifier loss: 0.260472; batch adversarial loss: 0.504731\n",
      "epoch 10; iter: 0; batch classifier loss: 0.314093; batch adversarial loss: 0.478661\n",
      "epoch 11; iter: 0; batch classifier loss: 0.183412; batch adversarial loss: 0.495595\n",
      "epoch 12; iter: 0; batch classifier loss: 0.257391; batch adversarial loss: 0.492784\n",
      "epoch 13; iter: 0; batch classifier loss: 0.174058; batch adversarial loss: 0.531728\n",
      "epoch 14; iter: 0; batch classifier loss: 0.174467; batch adversarial loss: 0.518814\n",
      "epoch 15; iter: 0; batch classifier loss: 0.193530; batch adversarial loss: 0.472164\n",
      "epoch 16; iter: 0; batch classifier loss: 0.194706; batch adversarial loss: 0.441448\n",
      "epoch 17; iter: 0; batch classifier loss: 0.148061; batch adversarial loss: 0.590061\n",
      "epoch 18; iter: 0; batch classifier loss: 0.193663; batch adversarial loss: 0.447182\n",
      "epoch 19; iter: 0; batch classifier loss: 0.152525; batch adversarial loss: 0.531023\n",
      "epoch 20; iter: 0; batch classifier loss: 0.126620; batch adversarial loss: 0.438151\n",
      "epoch 21; iter: 0; batch classifier loss: 0.207649; batch adversarial loss: 0.544755\n",
      "epoch 22; iter: 0; batch classifier loss: 0.138678; batch adversarial loss: 0.523386\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168614; batch adversarial loss: 0.539397\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194905; batch adversarial loss: 0.511436\n",
      "epoch 25; iter: 0; batch classifier loss: 0.178836; batch adversarial loss: 0.566350\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189937; batch adversarial loss: 0.562048\n",
      "epoch 27; iter: 0; batch classifier loss: 0.185970; batch adversarial loss: 0.512024\n",
      "epoch 28; iter: 0; batch classifier loss: 0.236386; batch adversarial loss: 0.592132\n",
      "epoch 29; iter: 0; batch classifier loss: 0.207801; batch adversarial loss: 0.567560\n",
      "epoch 30; iter: 0; batch classifier loss: 0.170511; batch adversarial loss: 0.527973\n",
      "epoch 31; iter: 0; batch classifier loss: 0.234572; batch adversarial loss: 0.536954\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210536; batch adversarial loss: 0.467614\n",
      "epoch 33; iter: 0; batch classifier loss: 0.264225; batch adversarial loss: 0.566227\n",
      "epoch 34; iter: 0; batch classifier loss: 0.267249; batch adversarial loss: 0.454913\n",
      "epoch 35; iter: 0; batch classifier loss: 0.265592; batch adversarial loss: 0.523290\n",
      "epoch 36; iter: 0; batch classifier loss: 0.183757; batch adversarial loss: 0.421418\n",
      "epoch 37; iter: 0; batch classifier loss: 0.097579; batch adversarial loss: 0.475065\n",
      "epoch 38; iter: 0; batch classifier loss: 0.146239; batch adversarial loss: 0.393501\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131238; batch adversarial loss: 0.548653\n",
      "epoch 40; iter: 0; batch classifier loss: 0.076909; batch adversarial loss: 0.512594\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106756; batch adversarial loss: 0.504693\n",
      "epoch 42; iter: 0; batch classifier loss: 0.100998; batch adversarial loss: 0.453721\n",
      "epoch 43; iter: 0; batch classifier loss: 0.077842; batch adversarial loss: 0.473523\n",
      "epoch 44; iter: 0; batch classifier loss: 0.056887; batch adversarial loss: 0.574748\n",
      "epoch 45; iter: 0; batch classifier loss: 0.077757; batch adversarial loss: 0.455090\n",
      "epoch 46; iter: 0; batch classifier loss: 0.083111; batch adversarial loss: 0.482660\n",
      "epoch 47; iter: 0; batch classifier loss: 0.078114; batch adversarial loss: 0.429027\n",
      "epoch 48; iter: 0; batch classifier loss: 0.134401; batch adversarial loss: 0.419132\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099526; batch adversarial loss: 0.428949\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096600; batch adversarial loss: 0.534407\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081724; batch adversarial loss: 0.338547\n",
      "epoch 52; iter: 0; batch classifier loss: 0.076773; batch adversarial loss: 0.492468\n",
      "epoch 53; iter: 0; batch classifier loss: 0.102656; batch adversarial loss: 0.472575\n",
      "epoch 54; iter: 0; batch classifier loss: 0.069192; batch adversarial loss: 0.601947\n",
      "epoch 55; iter: 0; batch classifier loss: 0.118512; batch adversarial loss: 0.427961\n",
      "epoch 56; iter: 0; batch classifier loss: 0.068992; batch adversarial loss: 0.456870\n",
      "epoch 57; iter: 0; batch classifier loss: 0.059335; batch adversarial loss: 0.582487\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064924; batch adversarial loss: 0.376741\n",
      "epoch 59; iter: 0; batch classifier loss: 0.131660; batch adversarial loss: 0.488795\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070641; batch adversarial loss: 0.506158\n",
      "epoch 61; iter: 0; batch classifier loss: 0.096506; batch adversarial loss: 0.520665\n",
      "epoch 62; iter: 0; batch classifier loss: 0.132516; batch adversarial loss: 0.462770\n",
      "epoch 63; iter: 0; batch classifier loss: 0.109084; batch adversarial loss: 0.457358\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073259; batch adversarial loss: 0.467361\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079040; batch adversarial loss: 0.507142\n",
      "epoch 66; iter: 0; batch classifier loss: 0.055750; batch adversarial loss: 0.573391\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087019; batch adversarial loss: 0.450155\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072171; batch adversarial loss: 0.444208\n",
      "epoch 69; iter: 0; batch classifier loss: 0.077716; batch adversarial loss: 0.547525\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073089; batch adversarial loss: 0.528868\n",
      "epoch 71; iter: 0; batch classifier loss: 0.122924; batch adversarial loss: 0.494225\n",
      "epoch 72; iter: 0; batch classifier loss: 0.098152; batch adversarial loss: 0.487787\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081966; batch adversarial loss: 0.516747\n",
      "epoch 74; iter: 0; batch classifier loss: 0.104474; batch adversarial loss: 0.509519\n",
      "epoch 75; iter: 0; batch classifier loss: 0.074082; batch adversarial loss: 0.337879\n",
      "epoch 76; iter: 0; batch classifier loss: 0.050881; batch adversarial loss: 0.534888\n",
      "epoch 77; iter: 0; batch classifier loss: 0.089245; batch adversarial loss: 0.473268\n",
      "epoch 78; iter: 0; batch classifier loss: 0.108594; batch adversarial loss: 0.489800\n",
      "epoch 79; iter: 0; batch classifier loss: 0.051273; batch adversarial loss: 0.593278\n",
      "epoch 80; iter: 0; batch classifier loss: 0.071418; batch adversarial loss: 0.438733\n",
      "epoch 81; iter: 0; batch classifier loss: 0.072973; batch adversarial loss: 0.403623\n",
      "epoch 82; iter: 0; batch classifier loss: 0.105938; batch adversarial loss: 0.478098\n",
      "epoch 83; iter: 0; batch classifier loss: 0.037091; batch adversarial loss: 0.489075\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055293; batch adversarial loss: 0.455327\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073844; batch adversarial loss: 0.475597\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069081; batch adversarial loss: 0.373808\n",
      "epoch 87; iter: 0; batch classifier loss: 0.084051; batch adversarial loss: 0.498985\n",
      "epoch 88; iter: 0; batch classifier loss: 0.035388; batch adversarial loss: 0.494501\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058979; batch adversarial loss: 0.573344\n",
      "epoch 90; iter: 0; batch classifier loss: 0.099940; batch adversarial loss: 0.439490\n",
      "epoch 91; iter: 0; batch classifier loss: 0.088579; batch adversarial loss: 0.387310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.044182; batch adversarial loss: 0.563708\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052844; batch adversarial loss: 0.475908\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070443; batch adversarial loss: 0.437007\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068906; batch adversarial loss: 0.621502\n",
      "epoch 96; iter: 0; batch classifier loss: 0.067700; batch adversarial loss: 0.546186\n",
      "epoch 97; iter: 0; batch classifier loss: 0.089305; batch adversarial loss: 0.453150\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051106; batch adversarial loss: 0.451599\n",
      "epoch 99; iter: 0; batch classifier loss: 0.068107; batch adversarial loss: 0.499839\n",
      "epoch 100; iter: 0; batch classifier loss: 0.040037; batch adversarial loss: 0.494939\n",
      "epoch 101; iter: 0; batch classifier loss: 0.105221; batch adversarial loss: 0.492657\n",
      "epoch 102; iter: 0; batch classifier loss: 0.115064; batch adversarial loss: 0.467030\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042738; batch adversarial loss: 0.497259\n",
      "epoch 104; iter: 0; batch classifier loss: 0.077732; batch adversarial loss: 0.556899\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045127; batch adversarial loss: 0.499981\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047567; batch adversarial loss: 0.473237\n",
      "epoch 107; iter: 0; batch classifier loss: 0.070161; batch adversarial loss: 0.492810\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058778; batch adversarial loss: 0.434312\n",
      "epoch 109; iter: 0; batch classifier loss: 0.076591; batch adversarial loss: 0.398537\n",
      "epoch 110; iter: 0; batch classifier loss: 0.062254; batch adversarial loss: 0.409389\n",
      "epoch 111; iter: 0; batch classifier loss: 0.081768; batch adversarial loss: 0.390140\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037203; batch adversarial loss: 0.466701\n",
      "epoch 113; iter: 0; batch classifier loss: 0.067683; batch adversarial loss: 0.512031\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060638; batch adversarial loss: 0.484083\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051970; batch adversarial loss: 0.512725\n",
      "epoch 116; iter: 0; batch classifier loss: 0.076080; batch adversarial loss: 0.491030\n",
      "epoch 117; iter: 0; batch classifier loss: 0.062898; batch adversarial loss: 0.507925\n",
      "epoch 118; iter: 0; batch classifier loss: 0.071236; batch adversarial loss: 0.507233\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039025; batch adversarial loss: 0.508206\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044995; batch adversarial loss: 0.416849\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041869; batch adversarial loss: 0.408556\n",
      "epoch 122; iter: 0; batch classifier loss: 0.053893; batch adversarial loss: 0.432387\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043402; batch adversarial loss: 0.513873\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038439; batch adversarial loss: 0.454028\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028879; batch adversarial loss: 0.541464\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050244; batch adversarial loss: 0.473899\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037021; batch adversarial loss: 0.450053\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055063; batch adversarial loss: 0.525336\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035127; batch adversarial loss: 0.597594\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023748; batch adversarial loss: 0.552756\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031693; batch adversarial loss: 0.395396\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041335; batch adversarial loss: 0.513254\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027923; batch adversarial loss: 0.473955\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053964; batch adversarial loss: 0.413789\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038104; batch adversarial loss: 0.502613\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033323; batch adversarial loss: 0.464540\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023221; batch adversarial loss: 0.485047\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048625; batch adversarial loss: 0.408104\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018714; batch adversarial loss: 0.429278\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041647; batch adversarial loss: 0.374773\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017938; batch adversarial loss: 0.407525\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034525; batch adversarial loss: 0.522043\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013392; batch adversarial loss: 0.478198\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018558; batch adversarial loss: 0.408617\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037713; batch adversarial loss: 0.437836\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032632; batch adversarial loss: 0.462199\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022209; batch adversarial loss: 0.470188\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046750; batch adversarial loss: 0.475737\n",
      "epoch 149; iter: 0; batch classifier loss: 0.052837; batch adversarial loss: 0.480636\n",
      "epoch 150; iter: 0; batch classifier loss: 0.051851; batch adversarial loss: 0.495250\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036777; batch adversarial loss: 0.495543\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008564; batch adversarial loss: 0.476369\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035108; batch adversarial loss: 0.551899\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027588; batch adversarial loss: 0.457582\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025301; batch adversarial loss: 0.460751\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021927; batch adversarial loss: 0.434585\n",
      "epoch 157; iter: 0; batch classifier loss: 0.058202; batch adversarial loss: 0.504916\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031488; batch adversarial loss: 0.490266\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017900; batch adversarial loss: 0.408866\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032684; batch adversarial loss: 0.536256\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033833; batch adversarial loss: 0.410619\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012257; batch adversarial loss: 0.488741\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011369; batch adversarial loss: 0.455051\n",
      "epoch 164; iter: 0; batch classifier loss: 0.066201; batch adversarial loss: 0.402372\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028097; batch adversarial loss: 0.446970\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027603; batch adversarial loss: 0.470766\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018034; batch adversarial loss: 0.488106\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009941; batch adversarial loss: 0.537090\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013115; batch adversarial loss: 0.485522\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029716; batch adversarial loss: 0.510831\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011726; batch adversarial loss: 0.416873\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019188; batch adversarial loss: 0.396974\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018615; batch adversarial loss: 0.419006\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010237; batch adversarial loss: 0.512613\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042314; batch adversarial loss: 0.401290\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037024; batch adversarial loss: 0.443470\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036764; batch adversarial loss: 0.390474\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034031; batch adversarial loss: 0.433762\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030052; batch adversarial loss: 0.451161\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024967; batch adversarial loss: 0.378083\n",
      "epoch 181; iter: 0; batch classifier loss: 0.051764; batch adversarial loss: 0.511770\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007691; batch adversarial loss: 0.551597\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015000; batch adversarial loss: 0.475008\n",
      "epoch 184; iter: 0; batch classifier loss: 0.058962; batch adversarial loss: 0.511133\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024391; batch adversarial loss: 0.372283\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023211; batch adversarial loss: 0.522060\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014581; batch adversarial loss: 0.406444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.018818; batch adversarial loss: 0.441510\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020409; batch adversarial loss: 0.530400\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010559; batch adversarial loss: 0.540293\n",
      "epoch 191; iter: 0; batch classifier loss: 0.053001; batch adversarial loss: 0.411119\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015107; batch adversarial loss: 0.448619\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016645; batch adversarial loss: 0.372674\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016873; batch adversarial loss: 0.420563\n",
      "epoch 195; iter: 0; batch classifier loss: 0.007479; batch adversarial loss: 0.552817\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011418; batch adversarial loss: 0.520836\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017015; batch adversarial loss: 0.533455\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028057; batch adversarial loss: 0.393226\n",
      "epoch 199; iter: 0; batch classifier loss: 0.034025; batch adversarial loss: 0.495243\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687675; batch adversarial loss: 0.576795\n",
      "epoch 1; iter: 0; batch classifier loss: 0.386237; batch adversarial loss: 0.591761\n",
      "epoch 2; iter: 0; batch classifier loss: 0.382622; batch adversarial loss: 0.583100\n",
      "epoch 3; iter: 0; batch classifier loss: 0.417834; batch adversarial loss: 0.598302\n",
      "epoch 4; iter: 0; batch classifier loss: 0.386097; batch adversarial loss: 0.579890\n",
      "epoch 5; iter: 0; batch classifier loss: 0.329309; batch adversarial loss: 0.563684\n",
      "epoch 6; iter: 0; batch classifier loss: 0.312224; batch adversarial loss: 0.545507\n",
      "epoch 7; iter: 0; batch classifier loss: 0.301902; batch adversarial loss: 0.555579\n",
      "epoch 8; iter: 0; batch classifier loss: 0.345624; batch adversarial loss: 0.549017\n",
      "epoch 9; iter: 0; batch classifier loss: 0.411493; batch adversarial loss: 0.633518\n",
      "epoch 10; iter: 0; batch classifier loss: 0.384364; batch adversarial loss: 0.574906\n",
      "epoch 11; iter: 0; batch classifier loss: 0.459609; batch adversarial loss: 0.564758\n",
      "epoch 12; iter: 0; batch classifier loss: 0.757447; batch adversarial loss: 0.536553\n",
      "epoch 13; iter: 0; batch classifier loss: 0.490201; batch adversarial loss: 0.507903\n",
      "epoch 14; iter: 0; batch classifier loss: 0.391987; batch adversarial loss: 0.500529\n",
      "epoch 15; iter: 0; batch classifier loss: 0.333693; batch adversarial loss: 0.532741\n",
      "epoch 16; iter: 0; batch classifier loss: 0.299459; batch adversarial loss: 0.468851\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269987; batch adversarial loss: 0.452747\n",
      "epoch 18; iter: 0; batch classifier loss: 0.227096; batch adversarial loss: 0.411747\n",
      "epoch 19; iter: 0; batch classifier loss: 0.271200; batch adversarial loss: 0.467525\n",
      "epoch 20; iter: 0; batch classifier loss: 0.218344; batch adversarial loss: 0.405661\n",
      "epoch 21; iter: 0; batch classifier loss: 0.148795; batch adversarial loss: 0.491449\n",
      "epoch 22; iter: 0; batch classifier loss: 0.197811; batch adversarial loss: 0.492939\n",
      "epoch 23; iter: 0; batch classifier loss: 0.216387; batch adversarial loss: 0.504462\n",
      "epoch 24; iter: 0; batch classifier loss: 0.244276; batch adversarial loss: 0.472263\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201245; batch adversarial loss: 0.452460\n",
      "epoch 26; iter: 0; batch classifier loss: 0.156029; batch adversarial loss: 0.540032\n",
      "epoch 27; iter: 0; batch classifier loss: 0.200175; batch adversarial loss: 0.447322\n",
      "epoch 28; iter: 0; batch classifier loss: 0.151313; batch adversarial loss: 0.376045\n",
      "epoch 29; iter: 0; batch classifier loss: 0.200556; batch adversarial loss: 0.393328\n",
      "epoch 30; iter: 0; batch classifier loss: 0.166311; batch adversarial loss: 0.382385\n",
      "epoch 31; iter: 0; batch classifier loss: 0.143869; batch adversarial loss: 0.483950\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140478; batch adversarial loss: 0.483936\n",
      "epoch 33; iter: 0; batch classifier loss: 0.103143; batch adversarial loss: 0.452331\n",
      "epoch 34; iter: 0; batch classifier loss: 0.155574; batch adversarial loss: 0.500456\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118521; batch adversarial loss: 0.453911\n",
      "epoch 36; iter: 0; batch classifier loss: 0.067268; batch adversarial loss: 0.503151\n",
      "epoch 37; iter: 0; batch classifier loss: 0.109815; batch adversarial loss: 0.350636\n",
      "epoch 38; iter: 0; batch classifier loss: 0.085697; batch adversarial loss: 0.415877\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118834; batch adversarial loss: 0.448911\n",
      "epoch 40; iter: 0; batch classifier loss: 0.096463; batch adversarial loss: 0.470667\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135916; batch adversarial loss: 0.476313\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146564; batch adversarial loss: 0.418082\n",
      "epoch 43; iter: 0; batch classifier loss: 0.120978; batch adversarial loss: 0.407903\n",
      "epoch 44; iter: 0; batch classifier loss: 0.094764; batch adversarial loss: 0.446674\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102674; batch adversarial loss: 0.418601\n",
      "epoch 46; iter: 0; batch classifier loss: 0.091450; batch adversarial loss: 0.393794\n",
      "epoch 47; iter: 0; batch classifier loss: 0.116366; batch adversarial loss: 0.429271\n",
      "epoch 48; iter: 0; batch classifier loss: 0.117738; batch adversarial loss: 0.443178\n",
      "epoch 49; iter: 0; batch classifier loss: 0.127469; batch adversarial loss: 0.456303\n",
      "epoch 50; iter: 0; batch classifier loss: 0.115348; batch adversarial loss: 0.503310\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092199; batch adversarial loss: 0.405631\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100701; batch adversarial loss: 0.409773\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122574; batch adversarial loss: 0.440832\n",
      "epoch 54; iter: 0; batch classifier loss: 0.083546; batch adversarial loss: 0.461112\n",
      "epoch 55; iter: 0; batch classifier loss: 0.161095; batch adversarial loss: 0.404113\n",
      "epoch 56; iter: 0; batch classifier loss: 0.237482; batch adversarial loss: 0.420554\n",
      "epoch 57; iter: 0; batch classifier loss: 0.102829; batch adversarial loss: 0.440593\n",
      "epoch 58; iter: 0; batch classifier loss: 0.119629; batch adversarial loss: 0.352253\n",
      "epoch 59; iter: 0; batch classifier loss: 0.153006; batch adversarial loss: 0.460891\n",
      "epoch 60; iter: 0; batch classifier loss: 0.112178; batch adversarial loss: 0.446127\n",
      "epoch 61; iter: 0; batch classifier loss: 0.052979; batch adversarial loss: 0.586182\n",
      "epoch 62; iter: 0; batch classifier loss: 0.097477; batch adversarial loss: 0.415565\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128989; batch adversarial loss: 0.393295\n",
      "epoch 64; iter: 0; batch classifier loss: 0.136273; batch adversarial loss: 0.427371\n",
      "epoch 65; iter: 0; batch classifier loss: 0.127957; batch adversarial loss: 0.376384\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085621; batch adversarial loss: 0.508208\n",
      "epoch 67; iter: 0; batch classifier loss: 0.160887; batch adversarial loss: 0.520930\n",
      "epoch 68; iter: 0; batch classifier loss: 0.194973; batch adversarial loss: 0.439929\n",
      "epoch 69; iter: 0; batch classifier loss: 0.114609; batch adversarial loss: 0.442618\n",
      "epoch 70; iter: 0; batch classifier loss: 0.133650; batch adversarial loss: 0.562300\n",
      "epoch 71; iter: 0; batch classifier loss: 0.127826; batch adversarial loss: 0.538768\n",
      "epoch 72; iter: 0; batch classifier loss: 0.110940; batch adversarial loss: 0.456956\n",
      "epoch 73; iter: 0; batch classifier loss: 0.094298; batch adversarial loss: 0.398977\n",
      "epoch 74; iter: 0; batch classifier loss: 0.134326; batch adversarial loss: 0.394074\n",
      "epoch 75; iter: 0; batch classifier loss: 0.114706; batch adversarial loss: 0.504900\n",
      "epoch 76; iter: 0; batch classifier loss: 0.118817; batch adversarial loss: 0.415092\n",
      "epoch 77; iter: 0; batch classifier loss: 0.148108; batch adversarial loss: 0.502029\n",
      "epoch 78; iter: 0; batch classifier loss: 0.121146; batch adversarial loss: 0.411205\n",
      "epoch 79; iter: 0; batch classifier loss: 0.112920; batch adversarial loss: 0.533016\n",
      "epoch 80; iter: 0; batch classifier loss: 0.157707; batch adversarial loss: 0.388532\n",
      "epoch 81; iter: 0; batch classifier loss: 0.153240; batch adversarial loss: 0.507703\n",
      "epoch 82; iter: 0; batch classifier loss: 0.185243; batch adversarial loss: 0.446139\n",
      "epoch 83; iter: 0; batch classifier loss: 0.140906; batch adversarial loss: 0.409918\n",
      "epoch 84; iter: 0; batch classifier loss: 0.100337; batch adversarial loss: 0.524463\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084297; batch adversarial loss: 0.521755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.083629; batch adversarial loss: 0.343063\n",
      "epoch 87; iter: 0; batch classifier loss: 0.115683; batch adversarial loss: 0.394896\n",
      "epoch 88; iter: 0; batch classifier loss: 0.127381; batch adversarial loss: 0.401078\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098735; batch adversarial loss: 0.532826\n",
      "epoch 90; iter: 0; batch classifier loss: 0.139277; batch adversarial loss: 0.449912\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082079; batch adversarial loss: 0.519422\n",
      "epoch 92; iter: 0; batch classifier loss: 0.125623; batch adversarial loss: 0.351503\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080268; batch adversarial loss: 0.347796\n",
      "epoch 94; iter: 0; batch classifier loss: 0.138104; batch adversarial loss: 0.538749\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064746; batch adversarial loss: 0.555793\n",
      "epoch 96; iter: 0; batch classifier loss: 0.158884; batch adversarial loss: 0.467664\n",
      "epoch 97; iter: 0; batch classifier loss: 0.101009; batch adversarial loss: 0.470246\n",
      "epoch 98; iter: 0; batch classifier loss: 0.136477; batch adversarial loss: 0.479492\n",
      "epoch 99; iter: 0; batch classifier loss: 0.111775; batch adversarial loss: 0.467608\n",
      "epoch 100; iter: 0; batch classifier loss: 0.116643; batch adversarial loss: 0.451906\n",
      "epoch 101; iter: 0; batch classifier loss: 0.102624; batch adversarial loss: 0.502254\n",
      "epoch 102; iter: 0; batch classifier loss: 0.088715; batch adversarial loss: 0.539575\n",
      "epoch 103; iter: 0; batch classifier loss: 0.103560; batch adversarial loss: 0.488696\n",
      "epoch 104; iter: 0; batch classifier loss: 0.097936; batch adversarial loss: 0.419651\n",
      "epoch 105; iter: 0; batch classifier loss: 0.081644; batch adversarial loss: 0.472371\n",
      "epoch 106; iter: 0; batch classifier loss: 0.133776; batch adversarial loss: 0.434842\n",
      "epoch 107; iter: 0; batch classifier loss: 0.108881; batch adversarial loss: 0.433556\n",
      "epoch 108; iter: 0; batch classifier loss: 0.153800; batch adversarial loss: 0.400267\n",
      "epoch 109; iter: 0; batch classifier loss: 0.118818; batch adversarial loss: 0.469675\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053419; batch adversarial loss: 0.470946\n",
      "epoch 111; iter: 0; batch classifier loss: 0.146437; batch adversarial loss: 0.470378\n",
      "epoch 112; iter: 0; batch classifier loss: 0.108281; batch adversarial loss: 0.467362\n",
      "epoch 113; iter: 0; batch classifier loss: 0.123679; batch adversarial loss: 0.408805\n",
      "epoch 114; iter: 0; batch classifier loss: 0.108925; batch adversarial loss: 0.449202\n",
      "epoch 115; iter: 0; batch classifier loss: 0.113980; batch adversarial loss: 0.429518\n",
      "epoch 116; iter: 0; batch classifier loss: 0.089109; batch adversarial loss: 0.453828\n",
      "epoch 117; iter: 0; batch classifier loss: 0.085616; batch adversarial loss: 0.426942\n",
      "epoch 118; iter: 0; batch classifier loss: 0.102677; batch adversarial loss: 0.440749\n",
      "epoch 119; iter: 0; batch classifier loss: 0.085312; batch adversarial loss: 0.437399\n",
      "epoch 120; iter: 0; batch classifier loss: 0.114660; batch adversarial loss: 0.437552\n",
      "epoch 121; iter: 0; batch classifier loss: 0.074380; batch adversarial loss: 0.594959\n",
      "epoch 122; iter: 0; batch classifier loss: 0.115347; batch adversarial loss: 0.432757\n",
      "epoch 123; iter: 0; batch classifier loss: 0.113457; batch adversarial loss: 0.477321\n",
      "epoch 124; iter: 0; batch classifier loss: 0.088111; batch adversarial loss: 0.457358\n",
      "epoch 125; iter: 0; batch classifier loss: 0.133689; batch adversarial loss: 0.444242\n",
      "epoch 126; iter: 0; batch classifier loss: 0.094896; batch adversarial loss: 0.504906\n",
      "epoch 127; iter: 0; batch classifier loss: 0.099914; batch adversarial loss: 0.405780\n",
      "epoch 128; iter: 0; batch classifier loss: 0.080419; batch adversarial loss: 0.481090\n",
      "epoch 129; iter: 0; batch classifier loss: 0.092640; batch adversarial loss: 0.467416\n",
      "epoch 130; iter: 0; batch classifier loss: 0.153326; batch adversarial loss: 0.384668\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026204; batch adversarial loss: 0.467057\n",
      "epoch 132; iter: 0; batch classifier loss: 0.063451; batch adversarial loss: 0.443042\n",
      "epoch 133; iter: 0; batch classifier loss: 0.071246; batch adversarial loss: 0.525000\n",
      "epoch 134; iter: 0; batch classifier loss: 0.104641; batch adversarial loss: 0.460169\n",
      "epoch 135; iter: 0; batch classifier loss: 0.093056; batch adversarial loss: 0.482381\n",
      "epoch 136; iter: 0; batch classifier loss: 0.098117; batch adversarial loss: 0.380757\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054083; batch adversarial loss: 0.473532\n",
      "epoch 138; iter: 0; batch classifier loss: 0.065330; batch adversarial loss: 0.487229\n",
      "epoch 139; iter: 0; batch classifier loss: 0.093662; batch adversarial loss: 0.367422\n",
      "epoch 140; iter: 0; batch classifier loss: 0.049638; batch adversarial loss: 0.388508\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027643; batch adversarial loss: 0.499139\n",
      "epoch 142; iter: 0; batch classifier loss: 0.057456; batch adversarial loss: 0.388635\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029577; batch adversarial loss: 0.443892\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045782; batch adversarial loss: 0.391146\n",
      "epoch 145; iter: 0; batch classifier loss: 0.076879; batch adversarial loss: 0.508694\n",
      "epoch 146; iter: 0; batch classifier loss: 0.063643; batch adversarial loss: 0.559852\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023911; batch adversarial loss: 0.528216\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039369; batch adversarial loss: 0.450859\n",
      "epoch 149; iter: 0; batch classifier loss: 0.064275; batch adversarial loss: 0.492594\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029553; batch adversarial loss: 0.518781\n",
      "epoch 151; iter: 0; batch classifier loss: 0.087261; batch adversarial loss: 0.332447\n",
      "epoch 152; iter: 0; batch classifier loss: 0.060890; batch adversarial loss: 0.468308\n",
      "epoch 153; iter: 0; batch classifier loss: 0.072034; batch adversarial loss: 0.501270\n",
      "epoch 154; iter: 0; batch classifier loss: 0.045356; batch adversarial loss: 0.522099\n",
      "epoch 155; iter: 0; batch classifier loss: 0.053986; batch adversarial loss: 0.586015\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034388; batch adversarial loss: 0.429187\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019214; batch adversarial loss: 0.430736\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018979; batch adversarial loss: 0.411762\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030333; batch adversarial loss: 0.421780\n",
      "epoch 160; iter: 0; batch classifier loss: 0.055919; batch adversarial loss: 0.423518\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018252; batch adversarial loss: 0.444513\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042604; batch adversarial loss: 0.399818\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033279; batch adversarial loss: 0.395404\n",
      "epoch 164; iter: 0; batch classifier loss: 0.047532; batch adversarial loss: 0.410058\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037064; batch adversarial loss: 0.435401\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034812; batch adversarial loss: 0.481583\n",
      "epoch 167; iter: 0; batch classifier loss: 0.049480; batch adversarial loss: 0.423235\n",
      "epoch 168; iter: 0; batch classifier loss: 0.043100; batch adversarial loss: 0.414453\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024025; batch adversarial loss: 0.420538\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023374; batch adversarial loss: 0.476904\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017417; batch adversarial loss: 0.398183\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012989; batch adversarial loss: 0.494249\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015723; batch adversarial loss: 0.511109\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017806; batch adversarial loss: 0.427167\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009705; batch adversarial loss: 0.480565\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039130; batch adversarial loss: 0.449490\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013578; batch adversarial loss: 0.382753\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021129; batch adversarial loss: 0.443712\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030459; batch adversarial loss: 0.377402\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021370; batch adversarial loss: 0.487595\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012982; batch adversarial loss: 0.442383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.016742; batch adversarial loss: 0.385348\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020824; batch adversarial loss: 0.478628\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032452; batch adversarial loss: 0.423743\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029571; batch adversarial loss: 0.442776\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021297; batch adversarial loss: 0.465559\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011277; batch adversarial loss: 0.482334\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017222; batch adversarial loss: 0.422414\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028188; batch adversarial loss: 0.472510\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028609; batch adversarial loss: 0.472557\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022373; batch adversarial loss: 0.454120\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016712; batch adversarial loss: 0.531905\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022741; batch adversarial loss: 0.442850\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013914; batch adversarial loss: 0.484490\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009218; batch adversarial loss: 0.545057\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008000; batch adversarial loss: 0.522929\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037139; batch adversarial loss: 0.442834\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031375; batch adversarial loss: 0.480819\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010215; batch adversarial loss: 0.513406\n",
      "epoch 0; iter: 0; batch classifier loss: 0.741168; batch adversarial loss: 0.686803\n",
      "epoch 1; iter: 0; batch classifier loss: 0.559866; batch adversarial loss: 0.612423\n",
      "epoch 2; iter: 0; batch classifier loss: 0.420984; batch adversarial loss: 0.620080\n",
      "epoch 3; iter: 0; batch classifier loss: 0.379521; batch adversarial loss: 0.561862\n",
      "epoch 4; iter: 0; batch classifier loss: 0.352853; batch adversarial loss: 0.612732\n",
      "epoch 5; iter: 0; batch classifier loss: 0.312411; batch adversarial loss: 0.554910\n",
      "epoch 6; iter: 0; batch classifier loss: 0.357129; batch adversarial loss: 0.592486\n",
      "epoch 7; iter: 0; batch classifier loss: 0.294723; batch adversarial loss: 0.536157\n",
      "epoch 8; iter: 0; batch classifier loss: 0.249656; batch adversarial loss: 0.526339\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282648; batch adversarial loss: 0.514057\n",
      "epoch 10; iter: 0; batch classifier loss: 0.195397; batch adversarial loss: 0.497826\n",
      "epoch 11; iter: 0; batch classifier loss: 0.334702; batch adversarial loss: 0.495167\n",
      "epoch 12; iter: 0; batch classifier loss: 0.284639; batch adversarial loss: 0.542137\n",
      "epoch 13; iter: 0; batch classifier loss: 0.243858; batch adversarial loss: 0.536223\n",
      "epoch 14; iter: 0; batch classifier loss: 0.206513; batch adversarial loss: 0.482286\n",
      "epoch 15; iter: 0; batch classifier loss: 0.167191; batch adversarial loss: 0.552571\n",
      "epoch 16; iter: 0; batch classifier loss: 0.246814; batch adversarial loss: 0.493424\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192553; batch adversarial loss: 0.463616\n",
      "epoch 18; iter: 0; batch classifier loss: 0.228242; batch adversarial loss: 0.434069\n",
      "epoch 19; iter: 0; batch classifier loss: 0.210637; batch adversarial loss: 0.487690\n",
      "epoch 20; iter: 0; batch classifier loss: 0.217195; batch adversarial loss: 0.498938\n",
      "epoch 21; iter: 0; batch classifier loss: 0.243589; batch adversarial loss: 0.368648\n",
      "epoch 22; iter: 0; batch classifier loss: 0.159226; batch adversarial loss: 0.447680\n",
      "epoch 23; iter: 0; batch classifier loss: 0.119245; batch adversarial loss: 0.602516\n",
      "epoch 24; iter: 0; batch classifier loss: 0.171814; batch adversarial loss: 0.441793\n",
      "epoch 25; iter: 0; batch classifier loss: 0.221480; batch adversarial loss: 0.471960\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181334; batch adversarial loss: 0.481651\n",
      "epoch 27; iter: 0; batch classifier loss: 0.125266; batch adversarial loss: 0.433022\n",
      "epoch 28; iter: 0; batch classifier loss: 0.102376; batch adversarial loss: 0.504960\n",
      "epoch 29; iter: 0; batch classifier loss: 0.186095; batch adversarial loss: 0.432762\n",
      "epoch 30; iter: 0; batch classifier loss: 0.218076; batch adversarial loss: 0.442364\n",
      "epoch 31; iter: 0; batch classifier loss: 0.184633; batch adversarial loss: 0.415513\n",
      "epoch 32; iter: 0; batch classifier loss: 0.166226; batch adversarial loss: 0.402758\n",
      "epoch 33; iter: 0; batch classifier loss: 0.179390; batch adversarial loss: 0.492109\n",
      "epoch 34; iter: 0; batch classifier loss: 0.154569; batch adversarial loss: 0.408850\n",
      "epoch 35; iter: 0; batch classifier loss: 0.135159; batch adversarial loss: 0.411768\n",
      "epoch 36; iter: 0; batch classifier loss: 0.168831; batch adversarial loss: 0.508233\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111598; batch adversarial loss: 0.523663\n",
      "epoch 38; iter: 0; batch classifier loss: 0.188180; batch adversarial loss: 0.446901\n",
      "epoch 39; iter: 0; batch classifier loss: 0.186327; batch adversarial loss: 0.432131\n",
      "epoch 40; iter: 0; batch classifier loss: 0.194203; batch adversarial loss: 0.443725\n",
      "epoch 41; iter: 0; batch classifier loss: 0.140476; batch adversarial loss: 0.383943\n",
      "epoch 42; iter: 0; batch classifier loss: 0.135988; batch adversarial loss: 0.441215\n",
      "epoch 43; iter: 0; batch classifier loss: 0.096246; batch adversarial loss: 0.380411\n",
      "epoch 44; iter: 0; batch classifier loss: 0.187214; batch adversarial loss: 0.389230\n",
      "epoch 45; iter: 0; batch classifier loss: 0.144108; batch adversarial loss: 0.440963\n",
      "epoch 46; iter: 0; batch classifier loss: 0.187788; batch adversarial loss: 0.407860\n",
      "epoch 47; iter: 0; batch classifier loss: 0.128989; batch adversarial loss: 0.543818\n",
      "epoch 48; iter: 0; batch classifier loss: 0.189137; batch adversarial loss: 0.426720\n",
      "epoch 49; iter: 0; batch classifier loss: 0.135291; batch adversarial loss: 0.411619\n",
      "epoch 50; iter: 0; batch classifier loss: 0.153238; batch adversarial loss: 0.515408\n",
      "epoch 51; iter: 0; batch classifier loss: 0.089544; batch adversarial loss: 0.463973\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082952; batch adversarial loss: 0.433210\n",
      "epoch 53; iter: 0; batch classifier loss: 0.143008; batch adversarial loss: 0.473277\n",
      "epoch 54; iter: 0; batch classifier loss: 0.137260; batch adversarial loss: 0.452614\n",
      "epoch 55; iter: 0; batch classifier loss: 0.157865; batch adversarial loss: 0.454352\n",
      "epoch 56; iter: 0; batch classifier loss: 0.159254; batch adversarial loss: 0.458852\n",
      "epoch 57; iter: 0; batch classifier loss: 0.116856; batch adversarial loss: 0.456395\n",
      "epoch 58; iter: 0; batch classifier loss: 0.181419; batch adversarial loss: 0.396634\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085802; batch adversarial loss: 0.470454\n",
      "epoch 60; iter: 0; batch classifier loss: 0.092267; batch adversarial loss: 0.525201\n",
      "epoch 61; iter: 0; batch classifier loss: 0.146287; batch adversarial loss: 0.433026\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108616; batch adversarial loss: 0.448599\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100514; batch adversarial loss: 0.454053\n",
      "epoch 64; iter: 0; batch classifier loss: 0.168735; batch adversarial loss: 0.458901\n",
      "epoch 65; iter: 0; batch classifier loss: 0.174016; batch adversarial loss: 0.387725\n",
      "epoch 66; iter: 0; batch classifier loss: 0.128819; batch adversarial loss: 0.499578\n",
      "epoch 67; iter: 0; batch classifier loss: 0.147478; batch adversarial loss: 0.411173\n",
      "epoch 68; iter: 0; batch classifier loss: 0.167944; batch adversarial loss: 0.437328\n",
      "epoch 69; iter: 0; batch classifier loss: 0.092776; batch adversarial loss: 0.417056\n",
      "epoch 70; iter: 0; batch classifier loss: 0.139435; batch adversarial loss: 0.524795\n",
      "epoch 71; iter: 0; batch classifier loss: 0.126002; batch adversarial loss: 0.493627\n",
      "epoch 72; iter: 0; batch classifier loss: 0.111370; batch adversarial loss: 0.405691\n",
      "epoch 73; iter: 0; batch classifier loss: 0.111091; batch adversarial loss: 0.442059\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082195; batch adversarial loss: 0.410098\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083732; batch adversarial loss: 0.446011\n",
      "epoch 76; iter: 0; batch classifier loss: 0.118538; batch adversarial loss: 0.491265\n",
      "epoch 77; iter: 0; batch classifier loss: 0.100438; batch adversarial loss: 0.496271\n",
      "epoch 78; iter: 0; batch classifier loss: 0.112554; batch adversarial loss: 0.456987\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071061; batch adversarial loss: 0.406844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.093378; batch adversarial loss: 0.424067\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079097; batch adversarial loss: 0.376080\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090082; batch adversarial loss: 0.302328\n",
      "epoch 83; iter: 0; batch classifier loss: 0.105081; batch adversarial loss: 0.385625\n",
      "epoch 84; iter: 0; batch classifier loss: 0.105846; batch adversarial loss: 0.457076\n",
      "epoch 85; iter: 0; batch classifier loss: 0.069218; batch adversarial loss: 0.459784\n",
      "epoch 86; iter: 0; batch classifier loss: 0.092915; batch adversarial loss: 0.378483\n",
      "epoch 87; iter: 0; batch classifier loss: 0.092553; batch adversarial loss: 0.375265\n",
      "epoch 88; iter: 0; batch classifier loss: 0.089396; batch adversarial loss: 0.496573\n",
      "epoch 89; iter: 0; batch classifier loss: 0.043438; batch adversarial loss: 0.589513\n",
      "epoch 90; iter: 0; batch classifier loss: 0.094599; batch adversarial loss: 0.401698\n",
      "epoch 91; iter: 0; batch classifier loss: 0.097639; batch adversarial loss: 0.433447\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068278; batch adversarial loss: 0.573693\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052893; batch adversarial loss: 0.465788\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058814; batch adversarial loss: 0.440506\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070786; batch adversarial loss: 0.352747\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055434; batch adversarial loss: 0.407217\n",
      "epoch 97; iter: 0; batch classifier loss: 0.030032; batch adversarial loss: 0.343208\n",
      "epoch 98; iter: 0; batch classifier loss: 0.057063; batch adversarial loss: 0.357714\n",
      "epoch 99; iter: 0; batch classifier loss: 0.094449; batch adversarial loss: 0.443374\n",
      "epoch 100; iter: 0; batch classifier loss: 0.096643; batch adversarial loss: 0.373669\n",
      "epoch 101; iter: 0; batch classifier loss: 0.036132; batch adversarial loss: 0.513613\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048917; batch adversarial loss: 0.468894\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039842; batch adversarial loss: 0.472640\n",
      "epoch 104; iter: 0; batch classifier loss: 0.049484; batch adversarial loss: 0.520717\n",
      "epoch 105; iter: 0; batch classifier loss: 0.021801; batch adversarial loss: 0.493694\n",
      "epoch 106; iter: 0; batch classifier loss: 0.070640; batch adversarial loss: 0.417971\n",
      "epoch 107; iter: 0; batch classifier loss: 0.086163; batch adversarial loss: 0.390579\n",
      "epoch 108; iter: 0; batch classifier loss: 0.021580; batch adversarial loss: 0.512331\n",
      "epoch 109; iter: 0; batch classifier loss: 0.020259; batch adversarial loss: 0.492164\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030536; batch adversarial loss: 0.540443\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031214; batch adversarial loss: 0.463307\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060197; batch adversarial loss: 0.403003\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028620; batch adversarial loss: 0.396987\n",
      "epoch 114; iter: 0; batch classifier loss: 0.058240; batch adversarial loss: 0.374625\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038149; batch adversarial loss: 0.414670\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021723; batch adversarial loss: 0.530330\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028644; batch adversarial loss: 0.414318\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049386; batch adversarial loss: 0.508990\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050039; batch adversarial loss: 0.519618\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038361; batch adversarial loss: 0.440227\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025360; batch adversarial loss: 0.426217\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040466; batch adversarial loss: 0.486857\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050906; batch adversarial loss: 0.463309\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051006; batch adversarial loss: 0.379235\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024933; batch adversarial loss: 0.487818\n",
      "epoch 126; iter: 0; batch classifier loss: 0.058601; batch adversarial loss: 0.387250\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032442; batch adversarial loss: 0.481455\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017705; batch adversarial loss: 0.396383\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029948; batch adversarial loss: 0.449724\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023254; batch adversarial loss: 0.466777\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046292; batch adversarial loss: 0.404983\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032164; batch adversarial loss: 0.343259\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028301; batch adversarial loss: 0.536749\n",
      "epoch 134; iter: 0; batch classifier loss: 0.013506; batch adversarial loss: 0.425429\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057576; batch adversarial loss: 0.407971\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024008; batch adversarial loss: 0.437622\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025115; batch adversarial loss: 0.400092\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029765; batch adversarial loss: 0.502488\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039917; batch adversarial loss: 0.411805\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027451; batch adversarial loss: 0.322295\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025941; batch adversarial loss: 0.479951\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044011; batch adversarial loss: 0.462642\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021032; batch adversarial loss: 0.474193\n",
      "epoch 144; iter: 0; batch classifier loss: 0.056306; batch adversarial loss: 0.431100\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019933; batch adversarial loss: 0.370088\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020061; batch adversarial loss: 0.437738\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017808; batch adversarial loss: 0.448895\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030945; batch adversarial loss: 0.526018\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016249; batch adversarial loss: 0.427610\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036320; batch adversarial loss: 0.469743\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044685; batch adversarial loss: 0.468987\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025945; batch adversarial loss: 0.444713\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015772; batch adversarial loss: 0.563000\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013640; batch adversarial loss: 0.497640\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031277; batch adversarial loss: 0.418537\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024157; batch adversarial loss: 0.433695\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020415; batch adversarial loss: 0.491518\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012409; batch adversarial loss: 0.515813\n",
      "epoch 159; iter: 0; batch classifier loss: 0.004483; batch adversarial loss: 0.376406\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027295; batch adversarial loss: 0.472567\n",
      "epoch 161; iter: 0; batch classifier loss: 0.041099; batch adversarial loss: 0.402996\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015433; batch adversarial loss: 0.491831\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015916; batch adversarial loss: 0.376579\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033990; batch adversarial loss: 0.405802\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026145; batch adversarial loss: 0.419808\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027515; batch adversarial loss: 0.457531\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017169; batch adversarial loss: 0.482959\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018745; batch adversarial loss: 0.603668\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013709; batch adversarial loss: 0.452593\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030078; batch adversarial loss: 0.485822\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022419; batch adversarial loss: 0.525733\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020522; batch adversarial loss: 0.461212\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026440; batch adversarial loss: 0.493082\n",
      "epoch 174; iter: 0; batch classifier loss: 0.003735; batch adversarial loss: 0.341552\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010020; batch adversarial loss: 0.429659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.030963; batch adversarial loss: 0.444135\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015590; batch adversarial loss: 0.498547\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025183; batch adversarial loss: 0.463527\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014867; batch adversarial loss: 0.476476\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017024; batch adversarial loss: 0.475059\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012457; batch adversarial loss: 0.468289\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011558; batch adversarial loss: 0.518505\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017297; batch adversarial loss: 0.432389\n",
      "epoch 184; iter: 0; batch classifier loss: 0.057260; batch adversarial loss: 0.419908\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021527; batch adversarial loss: 0.444953\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032016; batch adversarial loss: 0.375797\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028175; batch adversarial loss: 0.476758\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014107; batch adversarial loss: 0.342670\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008033; batch adversarial loss: 0.458940\n",
      "epoch 190; iter: 0; batch classifier loss: 0.048916; batch adversarial loss: 0.498843\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005133; batch adversarial loss: 0.474295\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012293; batch adversarial loss: 0.588691\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010885; batch adversarial loss: 0.402134\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011841; batch adversarial loss: 0.363295\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010375; batch adversarial loss: 0.357392\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021820; batch adversarial loss: 0.414277\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013060; batch adversarial loss: 0.433540\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011213; batch adversarial loss: 0.349208\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016060; batch adversarial loss: 0.330655\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702774; batch adversarial loss: 0.665955\n",
      "epoch 1; iter: 0; batch classifier loss: 0.438088; batch adversarial loss: 0.666599\n",
      "epoch 2; iter: 0; batch classifier loss: 0.412998; batch adversarial loss: 0.636705\n",
      "epoch 3; iter: 0; batch classifier loss: 0.347099; batch adversarial loss: 0.591722\n",
      "epoch 4; iter: 0; batch classifier loss: 0.350144; batch adversarial loss: 0.561336\n",
      "epoch 5; iter: 0; batch classifier loss: 0.279972; batch adversarial loss: 0.561411\n",
      "epoch 6; iter: 0; batch classifier loss: 0.318432; batch adversarial loss: 0.520622\n",
      "epoch 7; iter: 0; batch classifier loss: 0.303126; batch adversarial loss: 0.491562\n",
      "epoch 8; iter: 0; batch classifier loss: 0.269123; batch adversarial loss: 0.453082\n",
      "epoch 9; iter: 0; batch classifier loss: 0.269016; batch adversarial loss: 0.493889\n",
      "epoch 10; iter: 0; batch classifier loss: 0.253574; batch adversarial loss: 0.522735\n",
      "epoch 11; iter: 0; batch classifier loss: 0.274242; batch adversarial loss: 0.484182\n",
      "epoch 12; iter: 0; batch classifier loss: 0.190287; batch adversarial loss: 0.554330\n",
      "epoch 13; iter: 0; batch classifier loss: 0.255880; batch adversarial loss: 0.512900\n",
      "epoch 14; iter: 0; batch classifier loss: 0.182666; batch adversarial loss: 0.445591\n",
      "epoch 15; iter: 0; batch classifier loss: 0.163074; batch adversarial loss: 0.444452\n",
      "epoch 16; iter: 0; batch classifier loss: 0.186769; batch adversarial loss: 0.456671\n",
      "epoch 17; iter: 0; batch classifier loss: 0.208972; batch adversarial loss: 0.459072\n",
      "epoch 18; iter: 0; batch classifier loss: 0.139498; batch adversarial loss: 0.460067\n",
      "epoch 19; iter: 0; batch classifier loss: 0.202353; batch adversarial loss: 0.452515\n",
      "epoch 20; iter: 0; batch classifier loss: 0.144956; batch adversarial loss: 0.509495\n",
      "epoch 21; iter: 0; batch classifier loss: 0.135917; batch adversarial loss: 0.466591\n",
      "epoch 22; iter: 0; batch classifier loss: 0.143075; batch adversarial loss: 0.463420\n",
      "epoch 23; iter: 0; batch classifier loss: 0.152117; batch adversarial loss: 0.516727\n",
      "epoch 24; iter: 0; batch classifier loss: 0.132266; batch adversarial loss: 0.486452\n",
      "epoch 25; iter: 0; batch classifier loss: 0.130149; batch adversarial loss: 0.441061\n",
      "epoch 26; iter: 0; batch classifier loss: 0.114669; batch adversarial loss: 0.533775\n",
      "epoch 27; iter: 0; batch classifier loss: 0.150170; batch adversarial loss: 0.448489\n",
      "epoch 28; iter: 0; batch classifier loss: 0.141076; batch adversarial loss: 0.447522\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179502; batch adversarial loss: 0.542199\n",
      "epoch 30; iter: 0; batch classifier loss: 0.200613; batch adversarial loss: 0.464236\n",
      "epoch 31; iter: 0; batch classifier loss: 0.186692; batch adversarial loss: 0.505772\n",
      "epoch 32; iter: 0; batch classifier loss: 0.231376; batch adversarial loss: 0.502908\n",
      "epoch 33; iter: 0; batch classifier loss: 0.223574; batch adversarial loss: 0.461244\n",
      "epoch 34; iter: 0; batch classifier loss: 0.157972; batch adversarial loss: 0.485794\n",
      "epoch 35; iter: 0; batch classifier loss: 0.230854; batch adversarial loss: 0.377589\n",
      "epoch 36; iter: 0; batch classifier loss: 0.330526; batch adversarial loss: 0.473232\n",
      "epoch 37; iter: 0; batch classifier loss: 0.118730; batch adversarial loss: 0.494023\n",
      "epoch 38; iter: 0; batch classifier loss: 0.134199; batch adversarial loss: 0.471897\n",
      "epoch 39; iter: 0; batch classifier loss: 0.141506; batch adversarial loss: 0.435158\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099593; batch adversarial loss: 0.364971\n",
      "epoch 41; iter: 0; batch classifier loss: 0.066999; batch adversarial loss: 0.390391\n",
      "epoch 42; iter: 0; batch classifier loss: 0.063742; batch adversarial loss: 0.485420\n",
      "epoch 43; iter: 0; batch classifier loss: 0.072762; batch adversarial loss: 0.427255\n",
      "epoch 44; iter: 0; batch classifier loss: 0.095602; batch adversarial loss: 0.412315\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089575; batch adversarial loss: 0.388187\n",
      "epoch 46; iter: 0; batch classifier loss: 0.094399; batch adversarial loss: 0.557970\n",
      "epoch 47; iter: 0; batch classifier loss: 0.086934; batch adversarial loss: 0.392999\n",
      "epoch 48; iter: 0; batch classifier loss: 0.086796; batch adversarial loss: 0.473914\n",
      "epoch 49; iter: 0; batch classifier loss: 0.121092; batch adversarial loss: 0.487497\n",
      "epoch 50; iter: 0; batch classifier loss: 0.086126; batch adversarial loss: 0.482168\n",
      "epoch 51; iter: 0; batch classifier loss: 0.067192; batch adversarial loss: 0.379331\n",
      "epoch 52; iter: 0; batch classifier loss: 0.076301; batch adversarial loss: 0.391685\n",
      "epoch 53; iter: 0; batch classifier loss: 0.041024; batch adversarial loss: 0.598940\n",
      "epoch 54; iter: 0; batch classifier loss: 0.055764; batch adversarial loss: 0.431639\n",
      "epoch 55; iter: 0; batch classifier loss: 0.055419; batch adversarial loss: 0.420379\n",
      "epoch 56; iter: 0; batch classifier loss: 0.047128; batch adversarial loss: 0.443327\n",
      "epoch 57; iter: 0; batch classifier loss: 0.045872; batch adversarial loss: 0.504466\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064636; batch adversarial loss: 0.618574\n",
      "epoch 59; iter: 0; batch classifier loss: 0.078115; batch adversarial loss: 0.511769\n",
      "epoch 60; iter: 0; batch classifier loss: 0.059726; batch adversarial loss: 0.444127\n",
      "epoch 61; iter: 0; batch classifier loss: 0.077210; batch adversarial loss: 0.515692\n",
      "epoch 62; iter: 0; batch classifier loss: 0.124089; batch adversarial loss: 0.408641\n",
      "epoch 63; iter: 0; batch classifier loss: 0.056293; batch adversarial loss: 0.484974\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066060; batch adversarial loss: 0.448322\n",
      "epoch 65; iter: 0; batch classifier loss: 0.080701; batch adversarial loss: 0.455649\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060616; batch adversarial loss: 0.464409\n",
      "epoch 67; iter: 0; batch classifier loss: 0.077262; batch adversarial loss: 0.458607\n",
      "epoch 68; iter: 0; batch classifier loss: 0.066494; batch adversarial loss: 0.539805\n",
      "epoch 69; iter: 0; batch classifier loss: 0.034516; batch adversarial loss: 0.507654\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066593; batch adversarial loss: 0.414892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083623; batch adversarial loss: 0.440991\n",
      "epoch 72; iter: 0; batch classifier loss: 0.057217; batch adversarial loss: 0.524601\n",
      "epoch 73; iter: 0; batch classifier loss: 0.109327; batch adversarial loss: 0.537996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.095401; batch adversarial loss: 0.397876\n",
      "epoch 75; iter: 0; batch classifier loss: 0.098604; batch adversarial loss: 0.456844\n",
      "epoch 76; iter: 0; batch classifier loss: 0.042971; batch adversarial loss: 0.452882\n",
      "epoch 77; iter: 0; batch classifier loss: 0.046685; batch adversarial loss: 0.489164\n",
      "epoch 78; iter: 0; batch classifier loss: 0.070146; batch adversarial loss: 0.415147\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057986; batch adversarial loss: 0.508456\n",
      "epoch 80; iter: 0; batch classifier loss: 0.072477; batch adversarial loss: 0.421195\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081024; batch adversarial loss: 0.476797\n",
      "epoch 82; iter: 0; batch classifier loss: 0.039743; batch adversarial loss: 0.468873\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071692; batch adversarial loss: 0.526180\n",
      "epoch 84; iter: 0; batch classifier loss: 0.036574; batch adversarial loss: 0.399475\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059885; batch adversarial loss: 0.546652\n",
      "epoch 86; iter: 0; batch classifier loss: 0.044509; batch adversarial loss: 0.510859\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066163; batch adversarial loss: 0.419845\n",
      "epoch 88; iter: 0; batch classifier loss: 0.022793; batch adversarial loss: 0.395595\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060687; batch adversarial loss: 0.527531\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073040; batch adversarial loss: 0.390834\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047467; batch adversarial loss: 0.412626\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047283; batch adversarial loss: 0.534968\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047791; batch adversarial loss: 0.511480\n",
      "epoch 94; iter: 0; batch classifier loss: 0.035887; batch adversarial loss: 0.433967\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040098; batch adversarial loss: 0.490736\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036327; batch adversarial loss: 0.458187\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060458; batch adversarial loss: 0.435618\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035897; batch adversarial loss: 0.452004\n",
      "epoch 99; iter: 0; batch classifier loss: 0.082442; batch adversarial loss: 0.479924\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056671; batch adversarial loss: 0.487915\n",
      "epoch 101; iter: 0; batch classifier loss: 0.060075; batch adversarial loss: 0.465990\n",
      "epoch 102; iter: 0; batch classifier loss: 0.028569; batch adversarial loss: 0.489274\n",
      "epoch 103; iter: 0; batch classifier loss: 0.021500; batch adversarial loss: 0.433107\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045244; batch adversarial loss: 0.461508\n",
      "epoch 105; iter: 0; batch classifier loss: 0.067871; batch adversarial loss: 0.377202\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039842; batch adversarial loss: 0.502169\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050385; batch adversarial loss: 0.468257\n",
      "epoch 108; iter: 0; batch classifier loss: 0.034631; batch adversarial loss: 0.490972\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050655; batch adversarial loss: 0.500560\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044144; batch adversarial loss: 0.527349\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033836; batch adversarial loss: 0.418264\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046628; batch adversarial loss: 0.515052\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033252; batch adversarial loss: 0.460273\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060844; batch adversarial loss: 0.453011\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036381; batch adversarial loss: 0.398031\n",
      "epoch 116; iter: 0; batch classifier loss: 0.018171; batch adversarial loss: 0.429109\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027811; batch adversarial loss: 0.359351\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053705; batch adversarial loss: 0.445304\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030580; batch adversarial loss: 0.463198\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035678; batch adversarial loss: 0.581327\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068052; batch adversarial loss: 0.414380\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036294; batch adversarial loss: 0.477890\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039437; batch adversarial loss: 0.430022\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043984; batch adversarial loss: 0.479826\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039402; batch adversarial loss: 0.532055\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031490; batch adversarial loss: 0.449105\n",
      "epoch 127; iter: 0; batch classifier loss: 0.054456; batch adversarial loss: 0.473156\n",
      "epoch 128; iter: 0; batch classifier loss: 0.020920; batch adversarial loss: 0.463378\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047587; batch adversarial loss: 0.432744\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061421; batch adversarial loss: 0.467611\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040756; batch adversarial loss: 0.484618\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029510; batch adversarial loss: 0.481036\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020284; batch adversarial loss: 0.481177\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019420; batch adversarial loss: 0.486183\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044761; batch adversarial loss: 0.481105\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028158; batch adversarial loss: 0.440543\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042368; batch adversarial loss: 0.441220\n",
      "epoch 138; iter: 0; batch classifier loss: 0.059525; batch adversarial loss: 0.492929\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019871; batch adversarial loss: 0.493512\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014717; batch adversarial loss: 0.474578\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030206; batch adversarial loss: 0.450462\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022158; batch adversarial loss: 0.436516\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021427; batch adversarial loss: 0.579933\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018261; batch adversarial loss: 0.510375\n",
      "epoch 145; iter: 0; batch classifier loss: 0.004992; batch adversarial loss: 0.468683\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016154; batch adversarial loss: 0.477229\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044537; batch adversarial loss: 0.482906\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012463; batch adversarial loss: 0.424815\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027439; batch adversarial loss: 0.474547\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015074; batch adversarial loss: 0.561511\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033030; batch adversarial loss: 0.455435\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024503; batch adversarial loss: 0.386842\n",
      "epoch 153; iter: 0; batch classifier loss: 0.007327; batch adversarial loss: 0.401785\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036100; batch adversarial loss: 0.379010\n",
      "epoch 155; iter: 0; batch classifier loss: 0.057587; batch adversarial loss: 0.500838\n",
      "epoch 156; iter: 0; batch classifier loss: 0.006681; batch adversarial loss: 0.458964\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015411; batch adversarial loss: 0.552051\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013856; batch adversarial loss: 0.377310\n",
      "epoch 159; iter: 0; batch classifier loss: 0.072595; batch adversarial loss: 0.457704\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027322; batch adversarial loss: 0.465072\n",
      "epoch 161; iter: 0; batch classifier loss: 0.052990; batch adversarial loss: 0.522855\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024193; batch adversarial loss: 0.429520\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037103; batch adversarial loss: 0.414505\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013679; batch adversarial loss: 0.343240\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016388; batch adversarial loss: 0.544628\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040843; batch adversarial loss: 0.400206\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025365; batch adversarial loss: 0.520929\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033676; batch adversarial loss: 0.433978\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033241; batch adversarial loss: 0.438816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.031387; batch adversarial loss: 0.432581\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025697; batch adversarial loss: 0.465926\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031463; batch adversarial loss: 0.411031\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009441; batch adversarial loss: 0.468857\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030721; batch adversarial loss: 0.395946\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033000; batch adversarial loss: 0.447550\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010384; batch adversarial loss: 0.412748\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025916; batch adversarial loss: 0.489098\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013705; batch adversarial loss: 0.497503\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012351; batch adversarial loss: 0.494703\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028441; batch adversarial loss: 0.491118\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010500; batch adversarial loss: 0.532303\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030466; batch adversarial loss: 0.493727\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028231; batch adversarial loss: 0.371174\n",
      "epoch 184; iter: 0; batch classifier loss: 0.045013; batch adversarial loss: 0.551865\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016226; batch adversarial loss: 0.408208\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009318; batch adversarial loss: 0.473926\n",
      "epoch 187; iter: 0; batch classifier loss: 0.043392; batch adversarial loss: 0.495140\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006239; batch adversarial loss: 0.411108\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009620; batch adversarial loss: 0.330564\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028690; batch adversarial loss: 0.420140\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018829; batch adversarial loss: 0.381954\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009462; batch adversarial loss: 0.495556\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019663; batch adversarial loss: 0.477100\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012184; batch adversarial loss: 0.431576\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026868; batch adversarial loss: 0.402750\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011350; batch adversarial loss: 0.437805\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027095; batch adversarial loss: 0.431367\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016258; batch adversarial loss: 0.405769\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013492; batch adversarial loss: 0.500013\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713825; batch adversarial loss: 0.869351\n",
      "epoch 1; iter: 0; batch classifier loss: 0.411125; batch adversarial loss: 0.873798\n",
      "epoch 2; iter: 0; batch classifier loss: 0.385005; batch adversarial loss: 0.830077\n",
      "epoch 3; iter: 0; batch classifier loss: 0.386794; batch adversarial loss: 0.735483\n",
      "epoch 4; iter: 0; batch classifier loss: 0.269969; batch adversarial loss: 0.722844\n",
      "epoch 5; iter: 0; batch classifier loss: 0.291984; batch adversarial loss: 0.673474\n",
      "epoch 6; iter: 0; batch classifier loss: 0.272272; batch adversarial loss: 0.650336\n",
      "epoch 7; iter: 0; batch classifier loss: 0.294702; batch adversarial loss: 0.639957\n",
      "epoch 8; iter: 0; batch classifier loss: 0.278282; batch adversarial loss: 0.596490\n",
      "epoch 9; iter: 0; batch classifier loss: 0.345530; batch adversarial loss: 0.533131\n",
      "epoch 10; iter: 0; batch classifier loss: 0.295200; batch adversarial loss: 0.549631\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273113; batch adversarial loss: 0.539922\n",
      "epoch 12; iter: 0; batch classifier loss: 0.199507; batch adversarial loss: 0.540802\n",
      "epoch 13; iter: 0; batch classifier loss: 0.201688; batch adversarial loss: 0.546344\n",
      "epoch 14; iter: 0; batch classifier loss: 0.259206; batch adversarial loss: 0.527693\n",
      "epoch 15; iter: 0; batch classifier loss: 0.285491; batch adversarial loss: 0.494813\n",
      "epoch 16; iter: 0; batch classifier loss: 0.279386; batch adversarial loss: 0.440039\n",
      "epoch 17; iter: 0; batch classifier loss: 0.215481; batch adversarial loss: 0.518867\n",
      "epoch 18; iter: 0; batch classifier loss: 0.259953; batch adversarial loss: 0.477689\n",
      "epoch 19; iter: 0; batch classifier loss: 0.234174; batch adversarial loss: 0.495885\n",
      "epoch 20; iter: 0; batch classifier loss: 0.292642; batch adversarial loss: 0.461094\n",
      "epoch 21; iter: 0; batch classifier loss: 0.302097; batch adversarial loss: 0.377729\n",
      "epoch 22; iter: 0; batch classifier loss: 0.236160; batch adversarial loss: 0.406874\n",
      "epoch 23; iter: 0; batch classifier loss: 0.234950; batch adversarial loss: 0.469732\n",
      "epoch 24; iter: 0; batch classifier loss: 0.206507; batch adversarial loss: 0.403123\n",
      "epoch 25; iter: 0; batch classifier loss: 0.222579; batch adversarial loss: 0.425979\n",
      "epoch 26; iter: 0; batch classifier loss: 0.201759; batch adversarial loss: 0.443693\n",
      "epoch 27; iter: 0; batch classifier loss: 0.187952; batch adversarial loss: 0.379521\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179080; batch adversarial loss: 0.422245\n",
      "epoch 29; iter: 0; batch classifier loss: 0.163486; batch adversarial loss: 0.434508\n",
      "epoch 30; iter: 0; batch classifier loss: 0.186539; batch adversarial loss: 0.404287\n",
      "epoch 31; iter: 0; batch classifier loss: 0.161707; batch adversarial loss: 0.381623\n",
      "epoch 32; iter: 0; batch classifier loss: 0.176271; batch adversarial loss: 0.357283\n",
      "epoch 33; iter: 0; batch classifier loss: 0.209575; batch adversarial loss: 0.406480\n",
      "epoch 34; iter: 0; batch classifier loss: 0.179060; batch adversarial loss: 0.403710\n",
      "epoch 35; iter: 0; batch classifier loss: 0.119342; batch adversarial loss: 0.369814\n",
      "epoch 36; iter: 0; batch classifier loss: 0.157101; batch adversarial loss: 0.411305\n",
      "epoch 37; iter: 0; batch classifier loss: 0.177992; batch adversarial loss: 0.473448\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126501; batch adversarial loss: 0.395953\n",
      "epoch 39; iter: 0; batch classifier loss: 0.169928; batch adversarial loss: 0.424446\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124257; batch adversarial loss: 0.533334\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123733; batch adversarial loss: 0.406260\n",
      "epoch 42; iter: 0; batch classifier loss: 0.133416; batch adversarial loss: 0.444581\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110168; batch adversarial loss: 0.422865\n",
      "epoch 44; iter: 0; batch classifier loss: 0.161680; batch adversarial loss: 0.452824\n",
      "epoch 45; iter: 0; batch classifier loss: 0.073680; batch adversarial loss: 0.411087\n",
      "epoch 46; iter: 0; batch classifier loss: 0.110764; batch adversarial loss: 0.455579\n",
      "epoch 47; iter: 0; batch classifier loss: 0.092999; batch adversarial loss: 0.353275\n",
      "epoch 48; iter: 0; batch classifier loss: 0.120862; batch adversarial loss: 0.430275\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119388; batch adversarial loss: 0.442545\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119518; batch adversarial loss: 0.440292\n",
      "epoch 51; iter: 0; batch classifier loss: 0.116648; batch adversarial loss: 0.406452\n",
      "epoch 52; iter: 0; batch classifier loss: 0.074575; batch adversarial loss: 0.375035\n",
      "epoch 53; iter: 0; batch classifier loss: 0.082537; batch adversarial loss: 0.432365\n",
      "epoch 54; iter: 0; batch classifier loss: 0.062025; batch adversarial loss: 0.525048\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101301; batch adversarial loss: 0.444741\n",
      "epoch 56; iter: 0; batch classifier loss: 0.089712; batch adversarial loss: 0.358238\n",
      "epoch 57; iter: 0; batch classifier loss: 0.101470; batch adversarial loss: 0.440080\n",
      "epoch 58; iter: 0; batch classifier loss: 0.106350; batch adversarial loss: 0.445383\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083001; batch adversarial loss: 0.500947\n",
      "epoch 60; iter: 0; batch classifier loss: 0.096891; batch adversarial loss: 0.468184\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071146; batch adversarial loss: 0.412492\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069039; batch adversarial loss: 0.406126\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097896; batch adversarial loss: 0.433298\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068079; batch adversarial loss: 0.412359\n",
      "epoch 65; iter: 0; batch classifier loss: 0.085910; batch adversarial loss: 0.387097\n",
      "epoch 66; iter: 0; batch classifier loss: 0.127432; batch adversarial loss: 0.571207\n",
      "epoch 67; iter: 0; batch classifier loss: 0.103159; batch adversarial loss: 0.386385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.080737; batch adversarial loss: 0.464223\n",
      "epoch 69; iter: 0; batch classifier loss: 0.107749; batch adversarial loss: 0.430961\n",
      "epoch 70; iter: 0; batch classifier loss: 0.084817; batch adversarial loss: 0.462843\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084514; batch adversarial loss: 0.432719\n",
      "epoch 72; iter: 0; batch classifier loss: 0.099802; batch adversarial loss: 0.468419\n",
      "epoch 73; iter: 0; batch classifier loss: 0.056983; batch adversarial loss: 0.447331\n",
      "epoch 74; iter: 0; batch classifier loss: 0.080760; batch adversarial loss: 0.359557\n",
      "epoch 75; iter: 0; batch classifier loss: 0.082264; batch adversarial loss: 0.439844\n",
      "epoch 76; iter: 0; batch classifier loss: 0.061237; batch adversarial loss: 0.469571\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069401; batch adversarial loss: 0.356763\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073476; batch adversarial loss: 0.469856\n",
      "epoch 79; iter: 0; batch classifier loss: 0.098292; batch adversarial loss: 0.537330\n",
      "epoch 80; iter: 0; batch classifier loss: 0.107698; batch adversarial loss: 0.416101\n",
      "epoch 81; iter: 0; batch classifier loss: 0.094054; batch adversarial loss: 0.416050\n",
      "epoch 82; iter: 0; batch classifier loss: 0.092583; batch adversarial loss: 0.429336\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079004; batch adversarial loss: 0.395757\n",
      "epoch 84; iter: 0; batch classifier loss: 0.118280; batch adversarial loss: 0.503184\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088497; batch adversarial loss: 0.502327\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068818; batch adversarial loss: 0.380159\n",
      "epoch 87; iter: 0; batch classifier loss: 0.069066; batch adversarial loss: 0.448735\n",
      "epoch 88; iter: 0; batch classifier loss: 0.090802; batch adversarial loss: 0.454833\n",
      "epoch 89; iter: 0; batch classifier loss: 0.103600; batch adversarial loss: 0.372986\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050392; batch adversarial loss: 0.458217\n",
      "epoch 91; iter: 0; batch classifier loss: 0.065050; batch adversarial loss: 0.362525\n",
      "epoch 92; iter: 0; batch classifier loss: 0.118577; batch adversarial loss: 0.360142\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053572; batch adversarial loss: 0.370177\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048803; batch adversarial loss: 0.480871\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065074; batch adversarial loss: 0.444729\n",
      "epoch 96; iter: 0; batch classifier loss: 0.076642; batch adversarial loss: 0.395056\n",
      "epoch 97; iter: 0; batch classifier loss: 0.090218; batch adversarial loss: 0.465497\n",
      "epoch 98; iter: 0; batch classifier loss: 0.065528; batch adversarial loss: 0.466019\n",
      "epoch 99; iter: 0; batch classifier loss: 0.060562; batch adversarial loss: 0.336132\n",
      "epoch 100; iter: 0; batch classifier loss: 0.081873; batch adversarial loss: 0.570394\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068500; batch adversarial loss: 0.445376\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055778; batch adversarial loss: 0.424545\n",
      "epoch 103; iter: 0; batch classifier loss: 0.080933; batch adversarial loss: 0.408154\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033357; batch adversarial loss: 0.442858\n",
      "epoch 105; iter: 0; batch classifier loss: 0.088650; batch adversarial loss: 0.429221\n",
      "epoch 106; iter: 0; batch classifier loss: 0.106977; batch adversarial loss: 0.509864\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051837; batch adversarial loss: 0.442773\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041317; batch adversarial loss: 0.454703\n",
      "epoch 109; iter: 0; batch classifier loss: 0.087329; batch adversarial loss: 0.417816\n",
      "epoch 110; iter: 0; batch classifier loss: 0.086246; batch adversarial loss: 0.390951\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049143; batch adversarial loss: 0.355566\n",
      "epoch 112; iter: 0; batch classifier loss: 0.067223; batch adversarial loss: 0.421951\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046940; batch adversarial loss: 0.370127\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050020; batch adversarial loss: 0.489386\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048300; batch adversarial loss: 0.429339\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030574; batch adversarial loss: 0.598586\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060582; batch adversarial loss: 0.381697\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035304; batch adversarial loss: 0.465437\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042213; batch adversarial loss: 0.428747\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036627; batch adversarial loss: 0.454693\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050630; batch adversarial loss: 0.363543\n",
      "epoch 122; iter: 0; batch classifier loss: 0.081245; batch adversarial loss: 0.466283\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034992; batch adversarial loss: 0.505710\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057338; batch adversarial loss: 0.567375\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035291; batch adversarial loss: 0.498123\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055100; batch adversarial loss: 0.367981\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040250; batch adversarial loss: 0.506467\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033849; batch adversarial loss: 0.396689\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031275; batch adversarial loss: 0.416845\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039289; batch adversarial loss: 0.472766\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041485; batch adversarial loss: 0.524535\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021741; batch adversarial loss: 0.565014\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020275; batch adversarial loss: 0.478249\n",
      "epoch 134; iter: 0; batch classifier loss: 0.014138; batch adversarial loss: 0.471765\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028899; batch adversarial loss: 0.428253\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026458; batch adversarial loss: 0.549474\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037276; batch adversarial loss: 0.478124\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016476; batch adversarial loss: 0.536346\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026587; batch adversarial loss: 0.317223\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019181; batch adversarial loss: 0.427850\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038017; batch adversarial loss: 0.490816\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040078; batch adversarial loss: 0.471267\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039424; batch adversarial loss: 0.428198\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018446; batch adversarial loss: 0.389318\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027693; batch adversarial loss: 0.415646\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026900; batch adversarial loss: 0.492435\n",
      "epoch 147; iter: 0; batch classifier loss: 0.068359; batch adversarial loss: 0.470791\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020539; batch adversarial loss: 0.388859\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025654; batch adversarial loss: 0.455745\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012928; batch adversarial loss: 0.451334\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031304; batch adversarial loss: 0.538104\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015996; batch adversarial loss: 0.436456\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019428; batch adversarial loss: 0.517757\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022376; batch adversarial loss: 0.514293\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019809; batch adversarial loss: 0.426675\n",
      "epoch 156; iter: 0; batch classifier loss: 0.007394; batch adversarial loss: 0.433564\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026292; batch adversarial loss: 0.553017\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013139; batch adversarial loss: 0.389317\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032149; batch adversarial loss: 0.459188\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023780; batch adversarial loss: 0.558534\n",
      "epoch 161; iter: 0; batch classifier loss: 0.056000; batch adversarial loss: 0.584613\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015812; batch adversarial loss: 0.466359\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022259; batch adversarial loss: 0.449076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.024875; batch adversarial loss: 0.453559\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038646; batch adversarial loss: 0.463805\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019296; batch adversarial loss: 0.431882\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031810; batch adversarial loss: 0.507808\n",
      "epoch 168; iter: 0; batch classifier loss: 0.043223; batch adversarial loss: 0.499148\n",
      "epoch 169; iter: 0; batch classifier loss: 0.064954; batch adversarial loss: 0.562197\n",
      "epoch 170; iter: 0; batch classifier loss: 0.052103; batch adversarial loss: 0.474368\n",
      "epoch 171; iter: 0; batch classifier loss: 0.100290; batch adversarial loss: 0.534475\n",
      "epoch 172; iter: 0; batch classifier loss: 0.078295; batch adversarial loss: 0.590777\n",
      "epoch 173; iter: 0; batch classifier loss: 0.095104; batch adversarial loss: 0.655086\n",
      "epoch 174; iter: 0; batch classifier loss: 0.092304; batch adversarial loss: 0.598803\n",
      "epoch 175; iter: 0; batch classifier loss: 0.104685; batch adversarial loss: 0.683519\n",
      "epoch 176; iter: 0; batch classifier loss: 0.096623; batch adversarial loss: 0.507699\n",
      "epoch 177; iter: 0; batch classifier loss: 0.129545; batch adversarial loss: 0.777157\n",
      "epoch 178; iter: 0; batch classifier loss: 0.134978; batch adversarial loss: 0.656126\n",
      "epoch 179; iter: 0; batch classifier loss: 0.101431; batch adversarial loss: 0.614242\n",
      "epoch 180; iter: 0; batch classifier loss: 0.104672; batch adversarial loss: 0.551857\n",
      "epoch 181; iter: 0; batch classifier loss: 0.167494; batch adversarial loss: 0.681414\n",
      "epoch 182; iter: 0; batch classifier loss: 0.216481; batch adversarial loss: 0.775249\n",
      "epoch 183; iter: 0; batch classifier loss: 0.077868; batch adversarial loss: 0.537765\n",
      "epoch 184; iter: 0; batch classifier loss: 0.165367; batch adversarial loss: 0.590122\n",
      "epoch 185; iter: 0; batch classifier loss: 0.119587; batch adversarial loss: 0.549985\n",
      "epoch 186; iter: 0; batch classifier loss: 0.140786; batch adversarial loss: 0.586421\n",
      "epoch 187; iter: 0; batch classifier loss: 0.082251; batch adversarial loss: 0.454759\n",
      "epoch 188; iter: 0; batch classifier loss: 0.121963; batch adversarial loss: 0.621927\n",
      "epoch 189; iter: 0; batch classifier loss: 0.149409; batch adversarial loss: 0.580102\n",
      "epoch 190; iter: 0; batch classifier loss: 0.237509; batch adversarial loss: 0.745454\n",
      "epoch 191; iter: 0; batch classifier loss: 0.099789; batch adversarial loss: 0.581381\n",
      "epoch 192; iter: 0; batch classifier loss: 0.174924; batch adversarial loss: 0.670717\n",
      "epoch 193; iter: 0; batch classifier loss: 0.159478; batch adversarial loss: 0.627903\n",
      "epoch 194; iter: 0; batch classifier loss: 0.137129; batch adversarial loss: 0.630314\n",
      "epoch 195; iter: 0; batch classifier loss: 0.178986; batch adversarial loss: 0.692506\n",
      "epoch 196; iter: 0; batch classifier loss: 0.108461; batch adversarial loss: 0.513067\n",
      "epoch 197; iter: 0; batch classifier loss: 0.212289; batch adversarial loss: 0.690640\n",
      "epoch 198; iter: 0; batch classifier loss: 0.125245; batch adversarial loss: 0.610006\n",
      "epoch 199; iter: 0; batch classifier loss: 0.116632; batch adversarial loss: 0.485148\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701252; batch adversarial loss: 0.671035\n",
      "epoch 1; iter: 0; batch classifier loss: 0.465779; batch adversarial loss: 0.700282\n",
      "epoch 2; iter: 0; batch classifier loss: 0.466180; batch adversarial loss: 0.668313\n",
      "epoch 3; iter: 0; batch classifier loss: 0.351533; batch adversarial loss: 0.630183\n",
      "epoch 4; iter: 0; batch classifier loss: 0.363361; batch adversarial loss: 0.643583\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313590; batch adversarial loss: 0.592275\n",
      "epoch 6; iter: 0; batch classifier loss: 0.362402; batch adversarial loss: 0.544106\n",
      "epoch 7; iter: 0; batch classifier loss: 0.298047; batch adversarial loss: 0.532201\n",
      "epoch 8; iter: 0; batch classifier loss: 0.266163; batch adversarial loss: 0.486510\n",
      "epoch 9; iter: 0; batch classifier loss: 0.232087; batch adversarial loss: 0.496962\n",
      "epoch 10; iter: 0; batch classifier loss: 0.247462; batch adversarial loss: 0.426346\n",
      "epoch 11; iter: 0; batch classifier loss: 0.259321; batch adversarial loss: 0.482693\n",
      "epoch 12; iter: 0; batch classifier loss: 0.235119; batch adversarial loss: 0.511548\n",
      "epoch 13; iter: 0; batch classifier loss: 0.186182; batch adversarial loss: 0.436142\n",
      "epoch 14; iter: 0; batch classifier loss: 0.223104; batch adversarial loss: 0.487322\n",
      "epoch 15; iter: 0; batch classifier loss: 0.169086; batch adversarial loss: 0.493098\n",
      "epoch 16; iter: 0; batch classifier loss: 0.163676; batch adversarial loss: 0.401857\n",
      "epoch 17; iter: 0; batch classifier loss: 0.181637; batch adversarial loss: 0.440307\n",
      "epoch 18; iter: 0; batch classifier loss: 0.195671; batch adversarial loss: 0.448715\n",
      "epoch 19; iter: 0; batch classifier loss: 0.152578; batch adversarial loss: 0.390835\n",
      "epoch 20; iter: 0; batch classifier loss: 0.139667; batch adversarial loss: 0.411805\n",
      "epoch 21; iter: 0; batch classifier loss: 0.159561; batch adversarial loss: 0.434817\n",
      "epoch 22; iter: 0; batch classifier loss: 0.108613; batch adversarial loss: 0.462081\n",
      "epoch 23; iter: 0; batch classifier loss: 0.137318; batch adversarial loss: 0.376115\n",
      "epoch 24; iter: 0; batch classifier loss: 0.117522; batch adversarial loss: 0.507663\n",
      "epoch 25; iter: 0; batch classifier loss: 0.104972; batch adversarial loss: 0.364900\n",
      "epoch 26; iter: 0; batch classifier loss: 0.112375; batch adversarial loss: 0.351554\n",
      "epoch 27; iter: 0; batch classifier loss: 0.115106; batch adversarial loss: 0.427028\n",
      "epoch 28; iter: 0; batch classifier loss: 0.162644; batch adversarial loss: 0.435557\n",
      "epoch 29; iter: 0; batch classifier loss: 0.190036; batch adversarial loss: 0.380051\n",
      "epoch 30; iter: 0; batch classifier loss: 0.124037; batch adversarial loss: 0.403249\n",
      "epoch 31; iter: 0; batch classifier loss: 0.125024; batch adversarial loss: 0.423256\n",
      "epoch 32; iter: 0; batch classifier loss: 0.114575; batch adversarial loss: 0.476513\n",
      "epoch 33; iter: 0; batch classifier loss: 0.112858; batch adversarial loss: 0.365449\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142903; batch adversarial loss: 0.481876\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118827; batch adversarial loss: 0.356334\n",
      "epoch 36; iter: 0; batch classifier loss: 0.153612; batch adversarial loss: 0.528239\n",
      "epoch 37; iter: 0; batch classifier loss: 0.070240; batch adversarial loss: 0.397454\n",
      "epoch 38; iter: 0; batch classifier loss: 0.147791; batch adversarial loss: 0.353929\n",
      "epoch 39; iter: 0; batch classifier loss: 0.098452; batch adversarial loss: 0.473580\n",
      "epoch 40; iter: 0; batch classifier loss: 0.120716; batch adversarial loss: 0.320968\n",
      "epoch 41; iter: 0; batch classifier loss: 0.082320; batch adversarial loss: 0.363944\n",
      "epoch 42; iter: 0; batch classifier loss: 0.126969; batch adversarial loss: 0.420121\n",
      "epoch 43; iter: 0; batch classifier loss: 0.121876; batch adversarial loss: 0.397436\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106959; batch adversarial loss: 0.449055\n",
      "epoch 45; iter: 0; batch classifier loss: 0.090474; batch adversarial loss: 0.394033\n",
      "epoch 46; iter: 0; batch classifier loss: 0.069489; batch adversarial loss: 0.463444\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096821; batch adversarial loss: 0.392911\n",
      "epoch 48; iter: 0; batch classifier loss: 0.074209; batch adversarial loss: 0.418563\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096190; batch adversarial loss: 0.456953\n",
      "epoch 50; iter: 0; batch classifier loss: 0.076576; batch adversarial loss: 0.413209\n",
      "epoch 51; iter: 0; batch classifier loss: 0.091159; batch adversarial loss: 0.419056\n",
      "epoch 52; iter: 0; batch classifier loss: 0.086883; batch adversarial loss: 0.386913\n",
      "epoch 53; iter: 0; batch classifier loss: 0.047536; batch adversarial loss: 0.443737\n",
      "epoch 54; iter: 0; batch classifier loss: 0.073249; batch adversarial loss: 0.381964\n",
      "epoch 55; iter: 0; batch classifier loss: 0.059956; batch adversarial loss: 0.344354\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083568; batch adversarial loss: 0.430780\n",
      "epoch 57; iter: 0; batch classifier loss: 0.047354; batch adversarial loss: 0.395585\n",
      "epoch 58; iter: 0; batch classifier loss: 0.095383; batch adversarial loss: 0.398556\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081586; batch adversarial loss: 0.469326\n",
      "epoch 60; iter: 0; batch classifier loss: 0.082258; batch adversarial loss: 0.458585\n",
      "epoch 61; iter: 0; batch classifier loss: 0.077577; batch adversarial loss: 0.479807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.074662; batch adversarial loss: 0.365752\n",
      "epoch 63; iter: 0; batch classifier loss: 0.063089; batch adversarial loss: 0.443374\n",
      "epoch 64; iter: 0; batch classifier loss: 0.055793; batch adversarial loss: 0.374889\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073845; batch adversarial loss: 0.429010\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070852; batch adversarial loss: 0.448459\n",
      "epoch 67; iter: 0; batch classifier loss: 0.072845; batch adversarial loss: 0.495951\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060144; batch adversarial loss: 0.328075\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061775; batch adversarial loss: 0.369757\n",
      "epoch 70; iter: 0; batch classifier loss: 0.036263; batch adversarial loss: 0.430006\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073378; batch adversarial loss: 0.445000\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077770; batch adversarial loss: 0.379771\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067036; batch adversarial loss: 0.281599\n",
      "epoch 74; iter: 0; batch classifier loss: 0.061225; batch adversarial loss: 0.332506\n",
      "epoch 75; iter: 0; batch classifier loss: 0.051492; batch adversarial loss: 0.426099\n",
      "epoch 76; iter: 0; batch classifier loss: 0.051388; batch adversarial loss: 0.482965\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050572; batch adversarial loss: 0.408035\n",
      "epoch 78; iter: 0; batch classifier loss: 0.057844; batch adversarial loss: 0.434993\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064380; batch adversarial loss: 0.450144\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043933; batch adversarial loss: 0.414476\n",
      "epoch 81; iter: 0; batch classifier loss: 0.053885; batch adversarial loss: 0.321692\n",
      "epoch 82; iter: 0; batch classifier loss: 0.070934; batch adversarial loss: 0.375801\n",
      "epoch 83; iter: 0; batch classifier loss: 0.032977; batch adversarial loss: 0.329014\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060828; batch adversarial loss: 0.468753\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055580; batch adversarial loss: 0.419503\n",
      "epoch 86; iter: 0; batch classifier loss: 0.039578; batch adversarial loss: 0.407535\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057448; batch adversarial loss: 0.469168\n",
      "epoch 88; iter: 0; batch classifier loss: 0.032164; batch adversarial loss: 0.406615\n",
      "epoch 89; iter: 0; batch classifier loss: 0.038596; batch adversarial loss: 0.367356\n",
      "epoch 90; iter: 0; batch classifier loss: 0.041500; batch adversarial loss: 0.482787\n",
      "epoch 91; iter: 0; batch classifier loss: 0.042141; batch adversarial loss: 0.437324\n",
      "epoch 92; iter: 0; batch classifier loss: 0.038938; batch adversarial loss: 0.430500\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062324; batch adversarial loss: 0.411792\n",
      "epoch 94; iter: 0; batch classifier loss: 0.030848; batch adversarial loss: 0.511502\n",
      "epoch 95; iter: 0; batch classifier loss: 0.033206; batch adversarial loss: 0.420436\n",
      "epoch 96; iter: 0; batch classifier loss: 0.020992; batch adversarial loss: 0.520787\n",
      "epoch 97; iter: 0; batch classifier loss: 0.035448; batch adversarial loss: 0.429334\n",
      "epoch 98; iter: 0; batch classifier loss: 0.040746; batch adversarial loss: 0.472371\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037106; batch adversarial loss: 0.436226\n",
      "epoch 100; iter: 0; batch classifier loss: 0.041768; batch adversarial loss: 0.367825\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043538; batch adversarial loss: 0.423810\n",
      "epoch 102; iter: 0; batch classifier loss: 0.030197; batch adversarial loss: 0.374504\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035758; batch adversarial loss: 0.515604\n",
      "epoch 104; iter: 0; batch classifier loss: 0.028041; batch adversarial loss: 0.603922\n",
      "epoch 105; iter: 0; batch classifier loss: 0.021777; batch adversarial loss: 0.463813\n",
      "epoch 106; iter: 0; batch classifier loss: 0.026272; batch adversarial loss: 0.404655\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032372; batch adversarial loss: 0.468421\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053374; batch adversarial loss: 0.394673\n",
      "epoch 109; iter: 0; batch classifier loss: 0.018028; batch adversarial loss: 0.512796\n",
      "epoch 110; iter: 0; batch classifier loss: 0.012584; batch adversarial loss: 0.451081\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032675; batch adversarial loss: 0.441833\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025596; batch adversarial loss: 0.347173\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021596; batch adversarial loss: 0.382284\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035874; batch adversarial loss: 0.419114\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034117; batch adversarial loss: 0.408562\n",
      "epoch 116; iter: 0; batch classifier loss: 0.019397; batch adversarial loss: 0.354290\n",
      "epoch 117; iter: 0; batch classifier loss: 0.017393; batch adversarial loss: 0.410542\n",
      "epoch 118; iter: 0; batch classifier loss: 0.012206; batch adversarial loss: 0.424618\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037574; batch adversarial loss: 0.513613\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039257; batch adversarial loss: 0.473131\n",
      "epoch 121; iter: 0; batch classifier loss: 0.019446; batch adversarial loss: 0.499672\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029793; batch adversarial loss: 0.602635\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026352; batch adversarial loss: 0.542124\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035842; batch adversarial loss: 0.380625\n",
      "epoch 125; iter: 0; batch classifier loss: 0.016897; batch adversarial loss: 0.542886\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043226; batch adversarial loss: 0.439760\n",
      "epoch 127; iter: 0; batch classifier loss: 0.016954; batch adversarial loss: 0.452787\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041561; batch adversarial loss: 0.473521\n",
      "epoch 129; iter: 0; batch classifier loss: 0.076472; batch adversarial loss: 0.489342\n",
      "epoch 130; iter: 0; batch classifier loss: 0.077977; batch adversarial loss: 0.581895\n",
      "epoch 131; iter: 0; batch classifier loss: 0.087850; batch adversarial loss: 0.500934\n",
      "epoch 132; iter: 0; batch classifier loss: 0.085809; batch adversarial loss: 0.491645\n",
      "epoch 133; iter: 0; batch classifier loss: 0.120888; batch adversarial loss: 0.585475\n",
      "epoch 134; iter: 0; batch classifier loss: 0.092192; batch adversarial loss: 0.476536\n",
      "epoch 135; iter: 0; batch classifier loss: 0.124048; batch adversarial loss: 0.814497\n",
      "epoch 136; iter: 0; batch classifier loss: 0.107543; batch adversarial loss: 0.575126\n",
      "epoch 137; iter: 0; batch classifier loss: 0.208664; batch adversarial loss: 0.732809\n",
      "epoch 138; iter: 0; batch classifier loss: 0.089249; batch adversarial loss: 0.609585\n",
      "epoch 139; iter: 0; batch classifier loss: 0.058316; batch adversarial loss: 0.388678\n",
      "epoch 140; iter: 0; batch classifier loss: 0.218545; batch adversarial loss: 0.740216\n",
      "epoch 141; iter: 0; batch classifier loss: 0.124090; batch adversarial loss: 0.586112\n",
      "epoch 142; iter: 0; batch classifier loss: 0.267917; batch adversarial loss: 0.869263\n",
      "epoch 143; iter: 0; batch classifier loss: 0.141647; batch adversarial loss: 0.645335\n",
      "epoch 144; iter: 0; batch classifier loss: 0.149890; batch adversarial loss: 0.594621\n",
      "epoch 145; iter: 0; batch classifier loss: 0.108613; batch adversarial loss: 0.559636\n",
      "epoch 146; iter: 0; batch classifier loss: 0.156275; batch adversarial loss: 0.504648\n",
      "epoch 147; iter: 0; batch classifier loss: 0.162262; batch adversarial loss: 0.728852\n",
      "epoch 148; iter: 0; batch classifier loss: 0.130892; batch adversarial loss: 0.548447\n",
      "epoch 149; iter: 0; batch classifier loss: 0.155923; batch adversarial loss: 0.724012\n",
      "epoch 150; iter: 0; batch classifier loss: 0.125260; batch adversarial loss: 0.561990\n",
      "epoch 151; iter: 0; batch classifier loss: 0.176528; batch adversarial loss: 0.633670\n",
      "epoch 152; iter: 0; batch classifier loss: 0.130775; batch adversarial loss: 0.508006\n",
      "epoch 153; iter: 0; batch classifier loss: 0.122384; batch adversarial loss: 0.566358\n",
      "epoch 154; iter: 0; batch classifier loss: 0.167197; batch adversarial loss: 0.572959\n",
      "epoch 155; iter: 0; batch classifier loss: 0.106201; batch adversarial loss: 0.510190\n",
      "epoch 156; iter: 0; batch classifier loss: 0.133409; batch adversarial loss: 0.485276\n",
      "epoch 157; iter: 0; batch classifier loss: 0.168147; batch adversarial loss: 0.621137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.129763; batch adversarial loss: 0.576197\n",
      "epoch 159; iter: 0; batch classifier loss: 0.099343; batch adversarial loss: 0.389982\n",
      "epoch 160; iter: 0; batch classifier loss: 0.147703; batch adversarial loss: 0.602751\n",
      "epoch 161; iter: 0; batch classifier loss: 0.071496; batch adversarial loss: 0.476437\n",
      "epoch 162; iter: 0; batch classifier loss: 0.141527; batch adversarial loss: 0.480840\n",
      "epoch 163; iter: 0; batch classifier loss: 0.133920; batch adversarial loss: 0.476910\n",
      "epoch 164; iter: 0; batch classifier loss: 0.143551; batch adversarial loss: 0.617528\n",
      "epoch 165; iter: 0; batch classifier loss: 0.141449; batch adversarial loss: 0.426348\n",
      "epoch 166; iter: 0; batch classifier loss: 0.149142; batch adversarial loss: 0.578629\n",
      "epoch 167; iter: 0; batch classifier loss: 0.092925; batch adversarial loss: 0.489637\n",
      "epoch 168; iter: 0; batch classifier loss: 0.129511; batch adversarial loss: 0.600230\n",
      "epoch 169; iter: 0; batch classifier loss: 0.125268; batch adversarial loss: 0.455627\n",
      "epoch 170; iter: 0; batch classifier loss: 0.087344; batch adversarial loss: 0.479254\n",
      "epoch 171; iter: 0; batch classifier loss: 0.070553; batch adversarial loss: 0.445773\n",
      "epoch 172; iter: 0; batch classifier loss: 0.078630; batch adversarial loss: 0.430498\n",
      "epoch 173; iter: 0; batch classifier loss: 0.132388; batch adversarial loss: 0.467996\n",
      "epoch 174; iter: 0; batch classifier loss: 0.150845; batch adversarial loss: 0.492232\n",
      "epoch 175; iter: 0; batch classifier loss: 0.105512; batch adversarial loss: 0.509570\n",
      "epoch 176; iter: 0; batch classifier loss: 0.126001; batch adversarial loss: 0.459928\n",
      "epoch 177; iter: 0; batch classifier loss: 0.114803; batch adversarial loss: 0.433633\n",
      "epoch 178; iter: 0; batch classifier loss: 0.142624; batch adversarial loss: 0.420007\n",
      "epoch 179; iter: 0; batch classifier loss: 0.095123; batch adversarial loss: 0.339459\n",
      "epoch 180; iter: 0; batch classifier loss: 0.055139; batch adversarial loss: 0.314035\n",
      "epoch 181; iter: 0; batch classifier loss: 0.074639; batch adversarial loss: 0.399260\n",
      "epoch 182; iter: 0; batch classifier loss: 0.044874; batch adversarial loss: 0.540252\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023253; batch adversarial loss: 0.352164\n",
      "epoch 184; iter: 0; batch classifier loss: 0.070959; batch adversarial loss: 0.450908\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031026; batch adversarial loss: 0.436158\n",
      "epoch 186; iter: 0; batch classifier loss: 0.050029; batch adversarial loss: 0.339791\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039868; batch adversarial loss: 0.402961\n",
      "epoch 188; iter: 0; batch classifier loss: 0.062159; batch adversarial loss: 0.476352\n",
      "epoch 189; iter: 0; batch classifier loss: 0.040766; batch adversarial loss: 0.425699\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028549; batch adversarial loss: 0.425964\n",
      "epoch 191; iter: 0; batch classifier loss: 0.073749; batch adversarial loss: 0.490490\n",
      "epoch 192; iter: 0; batch classifier loss: 0.112454; batch adversarial loss: 0.417713\n",
      "epoch 193; iter: 0; batch classifier loss: 0.068409; batch adversarial loss: 0.436802\n",
      "epoch 194; iter: 0; batch classifier loss: 0.066817; batch adversarial loss: 0.475194\n",
      "epoch 195; iter: 0; batch classifier loss: 0.043932; batch adversarial loss: 0.407222\n",
      "epoch 196; iter: 0; batch classifier loss: 0.071817; batch adversarial loss: 0.480802\n",
      "epoch 197; iter: 0; batch classifier loss: 0.065678; batch adversarial loss: 0.483952\n",
      "epoch 198; iter: 0; batch classifier loss: 0.094439; batch adversarial loss: 0.390584\n",
      "epoch 199; iter: 0; batch classifier loss: 0.038811; batch adversarial loss: 0.481670\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685487; batch adversarial loss: 0.844114\n",
      "epoch 1; iter: 0; batch classifier loss: 0.569720; batch adversarial loss: 0.887576\n",
      "epoch 2; iter: 0; batch classifier loss: 0.482929; batch adversarial loss: 0.845412\n",
      "epoch 3; iter: 0; batch classifier loss: 0.849713; batch adversarial loss: 0.816312\n",
      "epoch 4; iter: 0; batch classifier loss: 0.830183; batch adversarial loss: 0.730137\n",
      "epoch 5; iter: 0; batch classifier loss: 0.911884; batch adversarial loss: 0.655823\n",
      "epoch 6; iter: 0; batch classifier loss: 0.782486; batch adversarial loss: 0.598032\n",
      "epoch 7; iter: 0; batch classifier loss: 0.472107; batch adversarial loss: 0.564103\n",
      "epoch 8; iter: 0; batch classifier loss: 0.390895; batch adversarial loss: 0.571543\n",
      "epoch 9; iter: 0; batch classifier loss: 0.407847; batch adversarial loss: 0.541630\n",
      "epoch 10; iter: 0; batch classifier loss: 0.373893; batch adversarial loss: 0.528163\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273763; batch adversarial loss: 0.508534\n",
      "epoch 12; iter: 0; batch classifier loss: 0.356264; batch adversarial loss: 0.529934\n",
      "epoch 13; iter: 0; batch classifier loss: 0.317322; batch adversarial loss: 0.504590\n",
      "epoch 14; iter: 0; batch classifier loss: 0.333840; batch adversarial loss: 0.532060\n",
      "epoch 15; iter: 0; batch classifier loss: 0.385653; batch adversarial loss: 0.480770\n",
      "epoch 16; iter: 0; batch classifier loss: 0.323132; batch adversarial loss: 0.502904\n",
      "epoch 17; iter: 0; batch classifier loss: 0.276170; batch adversarial loss: 0.505376\n",
      "epoch 18; iter: 0; batch classifier loss: 0.339804; batch adversarial loss: 0.514932\n",
      "epoch 19; iter: 0; batch classifier loss: 0.301773; batch adversarial loss: 0.511344\n",
      "epoch 20; iter: 0; batch classifier loss: 0.324562; batch adversarial loss: 0.448718\n",
      "epoch 21; iter: 0; batch classifier loss: 0.315681; batch adversarial loss: 0.459383\n",
      "epoch 22; iter: 0; batch classifier loss: 0.319194; batch adversarial loss: 0.479258\n",
      "epoch 23; iter: 0; batch classifier loss: 0.243202; batch adversarial loss: 0.453662\n",
      "epoch 24; iter: 0; batch classifier loss: 0.370029; batch adversarial loss: 0.443566\n",
      "epoch 25; iter: 0; batch classifier loss: 0.308581; batch adversarial loss: 0.490915\n",
      "epoch 26; iter: 0; batch classifier loss: 0.286123; batch adversarial loss: 0.418180\n",
      "epoch 27; iter: 0; batch classifier loss: 0.303664; batch adversarial loss: 0.482898\n",
      "epoch 28; iter: 0; batch classifier loss: 0.273130; batch adversarial loss: 0.456515\n",
      "epoch 29; iter: 0; batch classifier loss: 0.207859; batch adversarial loss: 0.505387\n",
      "epoch 30; iter: 0; batch classifier loss: 0.246458; batch adversarial loss: 0.499733\n",
      "epoch 31; iter: 0; batch classifier loss: 0.198346; batch adversarial loss: 0.537245\n",
      "epoch 32; iter: 0; batch classifier loss: 0.214502; batch adversarial loss: 0.402002\n",
      "epoch 33; iter: 0; batch classifier loss: 0.241869; batch adversarial loss: 0.499366\n",
      "epoch 34; iter: 0; batch classifier loss: 0.231552; batch adversarial loss: 0.455180\n",
      "epoch 35; iter: 0; batch classifier loss: 0.227404; batch adversarial loss: 0.494848\n",
      "epoch 36; iter: 0; batch classifier loss: 0.227677; batch adversarial loss: 0.494839\n",
      "epoch 37; iter: 0; batch classifier loss: 0.193045; batch adversarial loss: 0.362956\n",
      "epoch 38; iter: 0; batch classifier loss: 0.225934; batch adversarial loss: 0.466412\n",
      "epoch 39; iter: 0; batch classifier loss: 0.201294; batch adversarial loss: 0.431234\n",
      "epoch 40; iter: 0; batch classifier loss: 0.261345; batch adversarial loss: 0.478179\n",
      "epoch 41; iter: 0; batch classifier loss: 0.236032; batch adversarial loss: 0.539305\n",
      "epoch 42; iter: 0; batch classifier loss: 0.213838; batch adversarial loss: 0.496789\n",
      "epoch 43; iter: 0; batch classifier loss: 0.229654; batch adversarial loss: 0.510578\n",
      "epoch 44; iter: 0; batch classifier loss: 0.183145; batch adversarial loss: 0.495082\n",
      "epoch 45; iter: 0; batch classifier loss: 0.157970; batch adversarial loss: 0.454139\n",
      "epoch 46; iter: 0; batch classifier loss: 0.230413; batch adversarial loss: 0.393099\n",
      "epoch 47; iter: 0; batch classifier loss: 0.229791; batch adversarial loss: 0.408983\n",
      "epoch 48; iter: 0; batch classifier loss: 0.144992; batch adversarial loss: 0.515268\n",
      "epoch 49; iter: 0; batch classifier loss: 0.169193; batch adversarial loss: 0.498786\n",
      "epoch 50; iter: 0; batch classifier loss: 0.169874; batch adversarial loss: 0.431579\n",
      "epoch 51; iter: 0; batch classifier loss: 0.225964; batch adversarial loss: 0.526635\n",
      "epoch 52; iter: 0; batch classifier loss: 0.159919; batch adversarial loss: 0.539712\n",
      "epoch 53; iter: 0; batch classifier loss: 0.114356; batch adversarial loss: 0.495477\n",
      "epoch 54; iter: 0; batch classifier loss: 0.117740; batch adversarial loss: 0.549836\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122779; batch adversarial loss: 0.478515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.154194; batch adversarial loss: 0.461875\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106683; batch adversarial loss: 0.445550\n",
      "epoch 58; iter: 0; batch classifier loss: 0.095920; batch adversarial loss: 0.431340\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105807; batch adversarial loss: 0.453796\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095649; batch adversarial loss: 0.546474\n",
      "epoch 61; iter: 0; batch classifier loss: 0.135117; batch adversarial loss: 0.498803\n",
      "epoch 62; iter: 0; batch classifier loss: 0.151492; batch adversarial loss: 0.452472\n",
      "epoch 63; iter: 0; batch classifier loss: 0.112284; batch adversarial loss: 0.482291\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106686; batch adversarial loss: 0.420721\n",
      "epoch 65; iter: 0; batch classifier loss: 0.105298; batch adversarial loss: 0.530061\n",
      "epoch 66; iter: 0; batch classifier loss: 0.138996; batch adversarial loss: 0.415405\n",
      "epoch 67; iter: 0; batch classifier loss: 0.093515; batch adversarial loss: 0.515195\n",
      "epoch 68; iter: 0; batch classifier loss: 0.066307; batch adversarial loss: 0.551551\n",
      "epoch 69; iter: 0; batch classifier loss: 0.116065; batch adversarial loss: 0.538645\n",
      "epoch 70; iter: 0; batch classifier loss: 0.042993; batch adversarial loss: 0.530982\n",
      "epoch 71; iter: 0; batch classifier loss: 0.107918; batch adversarial loss: 0.434060\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062009; batch adversarial loss: 0.524976\n",
      "epoch 73; iter: 0; batch classifier loss: 0.064030; batch adversarial loss: 0.446230\n",
      "epoch 74; iter: 0; batch classifier loss: 0.106750; batch adversarial loss: 0.471701\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063615; batch adversarial loss: 0.470789\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058552; batch adversarial loss: 0.485514\n",
      "epoch 77; iter: 0; batch classifier loss: 0.079538; batch adversarial loss: 0.425519\n",
      "epoch 78; iter: 0; batch classifier loss: 0.050578; batch adversarial loss: 0.484712\n",
      "epoch 79; iter: 0; batch classifier loss: 0.087901; batch adversarial loss: 0.446431\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084595; batch adversarial loss: 0.375756\n",
      "epoch 81; iter: 0; batch classifier loss: 0.052514; batch adversarial loss: 0.439160\n",
      "epoch 82; iter: 0; batch classifier loss: 0.049871; batch adversarial loss: 0.595717\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068440; batch adversarial loss: 0.541503\n",
      "epoch 84; iter: 0; batch classifier loss: 0.054967; batch adversarial loss: 0.412513\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059005; batch adversarial loss: 0.423352\n",
      "epoch 86; iter: 0; batch classifier loss: 0.038368; batch adversarial loss: 0.463117\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064013; batch adversarial loss: 0.449362\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064734; batch adversarial loss: 0.583693\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035851; batch adversarial loss: 0.426671\n",
      "epoch 90; iter: 0; batch classifier loss: 0.028033; batch adversarial loss: 0.452332\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043929; batch adversarial loss: 0.475674\n",
      "epoch 92; iter: 0; batch classifier loss: 0.024209; batch adversarial loss: 0.503101\n",
      "epoch 93; iter: 0; batch classifier loss: 0.040896; batch adversarial loss: 0.468244\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051616; batch adversarial loss: 0.480938\n",
      "epoch 95; iter: 0; batch classifier loss: 0.035784; batch adversarial loss: 0.431326\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035510; batch adversarial loss: 0.455258\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050946; batch adversarial loss: 0.554032\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072134; batch adversarial loss: 0.455995\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040951; batch adversarial loss: 0.441010\n",
      "epoch 100; iter: 0; batch classifier loss: 0.028676; batch adversarial loss: 0.417420\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061568; batch adversarial loss: 0.443629\n",
      "epoch 102; iter: 0; batch classifier loss: 0.026848; batch adversarial loss: 0.488097\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049821; batch adversarial loss: 0.450156\n",
      "epoch 104; iter: 0; batch classifier loss: 0.028828; batch adversarial loss: 0.512213\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038953; batch adversarial loss: 0.424788\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057855; batch adversarial loss: 0.533252\n",
      "epoch 107; iter: 0; batch classifier loss: 0.042720; batch adversarial loss: 0.339465\n",
      "epoch 108; iter: 0; batch classifier loss: 0.023242; batch adversarial loss: 0.488999\n",
      "epoch 109; iter: 0; batch classifier loss: 0.019337; batch adversarial loss: 0.463379\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027630; batch adversarial loss: 0.456176\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039339; batch adversarial loss: 0.396668\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030109; batch adversarial loss: 0.468586\n",
      "epoch 113; iter: 0; batch classifier loss: 0.023382; batch adversarial loss: 0.344598\n",
      "epoch 114; iter: 0; batch classifier loss: 0.017242; batch adversarial loss: 0.498925\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022876; batch adversarial loss: 0.476155\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026511; batch adversarial loss: 0.497336\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035357; batch adversarial loss: 0.451937\n",
      "epoch 118; iter: 0; batch classifier loss: 0.021183; batch adversarial loss: 0.525909\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052115; batch adversarial loss: 0.391456\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025320; batch adversarial loss: 0.460468\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025476; batch adversarial loss: 0.536989\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048617; batch adversarial loss: 0.486994\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033201; batch adversarial loss: 0.486993\n",
      "epoch 124; iter: 0; batch classifier loss: 0.016456; batch adversarial loss: 0.402845\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023575; batch adversarial loss: 0.420296\n",
      "epoch 126; iter: 0; batch classifier loss: 0.015923; batch adversarial loss: 0.501159\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030531; batch adversarial loss: 0.451494\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018553; batch adversarial loss: 0.433897\n",
      "epoch 129; iter: 0; batch classifier loss: 0.060412; batch adversarial loss: 0.448921\n",
      "epoch 130; iter: 0; batch classifier loss: 0.013780; batch adversarial loss: 0.497440\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052839; batch adversarial loss: 0.474919\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015824; batch adversarial loss: 0.413509\n",
      "epoch 133; iter: 0; batch classifier loss: 0.047795; batch adversarial loss: 0.382827\n",
      "epoch 134; iter: 0; batch classifier loss: 0.012323; batch adversarial loss: 0.375603\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027240; batch adversarial loss: 0.420414\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017779; batch adversarial loss: 0.399466\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037142; batch adversarial loss: 0.458910\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023976; batch adversarial loss: 0.461522\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009692; batch adversarial loss: 0.431141\n",
      "epoch 140; iter: 0; batch classifier loss: 0.007343; batch adversarial loss: 0.384948\n",
      "epoch 141; iter: 0; batch classifier loss: 0.009585; batch adversarial loss: 0.473827\n",
      "epoch 142; iter: 0; batch classifier loss: 0.010147; batch adversarial loss: 0.455940\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037073; batch adversarial loss: 0.433264\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012618; batch adversarial loss: 0.433850\n",
      "epoch 145; iter: 0; batch classifier loss: 0.004591; batch adversarial loss: 0.339079\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027673; batch adversarial loss: 0.449859\n",
      "epoch 147; iter: 0; batch classifier loss: 0.004515; batch adversarial loss: 0.468971\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026404; batch adversarial loss: 0.444703\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024863; batch adversarial loss: 0.456440\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019591; batch adversarial loss: 0.422140\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021975; batch adversarial loss: 0.469285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.009928; batch adversarial loss: 0.488155\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019955; batch adversarial loss: 0.415462\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024462; batch adversarial loss: 0.387501\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025939; batch adversarial loss: 0.439678\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012483; batch adversarial loss: 0.485905\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022041; batch adversarial loss: 0.432615\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010991; batch adversarial loss: 0.507037\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018731; batch adversarial loss: 0.495840\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016825; batch adversarial loss: 0.478689\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014858; batch adversarial loss: 0.397265\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039063; batch adversarial loss: 0.356756\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010809; batch adversarial loss: 0.472392\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009756; batch adversarial loss: 0.525248\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023870; batch adversarial loss: 0.564366\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031986; batch adversarial loss: 0.515985\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008096; batch adversarial loss: 0.394323\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013078; batch adversarial loss: 0.553487\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013395; batch adversarial loss: 0.377042\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029994; batch adversarial loss: 0.410430\n",
      "epoch 171; iter: 0; batch classifier loss: 0.006703; batch adversarial loss: 0.469557\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007257; batch adversarial loss: 0.496349\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010130; batch adversarial loss: 0.455357\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018838; batch adversarial loss: 0.412140\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020972; batch adversarial loss: 0.512666\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013446; batch adversarial loss: 0.483188\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012931; batch adversarial loss: 0.518521\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014543; batch adversarial loss: 0.462108\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010048; batch adversarial loss: 0.405664\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011471; batch adversarial loss: 0.423742\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015661; batch adversarial loss: 0.500210\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034870; batch adversarial loss: 0.474664\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026419; batch adversarial loss: 0.423481\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003238; batch adversarial loss: 0.497696\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009069; batch adversarial loss: 0.532225\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011601; batch adversarial loss: 0.456358\n",
      "epoch 187; iter: 0; batch classifier loss: 0.004351; batch adversarial loss: 0.436383\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020629; batch adversarial loss: 0.483605\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010321; batch adversarial loss: 0.453973\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014633; batch adversarial loss: 0.446658\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020982; batch adversarial loss: 0.514874\n",
      "epoch 192; iter: 0; batch classifier loss: 0.039591; batch adversarial loss: 0.524390\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019024; batch adversarial loss: 0.472650\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007718; batch adversarial loss: 0.402672\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005035; batch adversarial loss: 0.539286\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009946; batch adversarial loss: 0.357300\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027432; batch adversarial loss: 0.387163\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009099; batch adversarial loss: 0.507987\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026537; batch adversarial loss: 0.455506\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697147; batch adversarial loss: 0.566263\n",
      "epoch 1; iter: 0; batch classifier loss: 0.373564; batch adversarial loss: 0.592201\n",
      "epoch 2; iter: 0; batch classifier loss: 0.412622; batch adversarial loss: 0.572080\n",
      "epoch 3; iter: 0; batch classifier loss: 0.297947; batch adversarial loss: 0.605178\n",
      "epoch 4; iter: 0; batch classifier loss: 0.317053; batch adversarial loss: 0.502668\n",
      "epoch 5; iter: 0; batch classifier loss: 0.289639; batch adversarial loss: 0.493234\n",
      "epoch 6; iter: 0; batch classifier loss: 0.311854; batch adversarial loss: 0.536097\n",
      "epoch 7; iter: 0; batch classifier loss: 0.359278; batch adversarial loss: 0.598730\n",
      "epoch 8; iter: 0; batch classifier loss: 0.282041; batch adversarial loss: 0.528648\n",
      "epoch 9; iter: 0; batch classifier loss: 0.298535; batch adversarial loss: 0.598486\n",
      "epoch 10; iter: 0; batch classifier loss: 0.362562; batch adversarial loss: 0.594096\n",
      "epoch 11; iter: 0; batch classifier loss: 0.242394; batch adversarial loss: 0.554542\n",
      "epoch 12; iter: 0; batch classifier loss: 0.382006; batch adversarial loss: 0.532193\n",
      "epoch 13; iter: 0; batch classifier loss: 0.399467; batch adversarial loss: 0.559702\n",
      "epoch 14; iter: 0; batch classifier loss: 0.475609; batch adversarial loss: 0.611316\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505075; batch adversarial loss: 0.502532\n",
      "epoch 16; iter: 0; batch classifier loss: 0.471500; batch adversarial loss: 0.537994\n",
      "epoch 17; iter: 0; batch classifier loss: 0.339628; batch adversarial loss: 0.513759\n",
      "epoch 18; iter: 0; batch classifier loss: 0.287082; batch adversarial loss: 0.451564\n",
      "epoch 19; iter: 0; batch classifier loss: 0.184341; batch adversarial loss: 0.413113\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220727; batch adversarial loss: 0.562063\n",
      "epoch 21; iter: 0; batch classifier loss: 0.223364; batch adversarial loss: 0.462211\n",
      "epoch 22; iter: 0; batch classifier loss: 0.231421; batch adversarial loss: 0.483380\n",
      "epoch 23; iter: 0; batch classifier loss: 0.205765; batch adversarial loss: 0.373980\n",
      "epoch 24; iter: 0; batch classifier loss: 0.170849; batch adversarial loss: 0.563420\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179083; batch adversarial loss: 0.462974\n",
      "epoch 26; iter: 0; batch classifier loss: 0.152803; batch adversarial loss: 0.637867\n",
      "epoch 27; iter: 0; batch classifier loss: 0.165525; batch adversarial loss: 0.406829\n",
      "epoch 28; iter: 0; batch classifier loss: 0.115135; batch adversarial loss: 0.468897\n",
      "epoch 29; iter: 0; batch classifier loss: 0.108170; batch adversarial loss: 0.555417\n",
      "epoch 30; iter: 0; batch classifier loss: 0.184589; batch adversarial loss: 0.390083\n",
      "epoch 31; iter: 0; batch classifier loss: 0.143835; batch adversarial loss: 0.420767\n",
      "epoch 32; iter: 0; batch classifier loss: 0.173502; batch adversarial loss: 0.585564\n",
      "epoch 33; iter: 0; batch classifier loss: 0.085929; batch adversarial loss: 0.452218\n",
      "epoch 34; iter: 0; batch classifier loss: 0.135134; batch adversarial loss: 0.520387\n",
      "epoch 35; iter: 0; batch classifier loss: 0.135666; batch adversarial loss: 0.468380\n",
      "epoch 36; iter: 0; batch classifier loss: 0.190665; batch adversarial loss: 0.422078\n",
      "epoch 37; iter: 0; batch classifier loss: 0.139169; batch adversarial loss: 0.426054\n",
      "epoch 38; iter: 0; batch classifier loss: 0.156822; batch adversarial loss: 0.436796\n",
      "epoch 39; iter: 0; batch classifier loss: 0.158032; batch adversarial loss: 0.401110\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124751; batch adversarial loss: 0.426792\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106099; batch adversarial loss: 0.477639\n",
      "epoch 42; iter: 0; batch classifier loss: 0.158913; batch adversarial loss: 0.408338\n",
      "epoch 43; iter: 0; batch classifier loss: 0.121637; batch adversarial loss: 0.435716\n",
      "epoch 44; iter: 0; batch classifier loss: 0.110290; batch adversarial loss: 0.501489\n",
      "epoch 45; iter: 0; batch classifier loss: 0.150830; batch adversarial loss: 0.444264\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117301; batch adversarial loss: 0.490735\n",
      "epoch 47; iter: 0; batch classifier loss: 0.129945; batch adversarial loss: 0.519346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.095743; batch adversarial loss: 0.553054\n",
      "epoch 49; iter: 0; batch classifier loss: 0.104640; batch adversarial loss: 0.494349\n",
      "epoch 50; iter: 0; batch classifier loss: 0.157581; batch adversarial loss: 0.474626\n",
      "epoch 51; iter: 0; batch classifier loss: 0.149902; batch adversarial loss: 0.398032\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111717; batch adversarial loss: 0.420384\n",
      "epoch 53; iter: 0; batch classifier loss: 0.051068; batch adversarial loss: 0.433902\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114210; batch adversarial loss: 0.486269\n",
      "epoch 55; iter: 0; batch classifier loss: 0.186925; batch adversarial loss: 0.407621\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103462; batch adversarial loss: 0.496794\n",
      "epoch 57; iter: 0; batch classifier loss: 0.140188; batch adversarial loss: 0.385872\n",
      "epoch 58; iter: 0; batch classifier loss: 0.100612; batch adversarial loss: 0.489985\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090964; batch adversarial loss: 0.529389\n",
      "epoch 60; iter: 0; batch classifier loss: 0.131754; batch adversarial loss: 0.505901\n",
      "epoch 61; iter: 0; batch classifier loss: 0.049507; batch adversarial loss: 0.435070\n",
      "epoch 62; iter: 0; batch classifier loss: 0.122021; batch adversarial loss: 0.417390\n",
      "epoch 63; iter: 0; batch classifier loss: 0.131079; batch adversarial loss: 0.475454\n",
      "epoch 64; iter: 0; batch classifier loss: 0.091089; batch adversarial loss: 0.456276\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107946; batch adversarial loss: 0.451812\n",
      "epoch 66; iter: 0; batch classifier loss: 0.150056; batch adversarial loss: 0.463565\n",
      "epoch 67; iter: 0; batch classifier loss: 0.148141; batch adversarial loss: 0.446122\n",
      "epoch 68; iter: 0; batch classifier loss: 0.177124; batch adversarial loss: 0.558932\n",
      "epoch 69; iter: 0; batch classifier loss: 0.115135; batch adversarial loss: 0.529883\n",
      "epoch 70; iter: 0; batch classifier loss: 0.099415; batch adversarial loss: 0.533075\n",
      "epoch 71; iter: 0; batch classifier loss: 0.135674; batch adversarial loss: 0.438321\n",
      "epoch 72; iter: 0; batch classifier loss: 0.068018; batch adversarial loss: 0.496431\n",
      "epoch 73; iter: 0; batch classifier loss: 0.092915; batch adversarial loss: 0.526804\n",
      "epoch 74; iter: 0; batch classifier loss: 0.112678; batch adversarial loss: 0.469852\n",
      "epoch 75; iter: 0; batch classifier loss: 0.129665; batch adversarial loss: 0.490134\n",
      "epoch 76; iter: 0; batch classifier loss: 0.141424; batch adversarial loss: 0.350545\n",
      "epoch 77; iter: 0; batch classifier loss: 0.122478; batch adversarial loss: 0.409169\n",
      "epoch 78; iter: 0; batch classifier loss: 0.104847; batch adversarial loss: 0.527365\n",
      "epoch 79; iter: 0; batch classifier loss: 0.100575; batch adversarial loss: 0.455490\n",
      "epoch 80; iter: 0; batch classifier loss: 0.102140; batch adversarial loss: 0.471856\n",
      "epoch 81; iter: 0; batch classifier loss: 0.106012; batch adversarial loss: 0.403231\n",
      "epoch 82; iter: 0; batch classifier loss: 0.148136; batch adversarial loss: 0.381086\n",
      "epoch 83; iter: 0; batch classifier loss: 0.149301; batch adversarial loss: 0.380837\n",
      "epoch 84; iter: 0; batch classifier loss: 0.114800; batch adversarial loss: 0.417439\n",
      "epoch 85; iter: 0; batch classifier loss: 0.123136; batch adversarial loss: 0.501590\n",
      "epoch 86; iter: 0; batch classifier loss: 0.118932; batch adversarial loss: 0.403087\n",
      "epoch 87; iter: 0; batch classifier loss: 0.097734; batch adversarial loss: 0.412051\n",
      "epoch 88; iter: 0; batch classifier loss: 0.123318; batch adversarial loss: 0.398259\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053714; batch adversarial loss: 0.515832\n",
      "epoch 90; iter: 0; batch classifier loss: 0.122310; batch adversarial loss: 0.433857\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075103; batch adversarial loss: 0.377565\n",
      "epoch 92; iter: 0; batch classifier loss: 0.085856; batch adversarial loss: 0.386269\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063326; batch adversarial loss: 0.505221\n",
      "epoch 94; iter: 0; batch classifier loss: 0.076712; batch adversarial loss: 0.588962\n",
      "epoch 95; iter: 0; batch classifier loss: 0.086576; batch adversarial loss: 0.386291\n",
      "epoch 96; iter: 0; batch classifier loss: 0.077594; batch adversarial loss: 0.425711\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061804; batch adversarial loss: 0.417942\n",
      "epoch 98; iter: 0; batch classifier loss: 0.093706; batch adversarial loss: 0.521102\n",
      "epoch 99; iter: 0; batch classifier loss: 0.098014; batch adversarial loss: 0.484049\n",
      "epoch 100; iter: 0; batch classifier loss: 0.099734; batch adversarial loss: 0.442480\n",
      "epoch 101; iter: 0; batch classifier loss: 0.150593; batch adversarial loss: 0.512292\n",
      "epoch 102; iter: 0; batch classifier loss: 0.091375; batch adversarial loss: 0.533623\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064679; batch adversarial loss: 0.527173\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059909; batch adversarial loss: 0.414042\n",
      "epoch 105; iter: 0; batch classifier loss: 0.106699; batch adversarial loss: 0.415034\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052227; batch adversarial loss: 0.522679\n",
      "epoch 107; iter: 0; batch classifier loss: 0.115667; batch adversarial loss: 0.405626\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058945; batch adversarial loss: 0.464472\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067280; batch adversarial loss: 0.446545\n",
      "epoch 110; iter: 0; batch classifier loss: 0.106197; batch adversarial loss: 0.484185\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057329; batch adversarial loss: 0.455974\n",
      "epoch 112; iter: 0; batch classifier loss: 0.061214; batch adversarial loss: 0.472083\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058432; batch adversarial loss: 0.494077\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056090; batch adversarial loss: 0.487684\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054096; batch adversarial loss: 0.449485\n",
      "epoch 116; iter: 0; batch classifier loss: 0.077674; batch adversarial loss: 0.481750\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051478; batch adversarial loss: 0.501441\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043020; batch adversarial loss: 0.461639\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056545; batch adversarial loss: 0.450209\n",
      "epoch 120; iter: 0; batch classifier loss: 0.017903; batch adversarial loss: 0.472268\n",
      "epoch 121; iter: 0; batch classifier loss: 0.096662; batch adversarial loss: 0.347847\n",
      "epoch 122; iter: 0; batch classifier loss: 0.060684; batch adversarial loss: 0.444447\n",
      "epoch 123; iter: 0; batch classifier loss: 0.058640; batch adversarial loss: 0.464050\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067440; batch adversarial loss: 0.533030\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053975; batch adversarial loss: 0.385790\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043949; batch adversarial loss: 0.449158\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045468; batch adversarial loss: 0.470712\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034558; batch adversarial loss: 0.388146\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034914; batch adversarial loss: 0.517150\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057985; batch adversarial loss: 0.461806\n",
      "epoch 131; iter: 0; batch classifier loss: 0.076847; batch adversarial loss: 0.527077\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014213; batch adversarial loss: 0.433421\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021824; batch adversarial loss: 0.488480\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054075; batch adversarial loss: 0.472866\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029036; batch adversarial loss: 0.426645\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032129; batch adversarial loss: 0.417653\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034233; batch adversarial loss: 0.477512\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038951; batch adversarial loss: 0.427197\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042259; batch adversarial loss: 0.450422\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044717; batch adversarial loss: 0.501795\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036873; batch adversarial loss: 0.424346\n",
      "epoch 142; iter: 0; batch classifier loss: 0.038796; batch adversarial loss: 0.509068\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032827; batch adversarial loss: 0.453535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.032725; batch adversarial loss: 0.542429\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045728; batch adversarial loss: 0.386057\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030455; batch adversarial loss: 0.540993\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039560; batch adversarial loss: 0.445475\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019488; batch adversarial loss: 0.473460\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034811; batch adversarial loss: 0.443826\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021368; batch adversarial loss: 0.437108\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043432; batch adversarial loss: 0.557534\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031600; batch adversarial loss: 0.493241\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036315; batch adversarial loss: 0.411020\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029371; batch adversarial loss: 0.500456\n",
      "epoch 155; iter: 0; batch classifier loss: 0.096553; batch adversarial loss: 0.475848\n",
      "epoch 156; iter: 0; batch classifier loss: 0.065673; batch adversarial loss: 0.458398\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038220; batch adversarial loss: 0.413784\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042847; batch adversarial loss: 0.536042\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040572; batch adversarial loss: 0.439772\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014382; batch adversarial loss: 0.452019\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018241; batch adversarial loss: 0.488563\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020773; batch adversarial loss: 0.435211\n",
      "epoch 163; iter: 0; batch classifier loss: 0.061866; batch adversarial loss: 0.477140\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018926; batch adversarial loss: 0.470230\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028449; batch adversarial loss: 0.522377\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012815; batch adversarial loss: 0.479633\n",
      "epoch 167; iter: 0; batch classifier loss: 0.054213; batch adversarial loss: 0.510403\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037650; batch adversarial loss: 0.380288\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028240; batch adversarial loss: 0.395047\n",
      "epoch 170; iter: 0; batch classifier loss: 0.045764; batch adversarial loss: 0.445112\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031465; batch adversarial loss: 0.390954\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018123; batch adversarial loss: 0.444615\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015969; batch adversarial loss: 0.411990\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019358; batch adversarial loss: 0.432965\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009145; batch adversarial loss: 0.483526\n",
      "epoch 176; iter: 0; batch classifier loss: 0.043841; batch adversarial loss: 0.374725\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017378; batch adversarial loss: 0.530596\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011422; batch adversarial loss: 0.467976\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023573; batch adversarial loss: 0.373317\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026559; batch adversarial loss: 0.393719\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008742; batch adversarial loss: 0.461891\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025126; batch adversarial loss: 0.532015\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030348; batch adversarial loss: 0.441737\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022283; batch adversarial loss: 0.440765\n",
      "epoch 185; iter: 0; batch classifier loss: 0.062627; batch adversarial loss: 0.514496\n",
      "epoch 186; iter: 0; batch classifier loss: 0.047106; batch adversarial loss: 0.422938\n",
      "epoch 187; iter: 0; batch classifier loss: 0.003675; batch adversarial loss: 0.474346\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006688; batch adversarial loss: 0.513735\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018269; batch adversarial loss: 0.558623\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021644; batch adversarial loss: 0.476384\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008231; batch adversarial loss: 0.492348\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033816; batch adversarial loss: 0.503683\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025062; batch adversarial loss: 0.416308\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009361; batch adversarial loss: 0.429804\n",
      "epoch 195; iter: 0; batch classifier loss: 0.048832; batch adversarial loss: 0.378281\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021907; batch adversarial loss: 0.445444\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021226; batch adversarial loss: 0.510300\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027183; batch adversarial loss: 0.400973\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018859; batch adversarial loss: 0.340280\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725578; batch adversarial loss: 0.991525\n",
      "epoch 1; iter: 0; batch classifier loss: 0.600595; batch adversarial loss: 1.071976\n",
      "epoch 2; iter: 0; batch classifier loss: 0.734866; batch adversarial loss: 1.036554\n",
      "epoch 3; iter: 0; batch classifier loss: 0.879784; batch adversarial loss: 0.947003\n",
      "epoch 4; iter: 0; batch classifier loss: 0.969236; batch adversarial loss: 0.862948\n",
      "epoch 5; iter: 0; batch classifier loss: 0.984214; batch adversarial loss: 0.781403\n",
      "epoch 6; iter: 0; batch classifier loss: 0.953295; batch adversarial loss: 0.713308\n",
      "epoch 7; iter: 0; batch classifier loss: 0.965060; batch adversarial loss: 0.664222\n",
      "epoch 8; iter: 0; batch classifier loss: 0.872854; batch adversarial loss: 0.622018\n",
      "epoch 9; iter: 0; batch classifier loss: 0.835632; batch adversarial loss: 0.564835\n",
      "epoch 10; iter: 0; batch classifier loss: 0.291967; batch adversarial loss: 0.550080\n",
      "epoch 11; iter: 0; batch classifier loss: 0.217850; batch adversarial loss: 0.563180\n",
      "epoch 12; iter: 0; batch classifier loss: 0.276744; batch adversarial loss: 0.545107\n",
      "epoch 13; iter: 0; batch classifier loss: 0.208609; batch adversarial loss: 0.511027\n",
      "epoch 14; iter: 0; batch classifier loss: 0.207293; batch adversarial loss: 0.485049\n",
      "epoch 15; iter: 0; batch classifier loss: 0.210533; batch adversarial loss: 0.516035\n",
      "epoch 16; iter: 0; batch classifier loss: 0.223320; batch adversarial loss: 0.502207\n",
      "epoch 17; iter: 0; batch classifier loss: 0.248576; batch adversarial loss: 0.492999\n",
      "epoch 18; iter: 0; batch classifier loss: 0.180849; batch adversarial loss: 0.527876\n",
      "epoch 19; iter: 0; batch classifier loss: 0.132129; batch adversarial loss: 0.419066\n",
      "epoch 20; iter: 0; batch classifier loss: 0.189304; batch adversarial loss: 0.561078\n",
      "epoch 21; iter: 0; batch classifier loss: 0.209976; batch adversarial loss: 0.442577\n",
      "epoch 22; iter: 0; batch classifier loss: 0.220775; batch adversarial loss: 0.507739\n",
      "epoch 23; iter: 0; batch classifier loss: 0.230860; batch adversarial loss: 0.436005\n",
      "epoch 24; iter: 0; batch classifier loss: 0.291030; batch adversarial loss: 0.426829\n",
      "epoch 25; iter: 0; batch classifier loss: 0.321677; batch adversarial loss: 0.400647\n",
      "epoch 26; iter: 0; batch classifier loss: 0.239028; batch adversarial loss: 0.493078\n",
      "epoch 27; iter: 0; batch classifier loss: 0.240949; batch adversarial loss: 0.468618\n",
      "epoch 28; iter: 0; batch classifier loss: 0.244724; batch adversarial loss: 0.502835\n",
      "epoch 29; iter: 0; batch classifier loss: 0.171166; batch adversarial loss: 0.453539\n",
      "epoch 30; iter: 0; batch classifier loss: 0.257051; batch adversarial loss: 0.423697\n",
      "epoch 31; iter: 0; batch classifier loss: 0.206134; batch adversarial loss: 0.395365\n",
      "epoch 32; iter: 0; batch classifier loss: 0.192474; batch adversarial loss: 0.460140\n",
      "epoch 33; iter: 0; batch classifier loss: 0.166739; batch adversarial loss: 0.483822\n",
      "epoch 34; iter: 0; batch classifier loss: 0.198790; batch adversarial loss: 0.489377\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137377; batch adversarial loss: 0.452581\n",
      "epoch 36; iter: 0; batch classifier loss: 0.104343; batch adversarial loss: 0.473580\n",
      "epoch 37; iter: 0; batch classifier loss: 0.128606; batch adversarial loss: 0.451340\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122408; batch adversarial loss: 0.450887\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126018; batch adversarial loss: 0.453924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.133489; batch adversarial loss: 0.437380\n",
      "epoch 41; iter: 0; batch classifier loss: 0.112431; batch adversarial loss: 0.479065\n",
      "epoch 42; iter: 0; batch classifier loss: 0.133814; batch adversarial loss: 0.449121\n",
      "epoch 43; iter: 0; batch classifier loss: 0.132323; batch adversarial loss: 0.441749\n",
      "epoch 44; iter: 0; batch classifier loss: 0.087392; batch adversarial loss: 0.414066\n",
      "epoch 45; iter: 0; batch classifier loss: 0.148695; batch adversarial loss: 0.406595\n",
      "epoch 46; iter: 0; batch classifier loss: 0.111555; batch adversarial loss: 0.476271\n",
      "epoch 47; iter: 0; batch classifier loss: 0.089806; batch adversarial loss: 0.443434\n",
      "epoch 48; iter: 0; batch classifier loss: 0.085597; batch adversarial loss: 0.474031\n",
      "epoch 49; iter: 0; batch classifier loss: 0.087354; batch adversarial loss: 0.331050\n",
      "epoch 50; iter: 0; batch classifier loss: 0.064028; batch adversarial loss: 0.469419\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070940; batch adversarial loss: 0.519774\n",
      "epoch 52; iter: 0; batch classifier loss: 0.128105; batch adversarial loss: 0.453829\n",
      "epoch 53; iter: 0; batch classifier loss: 0.083404; batch adversarial loss: 0.433671\n",
      "epoch 54; iter: 0; batch classifier loss: 0.124211; batch adversarial loss: 0.404280\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096846; batch adversarial loss: 0.402587\n",
      "epoch 56; iter: 0; batch classifier loss: 0.092325; batch adversarial loss: 0.492915\n",
      "epoch 57; iter: 0; batch classifier loss: 0.105556; batch adversarial loss: 0.435763\n",
      "epoch 58; iter: 0; batch classifier loss: 0.063737; batch adversarial loss: 0.401312\n",
      "epoch 59; iter: 0; batch classifier loss: 0.073138; batch adversarial loss: 0.413753\n",
      "epoch 60; iter: 0; batch classifier loss: 0.052587; batch adversarial loss: 0.409354\n",
      "epoch 61; iter: 0; batch classifier loss: 0.058934; batch adversarial loss: 0.452726\n",
      "epoch 62; iter: 0; batch classifier loss: 0.070974; batch adversarial loss: 0.526304\n",
      "epoch 63; iter: 0; batch classifier loss: 0.081396; batch adversarial loss: 0.347258\n",
      "epoch 64; iter: 0; batch classifier loss: 0.069916; batch adversarial loss: 0.441424\n",
      "epoch 65; iter: 0; batch classifier loss: 0.062827; batch adversarial loss: 0.451050\n",
      "epoch 66; iter: 0; batch classifier loss: 0.046868; batch adversarial loss: 0.458034\n",
      "epoch 67; iter: 0; batch classifier loss: 0.057825; batch adversarial loss: 0.492976\n",
      "epoch 68; iter: 0; batch classifier loss: 0.043822; batch adversarial loss: 0.577198\n",
      "epoch 69; iter: 0; batch classifier loss: 0.056333; batch adversarial loss: 0.506566\n",
      "epoch 70; iter: 0; batch classifier loss: 0.130599; batch adversarial loss: 0.361512\n",
      "epoch 71; iter: 0; batch classifier loss: 0.053661; batch adversarial loss: 0.387981\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064669; batch adversarial loss: 0.435049\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079541; batch adversarial loss: 0.479830\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079054; batch adversarial loss: 0.480130\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067453; batch adversarial loss: 0.404920\n",
      "epoch 76; iter: 0; batch classifier loss: 0.061031; batch adversarial loss: 0.405173\n",
      "epoch 77; iter: 0; batch classifier loss: 0.046905; batch adversarial loss: 0.362668\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082727; batch adversarial loss: 0.387600\n",
      "epoch 79; iter: 0; batch classifier loss: 0.046053; batch adversarial loss: 0.377342\n",
      "epoch 80; iter: 0; batch classifier loss: 0.025112; batch adversarial loss: 0.471681\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050290; batch adversarial loss: 0.540745\n",
      "epoch 82; iter: 0; batch classifier loss: 0.039600; batch adversarial loss: 0.457916\n",
      "epoch 83; iter: 0; batch classifier loss: 0.055230; batch adversarial loss: 0.479003\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069558; batch adversarial loss: 0.466796\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068386; batch adversarial loss: 0.516410\n",
      "epoch 86; iter: 0; batch classifier loss: 0.027863; batch adversarial loss: 0.448599\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068597; batch adversarial loss: 0.495529\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040116; batch adversarial loss: 0.486692\n",
      "epoch 89; iter: 0; batch classifier loss: 0.049021; batch adversarial loss: 0.513729\n",
      "epoch 90; iter: 0; batch classifier loss: 0.021348; batch adversarial loss: 0.506998\n",
      "epoch 91; iter: 0; batch classifier loss: 0.088706; batch adversarial loss: 0.414593\n",
      "epoch 92; iter: 0; batch classifier loss: 0.036828; batch adversarial loss: 0.406036\n",
      "epoch 93; iter: 0; batch classifier loss: 0.032441; batch adversarial loss: 0.447291\n",
      "epoch 94; iter: 0; batch classifier loss: 0.029504; batch adversarial loss: 0.415103\n",
      "epoch 95; iter: 0; batch classifier loss: 0.034006; batch adversarial loss: 0.426191\n",
      "epoch 96; iter: 0; batch classifier loss: 0.053785; batch adversarial loss: 0.448385\n",
      "epoch 97; iter: 0; batch classifier loss: 0.045295; batch adversarial loss: 0.439587\n",
      "epoch 98; iter: 0; batch classifier loss: 0.011128; batch adversarial loss: 0.459088\n",
      "epoch 99; iter: 0; batch classifier loss: 0.016071; batch adversarial loss: 0.481066\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036378; batch adversarial loss: 0.438543\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058119; batch adversarial loss: 0.508987\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062077; batch adversarial loss: 0.393828\n",
      "epoch 103; iter: 0; batch classifier loss: 0.069547; batch adversarial loss: 0.397212\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036167; batch adversarial loss: 0.495251\n",
      "epoch 105; iter: 0; batch classifier loss: 0.018433; batch adversarial loss: 0.517270\n",
      "epoch 106; iter: 0; batch classifier loss: 0.066180; batch adversarial loss: 0.436138\n",
      "epoch 107; iter: 0; batch classifier loss: 0.029039; batch adversarial loss: 0.443258\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031259; batch adversarial loss: 0.536623\n",
      "epoch 109; iter: 0; batch classifier loss: 0.020731; batch adversarial loss: 0.345596\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037937; batch adversarial loss: 0.350137\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052652; batch adversarial loss: 0.339358\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034310; batch adversarial loss: 0.410208\n",
      "epoch 113; iter: 0; batch classifier loss: 0.023691; batch adversarial loss: 0.507289\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046016; batch adversarial loss: 0.537702\n",
      "epoch 115; iter: 0; batch classifier loss: 0.019977; batch adversarial loss: 0.510508\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027812; batch adversarial loss: 0.521572\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033173; batch adversarial loss: 0.500797\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026522; batch adversarial loss: 0.443257\n",
      "epoch 119; iter: 0; batch classifier loss: 0.014773; batch adversarial loss: 0.444423\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043330; batch adversarial loss: 0.461315\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041636; batch adversarial loss: 0.347154\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044980; batch adversarial loss: 0.469592\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026342; batch adversarial loss: 0.416779\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037173; batch adversarial loss: 0.358093\n",
      "epoch 125; iter: 0; batch classifier loss: 0.019463; batch adversarial loss: 0.440732\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039895; batch adversarial loss: 0.272682\n",
      "epoch 127; iter: 0; batch classifier loss: 0.065233; batch adversarial loss: 0.403402\n",
      "epoch 128; iter: 0; batch classifier loss: 0.015714; batch adversarial loss: 0.411085\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034612; batch adversarial loss: 0.448442\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016549; batch adversarial loss: 0.469736\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051191; batch adversarial loss: 0.456767\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023991; batch adversarial loss: 0.350893\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037056; batch adversarial loss: 0.435071\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048611; batch adversarial loss: 0.411161\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019887; batch adversarial loss: 0.444515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.017265; batch adversarial loss: 0.419120\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012714; batch adversarial loss: 0.450926\n",
      "epoch 138; iter: 0; batch classifier loss: 0.009627; batch adversarial loss: 0.412935\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014536; batch adversarial loss: 0.431203\n",
      "epoch 140; iter: 0; batch classifier loss: 0.015854; batch adversarial loss: 0.396238\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021551; batch adversarial loss: 0.568749\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028523; batch adversarial loss: 0.541129\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011293; batch adversarial loss: 0.526947\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012230; batch adversarial loss: 0.416912\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021437; batch adversarial loss: 0.483715\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032902; batch adversarial loss: 0.426340\n",
      "epoch 147; iter: 0; batch classifier loss: 0.012328; batch adversarial loss: 0.536969\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013601; batch adversarial loss: 0.504730\n",
      "epoch 149; iter: 0; batch classifier loss: 0.008154; batch adversarial loss: 0.428836\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036334; batch adversarial loss: 0.572206\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023776; batch adversarial loss: 0.402147\n",
      "epoch 152; iter: 0; batch classifier loss: 0.005314; batch adversarial loss: 0.359554\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024507; batch adversarial loss: 0.412797\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015836; batch adversarial loss: 0.422682\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025869; batch adversarial loss: 0.365836\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019405; batch adversarial loss: 0.513844\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031644; batch adversarial loss: 0.478949\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026771; batch adversarial loss: 0.422518\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036759; batch adversarial loss: 0.477718\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010751; batch adversarial loss: 0.438700\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028617; batch adversarial loss: 0.502440\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037451; batch adversarial loss: 0.392467\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018601; batch adversarial loss: 0.495517\n",
      "epoch 164; iter: 0; batch classifier loss: 0.007856; batch adversarial loss: 0.488645\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029766; batch adversarial loss: 0.403459\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016933; batch adversarial loss: 0.535634\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030386; batch adversarial loss: 0.431844\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022651; batch adversarial loss: 0.508197\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008258; batch adversarial loss: 0.472909\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015721; batch adversarial loss: 0.469447\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027397; batch adversarial loss: 0.409808\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007313; batch adversarial loss: 0.474047\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026707; batch adversarial loss: 0.476744\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020527; batch adversarial loss: 0.497997\n",
      "epoch 175; iter: 0; batch classifier loss: 0.005860; batch adversarial loss: 0.461117\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022933; batch adversarial loss: 0.517588\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030245; batch adversarial loss: 0.550921\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013451; batch adversarial loss: 0.408229\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010836; batch adversarial loss: 0.471477\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011074; batch adversarial loss: 0.541484\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012856; batch adversarial loss: 0.430917\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027305; batch adversarial loss: 0.406823\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030389; batch adversarial loss: 0.499145\n",
      "epoch 184; iter: 0; batch classifier loss: 0.005072; batch adversarial loss: 0.436843\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008897; batch adversarial loss: 0.466138\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007959; batch adversarial loss: 0.462016\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010395; batch adversarial loss: 0.497679\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015690; batch adversarial loss: 0.480153\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024417; batch adversarial loss: 0.467291\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009806; batch adversarial loss: 0.470047\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018910; batch adversarial loss: 0.455040\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024237; batch adversarial loss: 0.386517\n",
      "epoch 193; iter: 0; batch classifier loss: 0.003834; batch adversarial loss: 0.483858\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030491; batch adversarial loss: 0.453176\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020537; batch adversarial loss: 0.507577\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019924; batch adversarial loss: 0.417682\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010112; batch adversarial loss: 0.438555\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004718; batch adversarial loss: 0.389498\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008143; batch adversarial loss: 0.452067\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690218; batch adversarial loss: 0.809076\n",
      "epoch 1; iter: 0; batch classifier loss: 0.734230; batch adversarial loss: 0.900245\n",
      "epoch 2; iter: 0; batch classifier loss: 0.881557; batch adversarial loss: 0.880430\n",
      "epoch 3; iter: 0; batch classifier loss: 0.778439; batch adversarial loss: 0.762800\n",
      "epoch 4; iter: 0; batch classifier loss: 0.755394; batch adversarial loss: 0.705547\n",
      "epoch 5; iter: 0; batch classifier loss: 0.599549; batch adversarial loss: 0.604209\n",
      "epoch 6; iter: 0; batch classifier loss: 0.485424; batch adversarial loss: 0.579303\n",
      "epoch 7; iter: 0; batch classifier loss: 0.345960; batch adversarial loss: 0.559165\n",
      "epoch 8; iter: 0; batch classifier loss: 0.359831; batch adversarial loss: 0.501440\n",
      "epoch 9; iter: 0; batch classifier loss: 0.360590; batch adversarial loss: 0.537712\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258259; batch adversarial loss: 0.564903\n",
      "epoch 11; iter: 0; batch classifier loss: 0.284944; batch adversarial loss: 0.518355\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282407; batch adversarial loss: 0.495027\n",
      "epoch 13; iter: 0; batch classifier loss: 0.192624; batch adversarial loss: 0.509467\n",
      "epoch 14; iter: 0; batch classifier loss: 0.226302; batch adversarial loss: 0.479297\n",
      "epoch 15; iter: 0; batch classifier loss: 0.249144; batch adversarial loss: 0.474135\n",
      "epoch 16; iter: 0; batch classifier loss: 0.282332; batch adversarial loss: 0.456949\n",
      "epoch 17; iter: 0; batch classifier loss: 0.234486; batch adversarial loss: 0.441810\n",
      "epoch 18; iter: 0; batch classifier loss: 0.200506; batch adversarial loss: 0.564914\n",
      "epoch 19; iter: 0; batch classifier loss: 0.243053; batch adversarial loss: 0.552126\n",
      "epoch 20; iter: 0; batch classifier loss: 0.151655; batch adversarial loss: 0.468587\n",
      "epoch 21; iter: 0; batch classifier loss: 0.161889; batch adversarial loss: 0.524526\n",
      "epoch 22; iter: 0; batch classifier loss: 0.199275; batch adversarial loss: 0.430225\n",
      "epoch 23; iter: 0; batch classifier loss: 0.148961; batch adversarial loss: 0.507255\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192695; batch adversarial loss: 0.435643\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215080; batch adversarial loss: 0.441734\n",
      "epoch 26; iter: 0; batch classifier loss: 0.145786; batch adversarial loss: 0.502321\n",
      "epoch 27; iter: 0; batch classifier loss: 0.206987; batch adversarial loss: 0.380495\n",
      "epoch 28; iter: 0; batch classifier loss: 0.158445; batch adversarial loss: 0.489129\n",
      "epoch 29; iter: 0; batch classifier loss: 0.165613; batch adversarial loss: 0.502474\n",
      "epoch 30; iter: 0; batch classifier loss: 0.150545; batch adversarial loss: 0.479034\n",
      "epoch 31; iter: 0; batch classifier loss: 0.149505; batch adversarial loss: 0.407693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.185732; batch adversarial loss: 0.438623\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128170; batch adversarial loss: 0.463396\n",
      "epoch 34; iter: 0; batch classifier loss: 0.143185; batch adversarial loss: 0.577238\n",
      "epoch 35; iter: 0; batch classifier loss: 0.172486; batch adversarial loss: 0.451381\n",
      "epoch 36; iter: 0; batch classifier loss: 0.145870; batch adversarial loss: 0.444457\n",
      "epoch 37; iter: 0; batch classifier loss: 0.147018; batch adversarial loss: 0.546576\n",
      "epoch 38; iter: 0; batch classifier loss: 0.166864; batch adversarial loss: 0.400995\n",
      "epoch 39; iter: 0; batch classifier loss: 0.133820; batch adversarial loss: 0.482419\n",
      "epoch 40; iter: 0; batch classifier loss: 0.178240; batch adversarial loss: 0.463480\n",
      "epoch 41; iter: 0; batch classifier loss: 0.088363; batch adversarial loss: 0.359198\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102712; batch adversarial loss: 0.430342\n",
      "epoch 43; iter: 0; batch classifier loss: 0.154730; batch adversarial loss: 0.458971\n",
      "epoch 44; iter: 0; batch classifier loss: 0.087892; batch adversarial loss: 0.471530\n",
      "epoch 45; iter: 0; batch classifier loss: 0.059852; batch adversarial loss: 0.446605\n",
      "epoch 46; iter: 0; batch classifier loss: 0.093133; batch adversarial loss: 0.500039\n",
      "epoch 47; iter: 0; batch classifier loss: 0.111937; batch adversarial loss: 0.492518\n",
      "epoch 48; iter: 0; batch classifier loss: 0.114827; batch adversarial loss: 0.467579\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114562; batch adversarial loss: 0.396501\n",
      "epoch 50; iter: 0; batch classifier loss: 0.092871; batch adversarial loss: 0.511088\n",
      "epoch 51; iter: 0; batch classifier loss: 0.131086; batch adversarial loss: 0.367223\n",
      "epoch 52; iter: 0; batch classifier loss: 0.148661; batch adversarial loss: 0.466302\n",
      "epoch 53; iter: 0; batch classifier loss: 0.111069; batch adversarial loss: 0.407252\n",
      "epoch 54; iter: 0; batch classifier loss: 0.075363; batch adversarial loss: 0.372205\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087507; batch adversarial loss: 0.428806\n",
      "epoch 56; iter: 0; batch classifier loss: 0.066713; batch adversarial loss: 0.427527\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110580; batch adversarial loss: 0.464055\n",
      "epoch 58; iter: 0; batch classifier loss: 0.100991; batch adversarial loss: 0.372654\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072617; batch adversarial loss: 0.452128\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087814; batch adversarial loss: 0.526837\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113683; batch adversarial loss: 0.523595\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104902; batch adversarial loss: 0.461273\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098297; batch adversarial loss: 0.510565\n",
      "epoch 64; iter: 0; batch classifier loss: 0.110973; batch adversarial loss: 0.439756\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088900; batch adversarial loss: 0.506864\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084857; batch adversarial loss: 0.498296\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087360; batch adversarial loss: 0.469375\n",
      "epoch 68; iter: 0; batch classifier loss: 0.075102; batch adversarial loss: 0.468994\n",
      "epoch 69; iter: 0; batch classifier loss: 0.086646; batch adversarial loss: 0.526039\n",
      "epoch 70; iter: 0; batch classifier loss: 0.108171; batch adversarial loss: 0.496114\n",
      "epoch 71; iter: 0; batch classifier loss: 0.100210; batch adversarial loss: 0.506265\n",
      "epoch 72; iter: 0; batch classifier loss: 0.093513; batch adversarial loss: 0.451598\n",
      "epoch 73; iter: 0; batch classifier loss: 0.037448; batch adversarial loss: 0.435017\n",
      "epoch 74; iter: 0; batch classifier loss: 0.058250; batch adversarial loss: 0.492987\n",
      "epoch 75; iter: 0; batch classifier loss: 0.117842; batch adversarial loss: 0.491887\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082051; batch adversarial loss: 0.429606\n",
      "epoch 77; iter: 0; batch classifier loss: 0.059531; batch adversarial loss: 0.498908\n",
      "epoch 78; iter: 0; batch classifier loss: 0.045045; batch adversarial loss: 0.506837\n",
      "epoch 79; iter: 0; batch classifier loss: 0.095345; batch adversarial loss: 0.505974\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056675; batch adversarial loss: 0.438995\n",
      "epoch 81; iter: 0; batch classifier loss: 0.100508; batch adversarial loss: 0.535884\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073549; batch adversarial loss: 0.467798\n",
      "epoch 83; iter: 0; batch classifier loss: 0.058192; batch adversarial loss: 0.481399\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045126; batch adversarial loss: 0.429312\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065575; batch adversarial loss: 0.479613\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052545; batch adversarial loss: 0.520941\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068845; batch adversarial loss: 0.416352\n",
      "epoch 88; iter: 0; batch classifier loss: 0.111379; batch adversarial loss: 0.386074\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078663; batch adversarial loss: 0.557589\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056209; batch adversarial loss: 0.503148\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060009; batch adversarial loss: 0.438295\n",
      "epoch 92; iter: 0; batch classifier loss: 0.096927; batch adversarial loss: 0.458499\n",
      "epoch 93; iter: 0; batch classifier loss: 0.073112; batch adversarial loss: 0.435360\n",
      "epoch 94; iter: 0; batch classifier loss: 0.040191; batch adversarial loss: 0.458574\n",
      "epoch 95; iter: 0; batch classifier loss: 0.019045; batch adversarial loss: 0.437784\n",
      "epoch 96; iter: 0; batch classifier loss: 0.094664; batch adversarial loss: 0.424077\n",
      "epoch 97; iter: 0; batch classifier loss: 0.093454; batch adversarial loss: 0.574819\n",
      "epoch 98; iter: 0; batch classifier loss: 0.041636; batch adversarial loss: 0.459968\n",
      "epoch 99; iter: 0; batch classifier loss: 0.035405; batch adversarial loss: 0.527063\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035107; batch adversarial loss: 0.503186\n",
      "epoch 101; iter: 0; batch classifier loss: 0.090431; batch adversarial loss: 0.326992\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039239; batch adversarial loss: 0.359794\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038851; batch adversarial loss: 0.504726\n",
      "epoch 104; iter: 0; batch classifier loss: 0.072445; batch adversarial loss: 0.528295\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031111; batch adversarial loss: 0.478498\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054906; batch adversarial loss: 0.478397\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033401; batch adversarial loss: 0.524063\n",
      "epoch 108; iter: 0; batch classifier loss: 0.091323; batch adversarial loss: 0.430476\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030306; batch adversarial loss: 0.426909\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061549; batch adversarial loss: 0.364506\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040914; batch adversarial loss: 0.498107\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054356; batch adversarial loss: 0.456490\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048476; batch adversarial loss: 0.532906\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050815; batch adversarial loss: 0.464187\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048090; batch adversarial loss: 0.379499\n",
      "epoch 116; iter: 0; batch classifier loss: 0.089339; batch adversarial loss: 0.394890\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042952; batch adversarial loss: 0.444056\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031026; batch adversarial loss: 0.452497\n",
      "epoch 119; iter: 0; batch classifier loss: 0.024107; batch adversarial loss: 0.528030\n",
      "epoch 120; iter: 0; batch classifier loss: 0.071648; batch adversarial loss: 0.437341\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054610; batch adversarial loss: 0.503764\n",
      "epoch 122; iter: 0; batch classifier loss: 0.047610; batch adversarial loss: 0.513726\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047343; batch adversarial loss: 0.476612\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033800; batch adversarial loss: 0.385018\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028215; batch adversarial loss: 0.416012\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036799; batch adversarial loss: 0.532947\n",
      "epoch 127; iter: 0; batch classifier loss: 0.013803; batch adversarial loss: 0.415454\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017929; batch adversarial loss: 0.464455\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051874; batch adversarial loss: 0.514748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.034054; batch adversarial loss: 0.368430\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051637; batch adversarial loss: 0.360543\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024937; batch adversarial loss: 0.577497\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032613; batch adversarial loss: 0.437401\n",
      "epoch 134; iter: 0; batch classifier loss: 0.012062; batch adversarial loss: 0.549645\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039199; batch adversarial loss: 0.474354\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026538; batch adversarial loss: 0.458924\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040619; batch adversarial loss: 0.561080\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039168; batch adversarial loss: 0.470581\n",
      "epoch 139; iter: 0; batch classifier loss: 0.008466; batch adversarial loss: 0.457347\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036422; batch adversarial loss: 0.388498\n",
      "epoch 141; iter: 0; batch classifier loss: 0.013510; batch adversarial loss: 0.490383\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020076; batch adversarial loss: 0.426638\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016462; batch adversarial loss: 0.501544\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041164; batch adversarial loss: 0.443779\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027400; batch adversarial loss: 0.441558\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035570; batch adversarial loss: 0.427223\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032318; batch adversarial loss: 0.490211\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024002; batch adversarial loss: 0.484075\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022281; batch adversarial loss: 0.406017\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033658; batch adversarial loss: 0.485895\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018998; batch adversarial loss: 0.426681\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035278; batch adversarial loss: 0.315027\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012097; batch adversarial loss: 0.373048\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043110; batch adversarial loss: 0.427405\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029048; batch adversarial loss: 0.486377\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018366; batch adversarial loss: 0.451234\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020358; batch adversarial loss: 0.484370\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011222; batch adversarial loss: 0.424395\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031988; batch adversarial loss: 0.470787\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022681; batch adversarial loss: 0.395116\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020897; batch adversarial loss: 0.463834\n",
      "epoch 162; iter: 0; batch classifier loss: 0.061387; batch adversarial loss: 0.384897\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022396; batch adversarial loss: 0.549034\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010713; batch adversarial loss: 0.369810\n",
      "epoch 165; iter: 0; batch classifier loss: 0.006850; batch adversarial loss: 0.414333\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017820; batch adversarial loss: 0.512003\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015474; batch adversarial loss: 0.495675\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024949; batch adversarial loss: 0.462723\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029272; batch adversarial loss: 0.429970\n",
      "epoch 170; iter: 0; batch classifier loss: 0.046639; batch adversarial loss: 0.439816\n",
      "epoch 171; iter: 0; batch classifier loss: 0.042292; batch adversarial loss: 0.454595\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009868; batch adversarial loss: 0.453980\n",
      "epoch 173; iter: 0; batch classifier loss: 0.055914; batch adversarial loss: 0.489757\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012487; batch adversarial loss: 0.405728\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010723; batch adversarial loss: 0.453360\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025680; batch adversarial loss: 0.475481\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010998; batch adversarial loss: 0.445555\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012091; batch adversarial loss: 0.495680\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028247; batch adversarial loss: 0.545506\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017781; batch adversarial loss: 0.375935\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019253; batch adversarial loss: 0.481529\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026344; batch adversarial loss: 0.479323\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008367; batch adversarial loss: 0.429767\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011906; batch adversarial loss: 0.495202\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038446; batch adversarial loss: 0.464706\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011663; batch adversarial loss: 0.498041\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016201; batch adversarial loss: 0.488457\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018842; batch adversarial loss: 0.470974\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013514; batch adversarial loss: 0.465966\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025140; batch adversarial loss: 0.380586\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024579; batch adversarial loss: 0.523323\n",
      "epoch 192; iter: 0; batch classifier loss: 0.046974; batch adversarial loss: 0.426288\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012777; batch adversarial loss: 0.557673\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008905; batch adversarial loss: 0.440180\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010604; batch adversarial loss: 0.457292\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011557; batch adversarial loss: 0.519556\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016622; batch adversarial loss: 0.449380\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003342; batch adversarial loss: 0.568209\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027033; batch adversarial loss: 0.512398\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667356; batch adversarial loss: 0.672951\n",
      "epoch 1; iter: 0; batch classifier loss: 0.481830; batch adversarial loss: 0.662414\n",
      "epoch 2; iter: 0; batch classifier loss: 0.421269; batch adversarial loss: 0.630938\n",
      "epoch 3; iter: 0; batch classifier loss: 0.449202; batch adversarial loss: 0.636943\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559861; batch adversarial loss: 0.604293\n",
      "epoch 5; iter: 0; batch classifier loss: 0.517068; batch adversarial loss: 0.589096\n",
      "epoch 6; iter: 0; batch classifier loss: 0.440550; batch adversarial loss: 0.587323\n",
      "epoch 7; iter: 0; batch classifier loss: 0.463781; batch adversarial loss: 0.542364\n",
      "epoch 8; iter: 0; batch classifier loss: 0.453544; batch adversarial loss: 0.542786\n",
      "epoch 9; iter: 0; batch classifier loss: 0.381311; batch adversarial loss: 0.572582\n",
      "epoch 10; iter: 0; batch classifier loss: 0.389835; batch adversarial loss: 0.522449\n",
      "epoch 11; iter: 0; batch classifier loss: 0.379313; batch adversarial loss: 0.538275\n",
      "epoch 12; iter: 0; batch classifier loss: 0.415926; batch adversarial loss: 0.536121\n",
      "epoch 13; iter: 0; batch classifier loss: 0.392815; batch adversarial loss: 0.492567\n",
      "epoch 14; iter: 0; batch classifier loss: 0.332229; batch adversarial loss: 0.555583\n",
      "epoch 15; iter: 0; batch classifier loss: 0.304541; batch adversarial loss: 0.480477\n",
      "epoch 16; iter: 0; batch classifier loss: 0.271908; batch adversarial loss: 0.474946\n",
      "epoch 17; iter: 0; batch classifier loss: 0.226301; batch adversarial loss: 0.532965\n",
      "epoch 18; iter: 0; batch classifier loss: 0.276577; batch adversarial loss: 0.490202\n",
      "epoch 19; iter: 0; batch classifier loss: 0.302797; batch adversarial loss: 0.457225\n",
      "epoch 20; iter: 0; batch classifier loss: 0.254789; batch adversarial loss: 0.502974\n",
      "epoch 21; iter: 0; batch classifier loss: 0.174272; batch adversarial loss: 0.501775\n",
      "epoch 22; iter: 0; batch classifier loss: 0.182404; batch adversarial loss: 0.500233\n",
      "epoch 23; iter: 0; batch classifier loss: 0.287565; batch adversarial loss: 0.403869\n",
      "epoch 24; iter: 0; batch classifier loss: 0.325333; batch adversarial loss: 0.356950\n",
      "epoch 25; iter: 0; batch classifier loss: 0.262941; batch adversarial loss: 0.470624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.240078; batch adversarial loss: 0.473464\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241523; batch adversarial loss: 0.504354\n",
      "epoch 28; iter: 0; batch classifier loss: 0.273307; batch adversarial loss: 0.437084\n",
      "epoch 29; iter: 0; batch classifier loss: 0.195132; batch adversarial loss: 0.538219\n",
      "epoch 30; iter: 0; batch classifier loss: 0.245714; batch adversarial loss: 0.449890\n",
      "epoch 31; iter: 0; batch classifier loss: 0.242652; batch adversarial loss: 0.462883\n",
      "epoch 32; iter: 0; batch classifier loss: 0.194703; batch adversarial loss: 0.484928\n",
      "epoch 33; iter: 0; batch classifier loss: 0.222747; batch adversarial loss: 0.465028\n",
      "epoch 34; iter: 0; batch classifier loss: 0.196996; batch adversarial loss: 0.452838\n",
      "epoch 35; iter: 0; batch classifier loss: 0.223158; batch adversarial loss: 0.461844\n",
      "epoch 36; iter: 0; batch classifier loss: 0.224136; batch adversarial loss: 0.428004\n",
      "epoch 37; iter: 0; batch classifier loss: 0.233292; batch adversarial loss: 0.423295\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148485; batch adversarial loss: 0.466234\n",
      "epoch 39; iter: 0; batch classifier loss: 0.177764; batch adversarial loss: 0.512545\n",
      "epoch 40; iter: 0; batch classifier loss: 0.206894; batch adversarial loss: 0.556773\n",
      "epoch 41; iter: 0; batch classifier loss: 0.192043; batch adversarial loss: 0.466685\n",
      "epoch 42; iter: 0; batch classifier loss: 0.283159; batch adversarial loss: 0.460617\n",
      "epoch 43; iter: 0; batch classifier loss: 0.182402; batch adversarial loss: 0.453505\n",
      "epoch 44; iter: 0; batch classifier loss: 0.261439; batch adversarial loss: 0.509386\n",
      "epoch 45; iter: 0; batch classifier loss: 0.154025; batch adversarial loss: 0.472104\n",
      "epoch 46; iter: 0; batch classifier loss: 0.280278; batch adversarial loss: 0.449612\n",
      "epoch 47; iter: 0; batch classifier loss: 0.286637; batch adversarial loss: 0.469512\n",
      "epoch 48; iter: 0; batch classifier loss: 0.271437; batch adversarial loss: 0.339630\n",
      "epoch 49; iter: 0; batch classifier loss: 0.219880; batch adversarial loss: 0.504435\n",
      "epoch 50; iter: 0; batch classifier loss: 0.240044; batch adversarial loss: 0.445822\n",
      "epoch 51; iter: 0; batch classifier loss: 0.283898; batch adversarial loss: 0.410388\n",
      "epoch 52; iter: 0; batch classifier loss: 0.319316; batch adversarial loss: 0.412442\n",
      "epoch 53; iter: 0; batch classifier loss: 0.198874; batch adversarial loss: 0.480337\n",
      "epoch 54; iter: 0; batch classifier loss: 0.253244; batch adversarial loss: 0.541680\n",
      "epoch 55; iter: 0; batch classifier loss: 0.223082; batch adversarial loss: 0.369471\n",
      "epoch 56; iter: 0; batch classifier loss: 0.266656; batch adversarial loss: 0.352560\n",
      "epoch 57; iter: 0; batch classifier loss: 0.284337; batch adversarial loss: 0.412098\n",
      "epoch 58; iter: 0; batch classifier loss: 0.193946; batch adversarial loss: 0.531397\n",
      "epoch 59; iter: 0; batch classifier loss: 0.182028; batch adversarial loss: 0.374864\n",
      "epoch 60; iter: 0; batch classifier loss: 0.233214; batch adversarial loss: 0.435008\n",
      "epoch 61; iter: 0; batch classifier loss: 0.202048; batch adversarial loss: 0.398032\n",
      "epoch 62; iter: 0; batch classifier loss: 0.203374; batch adversarial loss: 0.543822\n",
      "epoch 63; iter: 0; batch classifier loss: 0.247903; batch adversarial loss: 0.493801\n",
      "epoch 64; iter: 0; batch classifier loss: 0.185912; batch adversarial loss: 0.484778\n",
      "epoch 65; iter: 0; batch classifier loss: 0.234151; batch adversarial loss: 0.362034\n",
      "epoch 66; iter: 0; batch classifier loss: 0.312466; batch adversarial loss: 0.460028\n",
      "epoch 67; iter: 0; batch classifier loss: 0.216717; batch adversarial loss: 0.411094\n",
      "epoch 68; iter: 0; batch classifier loss: 0.167658; batch adversarial loss: 0.494280\n",
      "epoch 69; iter: 0; batch classifier loss: 0.256976; batch adversarial loss: 0.434771\n",
      "epoch 70; iter: 0; batch classifier loss: 0.227453; batch adversarial loss: 0.506824\n",
      "epoch 71; iter: 0; batch classifier loss: 0.114145; batch adversarial loss: 0.481185\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072210; batch adversarial loss: 0.429253\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058706; batch adversarial loss: 0.415746\n",
      "epoch 74; iter: 0; batch classifier loss: 0.039924; batch adversarial loss: 0.489694\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069732; batch adversarial loss: 0.492192\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046310; batch adversarial loss: 0.439057\n",
      "epoch 77; iter: 0; batch classifier loss: 0.068771; batch adversarial loss: 0.416414\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061389; batch adversarial loss: 0.495795\n",
      "epoch 79; iter: 0; batch classifier loss: 0.079056; batch adversarial loss: 0.487274\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087656; batch adversarial loss: 0.452231\n",
      "epoch 81; iter: 0; batch classifier loss: 0.038803; batch adversarial loss: 0.411193\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063405; batch adversarial loss: 0.517741\n",
      "epoch 83; iter: 0; batch classifier loss: 0.039898; batch adversarial loss: 0.455993\n",
      "epoch 84; iter: 0; batch classifier loss: 0.063145; batch adversarial loss: 0.466399\n",
      "epoch 85; iter: 0; batch classifier loss: 0.053966; batch adversarial loss: 0.468766\n",
      "epoch 86; iter: 0; batch classifier loss: 0.038602; batch adversarial loss: 0.459473\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071443; batch adversarial loss: 0.464695\n",
      "epoch 88; iter: 0; batch classifier loss: 0.068436; batch adversarial loss: 0.342422\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054126; batch adversarial loss: 0.381640\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053325; batch adversarial loss: 0.488774\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063387; batch adversarial loss: 0.401724\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077527; batch adversarial loss: 0.467203\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056659; batch adversarial loss: 0.508003\n",
      "epoch 94; iter: 0; batch classifier loss: 0.057617; batch adversarial loss: 0.557954\n",
      "epoch 95; iter: 0; batch classifier loss: 0.041641; batch adversarial loss: 0.436844\n",
      "epoch 96; iter: 0; batch classifier loss: 0.029568; batch adversarial loss: 0.458487\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064995; batch adversarial loss: 0.374874\n",
      "epoch 98; iter: 0; batch classifier loss: 0.038488; batch adversarial loss: 0.404889\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074794; batch adversarial loss: 0.417036\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053872; batch adversarial loss: 0.337862\n",
      "epoch 101; iter: 0; batch classifier loss: 0.087235; batch adversarial loss: 0.466157\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034361; batch adversarial loss: 0.467503\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055045; batch adversarial loss: 0.346303\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046060; batch adversarial loss: 0.432197\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062561; batch adversarial loss: 0.416623\n",
      "epoch 106; iter: 0; batch classifier loss: 0.021899; batch adversarial loss: 0.481665\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055845; batch adversarial loss: 0.465627\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036431; batch adversarial loss: 0.436633\n",
      "epoch 109; iter: 0; batch classifier loss: 0.072108; batch adversarial loss: 0.341515\n",
      "epoch 110; iter: 0; batch classifier loss: 0.021950; batch adversarial loss: 0.467984\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059003; batch adversarial loss: 0.413640\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057646; batch adversarial loss: 0.467450\n",
      "epoch 113; iter: 0; batch classifier loss: 0.073237; batch adversarial loss: 0.513490\n",
      "epoch 114; iter: 0; batch classifier loss: 0.058646; batch adversarial loss: 0.379565\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039902; batch adversarial loss: 0.339697\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043322; batch adversarial loss: 0.477202\n",
      "epoch 117; iter: 0; batch classifier loss: 0.017454; batch adversarial loss: 0.440390\n",
      "epoch 118; iter: 0; batch classifier loss: 0.062371; batch adversarial loss: 0.419668\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035159; batch adversarial loss: 0.527663\n",
      "epoch 120; iter: 0; batch classifier loss: 0.098064; batch adversarial loss: 0.502133\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052688; batch adversarial loss: 0.364869\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066205; batch adversarial loss: 0.500912\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044719; batch adversarial loss: 0.375263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.045783; batch adversarial loss: 0.351579\n",
      "epoch 125; iter: 0; batch classifier loss: 0.059941; batch adversarial loss: 0.455856\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057342; batch adversarial loss: 0.429153\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045740; batch adversarial loss: 0.411776\n",
      "epoch 128; iter: 0; batch classifier loss: 0.050176; batch adversarial loss: 0.431709\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028954; batch adversarial loss: 0.432267\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044428; batch adversarial loss: 0.398030\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036365; batch adversarial loss: 0.485894\n",
      "epoch 132; iter: 0; batch classifier loss: 0.071461; batch adversarial loss: 0.402813\n",
      "epoch 133; iter: 0; batch classifier loss: 0.063525; batch adversarial loss: 0.391035\n",
      "epoch 134; iter: 0; batch classifier loss: 0.064337; batch adversarial loss: 0.389433\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039273; batch adversarial loss: 0.398395\n",
      "epoch 136; iter: 0; batch classifier loss: 0.061799; batch adversarial loss: 0.373014\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039891; batch adversarial loss: 0.524872\n",
      "epoch 138; iter: 0; batch classifier loss: 0.064977; batch adversarial loss: 0.504641\n",
      "epoch 139; iter: 0; batch classifier loss: 0.063088; batch adversarial loss: 0.325465\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024608; batch adversarial loss: 0.467221\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042342; batch adversarial loss: 0.562332\n",
      "epoch 142; iter: 0; batch classifier loss: 0.080427; batch adversarial loss: 0.429022\n",
      "epoch 143; iter: 0; batch classifier loss: 0.059820; batch adversarial loss: 0.408631\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045319; batch adversarial loss: 0.476740\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039598; batch adversarial loss: 0.431748\n",
      "epoch 146; iter: 0; batch classifier loss: 0.067205; batch adversarial loss: 0.498739\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032575; batch adversarial loss: 0.523598\n",
      "epoch 148; iter: 0; batch classifier loss: 0.084598; batch adversarial loss: 0.378914\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039130; batch adversarial loss: 0.437919\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044795; batch adversarial loss: 0.451321\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027510; batch adversarial loss: 0.476062\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039445; batch adversarial loss: 0.473516\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028770; batch adversarial loss: 0.391594\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026960; batch adversarial loss: 0.507986\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027301; batch adversarial loss: 0.464030\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042689; batch adversarial loss: 0.366811\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025456; batch adversarial loss: 0.485548\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026455; batch adversarial loss: 0.456192\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027551; batch adversarial loss: 0.402007\n",
      "epoch 160; iter: 0; batch classifier loss: 0.069988; batch adversarial loss: 0.416763\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024052; batch adversarial loss: 0.501951\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034587; batch adversarial loss: 0.486253\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018770; batch adversarial loss: 0.399222\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022019; batch adversarial loss: 0.407010\n",
      "epoch 165; iter: 0; batch classifier loss: 0.051856; batch adversarial loss: 0.388505\n",
      "epoch 166; iter: 0; batch classifier loss: 0.055680; batch adversarial loss: 0.411997\n",
      "epoch 167; iter: 0; batch classifier loss: 0.055026; batch adversarial loss: 0.538988\n",
      "epoch 168; iter: 0; batch classifier loss: 0.047864; batch adversarial loss: 0.471391\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028612; batch adversarial loss: 0.469074\n",
      "epoch 170; iter: 0; batch classifier loss: 0.043319; batch adversarial loss: 0.397484\n",
      "epoch 171; iter: 0; batch classifier loss: 0.065857; batch adversarial loss: 0.547217\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021902; batch adversarial loss: 0.411778\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025712; batch adversarial loss: 0.437108\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040638; batch adversarial loss: 0.418587\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018907; batch adversarial loss: 0.487202\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031051; batch adversarial loss: 0.378835\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034442; batch adversarial loss: 0.391774\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018572; batch adversarial loss: 0.418011\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037400; batch adversarial loss: 0.487140\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026188; batch adversarial loss: 0.397515\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020409; batch adversarial loss: 0.488863\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032711; batch adversarial loss: 0.447678\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027335; batch adversarial loss: 0.421540\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028349; batch adversarial loss: 0.464040\n",
      "epoch 185; iter: 0; batch classifier loss: 0.039942; batch adversarial loss: 0.349156\n",
      "epoch 186; iter: 0; batch classifier loss: 0.080097; batch adversarial loss: 0.445375\n",
      "epoch 187; iter: 0; batch classifier loss: 0.072837; batch adversarial loss: 0.424087\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022783; batch adversarial loss: 0.529415\n",
      "epoch 189; iter: 0; batch classifier loss: 0.045644; batch adversarial loss: 0.437905\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031791; batch adversarial loss: 0.457739\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018520; batch adversarial loss: 0.425563\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018486; batch adversarial loss: 0.562173\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027016; batch adversarial loss: 0.457642\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021670; batch adversarial loss: 0.522673\n",
      "epoch 195; iter: 0; batch classifier loss: 0.042551; batch adversarial loss: 0.463255\n",
      "epoch 196; iter: 0; batch classifier loss: 0.053910; batch adversarial loss: 0.383649\n",
      "epoch 197; iter: 0; batch classifier loss: 0.062730; batch adversarial loss: 0.490706\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019933; batch adversarial loss: 0.448321\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008236; batch adversarial loss: 0.453053\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696558; batch adversarial loss: 0.589229\n",
      "epoch 1; iter: 0; batch classifier loss: 0.426648; batch adversarial loss: 0.608115\n",
      "epoch 2; iter: 0; batch classifier loss: 0.363044; batch adversarial loss: 0.623654\n",
      "epoch 3; iter: 0; batch classifier loss: 0.363917; batch adversarial loss: 0.590723\n",
      "epoch 4; iter: 0; batch classifier loss: 0.390382; batch adversarial loss: 0.589180\n",
      "epoch 5; iter: 0; batch classifier loss: 0.413953; batch adversarial loss: 0.526041\n",
      "epoch 6; iter: 0; batch classifier loss: 0.402968; batch adversarial loss: 0.590112\n",
      "epoch 7; iter: 0; batch classifier loss: 0.388433; batch adversarial loss: 0.569775\n",
      "epoch 8; iter: 0; batch classifier loss: 0.505626; batch adversarial loss: 0.559478\n",
      "epoch 9; iter: 0; batch classifier loss: 0.572323; batch adversarial loss: 0.561171\n",
      "epoch 10; iter: 0; batch classifier loss: 0.587546; batch adversarial loss: 0.535480\n",
      "epoch 11; iter: 0; batch classifier loss: 0.480272; batch adversarial loss: 0.493846\n",
      "epoch 12; iter: 0; batch classifier loss: 0.390504; batch adversarial loss: 0.501085\n",
      "epoch 13; iter: 0; batch classifier loss: 0.298698; batch adversarial loss: 0.566162\n",
      "epoch 14; iter: 0; batch classifier loss: 0.345796; batch adversarial loss: 0.514737\n",
      "epoch 15; iter: 0; batch classifier loss: 0.316425; batch adversarial loss: 0.487699\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243223; batch adversarial loss: 0.473286\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269810; batch adversarial loss: 0.491829\n",
      "epoch 18; iter: 0; batch classifier loss: 0.244676; batch adversarial loss: 0.454182\n",
      "epoch 19; iter: 0; batch classifier loss: 0.258051; batch adversarial loss: 0.448581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.164892; batch adversarial loss: 0.528077\n",
      "epoch 21; iter: 0; batch classifier loss: 0.227843; batch adversarial loss: 0.475616\n",
      "epoch 22; iter: 0; batch classifier loss: 0.236669; batch adversarial loss: 0.462821\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175504; batch adversarial loss: 0.498627\n",
      "epoch 24; iter: 0; batch classifier loss: 0.206828; batch adversarial loss: 0.451586\n",
      "epoch 25; iter: 0; batch classifier loss: 0.185108; batch adversarial loss: 0.447129\n",
      "epoch 26; iter: 0; batch classifier loss: 0.159928; batch adversarial loss: 0.555704\n",
      "epoch 27; iter: 0; batch classifier loss: 0.238209; batch adversarial loss: 0.438207\n",
      "epoch 28; iter: 0; batch classifier loss: 0.164112; batch adversarial loss: 0.526672\n",
      "epoch 29; iter: 0; batch classifier loss: 0.187887; batch adversarial loss: 0.460879\n",
      "epoch 30; iter: 0; batch classifier loss: 0.183503; batch adversarial loss: 0.474175\n",
      "epoch 31; iter: 0; batch classifier loss: 0.183302; batch adversarial loss: 0.358553\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154567; batch adversarial loss: 0.445269\n",
      "epoch 33; iter: 0; batch classifier loss: 0.157534; batch adversarial loss: 0.514665\n",
      "epoch 34; iter: 0; batch classifier loss: 0.236756; batch adversarial loss: 0.397823\n",
      "epoch 35; iter: 0; batch classifier loss: 0.168267; batch adversarial loss: 0.463262\n",
      "epoch 36; iter: 0; batch classifier loss: 0.180982; batch adversarial loss: 0.360650\n",
      "epoch 37; iter: 0; batch classifier loss: 0.159911; batch adversarial loss: 0.410972\n",
      "epoch 38; iter: 0; batch classifier loss: 0.193684; batch adversarial loss: 0.479225\n",
      "epoch 39; iter: 0; batch classifier loss: 0.173653; batch adversarial loss: 0.403554\n",
      "epoch 40; iter: 0; batch classifier loss: 0.122266; batch adversarial loss: 0.444064\n",
      "epoch 41; iter: 0; batch classifier loss: 0.181058; batch adversarial loss: 0.515325\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146271; batch adversarial loss: 0.389097\n",
      "epoch 43; iter: 0; batch classifier loss: 0.132929; batch adversarial loss: 0.462990\n",
      "epoch 44; iter: 0; batch classifier loss: 0.135457; batch adversarial loss: 0.414573\n",
      "epoch 45; iter: 0; batch classifier loss: 0.129294; batch adversarial loss: 0.461622\n",
      "epoch 46; iter: 0; batch classifier loss: 0.130461; batch adversarial loss: 0.432947\n",
      "epoch 47; iter: 0; batch classifier loss: 0.116797; batch adversarial loss: 0.594492\n",
      "epoch 48; iter: 0; batch classifier loss: 0.095381; batch adversarial loss: 0.478430\n",
      "epoch 49; iter: 0; batch classifier loss: 0.135451; batch adversarial loss: 0.371702\n",
      "epoch 50; iter: 0; batch classifier loss: 0.118151; batch adversarial loss: 0.474664\n",
      "epoch 51; iter: 0; batch classifier loss: 0.158357; batch adversarial loss: 0.407847\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103258; batch adversarial loss: 0.449778\n",
      "epoch 53; iter: 0; batch classifier loss: 0.187200; batch adversarial loss: 0.562288\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116983; batch adversarial loss: 0.608813\n",
      "epoch 55; iter: 0; batch classifier loss: 0.149667; batch adversarial loss: 0.392241\n",
      "epoch 56; iter: 0; batch classifier loss: 0.131471; batch adversarial loss: 0.455826\n",
      "epoch 57; iter: 0; batch classifier loss: 0.087007; batch adversarial loss: 0.382013\n",
      "epoch 58; iter: 0; batch classifier loss: 0.108721; batch adversarial loss: 0.379338\n",
      "epoch 59; iter: 0; batch classifier loss: 0.147696; batch adversarial loss: 0.422409\n",
      "epoch 60; iter: 0; batch classifier loss: 0.126539; batch adversarial loss: 0.420911\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088972; batch adversarial loss: 0.535500\n",
      "epoch 62; iter: 0; batch classifier loss: 0.171518; batch adversarial loss: 0.438746\n",
      "epoch 63; iter: 0; batch classifier loss: 0.113264; batch adversarial loss: 0.379627\n",
      "epoch 64; iter: 0; batch classifier loss: 0.118073; batch adversarial loss: 0.397697\n",
      "epoch 65; iter: 0; batch classifier loss: 0.123814; batch adversarial loss: 0.428583\n",
      "epoch 66; iter: 0; batch classifier loss: 0.077930; batch adversarial loss: 0.433389\n",
      "epoch 67; iter: 0; batch classifier loss: 0.083613; batch adversarial loss: 0.366139\n",
      "epoch 68; iter: 0; batch classifier loss: 0.095623; batch adversarial loss: 0.447250\n",
      "epoch 69; iter: 0; batch classifier loss: 0.068563; batch adversarial loss: 0.366955\n",
      "epoch 70; iter: 0; batch classifier loss: 0.108726; batch adversarial loss: 0.454115\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092057; batch adversarial loss: 0.393335\n",
      "epoch 72; iter: 0; batch classifier loss: 0.099231; batch adversarial loss: 0.308732\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055874; batch adversarial loss: 0.465346\n",
      "epoch 74; iter: 0; batch classifier loss: 0.097339; batch adversarial loss: 0.506362\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071153; batch adversarial loss: 0.441650\n",
      "epoch 76; iter: 0; batch classifier loss: 0.094009; batch adversarial loss: 0.415809\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084154; batch adversarial loss: 0.419780\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066325; batch adversarial loss: 0.547996\n",
      "epoch 79; iter: 0; batch classifier loss: 0.113636; batch adversarial loss: 0.428834\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084470; batch adversarial loss: 0.437419\n",
      "epoch 81; iter: 0; batch classifier loss: 0.117786; batch adversarial loss: 0.425916\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072958; batch adversarial loss: 0.381412\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078076; batch adversarial loss: 0.413664\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075787; batch adversarial loss: 0.405972\n",
      "epoch 85; iter: 0; batch classifier loss: 0.097491; batch adversarial loss: 0.515180\n",
      "epoch 86; iter: 0; batch classifier loss: 0.095407; batch adversarial loss: 0.429514\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054694; batch adversarial loss: 0.449198\n",
      "epoch 88; iter: 0; batch classifier loss: 0.102514; batch adversarial loss: 0.396574\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068210; batch adversarial loss: 0.529923\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051147; batch adversarial loss: 0.490556\n",
      "epoch 91; iter: 0; batch classifier loss: 0.112331; batch adversarial loss: 0.445155\n",
      "epoch 92; iter: 0; batch classifier loss: 0.108150; batch adversarial loss: 0.466415\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046110; batch adversarial loss: 0.500474\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049579; batch adversarial loss: 0.407797\n",
      "epoch 95; iter: 0; batch classifier loss: 0.035528; batch adversarial loss: 0.376359\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041959; batch adversarial loss: 0.458696\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055727; batch adversarial loss: 0.374443\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067302; batch adversarial loss: 0.416429\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037498; batch adversarial loss: 0.513124\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048642; batch adversarial loss: 0.398223\n",
      "epoch 101; iter: 0; batch classifier loss: 0.036296; batch adversarial loss: 0.422401\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033550; batch adversarial loss: 0.527163\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040250; batch adversarial loss: 0.456056\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058697; batch adversarial loss: 0.426667\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030280; batch adversarial loss: 0.409815\n",
      "epoch 106; iter: 0; batch classifier loss: 0.075933; batch adversarial loss: 0.467828\n",
      "epoch 107; iter: 0; batch classifier loss: 0.023965; batch adversarial loss: 0.528820\n",
      "epoch 108; iter: 0; batch classifier loss: 0.086810; batch adversarial loss: 0.485955\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039767; batch adversarial loss: 0.495941\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058240; batch adversarial loss: 0.457255\n",
      "epoch 111; iter: 0; batch classifier loss: 0.065094; batch adversarial loss: 0.456302\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051003; batch adversarial loss: 0.350070\n",
      "epoch 113; iter: 0; batch classifier loss: 0.016141; batch adversarial loss: 0.343263\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045781; batch adversarial loss: 0.404014\n",
      "epoch 115; iter: 0; batch classifier loss: 0.012459; batch adversarial loss: 0.469456\n",
      "epoch 116; iter: 0; batch classifier loss: 0.015649; batch adversarial loss: 0.500941\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034613; batch adversarial loss: 0.334304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.043906; batch adversarial loss: 0.452165\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030863; batch adversarial loss: 0.492687\n",
      "epoch 120; iter: 0; batch classifier loss: 0.071559; batch adversarial loss: 0.439534\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021480; batch adversarial loss: 0.392027\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050282; batch adversarial loss: 0.438653\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043079; batch adversarial loss: 0.442655\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043072; batch adversarial loss: 0.386653\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036709; batch adversarial loss: 0.505508\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022615; batch adversarial loss: 0.501455\n",
      "epoch 127; iter: 0; batch classifier loss: 0.038007; batch adversarial loss: 0.537487\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032708; batch adversarial loss: 0.405554\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027968; batch adversarial loss: 0.455160\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038870; batch adversarial loss: 0.487902\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034086; batch adversarial loss: 0.423156\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016955; batch adversarial loss: 0.484212\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029357; batch adversarial loss: 0.419894\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036903; batch adversarial loss: 0.437441\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023466; batch adversarial loss: 0.425629\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033534; batch adversarial loss: 0.419648\n",
      "epoch 137; iter: 0; batch classifier loss: 0.008162; batch adversarial loss: 0.523268\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044549; batch adversarial loss: 0.469104\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019313; batch adversarial loss: 0.469916\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021425; batch adversarial loss: 0.481232\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025982; batch adversarial loss: 0.438956\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025323; batch adversarial loss: 0.455567\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028774; batch adversarial loss: 0.417194\n",
      "epoch 144; iter: 0; batch classifier loss: 0.046526; batch adversarial loss: 0.426439\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016045; batch adversarial loss: 0.500277\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021500; batch adversarial loss: 0.485423\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017339; batch adversarial loss: 0.462930\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029735; batch adversarial loss: 0.517490\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039188; batch adversarial loss: 0.478156\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012275; batch adversarial loss: 0.425880\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016638; batch adversarial loss: 0.429323\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016568; batch adversarial loss: 0.395164\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010859; batch adversarial loss: 0.482765\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023571; batch adversarial loss: 0.418125\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036535; batch adversarial loss: 0.479105\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019181; batch adversarial loss: 0.420464\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031456; batch adversarial loss: 0.441942\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016684; batch adversarial loss: 0.386700\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010440; batch adversarial loss: 0.433615\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013379; batch adversarial loss: 0.450914\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020507; batch adversarial loss: 0.507425\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007467; batch adversarial loss: 0.500218\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016542; batch adversarial loss: 0.391833\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018549; batch adversarial loss: 0.472043\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030376; batch adversarial loss: 0.457420\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018726; batch adversarial loss: 0.533865\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041000; batch adversarial loss: 0.351854\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014388; batch adversarial loss: 0.437481\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016430; batch adversarial loss: 0.417910\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007178; batch adversarial loss: 0.496874\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025452; batch adversarial loss: 0.472974\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006812; batch adversarial loss: 0.408941\n",
      "epoch 173; iter: 0; batch classifier loss: 0.047995; batch adversarial loss: 0.434573\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017807; batch adversarial loss: 0.476240\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009886; batch adversarial loss: 0.477511\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023672; batch adversarial loss: 0.446257\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006255; batch adversarial loss: 0.361189\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010057; batch adversarial loss: 0.483137\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009338; batch adversarial loss: 0.469818\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023070; batch adversarial loss: 0.476067\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012055; batch adversarial loss: 0.425160\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030937; batch adversarial loss: 0.427532\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016728; batch adversarial loss: 0.420244\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032084; batch adversarial loss: 0.379383\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021571; batch adversarial loss: 0.322656\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024538; batch adversarial loss: 0.461902\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030605; batch adversarial loss: 0.458769\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018707; batch adversarial loss: 0.568787\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031291; batch adversarial loss: 0.510957\n",
      "epoch 190; iter: 0; batch classifier loss: 0.045867; batch adversarial loss: 0.479725\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013302; batch adversarial loss: 0.424924\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015418; batch adversarial loss: 0.548019\n",
      "epoch 193; iter: 0; batch classifier loss: 0.003496; batch adversarial loss: 0.455831\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014870; batch adversarial loss: 0.471774\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013330; batch adversarial loss: 0.390207\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016251; batch adversarial loss: 0.489197\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022158; batch adversarial loss: 0.405824\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015886; batch adversarial loss: 0.416368\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010465; batch adversarial loss: 0.463660\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698465; batch adversarial loss: 0.570974\n",
      "epoch 1; iter: 0; batch classifier loss: 0.411740; batch adversarial loss: 0.598261\n",
      "epoch 2; iter: 0; batch classifier loss: 0.360068; batch adversarial loss: 0.596412\n",
      "epoch 3; iter: 0; batch classifier loss: 0.321535; batch adversarial loss: 0.555427\n",
      "epoch 4; iter: 0; batch classifier loss: 0.347840; batch adversarial loss: 0.569150\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313004; batch adversarial loss: 0.573787\n",
      "epoch 6; iter: 0; batch classifier loss: 0.359584; batch adversarial loss: 0.522674\n",
      "epoch 7; iter: 0; batch classifier loss: 0.271217; batch adversarial loss: 0.555900\n",
      "epoch 8; iter: 0; batch classifier loss: 0.391702; batch adversarial loss: 0.574786\n",
      "epoch 9; iter: 0; batch classifier loss: 0.471945; batch adversarial loss: 0.583576\n",
      "epoch 10; iter: 0; batch classifier loss: 0.445224; batch adversarial loss: 0.516679\n",
      "epoch 11; iter: 0; batch classifier loss: 0.581370; batch adversarial loss: 0.546219\n",
      "epoch 12; iter: 0; batch classifier loss: 0.513535; batch adversarial loss: 0.571902\n",
      "epoch 13; iter: 0; batch classifier loss: 0.478903; batch adversarial loss: 0.506243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.366362; batch adversarial loss: 0.486266\n",
      "epoch 15; iter: 0; batch classifier loss: 0.234506; batch adversarial loss: 0.493291\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222494; batch adversarial loss: 0.554409\n",
      "epoch 17; iter: 0; batch classifier loss: 0.188085; batch adversarial loss: 0.523674\n",
      "epoch 18; iter: 0; batch classifier loss: 0.213455; batch adversarial loss: 0.436486\n",
      "epoch 19; iter: 0; batch classifier loss: 0.200407; batch adversarial loss: 0.485727\n",
      "epoch 20; iter: 0; batch classifier loss: 0.147132; batch adversarial loss: 0.505563\n",
      "epoch 21; iter: 0; batch classifier loss: 0.161223; batch adversarial loss: 0.548317\n",
      "epoch 22; iter: 0; batch classifier loss: 0.163554; batch adversarial loss: 0.449610\n",
      "epoch 23; iter: 0; batch classifier loss: 0.169278; batch adversarial loss: 0.399038\n",
      "epoch 24; iter: 0; batch classifier loss: 0.160421; batch adversarial loss: 0.452732\n",
      "epoch 25; iter: 0; batch classifier loss: 0.100678; batch adversarial loss: 0.422259\n",
      "epoch 26; iter: 0; batch classifier loss: 0.139617; batch adversarial loss: 0.365726\n",
      "epoch 27; iter: 0; batch classifier loss: 0.128978; batch adversarial loss: 0.444389\n",
      "epoch 28; iter: 0; batch classifier loss: 0.236236; batch adversarial loss: 0.404865\n",
      "epoch 29; iter: 0; batch classifier loss: 0.217952; batch adversarial loss: 0.399235\n",
      "epoch 30; iter: 0; batch classifier loss: 0.146449; batch adversarial loss: 0.477312\n",
      "epoch 31; iter: 0; batch classifier loss: 0.200174; batch adversarial loss: 0.579652\n",
      "epoch 32; iter: 0; batch classifier loss: 0.112648; batch adversarial loss: 0.438457\n",
      "epoch 33; iter: 0; batch classifier loss: 0.137830; batch adversarial loss: 0.443403\n",
      "epoch 34; iter: 0; batch classifier loss: 0.143074; batch adversarial loss: 0.355854\n",
      "epoch 35; iter: 0; batch classifier loss: 0.132360; batch adversarial loss: 0.463455\n",
      "epoch 36; iter: 0; batch classifier loss: 0.167907; batch adversarial loss: 0.393469\n",
      "epoch 37; iter: 0; batch classifier loss: 0.117246; batch adversarial loss: 0.476982\n",
      "epoch 38; iter: 0; batch classifier loss: 0.133105; batch adversarial loss: 0.498131\n",
      "epoch 39; iter: 0; batch classifier loss: 0.136188; batch adversarial loss: 0.463522\n",
      "epoch 40; iter: 0; batch classifier loss: 0.162268; batch adversarial loss: 0.348176\n",
      "epoch 41; iter: 0; batch classifier loss: 0.179110; batch adversarial loss: 0.535738\n",
      "epoch 42; iter: 0; batch classifier loss: 0.190641; batch adversarial loss: 0.551841\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112726; batch adversarial loss: 0.429365\n",
      "epoch 44; iter: 0; batch classifier loss: 0.114582; batch adversarial loss: 0.538895\n",
      "epoch 45; iter: 0; batch classifier loss: 0.148111; batch adversarial loss: 0.510854\n",
      "epoch 46; iter: 0; batch classifier loss: 0.125291; batch adversarial loss: 0.381726\n",
      "epoch 47; iter: 0; batch classifier loss: 0.127293; batch adversarial loss: 0.389346\n",
      "epoch 48; iter: 0; batch classifier loss: 0.196569; batch adversarial loss: 0.511959\n",
      "epoch 49; iter: 0; batch classifier loss: 0.159967; batch adversarial loss: 0.531737\n",
      "epoch 50; iter: 0; batch classifier loss: 0.148654; batch adversarial loss: 0.454705\n",
      "epoch 51; iter: 0; batch classifier loss: 0.155070; batch adversarial loss: 0.506446\n",
      "epoch 52; iter: 0; batch classifier loss: 0.198973; batch adversarial loss: 0.454081\n",
      "epoch 53; iter: 0; batch classifier loss: 0.123037; batch adversarial loss: 0.442255\n",
      "epoch 54; iter: 0; batch classifier loss: 0.166423; batch adversarial loss: 0.431597\n",
      "epoch 55; iter: 0; batch classifier loss: 0.197403; batch adversarial loss: 0.444400\n",
      "epoch 56; iter: 0; batch classifier loss: 0.264849; batch adversarial loss: 0.406829\n",
      "epoch 57; iter: 0; batch classifier loss: 0.143177; batch adversarial loss: 0.557326\n",
      "epoch 58; iter: 0; batch classifier loss: 0.170737; batch adversarial loss: 0.460505\n",
      "epoch 59; iter: 0; batch classifier loss: 0.178295; batch adversarial loss: 0.527825\n",
      "epoch 60; iter: 0; batch classifier loss: 0.226062; batch adversarial loss: 0.468630\n",
      "epoch 61; iter: 0; batch classifier loss: 0.210398; batch adversarial loss: 0.480072\n",
      "epoch 62; iter: 0; batch classifier loss: 0.203666; batch adversarial loss: 0.423946\n",
      "epoch 63; iter: 0; batch classifier loss: 0.167648; batch adversarial loss: 0.409550\n",
      "epoch 64; iter: 0; batch classifier loss: 0.150800; batch adversarial loss: 0.545283\n",
      "epoch 65; iter: 0; batch classifier loss: 0.239413; batch adversarial loss: 0.401960\n",
      "epoch 66; iter: 0; batch classifier loss: 0.212087; batch adversarial loss: 0.530522\n",
      "epoch 67; iter: 0; batch classifier loss: 0.162657; batch adversarial loss: 0.407837\n",
      "epoch 68; iter: 0; batch classifier loss: 0.210221; batch adversarial loss: 0.496799\n",
      "epoch 69; iter: 0; batch classifier loss: 0.219015; batch adversarial loss: 0.438670\n",
      "epoch 70; iter: 0; batch classifier loss: 0.184286; batch adversarial loss: 0.448595\n",
      "epoch 71; iter: 0; batch classifier loss: 0.191878; batch adversarial loss: 0.484645\n",
      "epoch 72; iter: 0; batch classifier loss: 0.182580; batch adversarial loss: 0.449277\n",
      "epoch 73; iter: 0; batch classifier loss: 0.190928; batch adversarial loss: 0.519209\n",
      "epoch 74; iter: 0; batch classifier loss: 0.212378; batch adversarial loss: 0.458033\n",
      "epoch 75; iter: 0; batch classifier loss: 0.229010; batch adversarial loss: 0.483995\n",
      "epoch 76; iter: 0; batch classifier loss: 0.180467; batch adversarial loss: 0.482917\n",
      "epoch 77; iter: 0; batch classifier loss: 0.249878; batch adversarial loss: 0.422556\n",
      "epoch 78; iter: 0; batch classifier loss: 0.206185; batch adversarial loss: 0.434838\n",
      "epoch 79; iter: 0; batch classifier loss: 0.263629; batch adversarial loss: 0.495100\n",
      "epoch 80; iter: 0; batch classifier loss: 0.098673; batch adversarial loss: 0.518645\n",
      "epoch 81; iter: 0; batch classifier loss: 0.070330; batch adversarial loss: 0.491366\n",
      "epoch 82; iter: 0; batch classifier loss: 0.054262; batch adversarial loss: 0.553278\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065903; batch adversarial loss: 0.542889\n",
      "epoch 84; iter: 0; batch classifier loss: 0.087967; batch adversarial loss: 0.479187\n",
      "epoch 85; iter: 0; batch classifier loss: 0.072379; batch adversarial loss: 0.403067\n",
      "epoch 86; iter: 0; batch classifier loss: 0.048940; batch adversarial loss: 0.496247\n",
      "epoch 87; iter: 0; batch classifier loss: 0.080438; batch adversarial loss: 0.410114\n",
      "epoch 88; iter: 0; batch classifier loss: 0.081722; batch adversarial loss: 0.459318\n",
      "epoch 89; iter: 0; batch classifier loss: 0.158567; batch adversarial loss: 0.550175\n",
      "epoch 90; iter: 0; batch classifier loss: 0.071705; batch adversarial loss: 0.612372\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081450; batch adversarial loss: 0.563505\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077574; batch adversarial loss: 0.531813\n",
      "epoch 93; iter: 0; batch classifier loss: 0.109545; batch adversarial loss: 0.441100\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083496; batch adversarial loss: 0.487114\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064946; batch adversarial loss: 0.457575\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081783; batch adversarial loss: 0.452160\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062874; batch adversarial loss: 0.507318\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054514; batch adversarial loss: 0.528979\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058497; batch adversarial loss: 0.506151\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054402; batch adversarial loss: 0.468750\n",
      "epoch 101; iter: 0; batch classifier loss: 0.076457; batch adversarial loss: 0.382785\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060491; batch adversarial loss: 0.382878\n",
      "epoch 103; iter: 0; batch classifier loss: 0.025214; batch adversarial loss: 0.505468\n",
      "epoch 104; iter: 0; batch classifier loss: 0.092870; batch adversarial loss: 0.421999\n",
      "epoch 105; iter: 0; batch classifier loss: 0.093469; batch adversarial loss: 0.425844\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060244; batch adversarial loss: 0.438775\n",
      "epoch 107; iter: 0; batch classifier loss: 0.030155; batch adversarial loss: 0.472343\n",
      "epoch 108; iter: 0; batch classifier loss: 0.068949; batch adversarial loss: 0.442173\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067326; batch adversarial loss: 0.442365\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061342; batch adversarial loss: 0.379183\n",
      "epoch 111; iter: 0; batch classifier loss: 0.026602; batch adversarial loss: 0.601137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.034570; batch adversarial loss: 0.462437\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051987; batch adversarial loss: 0.458972\n",
      "epoch 114; iter: 0; batch classifier loss: 0.089342; batch adversarial loss: 0.439415\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043089; batch adversarial loss: 0.396331\n",
      "epoch 116; iter: 0; batch classifier loss: 0.085119; batch adversarial loss: 0.408187\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031540; batch adversarial loss: 0.444026\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051751; batch adversarial loss: 0.447192\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021986; batch adversarial loss: 0.461649\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050632; batch adversarial loss: 0.520790\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047545; batch adversarial loss: 0.427622\n",
      "epoch 122; iter: 0; batch classifier loss: 0.061301; batch adversarial loss: 0.436990\n",
      "epoch 123; iter: 0; batch classifier loss: 0.054775; batch adversarial loss: 0.413384\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022993; batch adversarial loss: 0.448612\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052791; batch adversarial loss: 0.397370\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037843; batch adversarial loss: 0.332390\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045538; batch adversarial loss: 0.446244\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024089; batch adversarial loss: 0.504787\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030600; batch adversarial loss: 0.490734\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020007; batch adversarial loss: 0.425873\n",
      "epoch 131; iter: 0; batch classifier loss: 0.013688; batch adversarial loss: 0.469703\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023819; batch adversarial loss: 0.539031\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025805; batch adversarial loss: 0.494981\n",
      "epoch 134; iter: 0; batch classifier loss: 0.047490; batch adversarial loss: 0.518072\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026027; batch adversarial loss: 0.461238\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030831; batch adversarial loss: 0.451310\n",
      "epoch 137; iter: 0; batch classifier loss: 0.099324; batch adversarial loss: 0.471131\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032476; batch adversarial loss: 0.334947\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040950; batch adversarial loss: 0.412089\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023412; batch adversarial loss: 0.419300\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017524; batch adversarial loss: 0.511409\n",
      "epoch 142; iter: 0; batch classifier loss: 0.055913; batch adversarial loss: 0.455821\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032966; batch adversarial loss: 0.501519\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019406; batch adversarial loss: 0.590513\n",
      "epoch 145; iter: 0; batch classifier loss: 0.049158; batch adversarial loss: 0.439423\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021476; batch adversarial loss: 0.492030\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037117; batch adversarial loss: 0.432356\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046270; batch adversarial loss: 0.473980\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053567; batch adversarial loss: 0.451747\n",
      "epoch 150; iter: 0; batch classifier loss: 0.049661; batch adversarial loss: 0.428193\n",
      "epoch 151; iter: 0; batch classifier loss: 0.060201; batch adversarial loss: 0.403994\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014772; batch adversarial loss: 0.483946\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019785; batch adversarial loss: 0.503704\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033424; batch adversarial loss: 0.414127\n",
      "epoch 155; iter: 0; batch classifier loss: 0.003973; batch adversarial loss: 0.453194\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031080; batch adversarial loss: 0.432498\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029995; batch adversarial loss: 0.386809\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013142; batch adversarial loss: 0.522099\n",
      "epoch 159; iter: 0; batch classifier loss: 0.009900; batch adversarial loss: 0.381360\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023501; batch adversarial loss: 0.487767\n",
      "epoch 161; iter: 0; batch classifier loss: 0.052943; batch adversarial loss: 0.492728\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019596; batch adversarial loss: 0.469925\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020025; batch adversarial loss: 0.432675\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009468; batch adversarial loss: 0.438683\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032382; batch adversarial loss: 0.513865\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012711; batch adversarial loss: 0.592105\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013103; batch adversarial loss: 0.396462\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010851; batch adversarial loss: 0.426476\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010474; batch adversarial loss: 0.478379\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039866; batch adversarial loss: 0.421261\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009515; batch adversarial loss: 0.478363\n",
      "epoch 172; iter: 0; batch classifier loss: 0.004702; batch adversarial loss: 0.596084\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030158; batch adversarial loss: 0.472929\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013820; batch adversarial loss: 0.369220\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012573; batch adversarial loss: 0.430928\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009193; batch adversarial loss: 0.402578\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012593; batch adversarial loss: 0.438659\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019670; batch adversarial loss: 0.537193\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044911; batch adversarial loss: 0.516669\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013804; batch adversarial loss: 0.423749\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017313; batch adversarial loss: 0.433826\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021257; batch adversarial loss: 0.418376\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015525; batch adversarial loss: 0.519258\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009798; batch adversarial loss: 0.424450\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022434; batch adversarial loss: 0.478602\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027268; batch adversarial loss: 0.371961\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027637; batch adversarial loss: 0.474362\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023895; batch adversarial loss: 0.380046\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007472; batch adversarial loss: 0.458894\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011127; batch adversarial loss: 0.499521\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011669; batch adversarial loss: 0.490912\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026341; batch adversarial loss: 0.553305\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008859; batch adversarial loss: 0.478381\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014658; batch adversarial loss: 0.448549\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008596; batch adversarial loss: 0.473672\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016484; batch adversarial loss: 0.502505\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011230; batch adversarial loss: 0.388399\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010276; batch adversarial loss: 0.469252\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005671; batch adversarial loss: 0.433015\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692738; batch adversarial loss: 0.857233\n",
      "epoch 1; iter: 0; batch classifier loss: 0.541767; batch adversarial loss: 0.874269\n",
      "epoch 2; iter: 0; batch classifier loss: 0.826361; batch adversarial loss: 0.899868\n",
      "epoch 3; iter: 0; batch classifier loss: 1.015799; batch adversarial loss: 0.849198\n",
      "epoch 4; iter: 0; batch classifier loss: 0.851939; batch adversarial loss: 0.729470\n",
      "epoch 5; iter: 0; batch classifier loss: 0.677842; batch adversarial loss: 0.669515\n",
      "epoch 6; iter: 0; batch classifier loss: 0.645691; batch adversarial loss: 0.613302\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493306; batch adversarial loss: 0.572315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.355939; batch adversarial loss: 0.544622\n",
      "epoch 9; iter: 0; batch classifier loss: 0.286664; batch adversarial loss: 0.549911\n",
      "epoch 10; iter: 0; batch classifier loss: 0.341917; batch adversarial loss: 0.522180\n",
      "epoch 11; iter: 0; batch classifier loss: 0.376711; batch adversarial loss: 0.508132\n",
      "epoch 12; iter: 0; batch classifier loss: 0.368446; batch adversarial loss: 0.514568\n",
      "epoch 13; iter: 0; batch classifier loss: 0.365491; batch adversarial loss: 0.555413\n",
      "epoch 14; iter: 0; batch classifier loss: 0.268900; batch adversarial loss: 0.515161\n",
      "epoch 15; iter: 0; batch classifier loss: 0.254839; batch adversarial loss: 0.488368\n",
      "epoch 16; iter: 0; batch classifier loss: 0.301607; batch adversarial loss: 0.482758\n",
      "epoch 17; iter: 0; batch classifier loss: 0.257708; batch adversarial loss: 0.495349\n",
      "epoch 18; iter: 0; batch classifier loss: 0.232117; batch adversarial loss: 0.435602\n",
      "epoch 19; iter: 0; batch classifier loss: 0.278908; batch adversarial loss: 0.423407\n",
      "epoch 20; iter: 0; batch classifier loss: 0.252937; batch adversarial loss: 0.510987\n",
      "epoch 21; iter: 0; batch classifier loss: 0.192369; batch adversarial loss: 0.559542\n",
      "epoch 22; iter: 0; batch classifier loss: 0.238759; batch adversarial loss: 0.428798\n",
      "epoch 23; iter: 0; batch classifier loss: 0.238058; batch adversarial loss: 0.491964\n",
      "epoch 24; iter: 0; batch classifier loss: 0.242295; batch adversarial loss: 0.409100\n",
      "epoch 25; iter: 0; batch classifier loss: 0.233063; batch adversarial loss: 0.415809\n",
      "epoch 26; iter: 0; batch classifier loss: 0.162747; batch adversarial loss: 0.498209\n",
      "epoch 27; iter: 0; batch classifier loss: 0.199702; batch adversarial loss: 0.499635\n",
      "epoch 28; iter: 0; batch classifier loss: 0.170609; batch adversarial loss: 0.438167\n",
      "epoch 29; iter: 0; batch classifier loss: 0.131960; batch adversarial loss: 0.486099\n",
      "epoch 30; iter: 0; batch classifier loss: 0.185545; batch adversarial loss: 0.551845\n",
      "epoch 31; iter: 0; batch classifier loss: 0.096171; batch adversarial loss: 0.520980\n",
      "epoch 32; iter: 0; batch classifier loss: 0.182258; batch adversarial loss: 0.446764\n",
      "epoch 33; iter: 0; batch classifier loss: 0.164269; batch adversarial loss: 0.416476\n",
      "epoch 34; iter: 0; batch classifier loss: 0.221876; batch adversarial loss: 0.488272\n",
      "epoch 35; iter: 0; batch classifier loss: 0.114453; batch adversarial loss: 0.448458\n",
      "epoch 36; iter: 0; batch classifier loss: 0.118069; batch adversarial loss: 0.397295\n",
      "epoch 37; iter: 0; batch classifier loss: 0.104429; batch adversarial loss: 0.361039\n",
      "epoch 38; iter: 0; batch classifier loss: 0.113413; batch adversarial loss: 0.402684\n",
      "epoch 39; iter: 0; batch classifier loss: 0.198729; batch adversarial loss: 0.345982\n",
      "epoch 40; iter: 0; batch classifier loss: 0.120197; batch adversarial loss: 0.385830\n",
      "epoch 41; iter: 0; batch classifier loss: 0.151744; batch adversarial loss: 0.328393\n",
      "epoch 42; iter: 0; batch classifier loss: 0.092611; batch adversarial loss: 0.484563\n",
      "epoch 43; iter: 0; batch classifier loss: 0.170317; batch adversarial loss: 0.449256\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106060; batch adversarial loss: 0.474292\n",
      "epoch 45; iter: 0; batch classifier loss: 0.132305; batch adversarial loss: 0.348654\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117450; batch adversarial loss: 0.443997\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106264; batch adversarial loss: 0.446198\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100452; batch adversarial loss: 0.455756\n",
      "epoch 49; iter: 0; batch classifier loss: 0.136773; batch adversarial loss: 0.494690\n",
      "epoch 50; iter: 0; batch classifier loss: 0.075931; batch adversarial loss: 0.513680\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106589; batch adversarial loss: 0.525131\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111219; batch adversarial loss: 0.434811\n",
      "epoch 53; iter: 0; batch classifier loss: 0.090511; batch adversarial loss: 0.456843\n",
      "epoch 54; iter: 0; batch classifier loss: 0.106009; batch adversarial loss: 0.405196\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086162; batch adversarial loss: 0.504166\n",
      "epoch 56; iter: 0; batch classifier loss: 0.057104; batch adversarial loss: 0.527954\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095409; batch adversarial loss: 0.494258\n",
      "epoch 58; iter: 0; batch classifier loss: 0.050763; batch adversarial loss: 0.465640\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088344; batch adversarial loss: 0.447268\n",
      "epoch 60; iter: 0; batch classifier loss: 0.090468; batch adversarial loss: 0.511229\n",
      "epoch 61; iter: 0; batch classifier loss: 0.052794; batch adversarial loss: 0.495657\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080039; batch adversarial loss: 0.351565\n",
      "epoch 63; iter: 0; batch classifier loss: 0.072831; batch adversarial loss: 0.543253\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080823; batch adversarial loss: 0.493042\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065078; batch adversarial loss: 0.540283\n",
      "epoch 66; iter: 0; batch classifier loss: 0.067113; batch adversarial loss: 0.422527\n",
      "epoch 67; iter: 0; batch classifier loss: 0.118813; batch adversarial loss: 0.396797\n",
      "epoch 68; iter: 0; batch classifier loss: 0.098482; batch adversarial loss: 0.473081\n",
      "epoch 69; iter: 0; batch classifier loss: 0.079339; batch adversarial loss: 0.363593\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070270; batch adversarial loss: 0.528448\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083365; batch adversarial loss: 0.411078\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085304; batch adversarial loss: 0.400010\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081449; batch adversarial loss: 0.408120\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069509; batch adversarial loss: 0.380794\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076814; batch adversarial loss: 0.474855\n",
      "epoch 76; iter: 0; batch classifier loss: 0.071810; batch adversarial loss: 0.461735\n",
      "epoch 77; iter: 0; batch classifier loss: 0.078349; batch adversarial loss: 0.495578\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054678; batch adversarial loss: 0.422686\n",
      "epoch 79; iter: 0; batch classifier loss: 0.046289; batch adversarial loss: 0.435923\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061514; batch adversarial loss: 0.433190\n",
      "epoch 81; iter: 0; batch classifier loss: 0.028203; batch adversarial loss: 0.394928\n",
      "epoch 82; iter: 0; batch classifier loss: 0.094615; batch adversarial loss: 0.457056\n",
      "epoch 83; iter: 0; batch classifier loss: 0.043158; batch adversarial loss: 0.465136\n",
      "epoch 84; iter: 0; batch classifier loss: 0.058557; batch adversarial loss: 0.385922\n",
      "epoch 85; iter: 0; batch classifier loss: 0.086434; batch adversarial loss: 0.386411\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067401; batch adversarial loss: 0.409851\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046952; batch adversarial loss: 0.403553\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070667; batch adversarial loss: 0.423001\n",
      "epoch 89; iter: 0; batch classifier loss: 0.026635; batch adversarial loss: 0.469522\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073176; batch adversarial loss: 0.464350\n",
      "epoch 91; iter: 0; batch classifier loss: 0.049271; batch adversarial loss: 0.400928\n",
      "epoch 92; iter: 0; batch classifier loss: 0.046923; batch adversarial loss: 0.410845\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051854; batch adversarial loss: 0.408338\n",
      "epoch 94; iter: 0; batch classifier loss: 0.037137; batch adversarial loss: 0.414012\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042093; batch adversarial loss: 0.489617\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047363; batch adversarial loss: 0.432763\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049534; batch adversarial loss: 0.489241\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044441; batch adversarial loss: 0.504035\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048563; batch adversarial loss: 0.399085\n",
      "epoch 100; iter: 0; batch classifier loss: 0.042138; batch adversarial loss: 0.422075\n",
      "epoch 101; iter: 0; batch classifier loss: 0.025726; batch adversarial loss: 0.497198\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036687; batch adversarial loss: 0.413229\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060484; batch adversarial loss: 0.463263\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047941; batch adversarial loss: 0.345694\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058889; batch adversarial loss: 0.404641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.054844; batch adversarial loss: 0.518038\n",
      "epoch 107; iter: 0; batch classifier loss: 0.016809; batch adversarial loss: 0.435470\n",
      "epoch 108; iter: 0; batch classifier loss: 0.062791; batch adversarial loss: 0.398431\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040248; batch adversarial loss: 0.459528\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043593; batch adversarial loss: 0.443227\n",
      "epoch 111; iter: 0; batch classifier loss: 0.038727; batch adversarial loss: 0.450297\n",
      "epoch 112; iter: 0; batch classifier loss: 0.017176; batch adversarial loss: 0.463378\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031295; batch adversarial loss: 0.472322\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046617; batch adversarial loss: 0.472944\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027900; batch adversarial loss: 0.405237\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028512; batch adversarial loss: 0.467333\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035515; batch adversarial loss: 0.497689\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024136; batch adversarial loss: 0.449817\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037255; batch adversarial loss: 0.468904\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037768; batch adversarial loss: 0.473578\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036510; batch adversarial loss: 0.419618\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033717; batch adversarial loss: 0.436819\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031964; batch adversarial loss: 0.440100\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039028; batch adversarial loss: 0.411499\n",
      "epoch 125; iter: 0; batch classifier loss: 0.015629; batch adversarial loss: 0.440846\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036835; batch adversarial loss: 0.389998\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023357; batch adversarial loss: 0.496667\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038659; batch adversarial loss: 0.448520\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033061; batch adversarial loss: 0.505890\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040323; batch adversarial loss: 0.370644\n",
      "epoch 131; iter: 0; batch classifier loss: 0.061572; batch adversarial loss: 0.446762\n",
      "epoch 132; iter: 0; batch classifier loss: 0.009125; batch adversarial loss: 0.474700\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034266; batch adversarial loss: 0.486554\n",
      "epoch 134; iter: 0; batch classifier loss: 0.007783; batch adversarial loss: 0.551141\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029023; batch adversarial loss: 0.389514\n",
      "epoch 136; iter: 0; batch classifier loss: 0.010743; batch adversarial loss: 0.420109\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022738; batch adversarial loss: 0.419836\n",
      "epoch 138; iter: 0; batch classifier loss: 0.054390; batch adversarial loss: 0.447107\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046377; batch adversarial loss: 0.475587\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013301; batch adversarial loss: 0.401138\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029372; batch adversarial loss: 0.530222\n",
      "epoch 142; iter: 0; batch classifier loss: 0.009806; batch adversarial loss: 0.370019\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034512; batch adversarial loss: 0.325397\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022053; batch adversarial loss: 0.373732\n",
      "epoch 145; iter: 0; batch classifier loss: 0.055640; batch adversarial loss: 0.447094\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013926; batch adversarial loss: 0.397487\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039990; batch adversarial loss: 0.536967\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040348; batch adversarial loss: 0.401219\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013117; batch adversarial loss: 0.484267\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010932; batch adversarial loss: 0.427254\n",
      "epoch 151; iter: 0; batch classifier loss: 0.046881; batch adversarial loss: 0.462483\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015870; batch adversarial loss: 0.422635\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012878; batch adversarial loss: 0.472004\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030408; batch adversarial loss: 0.390456\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041949; batch adversarial loss: 0.442158\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024790; batch adversarial loss: 0.386347\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016194; batch adversarial loss: 0.394088\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011471; batch adversarial loss: 0.449164\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028901; batch adversarial loss: 0.466768\n",
      "epoch 160; iter: 0; batch classifier loss: 0.050612; batch adversarial loss: 0.469934\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012894; batch adversarial loss: 0.465227\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013835; batch adversarial loss: 0.384762\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026253; batch adversarial loss: 0.530650\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025432; batch adversarial loss: 0.458906\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020566; batch adversarial loss: 0.585302\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014989; batch adversarial loss: 0.475401\n",
      "epoch 167; iter: 0; batch classifier loss: 0.059364; batch adversarial loss: 0.349461\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027682; batch adversarial loss: 0.396135\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023831; batch adversarial loss: 0.492858\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020425; batch adversarial loss: 0.465258\n",
      "epoch 171; iter: 0; batch classifier loss: 0.006108; batch adversarial loss: 0.463179\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015434; batch adversarial loss: 0.428422\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033579; batch adversarial loss: 0.456527\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007077; batch adversarial loss: 0.425646\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016621; batch adversarial loss: 0.437047\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022494; batch adversarial loss: 0.438526\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019126; batch adversarial loss: 0.475860\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024301; batch adversarial loss: 0.393336\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040099; batch adversarial loss: 0.477789\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019024; batch adversarial loss: 0.444819\n",
      "epoch 181; iter: 0; batch classifier loss: 0.004005; batch adversarial loss: 0.517575\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008434; batch adversarial loss: 0.384428\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023646; batch adversarial loss: 0.454406\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026349; batch adversarial loss: 0.493206\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015494; batch adversarial loss: 0.397063\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032240; batch adversarial loss: 0.456748\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024943; batch adversarial loss: 0.444530\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014457; batch adversarial loss: 0.425527\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028587; batch adversarial loss: 0.368516\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011542; batch adversarial loss: 0.469193\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005343; batch adversarial loss: 0.510902\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007632; batch adversarial loss: 0.434438\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007008; batch adversarial loss: 0.473453\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018142; batch adversarial loss: 0.350207\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006435; batch adversarial loss: 0.395120\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028377; batch adversarial loss: 0.433521\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006092; batch adversarial loss: 0.370825\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039667; batch adversarial loss: 0.418994\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022649; batch adversarial loss: 0.387400\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700326; batch adversarial loss: 0.597195\n",
      "epoch 1; iter: 0; batch classifier loss: 0.451319; batch adversarial loss: 0.595467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.333681; batch adversarial loss: 0.585929\n",
      "epoch 3; iter: 0; batch classifier loss: 0.301217; batch adversarial loss: 0.604002\n",
      "epoch 4; iter: 0; batch classifier loss: 0.275295; batch adversarial loss: 0.546809\n",
      "epoch 5; iter: 0; batch classifier loss: 0.286800; batch adversarial loss: 0.619860\n",
      "epoch 6; iter: 0; batch classifier loss: 0.264123; batch adversarial loss: 0.452675\n",
      "epoch 7; iter: 0; batch classifier loss: 0.255686; batch adversarial loss: 0.478242\n",
      "epoch 8; iter: 0; batch classifier loss: 0.245153; batch adversarial loss: 0.558624\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282870; batch adversarial loss: 0.595058\n",
      "epoch 10; iter: 0; batch classifier loss: 0.317890; batch adversarial loss: 0.524056\n",
      "epoch 11; iter: 0; batch classifier loss: 0.334364; batch adversarial loss: 0.530859\n",
      "epoch 12; iter: 0; batch classifier loss: 0.232713; batch adversarial loss: 0.527435\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245335; batch adversarial loss: 0.516000\n",
      "epoch 14; iter: 0; batch classifier loss: 0.262722; batch adversarial loss: 0.549231\n",
      "epoch 15; iter: 0; batch classifier loss: 0.186717; batch adversarial loss: 0.570426\n",
      "epoch 16; iter: 0; batch classifier loss: 0.263954; batch adversarial loss: 0.548661\n",
      "epoch 17; iter: 0; batch classifier loss: 0.215103; batch adversarial loss: 0.517780\n",
      "epoch 18; iter: 0; batch classifier loss: 0.274243; batch adversarial loss: 0.560596\n",
      "epoch 19; iter: 0; batch classifier loss: 0.272198; batch adversarial loss: 0.591890\n",
      "epoch 20; iter: 0; batch classifier loss: 0.182146; batch adversarial loss: 0.522027\n",
      "epoch 21; iter: 0; batch classifier loss: 0.230975; batch adversarial loss: 0.446358\n",
      "epoch 22; iter: 0; batch classifier loss: 0.279513; batch adversarial loss: 0.459648\n",
      "epoch 23; iter: 0; batch classifier loss: 0.248339; batch adversarial loss: 0.521654\n",
      "epoch 24; iter: 0; batch classifier loss: 0.205238; batch adversarial loss: 0.431717\n",
      "epoch 25; iter: 0; batch classifier loss: 0.331244; batch adversarial loss: 0.549146\n",
      "epoch 26; iter: 0; batch classifier loss: 0.332669; batch adversarial loss: 0.389081\n",
      "epoch 27; iter: 0; batch classifier loss: 0.283124; batch adversarial loss: 0.484962\n",
      "epoch 28; iter: 0; batch classifier loss: 0.206886; batch adversarial loss: 0.519100\n",
      "epoch 29; iter: 0; batch classifier loss: 0.157454; batch adversarial loss: 0.461966\n",
      "epoch 30; iter: 0; batch classifier loss: 0.105031; batch adversarial loss: 0.435677\n",
      "epoch 31; iter: 0; batch classifier loss: 0.130492; batch adversarial loss: 0.429527\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146177; batch adversarial loss: 0.478218\n",
      "epoch 33; iter: 0; batch classifier loss: 0.129776; batch adversarial loss: 0.416794\n",
      "epoch 34; iter: 0; batch classifier loss: 0.123867; batch adversarial loss: 0.437930\n",
      "epoch 35; iter: 0; batch classifier loss: 0.109113; batch adversarial loss: 0.423841\n",
      "epoch 36; iter: 0; batch classifier loss: 0.108431; batch adversarial loss: 0.447899\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113181; batch adversarial loss: 0.447981\n",
      "epoch 38; iter: 0; batch classifier loss: 0.096651; batch adversarial loss: 0.456083\n",
      "epoch 39; iter: 0; batch classifier loss: 0.121255; batch adversarial loss: 0.429620\n",
      "epoch 40; iter: 0; batch classifier loss: 0.079162; batch adversarial loss: 0.470044\n",
      "epoch 41; iter: 0; batch classifier loss: 0.068562; batch adversarial loss: 0.513912\n",
      "epoch 42; iter: 0; batch classifier loss: 0.159031; batch adversarial loss: 0.379269\n",
      "epoch 43; iter: 0; batch classifier loss: 0.115013; batch adversarial loss: 0.547521\n",
      "epoch 44; iter: 0; batch classifier loss: 0.078032; batch adversarial loss: 0.487384\n",
      "epoch 45; iter: 0; batch classifier loss: 0.101274; batch adversarial loss: 0.448845\n",
      "epoch 46; iter: 0; batch classifier loss: 0.164250; batch adversarial loss: 0.428096\n",
      "epoch 47; iter: 0; batch classifier loss: 0.130178; batch adversarial loss: 0.426894\n",
      "epoch 48; iter: 0; batch classifier loss: 0.083554; batch adversarial loss: 0.420100\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129650; batch adversarial loss: 0.432264\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083849; batch adversarial loss: 0.474565\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106183; batch adversarial loss: 0.444917\n",
      "epoch 52; iter: 0; batch classifier loss: 0.118831; batch adversarial loss: 0.481766\n",
      "epoch 53; iter: 0; batch classifier loss: 0.090775; batch adversarial loss: 0.426606\n",
      "epoch 54; iter: 0; batch classifier loss: 0.124560; batch adversarial loss: 0.529528\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103108; batch adversarial loss: 0.472870\n",
      "epoch 56; iter: 0; batch classifier loss: 0.075618; batch adversarial loss: 0.421781\n",
      "epoch 57; iter: 0; batch classifier loss: 0.070589; batch adversarial loss: 0.466621\n",
      "epoch 58; iter: 0; batch classifier loss: 0.113717; batch adversarial loss: 0.486324\n",
      "epoch 59; iter: 0; batch classifier loss: 0.107594; batch adversarial loss: 0.453488\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076537; batch adversarial loss: 0.514931\n",
      "epoch 61; iter: 0; batch classifier loss: 0.086821; batch adversarial loss: 0.371635\n",
      "epoch 62; iter: 0; batch classifier loss: 0.146970; batch adversarial loss: 0.387872\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085587; batch adversarial loss: 0.410657\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090656; batch adversarial loss: 0.416427\n",
      "epoch 65; iter: 0; batch classifier loss: 0.094302; batch adversarial loss: 0.479448\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084169; batch adversarial loss: 0.488994\n",
      "epoch 67; iter: 0; batch classifier loss: 0.078836; batch adversarial loss: 0.370808\n",
      "epoch 68; iter: 0; batch classifier loss: 0.104354; batch adversarial loss: 0.449067\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071641; batch adversarial loss: 0.528409\n",
      "epoch 70; iter: 0; batch classifier loss: 0.109883; batch adversarial loss: 0.430102\n",
      "epoch 71; iter: 0; batch classifier loss: 0.049240; batch adversarial loss: 0.517604\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097845; batch adversarial loss: 0.462559\n",
      "epoch 73; iter: 0; batch classifier loss: 0.131136; batch adversarial loss: 0.572763\n",
      "epoch 74; iter: 0; batch classifier loss: 0.091435; batch adversarial loss: 0.490834\n",
      "epoch 75; iter: 0; batch classifier loss: 0.085801; batch adversarial loss: 0.544160\n",
      "epoch 76; iter: 0; batch classifier loss: 0.134312; batch adversarial loss: 0.455188\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065910; batch adversarial loss: 0.348094\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080115; batch adversarial loss: 0.530153\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068475; batch adversarial loss: 0.379818\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078775; batch adversarial loss: 0.460556\n",
      "epoch 81; iter: 0; batch classifier loss: 0.062795; batch adversarial loss: 0.519618\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066691; batch adversarial loss: 0.543242\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062118; batch adversarial loss: 0.501925\n",
      "epoch 84; iter: 0; batch classifier loss: 0.111933; batch adversarial loss: 0.451889\n",
      "epoch 85; iter: 0; batch classifier loss: 0.103175; batch adversarial loss: 0.415016\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083556; batch adversarial loss: 0.498519\n",
      "epoch 87; iter: 0; batch classifier loss: 0.096959; batch adversarial loss: 0.393867\n",
      "epoch 88; iter: 0; batch classifier loss: 0.164950; batch adversarial loss: 0.503647\n",
      "epoch 89; iter: 0; batch classifier loss: 0.117155; batch adversarial loss: 0.372120\n",
      "epoch 90; iter: 0; batch classifier loss: 0.092468; batch adversarial loss: 0.464168\n",
      "epoch 91; iter: 0; batch classifier loss: 0.101504; batch adversarial loss: 0.402165\n",
      "epoch 92; iter: 0; batch classifier loss: 0.138058; batch adversarial loss: 0.472589\n",
      "epoch 93; iter: 0; batch classifier loss: 0.104720; batch adversarial loss: 0.529765\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072895; batch adversarial loss: 0.515998\n",
      "epoch 95; iter: 0; batch classifier loss: 0.084054; batch adversarial loss: 0.498364\n",
      "epoch 96; iter: 0; batch classifier loss: 0.157804; batch adversarial loss: 0.350037\n",
      "epoch 97; iter: 0; batch classifier loss: 0.079638; batch adversarial loss: 0.432611\n",
      "epoch 98; iter: 0; batch classifier loss: 0.078524; batch adversarial loss: 0.450426\n",
      "epoch 99; iter: 0; batch classifier loss: 0.093532; batch adversarial loss: 0.404039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.093188; batch adversarial loss: 0.498877\n",
      "epoch 101; iter: 0; batch classifier loss: 0.104772; batch adversarial loss: 0.491836\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056128; batch adversarial loss: 0.541684\n",
      "epoch 103; iter: 0; batch classifier loss: 0.114264; batch adversarial loss: 0.512274\n",
      "epoch 104; iter: 0; batch classifier loss: 0.072319; batch adversarial loss: 0.457602\n",
      "epoch 105; iter: 0; batch classifier loss: 0.078038; batch adversarial loss: 0.446049\n",
      "epoch 106; iter: 0; batch classifier loss: 0.089831; batch adversarial loss: 0.418490\n",
      "epoch 107; iter: 0; batch classifier loss: 0.087410; batch adversarial loss: 0.494418\n",
      "epoch 108; iter: 0; batch classifier loss: 0.076148; batch adversarial loss: 0.459454\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051510; batch adversarial loss: 0.475520\n",
      "epoch 110; iter: 0; batch classifier loss: 0.081685; batch adversarial loss: 0.483813\n",
      "epoch 111; iter: 0; batch classifier loss: 0.104243; batch adversarial loss: 0.406442\n",
      "epoch 112; iter: 0; batch classifier loss: 0.068182; batch adversarial loss: 0.364182\n",
      "epoch 113; iter: 0; batch classifier loss: 0.085917; batch adversarial loss: 0.556092\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050981; batch adversarial loss: 0.466299\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057706; batch adversarial loss: 0.470625\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053174; batch adversarial loss: 0.496220\n",
      "epoch 117; iter: 0; batch classifier loss: 0.100725; batch adversarial loss: 0.610661\n",
      "epoch 118; iter: 0; batch classifier loss: 0.082823; batch adversarial loss: 0.351524\n",
      "epoch 119; iter: 0; batch classifier loss: 0.089865; batch adversarial loss: 0.347919\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041760; batch adversarial loss: 0.482518\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050543; batch adversarial loss: 0.459089\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040857; batch adversarial loss: 0.486852\n",
      "epoch 123; iter: 0; batch classifier loss: 0.073259; batch adversarial loss: 0.407565\n",
      "epoch 124; iter: 0; batch classifier loss: 0.079217; batch adversarial loss: 0.516403\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050917; batch adversarial loss: 0.510395\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048545; batch adversarial loss: 0.445565\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042853; batch adversarial loss: 0.434116\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036962; batch adversarial loss: 0.516205\n",
      "epoch 129; iter: 0; batch classifier loss: 0.067290; batch adversarial loss: 0.443775\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046303; batch adversarial loss: 0.412430\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050540; batch adversarial loss: 0.464431\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029709; batch adversarial loss: 0.449508\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037530; batch adversarial loss: 0.561666\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030319; batch adversarial loss: 0.428708\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041053; batch adversarial loss: 0.504962\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050929; batch adversarial loss: 0.446188\n",
      "epoch 137; iter: 0; batch classifier loss: 0.111090; batch adversarial loss: 0.490590\n",
      "epoch 138; iter: 0; batch classifier loss: 0.054702; batch adversarial loss: 0.517933\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041260; batch adversarial loss: 0.553396\n",
      "epoch 140; iter: 0; batch classifier loss: 0.069910; batch adversarial loss: 0.378700\n",
      "epoch 141; iter: 0; batch classifier loss: 0.069954; batch adversarial loss: 0.348996\n",
      "epoch 142; iter: 0; batch classifier loss: 0.063966; batch adversarial loss: 0.550202\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042350; batch adversarial loss: 0.525021\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034452; batch adversarial loss: 0.448235\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017830; batch adversarial loss: 0.492657\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020231; batch adversarial loss: 0.498039\n",
      "epoch 147; iter: 0; batch classifier loss: 0.060812; batch adversarial loss: 0.400744\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049547; batch adversarial loss: 0.520850\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040139; batch adversarial loss: 0.431832\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029652; batch adversarial loss: 0.537875\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035356; batch adversarial loss: 0.419512\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044815; batch adversarial loss: 0.395896\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038252; batch adversarial loss: 0.530001\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038289; batch adversarial loss: 0.478407\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042958; batch adversarial loss: 0.420117\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024221; batch adversarial loss: 0.440236\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024446; batch adversarial loss: 0.498045\n",
      "epoch 158; iter: 0; batch classifier loss: 0.049110; batch adversarial loss: 0.468610\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038858; batch adversarial loss: 0.429152\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045190; batch adversarial loss: 0.448909\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015991; batch adversarial loss: 0.515792\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021157; batch adversarial loss: 0.499367\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013789; batch adversarial loss: 0.498359\n",
      "epoch 164; iter: 0; batch classifier loss: 0.066438; batch adversarial loss: 0.375574\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025440; batch adversarial loss: 0.474756\n",
      "epoch 166; iter: 0; batch classifier loss: 0.008612; batch adversarial loss: 0.464123\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023145; batch adversarial loss: 0.449914\n",
      "epoch 168; iter: 0; batch classifier loss: 0.061677; batch adversarial loss: 0.503788\n",
      "epoch 169; iter: 0; batch classifier loss: 0.056762; batch adversarial loss: 0.430212\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036829; batch adversarial loss: 0.387293\n",
      "epoch 171; iter: 0; batch classifier loss: 0.070826; batch adversarial loss: 0.460855\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016812; batch adversarial loss: 0.490796\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035337; batch adversarial loss: 0.510292\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027206; batch adversarial loss: 0.374576\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018731; batch adversarial loss: 0.387878\n",
      "epoch 176; iter: 0; batch classifier loss: 0.048094; batch adversarial loss: 0.404328\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021440; batch adversarial loss: 0.492514\n",
      "epoch 178; iter: 0; batch classifier loss: 0.060753; batch adversarial loss: 0.524041\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012391; batch adversarial loss: 0.416867\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021892; batch adversarial loss: 0.464005\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030198; batch adversarial loss: 0.482112\n",
      "epoch 182; iter: 0; batch classifier loss: 0.046257; batch adversarial loss: 0.480316\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036771; batch adversarial loss: 0.510014\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010177; batch adversarial loss: 0.541686\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024627; batch adversarial loss: 0.389821\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031009; batch adversarial loss: 0.512436\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026735; batch adversarial loss: 0.538406\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027778; batch adversarial loss: 0.420393\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027304; batch adversarial loss: 0.442919\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014591; batch adversarial loss: 0.480209\n",
      "epoch 191; iter: 0; batch classifier loss: 0.040109; batch adversarial loss: 0.496049\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021195; batch adversarial loss: 0.532753\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021380; batch adversarial loss: 0.409518\n",
      "epoch 194; iter: 0; batch classifier loss: 0.043559; batch adversarial loss: 0.461453\n",
      "epoch 195; iter: 0; batch classifier loss: 0.061234; batch adversarial loss: 0.527883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.023698; batch adversarial loss: 0.465889\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028772; batch adversarial loss: 0.542702\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025619; batch adversarial loss: 0.484451\n",
      "epoch 199; iter: 0; batch classifier loss: 0.046122; batch adversarial loss: 0.457774\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688209; batch adversarial loss: 0.750316\n",
      "epoch 1; iter: 0; batch classifier loss: 0.452605; batch adversarial loss: 0.700158\n",
      "epoch 2; iter: 0; batch classifier loss: 0.406619; batch adversarial loss: 0.665240\n",
      "epoch 3; iter: 0; batch classifier loss: 0.310594; batch adversarial loss: 0.645292\n",
      "epoch 4; iter: 0; batch classifier loss: 0.313050; batch adversarial loss: 0.601599\n",
      "epoch 5; iter: 0; batch classifier loss: 0.351936; batch adversarial loss: 0.556248\n",
      "epoch 6; iter: 0; batch classifier loss: 0.313972; batch adversarial loss: 0.523819\n",
      "epoch 7; iter: 0; batch classifier loss: 0.272222; batch adversarial loss: 0.543221\n",
      "epoch 8; iter: 0; batch classifier loss: 0.271717; batch adversarial loss: 0.548707\n",
      "epoch 9; iter: 0; batch classifier loss: 0.250927; batch adversarial loss: 0.521448\n",
      "epoch 10; iter: 0; batch classifier loss: 0.256998; batch adversarial loss: 0.517702\n",
      "epoch 11; iter: 0; batch classifier loss: 0.237920; batch adversarial loss: 0.519175\n",
      "epoch 12; iter: 0; batch classifier loss: 0.247206; batch adversarial loss: 0.513367\n",
      "epoch 13; iter: 0; batch classifier loss: 0.231883; batch adversarial loss: 0.496640\n",
      "epoch 14; iter: 0; batch classifier loss: 0.187325; batch adversarial loss: 0.466704\n",
      "epoch 15; iter: 0; batch classifier loss: 0.170310; batch adversarial loss: 0.528345\n",
      "epoch 16; iter: 0; batch classifier loss: 0.150349; batch adversarial loss: 0.521642\n",
      "epoch 17; iter: 0; batch classifier loss: 0.253195; batch adversarial loss: 0.517134\n",
      "epoch 18; iter: 0; batch classifier loss: 0.219721; batch adversarial loss: 0.568924\n",
      "epoch 19; iter: 0; batch classifier loss: 0.168879; batch adversarial loss: 0.453373\n",
      "epoch 20; iter: 0; batch classifier loss: 0.287886; batch adversarial loss: 0.507791\n",
      "epoch 21; iter: 0; batch classifier loss: 0.355723; batch adversarial loss: 0.482672\n",
      "epoch 22; iter: 0; batch classifier loss: 0.407003; batch adversarial loss: 0.458297\n",
      "epoch 23; iter: 0; batch classifier loss: 0.345393; batch adversarial loss: 0.509132\n",
      "epoch 24; iter: 0; batch classifier loss: 0.206859; batch adversarial loss: 0.465320\n",
      "epoch 25; iter: 0; batch classifier loss: 0.184926; batch adversarial loss: 0.435036\n",
      "epoch 26; iter: 0; batch classifier loss: 0.178579; batch adversarial loss: 0.482374\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151994; batch adversarial loss: 0.495768\n",
      "epoch 28; iter: 0; batch classifier loss: 0.132318; batch adversarial loss: 0.442954\n",
      "epoch 29; iter: 0; batch classifier loss: 0.120260; batch adversarial loss: 0.464305\n",
      "epoch 30; iter: 0; batch classifier loss: 0.107279; batch adversarial loss: 0.501627\n",
      "epoch 31; iter: 0; batch classifier loss: 0.148964; batch adversarial loss: 0.512062\n",
      "epoch 32; iter: 0; batch classifier loss: 0.125774; batch adversarial loss: 0.483938\n",
      "epoch 33; iter: 0; batch classifier loss: 0.141298; batch adversarial loss: 0.456479\n",
      "epoch 34; iter: 0; batch classifier loss: 0.094083; batch adversarial loss: 0.443845\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140331; batch adversarial loss: 0.457434\n",
      "epoch 36; iter: 0; batch classifier loss: 0.121565; batch adversarial loss: 0.517778\n",
      "epoch 37; iter: 0; batch classifier loss: 0.182175; batch adversarial loss: 0.449368\n",
      "epoch 38; iter: 0; batch classifier loss: 0.086039; batch adversarial loss: 0.446306\n",
      "epoch 39; iter: 0; batch classifier loss: 0.105359; batch adversarial loss: 0.437129\n",
      "epoch 40; iter: 0; batch classifier loss: 0.130993; batch adversarial loss: 0.456783\n",
      "epoch 41; iter: 0; batch classifier loss: 0.075066; batch adversarial loss: 0.499435\n",
      "epoch 42; iter: 0; batch classifier loss: 0.097182; batch adversarial loss: 0.397870\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089674; batch adversarial loss: 0.392360\n",
      "epoch 44; iter: 0; batch classifier loss: 0.096917; batch adversarial loss: 0.359063\n",
      "epoch 45; iter: 0; batch classifier loss: 0.106432; batch adversarial loss: 0.442031\n",
      "epoch 46; iter: 0; batch classifier loss: 0.091509; batch adversarial loss: 0.506749\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096615; batch adversarial loss: 0.461404\n",
      "epoch 48; iter: 0; batch classifier loss: 0.162044; batch adversarial loss: 0.470262\n",
      "epoch 49; iter: 0; batch classifier loss: 0.106798; batch adversarial loss: 0.494186\n",
      "epoch 50; iter: 0; batch classifier loss: 0.121038; batch adversarial loss: 0.441376\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121439; batch adversarial loss: 0.515052\n",
      "epoch 52; iter: 0; batch classifier loss: 0.086997; batch adversarial loss: 0.491148\n",
      "epoch 53; iter: 0; batch classifier loss: 0.106149; batch adversarial loss: 0.634795\n",
      "epoch 54; iter: 0; batch classifier loss: 0.141521; batch adversarial loss: 0.447694\n",
      "epoch 55; iter: 0; batch classifier loss: 0.102467; batch adversarial loss: 0.519289\n",
      "epoch 56; iter: 0; batch classifier loss: 0.118209; batch adversarial loss: 0.338199\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107972; batch adversarial loss: 0.437686\n",
      "epoch 58; iter: 0; batch classifier loss: 0.156040; batch adversarial loss: 0.408206\n",
      "epoch 59; iter: 0; batch classifier loss: 0.140666; batch adversarial loss: 0.485615\n",
      "epoch 60; iter: 0; batch classifier loss: 0.084613; batch adversarial loss: 0.493324\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113155; batch adversarial loss: 0.478874\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120270; batch adversarial loss: 0.491769\n",
      "epoch 63; iter: 0; batch classifier loss: 0.120486; batch adversarial loss: 0.386019\n",
      "epoch 64; iter: 0; batch classifier loss: 0.063034; batch adversarial loss: 0.418790\n",
      "epoch 65; iter: 0; batch classifier loss: 0.139336; batch adversarial loss: 0.456777\n",
      "epoch 66; iter: 0; batch classifier loss: 0.077419; batch adversarial loss: 0.528369\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130578; batch adversarial loss: 0.447208\n",
      "epoch 68; iter: 0; batch classifier loss: 0.086948; batch adversarial loss: 0.462212\n",
      "epoch 69; iter: 0; batch classifier loss: 0.126889; batch adversarial loss: 0.479757\n",
      "epoch 70; iter: 0; batch classifier loss: 0.094327; batch adversarial loss: 0.421548\n",
      "epoch 71; iter: 0; batch classifier loss: 0.145539; batch adversarial loss: 0.399624\n",
      "epoch 72; iter: 0; batch classifier loss: 0.113271; batch adversarial loss: 0.507732\n",
      "epoch 73; iter: 0; batch classifier loss: 0.061527; batch adversarial loss: 0.492746\n",
      "epoch 74; iter: 0; batch classifier loss: 0.094642; batch adversarial loss: 0.475505\n",
      "epoch 75; iter: 0; batch classifier loss: 0.141917; batch adversarial loss: 0.483679\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085032; batch adversarial loss: 0.446708\n",
      "epoch 77; iter: 0; batch classifier loss: 0.118537; batch adversarial loss: 0.355010\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076614; batch adversarial loss: 0.422399\n",
      "epoch 79; iter: 0; batch classifier loss: 0.143882; batch adversarial loss: 0.456540\n",
      "epoch 80; iter: 0; batch classifier loss: 0.085277; batch adversarial loss: 0.474320\n",
      "epoch 81; iter: 0; batch classifier loss: 0.056774; batch adversarial loss: 0.416675\n",
      "epoch 82; iter: 0; batch classifier loss: 0.106430; batch adversarial loss: 0.508774\n",
      "epoch 83; iter: 0; batch classifier loss: 0.099224; batch adversarial loss: 0.535391\n",
      "epoch 84; iter: 0; batch classifier loss: 0.091593; batch adversarial loss: 0.480870\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074511; batch adversarial loss: 0.457303\n",
      "epoch 86; iter: 0; batch classifier loss: 0.059503; batch adversarial loss: 0.517815\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078921; batch adversarial loss: 0.466361\n",
      "epoch 88; iter: 0; batch classifier loss: 0.091744; batch adversarial loss: 0.505104\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087192; batch adversarial loss: 0.414440\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066081; batch adversarial loss: 0.464032\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050303; batch adversarial loss: 0.431088\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062036; batch adversarial loss: 0.527685\n",
      "epoch 93; iter: 0; batch classifier loss: 0.106505; batch adversarial loss: 0.446003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.095660; batch adversarial loss: 0.371668\n",
      "epoch 95; iter: 0; batch classifier loss: 0.092132; batch adversarial loss: 0.426074\n",
      "epoch 96; iter: 0; batch classifier loss: 0.088386; batch adversarial loss: 0.502795\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065975; batch adversarial loss: 0.429988\n",
      "epoch 98; iter: 0; batch classifier loss: 0.076454; batch adversarial loss: 0.412376\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074704; batch adversarial loss: 0.426431\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050782; batch adversarial loss: 0.474982\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071224; batch adversarial loss: 0.433329\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031396; batch adversarial loss: 0.446300\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052116; batch adversarial loss: 0.420140\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055840; batch adversarial loss: 0.492030\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040422; batch adversarial loss: 0.499689\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032980; batch adversarial loss: 0.462008\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041954; batch adversarial loss: 0.390928\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070077; batch adversarial loss: 0.471947\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042932; batch adversarial loss: 0.388749\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053051; batch adversarial loss: 0.500973\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055344; batch adversarial loss: 0.430826\n",
      "epoch 112; iter: 0; batch classifier loss: 0.066314; batch adversarial loss: 0.483279\n",
      "epoch 113; iter: 0; batch classifier loss: 0.030007; batch adversarial loss: 0.523426\n",
      "epoch 114; iter: 0; batch classifier loss: 0.065618; batch adversarial loss: 0.426974\n",
      "epoch 115; iter: 0; batch classifier loss: 0.100696; batch adversarial loss: 0.368641\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043440; batch adversarial loss: 0.417169\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048669; batch adversarial loss: 0.577506\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033821; batch adversarial loss: 0.444556\n",
      "epoch 119; iter: 0; batch classifier loss: 0.062552; batch adversarial loss: 0.407835\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039256; batch adversarial loss: 0.491148\n",
      "epoch 121; iter: 0; batch classifier loss: 0.063359; batch adversarial loss: 0.444970\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033098; batch adversarial loss: 0.559343\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053690; batch adversarial loss: 0.553531\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025949; batch adversarial loss: 0.468762\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050025; batch adversarial loss: 0.421703\n",
      "epoch 126; iter: 0; batch classifier loss: 0.066315; batch adversarial loss: 0.508139\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050527; batch adversarial loss: 0.424986\n",
      "epoch 128; iter: 0; batch classifier loss: 0.065459; batch adversarial loss: 0.446177\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048230; batch adversarial loss: 0.370258\n",
      "epoch 130; iter: 0; batch classifier loss: 0.049952; batch adversarial loss: 0.373564\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055127; batch adversarial loss: 0.531199\n",
      "epoch 132; iter: 0; batch classifier loss: 0.054752; batch adversarial loss: 0.433554\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025941; batch adversarial loss: 0.494919\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026333; batch adversarial loss: 0.564456\n",
      "epoch 135; iter: 0; batch classifier loss: 0.056514; batch adversarial loss: 0.448849\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019542; batch adversarial loss: 0.418437\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041209; batch adversarial loss: 0.366226\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037000; batch adversarial loss: 0.393711\n",
      "epoch 139; iter: 0; batch classifier loss: 0.008734; batch adversarial loss: 0.510612\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046135; batch adversarial loss: 0.486172\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019875; batch adversarial loss: 0.575961\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022632; batch adversarial loss: 0.527584\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053171; batch adversarial loss: 0.522050\n",
      "epoch 144; iter: 0; batch classifier loss: 0.069671; batch adversarial loss: 0.443203\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033341; batch adversarial loss: 0.484867\n",
      "epoch 146; iter: 0; batch classifier loss: 0.007153; batch adversarial loss: 0.463017\n",
      "epoch 147; iter: 0; batch classifier loss: 0.012851; batch adversarial loss: 0.498710\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016674; batch adversarial loss: 0.440038\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026989; batch adversarial loss: 0.439251\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017937; batch adversarial loss: 0.333716\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044070; batch adversarial loss: 0.429160\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024379; batch adversarial loss: 0.530162\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012478; batch adversarial loss: 0.436507\n",
      "epoch 154; iter: 0; batch classifier loss: 0.054189; batch adversarial loss: 0.545660\n",
      "epoch 155; iter: 0; batch classifier loss: 0.008555; batch adversarial loss: 0.438368\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035168; batch adversarial loss: 0.477320\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034363; batch adversarial loss: 0.411973\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023579; batch adversarial loss: 0.507315\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029782; batch adversarial loss: 0.447461\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023237; batch adversarial loss: 0.505783\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024148; batch adversarial loss: 0.463453\n",
      "epoch 162; iter: 0; batch classifier loss: 0.035565; batch adversarial loss: 0.479887\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030676; batch adversarial loss: 0.437942\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028017; batch adversarial loss: 0.450654\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008261; batch adversarial loss: 0.479399\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019363; batch adversarial loss: 0.399659\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010411; batch adversarial loss: 0.607395\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031179; batch adversarial loss: 0.550072\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025388; batch adversarial loss: 0.430934\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030024; batch adversarial loss: 0.487697\n",
      "epoch 171; iter: 0; batch classifier loss: 0.059174; batch adversarial loss: 0.473084\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013229; batch adversarial loss: 0.477428\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032549; batch adversarial loss: 0.417490\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027357; batch adversarial loss: 0.542246\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006396; batch adversarial loss: 0.472348\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015091; batch adversarial loss: 0.459100\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042235; batch adversarial loss: 0.514091\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040542; batch adversarial loss: 0.486993\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010475; batch adversarial loss: 0.400291\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026627; batch adversarial loss: 0.396892\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018539; batch adversarial loss: 0.392326\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012307; batch adversarial loss: 0.496928\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010748; batch adversarial loss: 0.464784\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026915; batch adversarial loss: 0.415576\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014434; batch adversarial loss: 0.446834\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014549; batch adversarial loss: 0.501879\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017393; batch adversarial loss: 0.390513\n",
      "epoch 188; iter: 0; batch classifier loss: 0.043208; batch adversarial loss: 0.462032\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024093; batch adversarial loss: 0.555744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.007746; batch adversarial loss: 0.356484\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021669; batch adversarial loss: 0.498561\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015140; batch adversarial loss: 0.580509\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008861; batch adversarial loss: 0.451326\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011533; batch adversarial loss: 0.357883\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018678; batch adversarial loss: 0.484722\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027422; batch adversarial loss: 0.390105\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019859; batch adversarial loss: 0.492156\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020499; batch adversarial loss: 0.471407\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032305; batch adversarial loss: 0.482385\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715671; batch adversarial loss: 1.138574\n",
      "epoch 1; iter: 0; batch classifier loss: 0.733529; batch adversarial loss: 1.266516\n",
      "epoch 2; iter: 0; batch classifier loss: 1.032989; batch adversarial loss: 1.294057\n",
      "epoch 3; iter: 0; batch classifier loss: 1.202784; batch adversarial loss: 1.235108\n",
      "epoch 4; iter: 0; batch classifier loss: 0.971070; batch adversarial loss: 1.088840\n",
      "epoch 5; iter: 0; batch classifier loss: 1.043614; batch adversarial loss: 1.000986\n",
      "epoch 6; iter: 0; batch classifier loss: 1.011796; batch adversarial loss: 0.909852\n",
      "epoch 7; iter: 0; batch classifier loss: 1.085467; batch adversarial loss: 0.833949\n",
      "epoch 8; iter: 0; batch classifier loss: 1.133676; batch adversarial loss: 0.756154\n",
      "epoch 9; iter: 0; batch classifier loss: 0.964490; batch adversarial loss: 0.715179\n",
      "epoch 10; iter: 0; batch classifier loss: 0.972811; batch adversarial loss: 0.617500\n",
      "epoch 11; iter: 0; batch classifier loss: 0.806057; batch adversarial loss: 0.591788\n",
      "epoch 12; iter: 0; batch classifier loss: 0.666570; batch adversarial loss: 0.595195\n",
      "epoch 13; iter: 0; batch classifier loss: 0.640142; batch adversarial loss: 0.526759\n",
      "epoch 14; iter: 0; batch classifier loss: 0.252900; batch adversarial loss: 0.554787\n",
      "epoch 15; iter: 0; batch classifier loss: 0.325035; batch adversarial loss: 0.495742\n",
      "epoch 16; iter: 0; batch classifier loss: 0.204531; batch adversarial loss: 0.503322\n",
      "epoch 17; iter: 0; batch classifier loss: 0.275950; batch adversarial loss: 0.478290\n",
      "epoch 18; iter: 0; batch classifier loss: 0.185173; batch adversarial loss: 0.517948\n",
      "epoch 19; iter: 0; batch classifier loss: 0.220968; batch adversarial loss: 0.484865\n",
      "epoch 20; iter: 0; batch classifier loss: 0.167760; batch adversarial loss: 0.483915\n",
      "epoch 21; iter: 0; batch classifier loss: 0.130313; batch adversarial loss: 0.462802\n",
      "epoch 22; iter: 0; batch classifier loss: 0.144691; batch adversarial loss: 0.502494\n",
      "epoch 23; iter: 0; batch classifier loss: 0.157435; batch adversarial loss: 0.485469\n",
      "epoch 24; iter: 0; batch classifier loss: 0.089439; batch adversarial loss: 0.423633\n",
      "epoch 25; iter: 0; batch classifier loss: 0.089654; batch adversarial loss: 0.442742\n",
      "epoch 26; iter: 0; batch classifier loss: 0.097622; batch adversarial loss: 0.468105\n",
      "epoch 27; iter: 0; batch classifier loss: 0.088513; batch adversarial loss: 0.427844\n",
      "epoch 28; iter: 0; batch classifier loss: 0.163161; batch adversarial loss: 0.416365\n",
      "epoch 29; iter: 0; batch classifier loss: 0.097469; batch adversarial loss: 0.459779\n",
      "epoch 30; iter: 0; batch classifier loss: 0.113671; batch adversarial loss: 0.430216\n",
      "epoch 31; iter: 0; batch classifier loss: 0.084929; batch adversarial loss: 0.392145\n",
      "epoch 32; iter: 0; batch classifier loss: 0.081474; batch adversarial loss: 0.478438\n",
      "epoch 33; iter: 0; batch classifier loss: 0.082348; batch adversarial loss: 0.458116\n",
      "epoch 34; iter: 0; batch classifier loss: 0.135289; batch adversarial loss: 0.419957\n",
      "epoch 35; iter: 0; batch classifier loss: 0.078754; batch adversarial loss: 0.424959\n",
      "epoch 36; iter: 0; batch classifier loss: 0.069020; batch adversarial loss: 0.493723\n",
      "epoch 37; iter: 0; batch classifier loss: 0.094992; batch adversarial loss: 0.420321\n",
      "epoch 38; iter: 0; batch classifier loss: 0.056803; batch adversarial loss: 0.469350\n",
      "epoch 39; iter: 0; batch classifier loss: 0.069667; batch adversarial loss: 0.446311\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099722; batch adversarial loss: 0.420453\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146027; batch adversarial loss: 0.498409\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103174; batch adversarial loss: 0.396600\n",
      "epoch 43; iter: 0; batch classifier loss: 0.092900; batch adversarial loss: 0.498647\n",
      "epoch 44; iter: 0; batch classifier loss: 0.090475; batch adversarial loss: 0.510564\n",
      "epoch 45; iter: 0; batch classifier loss: 0.161053; batch adversarial loss: 0.519871\n",
      "epoch 46; iter: 0; batch classifier loss: 0.096656; batch adversarial loss: 0.432290\n",
      "epoch 47; iter: 0; batch classifier loss: 0.170601; batch adversarial loss: 0.518028\n",
      "epoch 48; iter: 0; batch classifier loss: 0.133281; batch adversarial loss: 0.392337\n",
      "epoch 49; iter: 0; batch classifier loss: 0.124017; batch adversarial loss: 0.401935\n",
      "epoch 50; iter: 0; batch classifier loss: 0.072981; batch adversarial loss: 0.435898\n",
      "epoch 51; iter: 0; batch classifier loss: 0.132608; batch adversarial loss: 0.521342\n",
      "epoch 52; iter: 0; batch classifier loss: 0.116753; batch adversarial loss: 0.374928\n",
      "epoch 53; iter: 0; batch classifier loss: 0.073473; batch adversarial loss: 0.531549\n",
      "epoch 54; iter: 0; batch classifier loss: 0.073095; batch adversarial loss: 0.424350\n",
      "epoch 55; iter: 0; batch classifier loss: 0.063623; batch adversarial loss: 0.457137\n",
      "epoch 56; iter: 0; batch classifier loss: 0.040136; batch adversarial loss: 0.491981\n",
      "epoch 57; iter: 0; batch classifier loss: 0.064736; batch adversarial loss: 0.444242\n",
      "epoch 58; iter: 0; batch classifier loss: 0.071656; batch adversarial loss: 0.563377\n",
      "epoch 59; iter: 0; batch classifier loss: 0.038348; batch adversarial loss: 0.466938\n",
      "epoch 60; iter: 0; batch classifier loss: 0.069717; batch adversarial loss: 0.390844\n",
      "epoch 61; iter: 0; batch classifier loss: 0.036256; batch adversarial loss: 0.422893\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082119; batch adversarial loss: 0.374058\n",
      "epoch 63; iter: 0; batch classifier loss: 0.048820; batch adversarial loss: 0.441250\n",
      "epoch 64; iter: 0; batch classifier loss: 0.050119; batch adversarial loss: 0.458917\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074431; batch adversarial loss: 0.516921\n",
      "epoch 66; iter: 0; batch classifier loss: 0.033028; batch adversarial loss: 0.464984\n",
      "epoch 67; iter: 0; batch classifier loss: 0.070140; batch adversarial loss: 0.426779\n",
      "epoch 68; iter: 0; batch classifier loss: 0.065130; batch adversarial loss: 0.341245\n",
      "epoch 69; iter: 0; batch classifier loss: 0.038820; batch adversarial loss: 0.403353\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067291; batch adversarial loss: 0.483918\n",
      "epoch 71; iter: 0; batch classifier loss: 0.086453; batch adversarial loss: 0.484763\n",
      "epoch 72; iter: 0; batch classifier loss: 0.059462; batch adversarial loss: 0.414777\n",
      "epoch 73; iter: 0; batch classifier loss: 0.052099; batch adversarial loss: 0.426116\n",
      "epoch 74; iter: 0; batch classifier loss: 0.052687; batch adversarial loss: 0.464696\n",
      "epoch 75; iter: 0; batch classifier loss: 0.049727; batch adversarial loss: 0.456474\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060504; batch adversarial loss: 0.476494\n",
      "epoch 77; iter: 0; batch classifier loss: 0.058380; batch adversarial loss: 0.526884\n",
      "epoch 78; iter: 0; batch classifier loss: 0.050814; batch adversarial loss: 0.399176\n",
      "epoch 79; iter: 0; batch classifier loss: 0.119762; batch adversarial loss: 0.406844\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054234; batch adversarial loss: 0.441921\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055401; batch adversarial loss: 0.461013\n",
      "epoch 82; iter: 0; batch classifier loss: 0.017447; batch adversarial loss: 0.484380\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056289; batch adversarial loss: 0.419155\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085441; batch adversarial loss: 0.410378\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064524; batch adversarial loss: 0.407657\n",
      "epoch 86; iter: 0; batch classifier loss: 0.059326; batch adversarial loss: 0.465579\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062209; batch adversarial loss: 0.401605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.017390; batch adversarial loss: 0.503152\n",
      "epoch 89; iter: 0; batch classifier loss: 0.041414; batch adversarial loss: 0.452277\n",
      "epoch 90; iter: 0; batch classifier loss: 0.024211; batch adversarial loss: 0.434735\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050159; batch adversarial loss: 0.327990\n",
      "epoch 92; iter: 0; batch classifier loss: 0.103323; batch adversarial loss: 0.464688\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043880; batch adversarial loss: 0.382825\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044536; batch adversarial loss: 0.390302\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044749; batch adversarial loss: 0.459014\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082096; batch adversarial loss: 0.422284\n",
      "epoch 97; iter: 0; batch classifier loss: 0.041374; batch adversarial loss: 0.563704\n",
      "epoch 98; iter: 0; batch classifier loss: 0.025065; batch adversarial loss: 0.497054\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039119; batch adversarial loss: 0.430614\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039163; batch adversarial loss: 0.483234\n",
      "epoch 101; iter: 0; batch classifier loss: 0.064608; batch adversarial loss: 0.506990\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057996; batch adversarial loss: 0.440886\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049663; batch adversarial loss: 0.477427\n",
      "epoch 104; iter: 0; batch classifier loss: 0.032130; batch adversarial loss: 0.578528\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028991; batch adversarial loss: 0.393011\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033345; batch adversarial loss: 0.430603\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025425; batch adversarial loss: 0.357050\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039515; batch adversarial loss: 0.377693\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057049; batch adversarial loss: 0.488020\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037976; batch adversarial loss: 0.423778\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042692; batch adversarial loss: 0.466460\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033875; batch adversarial loss: 0.456060\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063389; batch adversarial loss: 0.431569\n",
      "epoch 114; iter: 0; batch classifier loss: 0.021455; batch adversarial loss: 0.420092\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047674; batch adversarial loss: 0.419129\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054958; batch adversarial loss: 0.453205\n",
      "epoch 117; iter: 0; batch classifier loss: 0.018158; batch adversarial loss: 0.390668\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024455; batch adversarial loss: 0.482350\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035753; batch adversarial loss: 0.480970\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041242; batch adversarial loss: 0.373333\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023246; batch adversarial loss: 0.513488\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044938; batch adversarial loss: 0.505193\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047791; batch adversarial loss: 0.389884\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023606; batch adversarial loss: 0.538367\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031845; batch adversarial loss: 0.399521\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025444; batch adversarial loss: 0.422503\n",
      "epoch 127; iter: 0; batch classifier loss: 0.059734; batch adversarial loss: 0.406329\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024947; batch adversarial loss: 0.436218\n",
      "epoch 129; iter: 0; batch classifier loss: 0.011547; batch adversarial loss: 0.474859\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018887; batch adversarial loss: 0.406152\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018586; batch adversarial loss: 0.432957\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016900; batch adversarial loss: 0.530687\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041607; batch adversarial loss: 0.440750\n",
      "epoch 134; iter: 0; batch classifier loss: 0.060395; batch adversarial loss: 0.450286\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030152; batch adversarial loss: 0.554760\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016919; batch adversarial loss: 0.378931\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032088; batch adversarial loss: 0.484769\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025972; batch adversarial loss: 0.475835\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015803; batch adversarial loss: 0.507208\n",
      "epoch 140; iter: 0; batch classifier loss: 0.015564; batch adversarial loss: 0.449952\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033528; batch adversarial loss: 0.427960\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034265; batch adversarial loss: 0.391895\n",
      "epoch 143; iter: 0; batch classifier loss: 0.044303; batch adversarial loss: 0.438717\n",
      "epoch 144; iter: 0; batch classifier loss: 0.010758; batch adversarial loss: 0.517744\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021861; batch adversarial loss: 0.495316\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032605; batch adversarial loss: 0.414496\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023176; batch adversarial loss: 0.386868\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039424; batch adversarial loss: 0.500035\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039726; batch adversarial loss: 0.415039\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038510; batch adversarial loss: 0.457861\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029037; batch adversarial loss: 0.523108\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011454; batch adversarial loss: 0.419138\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039066; batch adversarial loss: 0.417933\n",
      "epoch 154; iter: 0; batch classifier loss: 0.058311; batch adversarial loss: 0.479868\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018154; batch adversarial loss: 0.446771\n",
      "epoch 156; iter: 0; batch classifier loss: 0.002790; batch adversarial loss: 0.428554\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018753; batch adversarial loss: 0.504033\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018067; batch adversarial loss: 0.403954\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031981; batch adversarial loss: 0.428860\n",
      "epoch 160; iter: 0; batch classifier loss: 0.064542; batch adversarial loss: 0.439550\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038311; batch adversarial loss: 0.423323\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015840; batch adversarial loss: 0.560322\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009871; batch adversarial loss: 0.448802\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024790; batch adversarial loss: 0.398484\n",
      "epoch 165; iter: 0; batch classifier loss: 0.004908; batch adversarial loss: 0.361158\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046945; batch adversarial loss: 0.385775\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021685; batch adversarial loss: 0.284918\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038496; batch adversarial loss: 0.521981\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023075; batch adversarial loss: 0.467914\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021207; batch adversarial loss: 0.501295\n",
      "epoch 171; iter: 0; batch classifier loss: 0.044645; batch adversarial loss: 0.495561\n",
      "epoch 172; iter: 0; batch classifier loss: 0.044826; batch adversarial loss: 0.401569\n",
      "epoch 173; iter: 0; batch classifier loss: 0.047095; batch adversarial loss: 0.387387\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011037; batch adversarial loss: 0.365433\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033211; batch adversarial loss: 0.458936\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040202; batch adversarial loss: 0.457908\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029377; batch adversarial loss: 0.526365\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033141; batch adversarial loss: 0.512424\n",
      "epoch 179; iter: 0; batch classifier loss: 0.005590; batch adversarial loss: 0.399326\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033421; batch adversarial loss: 0.416714\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013928; batch adversarial loss: 0.366982\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024777; batch adversarial loss: 0.424987\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022992; batch adversarial loss: 0.432991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.049770; batch adversarial loss: 0.525006\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014493; batch adversarial loss: 0.364760\n",
      "epoch 186; iter: 0; batch classifier loss: 0.004407; batch adversarial loss: 0.344778\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015487; batch adversarial loss: 0.445193\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017599; batch adversarial loss: 0.520047\n",
      "epoch 189; iter: 0; batch classifier loss: 0.040378; batch adversarial loss: 0.366267\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022758; batch adversarial loss: 0.476930\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015636; batch adversarial loss: 0.459975\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034688; batch adversarial loss: 0.513613\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022632; batch adversarial loss: 0.365706\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017844; batch adversarial loss: 0.456437\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027100; batch adversarial loss: 0.504402\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011221; batch adversarial loss: 0.383698\n",
      "epoch 197; iter: 0; batch classifier loss: 0.003358; batch adversarial loss: 0.445187\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028716; batch adversarial loss: 0.476187\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007172; batch adversarial loss: 0.418403\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705793; batch adversarial loss: 0.674858\n",
      "epoch 1; iter: 0; batch classifier loss: 0.449208; batch adversarial loss: 0.652480\n",
      "epoch 2; iter: 0; batch classifier loss: 0.392488; batch adversarial loss: 0.626303\n",
      "epoch 3; iter: 0; batch classifier loss: 0.409649; batch adversarial loss: 0.621167\n",
      "epoch 4; iter: 0; batch classifier loss: 0.434784; batch adversarial loss: 0.594966\n",
      "epoch 5; iter: 0; batch classifier loss: 0.509748; batch adversarial loss: 0.603224\n",
      "epoch 6; iter: 0; batch classifier loss: 0.536376; batch adversarial loss: 0.566858\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553083; batch adversarial loss: 0.596543\n",
      "epoch 8; iter: 0; batch classifier loss: 0.403481; batch adversarial loss: 0.584637\n",
      "epoch 9; iter: 0; batch classifier loss: 0.454997; batch adversarial loss: 0.531599\n",
      "epoch 10; iter: 0; batch classifier loss: 0.436134; batch adversarial loss: 0.521968\n",
      "epoch 11; iter: 0; batch classifier loss: 0.343305; batch adversarial loss: 0.530250\n",
      "epoch 12; iter: 0; batch classifier loss: 0.377172; batch adversarial loss: 0.546525\n",
      "epoch 13; iter: 0; batch classifier loss: 0.353064; batch adversarial loss: 0.496613\n",
      "epoch 14; iter: 0; batch classifier loss: 0.371424; batch adversarial loss: 0.491873\n",
      "epoch 15; iter: 0; batch classifier loss: 0.427555; batch adversarial loss: 0.464459\n",
      "epoch 16; iter: 0; batch classifier loss: 0.337227; batch adversarial loss: 0.486795\n",
      "epoch 17; iter: 0; batch classifier loss: 0.356851; batch adversarial loss: 0.426685\n",
      "epoch 18; iter: 0; batch classifier loss: 0.374656; batch adversarial loss: 0.492881\n",
      "epoch 19; iter: 0; batch classifier loss: 0.317423; batch adversarial loss: 0.475396\n",
      "epoch 20; iter: 0; batch classifier loss: 0.360000; batch adversarial loss: 0.472949\n",
      "epoch 21; iter: 0; batch classifier loss: 0.251905; batch adversarial loss: 0.474190\n",
      "epoch 22; iter: 0; batch classifier loss: 0.230779; batch adversarial loss: 0.357050\n",
      "epoch 23; iter: 0; batch classifier loss: 0.243092; batch adversarial loss: 0.455363\n",
      "epoch 24; iter: 0; batch classifier loss: 0.261256; batch adversarial loss: 0.465312\n",
      "epoch 25; iter: 0; batch classifier loss: 0.248719; batch adversarial loss: 0.532914\n",
      "epoch 26; iter: 0; batch classifier loss: 0.250788; batch adversarial loss: 0.470974\n",
      "epoch 27; iter: 0; batch classifier loss: 0.227102; batch adversarial loss: 0.503026\n",
      "epoch 28; iter: 0; batch classifier loss: 0.243399; batch adversarial loss: 0.438218\n",
      "epoch 29; iter: 0; batch classifier loss: 0.204286; batch adversarial loss: 0.401620\n",
      "epoch 30; iter: 0; batch classifier loss: 0.281741; batch adversarial loss: 0.442160\n",
      "epoch 31; iter: 0; batch classifier loss: 0.172668; batch adversarial loss: 0.454210\n",
      "epoch 32; iter: 0; batch classifier loss: 0.206523; batch adversarial loss: 0.464173\n",
      "epoch 33; iter: 0; batch classifier loss: 0.215878; batch adversarial loss: 0.507850\n",
      "epoch 34; iter: 0; batch classifier loss: 0.227675; batch adversarial loss: 0.418492\n",
      "epoch 35; iter: 0; batch classifier loss: 0.232711; batch adversarial loss: 0.439883\n",
      "epoch 36; iter: 0; batch classifier loss: 0.275972; batch adversarial loss: 0.434266\n",
      "epoch 37; iter: 0; batch classifier loss: 0.216345; batch adversarial loss: 0.394102\n",
      "epoch 38; iter: 0; batch classifier loss: 0.220857; batch adversarial loss: 0.414353\n",
      "epoch 39; iter: 0; batch classifier loss: 0.216649; batch adversarial loss: 0.527610\n",
      "epoch 40; iter: 0; batch classifier loss: 0.209367; batch adversarial loss: 0.405348\n",
      "epoch 41; iter: 0; batch classifier loss: 0.191470; batch adversarial loss: 0.454609\n",
      "epoch 42; iter: 0; batch classifier loss: 0.210712; batch adversarial loss: 0.520675\n",
      "epoch 43; iter: 0; batch classifier loss: 0.185592; batch adversarial loss: 0.471010\n",
      "epoch 44; iter: 0; batch classifier loss: 0.144870; batch adversarial loss: 0.565334\n",
      "epoch 45; iter: 0; batch classifier loss: 0.224796; batch adversarial loss: 0.366214\n",
      "epoch 46; iter: 0; batch classifier loss: 0.186691; batch adversarial loss: 0.470915\n",
      "epoch 47; iter: 0; batch classifier loss: 0.151240; batch adversarial loss: 0.528297\n",
      "epoch 48; iter: 0; batch classifier loss: 0.228321; batch adversarial loss: 0.448432\n",
      "epoch 49; iter: 0; batch classifier loss: 0.127521; batch adversarial loss: 0.554460\n",
      "epoch 50; iter: 0; batch classifier loss: 0.238804; batch adversarial loss: 0.445146\n",
      "epoch 51; iter: 0; batch classifier loss: 0.198755; batch adversarial loss: 0.435539\n",
      "epoch 52; iter: 0; batch classifier loss: 0.235703; batch adversarial loss: 0.398527\n",
      "epoch 53; iter: 0; batch classifier loss: 0.244188; batch adversarial loss: 0.447367\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090320; batch adversarial loss: 0.481394\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084252; batch adversarial loss: 0.520073\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098200; batch adversarial loss: 0.461436\n",
      "epoch 57; iter: 0; batch classifier loss: 0.120254; batch adversarial loss: 0.517772\n",
      "epoch 58; iter: 0; batch classifier loss: 0.117543; batch adversarial loss: 0.458870\n",
      "epoch 59; iter: 0; batch classifier loss: 0.161682; batch adversarial loss: 0.398680\n",
      "epoch 60; iter: 0; batch classifier loss: 0.155229; batch adversarial loss: 0.501401\n",
      "epoch 61; iter: 0; batch classifier loss: 0.120249; batch adversarial loss: 0.470836\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120466; batch adversarial loss: 0.406821\n",
      "epoch 63; iter: 0; batch classifier loss: 0.101823; batch adversarial loss: 0.444110\n",
      "epoch 64; iter: 0; batch classifier loss: 0.085715; batch adversarial loss: 0.440961\n",
      "epoch 65; iter: 0; batch classifier loss: 0.116185; batch adversarial loss: 0.468777\n",
      "epoch 66; iter: 0; batch classifier loss: 0.155265; batch adversarial loss: 0.385941\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107559; batch adversarial loss: 0.466749\n",
      "epoch 68; iter: 0; batch classifier loss: 0.166851; batch adversarial loss: 0.422526\n",
      "epoch 69; iter: 0; batch classifier loss: 0.119158; batch adversarial loss: 0.443968\n",
      "epoch 70; iter: 0; batch classifier loss: 0.133909; batch adversarial loss: 0.429865\n",
      "epoch 71; iter: 0; batch classifier loss: 0.109386; batch adversarial loss: 0.439816\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074299; batch adversarial loss: 0.430807\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079738; batch adversarial loss: 0.454053\n",
      "epoch 74; iter: 0; batch classifier loss: 0.125407; batch adversarial loss: 0.410433\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110550; batch adversarial loss: 0.425927\n",
      "epoch 76; iter: 0; batch classifier loss: 0.148355; batch adversarial loss: 0.485442\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084155; batch adversarial loss: 0.483162\n",
      "epoch 78; iter: 0; batch classifier loss: 0.153430; batch adversarial loss: 0.424142\n",
      "epoch 79; iter: 0; batch classifier loss: 0.089954; batch adversarial loss: 0.545881\n",
      "epoch 80; iter: 0; batch classifier loss: 0.071206; batch adversarial loss: 0.439797\n",
      "epoch 81; iter: 0; batch classifier loss: 0.093706; batch adversarial loss: 0.496865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.119449; batch adversarial loss: 0.436816\n",
      "epoch 83; iter: 0; batch classifier loss: 0.120847; batch adversarial loss: 0.527070\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067770; batch adversarial loss: 0.589801\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061120; batch adversarial loss: 0.543587\n",
      "epoch 86; iter: 0; batch classifier loss: 0.096866; batch adversarial loss: 0.401801\n",
      "epoch 87; iter: 0; batch classifier loss: 0.093142; batch adversarial loss: 0.435962\n",
      "epoch 88; iter: 0; batch classifier loss: 0.085021; batch adversarial loss: 0.334254\n",
      "epoch 89; iter: 0; batch classifier loss: 0.083388; batch adversarial loss: 0.531483\n",
      "epoch 90; iter: 0; batch classifier loss: 0.069939; batch adversarial loss: 0.531065\n",
      "epoch 91; iter: 0; batch classifier loss: 0.088006; batch adversarial loss: 0.517468\n",
      "epoch 92; iter: 0; batch classifier loss: 0.089278; batch adversarial loss: 0.439920\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048755; batch adversarial loss: 0.504880\n",
      "epoch 94; iter: 0; batch classifier loss: 0.054705; batch adversarial loss: 0.540440\n",
      "epoch 95; iter: 0; batch classifier loss: 0.107337; batch adversarial loss: 0.556259\n",
      "epoch 96; iter: 0; batch classifier loss: 0.030981; batch adversarial loss: 0.437574\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053116; batch adversarial loss: 0.457982\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058549; batch adversarial loss: 0.391568\n",
      "epoch 99; iter: 0; batch classifier loss: 0.099306; batch adversarial loss: 0.514306\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051487; batch adversarial loss: 0.450187\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042879; batch adversarial loss: 0.500328\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041978; batch adversarial loss: 0.491480\n",
      "epoch 103; iter: 0; batch classifier loss: 0.080393; batch adversarial loss: 0.450568\n",
      "epoch 104; iter: 0; batch classifier loss: 0.054386; batch adversarial loss: 0.452522\n",
      "epoch 105; iter: 0; batch classifier loss: 0.098523; batch adversarial loss: 0.370960\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056712; batch adversarial loss: 0.373702\n",
      "epoch 107; iter: 0; batch classifier loss: 0.068082; batch adversarial loss: 0.337293\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055397; batch adversarial loss: 0.291393\n",
      "epoch 109; iter: 0; batch classifier loss: 0.069958; batch adversarial loss: 0.356988\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068282; batch adversarial loss: 0.439826\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034590; batch adversarial loss: 0.464373\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044142; batch adversarial loss: 0.504824\n",
      "epoch 113; iter: 0; batch classifier loss: 0.020438; batch adversarial loss: 0.416254\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039051; batch adversarial loss: 0.409189\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060999; batch adversarial loss: 0.426477\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042903; batch adversarial loss: 0.523553\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020235; batch adversarial loss: 0.553440\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069714; batch adversarial loss: 0.442267\n",
      "epoch 119; iter: 0; batch classifier loss: 0.058609; batch adversarial loss: 0.584620\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032669; batch adversarial loss: 0.518077\n",
      "epoch 121; iter: 0; batch classifier loss: 0.019239; batch adversarial loss: 0.435410\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052724; batch adversarial loss: 0.550803\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036444; batch adversarial loss: 0.494837\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026195; batch adversarial loss: 0.391910\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046681; batch adversarial loss: 0.439302\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043830; batch adversarial loss: 0.333037\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024893; batch adversarial loss: 0.496465\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021185; batch adversarial loss: 0.449622\n",
      "epoch 129; iter: 0; batch classifier loss: 0.055501; batch adversarial loss: 0.393750\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022874; batch adversarial loss: 0.411290\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054436; batch adversarial loss: 0.403409\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031667; batch adversarial loss: 0.472757\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028325; batch adversarial loss: 0.386776\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035241; batch adversarial loss: 0.386388\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040267; batch adversarial loss: 0.384148\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028517; batch adversarial loss: 0.469381\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037326; batch adversarial loss: 0.395897\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027383; batch adversarial loss: 0.457780\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018114; batch adversarial loss: 0.434240\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052373; batch adversarial loss: 0.468603\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016732; batch adversarial loss: 0.503193\n",
      "epoch 142; iter: 0; batch classifier loss: 0.011626; batch adversarial loss: 0.502048\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035940; batch adversarial loss: 0.526821\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025380; batch adversarial loss: 0.446453\n",
      "epoch 145; iter: 0; batch classifier loss: 0.009620; batch adversarial loss: 0.510811\n",
      "epoch 146; iter: 0; batch classifier loss: 0.009172; batch adversarial loss: 0.437938\n",
      "epoch 147; iter: 0; batch classifier loss: 0.048609; batch adversarial loss: 0.424154\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025518; batch adversarial loss: 0.421516\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036136; batch adversarial loss: 0.434060\n",
      "epoch 150; iter: 0; batch classifier loss: 0.006622; batch adversarial loss: 0.483147\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021921; batch adversarial loss: 0.441433\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042861; batch adversarial loss: 0.465551\n",
      "epoch 153; iter: 0; batch classifier loss: 0.007077; batch adversarial loss: 0.524293\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032013; batch adversarial loss: 0.503059\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034664; batch adversarial loss: 0.421983\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025689; batch adversarial loss: 0.423919\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029756; batch adversarial loss: 0.405790\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020565; batch adversarial loss: 0.477086\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025851; batch adversarial loss: 0.414733\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021520; batch adversarial loss: 0.458880\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009163; batch adversarial loss: 0.418728\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007333; batch adversarial loss: 0.479864\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027237; batch adversarial loss: 0.429129\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021012; batch adversarial loss: 0.541713\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023035; batch adversarial loss: 0.477539\n",
      "epoch 166; iter: 0; batch classifier loss: 0.006128; batch adversarial loss: 0.364856\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016759; batch adversarial loss: 0.430307\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021669; batch adversarial loss: 0.344690\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024734; batch adversarial loss: 0.442756\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023189; batch adversarial loss: 0.482174\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017485; batch adversarial loss: 0.418340\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011676; batch adversarial loss: 0.544814\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012675; batch adversarial loss: 0.439625\n",
      "epoch 174; iter: 0; batch classifier loss: 0.004790; batch adversarial loss: 0.464452\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030242; batch adversarial loss: 0.384775\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026022; batch adversarial loss: 0.400240\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030494; batch adversarial loss: 0.588197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.055787; batch adversarial loss: 0.486795\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011776; batch adversarial loss: 0.447823\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026255; batch adversarial loss: 0.372878\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024222; batch adversarial loss: 0.469157\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007022; batch adversarial loss: 0.449224\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005452; batch adversarial loss: 0.485444\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022441; batch adversarial loss: 0.480609\n",
      "epoch 185; iter: 0; batch classifier loss: 0.030449; batch adversarial loss: 0.455808\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006516; batch adversarial loss: 0.358109\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011521; batch adversarial loss: 0.461644\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026723; batch adversarial loss: 0.443633\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004523; batch adversarial loss: 0.495536\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009562; batch adversarial loss: 0.392991\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025399; batch adversarial loss: 0.372907\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021539; batch adversarial loss: 0.404707\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017935; batch adversarial loss: 0.360520\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024660; batch adversarial loss: 0.408955\n",
      "epoch 195; iter: 0; batch classifier loss: 0.032761; batch adversarial loss: 0.458036\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011331; batch adversarial loss: 0.450270\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018725; batch adversarial loss: 0.525635\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018988; batch adversarial loss: 0.522820\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008021; batch adversarial loss: 0.499937\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727259; batch adversarial loss: 0.609560\n",
      "epoch 1; iter: 0; batch classifier loss: 0.359837; batch adversarial loss: 0.619552\n",
      "epoch 2; iter: 0; batch classifier loss: 0.400416; batch adversarial loss: 0.577865\n",
      "epoch 3; iter: 0; batch classifier loss: 0.356504; batch adversarial loss: 0.595210\n",
      "epoch 4; iter: 0; batch classifier loss: 0.263990; batch adversarial loss: 0.560615\n",
      "epoch 5; iter: 0; batch classifier loss: 0.339826; batch adversarial loss: 0.500946\n",
      "epoch 6; iter: 0; batch classifier loss: 0.278945; batch adversarial loss: 0.521979\n",
      "epoch 7; iter: 0; batch classifier loss: 0.307706; batch adversarial loss: 0.505379\n",
      "epoch 8; iter: 0; batch classifier loss: 0.268744; batch adversarial loss: 0.512176\n",
      "epoch 9; iter: 0; batch classifier loss: 0.221170; batch adversarial loss: 0.541088\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258571; batch adversarial loss: 0.522122\n",
      "epoch 11; iter: 0; batch classifier loss: 0.176428; batch adversarial loss: 0.528799\n",
      "epoch 12; iter: 0; batch classifier loss: 0.225723; batch adversarial loss: 0.523223\n",
      "epoch 13; iter: 0; batch classifier loss: 0.293021; batch adversarial loss: 0.498861\n",
      "epoch 14; iter: 0; batch classifier loss: 0.190898; batch adversarial loss: 0.413574\n",
      "epoch 15; iter: 0; batch classifier loss: 0.253870; batch adversarial loss: 0.636108\n",
      "epoch 16; iter: 0; batch classifier loss: 0.185871; batch adversarial loss: 0.571997\n",
      "epoch 17; iter: 0; batch classifier loss: 0.244915; batch adversarial loss: 0.532225\n",
      "epoch 18; iter: 0; batch classifier loss: 0.272402; batch adversarial loss: 0.505470\n",
      "epoch 19; iter: 0; batch classifier loss: 0.330275; batch adversarial loss: 0.517202\n",
      "epoch 20; iter: 0; batch classifier loss: 0.339087; batch adversarial loss: 0.561604\n",
      "epoch 21; iter: 0; batch classifier loss: 0.348750; batch adversarial loss: 0.524512\n",
      "epoch 22; iter: 0; batch classifier loss: 0.348338; batch adversarial loss: 0.488311\n",
      "epoch 23; iter: 0; batch classifier loss: 0.352214; batch adversarial loss: 0.458966\n",
      "epoch 24; iter: 0; batch classifier loss: 0.190244; batch adversarial loss: 0.451977\n",
      "epoch 25; iter: 0; batch classifier loss: 0.163083; batch adversarial loss: 0.477498\n",
      "epoch 26; iter: 0; batch classifier loss: 0.141995; batch adversarial loss: 0.441134\n",
      "epoch 27; iter: 0; batch classifier loss: 0.138711; batch adversarial loss: 0.473124\n",
      "epoch 28; iter: 0; batch classifier loss: 0.214800; batch adversarial loss: 0.502434\n",
      "epoch 29; iter: 0; batch classifier loss: 0.160815; batch adversarial loss: 0.421072\n",
      "epoch 30; iter: 0; batch classifier loss: 0.118492; batch adversarial loss: 0.487067\n",
      "epoch 31; iter: 0; batch classifier loss: 0.157175; batch adversarial loss: 0.462609\n",
      "epoch 32; iter: 0; batch classifier loss: 0.142207; batch adversarial loss: 0.394576\n",
      "epoch 33; iter: 0; batch classifier loss: 0.146914; batch adversarial loss: 0.469800\n",
      "epoch 34; iter: 0; batch classifier loss: 0.097619; batch adversarial loss: 0.567092\n",
      "epoch 35; iter: 0; batch classifier loss: 0.147421; batch adversarial loss: 0.452601\n",
      "epoch 36; iter: 0; batch classifier loss: 0.180861; batch adversarial loss: 0.527940\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110774; batch adversarial loss: 0.426393\n",
      "epoch 38; iter: 0; batch classifier loss: 0.158392; batch adversarial loss: 0.417497\n",
      "epoch 39; iter: 0; batch classifier loss: 0.101676; batch adversarial loss: 0.435830\n",
      "epoch 40; iter: 0; batch classifier loss: 0.101125; batch adversarial loss: 0.519238\n",
      "epoch 41; iter: 0; batch classifier loss: 0.090749; batch adversarial loss: 0.515436\n",
      "epoch 42; iter: 0; batch classifier loss: 0.128867; batch adversarial loss: 0.461312\n",
      "epoch 43; iter: 0; batch classifier loss: 0.072488; batch adversarial loss: 0.507483\n",
      "epoch 44; iter: 0; batch classifier loss: 0.114510; batch adversarial loss: 0.411972\n",
      "epoch 45; iter: 0; batch classifier loss: 0.140525; batch adversarial loss: 0.466231\n",
      "epoch 46; iter: 0; batch classifier loss: 0.080576; batch adversarial loss: 0.455161\n",
      "epoch 47; iter: 0; batch classifier loss: 0.115086; batch adversarial loss: 0.443425\n",
      "epoch 48; iter: 0; batch classifier loss: 0.122600; batch adversarial loss: 0.372431\n",
      "epoch 49; iter: 0; batch classifier loss: 0.089547; batch adversarial loss: 0.540494\n",
      "epoch 50; iter: 0; batch classifier loss: 0.079360; batch adversarial loss: 0.521567\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081775; batch adversarial loss: 0.506948\n",
      "epoch 52; iter: 0; batch classifier loss: 0.094207; batch adversarial loss: 0.506012\n",
      "epoch 53; iter: 0; batch classifier loss: 0.083581; batch adversarial loss: 0.467219\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101470; batch adversarial loss: 0.484446\n",
      "epoch 55; iter: 0; batch classifier loss: 0.133143; batch adversarial loss: 0.397782\n",
      "epoch 56; iter: 0; batch classifier loss: 0.105445; batch adversarial loss: 0.532548\n",
      "epoch 57; iter: 0; batch classifier loss: 0.070811; batch adversarial loss: 0.488891\n",
      "epoch 58; iter: 0; batch classifier loss: 0.066648; batch adversarial loss: 0.446453\n",
      "epoch 59; iter: 0; batch classifier loss: 0.063159; batch adversarial loss: 0.517534\n",
      "epoch 60; iter: 0; batch classifier loss: 0.116977; batch adversarial loss: 0.483277\n",
      "epoch 61; iter: 0; batch classifier loss: 0.109091; batch adversarial loss: 0.395878\n",
      "epoch 62; iter: 0; batch classifier loss: 0.139816; batch adversarial loss: 0.513004\n",
      "epoch 63; iter: 0; batch classifier loss: 0.054947; batch adversarial loss: 0.583147\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080735; batch adversarial loss: 0.422430\n",
      "epoch 65; iter: 0; batch classifier loss: 0.126494; batch adversarial loss: 0.436124\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066823; batch adversarial loss: 0.465623\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091045; batch adversarial loss: 0.443365\n",
      "epoch 68; iter: 0; batch classifier loss: 0.101294; batch adversarial loss: 0.491632\n",
      "epoch 69; iter: 0; batch classifier loss: 0.107224; batch adversarial loss: 0.437868\n",
      "epoch 70; iter: 0; batch classifier loss: 0.135451; batch adversarial loss: 0.508460\n",
      "epoch 71; iter: 0; batch classifier loss: 0.126603; batch adversarial loss: 0.403353\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100621; batch adversarial loss: 0.463021\n",
      "epoch 73; iter: 0; batch classifier loss: 0.040293; batch adversarial loss: 0.539678\n",
      "epoch 74; iter: 0; batch classifier loss: 0.110935; batch adversarial loss: 0.340309\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063361; batch adversarial loss: 0.500068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.105381; batch adversarial loss: 0.522761\n",
      "epoch 77; iter: 0; batch classifier loss: 0.075256; batch adversarial loss: 0.432097\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064438; batch adversarial loss: 0.550526\n",
      "epoch 79; iter: 0; batch classifier loss: 0.038488; batch adversarial loss: 0.524394\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064795; batch adversarial loss: 0.444418\n",
      "epoch 81; iter: 0; batch classifier loss: 0.118101; batch adversarial loss: 0.514788\n",
      "epoch 82; iter: 0; batch classifier loss: 0.109207; batch adversarial loss: 0.377095\n",
      "epoch 83; iter: 0; batch classifier loss: 0.111251; batch adversarial loss: 0.394244\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052530; batch adversarial loss: 0.549552\n",
      "epoch 85; iter: 0; batch classifier loss: 0.094281; batch adversarial loss: 0.385386\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053648; batch adversarial loss: 0.537873\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042968; batch adversarial loss: 0.527394\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067325; batch adversarial loss: 0.462044\n",
      "epoch 89; iter: 0; batch classifier loss: 0.038721; batch adversarial loss: 0.493208\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073113; batch adversarial loss: 0.480828\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045379; batch adversarial loss: 0.456074\n",
      "epoch 92; iter: 0; batch classifier loss: 0.078842; batch adversarial loss: 0.449738\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039710; batch adversarial loss: 0.494027\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038499; batch adversarial loss: 0.501320\n",
      "epoch 95; iter: 0; batch classifier loss: 0.094356; batch adversarial loss: 0.460119\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075131; batch adversarial loss: 0.513301\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049321; batch adversarial loss: 0.406336\n",
      "epoch 98; iter: 0; batch classifier loss: 0.041225; batch adversarial loss: 0.480515\n",
      "epoch 99; iter: 0; batch classifier loss: 0.066465; batch adversarial loss: 0.455546\n",
      "epoch 100; iter: 0; batch classifier loss: 0.101200; batch adversarial loss: 0.421570\n",
      "epoch 101; iter: 0; batch classifier loss: 0.077806; batch adversarial loss: 0.466489\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060453; batch adversarial loss: 0.336696\n",
      "epoch 103; iter: 0; batch classifier loss: 0.092813; batch adversarial loss: 0.473006\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065831; batch adversarial loss: 0.519803\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062348; batch adversarial loss: 0.479646\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039119; batch adversarial loss: 0.475218\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050607; batch adversarial loss: 0.440194\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039133; batch adversarial loss: 0.546403\n",
      "epoch 109; iter: 0; batch classifier loss: 0.065099; batch adversarial loss: 0.504554\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039755; batch adversarial loss: 0.409344\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041528; batch adversarial loss: 0.478570\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038751; batch adversarial loss: 0.537977\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044365; batch adversarial loss: 0.520879\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030103; batch adversarial loss: 0.407721\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063884; batch adversarial loss: 0.467214\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048186; batch adversarial loss: 0.487015\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053475; batch adversarial loss: 0.460737\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030448; batch adversarial loss: 0.426597\n",
      "epoch 119; iter: 0; batch classifier loss: 0.058726; batch adversarial loss: 0.494182\n",
      "epoch 120; iter: 0; batch classifier loss: 0.092783; batch adversarial loss: 0.346567\n",
      "epoch 121; iter: 0; batch classifier loss: 0.059457; batch adversarial loss: 0.419612\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036776; batch adversarial loss: 0.397816\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026240; batch adversarial loss: 0.466259\n",
      "epoch 124; iter: 0; batch classifier loss: 0.028476; batch adversarial loss: 0.452412\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043917; batch adversarial loss: 0.403991\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026334; batch adversarial loss: 0.466114\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032729; batch adversarial loss: 0.504765\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046226; batch adversarial loss: 0.465743\n",
      "epoch 129; iter: 0; batch classifier loss: 0.072265; batch adversarial loss: 0.433991\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040844; batch adversarial loss: 0.456559\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043686; batch adversarial loss: 0.528961\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047653; batch adversarial loss: 0.440351\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051723; batch adversarial loss: 0.444231\n",
      "epoch 134; iter: 0; batch classifier loss: 0.105650; batch adversarial loss: 0.515839\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059854; batch adversarial loss: 0.495753\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017091; batch adversarial loss: 0.520033\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048612; batch adversarial loss: 0.430999\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038008; batch adversarial loss: 0.477072\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029769; batch adversarial loss: 0.533728\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037845; batch adversarial loss: 0.411074\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053715; batch adversarial loss: 0.514566\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030457; batch adversarial loss: 0.580091\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037426; batch adversarial loss: 0.402278\n",
      "epoch 144; iter: 0; batch classifier loss: 0.009809; batch adversarial loss: 0.502998\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020256; batch adversarial loss: 0.468456\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026874; batch adversarial loss: 0.479460\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029971; batch adversarial loss: 0.356446\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028400; batch adversarial loss: 0.499969\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026090; batch adversarial loss: 0.510194\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052424; batch adversarial loss: 0.449613\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013327; batch adversarial loss: 0.430694\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030981; batch adversarial loss: 0.468288\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021415; batch adversarial loss: 0.538884\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023339; batch adversarial loss: 0.485216\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035539; batch adversarial loss: 0.377777\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029458; batch adversarial loss: 0.481253\n",
      "epoch 157; iter: 0; batch classifier loss: 0.060753; batch adversarial loss: 0.460374\n",
      "epoch 158; iter: 0; batch classifier loss: 0.056484; batch adversarial loss: 0.411718\n",
      "epoch 159; iter: 0; batch classifier loss: 0.059876; batch adversarial loss: 0.457692\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023983; batch adversarial loss: 0.474656\n",
      "epoch 161; iter: 0; batch classifier loss: 0.060550; batch adversarial loss: 0.560683\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031970; batch adversarial loss: 0.483650\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025385; batch adversarial loss: 0.447206\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017748; batch adversarial loss: 0.464727\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031178; batch adversarial loss: 0.419103\n",
      "epoch 166; iter: 0; batch classifier loss: 0.056580; batch adversarial loss: 0.445208\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022388; batch adversarial loss: 0.477480\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030524; batch adversarial loss: 0.437936\n",
      "epoch 169; iter: 0; batch classifier loss: 0.051158; batch adversarial loss: 0.478466\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036143; batch adversarial loss: 0.398746\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018845; batch adversarial loss: 0.586933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.045715; batch adversarial loss: 0.484758\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016343; batch adversarial loss: 0.468110\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025582; batch adversarial loss: 0.408676\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015559; batch adversarial loss: 0.472218\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025607; batch adversarial loss: 0.496602\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015390; batch adversarial loss: 0.515993\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034707; batch adversarial loss: 0.466818\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025670; batch adversarial loss: 0.484773\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016480; batch adversarial loss: 0.383246\n",
      "epoch 181; iter: 0; batch classifier loss: 0.050720; batch adversarial loss: 0.420945\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037445; batch adversarial loss: 0.403274\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009762; batch adversarial loss: 0.487547\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020857; batch adversarial loss: 0.532362\n",
      "epoch 185; iter: 0; batch classifier loss: 0.041950; batch adversarial loss: 0.475917\n",
      "epoch 186; iter: 0; batch classifier loss: 0.039214; batch adversarial loss: 0.444853\n",
      "epoch 187; iter: 0; batch classifier loss: 0.041624; batch adversarial loss: 0.423569\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023208; batch adversarial loss: 0.506591\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023483; batch adversarial loss: 0.480201\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025343; batch adversarial loss: 0.552966\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017594; batch adversarial loss: 0.582123\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029361; batch adversarial loss: 0.442063\n",
      "epoch 193; iter: 0; batch classifier loss: 0.036246; batch adversarial loss: 0.468335\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023318; batch adversarial loss: 0.523320\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010472; batch adversarial loss: 0.434069\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005987; batch adversarial loss: 0.442815\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008079; batch adversarial loss: 0.509206\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009452; batch adversarial loss: 0.444792\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011217; batch adversarial loss: 0.456141\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683092; batch adversarial loss: 0.574539\n",
      "epoch 1; iter: 0; batch classifier loss: 0.461165; batch adversarial loss: 0.596005\n",
      "epoch 2; iter: 0; batch classifier loss: 0.373840; batch adversarial loss: 0.598382\n",
      "epoch 3; iter: 0; batch classifier loss: 0.384210; batch adversarial loss: 0.559883\n",
      "epoch 4; iter: 0; batch classifier loss: 0.278467; batch adversarial loss: 0.525367\n",
      "epoch 5; iter: 0; batch classifier loss: 0.265115; batch adversarial loss: 0.558546\n",
      "epoch 6; iter: 0; batch classifier loss: 0.288868; batch adversarial loss: 0.553578\n",
      "epoch 7; iter: 0; batch classifier loss: 0.210320; batch adversarial loss: 0.527894\n",
      "epoch 8; iter: 0; batch classifier loss: 0.232873; batch adversarial loss: 0.451775\n",
      "epoch 9; iter: 0; batch classifier loss: 0.245914; batch adversarial loss: 0.543208\n",
      "epoch 10; iter: 0; batch classifier loss: 0.276562; batch adversarial loss: 0.537500\n",
      "epoch 11; iter: 0; batch classifier loss: 0.261723; batch adversarial loss: 0.565152\n",
      "epoch 12; iter: 0; batch classifier loss: 0.284269; batch adversarial loss: 0.578783\n",
      "epoch 13; iter: 0; batch classifier loss: 0.296191; batch adversarial loss: 0.532350\n",
      "epoch 14; iter: 0; batch classifier loss: 0.214644; batch adversarial loss: 0.463023\n",
      "epoch 15; iter: 0; batch classifier loss: 0.290122; batch adversarial loss: 0.469566\n",
      "epoch 16; iter: 0; batch classifier loss: 0.251311; batch adversarial loss: 0.574302\n",
      "epoch 17; iter: 0; batch classifier loss: 0.285670; batch adversarial loss: 0.596261\n",
      "epoch 18; iter: 0; batch classifier loss: 0.235994; batch adversarial loss: 0.456480\n",
      "epoch 19; iter: 0; batch classifier loss: 0.320472; batch adversarial loss: 0.530855\n",
      "epoch 20; iter: 0; batch classifier loss: 0.293825; batch adversarial loss: 0.512199\n",
      "epoch 21; iter: 0; batch classifier loss: 0.412832; batch adversarial loss: 0.482782\n",
      "epoch 22; iter: 0; batch classifier loss: 0.356004; batch adversarial loss: 0.520420\n",
      "epoch 23; iter: 0; batch classifier loss: 0.255571; batch adversarial loss: 0.372906\n",
      "epoch 24; iter: 0; batch classifier loss: 0.231188; batch adversarial loss: 0.476182\n",
      "epoch 25; iter: 0; batch classifier loss: 0.170526; batch adversarial loss: 0.524874\n",
      "epoch 26; iter: 0; batch classifier loss: 0.149146; batch adversarial loss: 0.416043\n",
      "epoch 27; iter: 0; batch classifier loss: 0.169486; batch adversarial loss: 0.444450\n",
      "epoch 28; iter: 0; batch classifier loss: 0.232369; batch adversarial loss: 0.412369\n",
      "epoch 29; iter: 0; batch classifier loss: 0.140022; batch adversarial loss: 0.419945\n",
      "epoch 30; iter: 0; batch classifier loss: 0.136300; batch adversarial loss: 0.404832\n",
      "epoch 31; iter: 0; batch classifier loss: 0.122480; batch adversarial loss: 0.480569\n",
      "epoch 32; iter: 0; batch classifier loss: 0.133314; batch adversarial loss: 0.467656\n",
      "epoch 33; iter: 0; batch classifier loss: 0.108967; batch adversarial loss: 0.478351\n",
      "epoch 34; iter: 0; batch classifier loss: 0.135168; batch adversarial loss: 0.505293\n",
      "epoch 35; iter: 0; batch classifier loss: 0.092300; batch adversarial loss: 0.444173\n",
      "epoch 36; iter: 0; batch classifier loss: 0.125274; batch adversarial loss: 0.365878\n",
      "epoch 37; iter: 0; batch classifier loss: 0.099670; batch adversarial loss: 0.505146\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107644; batch adversarial loss: 0.389261\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131309; batch adversarial loss: 0.354788\n",
      "epoch 40; iter: 0; batch classifier loss: 0.149435; batch adversarial loss: 0.426377\n",
      "epoch 41; iter: 0; batch classifier loss: 0.117390; batch adversarial loss: 0.503414\n",
      "epoch 42; iter: 0; batch classifier loss: 0.127523; batch adversarial loss: 0.507389\n",
      "epoch 43; iter: 0; batch classifier loss: 0.107657; batch adversarial loss: 0.414386\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107665; batch adversarial loss: 0.448647\n",
      "epoch 45; iter: 0; batch classifier loss: 0.125459; batch adversarial loss: 0.376731\n",
      "epoch 46; iter: 0; batch classifier loss: 0.118212; batch adversarial loss: 0.470814\n",
      "epoch 47; iter: 0; batch classifier loss: 0.072684; batch adversarial loss: 0.393588\n",
      "epoch 48; iter: 0; batch classifier loss: 0.158039; batch adversarial loss: 0.434354\n",
      "epoch 49; iter: 0; batch classifier loss: 0.149491; batch adversarial loss: 0.402045\n",
      "epoch 50; iter: 0; batch classifier loss: 0.120161; batch adversarial loss: 0.450162\n",
      "epoch 51; iter: 0; batch classifier loss: 0.136033; batch adversarial loss: 0.406062\n",
      "epoch 52; iter: 0; batch classifier loss: 0.076930; batch adversarial loss: 0.461529\n",
      "epoch 53; iter: 0; batch classifier loss: 0.115260; batch adversarial loss: 0.424814\n",
      "epoch 54; iter: 0; batch classifier loss: 0.093935; batch adversarial loss: 0.463197\n",
      "epoch 55; iter: 0; batch classifier loss: 0.118929; batch adversarial loss: 0.519099\n",
      "epoch 56; iter: 0; batch classifier loss: 0.104431; batch adversarial loss: 0.387551\n",
      "epoch 57; iter: 0; batch classifier loss: 0.149719; batch adversarial loss: 0.469194\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101841; batch adversarial loss: 0.525090\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088121; batch adversarial loss: 0.487839\n",
      "epoch 60; iter: 0; batch classifier loss: 0.166880; batch adversarial loss: 0.429646\n",
      "epoch 61; iter: 0; batch classifier loss: 0.136542; batch adversarial loss: 0.461223\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104291; batch adversarial loss: 0.466749\n",
      "epoch 63; iter: 0; batch classifier loss: 0.142751; batch adversarial loss: 0.489196\n",
      "epoch 64; iter: 0; batch classifier loss: 0.172933; batch adversarial loss: 0.393340\n",
      "epoch 65; iter: 0; batch classifier loss: 0.130094; batch adversarial loss: 0.461810\n",
      "epoch 66; iter: 0; batch classifier loss: 0.171796; batch adversarial loss: 0.538237\n",
      "epoch 67; iter: 0; batch classifier loss: 0.134201; batch adversarial loss: 0.415578\n",
      "epoch 68; iter: 0; batch classifier loss: 0.157954; batch adversarial loss: 0.506819\n",
      "epoch 69; iter: 0; batch classifier loss: 0.104484; batch adversarial loss: 0.522907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.142350; batch adversarial loss: 0.477552\n",
      "epoch 71; iter: 0; batch classifier loss: 0.135174; batch adversarial loss: 0.425468\n",
      "epoch 72; iter: 0; batch classifier loss: 0.188904; batch adversarial loss: 0.516397\n",
      "epoch 73; iter: 0; batch classifier loss: 0.216343; batch adversarial loss: 0.409170\n",
      "epoch 74; iter: 0; batch classifier loss: 0.179981; batch adversarial loss: 0.456571\n",
      "epoch 75; iter: 0; batch classifier loss: 0.084465; batch adversarial loss: 0.507586\n",
      "epoch 76; iter: 0; batch classifier loss: 0.113004; batch adversarial loss: 0.440792\n",
      "epoch 77; iter: 0; batch classifier loss: 0.110758; batch adversarial loss: 0.594289\n",
      "epoch 78; iter: 0; batch classifier loss: 0.143939; batch adversarial loss: 0.464285\n",
      "epoch 79; iter: 0; batch classifier loss: 0.105388; batch adversarial loss: 0.376730\n",
      "epoch 80; iter: 0; batch classifier loss: 0.143256; batch adversarial loss: 0.424850\n",
      "epoch 81; iter: 0; batch classifier loss: 0.174885; batch adversarial loss: 0.543494\n",
      "epoch 82; iter: 0; batch classifier loss: 0.159281; batch adversarial loss: 0.411753\n",
      "epoch 83; iter: 0; batch classifier loss: 0.134052; batch adversarial loss: 0.447964\n",
      "epoch 84; iter: 0; batch classifier loss: 0.131998; batch adversarial loss: 0.397285\n",
      "epoch 85; iter: 0; batch classifier loss: 0.118028; batch adversarial loss: 0.497544\n",
      "epoch 86; iter: 0; batch classifier loss: 0.141773; batch adversarial loss: 0.370613\n",
      "epoch 87; iter: 0; batch classifier loss: 0.129838; batch adversarial loss: 0.433739\n",
      "epoch 88; iter: 0; batch classifier loss: 0.094617; batch adversarial loss: 0.429682\n",
      "epoch 89; iter: 0; batch classifier loss: 0.094310; batch adversarial loss: 0.434634\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075527; batch adversarial loss: 0.380213\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070371; batch adversarial loss: 0.392440\n",
      "epoch 92; iter: 0; batch classifier loss: 0.094290; batch adversarial loss: 0.523791\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078471; batch adversarial loss: 0.392754\n",
      "epoch 94; iter: 0; batch classifier loss: 0.071816; batch adversarial loss: 0.474685\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087986; batch adversarial loss: 0.467040\n",
      "epoch 96; iter: 0; batch classifier loss: 0.102989; batch adversarial loss: 0.377990\n",
      "epoch 97; iter: 0; batch classifier loss: 0.127268; batch adversarial loss: 0.507141\n",
      "epoch 98; iter: 0; batch classifier loss: 0.073960; batch adversarial loss: 0.433599\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069864; batch adversarial loss: 0.465632\n",
      "epoch 100; iter: 0; batch classifier loss: 0.163448; batch adversarial loss: 0.434480\n",
      "epoch 101; iter: 0; batch classifier loss: 0.059856; batch adversarial loss: 0.577377\n",
      "epoch 102; iter: 0; batch classifier loss: 0.134679; batch adversarial loss: 0.556960\n",
      "epoch 103; iter: 0; batch classifier loss: 0.098189; batch adversarial loss: 0.448955\n",
      "epoch 104; iter: 0; batch classifier loss: 0.126536; batch adversarial loss: 0.501150\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064428; batch adversarial loss: 0.489388\n",
      "epoch 106; iter: 0; batch classifier loss: 0.091943; batch adversarial loss: 0.470805\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058535; batch adversarial loss: 0.494801\n",
      "epoch 108; iter: 0; batch classifier loss: 0.107910; batch adversarial loss: 0.381463\n",
      "epoch 109; iter: 0; batch classifier loss: 0.090014; batch adversarial loss: 0.473733\n",
      "epoch 110; iter: 0; batch classifier loss: 0.102359; batch adversarial loss: 0.462709\n",
      "epoch 111; iter: 0; batch classifier loss: 0.095580; batch adversarial loss: 0.484263\n",
      "epoch 112; iter: 0; batch classifier loss: 0.101010; batch adversarial loss: 0.518546\n",
      "epoch 113; iter: 0; batch classifier loss: 0.112593; batch adversarial loss: 0.434729\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041225; batch adversarial loss: 0.479255\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039130; batch adversarial loss: 0.445131\n",
      "epoch 116; iter: 0; batch classifier loss: 0.097398; batch adversarial loss: 0.385215\n",
      "epoch 117; iter: 0; batch classifier loss: 0.078216; batch adversarial loss: 0.362090\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049868; batch adversarial loss: 0.513305\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048959; batch adversarial loss: 0.407192\n",
      "epoch 120; iter: 0; batch classifier loss: 0.063605; batch adversarial loss: 0.433563\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046841; batch adversarial loss: 0.475019\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052623; batch adversarial loss: 0.427106\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021528; batch adversarial loss: 0.446270\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035178; batch adversarial loss: 0.425738\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051566; batch adversarial loss: 0.437028\n",
      "epoch 126; iter: 0; batch classifier loss: 0.073585; batch adversarial loss: 0.457888\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035227; batch adversarial loss: 0.492353\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044008; batch adversarial loss: 0.444617\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034233; batch adversarial loss: 0.495024\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044178; batch adversarial loss: 0.386710\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031324; batch adversarial loss: 0.402341\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036209; batch adversarial loss: 0.504722\n",
      "epoch 133; iter: 0; batch classifier loss: 0.070803; batch adversarial loss: 0.377573\n",
      "epoch 134; iter: 0; batch classifier loss: 0.058454; batch adversarial loss: 0.537212\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039734; batch adversarial loss: 0.478812\n",
      "epoch 136; iter: 0; batch classifier loss: 0.067885; batch adversarial loss: 0.430267\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024972; batch adversarial loss: 0.434892\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014948; batch adversarial loss: 0.448167\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040748; batch adversarial loss: 0.478189\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026247; batch adversarial loss: 0.477065\n",
      "epoch 141; iter: 0; batch classifier loss: 0.065274; batch adversarial loss: 0.447093\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029354; batch adversarial loss: 0.341437\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053407; batch adversarial loss: 0.467784\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022057; batch adversarial loss: 0.428770\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044188; batch adversarial loss: 0.363568\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035717; batch adversarial loss: 0.550181\n",
      "epoch 147; iter: 0; batch classifier loss: 0.048227; batch adversarial loss: 0.538936\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035542; batch adversarial loss: 0.381532\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040094; batch adversarial loss: 0.521132\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019107; batch adversarial loss: 0.473886\n",
      "epoch 151; iter: 0; batch classifier loss: 0.052001; batch adversarial loss: 0.456090\n",
      "epoch 152; iter: 0; batch classifier loss: 0.054827; batch adversarial loss: 0.475439\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021648; batch adversarial loss: 0.482059\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018512; batch adversarial loss: 0.388078\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037407; batch adversarial loss: 0.419925\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029107; batch adversarial loss: 0.496822\n",
      "epoch 157; iter: 0; batch classifier loss: 0.044165; batch adversarial loss: 0.432229\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014596; batch adversarial loss: 0.388846\n",
      "epoch 159; iter: 0; batch classifier loss: 0.068636; batch adversarial loss: 0.476983\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041185; batch adversarial loss: 0.467448\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022653; batch adversarial loss: 0.463084\n",
      "epoch 162; iter: 0; batch classifier loss: 0.081884; batch adversarial loss: 0.343268\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034480; batch adversarial loss: 0.411903\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018268; batch adversarial loss: 0.465936\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021292; batch adversarial loss: 0.560612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.032148; batch adversarial loss: 0.472360\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039264; batch adversarial loss: 0.438536\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029007; batch adversarial loss: 0.425423\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019742; batch adversarial loss: 0.398098\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012884; batch adversarial loss: 0.418631\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014048; batch adversarial loss: 0.574858\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022284; batch adversarial loss: 0.460314\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032728; batch adversarial loss: 0.444394\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017520; batch adversarial loss: 0.415231\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024111; batch adversarial loss: 0.474019\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021415; batch adversarial loss: 0.502236\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024453; batch adversarial loss: 0.421921\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019814; batch adversarial loss: 0.482998\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022693; batch adversarial loss: 0.424894\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039154; batch adversarial loss: 0.498028\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037496; batch adversarial loss: 0.436660\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008000; batch adversarial loss: 0.564133\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028944; batch adversarial loss: 0.396518\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010393; batch adversarial loss: 0.511239\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019742; batch adversarial loss: 0.489743\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005014; batch adversarial loss: 0.425280\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014933; batch adversarial loss: 0.416754\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019705; batch adversarial loss: 0.406025\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020264; batch adversarial loss: 0.414191\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050034; batch adversarial loss: 0.493607\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017415; batch adversarial loss: 0.484835\n",
      "epoch 192; iter: 0; batch classifier loss: 0.052568; batch adversarial loss: 0.423580\n",
      "epoch 193; iter: 0; batch classifier loss: 0.039380; batch adversarial loss: 0.381976\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039641; batch adversarial loss: 0.469871\n",
      "epoch 195; iter: 0; batch classifier loss: 0.007927; batch adversarial loss: 0.529563\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014642; batch adversarial loss: 0.369511\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024358; batch adversarial loss: 0.506976\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009025; batch adversarial loss: 0.504794\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021414; batch adversarial loss: 0.501439\n",
      "epoch 0; iter: 0; batch classifier loss: 0.655884; batch adversarial loss: 0.663309\n",
      "epoch 1; iter: 0; batch classifier loss: 0.430217; batch adversarial loss: 0.628073\n",
      "epoch 2; iter: 0; batch classifier loss: 0.446913; batch adversarial loss: 0.581224\n",
      "epoch 3; iter: 0; batch classifier loss: 0.473533; batch adversarial loss: 0.544580\n",
      "epoch 4; iter: 0; batch classifier loss: 0.319722; batch adversarial loss: 0.576973\n",
      "epoch 5; iter: 0; batch classifier loss: 0.358655; batch adversarial loss: 0.548683\n",
      "epoch 6; iter: 0; batch classifier loss: 0.337498; batch adversarial loss: 0.573419\n",
      "epoch 7; iter: 0; batch classifier loss: 0.400190; batch adversarial loss: 0.549960\n",
      "epoch 8; iter: 0; batch classifier loss: 0.322862; batch adversarial loss: 0.558189\n",
      "epoch 9; iter: 0; batch classifier loss: 0.360469; batch adversarial loss: 0.481722\n",
      "epoch 10; iter: 0; batch classifier loss: 0.275434; batch adversarial loss: 0.590947\n",
      "epoch 11; iter: 0; batch classifier loss: 0.223460; batch adversarial loss: 0.546124\n",
      "epoch 12; iter: 0; batch classifier loss: 0.294592; batch adversarial loss: 0.524226\n",
      "epoch 13; iter: 0; batch classifier loss: 0.219538; batch adversarial loss: 0.499702\n",
      "epoch 14; iter: 0; batch classifier loss: 0.267663; batch adversarial loss: 0.447497\n",
      "epoch 15; iter: 0; batch classifier loss: 0.246580; batch adversarial loss: 0.482410\n",
      "epoch 16; iter: 0; batch classifier loss: 0.206551; batch adversarial loss: 0.610595\n",
      "epoch 17; iter: 0; batch classifier loss: 0.249081; batch adversarial loss: 0.435603\n",
      "epoch 18; iter: 0; batch classifier loss: 0.225992; batch adversarial loss: 0.458127\n",
      "epoch 19; iter: 0; batch classifier loss: 0.190046; batch adversarial loss: 0.492590\n",
      "epoch 20; iter: 0; batch classifier loss: 0.177129; batch adversarial loss: 0.421797\n",
      "epoch 21; iter: 0; batch classifier loss: 0.201165; batch adversarial loss: 0.468557\n",
      "epoch 22; iter: 0; batch classifier loss: 0.159678; batch adversarial loss: 0.452214\n",
      "epoch 23; iter: 0; batch classifier loss: 0.181065; batch adversarial loss: 0.456698\n",
      "epoch 24; iter: 0; batch classifier loss: 0.180787; batch adversarial loss: 0.534855\n",
      "epoch 25; iter: 0; batch classifier loss: 0.170891; batch adversarial loss: 0.463666\n",
      "epoch 26; iter: 0; batch classifier loss: 0.163668; batch adversarial loss: 0.452859\n",
      "epoch 27; iter: 0; batch classifier loss: 0.146387; batch adversarial loss: 0.502875\n",
      "epoch 28; iter: 0; batch classifier loss: 0.133284; batch adversarial loss: 0.557175\n",
      "epoch 29; iter: 0; batch classifier loss: 0.165878; batch adversarial loss: 0.461485\n",
      "epoch 30; iter: 0; batch classifier loss: 0.113486; batch adversarial loss: 0.462112\n",
      "epoch 31; iter: 0; batch classifier loss: 0.157808; batch adversarial loss: 0.329080\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140196; batch adversarial loss: 0.498520\n",
      "epoch 33; iter: 0; batch classifier loss: 0.148755; batch adversarial loss: 0.417872\n",
      "epoch 34; iter: 0; batch classifier loss: 0.151899; batch adversarial loss: 0.361736\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148923; batch adversarial loss: 0.417061\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126251; batch adversarial loss: 0.397236\n",
      "epoch 37; iter: 0; batch classifier loss: 0.189863; batch adversarial loss: 0.450610\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127623; batch adversarial loss: 0.465194\n",
      "epoch 39; iter: 0; batch classifier loss: 0.144679; batch adversarial loss: 0.505712\n",
      "epoch 40; iter: 0; batch classifier loss: 0.147225; batch adversarial loss: 0.450210\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125550; batch adversarial loss: 0.511184\n",
      "epoch 42; iter: 0; batch classifier loss: 0.078765; batch adversarial loss: 0.399622\n",
      "epoch 43; iter: 0; batch classifier loss: 0.114346; batch adversarial loss: 0.406350\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124952; batch adversarial loss: 0.551069\n",
      "epoch 45; iter: 0; batch classifier loss: 0.113735; batch adversarial loss: 0.444162\n",
      "epoch 46; iter: 0; batch classifier loss: 0.147815; batch adversarial loss: 0.429513\n",
      "epoch 47; iter: 0; batch classifier loss: 0.195288; batch adversarial loss: 0.464946\n",
      "epoch 48; iter: 0; batch classifier loss: 0.174901; batch adversarial loss: 0.427011\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098300; batch adversarial loss: 0.424362\n",
      "epoch 50; iter: 0; batch classifier loss: 0.183498; batch adversarial loss: 0.380896\n",
      "epoch 51; iter: 0; batch classifier loss: 0.110497; batch adversarial loss: 0.391728\n",
      "epoch 52; iter: 0; batch classifier loss: 0.126592; batch adversarial loss: 0.495373\n",
      "epoch 53; iter: 0; batch classifier loss: 0.142654; batch adversarial loss: 0.505012\n",
      "epoch 54; iter: 0; batch classifier loss: 0.125106; batch adversarial loss: 0.416247\n",
      "epoch 55; iter: 0; batch classifier loss: 0.186579; batch adversarial loss: 0.503147\n",
      "epoch 56; iter: 0; batch classifier loss: 0.131517; batch adversarial loss: 0.441686\n",
      "epoch 57; iter: 0; batch classifier loss: 0.134034; batch adversarial loss: 0.419660\n",
      "epoch 58; iter: 0; batch classifier loss: 0.130704; batch adversarial loss: 0.467396\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102338; batch adversarial loss: 0.511129\n",
      "epoch 60; iter: 0; batch classifier loss: 0.162108; batch adversarial loss: 0.453183\n",
      "epoch 61; iter: 0; batch classifier loss: 0.165729; batch adversarial loss: 0.496641\n",
      "epoch 62; iter: 0; batch classifier loss: 0.148487; batch adversarial loss: 0.546391\n",
      "epoch 63; iter: 0; batch classifier loss: 0.158256; batch adversarial loss: 0.455097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.170514; batch adversarial loss: 0.362350\n",
      "epoch 65; iter: 0; batch classifier loss: 0.135355; batch adversarial loss: 0.401639\n",
      "epoch 66; iter: 0; batch classifier loss: 0.118519; batch adversarial loss: 0.463216\n",
      "epoch 67; iter: 0; batch classifier loss: 0.204224; batch adversarial loss: 0.381483\n",
      "epoch 68; iter: 0; batch classifier loss: 0.167985; batch adversarial loss: 0.506890\n",
      "epoch 69; iter: 0; batch classifier loss: 0.149384; batch adversarial loss: 0.471896\n",
      "epoch 70; iter: 0; batch classifier loss: 0.176316; batch adversarial loss: 0.490132\n",
      "epoch 71; iter: 0; batch classifier loss: 0.175074; batch adversarial loss: 0.420325\n",
      "epoch 72; iter: 0; batch classifier loss: 0.146219; batch adversarial loss: 0.475478\n",
      "epoch 73; iter: 0; batch classifier loss: 0.169883; batch adversarial loss: 0.540261\n",
      "epoch 74; iter: 0; batch classifier loss: 0.139768; batch adversarial loss: 0.435641\n",
      "epoch 75; iter: 0; batch classifier loss: 0.214591; batch adversarial loss: 0.460718\n",
      "epoch 76; iter: 0; batch classifier loss: 0.131095; batch adversarial loss: 0.443589\n",
      "epoch 77; iter: 0; batch classifier loss: 0.121262; batch adversarial loss: 0.505509\n",
      "epoch 78; iter: 0; batch classifier loss: 0.111062; batch adversarial loss: 0.358930\n",
      "epoch 79; iter: 0; batch classifier loss: 0.141346; batch adversarial loss: 0.523074\n",
      "epoch 80; iter: 0; batch classifier loss: 0.134914; batch adversarial loss: 0.431406\n",
      "epoch 81; iter: 0; batch classifier loss: 0.207665; batch adversarial loss: 0.548499\n",
      "epoch 82; iter: 0; batch classifier loss: 0.160593; batch adversarial loss: 0.474576\n",
      "epoch 83; iter: 0; batch classifier loss: 0.164748; batch adversarial loss: 0.369470\n",
      "epoch 84; iter: 0; batch classifier loss: 0.143206; batch adversarial loss: 0.430776\n",
      "epoch 85; iter: 0; batch classifier loss: 0.122116; batch adversarial loss: 0.349594\n",
      "epoch 86; iter: 0; batch classifier loss: 0.150341; batch adversarial loss: 0.546018\n",
      "epoch 87; iter: 0; batch classifier loss: 0.122202; batch adversarial loss: 0.426463\n",
      "epoch 88; iter: 0; batch classifier loss: 0.172151; batch adversarial loss: 0.482075\n",
      "epoch 89; iter: 0; batch classifier loss: 0.176343; batch adversarial loss: 0.419384\n",
      "epoch 90; iter: 0; batch classifier loss: 0.132692; batch adversarial loss: 0.448903\n",
      "epoch 91; iter: 0; batch classifier loss: 0.131304; batch adversarial loss: 0.449858\n",
      "epoch 92; iter: 0; batch classifier loss: 0.105589; batch adversarial loss: 0.497285\n",
      "epoch 93; iter: 0; batch classifier loss: 0.194676; batch adversarial loss: 0.394457\n",
      "epoch 94; iter: 0; batch classifier loss: 0.178858; batch adversarial loss: 0.398486\n",
      "epoch 95; iter: 0; batch classifier loss: 0.181004; batch adversarial loss: 0.430521\n",
      "epoch 96; iter: 0; batch classifier loss: 0.144966; batch adversarial loss: 0.522095\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081526; batch adversarial loss: 0.478815\n",
      "epoch 98; iter: 0; batch classifier loss: 0.145594; batch adversarial loss: 0.560560\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069666; batch adversarial loss: 0.543485\n",
      "epoch 100; iter: 0; batch classifier loss: 0.144984; batch adversarial loss: 0.401473\n",
      "epoch 101; iter: 0; batch classifier loss: 0.097667; batch adversarial loss: 0.368773\n",
      "epoch 102; iter: 0; batch classifier loss: 0.084176; batch adversarial loss: 0.387903\n",
      "epoch 103; iter: 0; batch classifier loss: 0.112540; batch adversarial loss: 0.431245\n",
      "epoch 104; iter: 0; batch classifier loss: 0.120324; batch adversarial loss: 0.442727\n",
      "epoch 105; iter: 0; batch classifier loss: 0.079841; batch adversarial loss: 0.425118\n",
      "epoch 106; iter: 0; batch classifier loss: 0.122493; batch adversarial loss: 0.498947\n",
      "epoch 107; iter: 0; batch classifier loss: 0.084009; batch adversarial loss: 0.553892\n",
      "epoch 108; iter: 0; batch classifier loss: 0.076492; batch adversarial loss: 0.460191\n",
      "epoch 109; iter: 0; batch classifier loss: 0.102540; batch adversarial loss: 0.448628\n",
      "epoch 110; iter: 0; batch classifier loss: 0.106395; batch adversarial loss: 0.460343\n",
      "epoch 111; iter: 0; batch classifier loss: 0.112569; batch adversarial loss: 0.435329\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055590; batch adversarial loss: 0.427135\n",
      "epoch 113; iter: 0; batch classifier loss: 0.081317; batch adversarial loss: 0.414998\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059965; batch adversarial loss: 0.479180\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054541; batch adversarial loss: 0.565149\n",
      "epoch 116; iter: 0; batch classifier loss: 0.049000; batch adversarial loss: 0.464426\n",
      "epoch 117; iter: 0; batch classifier loss: 0.086259; batch adversarial loss: 0.411127\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049470; batch adversarial loss: 0.466120\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049712; batch adversarial loss: 0.432987\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045488; batch adversarial loss: 0.511543\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039998; batch adversarial loss: 0.480745\n",
      "epoch 122; iter: 0; batch classifier loss: 0.054981; batch adversarial loss: 0.435858\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048491; batch adversarial loss: 0.483871\n",
      "epoch 124; iter: 0; batch classifier loss: 0.056354; batch adversarial loss: 0.506121\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044743; batch adversarial loss: 0.418437\n",
      "epoch 126; iter: 0; batch classifier loss: 0.053149; batch adversarial loss: 0.361497\n",
      "epoch 127; iter: 0; batch classifier loss: 0.086501; batch adversarial loss: 0.517025\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040706; batch adversarial loss: 0.427329\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038370; batch adversarial loss: 0.488094\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047641; batch adversarial loss: 0.357497\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021724; batch adversarial loss: 0.465149\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049488; batch adversarial loss: 0.403117\n",
      "epoch 133; iter: 0; batch classifier loss: 0.062082; batch adversarial loss: 0.442759\n",
      "epoch 134; iter: 0; batch classifier loss: 0.055154; batch adversarial loss: 0.360866\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028660; batch adversarial loss: 0.483247\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041581; batch adversarial loss: 0.457709\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035098; batch adversarial loss: 0.466341\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028082; batch adversarial loss: 0.465552\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020825; batch adversarial loss: 0.400172\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025656; batch adversarial loss: 0.373338\n",
      "epoch 141; iter: 0; batch classifier loss: 0.055568; batch adversarial loss: 0.464241\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021768; batch adversarial loss: 0.357158\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024526; batch adversarial loss: 0.402210\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033440; batch adversarial loss: 0.368140\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027037; batch adversarial loss: 0.467396\n",
      "epoch 146; iter: 0; batch classifier loss: 0.055071; batch adversarial loss: 0.421943\n",
      "epoch 147; iter: 0; batch classifier loss: 0.065143; batch adversarial loss: 0.417355\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020671; batch adversarial loss: 0.401422\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025340; batch adversarial loss: 0.532040\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016174; batch adversarial loss: 0.431970\n",
      "epoch 151; iter: 0; batch classifier loss: 0.050438; batch adversarial loss: 0.481619\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026702; batch adversarial loss: 0.499998\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048749; batch adversarial loss: 0.402648\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043857; batch adversarial loss: 0.522201\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041856; batch adversarial loss: 0.472326\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015763; batch adversarial loss: 0.473973\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039578; batch adversarial loss: 0.452406\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014698; batch adversarial loss: 0.466139\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039520; batch adversarial loss: 0.476631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.030307; batch adversarial loss: 0.423933\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019497; batch adversarial loss: 0.410972\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009996; batch adversarial loss: 0.356705\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029002; batch adversarial loss: 0.498609\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028676; batch adversarial loss: 0.418424\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010047; batch adversarial loss: 0.373182\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025005; batch adversarial loss: 0.432305\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030829; batch adversarial loss: 0.465862\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009119; batch adversarial loss: 0.470172\n",
      "epoch 169; iter: 0; batch classifier loss: 0.054169; batch adversarial loss: 0.536856\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022846; batch adversarial loss: 0.489000\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025254; batch adversarial loss: 0.548829\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009114; batch adversarial loss: 0.429378\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010794; batch adversarial loss: 0.385766\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018033; batch adversarial loss: 0.483223\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007102; batch adversarial loss: 0.416875\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035224; batch adversarial loss: 0.487567\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031729; batch adversarial loss: 0.420423\n",
      "epoch 178; iter: 0; batch classifier loss: 0.044758; batch adversarial loss: 0.414825\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009511; batch adversarial loss: 0.485429\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029363; batch adversarial loss: 0.434787\n",
      "epoch 181; iter: 0; batch classifier loss: 0.005379; batch adversarial loss: 0.451447\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016642; batch adversarial loss: 0.426771\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018456; batch adversarial loss: 0.522659\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022640; batch adversarial loss: 0.430680\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011637; batch adversarial loss: 0.448713\n",
      "epoch 186; iter: 0; batch classifier loss: 0.043928; batch adversarial loss: 0.407331\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007801; batch adversarial loss: 0.463062\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014893; batch adversarial loss: 0.397915\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013006; batch adversarial loss: 0.387362\n",
      "epoch 190; iter: 0; batch classifier loss: 0.043515; batch adversarial loss: 0.409542\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008288; batch adversarial loss: 0.431077\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006400; batch adversarial loss: 0.417452\n",
      "epoch 193; iter: 0; batch classifier loss: 0.033945; batch adversarial loss: 0.351824\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004879; batch adversarial loss: 0.338967\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014088; batch adversarial loss: 0.439002\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007166; batch adversarial loss: 0.464337\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026110; batch adversarial loss: 0.397006\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011626; batch adversarial loss: 0.444603\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030443; batch adversarial loss: 0.468806\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687239; batch adversarial loss: 0.699956\n",
      "epoch 1; iter: 0; batch classifier loss: 0.452876; batch adversarial loss: 0.635670\n",
      "epoch 2; iter: 0; batch classifier loss: 0.408810; batch adversarial loss: 0.626414\n",
      "epoch 3; iter: 0; batch classifier loss: 0.355582; batch adversarial loss: 0.580360\n",
      "epoch 4; iter: 0; batch classifier loss: 0.458738; batch adversarial loss: 0.572011\n",
      "epoch 5; iter: 0; batch classifier loss: 0.290639; batch adversarial loss: 0.566057\n",
      "epoch 6; iter: 0; batch classifier loss: 0.299540; batch adversarial loss: 0.573052\n",
      "epoch 7; iter: 0; batch classifier loss: 0.248407; batch adversarial loss: 0.524428\n",
      "epoch 8; iter: 0; batch classifier loss: 0.259137; batch adversarial loss: 0.506771\n",
      "epoch 9; iter: 0; batch classifier loss: 0.249089; batch adversarial loss: 0.460861\n",
      "epoch 10; iter: 0; batch classifier loss: 0.296689; batch adversarial loss: 0.482233\n",
      "epoch 11; iter: 0; batch classifier loss: 0.304030; batch adversarial loss: 0.481432\n",
      "epoch 12; iter: 0; batch classifier loss: 0.242265; batch adversarial loss: 0.484579\n",
      "epoch 13; iter: 0; batch classifier loss: 0.220502; batch adversarial loss: 0.431496\n",
      "epoch 14; iter: 0; batch classifier loss: 0.176474; batch adversarial loss: 0.476347\n",
      "epoch 15; iter: 0; batch classifier loss: 0.229695; batch adversarial loss: 0.445348\n",
      "epoch 16; iter: 0; batch classifier loss: 0.229424; batch adversarial loss: 0.547563\n",
      "epoch 17; iter: 0; batch classifier loss: 0.220929; batch adversarial loss: 0.437104\n",
      "epoch 18; iter: 0; batch classifier loss: 0.112446; batch adversarial loss: 0.490943\n",
      "epoch 19; iter: 0; batch classifier loss: 0.199396; batch adversarial loss: 0.461840\n",
      "epoch 20; iter: 0; batch classifier loss: 0.160775; batch adversarial loss: 0.443271\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186419; batch adversarial loss: 0.512196\n",
      "epoch 22; iter: 0; batch classifier loss: 0.217322; batch adversarial loss: 0.474264\n",
      "epoch 23; iter: 0; batch classifier loss: 0.190780; batch adversarial loss: 0.525032\n",
      "epoch 24; iter: 0; batch classifier loss: 0.258167; batch adversarial loss: 0.458689\n",
      "epoch 25; iter: 0; batch classifier loss: 0.282196; batch adversarial loss: 0.525802\n",
      "epoch 26; iter: 0; batch classifier loss: 0.184234; batch adversarial loss: 0.441357\n",
      "epoch 27; iter: 0; batch classifier loss: 0.157740; batch adversarial loss: 0.443207\n",
      "epoch 28; iter: 0; batch classifier loss: 0.194841; batch adversarial loss: 0.489970\n",
      "epoch 29; iter: 0; batch classifier loss: 0.181950; batch adversarial loss: 0.530828\n",
      "epoch 30; iter: 0; batch classifier loss: 0.260113; batch adversarial loss: 0.528712\n",
      "epoch 31; iter: 0; batch classifier loss: 0.284258; batch adversarial loss: 0.412154\n",
      "epoch 32; iter: 0; batch classifier loss: 0.231572; batch adversarial loss: 0.481482\n",
      "epoch 33; iter: 0; batch classifier loss: 0.189827; batch adversarial loss: 0.480799\n",
      "epoch 34; iter: 0; batch classifier loss: 0.103749; batch adversarial loss: 0.434962\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153243; batch adversarial loss: 0.420780\n",
      "epoch 36; iter: 0; batch classifier loss: 0.139541; batch adversarial loss: 0.445089\n",
      "epoch 37; iter: 0; batch classifier loss: 0.151882; batch adversarial loss: 0.454390\n",
      "epoch 38; iter: 0; batch classifier loss: 0.121348; batch adversarial loss: 0.391623\n",
      "epoch 39; iter: 0; batch classifier loss: 0.074747; batch adversarial loss: 0.358810\n",
      "epoch 40; iter: 0; batch classifier loss: 0.101977; batch adversarial loss: 0.469345\n",
      "epoch 41; iter: 0; batch classifier loss: 0.105353; batch adversarial loss: 0.456639\n",
      "epoch 42; iter: 0; batch classifier loss: 0.109911; batch adversarial loss: 0.485088\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089363; batch adversarial loss: 0.409162\n",
      "epoch 44; iter: 0; batch classifier loss: 0.121298; batch adversarial loss: 0.551755\n",
      "epoch 45; iter: 0; batch classifier loss: 0.094545; batch adversarial loss: 0.463401\n",
      "epoch 46; iter: 0; batch classifier loss: 0.082030; batch adversarial loss: 0.469054\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096858; batch adversarial loss: 0.442080\n",
      "epoch 48; iter: 0; batch classifier loss: 0.051053; batch adversarial loss: 0.486434\n",
      "epoch 49; iter: 0; batch classifier loss: 0.064687; batch adversarial loss: 0.479767\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084581; batch adversarial loss: 0.470691\n",
      "epoch 51; iter: 0; batch classifier loss: 0.089365; batch adversarial loss: 0.403079\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112658; batch adversarial loss: 0.507793\n",
      "epoch 53; iter: 0; batch classifier loss: 0.082988; batch adversarial loss: 0.473705\n",
      "epoch 54; iter: 0; batch classifier loss: 0.115461; batch adversarial loss: 0.489696\n",
      "epoch 55; iter: 0; batch classifier loss: 0.111816; batch adversarial loss: 0.484979\n",
      "epoch 56; iter: 0; batch classifier loss: 0.066684; batch adversarial loss: 0.392944\n",
      "epoch 57; iter: 0; batch classifier loss: 0.066302; batch adversarial loss: 0.322344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.093388; batch adversarial loss: 0.492807\n",
      "epoch 59; iter: 0; batch classifier loss: 0.075246; batch adversarial loss: 0.500427\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065310; batch adversarial loss: 0.401589\n",
      "epoch 61; iter: 0; batch classifier loss: 0.094307; batch adversarial loss: 0.431468\n",
      "epoch 62; iter: 0; batch classifier loss: 0.100073; batch adversarial loss: 0.433677\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097369; batch adversarial loss: 0.344279\n",
      "epoch 64; iter: 0; batch classifier loss: 0.091771; batch adversarial loss: 0.336511\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074373; batch adversarial loss: 0.449015\n",
      "epoch 66; iter: 0; batch classifier loss: 0.107180; batch adversarial loss: 0.434382\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110011; batch adversarial loss: 0.494590\n",
      "epoch 68; iter: 0; batch classifier loss: 0.098339; batch adversarial loss: 0.499763\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078152; batch adversarial loss: 0.422756\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079865; batch adversarial loss: 0.494794\n",
      "epoch 71; iter: 0; batch classifier loss: 0.050288; batch adversarial loss: 0.517390\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072038; batch adversarial loss: 0.579944\n",
      "epoch 73; iter: 0; batch classifier loss: 0.091685; batch adversarial loss: 0.419211\n",
      "epoch 74; iter: 0; batch classifier loss: 0.115199; batch adversarial loss: 0.465700\n",
      "epoch 75; iter: 0; batch classifier loss: 0.062237; batch adversarial loss: 0.554098\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069297; batch adversarial loss: 0.472721\n",
      "epoch 77; iter: 0; batch classifier loss: 0.086466; batch adversarial loss: 0.419327\n",
      "epoch 78; iter: 0; batch classifier loss: 0.094790; batch adversarial loss: 0.440074\n",
      "epoch 79; iter: 0; batch classifier loss: 0.105517; batch adversarial loss: 0.486036\n",
      "epoch 80; iter: 0; batch classifier loss: 0.127459; batch adversarial loss: 0.405009\n",
      "epoch 81; iter: 0; batch classifier loss: 0.150651; batch adversarial loss: 0.354642\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056865; batch adversarial loss: 0.563443\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068848; batch adversarial loss: 0.370928\n",
      "epoch 84; iter: 0; batch classifier loss: 0.089872; batch adversarial loss: 0.429691\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065715; batch adversarial loss: 0.451694\n",
      "epoch 86; iter: 0; batch classifier loss: 0.060223; batch adversarial loss: 0.372555\n",
      "epoch 87; iter: 0; batch classifier loss: 0.096722; batch adversarial loss: 0.482933\n",
      "epoch 88; iter: 0; batch classifier loss: 0.079387; batch adversarial loss: 0.466324\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054831; batch adversarial loss: 0.517346\n",
      "epoch 90; iter: 0; batch classifier loss: 0.086175; batch adversarial loss: 0.469001\n",
      "epoch 91; iter: 0; batch classifier loss: 0.104361; batch adversarial loss: 0.379955\n",
      "epoch 92; iter: 0; batch classifier loss: 0.089598; batch adversarial loss: 0.461535\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066200; batch adversarial loss: 0.347223\n",
      "epoch 94; iter: 0; batch classifier loss: 0.145515; batch adversarial loss: 0.467389\n",
      "epoch 95; iter: 0; batch classifier loss: 0.113922; batch adversarial loss: 0.486864\n",
      "epoch 96; iter: 0; batch classifier loss: 0.095435; batch adversarial loss: 0.534169\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075343; batch adversarial loss: 0.448313\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045902; batch adversarial loss: 0.389174\n",
      "epoch 99; iter: 0; batch classifier loss: 0.097799; batch adversarial loss: 0.405387\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034994; batch adversarial loss: 0.570420\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046501; batch adversarial loss: 0.459153\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052833; batch adversarial loss: 0.428864\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042156; batch adversarial loss: 0.541124\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036171; batch adversarial loss: 0.520029\n",
      "epoch 105; iter: 0; batch classifier loss: 0.083951; batch adversarial loss: 0.398208\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052155; batch adversarial loss: 0.472072\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048577; batch adversarial loss: 0.460832\n",
      "epoch 108; iter: 0; batch classifier loss: 0.090060; batch adversarial loss: 0.418362\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051869; batch adversarial loss: 0.537775\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060634; batch adversarial loss: 0.538123\n",
      "epoch 111; iter: 0; batch classifier loss: 0.067784; batch adversarial loss: 0.529868\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045521; batch adversarial loss: 0.516767\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035345; batch adversarial loss: 0.489500\n",
      "epoch 114; iter: 0; batch classifier loss: 0.065594; batch adversarial loss: 0.350223\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041814; batch adversarial loss: 0.556590\n",
      "epoch 116; iter: 0; batch classifier loss: 0.073108; batch adversarial loss: 0.374852\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034781; batch adversarial loss: 0.453904\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054720; batch adversarial loss: 0.384023\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037818; batch adversarial loss: 0.464738\n",
      "epoch 120; iter: 0; batch classifier loss: 0.076785; batch adversarial loss: 0.588306\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028108; batch adversarial loss: 0.464300\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025220; batch adversarial loss: 0.470384\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051907; batch adversarial loss: 0.508965\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029962; batch adversarial loss: 0.493284\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054299; batch adversarial loss: 0.459494\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030265; batch adversarial loss: 0.446616\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022766; batch adversarial loss: 0.453667\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028361; batch adversarial loss: 0.422274\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028770; batch adversarial loss: 0.465382\n",
      "epoch 130; iter: 0; batch classifier loss: 0.049838; batch adversarial loss: 0.448881\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038395; batch adversarial loss: 0.487390\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044594; batch adversarial loss: 0.427746\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036541; batch adversarial loss: 0.436870\n",
      "epoch 134; iter: 0; batch classifier loss: 0.060189; batch adversarial loss: 0.561796\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037636; batch adversarial loss: 0.511959\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023090; batch adversarial loss: 0.526384\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032315; batch adversarial loss: 0.378217\n",
      "epoch 138; iter: 0; batch classifier loss: 0.052337; batch adversarial loss: 0.465979\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016008; batch adversarial loss: 0.396509\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020576; batch adversarial loss: 0.517041\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034336; batch adversarial loss: 0.529590\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028843; batch adversarial loss: 0.394578\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019070; batch adversarial loss: 0.515496\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026989; batch adversarial loss: 0.474069\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032897; batch adversarial loss: 0.409589\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032805; batch adversarial loss: 0.453341\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010402; batch adversarial loss: 0.480196\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021394; batch adversarial loss: 0.469126\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029762; batch adversarial loss: 0.485705\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026234; batch adversarial loss: 0.398843\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039668; batch adversarial loss: 0.400102\n",
      "epoch 152; iter: 0; batch classifier loss: 0.012460; batch adversarial loss: 0.473320\n",
      "epoch 153; iter: 0; batch classifier loss: 0.033184; batch adversarial loss: 0.539464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.066887; batch adversarial loss: 0.443458\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037556; batch adversarial loss: 0.453897\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018886; batch adversarial loss: 0.446941\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022837; batch adversarial loss: 0.451979\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044401; batch adversarial loss: 0.395136\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023949; batch adversarial loss: 0.453842\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012603; batch adversarial loss: 0.445676\n",
      "epoch 161; iter: 0; batch classifier loss: 0.055591; batch adversarial loss: 0.398631\n",
      "epoch 162; iter: 0; batch classifier loss: 0.060395; batch adversarial loss: 0.467664\n",
      "epoch 163; iter: 0; batch classifier loss: 0.041850; batch adversarial loss: 0.430241\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029704; batch adversarial loss: 0.456667\n",
      "epoch 165; iter: 0; batch classifier loss: 0.052517; batch adversarial loss: 0.439459\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032840; batch adversarial loss: 0.488225\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028430; batch adversarial loss: 0.431903\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013857; batch adversarial loss: 0.470857\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033710; batch adversarial loss: 0.386468\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032227; batch adversarial loss: 0.480037\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018716; batch adversarial loss: 0.475606\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010024; batch adversarial loss: 0.458884\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026331; batch adversarial loss: 0.487483\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018303; batch adversarial loss: 0.452614\n",
      "epoch 175; iter: 0; batch classifier loss: 0.047763; batch adversarial loss: 0.358469\n",
      "epoch 176; iter: 0; batch classifier loss: 0.038489; batch adversarial loss: 0.487574\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013975; batch adversarial loss: 0.507440\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025486; batch adversarial loss: 0.505836\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028696; batch adversarial loss: 0.339988\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010730; batch adversarial loss: 0.444450\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017841; batch adversarial loss: 0.506549\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022194; batch adversarial loss: 0.437016\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022857; batch adversarial loss: 0.385658\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037810; batch adversarial loss: 0.438514\n",
      "epoch 185; iter: 0; batch classifier loss: 0.055162; batch adversarial loss: 0.428791\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018380; batch adversarial loss: 0.508713\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030332; batch adversarial loss: 0.394107\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034197; batch adversarial loss: 0.329955\n",
      "epoch 189; iter: 0; batch classifier loss: 0.082230; batch adversarial loss: 0.406709\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016749; batch adversarial loss: 0.411831\n",
      "epoch 191; iter: 0; batch classifier loss: 0.045873; batch adversarial loss: 0.407124\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006363; batch adversarial loss: 0.432543\n",
      "epoch 193; iter: 0; batch classifier loss: 0.048766; batch adversarial loss: 0.531228\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036618; batch adversarial loss: 0.479734\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020380; batch adversarial loss: 0.325148\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026311; batch adversarial loss: 0.444183\n",
      "epoch 197; iter: 0; batch classifier loss: 0.043849; batch adversarial loss: 0.469960\n",
      "epoch 198; iter: 0; batch classifier loss: 0.055793; batch adversarial loss: 0.455433\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004258; batch adversarial loss: 0.468620\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689877; batch adversarial loss: 0.816720\n",
      "epoch 1; iter: 0; batch classifier loss: 0.506442; batch adversarial loss: 0.832999\n",
      "epoch 2; iter: 0; batch classifier loss: 0.493539; batch adversarial loss: 0.784676\n",
      "epoch 3; iter: 0; batch classifier loss: 0.793010; batch adversarial loss: 0.753901\n",
      "epoch 4; iter: 0; batch classifier loss: 0.802478; batch adversarial loss: 0.687222\n",
      "epoch 5; iter: 0; batch classifier loss: 0.850366; batch adversarial loss: 0.610707\n",
      "epoch 6; iter: 0; batch classifier loss: 0.405892; batch adversarial loss: 0.593069\n",
      "epoch 7; iter: 0; batch classifier loss: 0.395289; batch adversarial loss: 0.561918\n",
      "epoch 8; iter: 0; batch classifier loss: 0.364066; batch adversarial loss: 0.542239\n",
      "epoch 9; iter: 0; batch classifier loss: 0.293679; batch adversarial loss: 0.575908\n",
      "epoch 10; iter: 0; batch classifier loss: 0.337348; batch adversarial loss: 0.534027\n",
      "epoch 11; iter: 0; batch classifier loss: 0.301354; batch adversarial loss: 0.594122\n",
      "epoch 12; iter: 0; batch classifier loss: 0.398023; batch adversarial loss: 0.514756\n",
      "epoch 13; iter: 0; batch classifier loss: 0.378698; batch adversarial loss: 0.543585\n",
      "epoch 14; iter: 0; batch classifier loss: 0.435745; batch adversarial loss: 0.515194\n",
      "epoch 15; iter: 0; batch classifier loss: 0.291678; batch adversarial loss: 0.524021\n",
      "epoch 16; iter: 0; batch classifier loss: 0.410759; batch adversarial loss: 0.500417\n",
      "epoch 17; iter: 0; batch classifier loss: 0.387811; batch adversarial loss: 0.482537\n",
      "epoch 18; iter: 0; batch classifier loss: 0.442874; batch adversarial loss: 0.513946\n",
      "epoch 19; iter: 0; batch classifier loss: 0.359125; batch adversarial loss: 0.518255\n",
      "epoch 20; iter: 0; batch classifier loss: 0.343238; batch adversarial loss: 0.546347\n",
      "epoch 21; iter: 0; batch classifier loss: 0.297074; batch adversarial loss: 0.441062\n",
      "epoch 22; iter: 0; batch classifier loss: 0.304603; batch adversarial loss: 0.473814\n",
      "epoch 23; iter: 0; batch classifier loss: 0.333334; batch adversarial loss: 0.464817\n",
      "epoch 24; iter: 0; batch classifier loss: 0.272657; batch adversarial loss: 0.443166\n",
      "epoch 25; iter: 0; batch classifier loss: 0.274907; batch adversarial loss: 0.446853\n",
      "epoch 26; iter: 0; batch classifier loss: 0.315148; batch adversarial loss: 0.477538\n",
      "epoch 27; iter: 0; batch classifier loss: 0.282435; batch adversarial loss: 0.467797\n",
      "epoch 28; iter: 0; batch classifier loss: 0.311984; batch adversarial loss: 0.396882\n",
      "epoch 29; iter: 0; batch classifier loss: 0.281056; batch adversarial loss: 0.509157\n",
      "epoch 30; iter: 0; batch classifier loss: 0.262918; batch adversarial loss: 0.429728\n",
      "epoch 31; iter: 0; batch classifier loss: 0.211223; batch adversarial loss: 0.436372\n",
      "epoch 32; iter: 0; batch classifier loss: 0.328976; batch adversarial loss: 0.426024\n",
      "epoch 33; iter: 0; batch classifier loss: 0.244342; batch adversarial loss: 0.451702\n",
      "epoch 34; iter: 0; batch classifier loss: 0.231743; batch adversarial loss: 0.400442\n",
      "epoch 35; iter: 0; batch classifier loss: 0.158779; batch adversarial loss: 0.470699\n",
      "epoch 36; iter: 0; batch classifier loss: 0.246355; batch adversarial loss: 0.505048\n",
      "epoch 37; iter: 0; batch classifier loss: 0.220244; batch adversarial loss: 0.476231\n",
      "epoch 38; iter: 0; batch classifier loss: 0.183712; batch adversarial loss: 0.470782\n",
      "epoch 39; iter: 0; batch classifier loss: 0.238294; batch adversarial loss: 0.503472\n",
      "epoch 40; iter: 0; batch classifier loss: 0.227259; batch adversarial loss: 0.428184\n",
      "epoch 41; iter: 0; batch classifier loss: 0.140965; batch adversarial loss: 0.470814\n",
      "epoch 42; iter: 0; batch classifier loss: 0.155712; batch adversarial loss: 0.485108\n",
      "epoch 43; iter: 0; batch classifier loss: 0.168170; batch adversarial loss: 0.449730\n",
      "epoch 44; iter: 0; batch classifier loss: 0.194807; batch adversarial loss: 0.521573\n",
      "epoch 45; iter: 0; batch classifier loss: 0.179449; batch adversarial loss: 0.475527\n",
      "epoch 46; iter: 0; batch classifier loss: 0.129028; batch adversarial loss: 0.533968\n",
      "epoch 47; iter: 0; batch classifier loss: 0.165708; batch adversarial loss: 0.472569\n",
      "epoch 48; iter: 0; batch classifier loss: 0.160306; batch adversarial loss: 0.504024\n",
      "epoch 49; iter: 0; batch classifier loss: 0.102554; batch adversarial loss: 0.475571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.180530; batch adversarial loss: 0.380211\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112490; batch adversarial loss: 0.464412\n",
      "epoch 52; iter: 0; batch classifier loss: 0.104422; batch adversarial loss: 0.429789\n",
      "epoch 53; iter: 0; batch classifier loss: 0.154827; batch adversarial loss: 0.406522\n",
      "epoch 54; iter: 0; batch classifier loss: 0.141291; batch adversarial loss: 0.409564\n",
      "epoch 55; iter: 0; batch classifier loss: 0.068249; batch adversarial loss: 0.513590\n",
      "epoch 56; iter: 0; batch classifier loss: 0.068369; batch adversarial loss: 0.341996\n",
      "epoch 57; iter: 0; batch classifier loss: 0.089901; batch adversarial loss: 0.495411\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097124; batch adversarial loss: 0.426825\n",
      "epoch 59; iter: 0; batch classifier loss: 0.094275; batch adversarial loss: 0.430599\n",
      "epoch 60; iter: 0; batch classifier loss: 0.119163; batch adversarial loss: 0.405687\n",
      "epoch 61; iter: 0; batch classifier loss: 0.060690; batch adversarial loss: 0.490934\n",
      "epoch 62; iter: 0; batch classifier loss: 0.119393; batch adversarial loss: 0.462104\n",
      "epoch 63; iter: 0; batch classifier loss: 0.053683; batch adversarial loss: 0.418901\n",
      "epoch 64; iter: 0; batch classifier loss: 0.046227; batch adversarial loss: 0.456127\n",
      "epoch 65; iter: 0; batch classifier loss: 0.098739; batch adversarial loss: 0.411904\n",
      "epoch 66; iter: 0; batch classifier loss: 0.104147; batch adversarial loss: 0.438777\n",
      "epoch 67; iter: 0; batch classifier loss: 0.092304; batch adversarial loss: 0.429325\n",
      "epoch 68; iter: 0; batch classifier loss: 0.098702; batch adversarial loss: 0.403217\n",
      "epoch 69; iter: 0; batch classifier loss: 0.052909; batch adversarial loss: 0.482932\n",
      "epoch 70; iter: 0; batch classifier loss: 0.058683; batch adversarial loss: 0.424291\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058677; batch adversarial loss: 0.454450\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077781; batch adversarial loss: 0.422152\n",
      "epoch 73; iter: 0; batch classifier loss: 0.066911; batch adversarial loss: 0.490552\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075162; batch adversarial loss: 0.470439\n",
      "epoch 75; iter: 0; batch classifier loss: 0.047401; batch adversarial loss: 0.398709\n",
      "epoch 76; iter: 0; batch classifier loss: 0.048426; batch adversarial loss: 0.571784\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074008; batch adversarial loss: 0.440962\n",
      "epoch 78; iter: 0; batch classifier loss: 0.046500; batch adversarial loss: 0.432783\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057997; batch adversarial loss: 0.497557\n",
      "epoch 80; iter: 0; batch classifier loss: 0.055077; batch adversarial loss: 0.503193\n",
      "epoch 81; iter: 0; batch classifier loss: 0.063170; batch adversarial loss: 0.529242\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063028; batch adversarial loss: 0.562646\n",
      "epoch 83; iter: 0; batch classifier loss: 0.046490; batch adversarial loss: 0.533204\n",
      "epoch 84; iter: 0; batch classifier loss: 0.037083; batch adversarial loss: 0.465404\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052049; batch adversarial loss: 0.457627\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069192; batch adversarial loss: 0.449946\n",
      "epoch 87; iter: 0; batch classifier loss: 0.026292; batch adversarial loss: 0.623860\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055184; batch adversarial loss: 0.494242\n",
      "epoch 89; iter: 0; batch classifier loss: 0.046034; batch adversarial loss: 0.428596\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054295; batch adversarial loss: 0.450904\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062173; batch adversarial loss: 0.500919\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040890; batch adversarial loss: 0.429048\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041910; batch adversarial loss: 0.357038\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038525; batch adversarial loss: 0.477472\n",
      "epoch 95; iter: 0; batch classifier loss: 0.029774; batch adversarial loss: 0.400677\n",
      "epoch 96; iter: 0; batch classifier loss: 0.032090; batch adversarial loss: 0.508682\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046763; batch adversarial loss: 0.425161\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051667; batch adversarial loss: 0.434424\n",
      "epoch 99; iter: 0; batch classifier loss: 0.032651; batch adversarial loss: 0.484673\n",
      "epoch 100; iter: 0; batch classifier loss: 0.022375; batch adversarial loss: 0.540470\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037256; batch adversarial loss: 0.589127\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039419; batch adversarial loss: 0.577787\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039259; batch adversarial loss: 0.526636\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060460; batch adversarial loss: 0.412803\n",
      "epoch 105; iter: 0; batch classifier loss: 0.023312; batch adversarial loss: 0.509768\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031102; batch adversarial loss: 0.438824\n",
      "epoch 107; iter: 0; batch classifier loss: 0.030896; batch adversarial loss: 0.468458\n",
      "epoch 108; iter: 0; batch classifier loss: 0.083950; batch adversarial loss: 0.453615\n",
      "epoch 109; iter: 0; batch classifier loss: 0.028283; batch adversarial loss: 0.403440\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030688; batch adversarial loss: 0.409892\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035004; batch adversarial loss: 0.461968\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024464; batch adversarial loss: 0.393082\n",
      "epoch 113; iter: 0; batch classifier loss: 0.020426; batch adversarial loss: 0.531784\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054700; batch adversarial loss: 0.550239\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056742; batch adversarial loss: 0.516621\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039557; batch adversarial loss: 0.510776\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031081; batch adversarial loss: 0.445060\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042674; batch adversarial loss: 0.539362\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040561; batch adversarial loss: 0.430767\n",
      "epoch 120; iter: 0; batch classifier loss: 0.026107; batch adversarial loss: 0.355440\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035261; batch adversarial loss: 0.506911\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044154; batch adversarial loss: 0.482850\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024904; batch adversarial loss: 0.402474\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032512; batch adversarial loss: 0.320649\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045273; batch adversarial loss: 0.462083\n",
      "epoch 126; iter: 0; batch classifier loss: 0.015322; batch adversarial loss: 0.464105\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037212; batch adversarial loss: 0.502801\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036101; batch adversarial loss: 0.459923\n",
      "epoch 129; iter: 0; batch classifier loss: 0.013281; batch adversarial loss: 0.521553\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059080; batch adversarial loss: 0.510502\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035796; batch adversarial loss: 0.463677\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038677; batch adversarial loss: 0.410684\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021732; batch adversarial loss: 0.463212\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025839; batch adversarial loss: 0.438184\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026546; batch adversarial loss: 0.377216\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054597; batch adversarial loss: 0.474262\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030169; batch adversarial loss: 0.476059\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021425; batch adversarial loss: 0.443087\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018785; batch adversarial loss: 0.589142\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036160; batch adversarial loss: 0.467133\n",
      "epoch 141; iter: 0; batch classifier loss: 0.012285; batch adversarial loss: 0.395788\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013399; batch adversarial loss: 0.451197\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014251; batch adversarial loss: 0.473845\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020778; batch adversarial loss: 0.495121\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018589; batch adversarial loss: 0.539676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.017147; batch adversarial loss: 0.450474\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031655; batch adversarial loss: 0.393097\n",
      "epoch 148; iter: 0; batch classifier loss: 0.009058; batch adversarial loss: 0.512524\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012894; batch adversarial loss: 0.494820\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028313; batch adversarial loss: 0.389672\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015329; batch adversarial loss: 0.355292\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010107; batch adversarial loss: 0.468245\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020637; batch adversarial loss: 0.363425\n",
      "epoch 154; iter: 0; batch classifier loss: 0.006857; batch adversarial loss: 0.431809\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022210; batch adversarial loss: 0.340437\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010193; batch adversarial loss: 0.445327\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041930; batch adversarial loss: 0.406640\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016117; batch adversarial loss: 0.450521\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033336; batch adversarial loss: 0.477302\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023635; batch adversarial loss: 0.376493\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024299; batch adversarial loss: 0.512023\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015750; batch adversarial loss: 0.551134\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013002; batch adversarial loss: 0.465482\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032748; batch adversarial loss: 0.529913\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031830; batch adversarial loss: 0.442270\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011411; batch adversarial loss: 0.471034\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026336; batch adversarial loss: 0.480816\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018748; batch adversarial loss: 0.483585\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007226; batch adversarial loss: 0.386223\n",
      "epoch 170; iter: 0; batch classifier loss: 0.006337; batch adversarial loss: 0.374600\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029794; batch adversarial loss: 0.425249\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020605; batch adversarial loss: 0.507911\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016915; batch adversarial loss: 0.425288\n",
      "epoch 174; iter: 0; batch classifier loss: 0.044353; batch adversarial loss: 0.409787\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016034; batch adversarial loss: 0.425745\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013914; batch adversarial loss: 0.503295\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012326; batch adversarial loss: 0.476335\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009474; batch adversarial loss: 0.460764\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019289; batch adversarial loss: 0.397710\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030357; batch adversarial loss: 0.396485\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018996; batch adversarial loss: 0.439196\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022770; batch adversarial loss: 0.450984\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007818; batch adversarial loss: 0.415798\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007475; batch adversarial loss: 0.463081\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029552; batch adversarial loss: 0.467439\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017833; batch adversarial loss: 0.484261\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006963; batch adversarial loss: 0.362127\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009212; batch adversarial loss: 0.482941\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015802; batch adversarial loss: 0.386980\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007846; batch adversarial loss: 0.455119\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020253; batch adversarial loss: 0.408255\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009514; batch adversarial loss: 0.491701\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006532; batch adversarial loss: 0.385752\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017866; batch adversarial loss: 0.432445\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023311; batch adversarial loss: 0.505766\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011386; batch adversarial loss: 0.518862\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009479; batch adversarial loss: 0.389648\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031160; batch adversarial loss: 0.429426\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012100; batch adversarial loss: 0.484241\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692967; batch adversarial loss: 0.617241\n",
      "epoch 1; iter: 0; batch classifier loss: 0.393953; batch adversarial loss: 0.627575\n",
      "epoch 2; iter: 0; batch classifier loss: 0.457986; batch adversarial loss: 0.592193\n",
      "epoch 3; iter: 0; batch classifier loss: 0.351412; batch adversarial loss: 0.617698\n",
      "epoch 4; iter: 0; batch classifier loss: 0.427293; batch adversarial loss: 0.627175\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551428; batch adversarial loss: 0.611454\n",
      "epoch 6; iter: 0; batch classifier loss: 0.502843; batch adversarial loss: 0.631375\n",
      "epoch 7; iter: 0; batch classifier loss: 0.431492; batch adversarial loss: 0.570486\n",
      "epoch 8; iter: 0; batch classifier loss: 0.504995; batch adversarial loss: 0.543799\n",
      "epoch 9; iter: 0; batch classifier loss: 0.418410; batch adversarial loss: 0.617910\n",
      "epoch 10; iter: 0; batch classifier loss: 0.434968; batch adversarial loss: 0.498283\n",
      "epoch 11; iter: 0; batch classifier loss: 0.321609; batch adversarial loss: 0.549054\n",
      "epoch 12; iter: 0; batch classifier loss: 0.333643; batch adversarial loss: 0.446080\n",
      "epoch 13; iter: 0; batch classifier loss: 0.325098; batch adversarial loss: 0.606945\n",
      "epoch 14; iter: 0; batch classifier loss: 0.347428; batch adversarial loss: 0.567052\n",
      "epoch 15; iter: 0; batch classifier loss: 0.253752; batch adversarial loss: 0.466303\n",
      "epoch 16; iter: 0; batch classifier loss: 0.321084; batch adversarial loss: 0.502619\n",
      "epoch 17; iter: 0; batch classifier loss: 0.276570; batch adversarial loss: 0.476653\n",
      "epoch 18; iter: 0; batch classifier loss: 0.216726; batch adversarial loss: 0.559284\n",
      "epoch 19; iter: 0; batch classifier loss: 0.188390; batch adversarial loss: 0.488742\n",
      "epoch 20; iter: 0; batch classifier loss: 0.189563; batch adversarial loss: 0.513243\n",
      "epoch 21; iter: 0; batch classifier loss: 0.286246; batch adversarial loss: 0.507119\n",
      "epoch 22; iter: 0; batch classifier loss: 0.233453; batch adversarial loss: 0.483721\n",
      "epoch 23; iter: 0; batch classifier loss: 0.254598; batch adversarial loss: 0.446421\n",
      "epoch 24; iter: 0; batch classifier loss: 0.172576; batch adversarial loss: 0.462746\n",
      "epoch 25; iter: 0; batch classifier loss: 0.123524; batch adversarial loss: 0.497583\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187760; batch adversarial loss: 0.557707\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175359; batch adversarial loss: 0.523059\n",
      "epoch 28; iter: 0; batch classifier loss: 0.148243; batch adversarial loss: 0.527130\n",
      "epoch 29; iter: 0; batch classifier loss: 0.164940; batch adversarial loss: 0.473078\n",
      "epoch 30; iter: 0; batch classifier loss: 0.165959; batch adversarial loss: 0.496139\n",
      "epoch 31; iter: 0; batch classifier loss: 0.165253; batch adversarial loss: 0.450305\n",
      "epoch 32; iter: 0; batch classifier loss: 0.155940; batch adversarial loss: 0.417998\n",
      "epoch 33; iter: 0; batch classifier loss: 0.200560; batch adversarial loss: 0.446041\n",
      "epoch 34; iter: 0; batch classifier loss: 0.176402; batch adversarial loss: 0.425187\n",
      "epoch 35; iter: 0; batch classifier loss: 0.114739; batch adversarial loss: 0.459172\n",
      "epoch 36; iter: 0; batch classifier loss: 0.138696; batch adversarial loss: 0.514619\n",
      "epoch 37; iter: 0; batch classifier loss: 0.126973; batch adversarial loss: 0.498310\n",
      "epoch 38; iter: 0; batch classifier loss: 0.151783; batch adversarial loss: 0.439649\n",
      "epoch 39; iter: 0; batch classifier loss: 0.166274; batch adversarial loss: 0.545074\n",
      "epoch 40; iter: 0; batch classifier loss: 0.202612; batch adversarial loss: 0.449710\n",
      "epoch 41; iter: 0; batch classifier loss: 0.154673; batch adversarial loss: 0.361110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.150976; batch adversarial loss: 0.457796\n",
      "epoch 43; iter: 0; batch classifier loss: 0.107716; batch adversarial loss: 0.524608\n",
      "epoch 44; iter: 0; batch classifier loss: 0.094529; batch adversarial loss: 0.470139\n",
      "epoch 45; iter: 0; batch classifier loss: 0.128464; batch adversarial loss: 0.425931\n",
      "epoch 46; iter: 0; batch classifier loss: 0.124330; batch adversarial loss: 0.463912\n",
      "epoch 47; iter: 0; batch classifier loss: 0.170301; batch adversarial loss: 0.417841\n",
      "epoch 48; iter: 0; batch classifier loss: 0.178742; batch adversarial loss: 0.433803\n",
      "epoch 49; iter: 0; batch classifier loss: 0.135513; batch adversarial loss: 0.471331\n",
      "epoch 50; iter: 0; batch classifier loss: 0.104343; batch adversarial loss: 0.535982\n",
      "epoch 51; iter: 0; batch classifier loss: 0.154613; batch adversarial loss: 0.498759\n",
      "epoch 52; iter: 0; batch classifier loss: 0.144470; batch adversarial loss: 0.434333\n",
      "epoch 53; iter: 0; batch classifier loss: 0.146571; batch adversarial loss: 0.496359\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122338; batch adversarial loss: 0.514365\n",
      "epoch 55; iter: 0; batch classifier loss: 0.142207; batch adversarial loss: 0.490144\n",
      "epoch 56; iter: 0; batch classifier loss: 0.139100; batch adversarial loss: 0.391520\n",
      "epoch 57; iter: 0; batch classifier loss: 0.151297; batch adversarial loss: 0.561527\n",
      "epoch 58; iter: 0; batch classifier loss: 0.119785; batch adversarial loss: 0.540459\n",
      "epoch 59; iter: 0; batch classifier loss: 0.147521; batch adversarial loss: 0.493205\n",
      "epoch 60; iter: 0; batch classifier loss: 0.151442; batch adversarial loss: 0.503060\n",
      "epoch 61; iter: 0; batch classifier loss: 0.124801; batch adversarial loss: 0.493197\n",
      "epoch 62; iter: 0; batch classifier loss: 0.139738; batch adversarial loss: 0.446282\n",
      "epoch 63; iter: 0; batch classifier loss: 0.174477; batch adversarial loss: 0.502454\n",
      "epoch 64; iter: 0; batch classifier loss: 0.116826; batch adversarial loss: 0.440778\n",
      "epoch 65; iter: 0; batch classifier loss: 0.124224; batch adversarial loss: 0.437908\n",
      "epoch 66; iter: 0; batch classifier loss: 0.194367; batch adversarial loss: 0.406931\n",
      "epoch 67; iter: 0; batch classifier loss: 0.127898; batch adversarial loss: 0.488476\n",
      "epoch 68; iter: 0; batch classifier loss: 0.148763; batch adversarial loss: 0.496652\n",
      "epoch 69; iter: 0; batch classifier loss: 0.204688; batch adversarial loss: 0.538237\n",
      "epoch 70; iter: 0; batch classifier loss: 0.128257; batch adversarial loss: 0.505244\n",
      "epoch 71; iter: 0; batch classifier loss: 0.184156; batch adversarial loss: 0.446414\n",
      "epoch 72; iter: 0; batch classifier loss: 0.142384; batch adversarial loss: 0.431861\n",
      "epoch 73; iter: 0; batch classifier loss: 0.106662; batch adversarial loss: 0.558533\n",
      "epoch 74; iter: 0; batch classifier loss: 0.236700; batch adversarial loss: 0.469508\n",
      "epoch 75; iter: 0; batch classifier loss: 0.138815; batch adversarial loss: 0.431712\n",
      "epoch 76; iter: 0; batch classifier loss: 0.179353; batch adversarial loss: 0.502319\n",
      "epoch 77; iter: 0; batch classifier loss: 0.160792; batch adversarial loss: 0.445516\n",
      "epoch 78; iter: 0; batch classifier loss: 0.154448; batch adversarial loss: 0.364723\n",
      "epoch 79; iter: 0; batch classifier loss: 0.122023; batch adversarial loss: 0.409279\n",
      "epoch 80; iter: 0; batch classifier loss: 0.138199; batch adversarial loss: 0.431064\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096655; batch adversarial loss: 0.468468\n",
      "epoch 82; iter: 0; batch classifier loss: 0.142044; batch adversarial loss: 0.420926\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061351; batch adversarial loss: 0.552470\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079619; batch adversarial loss: 0.471554\n",
      "epoch 85; iter: 0; batch classifier loss: 0.128371; batch adversarial loss: 0.397252\n",
      "epoch 86; iter: 0; batch classifier loss: 0.095908; batch adversarial loss: 0.512847\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106247; batch adversarial loss: 0.497159\n",
      "epoch 88; iter: 0; batch classifier loss: 0.124870; batch adversarial loss: 0.426155\n",
      "epoch 89; iter: 0; batch classifier loss: 0.131860; batch adversarial loss: 0.446698\n",
      "epoch 90; iter: 0; batch classifier loss: 0.124078; batch adversarial loss: 0.468692\n",
      "epoch 91; iter: 0; batch classifier loss: 0.094911; batch adversarial loss: 0.440103\n",
      "epoch 92; iter: 0; batch classifier loss: 0.128668; batch adversarial loss: 0.481533\n",
      "epoch 93; iter: 0; batch classifier loss: 0.113890; batch adversarial loss: 0.416196\n",
      "epoch 94; iter: 0; batch classifier loss: 0.127180; batch adversarial loss: 0.524070\n",
      "epoch 95; iter: 0; batch classifier loss: 0.134525; batch adversarial loss: 0.406781\n",
      "epoch 96; iter: 0; batch classifier loss: 0.087785; batch adversarial loss: 0.393775\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046070; batch adversarial loss: 0.396189\n",
      "epoch 98; iter: 0; batch classifier loss: 0.038208; batch adversarial loss: 0.430978\n",
      "epoch 99; iter: 0; batch classifier loss: 0.110513; batch adversarial loss: 0.523253\n",
      "epoch 100; iter: 0; batch classifier loss: 0.030339; batch adversarial loss: 0.448601\n",
      "epoch 101; iter: 0; batch classifier loss: 0.077049; batch adversarial loss: 0.396372\n",
      "epoch 102; iter: 0; batch classifier loss: 0.040330; batch adversarial loss: 0.491516\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032513; batch adversarial loss: 0.451646\n",
      "epoch 104; iter: 0; batch classifier loss: 0.080574; batch adversarial loss: 0.477857\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052342; batch adversarial loss: 0.428897\n",
      "epoch 106; iter: 0; batch classifier loss: 0.078945; batch adversarial loss: 0.412899\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052450; batch adversarial loss: 0.438410\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065366; batch adversarial loss: 0.452502\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044192; batch adversarial loss: 0.447632\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069649; batch adversarial loss: 0.403604\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040217; batch adversarial loss: 0.363688\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036762; batch adversarial loss: 0.559546\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048756; batch adversarial loss: 0.459692\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052555; batch adversarial loss: 0.461882\n",
      "epoch 115; iter: 0; batch classifier loss: 0.089424; batch adversarial loss: 0.426763\n",
      "epoch 116; iter: 0; batch classifier loss: 0.019994; batch adversarial loss: 0.372853\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061658; batch adversarial loss: 0.489338\n",
      "epoch 118; iter: 0; batch classifier loss: 0.020896; batch adversarial loss: 0.448129\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047454; batch adversarial loss: 0.390224\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054785; batch adversarial loss: 0.534272\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034506; batch adversarial loss: 0.542625\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044053; batch adversarial loss: 0.484652\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046007; batch adversarial loss: 0.463569\n",
      "epoch 124; iter: 0; batch classifier loss: 0.049012; batch adversarial loss: 0.411634\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058795; batch adversarial loss: 0.472439\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031441; batch adversarial loss: 0.481251\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029495; batch adversarial loss: 0.490819\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022980; batch adversarial loss: 0.522891\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029709; batch adversarial loss: 0.440481\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039664; batch adversarial loss: 0.409210\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036261; batch adversarial loss: 0.430247\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030504; batch adversarial loss: 0.472835\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039954; batch adversarial loss: 0.478007\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032484; batch adversarial loss: 0.413130\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011946; batch adversarial loss: 0.451632\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017056; batch adversarial loss: 0.444587\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020455; batch adversarial loss: 0.516279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.018925; batch adversarial loss: 0.521189\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042948; batch adversarial loss: 0.368223\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017975; batch adversarial loss: 0.411024\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022944; batch adversarial loss: 0.449172\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027450; batch adversarial loss: 0.491109\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046331; batch adversarial loss: 0.457411\n",
      "epoch 144; iter: 0; batch classifier loss: 0.042626; batch adversarial loss: 0.383299\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041444; batch adversarial loss: 0.461266\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051685; batch adversarial loss: 0.403097\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023561; batch adversarial loss: 0.437889\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034496; batch adversarial loss: 0.600473\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034536; batch adversarial loss: 0.450914\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012380; batch adversarial loss: 0.459623\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009658; batch adversarial loss: 0.467250\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041427; batch adversarial loss: 0.546296\n",
      "epoch 153; iter: 0; batch classifier loss: 0.053585; batch adversarial loss: 0.427582\n",
      "epoch 154; iter: 0; batch classifier loss: 0.050834; batch adversarial loss: 0.508042\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016386; batch adversarial loss: 0.421243\n",
      "epoch 156; iter: 0; batch classifier loss: 0.008582; batch adversarial loss: 0.449051\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017388; batch adversarial loss: 0.530763\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029135; batch adversarial loss: 0.407410\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020562; batch adversarial loss: 0.524179\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007648; batch adversarial loss: 0.471898\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009494; batch adversarial loss: 0.447554\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029004; batch adversarial loss: 0.481913\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009085; batch adversarial loss: 0.523293\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033046; batch adversarial loss: 0.498548\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025191; batch adversarial loss: 0.448609\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029933; batch adversarial loss: 0.496794\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017409; batch adversarial loss: 0.414028\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025470; batch adversarial loss: 0.451193\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014187; batch adversarial loss: 0.404056\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034220; batch adversarial loss: 0.437178\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015309; batch adversarial loss: 0.420702\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010951; batch adversarial loss: 0.481251\n",
      "epoch 173; iter: 0; batch classifier loss: 0.003154; batch adversarial loss: 0.501703\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016356; batch adversarial loss: 0.414352\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027235; batch adversarial loss: 0.497182\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017778; batch adversarial loss: 0.494040\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016711; batch adversarial loss: 0.493743\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029646; batch adversarial loss: 0.442515\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020797; batch adversarial loss: 0.417776\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016967; batch adversarial loss: 0.412817\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014733; batch adversarial loss: 0.445733\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031045; batch adversarial loss: 0.483963\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007439; batch adversarial loss: 0.439814\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014274; batch adversarial loss: 0.511925\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016436; batch adversarial loss: 0.511861\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034960; batch adversarial loss: 0.441081\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023754; batch adversarial loss: 0.377488\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029766; batch adversarial loss: 0.495827\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008183; batch adversarial loss: 0.461236\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020213; batch adversarial loss: 0.433517\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009704; batch adversarial loss: 0.431526\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009040; batch adversarial loss: 0.483723\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006968; batch adversarial loss: 0.452406\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024645; batch adversarial loss: 0.527178\n",
      "epoch 195; iter: 0; batch classifier loss: 0.003871; batch adversarial loss: 0.383619\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024627; batch adversarial loss: 0.501391\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015448; batch adversarial loss: 0.429960\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010635; batch adversarial loss: 0.610172\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004808; batch adversarial loss: 0.419948\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717968; batch adversarial loss: 0.579656\n",
      "epoch 1; iter: 0; batch classifier loss: 0.468767; batch adversarial loss: 0.596251\n",
      "epoch 2; iter: 0; batch classifier loss: 0.341012; batch adversarial loss: 0.608881\n",
      "epoch 3; iter: 0; batch classifier loss: 0.416447; batch adversarial loss: 0.584148\n",
      "epoch 4; iter: 0; batch classifier loss: 0.352953; batch adversarial loss: 0.533503\n",
      "epoch 5; iter: 0; batch classifier loss: 0.288254; batch adversarial loss: 0.548967\n",
      "epoch 6; iter: 0; batch classifier loss: 0.309156; batch adversarial loss: 0.569126\n",
      "epoch 7; iter: 0; batch classifier loss: 0.297300; batch adversarial loss: 0.506073\n",
      "epoch 8; iter: 0; batch classifier loss: 0.300386; batch adversarial loss: 0.528526\n",
      "epoch 9; iter: 0; batch classifier loss: 0.247225; batch adversarial loss: 0.476706\n",
      "epoch 10; iter: 0; batch classifier loss: 0.263781; batch adversarial loss: 0.591154\n",
      "epoch 11; iter: 0; batch classifier loss: 0.192086; batch adversarial loss: 0.509774\n",
      "epoch 12; iter: 0; batch classifier loss: 0.323120; batch adversarial loss: 0.488089\n",
      "epoch 13; iter: 0; batch classifier loss: 0.294799; batch adversarial loss: 0.560743\n",
      "epoch 14; iter: 0; batch classifier loss: 0.296789; batch adversarial loss: 0.634341\n",
      "epoch 15; iter: 0; batch classifier loss: 0.322444; batch adversarial loss: 0.461886\n",
      "epoch 16; iter: 0; batch classifier loss: 0.352782; batch adversarial loss: 0.529781\n",
      "epoch 17; iter: 0; batch classifier loss: 0.342999; batch adversarial loss: 0.557108\n",
      "epoch 18; iter: 0; batch classifier loss: 0.428011; batch adversarial loss: 0.457444\n",
      "epoch 19; iter: 0; batch classifier loss: 0.350916; batch adversarial loss: 0.525818\n",
      "epoch 20; iter: 0; batch classifier loss: 0.338306; batch adversarial loss: 0.464061\n",
      "epoch 21; iter: 0; batch classifier loss: 0.188151; batch adversarial loss: 0.500438\n",
      "epoch 22; iter: 0; batch classifier loss: 0.212193; batch adversarial loss: 0.462802\n",
      "epoch 23; iter: 0; batch classifier loss: 0.166997; batch adversarial loss: 0.568399\n",
      "epoch 24; iter: 0; batch classifier loss: 0.202979; batch adversarial loss: 0.447735\n",
      "epoch 25; iter: 0; batch classifier loss: 0.193132; batch adversarial loss: 0.484760\n",
      "epoch 26; iter: 0; batch classifier loss: 0.142643; batch adversarial loss: 0.499603\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152743; batch adversarial loss: 0.459742\n",
      "epoch 28; iter: 0; batch classifier loss: 0.155470; batch adversarial loss: 0.480046\n",
      "epoch 29; iter: 0; batch classifier loss: 0.171672; batch adversarial loss: 0.468422\n",
      "epoch 30; iter: 0; batch classifier loss: 0.136179; batch adversarial loss: 0.522940\n",
      "epoch 31; iter: 0; batch classifier loss: 0.143009; batch adversarial loss: 0.402482\n",
      "epoch 32; iter: 0; batch classifier loss: 0.152738; batch adversarial loss: 0.452615\n",
      "epoch 33; iter: 0; batch classifier loss: 0.164586; batch adversarial loss: 0.398295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.089823; batch adversarial loss: 0.521308\n",
      "epoch 35; iter: 0; batch classifier loss: 0.179884; batch adversarial loss: 0.400040\n",
      "epoch 36; iter: 0; batch classifier loss: 0.153972; batch adversarial loss: 0.391818\n",
      "epoch 37; iter: 0; batch classifier loss: 0.105554; batch adversarial loss: 0.438021\n",
      "epoch 38; iter: 0; batch classifier loss: 0.124698; batch adversarial loss: 0.439901\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132903; batch adversarial loss: 0.452092\n",
      "epoch 40; iter: 0; batch classifier loss: 0.073799; batch adversarial loss: 0.482003\n",
      "epoch 41; iter: 0; batch classifier loss: 0.131989; batch adversarial loss: 0.442792\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110594; batch adversarial loss: 0.378006\n",
      "epoch 43; iter: 0; batch classifier loss: 0.139097; batch adversarial loss: 0.537393\n",
      "epoch 44; iter: 0; batch classifier loss: 0.110253; batch adversarial loss: 0.463447\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108246; batch adversarial loss: 0.458575\n",
      "epoch 46; iter: 0; batch classifier loss: 0.119084; batch adversarial loss: 0.431887\n",
      "epoch 47; iter: 0; batch classifier loss: 0.109490; batch adversarial loss: 0.502582\n",
      "epoch 48; iter: 0; batch classifier loss: 0.169790; batch adversarial loss: 0.528211\n",
      "epoch 49; iter: 0; batch classifier loss: 0.102982; batch adversarial loss: 0.430652\n",
      "epoch 50; iter: 0; batch classifier loss: 0.097468; batch adversarial loss: 0.458673\n",
      "epoch 51; iter: 0; batch classifier loss: 0.082372; batch adversarial loss: 0.472186\n",
      "epoch 52; iter: 0; batch classifier loss: 0.091411; batch adversarial loss: 0.498108\n",
      "epoch 53; iter: 0; batch classifier loss: 0.082972; batch adversarial loss: 0.502864\n",
      "epoch 54; iter: 0; batch classifier loss: 0.125070; batch adversarial loss: 0.367749\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089622; batch adversarial loss: 0.467491\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103487; batch adversarial loss: 0.549184\n",
      "epoch 57; iter: 0; batch classifier loss: 0.124655; batch adversarial loss: 0.500269\n",
      "epoch 58; iter: 0; batch classifier loss: 0.177415; batch adversarial loss: 0.377685\n",
      "epoch 59; iter: 0; batch classifier loss: 0.154968; batch adversarial loss: 0.470212\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122638; batch adversarial loss: 0.483547\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080886; batch adversarial loss: 0.466614\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082937; batch adversarial loss: 0.443884\n",
      "epoch 63; iter: 0; batch classifier loss: 0.105234; batch adversarial loss: 0.440745\n",
      "epoch 64; iter: 0; batch classifier loss: 0.133636; batch adversarial loss: 0.430279\n",
      "epoch 65; iter: 0; batch classifier loss: 0.093136; batch adversarial loss: 0.601140\n",
      "epoch 66; iter: 0; batch classifier loss: 0.107910; batch adversarial loss: 0.461076\n",
      "epoch 67; iter: 0; batch classifier loss: 0.134463; batch adversarial loss: 0.432269\n",
      "epoch 68; iter: 0; batch classifier loss: 0.198738; batch adversarial loss: 0.422424\n",
      "epoch 69; iter: 0; batch classifier loss: 0.150439; batch adversarial loss: 0.530580\n",
      "epoch 70; iter: 0; batch classifier loss: 0.132911; batch adversarial loss: 0.532624\n",
      "epoch 71; iter: 0; batch classifier loss: 0.102218; batch adversarial loss: 0.533226\n",
      "epoch 72; iter: 0; batch classifier loss: 0.148469; batch adversarial loss: 0.481178\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083568; batch adversarial loss: 0.410434\n",
      "epoch 74; iter: 0; batch classifier loss: 0.120325; batch adversarial loss: 0.485498\n",
      "epoch 75; iter: 0; batch classifier loss: 0.111312; batch adversarial loss: 0.390626\n",
      "epoch 76; iter: 0; batch classifier loss: 0.138514; batch adversarial loss: 0.460207\n",
      "epoch 77; iter: 0; batch classifier loss: 0.125614; batch adversarial loss: 0.458595\n",
      "epoch 78; iter: 0; batch classifier loss: 0.106564; batch adversarial loss: 0.517465\n",
      "epoch 79; iter: 0; batch classifier loss: 0.101715; batch adversarial loss: 0.420989\n",
      "epoch 80; iter: 0; batch classifier loss: 0.146468; batch adversarial loss: 0.447556\n",
      "epoch 81; iter: 0; batch classifier loss: 0.204538; batch adversarial loss: 0.432187\n",
      "epoch 82; iter: 0; batch classifier loss: 0.120903; batch adversarial loss: 0.409820\n",
      "epoch 83; iter: 0; batch classifier loss: 0.138720; batch adversarial loss: 0.468167\n",
      "epoch 84; iter: 0; batch classifier loss: 0.122521; batch adversarial loss: 0.502476\n",
      "epoch 85; iter: 0; batch classifier loss: 0.147041; batch adversarial loss: 0.473361\n",
      "epoch 86; iter: 0; batch classifier loss: 0.218692; batch adversarial loss: 0.424008\n",
      "epoch 87; iter: 0; batch classifier loss: 0.146250; batch adversarial loss: 0.531891\n",
      "epoch 88; iter: 0; batch classifier loss: 0.142034; batch adversarial loss: 0.301040\n",
      "epoch 89; iter: 0; batch classifier loss: 0.188519; batch adversarial loss: 0.363408\n",
      "epoch 90; iter: 0; batch classifier loss: 0.107165; batch adversarial loss: 0.542457\n",
      "epoch 91; iter: 0; batch classifier loss: 0.123417; batch adversarial loss: 0.381681\n",
      "epoch 92; iter: 0; batch classifier loss: 0.091770; batch adversarial loss: 0.534611\n",
      "epoch 93; iter: 0; batch classifier loss: 0.095406; batch adversarial loss: 0.518443\n",
      "epoch 94; iter: 0; batch classifier loss: 0.120356; batch adversarial loss: 0.467393\n",
      "epoch 95; iter: 0; batch classifier loss: 0.127653; batch adversarial loss: 0.470207\n",
      "epoch 96; iter: 0; batch classifier loss: 0.111635; batch adversarial loss: 0.508707\n",
      "epoch 97; iter: 0; batch classifier loss: 0.150834; batch adversarial loss: 0.447982\n",
      "epoch 98; iter: 0; batch classifier loss: 0.114471; batch adversarial loss: 0.450491\n",
      "epoch 99; iter: 0; batch classifier loss: 0.084718; batch adversarial loss: 0.400008\n",
      "epoch 100; iter: 0; batch classifier loss: 0.090281; batch adversarial loss: 0.484870\n",
      "epoch 101; iter: 0; batch classifier loss: 0.134043; batch adversarial loss: 0.544710\n",
      "epoch 102; iter: 0; batch classifier loss: 0.140904; batch adversarial loss: 0.398646\n",
      "epoch 103; iter: 0; batch classifier loss: 0.088136; batch adversarial loss: 0.507512\n",
      "epoch 104; iter: 0; batch classifier loss: 0.115154; batch adversarial loss: 0.484078\n",
      "epoch 105; iter: 0; batch classifier loss: 0.183461; batch adversarial loss: 0.507824\n",
      "epoch 106; iter: 0; batch classifier loss: 0.151713; batch adversarial loss: 0.557148\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072776; batch adversarial loss: 0.582672\n",
      "epoch 108; iter: 0; batch classifier loss: 0.125967; batch adversarial loss: 0.470617\n",
      "epoch 109; iter: 0; batch classifier loss: 0.120901; batch adversarial loss: 0.482585\n",
      "epoch 110; iter: 0; batch classifier loss: 0.141123; batch adversarial loss: 0.409997\n",
      "epoch 111; iter: 0; batch classifier loss: 0.155835; batch adversarial loss: 0.498624\n",
      "epoch 112; iter: 0; batch classifier loss: 0.140986; batch adversarial loss: 0.361197\n",
      "epoch 113; iter: 0; batch classifier loss: 0.144307; batch adversarial loss: 0.481615\n",
      "epoch 114; iter: 0; batch classifier loss: 0.086188; batch adversarial loss: 0.370600\n",
      "epoch 115; iter: 0; batch classifier loss: 0.115438; batch adversarial loss: 0.419197\n",
      "epoch 116; iter: 0; batch classifier loss: 0.149799; batch adversarial loss: 0.386537\n",
      "epoch 117; iter: 0; batch classifier loss: 0.110780; batch adversarial loss: 0.421051\n",
      "epoch 118; iter: 0; batch classifier loss: 0.120964; batch adversarial loss: 0.407944\n",
      "epoch 119; iter: 0; batch classifier loss: 0.120626; batch adversarial loss: 0.444592\n",
      "epoch 120; iter: 0; batch classifier loss: 0.117167; batch adversarial loss: 0.404759\n",
      "epoch 121; iter: 0; batch classifier loss: 0.105496; batch adversarial loss: 0.406978\n",
      "epoch 122; iter: 0; batch classifier loss: 0.086235; batch adversarial loss: 0.535744\n",
      "epoch 123; iter: 0; batch classifier loss: 0.107074; batch adversarial loss: 0.370575\n",
      "epoch 124; iter: 0; batch classifier loss: 0.119953; batch adversarial loss: 0.494946\n",
      "epoch 125; iter: 0; batch classifier loss: 0.081336; batch adversarial loss: 0.473165\n",
      "epoch 126; iter: 0; batch classifier loss: 0.105185; batch adversarial loss: 0.540621\n",
      "epoch 127; iter: 0; batch classifier loss: 0.087327; batch adversarial loss: 0.459329\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058520; batch adversarial loss: 0.401749\n",
      "epoch 129; iter: 0; batch classifier loss: 0.103960; batch adversarial loss: 0.434543\n",
      "epoch 130; iter: 0; batch classifier loss: 0.094286; batch adversarial loss: 0.438943\n",
      "epoch 131; iter: 0; batch classifier loss: 0.089218; batch adversarial loss: 0.359474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.114789; batch adversarial loss: 0.486089\n",
      "epoch 133; iter: 0; batch classifier loss: 0.087451; batch adversarial loss: 0.443353\n",
      "epoch 134; iter: 0; batch classifier loss: 0.085101; batch adversarial loss: 0.437011\n",
      "epoch 135; iter: 0; batch classifier loss: 0.086965; batch adversarial loss: 0.376113\n",
      "epoch 136; iter: 0; batch classifier loss: 0.084738; batch adversarial loss: 0.410753\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046354; batch adversarial loss: 0.532594\n",
      "epoch 138; iter: 0; batch classifier loss: 0.058400; batch adversarial loss: 0.439075\n",
      "epoch 139; iter: 0; batch classifier loss: 0.058286; batch adversarial loss: 0.430073\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029469; batch adversarial loss: 0.434533\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026920; batch adversarial loss: 0.428550\n",
      "epoch 142; iter: 0; batch classifier loss: 0.060956; batch adversarial loss: 0.379081\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039042; batch adversarial loss: 0.394025\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040569; batch adversarial loss: 0.409216\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030330; batch adversarial loss: 0.458731\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032975; batch adversarial loss: 0.581732\n",
      "epoch 147; iter: 0; batch classifier loss: 0.078340; batch adversarial loss: 0.539113\n",
      "epoch 148; iter: 0; batch classifier loss: 0.062407; batch adversarial loss: 0.385760\n",
      "epoch 149; iter: 0; batch classifier loss: 0.063681; batch adversarial loss: 0.489248\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020106; batch adversarial loss: 0.469109\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041832; batch adversarial loss: 0.388183\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031627; batch adversarial loss: 0.489327\n",
      "epoch 153; iter: 0; batch classifier loss: 0.052000; batch adversarial loss: 0.429662\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031091; batch adversarial loss: 0.489585\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029114; batch adversarial loss: 0.388019\n",
      "epoch 156; iter: 0; batch classifier loss: 0.046463; batch adversarial loss: 0.527344\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034396; batch adversarial loss: 0.423553\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030618; batch adversarial loss: 0.359425\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033811; batch adversarial loss: 0.462578\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022919; batch adversarial loss: 0.448207\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011701; batch adversarial loss: 0.409048\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019031; batch adversarial loss: 0.484467\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026548; batch adversarial loss: 0.441060\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022209; batch adversarial loss: 0.383506\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031185; batch adversarial loss: 0.460108\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037820; batch adversarial loss: 0.476786\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029392; batch adversarial loss: 0.619426\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023814; batch adversarial loss: 0.463560\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034899; batch adversarial loss: 0.395405\n",
      "epoch 170; iter: 0; batch classifier loss: 0.047472; batch adversarial loss: 0.513423\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019701; batch adversarial loss: 0.532727\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033089; batch adversarial loss: 0.452040\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012021; batch adversarial loss: 0.373164\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018419; batch adversarial loss: 0.514064\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029876; batch adversarial loss: 0.391657\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013220; batch adversarial loss: 0.517362\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011690; batch adversarial loss: 0.370957\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023289; batch adversarial loss: 0.456802\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007808; batch adversarial loss: 0.548301\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018125; batch adversarial loss: 0.367018\n",
      "epoch 181; iter: 0; batch classifier loss: 0.048683; batch adversarial loss: 0.486660\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024306; batch adversarial loss: 0.452755\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036479; batch adversarial loss: 0.475772\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017416; batch adversarial loss: 0.444110\n",
      "epoch 185; iter: 0; batch classifier loss: 0.034503; batch adversarial loss: 0.388892\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023470; batch adversarial loss: 0.455991\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028809; batch adversarial loss: 0.466586\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019145; batch adversarial loss: 0.430533\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028647; batch adversarial loss: 0.480884\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028722; batch adversarial loss: 0.532536\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010562; batch adversarial loss: 0.452521\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009677; batch adversarial loss: 0.474276\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012337; batch adversarial loss: 0.432005\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014834; batch adversarial loss: 0.437560\n",
      "epoch 195; iter: 0; batch classifier loss: 0.046584; batch adversarial loss: 0.518588\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008827; batch adversarial loss: 0.488155\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028060; batch adversarial loss: 0.451275\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014341; batch adversarial loss: 0.476868\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033627; batch adversarial loss: 0.445438\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686991; batch adversarial loss: 0.534222\n",
      "epoch 1; iter: 0; batch classifier loss: 0.454066; batch adversarial loss: 0.622159\n",
      "epoch 2; iter: 0; batch classifier loss: 0.355308; batch adversarial loss: 0.605727\n",
      "epoch 3; iter: 0; batch classifier loss: 0.344736; batch adversarial loss: 0.573995\n",
      "epoch 4; iter: 0; batch classifier loss: 0.352704; batch adversarial loss: 0.587565\n",
      "epoch 5; iter: 0; batch classifier loss: 0.279925; batch adversarial loss: 0.592692\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340007; batch adversarial loss: 0.543381\n",
      "epoch 7; iter: 0; batch classifier loss: 0.315017; batch adversarial loss: 0.523926\n",
      "epoch 8; iter: 0; batch classifier loss: 0.226214; batch adversarial loss: 0.527828\n",
      "epoch 9; iter: 0; batch classifier loss: 0.248735; batch adversarial loss: 0.552927\n",
      "epoch 10; iter: 0; batch classifier loss: 0.260547; batch adversarial loss: 0.513114\n",
      "epoch 11; iter: 0; batch classifier loss: 0.266502; batch adversarial loss: 0.512764\n",
      "epoch 12; iter: 0; batch classifier loss: 0.266639; batch adversarial loss: 0.605653\n",
      "epoch 13; iter: 0; batch classifier loss: 0.181404; batch adversarial loss: 0.545257\n",
      "epoch 14; iter: 0; batch classifier loss: 0.282045; batch adversarial loss: 0.521210\n",
      "epoch 15; iter: 0; batch classifier loss: 0.234327; batch adversarial loss: 0.555113\n",
      "epoch 16; iter: 0; batch classifier loss: 0.333939; batch adversarial loss: 0.584485\n",
      "epoch 17; iter: 0; batch classifier loss: 0.254229; batch adversarial loss: 0.483899\n",
      "epoch 18; iter: 0; batch classifier loss: 0.282642; batch adversarial loss: 0.554301\n",
      "epoch 19; iter: 0; batch classifier loss: 0.360554; batch adversarial loss: 0.519694\n",
      "epoch 20; iter: 0; batch classifier loss: 0.370842; batch adversarial loss: 0.576568\n",
      "epoch 21; iter: 0; batch classifier loss: 0.426875; batch adversarial loss: 0.496174\n",
      "epoch 22; iter: 0; batch classifier loss: 0.344877; batch adversarial loss: 0.529670\n",
      "epoch 23; iter: 0; batch classifier loss: 0.180099; batch adversarial loss: 0.491652\n",
      "epoch 24; iter: 0; batch classifier loss: 0.165218; batch adversarial loss: 0.479606\n",
      "epoch 25; iter: 0; batch classifier loss: 0.147329; batch adversarial loss: 0.487242\n",
      "epoch 26; iter: 0; batch classifier loss: 0.145369; batch adversarial loss: 0.467032\n",
      "epoch 27; iter: 0; batch classifier loss: 0.116432; batch adversarial loss: 0.479955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.105496; batch adversarial loss: 0.551731\n",
      "epoch 29; iter: 0; batch classifier loss: 0.161315; batch adversarial loss: 0.383213\n",
      "epoch 30; iter: 0; batch classifier loss: 0.099921; batch adversarial loss: 0.463481\n",
      "epoch 31; iter: 0; batch classifier loss: 0.115210; batch adversarial loss: 0.389213\n",
      "epoch 32; iter: 0; batch classifier loss: 0.100282; batch adversarial loss: 0.477498\n",
      "epoch 33; iter: 0; batch classifier loss: 0.090099; batch adversarial loss: 0.371327\n",
      "epoch 34; iter: 0; batch classifier loss: 0.115944; batch adversarial loss: 0.467182\n",
      "epoch 35; iter: 0; batch classifier loss: 0.105427; batch adversarial loss: 0.493036\n",
      "epoch 36; iter: 0; batch classifier loss: 0.112172; batch adversarial loss: 0.425440\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145869; batch adversarial loss: 0.539434\n",
      "epoch 38; iter: 0; batch classifier loss: 0.118085; batch adversarial loss: 0.479507\n",
      "epoch 39; iter: 0; batch classifier loss: 0.105173; batch adversarial loss: 0.564788\n",
      "epoch 40; iter: 0; batch classifier loss: 0.097034; batch adversarial loss: 0.479513\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113268; batch adversarial loss: 0.477518\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103234; batch adversarial loss: 0.470964\n",
      "epoch 43; iter: 0; batch classifier loss: 0.083513; batch adversarial loss: 0.442254\n",
      "epoch 44; iter: 0; batch classifier loss: 0.093939; batch adversarial loss: 0.392484\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099622; batch adversarial loss: 0.492621\n",
      "epoch 46; iter: 0; batch classifier loss: 0.095126; batch adversarial loss: 0.469394\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096462; batch adversarial loss: 0.420571\n",
      "epoch 48; iter: 0; batch classifier loss: 0.094904; batch adversarial loss: 0.505377\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074173; batch adversarial loss: 0.459604\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119523; batch adversarial loss: 0.351759\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073517; batch adversarial loss: 0.506618\n",
      "epoch 52; iter: 0; batch classifier loss: 0.105806; batch adversarial loss: 0.360329\n",
      "epoch 53; iter: 0; batch classifier loss: 0.097460; batch adversarial loss: 0.492813\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112043; batch adversarial loss: 0.427941\n",
      "epoch 55; iter: 0; batch classifier loss: 0.080136; batch adversarial loss: 0.492976\n",
      "epoch 56; iter: 0; batch classifier loss: 0.124930; batch adversarial loss: 0.529179\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073225; batch adversarial loss: 0.474384\n",
      "epoch 58; iter: 0; batch classifier loss: 0.061274; batch adversarial loss: 0.403402\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087531; batch adversarial loss: 0.497824\n",
      "epoch 60; iter: 0; batch classifier loss: 0.066202; batch adversarial loss: 0.444156\n",
      "epoch 61; iter: 0; batch classifier loss: 0.100447; batch adversarial loss: 0.546852\n",
      "epoch 62; iter: 0; batch classifier loss: 0.065071; batch adversarial loss: 0.428644\n",
      "epoch 63; iter: 0; batch classifier loss: 0.127851; batch adversarial loss: 0.434315\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078410; batch adversarial loss: 0.528036\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077126; batch adversarial loss: 0.463724\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093134; batch adversarial loss: 0.439150\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096095; batch adversarial loss: 0.500864\n",
      "epoch 68; iter: 0; batch classifier loss: 0.080851; batch adversarial loss: 0.457010\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078507; batch adversarial loss: 0.564911\n",
      "epoch 70; iter: 0; batch classifier loss: 0.055358; batch adversarial loss: 0.467146\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079258; batch adversarial loss: 0.645006\n",
      "epoch 72; iter: 0; batch classifier loss: 0.132815; batch adversarial loss: 0.505291\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069309; batch adversarial loss: 0.473271\n",
      "epoch 74; iter: 0; batch classifier loss: 0.099603; batch adversarial loss: 0.469442\n",
      "epoch 75; iter: 0; batch classifier loss: 0.087083; batch adversarial loss: 0.412416\n",
      "epoch 76; iter: 0; batch classifier loss: 0.109062; batch adversarial loss: 0.436413\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102921; batch adversarial loss: 0.472384\n",
      "epoch 78; iter: 0; batch classifier loss: 0.126822; batch adversarial loss: 0.412749\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085559; batch adversarial loss: 0.505103\n",
      "epoch 80; iter: 0; batch classifier loss: 0.098010; batch adversarial loss: 0.535817\n",
      "epoch 81; iter: 0; batch classifier loss: 0.108162; batch adversarial loss: 0.418723\n",
      "epoch 82; iter: 0; batch classifier loss: 0.109362; batch adversarial loss: 0.430604\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081856; batch adversarial loss: 0.485242\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077245; batch adversarial loss: 0.515726\n",
      "epoch 85; iter: 0; batch classifier loss: 0.140793; batch adversarial loss: 0.437874\n",
      "epoch 86; iter: 0; batch classifier loss: 0.133137; batch adversarial loss: 0.428463\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083925; batch adversarial loss: 0.416293\n",
      "epoch 88; iter: 0; batch classifier loss: 0.134491; batch adversarial loss: 0.490654\n",
      "epoch 89; iter: 0; batch classifier loss: 0.124980; batch adversarial loss: 0.458793\n",
      "epoch 90; iter: 0; batch classifier loss: 0.071848; batch adversarial loss: 0.557073\n",
      "epoch 91; iter: 0; batch classifier loss: 0.121694; batch adversarial loss: 0.495942\n",
      "epoch 92; iter: 0; batch classifier loss: 0.123290; batch adversarial loss: 0.432528\n",
      "epoch 93; iter: 0; batch classifier loss: 0.084415; batch adversarial loss: 0.475442\n",
      "epoch 94; iter: 0; batch classifier loss: 0.121855; batch adversarial loss: 0.449013\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087941; batch adversarial loss: 0.352661\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049718; batch adversarial loss: 0.487595\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077747; batch adversarial loss: 0.465838\n",
      "epoch 98; iter: 0; batch classifier loss: 0.110410; batch adversarial loss: 0.491334\n",
      "epoch 99; iter: 0; batch classifier loss: 0.204461; batch adversarial loss: 0.483115\n",
      "epoch 100; iter: 0; batch classifier loss: 0.072044; batch adversarial loss: 0.557159\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063223; batch adversarial loss: 0.439145\n",
      "epoch 102; iter: 0; batch classifier loss: 0.097770; batch adversarial loss: 0.528258\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046304; batch adversarial loss: 0.451032\n",
      "epoch 104; iter: 0; batch classifier loss: 0.099942; batch adversarial loss: 0.643871\n",
      "epoch 105; iter: 0; batch classifier loss: 0.082079; batch adversarial loss: 0.411702\n",
      "epoch 106; iter: 0; batch classifier loss: 0.087254; batch adversarial loss: 0.456456\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061816; batch adversarial loss: 0.474853\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064215; batch adversarial loss: 0.428874\n",
      "epoch 109; iter: 0; batch classifier loss: 0.095881; batch adversarial loss: 0.442745\n",
      "epoch 110; iter: 0; batch classifier loss: 0.083128; batch adversarial loss: 0.376228\n",
      "epoch 111; iter: 0; batch classifier loss: 0.086654; batch adversarial loss: 0.557627\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057983; batch adversarial loss: 0.620354\n",
      "epoch 113; iter: 0; batch classifier loss: 0.074367; batch adversarial loss: 0.553120\n",
      "epoch 114; iter: 0; batch classifier loss: 0.131571; batch adversarial loss: 0.492281\n",
      "epoch 115; iter: 0; batch classifier loss: 0.119182; batch adversarial loss: 0.550454\n",
      "epoch 116; iter: 0; batch classifier loss: 0.075351; batch adversarial loss: 0.493833\n",
      "epoch 117; iter: 0; batch classifier loss: 0.058786; batch adversarial loss: 0.437432\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039898; batch adversarial loss: 0.430881\n",
      "epoch 119; iter: 0; batch classifier loss: 0.067549; batch adversarial loss: 0.404705\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037379; batch adversarial loss: 0.437494\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057466; batch adversarial loss: 0.555241\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032602; batch adversarial loss: 0.423944\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039657; batch adversarial loss: 0.396421\n",
      "epoch 124; iter: 0; batch classifier loss: 0.073201; batch adversarial loss: 0.568231\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058024; batch adversarial loss: 0.396596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.060576; batch adversarial loss: 0.570829\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050939; batch adversarial loss: 0.437151\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034933; batch adversarial loss: 0.436166\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041385; batch adversarial loss: 0.458073\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047657; batch adversarial loss: 0.419788\n",
      "epoch 131; iter: 0; batch classifier loss: 0.072652; batch adversarial loss: 0.506757\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051802; batch adversarial loss: 0.493414\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051992; batch adversarial loss: 0.472528\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050794; batch adversarial loss: 0.400161\n",
      "epoch 135; iter: 0; batch classifier loss: 0.061979; batch adversarial loss: 0.363647\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023192; batch adversarial loss: 0.504399\n",
      "epoch 137; iter: 0; batch classifier loss: 0.055715; batch adversarial loss: 0.515735\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023133; batch adversarial loss: 0.519408\n",
      "epoch 139; iter: 0; batch classifier loss: 0.058893; batch adversarial loss: 0.472080\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034041; batch adversarial loss: 0.541649\n",
      "epoch 141; iter: 0; batch classifier loss: 0.059850; batch adversarial loss: 0.402824\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028673; batch adversarial loss: 0.522911\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016015; batch adversarial loss: 0.372660\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037149; batch adversarial loss: 0.570988\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030978; batch adversarial loss: 0.548382\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022177; batch adversarial loss: 0.458302\n",
      "epoch 147; iter: 0; batch classifier loss: 0.065503; batch adversarial loss: 0.507957\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042002; batch adversarial loss: 0.505273\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044939; batch adversarial loss: 0.448040\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017512; batch adversarial loss: 0.481125\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026640; batch adversarial loss: 0.466736\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032728; batch adversarial loss: 0.415875\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030858; batch adversarial loss: 0.448188\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034137; batch adversarial loss: 0.458814\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033948; batch adversarial loss: 0.378035\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034688; batch adversarial loss: 0.479022\n",
      "epoch 157; iter: 0; batch classifier loss: 0.081885; batch adversarial loss: 0.458063\n",
      "epoch 158; iter: 0; batch classifier loss: 0.058787; batch adversarial loss: 0.377357\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020724; batch adversarial loss: 0.480429\n",
      "epoch 160; iter: 0; batch classifier loss: 0.052139; batch adversarial loss: 0.410866\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011885; batch adversarial loss: 0.509737\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031034; batch adversarial loss: 0.466728\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026475; batch adversarial loss: 0.445006\n",
      "epoch 164; iter: 0; batch classifier loss: 0.067272; batch adversarial loss: 0.473645\n",
      "epoch 165; iter: 0; batch classifier loss: 0.053546; batch adversarial loss: 0.546832\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046026; batch adversarial loss: 0.505995\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021604; batch adversarial loss: 0.527908\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032106; batch adversarial loss: 0.381378\n",
      "epoch 169; iter: 0; batch classifier loss: 0.052131; batch adversarial loss: 0.399514\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021109; batch adversarial loss: 0.476500\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017906; batch adversarial loss: 0.526148\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018105; batch adversarial loss: 0.416255\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024760; batch adversarial loss: 0.451065\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029068; batch adversarial loss: 0.452431\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019381; batch adversarial loss: 0.407480\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014014; batch adversarial loss: 0.497879\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018088; batch adversarial loss: 0.477316\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018632; batch adversarial loss: 0.572577\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029173; batch adversarial loss: 0.499575\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014390; batch adversarial loss: 0.539534\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025425; batch adversarial loss: 0.565821\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018358; batch adversarial loss: 0.484173\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028812; batch adversarial loss: 0.470891\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013203; batch adversarial loss: 0.486438\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033784; batch adversarial loss: 0.485711\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014969; batch adversarial loss: 0.438008\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034621; batch adversarial loss: 0.504975\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034664; batch adversarial loss: 0.467827\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028254; batch adversarial loss: 0.411717\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035779; batch adversarial loss: 0.477639\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018115; batch adversarial loss: 0.566989\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030202; batch adversarial loss: 0.584244\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008266; batch adversarial loss: 0.478957\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034823; batch adversarial loss: 0.532681\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021024; batch adversarial loss: 0.555272\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031229; batch adversarial loss: 0.419255\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018347; batch adversarial loss: 0.447604\n",
      "epoch 198; iter: 0; batch classifier loss: 0.034608; batch adversarial loss: 0.502249\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024118; batch adversarial loss: 0.553999\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688466; batch adversarial loss: 0.791053\n",
      "epoch 1; iter: 0; batch classifier loss: 0.466688; batch adversarial loss: 0.727191\n",
      "epoch 2; iter: 0; batch classifier loss: 0.494666; batch adversarial loss: 0.711854\n",
      "epoch 3; iter: 0; batch classifier loss: 0.402608; batch adversarial loss: 0.656777\n",
      "epoch 4; iter: 0; batch classifier loss: 0.409376; batch adversarial loss: 0.638082\n",
      "epoch 5; iter: 0; batch classifier loss: 0.297011; batch adversarial loss: 0.605969\n",
      "epoch 6; iter: 0; batch classifier loss: 0.361502; batch adversarial loss: 0.581393\n",
      "epoch 7; iter: 0; batch classifier loss: 0.388967; batch adversarial loss: 0.543286\n",
      "epoch 8; iter: 0; batch classifier loss: 0.252692; batch adversarial loss: 0.527925\n",
      "epoch 9; iter: 0; batch classifier loss: 0.297912; batch adversarial loss: 0.502434\n",
      "epoch 10; iter: 0; batch classifier loss: 0.256810; batch adversarial loss: 0.484002\n",
      "epoch 11; iter: 0; batch classifier loss: 0.353025; batch adversarial loss: 0.446950\n",
      "epoch 12; iter: 0; batch classifier loss: 0.229816; batch adversarial loss: 0.473014\n",
      "epoch 13; iter: 0; batch classifier loss: 0.224537; batch adversarial loss: 0.486738\n",
      "epoch 14; iter: 0; batch classifier loss: 0.244014; batch adversarial loss: 0.484251\n",
      "epoch 15; iter: 0; batch classifier loss: 0.210588; batch adversarial loss: 0.467823\n",
      "epoch 16; iter: 0; batch classifier loss: 0.261059; batch adversarial loss: 0.386563\n",
      "epoch 17; iter: 0; batch classifier loss: 0.187604; batch adversarial loss: 0.439533\n",
      "epoch 18; iter: 0; batch classifier loss: 0.267295; batch adversarial loss: 0.434945\n",
      "epoch 19; iter: 0; batch classifier loss: 0.198917; batch adversarial loss: 0.442654\n",
      "epoch 20; iter: 0; batch classifier loss: 0.221420; batch adversarial loss: 0.408227\n",
      "epoch 21; iter: 0; batch classifier loss: 0.235932; batch adversarial loss: 0.429497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.217129; batch adversarial loss: 0.478022\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168471; batch adversarial loss: 0.458396\n",
      "epoch 24; iter: 0; batch classifier loss: 0.197305; batch adversarial loss: 0.336814\n",
      "epoch 25; iter: 0; batch classifier loss: 0.120194; batch adversarial loss: 0.368977\n",
      "epoch 26; iter: 0; batch classifier loss: 0.137011; batch adversarial loss: 0.368757\n",
      "epoch 27; iter: 0; batch classifier loss: 0.228146; batch adversarial loss: 0.419653\n",
      "epoch 28; iter: 0; batch classifier loss: 0.105584; batch adversarial loss: 0.437517\n",
      "epoch 29; iter: 0; batch classifier loss: 0.173502; batch adversarial loss: 0.383348\n",
      "epoch 30; iter: 0; batch classifier loss: 0.135175; batch adversarial loss: 0.435977\n",
      "epoch 31; iter: 0; batch classifier loss: 0.176681; batch adversarial loss: 0.368277\n",
      "epoch 32; iter: 0; batch classifier loss: 0.123375; batch adversarial loss: 0.378019\n",
      "epoch 33; iter: 0; batch classifier loss: 0.154118; batch adversarial loss: 0.426854\n",
      "epoch 34; iter: 0; batch classifier loss: 0.147364; batch adversarial loss: 0.393339\n",
      "epoch 35; iter: 0; batch classifier loss: 0.177562; batch adversarial loss: 0.425916\n",
      "epoch 36; iter: 0; batch classifier loss: 0.093746; batch adversarial loss: 0.323714\n",
      "epoch 37; iter: 0; batch classifier loss: 0.136952; batch adversarial loss: 0.416349\n",
      "epoch 38; iter: 0; batch classifier loss: 0.153251; batch adversarial loss: 0.439052\n",
      "epoch 39; iter: 0; batch classifier loss: 0.086010; batch adversarial loss: 0.388708\n",
      "epoch 40; iter: 0; batch classifier loss: 0.117999; batch adversarial loss: 0.395103\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123879; batch adversarial loss: 0.384254\n",
      "epoch 42; iter: 0; batch classifier loss: 0.130177; batch adversarial loss: 0.525701\n",
      "epoch 43; iter: 0; batch classifier loss: 0.135835; batch adversarial loss: 0.381065\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101838; batch adversarial loss: 0.430891\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108609; batch adversarial loss: 0.349104\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112979; batch adversarial loss: 0.419477\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119777; batch adversarial loss: 0.416810\n",
      "epoch 48; iter: 0; batch classifier loss: 0.105282; batch adversarial loss: 0.404788\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114042; batch adversarial loss: 0.452140\n",
      "epoch 50; iter: 0; batch classifier loss: 0.102872; batch adversarial loss: 0.529559\n",
      "epoch 51; iter: 0; batch classifier loss: 0.146766; batch adversarial loss: 0.396647\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101101; batch adversarial loss: 0.414385\n",
      "epoch 53; iter: 0; batch classifier loss: 0.160216; batch adversarial loss: 0.408109\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077407; batch adversarial loss: 0.443935\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122370; batch adversarial loss: 0.400709\n",
      "epoch 56; iter: 0; batch classifier loss: 0.122128; batch adversarial loss: 0.523941\n",
      "epoch 57; iter: 0; batch classifier loss: 0.084014; batch adversarial loss: 0.365667\n",
      "epoch 58; iter: 0; batch classifier loss: 0.065972; batch adversarial loss: 0.452881\n",
      "epoch 59; iter: 0; batch classifier loss: 0.093521; batch adversarial loss: 0.397373\n",
      "epoch 60; iter: 0; batch classifier loss: 0.080163; batch adversarial loss: 0.379501\n",
      "epoch 61; iter: 0; batch classifier loss: 0.098149; batch adversarial loss: 0.401184\n",
      "epoch 62; iter: 0; batch classifier loss: 0.050103; batch adversarial loss: 0.424032\n",
      "epoch 63; iter: 0; batch classifier loss: 0.108114; batch adversarial loss: 0.385929\n",
      "epoch 64; iter: 0; batch classifier loss: 0.067967; batch adversarial loss: 0.420501\n",
      "epoch 65; iter: 0; batch classifier loss: 0.071133; batch adversarial loss: 0.449971\n",
      "epoch 66; iter: 0; batch classifier loss: 0.090658; batch adversarial loss: 0.413347\n",
      "epoch 67; iter: 0; batch classifier loss: 0.112553; batch adversarial loss: 0.410114\n",
      "epoch 68; iter: 0; batch classifier loss: 0.133977; batch adversarial loss: 0.511287\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103275; batch adversarial loss: 0.440964\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079095; batch adversarial loss: 0.447074\n",
      "epoch 71; iter: 0; batch classifier loss: 0.052355; batch adversarial loss: 0.311127\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081363; batch adversarial loss: 0.526380\n",
      "epoch 73; iter: 0; batch classifier loss: 0.099668; batch adversarial loss: 0.418860\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102056; batch adversarial loss: 0.423073\n",
      "epoch 75; iter: 0; batch classifier loss: 0.091450; batch adversarial loss: 0.419468\n",
      "epoch 76; iter: 0; batch classifier loss: 0.043313; batch adversarial loss: 0.473721\n",
      "epoch 77; iter: 0; batch classifier loss: 0.075711; batch adversarial loss: 0.423490\n",
      "epoch 78; iter: 0; batch classifier loss: 0.103461; batch adversarial loss: 0.491407\n",
      "epoch 79; iter: 0; batch classifier loss: 0.102531; batch adversarial loss: 0.432728\n",
      "epoch 80; iter: 0; batch classifier loss: 0.046982; batch adversarial loss: 0.457857\n",
      "epoch 81; iter: 0; batch classifier loss: 0.116140; batch adversarial loss: 0.375160\n",
      "epoch 82; iter: 0; batch classifier loss: 0.137676; batch adversarial loss: 0.413040\n",
      "epoch 83; iter: 0; batch classifier loss: 0.084377; batch adversarial loss: 0.457458\n",
      "epoch 84; iter: 0; batch classifier loss: 0.083484; batch adversarial loss: 0.302595\n",
      "epoch 85; iter: 0; batch classifier loss: 0.085622; batch adversarial loss: 0.387755\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061292; batch adversarial loss: 0.464039\n",
      "epoch 87; iter: 0; batch classifier loss: 0.061856; batch adversarial loss: 0.457416\n",
      "epoch 88; iter: 0; batch classifier loss: 0.081918; batch adversarial loss: 0.467793\n",
      "epoch 89; iter: 0; batch classifier loss: 0.072944; batch adversarial loss: 0.361013\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087086; batch adversarial loss: 0.320470\n",
      "epoch 91; iter: 0; batch classifier loss: 0.078621; batch adversarial loss: 0.365930\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062459; batch adversarial loss: 0.522822\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077119; batch adversarial loss: 0.489783\n",
      "epoch 94; iter: 0; batch classifier loss: 0.063067; batch adversarial loss: 0.335548\n",
      "epoch 95; iter: 0; batch classifier loss: 0.095651; batch adversarial loss: 0.499658\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046860; batch adversarial loss: 0.412918\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055430; batch adversarial loss: 0.374265\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063248; batch adversarial loss: 0.342106\n",
      "epoch 99; iter: 0; batch classifier loss: 0.077039; batch adversarial loss: 0.457815\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067972; batch adversarial loss: 0.394248\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083291; batch adversarial loss: 0.468661\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039206; batch adversarial loss: 0.468406\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072704; batch adversarial loss: 0.409432\n",
      "epoch 104; iter: 0; batch classifier loss: 0.084266; batch adversarial loss: 0.437123\n",
      "epoch 105; iter: 0; batch classifier loss: 0.067109; batch adversarial loss: 0.384126\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051812; batch adversarial loss: 0.468577\n",
      "epoch 107; iter: 0; batch classifier loss: 0.090237; batch adversarial loss: 0.435343\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058279; batch adversarial loss: 0.417126\n",
      "epoch 109; iter: 0; batch classifier loss: 0.068931; batch adversarial loss: 0.383345\n",
      "epoch 110; iter: 0; batch classifier loss: 0.089307; batch adversarial loss: 0.466981\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050504; batch adversarial loss: 0.465422\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046887; batch adversarial loss: 0.576636\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063390; batch adversarial loss: 0.471916\n",
      "epoch 114; iter: 0; batch classifier loss: 0.069637; batch adversarial loss: 0.535998\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044742; batch adversarial loss: 0.403752\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033539; batch adversarial loss: 0.500781\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030562; batch adversarial loss: 0.493313\n",
      "epoch 118; iter: 0; batch classifier loss: 0.076656; batch adversarial loss: 0.454079\n",
      "epoch 119; iter: 0; batch classifier loss: 0.076023; batch adversarial loss: 0.520550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.062481; batch adversarial loss: 0.450394\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052479; batch adversarial loss: 0.342238\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035456; batch adversarial loss: 0.418694\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033198; batch adversarial loss: 0.498038\n",
      "epoch 124; iter: 0; batch classifier loss: 0.018584; batch adversarial loss: 0.436498\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040449; batch adversarial loss: 0.421774\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046693; batch adversarial loss: 0.467154\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039989; batch adversarial loss: 0.406097\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028752; batch adversarial loss: 0.421795\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048131; batch adversarial loss: 0.541819\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027978; batch adversarial loss: 0.502985\n",
      "epoch 131; iter: 0; batch classifier loss: 0.010245; batch adversarial loss: 0.479795\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021297; batch adversarial loss: 0.432272\n",
      "epoch 133; iter: 0; batch classifier loss: 0.016362; batch adversarial loss: 0.454208\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016725; batch adversarial loss: 0.422347\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020921; batch adversarial loss: 0.411731\n",
      "epoch 136; iter: 0; batch classifier loss: 0.015531; batch adversarial loss: 0.446471\n",
      "epoch 137; iter: 0; batch classifier loss: 0.016040; batch adversarial loss: 0.420680\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046982; batch adversarial loss: 0.498023\n",
      "epoch 139; iter: 0; batch classifier loss: 0.060917; batch adversarial loss: 0.532566\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030818; batch adversarial loss: 0.432199\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039145; batch adversarial loss: 0.460829\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021758; batch adversarial loss: 0.546951\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034837; batch adversarial loss: 0.562175\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039307; batch adversarial loss: 0.496470\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036648; batch adversarial loss: 0.528782\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031405; batch adversarial loss: 0.481181\n",
      "epoch 147; iter: 0; batch classifier loss: 0.120915; batch adversarial loss: 0.710445\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032664; batch adversarial loss: 0.482645\n",
      "epoch 149; iter: 0; batch classifier loss: 0.176785; batch adversarial loss: 0.793621\n",
      "epoch 150; iter: 0; batch classifier loss: 0.187111; batch adversarial loss: 0.713233\n",
      "epoch 151; iter: 0; batch classifier loss: 0.104870; batch adversarial loss: 0.520915\n",
      "epoch 152; iter: 0; batch classifier loss: 0.122483; batch adversarial loss: 0.696859\n",
      "epoch 153; iter: 0; batch classifier loss: 0.158852; batch adversarial loss: 0.675879\n",
      "epoch 154; iter: 0; batch classifier loss: 0.132668; batch adversarial loss: 0.577826\n",
      "epoch 155; iter: 0; batch classifier loss: 0.181054; batch adversarial loss: 0.831011\n",
      "epoch 156; iter: 0; batch classifier loss: 0.169436; batch adversarial loss: 0.699569\n",
      "epoch 157; iter: 0; batch classifier loss: 0.170567; batch adversarial loss: 0.643670\n",
      "epoch 158; iter: 0; batch classifier loss: 0.155282; batch adversarial loss: 0.689456\n",
      "epoch 159; iter: 0; batch classifier loss: 0.134226; batch adversarial loss: 0.609415\n",
      "epoch 160; iter: 0; batch classifier loss: 0.181371; batch adversarial loss: 0.675842\n",
      "epoch 161; iter: 0; batch classifier loss: 0.221683; batch adversarial loss: 0.778981\n",
      "epoch 162; iter: 0; batch classifier loss: 0.180680; batch adversarial loss: 0.645575\n",
      "epoch 163; iter: 0; batch classifier loss: 0.115286; batch adversarial loss: 0.696324\n",
      "epoch 164; iter: 0; batch classifier loss: 0.189445; batch adversarial loss: 0.665779\n",
      "epoch 165; iter: 0; batch classifier loss: 0.131389; batch adversarial loss: 0.608916\n",
      "epoch 166; iter: 0; batch classifier loss: 0.150419; batch adversarial loss: 0.695058\n",
      "epoch 167; iter: 0; batch classifier loss: 0.293076; batch adversarial loss: 0.804875\n",
      "epoch 168; iter: 0; batch classifier loss: 0.138620; batch adversarial loss: 0.582540\n",
      "epoch 169; iter: 0; batch classifier loss: 0.167510; batch adversarial loss: 0.656761\n",
      "epoch 170; iter: 0; batch classifier loss: 0.224697; batch adversarial loss: 0.713988\n",
      "epoch 171; iter: 0; batch classifier loss: 0.209059; batch adversarial loss: 0.683488\n",
      "epoch 172; iter: 0; batch classifier loss: 0.161447; batch adversarial loss: 0.652101\n",
      "epoch 173; iter: 0; batch classifier loss: 0.251936; batch adversarial loss: 0.796280\n",
      "epoch 174; iter: 0; batch classifier loss: 0.161107; batch adversarial loss: 0.532905\n",
      "epoch 175; iter: 0; batch classifier loss: 0.244297; batch adversarial loss: 0.661986\n",
      "epoch 176; iter: 0; batch classifier loss: 0.192987; batch adversarial loss: 0.649680\n",
      "epoch 177; iter: 0; batch classifier loss: 0.157044; batch adversarial loss: 0.547226\n",
      "epoch 178; iter: 0; batch classifier loss: 0.118489; batch adversarial loss: 0.573020\n",
      "epoch 179; iter: 0; batch classifier loss: 0.172705; batch adversarial loss: 0.569941\n",
      "epoch 180; iter: 0; batch classifier loss: 0.178493; batch adversarial loss: 0.546225\n",
      "epoch 181; iter: 0; batch classifier loss: 0.133544; batch adversarial loss: 0.569815\n",
      "epoch 182; iter: 0; batch classifier loss: 0.155362; batch adversarial loss: 0.593850\n",
      "epoch 183; iter: 0; batch classifier loss: 0.156711; batch adversarial loss: 0.554226\n",
      "epoch 184; iter: 0; batch classifier loss: 0.140751; batch adversarial loss: 0.525064\n",
      "epoch 185; iter: 0; batch classifier loss: 0.149354; batch adversarial loss: 0.520358\n",
      "epoch 186; iter: 0; batch classifier loss: 0.190385; batch adversarial loss: 0.632853\n",
      "epoch 187; iter: 0; batch classifier loss: 0.155059; batch adversarial loss: 0.532204\n",
      "epoch 188; iter: 0; batch classifier loss: 0.164193; batch adversarial loss: 0.559346\n",
      "epoch 189; iter: 0; batch classifier loss: 0.085181; batch adversarial loss: 0.465557\n",
      "epoch 190; iter: 0; batch classifier loss: 0.123008; batch adversarial loss: 0.524869\n",
      "epoch 191; iter: 0; batch classifier loss: 0.197437; batch adversarial loss: 0.602341\n",
      "epoch 192; iter: 0; batch classifier loss: 0.162220; batch adversarial loss: 0.463305\n",
      "epoch 193; iter: 0; batch classifier loss: 0.112464; batch adversarial loss: 0.474051\n",
      "epoch 194; iter: 0; batch classifier loss: 0.195413; batch adversarial loss: 0.571192\n",
      "epoch 195; iter: 0; batch classifier loss: 0.158789; batch adversarial loss: 0.505205\n",
      "epoch 196; iter: 0; batch classifier loss: 0.173061; batch adversarial loss: 0.558338\n",
      "epoch 197; iter: 0; batch classifier loss: 0.136279; batch adversarial loss: 0.501208\n",
      "epoch 198; iter: 0; batch classifier loss: 0.136611; batch adversarial loss: 0.434745\n",
      "epoch 199; iter: 0; batch classifier loss: 0.125252; batch adversarial loss: 0.503645\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703607; batch adversarial loss: 0.796616\n",
      "epoch 1; iter: 0; batch classifier loss: 0.548336; batch adversarial loss: 0.770338\n",
      "epoch 2; iter: 0; batch classifier loss: 0.717108; batch adversarial loss: 0.771873\n",
      "epoch 3; iter: 0; batch classifier loss: 0.786906; batch adversarial loss: 0.709009\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548764; batch adversarial loss: 0.620184\n",
      "epoch 5; iter: 0; batch classifier loss: 0.421821; batch adversarial loss: 0.597966\n",
      "epoch 6; iter: 0; batch classifier loss: 0.335558; batch adversarial loss: 0.571827\n",
      "epoch 7; iter: 0; batch classifier loss: 0.325199; batch adversarial loss: 0.575283\n",
      "epoch 8; iter: 0; batch classifier loss: 0.357645; batch adversarial loss: 0.541193\n",
      "epoch 9; iter: 0; batch classifier loss: 0.272223; batch adversarial loss: 0.522064\n",
      "epoch 10; iter: 0; batch classifier loss: 0.300361; batch adversarial loss: 0.539780\n",
      "epoch 11; iter: 0; batch classifier loss: 0.274754; batch adversarial loss: 0.522947\n",
      "epoch 12; iter: 0; batch classifier loss: 0.196172; batch adversarial loss: 0.571525\n",
      "epoch 13; iter: 0; batch classifier loss: 0.268214; batch adversarial loss: 0.478574\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283536; batch adversarial loss: 0.508503\n",
      "epoch 15; iter: 0; batch classifier loss: 0.311247; batch adversarial loss: 0.433023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.250554; batch adversarial loss: 0.479116\n",
      "epoch 17; iter: 0; batch classifier loss: 0.198635; batch adversarial loss: 0.445713\n",
      "epoch 18; iter: 0; batch classifier loss: 0.264675; batch adversarial loss: 0.489888\n",
      "epoch 19; iter: 0; batch classifier loss: 0.173072; batch adversarial loss: 0.540895\n",
      "epoch 20; iter: 0; batch classifier loss: 0.216671; batch adversarial loss: 0.497907\n",
      "epoch 21; iter: 0; batch classifier loss: 0.168536; batch adversarial loss: 0.512382\n",
      "epoch 22; iter: 0; batch classifier loss: 0.183136; batch adversarial loss: 0.571037\n",
      "epoch 23; iter: 0; batch classifier loss: 0.208605; batch adversarial loss: 0.456253\n",
      "epoch 24; iter: 0; batch classifier loss: 0.222709; batch adversarial loss: 0.459038\n",
      "epoch 25; iter: 0; batch classifier loss: 0.186998; batch adversarial loss: 0.481396\n",
      "epoch 26; iter: 0; batch classifier loss: 0.146293; batch adversarial loss: 0.449053\n",
      "epoch 27; iter: 0; batch classifier loss: 0.198270; batch adversarial loss: 0.526844\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160259; batch adversarial loss: 0.416136\n",
      "epoch 29; iter: 0; batch classifier loss: 0.115972; batch adversarial loss: 0.472610\n",
      "epoch 30; iter: 0; batch classifier loss: 0.106910; batch adversarial loss: 0.419958\n",
      "epoch 31; iter: 0; batch classifier loss: 0.149916; batch adversarial loss: 0.440348\n",
      "epoch 32; iter: 0; batch classifier loss: 0.116867; batch adversarial loss: 0.496191\n",
      "epoch 33; iter: 0; batch classifier loss: 0.071965; batch adversarial loss: 0.425597\n",
      "epoch 34; iter: 0; batch classifier loss: 0.119291; batch adversarial loss: 0.468419\n",
      "epoch 35; iter: 0; batch classifier loss: 0.128612; batch adversarial loss: 0.440124\n",
      "epoch 36; iter: 0; batch classifier loss: 0.165355; batch adversarial loss: 0.433788\n",
      "epoch 37; iter: 0; batch classifier loss: 0.143966; batch adversarial loss: 0.446544\n",
      "epoch 38; iter: 0; batch classifier loss: 0.109905; batch adversarial loss: 0.466202\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126811; batch adversarial loss: 0.550776\n",
      "epoch 40; iter: 0; batch classifier loss: 0.119211; batch adversarial loss: 0.483421\n",
      "epoch 41; iter: 0; batch classifier loss: 0.103880; batch adversarial loss: 0.454137\n",
      "epoch 42; iter: 0; batch classifier loss: 0.061008; batch adversarial loss: 0.467640\n",
      "epoch 43; iter: 0; batch classifier loss: 0.128982; batch adversarial loss: 0.468333\n",
      "epoch 44; iter: 0; batch classifier loss: 0.067242; batch adversarial loss: 0.513684\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091319; batch adversarial loss: 0.466240\n",
      "epoch 46; iter: 0; batch classifier loss: 0.083416; batch adversarial loss: 0.418496\n",
      "epoch 47; iter: 0; batch classifier loss: 0.059958; batch adversarial loss: 0.419223\n",
      "epoch 48; iter: 0; batch classifier loss: 0.074351; batch adversarial loss: 0.422165\n",
      "epoch 49; iter: 0; batch classifier loss: 0.071536; batch adversarial loss: 0.389455\n",
      "epoch 50; iter: 0; batch classifier loss: 0.090179; batch adversarial loss: 0.495691\n",
      "epoch 51; iter: 0; batch classifier loss: 0.060518; batch adversarial loss: 0.535434\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071705; batch adversarial loss: 0.562699\n",
      "epoch 53; iter: 0; batch classifier loss: 0.069420; batch adversarial loss: 0.431580\n",
      "epoch 54; iter: 0; batch classifier loss: 0.072471; batch adversarial loss: 0.485474\n",
      "epoch 55; iter: 0; batch classifier loss: 0.039586; batch adversarial loss: 0.442972\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083523; batch adversarial loss: 0.416852\n",
      "epoch 57; iter: 0; batch classifier loss: 0.077876; batch adversarial loss: 0.451860\n",
      "epoch 58; iter: 0; batch classifier loss: 0.067751; batch adversarial loss: 0.453144\n",
      "epoch 59; iter: 0; batch classifier loss: 0.078175; batch adversarial loss: 0.441762\n",
      "epoch 60; iter: 0; batch classifier loss: 0.041569; batch adversarial loss: 0.536187\n",
      "epoch 61; iter: 0; batch classifier loss: 0.094692; batch adversarial loss: 0.473568\n",
      "epoch 62; iter: 0; batch classifier loss: 0.061394; batch adversarial loss: 0.397287\n",
      "epoch 63; iter: 0; batch classifier loss: 0.050113; batch adversarial loss: 0.488301\n",
      "epoch 64; iter: 0; batch classifier loss: 0.051445; batch adversarial loss: 0.463854\n",
      "epoch 65; iter: 0; batch classifier loss: 0.041341; batch adversarial loss: 0.478726\n",
      "epoch 66; iter: 0; batch classifier loss: 0.044816; batch adversarial loss: 0.620866\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069745; batch adversarial loss: 0.436045\n",
      "epoch 68; iter: 0; batch classifier loss: 0.080008; batch adversarial loss: 0.422195\n",
      "epoch 69; iter: 0; batch classifier loss: 0.043868; batch adversarial loss: 0.467556\n",
      "epoch 70; iter: 0; batch classifier loss: 0.105998; batch adversarial loss: 0.519803\n",
      "epoch 71; iter: 0; batch classifier loss: 0.037764; batch adversarial loss: 0.430403\n",
      "epoch 72; iter: 0; batch classifier loss: 0.045421; batch adversarial loss: 0.499296\n",
      "epoch 73; iter: 0; batch classifier loss: 0.029542; batch adversarial loss: 0.473355\n",
      "epoch 74; iter: 0; batch classifier loss: 0.046759; batch adversarial loss: 0.558769\n",
      "epoch 75; iter: 0; batch classifier loss: 0.041146; batch adversarial loss: 0.557043\n",
      "epoch 76; iter: 0; batch classifier loss: 0.037026; batch adversarial loss: 0.469937\n",
      "epoch 77; iter: 0; batch classifier loss: 0.073716; batch adversarial loss: 0.510412\n",
      "epoch 78; iter: 0; batch classifier loss: 0.038374; batch adversarial loss: 0.476352\n",
      "epoch 79; iter: 0; batch classifier loss: 0.058856; batch adversarial loss: 0.577419\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060319; batch adversarial loss: 0.445529\n",
      "epoch 81; iter: 0; batch classifier loss: 0.028410; batch adversarial loss: 0.546871\n",
      "epoch 82; iter: 0; batch classifier loss: 0.028908; batch adversarial loss: 0.495152\n",
      "epoch 83; iter: 0; batch classifier loss: 0.037328; batch adversarial loss: 0.394534\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052785; batch adversarial loss: 0.463239\n",
      "epoch 85; iter: 0; batch classifier loss: 0.035797; batch adversarial loss: 0.467719\n",
      "epoch 86; iter: 0; batch classifier loss: 0.033374; batch adversarial loss: 0.548996\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046854; batch adversarial loss: 0.446762\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041798; batch adversarial loss: 0.448098\n",
      "epoch 89; iter: 0; batch classifier loss: 0.034539; batch adversarial loss: 0.501606\n",
      "epoch 90; iter: 0; batch classifier loss: 0.028872; batch adversarial loss: 0.421281\n",
      "epoch 91; iter: 0; batch classifier loss: 0.034449; batch adversarial loss: 0.461371\n",
      "epoch 92; iter: 0; batch classifier loss: 0.038739; batch adversarial loss: 0.581545\n",
      "epoch 93; iter: 0; batch classifier loss: 0.029300; batch adversarial loss: 0.495380\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079661; batch adversarial loss: 0.366581\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048311; batch adversarial loss: 0.446321\n",
      "epoch 96; iter: 0; batch classifier loss: 0.038263; batch adversarial loss: 0.446643\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037581; batch adversarial loss: 0.431243\n",
      "epoch 98; iter: 0; batch classifier loss: 0.032874; batch adversarial loss: 0.437539\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038145; batch adversarial loss: 0.436814\n",
      "epoch 100; iter: 0; batch classifier loss: 0.025022; batch adversarial loss: 0.472161\n",
      "epoch 101; iter: 0; batch classifier loss: 0.038199; batch adversarial loss: 0.484836\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032435; batch adversarial loss: 0.502933\n",
      "epoch 103; iter: 0; batch classifier loss: 0.031311; batch adversarial loss: 0.436056\n",
      "epoch 104; iter: 0; batch classifier loss: 0.028679; batch adversarial loss: 0.483637\n",
      "epoch 105; iter: 0; batch classifier loss: 0.019886; batch adversarial loss: 0.463329\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068621; batch adversarial loss: 0.512281\n",
      "epoch 107; iter: 0; batch classifier loss: 0.013025; batch adversarial loss: 0.409765\n",
      "epoch 108; iter: 0; batch classifier loss: 0.013608; batch adversarial loss: 0.431904\n",
      "epoch 109; iter: 0; batch classifier loss: 0.014765; batch adversarial loss: 0.437560\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023842; batch adversarial loss: 0.388745\n",
      "epoch 111; iter: 0; batch classifier loss: 0.027446; batch adversarial loss: 0.623341\n",
      "epoch 112; iter: 0; batch classifier loss: 0.019327; batch adversarial loss: 0.516217\n",
      "epoch 113; iter: 0; batch classifier loss: 0.022515; batch adversarial loss: 0.535366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.023349; batch adversarial loss: 0.389240\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037111; batch adversarial loss: 0.367029\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024803; batch adversarial loss: 0.485561\n",
      "epoch 117; iter: 0; batch classifier loss: 0.018990; batch adversarial loss: 0.476185\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032123; batch adversarial loss: 0.433170\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049097; batch adversarial loss: 0.456268\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020668; batch adversarial loss: 0.477352\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027025; batch adversarial loss: 0.442220\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049026; batch adversarial loss: 0.519456\n",
      "epoch 123; iter: 0; batch classifier loss: 0.016569; batch adversarial loss: 0.448092\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041261; batch adversarial loss: 0.542727\n",
      "epoch 125; iter: 0; batch classifier loss: 0.007063; batch adversarial loss: 0.336828\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019117; batch adversarial loss: 0.494684\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028250; batch adversarial loss: 0.499214\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047963; batch adversarial loss: 0.409557\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031892; batch adversarial loss: 0.504947\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020988; batch adversarial loss: 0.504469\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021430; batch adversarial loss: 0.461644\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020003; batch adversarial loss: 0.501707\n",
      "epoch 133; iter: 0; batch classifier loss: 0.010408; batch adversarial loss: 0.416464\n",
      "epoch 134; iter: 0; batch classifier loss: 0.007510; batch adversarial loss: 0.430171\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027834; batch adversarial loss: 0.423833\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022001; batch adversarial loss: 0.483377\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043926; batch adversarial loss: 0.388656\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021575; batch adversarial loss: 0.526731\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010256; batch adversarial loss: 0.415105\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032417; batch adversarial loss: 0.524534\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030215; batch adversarial loss: 0.446151\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022956; batch adversarial loss: 0.473022\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011543; batch adversarial loss: 0.404079\n",
      "epoch 144; iter: 0; batch classifier loss: 0.035955; batch adversarial loss: 0.489079\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021341; batch adversarial loss: 0.380961\n",
      "epoch 146; iter: 0; batch classifier loss: 0.007410; batch adversarial loss: 0.435989\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017966; batch adversarial loss: 0.435678\n",
      "epoch 148; iter: 0; batch classifier loss: 0.009425; batch adversarial loss: 0.603098\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013579; batch adversarial loss: 0.463964\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042778; batch adversarial loss: 0.461356\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022429; batch adversarial loss: 0.420649\n",
      "epoch 152; iter: 0; batch classifier loss: 0.005873; batch adversarial loss: 0.437616\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013986; batch adversarial loss: 0.459234\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010441; batch adversarial loss: 0.542918\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030419; batch adversarial loss: 0.419527\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029296; batch adversarial loss: 0.390249\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027259; batch adversarial loss: 0.385350\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032998; batch adversarial loss: 0.413314\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015009; batch adversarial loss: 0.526172\n",
      "epoch 160; iter: 0; batch classifier loss: 0.011887; batch adversarial loss: 0.418186\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027448; batch adversarial loss: 0.365584\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010027; batch adversarial loss: 0.450007\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024450; batch adversarial loss: 0.443947\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022550; batch adversarial loss: 0.429356\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028022; batch adversarial loss: 0.505187\n",
      "epoch 166; iter: 0; batch classifier loss: 0.008324; batch adversarial loss: 0.518294\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010049; batch adversarial loss: 0.457769\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034094; batch adversarial loss: 0.493555\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010719; batch adversarial loss: 0.413326\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011310; batch adversarial loss: 0.474958\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030652; batch adversarial loss: 0.408217\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012940; batch adversarial loss: 0.416123\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007576; batch adversarial loss: 0.557562\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023673; batch adversarial loss: 0.477767\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034301; batch adversarial loss: 0.489454\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030269; batch adversarial loss: 0.462304\n",
      "epoch 177; iter: 0; batch classifier loss: 0.004740; batch adversarial loss: 0.473563\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023404; batch adversarial loss: 0.477407\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019424; batch adversarial loss: 0.375408\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008116; batch adversarial loss: 0.529075\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029620; batch adversarial loss: 0.476228\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015435; batch adversarial loss: 0.521534\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023252; batch adversarial loss: 0.459612\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004979; batch adversarial loss: 0.454949\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011272; batch adversarial loss: 0.414034\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008360; batch adversarial loss: 0.500322\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019506; batch adversarial loss: 0.459332\n",
      "epoch 188; iter: 0; batch classifier loss: 0.060557; batch adversarial loss: 0.541123\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007263; batch adversarial loss: 0.473460\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022221; batch adversarial loss: 0.422657\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015154; batch adversarial loss: 0.420056\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031265; batch adversarial loss: 0.476943\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016846; batch adversarial loss: 0.373462\n",
      "epoch 194; iter: 0; batch classifier loss: 0.037203; batch adversarial loss: 0.559622\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009056; batch adversarial loss: 0.419439\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013811; batch adversarial loss: 0.466623\n",
      "epoch 197; iter: 0; batch classifier loss: 0.002745; batch adversarial loss: 0.400375\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009230; batch adversarial loss: 0.441411\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026855; batch adversarial loss: 0.557734\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695120; batch adversarial loss: 0.608584\n",
      "epoch 1; iter: 0; batch classifier loss: 0.415082; batch adversarial loss: 0.614800\n",
      "epoch 2; iter: 0; batch classifier loss: 0.449083; batch adversarial loss: 0.571733\n",
      "epoch 3; iter: 0; batch classifier loss: 0.344982; batch adversarial loss: 0.563938\n",
      "epoch 4; iter: 0; batch classifier loss: 0.248126; batch adversarial loss: 0.553621\n",
      "epoch 5; iter: 0; batch classifier loss: 0.317425; batch adversarial loss: 0.582422\n",
      "epoch 6; iter: 0; batch classifier loss: 0.319541; batch adversarial loss: 0.548863\n",
      "epoch 7; iter: 0; batch classifier loss: 0.287449; batch adversarial loss: 0.492767\n",
      "epoch 8; iter: 0; batch classifier loss: 0.229301; batch adversarial loss: 0.509932\n",
      "epoch 9; iter: 0; batch classifier loss: 0.249336; batch adversarial loss: 0.485936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.198641; batch adversarial loss: 0.465465\n",
      "epoch 11; iter: 0; batch classifier loss: 0.225066; batch adversarial loss: 0.510866\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285500; batch adversarial loss: 0.496890\n",
      "epoch 13; iter: 0; batch classifier loss: 0.291756; batch adversarial loss: 0.476055\n",
      "epoch 14; iter: 0; batch classifier loss: 0.257531; batch adversarial loss: 0.508216\n",
      "epoch 15; iter: 0; batch classifier loss: 0.235144; batch adversarial loss: 0.443805\n",
      "epoch 16; iter: 0; batch classifier loss: 0.319237; batch adversarial loss: 0.459433\n",
      "epoch 17; iter: 0; batch classifier loss: 0.305298; batch adversarial loss: 0.519891\n",
      "epoch 18; iter: 0; batch classifier loss: 0.263578; batch adversarial loss: 0.546108\n",
      "epoch 19; iter: 0; batch classifier loss: 0.286807; batch adversarial loss: 0.502606\n",
      "epoch 20; iter: 0; batch classifier loss: 0.367230; batch adversarial loss: 0.531472\n",
      "epoch 21; iter: 0; batch classifier loss: 0.525244; batch adversarial loss: 0.506888\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465287; batch adversarial loss: 0.473966\n",
      "epoch 23; iter: 0; batch classifier loss: 0.308957; batch adversarial loss: 0.449147\n",
      "epoch 24; iter: 0; batch classifier loss: 0.216327; batch adversarial loss: 0.502423\n",
      "epoch 25; iter: 0; batch classifier loss: 0.227612; batch adversarial loss: 0.507087\n",
      "epoch 26; iter: 0; batch classifier loss: 0.168437; batch adversarial loss: 0.489762\n",
      "epoch 27; iter: 0; batch classifier loss: 0.118427; batch adversarial loss: 0.513277\n",
      "epoch 28; iter: 0; batch classifier loss: 0.172056; batch adversarial loss: 0.513311\n",
      "epoch 29; iter: 0; batch classifier loss: 0.131924; batch adversarial loss: 0.507675\n",
      "epoch 30; iter: 0; batch classifier loss: 0.104824; batch adversarial loss: 0.527246\n",
      "epoch 31; iter: 0; batch classifier loss: 0.143991; batch adversarial loss: 0.468505\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154008; batch adversarial loss: 0.482855\n",
      "epoch 33; iter: 0; batch classifier loss: 0.136261; batch adversarial loss: 0.442654\n",
      "epoch 34; iter: 0; batch classifier loss: 0.088238; batch adversarial loss: 0.471268\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151973; batch adversarial loss: 0.508944\n",
      "epoch 36; iter: 0; batch classifier loss: 0.134228; batch adversarial loss: 0.406022\n",
      "epoch 37; iter: 0; batch classifier loss: 0.219687; batch adversarial loss: 0.375873\n",
      "epoch 38; iter: 0; batch classifier loss: 0.140910; batch adversarial loss: 0.442266\n",
      "epoch 39; iter: 0; batch classifier loss: 0.166028; batch adversarial loss: 0.520668\n",
      "epoch 40; iter: 0; batch classifier loss: 0.137358; batch adversarial loss: 0.366956\n",
      "epoch 41; iter: 0; batch classifier loss: 0.128587; batch adversarial loss: 0.446293\n",
      "epoch 42; iter: 0; batch classifier loss: 0.141853; batch adversarial loss: 0.472801\n",
      "epoch 43; iter: 0; batch classifier loss: 0.101382; batch adversarial loss: 0.528015\n",
      "epoch 44; iter: 0; batch classifier loss: 0.090117; batch adversarial loss: 0.598898\n",
      "epoch 45; iter: 0; batch classifier loss: 0.158531; batch adversarial loss: 0.445372\n",
      "epoch 46; iter: 0; batch classifier loss: 0.097365; batch adversarial loss: 0.478157\n",
      "epoch 47; iter: 0; batch classifier loss: 0.093302; batch adversarial loss: 0.422673\n",
      "epoch 48; iter: 0; batch classifier loss: 0.118475; batch adversarial loss: 0.503855\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114515; batch adversarial loss: 0.444845\n",
      "epoch 50; iter: 0; batch classifier loss: 0.121715; batch adversarial loss: 0.419488\n",
      "epoch 51; iter: 0; batch classifier loss: 0.111312; batch adversarial loss: 0.475510\n",
      "epoch 52; iter: 0; batch classifier loss: 0.075296; batch adversarial loss: 0.451152\n",
      "epoch 53; iter: 0; batch classifier loss: 0.134632; batch adversarial loss: 0.439626\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079664; batch adversarial loss: 0.382133\n",
      "epoch 55; iter: 0; batch classifier loss: 0.074957; batch adversarial loss: 0.356148\n",
      "epoch 56; iter: 0; batch classifier loss: 0.075658; batch adversarial loss: 0.537216\n",
      "epoch 57; iter: 0; batch classifier loss: 0.074630; batch adversarial loss: 0.476563\n",
      "epoch 58; iter: 0; batch classifier loss: 0.079191; batch adversarial loss: 0.385256\n",
      "epoch 59; iter: 0; batch classifier loss: 0.060712; batch adversarial loss: 0.456941\n",
      "epoch 60; iter: 0; batch classifier loss: 0.103266; batch adversarial loss: 0.446740\n",
      "epoch 61; iter: 0; batch classifier loss: 0.123209; batch adversarial loss: 0.581029\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094941; batch adversarial loss: 0.477410\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059417; batch adversarial loss: 0.454935\n",
      "epoch 64; iter: 0; batch classifier loss: 0.058922; batch adversarial loss: 0.484964\n",
      "epoch 65; iter: 0; batch classifier loss: 0.066808; batch adversarial loss: 0.529409\n",
      "epoch 66; iter: 0; batch classifier loss: 0.100956; batch adversarial loss: 0.449743\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056466; batch adversarial loss: 0.466132\n",
      "epoch 68; iter: 0; batch classifier loss: 0.085080; batch adversarial loss: 0.415599\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073585; batch adversarial loss: 0.419124\n",
      "epoch 70; iter: 0; batch classifier loss: 0.083176; batch adversarial loss: 0.457518\n",
      "epoch 71; iter: 0; batch classifier loss: 0.050210; batch adversarial loss: 0.511773\n",
      "epoch 72; iter: 0; batch classifier loss: 0.079678; batch adversarial loss: 0.453683\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087907; batch adversarial loss: 0.426469\n",
      "epoch 74; iter: 0; batch classifier loss: 0.074210; batch adversarial loss: 0.556313\n",
      "epoch 75; iter: 0; batch classifier loss: 0.171288; batch adversarial loss: 0.547452\n",
      "epoch 76; iter: 0; batch classifier loss: 0.096582; batch adversarial loss: 0.418879\n",
      "epoch 77; iter: 0; batch classifier loss: 0.068339; batch adversarial loss: 0.510758\n",
      "epoch 78; iter: 0; batch classifier loss: 0.116042; batch adversarial loss: 0.445703\n",
      "epoch 79; iter: 0; batch classifier loss: 0.121881; batch adversarial loss: 0.490603\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088965; batch adversarial loss: 0.366284\n",
      "epoch 81; iter: 0; batch classifier loss: 0.037462; batch adversarial loss: 0.444034\n",
      "epoch 82; iter: 0; batch classifier loss: 0.081589; batch adversarial loss: 0.470485\n",
      "epoch 83; iter: 0; batch classifier loss: 0.042585; batch adversarial loss: 0.538968\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065114; batch adversarial loss: 0.446682\n",
      "epoch 85; iter: 0; batch classifier loss: 0.097885; batch adversarial loss: 0.458627\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040876; batch adversarial loss: 0.503109\n",
      "epoch 87; iter: 0; batch classifier loss: 0.103467; batch adversarial loss: 0.476532\n",
      "epoch 88; iter: 0; batch classifier loss: 0.074620; batch adversarial loss: 0.498441\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056584; batch adversarial loss: 0.546588\n",
      "epoch 90; iter: 0; batch classifier loss: 0.083431; batch adversarial loss: 0.404084\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081200; batch adversarial loss: 0.502112\n",
      "epoch 92; iter: 0; batch classifier loss: 0.067842; batch adversarial loss: 0.500432\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080484; batch adversarial loss: 0.367586\n",
      "epoch 94; iter: 0; batch classifier loss: 0.096569; batch adversarial loss: 0.467728\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051981; batch adversarial loss: 0.354057\n",
      "epoch 96; iter: 0; batch classifier loss: 0.092205; batch adversarial loss: 0.472757\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075091; batch adversarial loss: 0.505307\n",
      "epoch 98; iter: 0; batch classifier loss: 0.068409; batch adversarial loss: 0.571153\n",
      "epoch 99; iter: 0; batch classifier loss: 0.097713; batch adversarial loss: 0.420905\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056566; batch adversarial loss: 0.382786\n",
      "epoch 101; iter: 0; batch classifier loss: 0.081491; batch adversarial loss: 0.431530\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054915; batch adversarial loss: 0.575187\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054894; batch adversarial loss: 0.454601\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039040; batch adversarial loss: 0.519317\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055197; batch adversarial loss: 0.436356\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044354; batch adversarial loss: 0.494460\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053350; batch adversarial loss: 0.422848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.066228; batch adversarial loss: 0.517570\n",
      "epoch 109; iter: 0; batch classifier loss: 0.097711; batch adversarial loss: 0.457345\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040511; batch adversarial loss: 0.470181\n",
      "epoch 111; iter: 0; batch classifier loss: 0.038896; batch adversarial loss: 0.511854\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038225; batch adversarial loss: 0.511801\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045099; batch adversarial loss: 0.458116\n",
      "epoch 114; iter: 0; batch classifier loss: 0.065592; batch adversarial loss: 0.491223\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034730; batch adversarial loss: 0.472099\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043661; batch adversarial loss: 0.508247\n",
      "epoch 117; iter: 0; batch classifier loss: 0.090880; batch adversarial loss: 0.443327\n",
      "epoch 118; iter: 0; batch classifier loss: 0.087951; batch adversarial loss: 0.435827\n",
      "epoch 119; iter: 0; batch classifier loss: 0.018896; batch adversarial loss: 0.471956\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074569; batch adversarial loss: 0.541251\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033150; batch adversarial loss: 0.458970\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033452; batch adversarial loss: 0.484216\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043167; batch adversarial loss: 0.432642\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044945; batch adversarial loss: 0.566747\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062142; batch adversarial loss: 0.402020\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025403; batch adversarial loss: 0.425752\n",
      "epoch 127; iter: 0; batch classifier loss: 0.049818; batch adversarial loss: 0.429846\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041926; batch adversarial loss: 0.482014\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032578; batch adversarial loss: 0.398034\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028801; batch adversarial loss: 0.379242\n",
      "epoch 131; iter: 0; batch classifier loss: 0.100240; batch adversarial loss: 0.451428\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037463; batch adversarial loss: 0.416346\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028323; batch adversarial loss: 0.416100\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040187; batch adversarial loss: 0.523089\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025059; batch adversarial loss: 0.416622\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042151; batch adversarial loss: 0.400088\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044114; batch adversarial loss: 0.521920\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029604; batch adversarial loss: 0.442617\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039843; batch adversarial loss: 0.466693\n",
      "epoch 140; iter: 0; batch classifier loss: 0.068562; batch adversarial loss: 0.465471\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038679; batch adversarial loss: 0.440781\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019158; batch adversarial loss: 0.481938\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039036; batch adversarial loss: 0.403531\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048929; batch adversarial loss: 0.454896\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041209; batch adversarial loss: 0.441361\n",
      "epoch 146; iter: 0; batch classifier loss: 0.043204; batch adversarial loss: 0.383899\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038525; batch adversarial loss: 0.506518\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041110; batch adversarial loss: 0.385477\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014316; batch adversarial loss: 0.443137\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023497; batch adversarial loss: 0.468224\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021634; batch adversarial loss: 0.495066\n",
      "epoch 152; iter: 0; batch classifier loss: 0.047872; batch adversarial loss: 0.472873\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024402; batch adversarial loss: 0.450062\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034268; batch adversarial loss: 0.448623\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035472; batch adversarial loss: 0.415367\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045041; batch adversarial loss: 0.434123\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034114; batch adversarial loss: 0.556501\n",
      "epoch 158; iter: 0; batch classifier loss: 0.050857; batch adversarial loss: 0.420298\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015035; batch adversarial loss: 0.454262\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025071; batch adversarial loss: 0.355175\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014015; batch adversarial loss: 0.455840\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025508; batch adversarial loss: 0.438553\n",
      "epoch 163; iter: 0; batch classifier loss: 0.059087; batch adversarial loss: 0.448097\n",
      "epoch 164; iter: 0; batch classifier loss: 0.066806; batch adversarial loss: 0.381485\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030379; batch adversarial loss: 0.428485\n",
      "epoch 166; iter: 0; batch classifier loss: 0.049178; batch adversarial loss: 0.436020\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033414; batch adversarial loss: 0.522072\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041010; batch adversarial loss: 0.469944\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012578; batch adversarial loss: 0.435990\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035247; batch adversarial loss: 0.477208\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016548; batch adversarial loss: 0.387910\n",
      "epoch 172; iter: 0; batch classifier loss: 0.042878; batch adversarial loss: 0.543218\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030525; batch adversarial loss: 0.466090\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032546; batch adversarial loss: 0.612671\n",
      "epoch 175; iter: 0; batch classifier loss: 0.056550; batch adversarial loss: 0.435532\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026094; batch adversarial loss: 0.406497\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018977; batch adversarial loss: 0.542032\n",
      "epoch 178; iter: 0; batch classifier loss: 0.059629; batch adversarial loss: 0.496476\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034928; batch adversarial loss: 0.432370\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029352; batch adversarial loss: 0.541451\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020720; batch adversarial loss: 0.475735\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025232; batch adversarial loss: 0.370457\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026521; batch adversarial loss: 0.369044\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022074; batch adversarial loss: 0.455004\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040006; batch adversarial loss: 0.494036\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013018; batch adversarial loss: 0.471142\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026691; batch adversarial loss: 0.490481\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007884; batch adversarial loss: 0.417865\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016443; batch adversarial loss: 0.443008\n",
      "epoch 190; iter: 0; batch classifier loss: 0.039473; batch adversarial loss: 0.416376\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030239; batch adversarial loss: 0.422305\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016585; batch adversarial loss: 0.512744\n",
      "epoch 193; iter: 0; batch classifier loss: 0.045729; batch adversarial loss: 0.418344\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022365; batch adversarial loss: 0.490397\n",
      "epoch 195; iter: 0; batch classifier loss: 0.048092; batch adversarial loss: 0.490048\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019849; batch adversarial loss: 0.407478\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031739; batch adversarial loss: 0.449558\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030128; batch adversarial loss: 0.430963\n",
      "epoch 199; iter: 0; batch classifier loss: 0.040413; batch adversarial loss: 0.388493\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690573; batch adversarial loss: 0.535606\n",
      "epoch 1; iter: 0; batch classifier loss: 0.356091; batch adversarial loss: 0.623714\n",
      "epoch 2; iter: 0; batch classifier loss: 0.341437; batch adversarial loss: 0.594500\n",
      "epoch 3; iter: 0; batch classifier loss: 0.284730; batch adversarial loss: 0.560241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.364684; batch adversarial loss: 0.470970\n",
      "epoch 5; iter: 0; batch classifier loss: 0.415367; batch adversarial loss: 0.560946\n",
      "epoch 6; iter: 0; batch classifier loss: 0.364117; batch adversarial loss: 0.552857\n",
      "epoch 7; iter: 0; batch classifier loss: 0.344019; batch adversarial loss: 0.513924\n",
      "epoch 8; iter: 0; batch classifier loss: 0.291511; batch adversarial loss: 0.534666\n",
      "epoch 9; iter: 0; batch classifier loss: 0.377256; batch adversarial loss: 0.527490\n",
      "epoch 10; iter: 0; batch classifier loss: 0.306766; batch adversarial loss: 0.577071\n",
      "epoch 11; iter: 0; batch classifier loss: 0.243653; batch adversarial loss: 0.509915\n",
      "epoch 12; iter: 0; batch classifier loss: 0.308721; batch adversarial loss: 0.502918\n",
      "epoch 13; iter: 0; batch classifier loss: 0.341675; batch adversarial loss: 0.581592\n",
      "epoch 14; iter: 0; batch classifier loss: 0.339305; batch adversarial loss: 0.569837\n",
      "epoch 15; iter: 0; batch classifier loss: 0.426436; batch adversarial loss: 0.506140\n",
      "epoch 16; iter: 0; batch classifier loss: 0.526018; batch adversarial loss: 0.555780\n",
      "epoch 17; iter: 0; batch classifier loss: 0.362396; batch adversarial loss: 0.541114\n",
      "epoch 18; iter: 0; batch classifier loss: 0.301600; batch adversarial loss: 0.492704\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223271; batch adversarial loss: 0.494077\n",
      "epoch 20; iter: 0; batch classifier loss: 0.218331; batch adversarial loss: 0.496802\n",
      "epoch 21; iter: 0; batch classifier loss: 0.229089; batch adversarial loss: 0.432264\n",
      "epoch 22; iter: 0; batch classifier loss: 0.214633; batch adversarial loss: 0.408535\n",
      "epoch 23; iter: 0; batch classifier loss: 0.155603; batch adversarial loss: 0.450857\n",
      "epoch 24; iter: 0; batch classifier loss: 0.181329; batch adversarial loss: 0.470841\n",
      "epoch 25; iter: 0; batch classifier loss: 0.166387; batch adversarial loss: 0.410216\n",
      "epoch 26; iter: 0; batch classifier loss: 0.183885; batch adversarial loss: 0.400520\n",
      "epoch 27; iter: 0; batch classifier loss: 0.142639; batch adversarial loss: 0.503469\n",
      "epoch 28; iter: 0; batch classifier loss: 0.109645; batch adversarial loss: 0.452375\n",
      "epoch 29; iter: 0; batch classifier loss: 0.094725; batch adversarial loss: 0.509904\n",
      "epoch 30; iter: 0; batch classifier loss: 0.111620; batch adversarial loss: 0.405428\n",
      "epoch 31; iter: 0; batch classifier loss: 0.147326; batch adversarial loss: 0.495113\n",
      "epoch 32; iter: 0; batch classifier loss: 0.175106; batch adversarial loss: 0.432947\n",
      "epoch 33; iter: 0; batch classifier loss: 0.082833; batch adversarial loss: 0.551045\n",
      "epoch 34; iter: 0; batch classifier loss: 0.154089; batch adversarial loss: 0.378031\n",
      "epoch 35; iter: 0; batch classifier loss: 0.102284; batch adversarial loss: 0.524268\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150562; batch adversarial loss: 0.383998\n",
      "epoch 37; iter: 0; batch classifier loss: 0.087696; batch adversarial loss: 0.489103\n",
      "epoch 38; iter: 0; batch classifier loss: 0.123281; batch adversarial loss: 0.417122\n",
      "epoch 39; iter: 0; batch classifier loss: 0.111897; batch adversarial loss: 0.397191\n",
      "epoch 40; iter: 0; batch classifier loss: 0.102712; batch adversarial loss: 0.421832\n",
      "epoch 41; iter: 0; batch classifier loss: 0.065619; batch adversarial loss: 0.595043\n",
      "epoch 42; iter: 0; batch classifier loss: 0.145397; batch adversarial loss: 0.546563\n",
      "epoch 43; iter: 0; batch classifier loss: 0.097652; batch adversarial loss: 0.495054\n",
      "epoch 44; iter: 0; batch classifier loss: 0.103315; batch adversarial loss: 0.411007\n",
      "epoch 45; iter: 0; batch classifier loss: 0.133025; batch adversarial loss: 0.462278\n",
      "epoch 46; iter: 0; batch classifier loss: 0.134623; batch adversarial loss: 0.389573\n",
      "epoch 47; iter: 0; batch classifier loss: 0.117586; batch adversarial loss: 0.503507\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141530; batch adversarial loss: 0.431730\n",
      "epoch 49; iter: 0; batch classifier loss: 0.089483; batch adversarial loss: 0.461114\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096211; batch adversarial loss: 0.546702\n",
      "epoch 51; iter: 0; batch classifier loss: 0.091856; batch adversarial loss: 0.541005\n",
      "epoch 52; iter: 0; batch classifier loss: 0.076558; batch adversarial loss: 0.374815\n",
      "epoch 53; iter: 0; batch classifier loss: 0.100948; batch adversarial loss: 0.441147\n",
      "epoch 54; iter: 0; batch classifier loss: 0.107141; batch adversarial loss: 0.445513\n",
      "epoch 55; iter: 0; batch classifier loss: 0.102296; batch adversarial loss: 0.467275\n",
      "epoch 56; iter: 0; batch classifier loss: 0.066600; batch adversarial loss: 0.463938\n",
      "epoch 57; iter: 0; batch classifier loss: 0.076873; batch adversarial loss: 0.504893\n",
      "epoch 58; iter: 0; batch classifier loss: 0.123092; batch adversarial loss: 0.412905\n",
      "epoch 59; iter: 0; batch classifier loss: 0.133898; batch adversarial loss: 0.414374\n",
      "epoch 60; iter: 0; batch classifier loss: 0.109582; batch adversarial loss: 0.456575\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114641; batch adversarial loss: 0.424272\n",
      "epoch 62; iter: 0; batch classifier loss: 0.058351; batch adversarial loss: 0.468693\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079359; batch adversarial loss: 0.466154\n",
      "epoch 64; iter: 0; batch classifier loss: 0.062503; batch adversarial loss: 0.479925\n",
      "epoch 65; iter: 0; batch classifier loss: 0.095434; batch adversarial loss: 0.403271\n",
      "epoch 66; iter: 0; batch classifier loss: 0.048702; batch adversarial loss: 0.493451\n",
      "epoch 67; iter: 0; batch classifier loss: 0.066947; batch adversarial loss: 0.493453\n",
      "epoch 68; iter: 0; batch classifier loss: 0.131912; batch adversarial loss: 0.558591\n",
      "epoch 69; iter: 0; batch classifier loss: 0.088099; batch adversarial loss: 0.416941\n",
      "epoch 70; iter: 0; batch classifier loss: 0.052743; batch adversarial loss: 0.450647\n",
      "epoch 71; iter: 0; batch classifier loss: 0.121211; batch adversarial loss: 0.482197\n",
      "epoch 72; iter: 0; batch classifier loss: 0.119013; batch adversarial loss: 0.536838\n",
      "epoch 73; iter: 0; batch classifier loss: 0.091519; batch adversarial loss: 0.389895\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054164; batch adversarial loss: 0.436326\n",
      "epoch 75; iter: 0; batch classifier loss: 0.086705; batch adversarial loss: 0.506269\n",
      "epoch 76; iter: 0; batch classifier loss: 0.079349; batch adversarial loss: 0.604818\n",
      "epoch 77; iter: 0; batch classifier loss: 0.085981; batch adversarial loss: 0.476382\n",
      "epoch 78; iter: 0; batch classifier loss: 0.143650; batch adversarial loss: 0.372377\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075681; batch adversarial loss: 0.501920\n",
      "epoch 80; iter: 0; batch classifier loss: 0.063642; batch adversarial loss: 0.452803\n",
      "epoch 81; iter: 0; batch classifier loss: 0.051185; batch adversarial loss: 0.560573\n",
      "epoch 82; iter: 0; batch classifier loss: 0.064547; batch adversarial loss: 0.416758\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056569; batch adversarial loss: 0.391780\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048743; batch adversarial loss: 0.399471\n",
      "epoch 85; iter: 0; batch classifier loss: 0.133738; batch adversarial loss: 0.427642\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065147; batch adversarial loss: 0.450536\n",
      "epoch 87; iter: 0; batch classifier loss: 0.044318; batch adversarial loss: 0.493408\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070996; batch adversarial loss: 0.552666\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035501; batch adversarial loss: 0.530937\n",
      "epoch 90; iter: 0; batch classifier loss: 0.085874; batch adversarial loss: 0.483703\n",
      "epoch 91; iter: 0; batch classifier loss: 0.109173; batch adversarial loss: 0.367360\n",
      "epoch 92; iter: 0; batch classifier loss: 0.072852; batch adversarial loss: 0.476518\n",
      "epoch 93; iter: 0; batch classifier loss: 0.070255; batch adversarial loss: 0.425215\n",
      "epoch 94; iter: 0; batch classifier loss: 0.082659; batch adversarial loss: 0.498081\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047877; batch adversarial loss: 0.457839\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075567; batch adversarial loss: 0.465973\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069777; batch adversarial loss: 0.482501\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063980; batch adversarial loss: 0.443911\n",
      "epoch 99; iter: 0; batch classifier loss: 0.086359; batch adversarial loss: 0.478294\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051719; batch adversarial loss: 0.390738\n",
      "epoch 101; iter: 0; batch classifier loss: 0.073250; batch adversarial loss: 0.479872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.037625; batch adversarial loss: 0.527149\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049503; batch adversarial loss: 0.472704\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083664; batch adversarial loss: 0.547868\n",
      "epoch 105; iter: 0; batch classifier loss: 0.013224; batch adversarial loss: 0.442225\n",
      "epoch 106; iter: 0; batch classifier loss: 0.098764; batch adversarial loss: 0.498190\n",
      "epoch 107; iter: 0; batch classifier loss: 0.092454; batch adversarial loss: 0.532975\n",
      "epoch 108; iter: 0; batch classifier loss: 0.089630; batch adversarial loss: 0.413462\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048459; batch adversarial loss: 0.519758\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038675; batch adversarial loss: 0.448001\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041204; batch adversarial loss: 0.459182\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044186; batch adversarial loss: 0.383824\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047061; batch adversarial loss: 0.381807\n",
      "epoch 114; iter: 0; batch classifier loss: 0.070926; batch adversarial loss: 0.475841\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057322; batch adversarial loss: 0.589589\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039249; batch adversarial loss: 0.460619\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031794; batch adversarial loss: 0.531079\n",
      "epoch 118; iter: 0; batch classifier loss: 0.079359; batch adversarial loss: 0.472987\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032026; batch adversarial loss: 0.410196\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036261; batch adversarial loss: 0.471977\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036965; batch adversarial loss: 0.389755\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035302; batch adversarial loss: 0.400003\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034332; batch adversarial loss: 0.486556\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050927; batch adversarial loss: 0.420430\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034491; batch adversarial loss: 0.484702\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057298; batch adversarial loss: 0.462311\n",
      "epoch 127; iter: 0; batch classifier loss: 0.092362; batch adversarial loss: 0.472076\n",
      "epoch 128; iter: 0; batch classifier loss: 0.060854; batch adversarial loss: 0.459108\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025122; batch adversarial loss: 0.456646\n",
      "epoch 130; iter: 0; batch classifier loss: 0.101280; batch adversarial loss: 0.486111\n",
      "epoch 131; iter: 0; batch classifier loss: 0.069488; batch adversarial loss: 0.510687\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043814; batch adversarial loss: 0.569999\n",
      "epoch 133; iter: 0; batch classifier loss: 0.050350; batch adversarial loss: 0.422628\n",
      "epoch 134; iter: 0; batch classifier loss: 0.061830; batch adversarial loss: 0.499588\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021050; batch adversarial loss: 0.524762\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041364; batch adversarial loss: 0.489266\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028438; batch adversarial loss: 0.489335\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038894; batch adversarial loss: 0.485624\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035497; batch adversarial loss: 0.375816\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037961; batch adversarial loss: 0.490157\n",
      "epoch 141; iter: 0; batch classifier loss: 0.058554; batch adversarial loss: 0.421178\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041684; batch adversarial loss: 0.396811\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037691; batch adversarial loss: 0.416011\n",
      "epoch 144; iter: 0; batch classifier loss: 0.083174; batch adversarial loss: 0.357605\n",
      "epoch 145; iter: 0; batch classifier loss: 0.054576; batch adversarial loss: 0.484712\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048615; batch adversarial loss: 0.371507\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041607; batch adversarial loss: 0.527311\n",
      "epoch 148; iter: 0; batch classifier loss: 0.053066; batch adversarial loss: 0.456308\n",
      "epoch 149; iter: 0; batch classifier loss: 0.054598; batch adversarial loss: 0.505130\n",
      "epoch 150; iter: 0; batch classifier loss: 0.051098; batch adversarial loss: 0.456203\n",
      "epoch 151; iter: 0; batch classifier loss: 0.050264; batch adversarial loss: 0.458724\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031893; batch adversarial loss: 0.432885\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026049; batch adversarial loss: 0.466465\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036223; batch adversarial loss: 0.407068\n",
      "epoch 155; iter: 0; batch classifier loss: 0.058620; batch adversarial loss: 0.399370\n",
      "epoch 156; iter: 0; batch classifier loss: 0.054362; batch adversarial loss: 0.476326\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036775; batch adversarial loss: 0.491963\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045833; batch adversarial loss: 0.505725\n",
      "epoch 159; iter: 0; batch classifier loss: 0.051698; batch adversarial loss: 0.514050\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027952; batch adversarial loss: 0.415851\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033914; batch adversarial loss: 0.433283\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026106; batch adversarial loss: 0.420257\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021321; batch adversarial loss: 0.390969\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029888; batch adversarial loss: 0.385486\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019471; batch adversarial loss: 0.449601\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028821; batch adversarial loss: 0.406321\n",
      "epoch 167; iter: 0; batch classifier loss: 0.055999; batch adversarial loss: 0.391931\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022480; batch adversarial loss: 0.483942\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032941; batch adversarial loss: 0.455537\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030477; batch adversarial loss: 0.473335\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024963; batch adversarial loss: 0.422550\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025361; batch adversarial loss: 0.488954\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037601; batch adversarial loss: 0.473596\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027452; batch adversarial loss: 0.439096\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007691; batch adversarial loss: 0.501761\n",
      "epoch 176; iter: 0; batch classifier loss: 0.058879; batch adversarial loss: 0.425047\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029588; batch adversarial loss: 0.442865\n",
      "epoch 178; iter: 0; batch classifier loss: 0.043606; batch adversarial loss: 0.423630\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013530; batch adversarial loss: 0.434007\n",
      "epoch 180; iter: 0; batch classifier loss: 0.053839; batch adversarial loss: 0.499987\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023303; batch adversarial loss: 0.445962\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033390; batch adversarial loss: 0.603398\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026386; batch adversarial loss: 0.411691\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010906; batch adversarial loss: 0.418949\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038516; batch adversarial loss: 0.501038\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037846; batch adversarial loss: 0.504361\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026096; batch adversarial loss: 0.417404\n",
      "epoch 188; iter: 0; batch classifier loss: 0.042389; batch adversarial loss: 0.450436\n",
      "epoch 189; iter: 0; batch classifier loss: 0.066489; batch adversarial loss: 0.428365\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022983; batch adversarial loss: 0.492997\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032249; batch adversarial loss: 0.404832\n",
      "epoch 192; iter: 0; batch classifier loss: 0.038859; batch adversarial loss: 0.400697\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031304; batch adversarial loss: 0.436113\n",
      "epoch 194; iter: 0; batch classifier loss: 0.054665; batch adversarial loss: 0.365240\n",
      "epoch 195; iter: 0; batch classifier loss: 0.046416; batch adversarial loss: 0.414988\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018220; batch adversarial loss: 0.493194\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009246; batch adversarial loss: 0.474601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.015272; batch adversarial loss: 0.481875\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030270; batch adversarial loss: 0.420215\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708510; batch adversarial loss: 0.779223\n",
      "epoch 1; iter: 0; batch classifier loss: 0.446685; batch adversarial loss: 0.732482\n",
      "epoch 2; iter: 0; batch classifier loss: 0.329813; batch adversarial loss: 0.680236\n",
      "epoch 3; iter: 0; batch classifier loss: 0.451193; batch adversarial loss: 0.657662\n",
      "epoch 4; iter: 0; batch classifier loss: 0.350556; batch adversarial loss: 0.637870\n",
      "epoch 5; iter: 0; batch classifier loss: 0.287874; batch adversarial loss: 0.611250\n",
      "epoch 6; iter: 0; batch classifier loss: 0.329637; batch adversarial loss: 0.567361\n",
      "epoch 7; iter: 0; batch classifier loss: 0.227389; batch adversarial loss: 0.551539\n",
      "epoch 8; iter: 0; batch classifier loss: 0.324133; batch adversarial loss: 0.517295\n",
      "epoch 9; iter: 0; batch classifier loss: 0.271727; batch adversarial loss: 0.494009\n",
      "epoch 10; iter: 0; batch classifier loss: 0.297114; batch adversarial loss: 0.489056\n",
      "epoch 11; iter: 0; batch classifier loss: 0.226308; batch adversarial loss: 0.490522\n",
      "epoch 12; iter: 0; batch classifier loss: 0.228610; batch adversarial loss: 0.549678\n",
      "epoch 13; iter: 0; batch classifier loss: 0.172229; batch adversarial loss: 0.486462\n",
      "epoch 14; iter: 0; batch classifier loss: 0.172534; batch adversarial loss: 0.470600\n",
      "epoch 15; iter: 0; batch classifier loss: 0.180610; batch adversarial loss: 0.400876\n",
      "epoch 16; iter: 0; batch classifier loss: 0.196043; batch adversarial loss: 0.486198\n",
      "epoch 17; iter: 0; batch classifier loss: 0.226153; batch adversarial loss: 0.480882\n",
      "epoch 18; iter: 0; batch classifier loss: 0.191828; batch adversarial loss: 0.458471\n",
      "epoch 19; iter: 0; batch classifier loss: 0.181100; batch adversarial loss: 0.437445\n",
      "epoch 20; iter: 0; batch classifier loss: 0.223758; batch adversarial loss: 0.428979\n",
      "epoch 21; iter: 0; batch classifier loss: 0.185715; batch adversarial loss: 0.409528\n",
      "epoch 22; iter: 0; batch classifier loss: 0.153576; batch adversarial loss: 0.405083\n",
      "epoch 23; iter: 0; batch classifier loss: 0.234619; batch adversarial loss: 0.442297\n",
      "epoch 24; iter: 0; batch classifier loss: 0.185451; batch adversarial loss: 0.461159\n",
      "epoch 25; iter: 0; batch classifier loss: 0.193526; batch adversarial loss: 0.397648\n",
      "epoch 26; iter: 0; batch classifier loss: 0.135122; batch adversarial loss: 0.426097\n",
      "epoch 27; iter: 0; batch classifier loss: 0.135657; batch adversarial loss: 0.449377\n",
      "epoch 28; iter: 0; batch classifier loss: 0.145776; batch adversarial loss: 0.323954\n",
      "epoch 29; iter: 0; batch classifier loss: 0.154270; batch adversarial loss: 0.403323\n",
      "epoch 30; iter: 0; batch classifier loss: 0.196686; batch adversarial loss: 0.438133\n",
      "epoch 31; iter: 0; batch classifier loss: 0.138200; batch adversarial loss: 0.412661\n",
      "epoch 32; iter: 0; batch classifier loss: 0.117271; batch adversarial loss: 0.359168\n",
      "epoch 33; iter: 0; batch classifier loss: 0.088727; batch adversarial loss: 0.397147\n",
      "epoch 34; iter: 0; batch classifier loss: 0.087123; batch adversarial loss: 0.428347\n",
      "epoch 35; iter: 0; batch classifier loss: 0.126343; batch adversarial loss: 0.359339\n",
      "epoch 36; iter: 0; batch classifier loss: 0.125913; batch adversarial loss: 0.458921\n",
      "epoch 37; iter: 0; batch classifier loss: 0.151408; batch adversarial loss: 0.378327\n",
      "epoch 38; iter: 0; batch classifier loss: 0.131742; batch adversarial loss: 0.405254\n",
      "epoch 39; iter: 0; batch classifier loss: 0.117146; batch adversarial loss: 0.380407\n",
      "epoch 40; iter: 0; batch classifier loss: 0.190956; batch adversarial loss: 0.449802\n",
      "epoch 41; iter: 0; batch classifier loss: 0.128886; batch adversarial loss: 0.415668\n",
      "epoch 42; iter: 0; batch classifier loss: 0.076292; batch adversarial loss: 0.441338\n",
      "epoch 43; iter: 0; batch classifier loss: 0.107154; batch adversarial loss: 0.410323\n",
      "epoch 44; iter: 0; batch classifier loss: 0.062446; batch adversarial loss: 0.406113\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089422; batch adversarial loss: 0.427714\n",
      "epoch 46; iter: 0; batch classifier loss: 0.074726; batch adversarial loss: 0.369342\n",
      "epoch 47; iter: 0; batch classifier loss: 0.115576; batch adversarial loss: 0.462955\n",
      "epoch 48; iter: 0; batch classifier loss: 0.086440; batch adversarial loss: 0.450516\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101292; batch adversarial loss: 0.423032\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084408; batch adversarial loss: 0.452969\n",
      "epoch 51; iter: 0; batch classifier loss: 0.099994; batch adversarial loss: 0.432300\n",
      "epoch 52; iter: 0; batch classifier loss: 0.084899; batch adversarial loss: 0.454563\n",
      "epoch 53; iter: 0; batch classifier loss: 0.053142; batch adversarial loss: 0.389930\n",
      "epoch 54; iter: 0; batch classifier loss: 0.059052; batch adversarial loss: 0.469116\n",
      "epoch 55; iter: 0; batch classifier loss: 0.094438; batch adversarial loss: 0.435496\n",
      "epoch 56; iter: 0; batch classifier loss: 0.108818; batch adversarial loss: 0.482507\n",
      "epoch 57; iter: 0; batch classifier loss: 0.114791; batch adversarial loss: 0.487261\n",
      "epoch 58; iter: 0; batch classifier loss: 0.056776; batch adversarial loss: 0.422580\n",
      "epoch 59; iter: 0; batch classifier loss: 0.096617; batch adversarial loss: 0.432817\n",
      "epoch 60; iter: 0; batch classifier loss: 0.131701; batch adversarial loss: 0.445785\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087578; batch adversarial loss: 0.403605\n",
      "epoch 62; iter: 0; batch classifier loss: 0.127797; batch adversarial loss: 0.475972\n",
      "epoch 63; iter: 0; batch classifier loss: 0.071843; batch adversarial loss: 0.422278\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078010; batch adversarial loss: 0.386193\n",
      "epoch 65; iter: 0; batch classifier loss: 0.138030; batch adversarial loss: 0.435768\n",
      "epoch 66; iter: 0; batch classifier loss: 0.105185; batch adversarial loss: 0.446632\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065945; batch adversarial loss: 0.383812\n",
      "epoch 68; iter: 0; batch classifier loss: 0.098641; batch adversarial loss: 0.517884\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078031; batch adversarial loss: 0.436228\n",
      "epoch 70; iter: 0; batch classifier loss: 0.105465; batch adversarial loss: 0.497894\n",
      "epoch 71; iter: 0; batch classifier loss: 0.086645; batch adversarial loss: 0.498461\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087506; batch adversarial loss: 0.420415\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047717; batch adversarial loss: 0.376226\n",
      "epoch 74; iter: 0; batch classifier loss: 0.061190; batch adversarial loss: 0.454461\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061234; batch adversarial loss: 0.381881\n",
      "epoch 76; iter: 0; batch classifier loss: 0.145178; batch adversarial loss: 0.391410\n",
      "epoch 77; iter: 0; batch classifier loss: 0.095222; batch adversarial loss: 0.475113\n",
      "epoch 78; iter: 0; batch classifier loss: 0.067776; batch adversarial loss: 0.419827\n",
      "epoch 79; iter: 0; batch classifier loss: 0.066697; batch adversarial loss: 0.409607\n",
      "epoch 80; iter: 0; batch classifier loss: 0.049709; batch adversarial loss: 0.489279\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075614; batch adversarial loss: 0.482564\n",
      "epoch 82; iter: 0; batch classifier loss: 0.079623; batch adversarial loss: 0.435029\n",
      "epoch 83; iter: 0; batch classifier loss: 0.051402; batch adversarial loss: 0.440480\n",
      "epoch 84; iter: 0; batch classifier loss: 0.109123; batch adversarial loss: 0.534537\n",
      "epoch 85; iter: 0; batch classifier loss: 0.071159; batch adversarial loss: 0.449205\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058755; batch adversarial loss: 0.422548\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048897; batch adversarial loss: 0.488262\n",
      "epoch 88; iter: 0; batch classifier loss: 0.085272; batch adversarial loss: 0.490259\n",
      "epoch 89; iter: 0; batch classifier loss: 0.100939; batch adversarial loss: 0.466732\n",
      "epoch 90; iter: 0; batch classifier loss: 0.104500; batch adversarial loss: 0.437216\n",
      "epoch 91; iter: 0; batch classifier loss: 0.079707; batch adversarial loss: 0.458285\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069988; batch adversarial loss: 0.360505\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069271; batch adversarial loss: 0.337278\n",
      "epoch 94; iter: 0; batch classifier loss: 0.054472; batch adversarial loss: 0.483314\n",
      "epoch 95; iter: 0; batch classifier loss: 0.086787; batch adversarial loss: 0.480014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.060480; batch adversarial loss: 0.465105\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088465; batch adversarial loss: 0.364135\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079791; batch adversarial loss: 0.373055\n",
      "epoch 99; iter: 0; batch classifier loss: 0.090154; batch adversarial loss: 0.457868\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045549; batch adversarial loss: 0.380752\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058745; batch adversarial loss: 0.390294\n",
      "epoch 102; iter: 0; batch classifier loss: 0.064017; batch adversarial loss: 0.439260\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055666; batch adversarial loss: 0.351193\n",
      "epoch 104; iter: 0; batch classifier loss: 0.076219; batch adversarial loss: 0.456244\n",
      "epoch 105; iter: 0; batch classifier loss: 0.039201; batch adversarial loss: 0.423992\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068849; batch adversarial loss: 0.393354\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066936; batch adversarial loss: 0.426129\n",
      "epoch 108; iter: 0; batch classifier loss: 0.075554; batch adversarial loss: 0.421218\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067053; batch adversarial loss: 0.319868\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037577; batch adversarial loss: 0.378156\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062125; batch adversarial loss: 0.433466\n",
      "epoch 112; iter: 0; batch classifier loss: 0.062056; batch adversarial loss: 0.382808\n",
      "epoch 113; iter: 0; batch classifier loss: 0.088978; batch adversarial loss: 0.450027\n",
      "epoch 114; iter: 0; batch classifier loss: 0.063478; batch adversarial loss: 0.424146\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035105; batch adversarial loss: 0.464648\n",
      "epoch 116; iter: 0; batch classifier loss: 0.063722; batch adversarial loss: 0.445599\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048614; batch adversarial loss: 0.395876\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025366; batch adversarial loss: 0.376775\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041819; batch adversarial loss: 0.434152\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048177; batch adversarial loss: 0.454274\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065514; batch adversarial loss: 0.391636\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026298; batch adversarial loss: 0.360711\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067221; batch adversarial loss: 0.369937\n",
      "epoch 124; iter: 0; batch classifier loss: 0.049027; batch adversarial loss: 0.436426\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049443; batch adversarial loss: 0.458799\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047107; batch adversarial loss: 0.443690\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030689; batch adversarial loss: 0.396980\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036503; batch adversarial loss: 0.474252\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023057; batch adversarial loss: 0.458263\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051406; batch adversarial loss: 0.447730\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036381; batch adversarial loss: 0.427443\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027371; batch adversarial loss: 0.455000\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026543; batch adversarial loss: 0.474438\n",
      "epoch 134; iter: 0; batch classifier loss: 0.014469; batch adversarial loss: 0.426929\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035710; batch adversarial loss: 0.409448\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026921; batch adversarial loss: 0.479889\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025110; batch adversarial loss: 0.494340\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033384; batch adversarial loss: 0.460935\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023401; batch adversarial loss: 0.403030\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027752; batch adversarial loss: 0.536097\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023197; batch adversarial loss: 0.445509\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040188; batch adversarial loss: 0.457904\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029845; batch adversarial loss: 0.508637\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020783; batch adversarial loss: 0.420724\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016102; batch adversarial loss: 0.445887\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018564; batch adversarial loss: 0.424574\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023818; batch adversarial loss: 0.524330\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022813; batch adversarial loss: 0.428618\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015522; batch adversarial loss: 0.445924\n",
      "epoch 150; iter: 0; batch classifier loss: 0.009168; batch adversarial loss: 0.575864\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020918; batch adversarial loss: 0.441606\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019869; batch adversarial loss: 0.487055\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016260; batch adversarial loss: 0.489465\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032692; batch adversarial loss: 0.471670\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031404; batch adversarial loss: 0.450373\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025083; batch adversarial loss: 0.498981\n",
      "epoch 157; iter: 0; batch classifier loss: 0.054302; batch adversarial loss: 0.487413\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038045; batch adversarial loss: 0.489150\n",
      "epoch 159; iter: 0; batch classifier loss: 0.047922; batch adversarial loss: 0.473086\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025477; batch adversarial loss: 0.454876\n",
      "epoch 161; iter: 0; batch classifier loss: 0.075880; batch adversarial loss: 0.543626\n",
      "epoch 162; iter: 0; batch classifier loss: 0.072733; batch adversarial loss: 0.616488\n",
      "epoch 163; iter: 0; batch classifier loss: 0.110631; batch adversarial loss: 0.647426\n",
      "epoch 164; iter: 0; batch classifier loss: 0.156461; batch adversarial loss: 0.729872\n",
      "epoch 165; iter: 0; batch classifier loss: 0.116813; batch adversarial loss: 0.561876\n",
      "epoch 166; iter: 0; batch classifier loss: 0.211116; batch adversarial loss: 0.972655\n",
      "epoch 167; iter: 0; batch classifier loss: 0.134011; batch adversarial loss: 0.606236\n",
      "epoch 168; iter: 0; batch classifier loss: 0.091793; batch adversarial loss: 0.563712\n",
      "epoch 169; iter: 0; batch classifier loss: 0.224114; batch adversarial loss: 0.729272\n",
      "epoch 170; iter: 0; batch classifier loss: 0.203318; batch adversarial loss: 0.725067\n",
      "epoch 171; iter: 0; batch classifier loss: 0.136986; batch adversarial loss: 0.662224\n",
      "epoch 172; iter: 0; batch classifier loss: 0.171018; batch adversarial loss: 0.732120\n",
      "epoch 173; iter: 0; batch classifier loss: 0.122723; batch adversarial loss: 0.614190\n",
      "epoch 174; iter: 0; batch classifier loss: 0.251391; batch adversarial loss: 0.692494\n",
      "epoch 175; iter: 0; batch classifier loss: 0.164781; batch adversarial loss: 0.624602\n",
      "epoch 176; iter: 0; batch classifier loss: 0.197210; batch adversarial loss: 0.780106\n",
      "epoch 177; iter: 0; batch classifier loss: 0.205172; batch adversarial loss: 0.750787\n",
      "epoch 178; iter: 0; batch classifier loss: 0.159890; batch adversarial loss: 0.681792\n",
      "epoch 179; iter: 0; batch classifier loss: 0.223066; batch adversarial loss: 0.670524\n",
      "epoch 180; iter: 0; batch classifier loss: 0.144875; batch adversarial loss: 0.605764\n",
      "epoch 181; iter: 0; batch classifier loss: 0.136856; batch adversarial loss: 0.514664\n",
      "epoch 182; iter: 0; batch classifier loss: 0.170864; batch adversarial loss: 0.621381\n",
      "epoch 183; iter: 0; batch classifier loss: 0.204183; batch adversarial loss: 0.700451\n",
      "epoch 184; iter: 0; batch classifier loss: 0.113744; batch adversarial loss: 0.544957\n",
      "epoch 185; iter: 0; batch classifier loss: 0.166891; batch adversarial loss: 0.607610\n",
      "epoch 186; iter: 0; batch classifier loss: 0.261048; batch adversarial loss: 0.735774\n",
      "epoch 187; iter: 0; batch classifier loss: 0.129050; batch adversarial loss: 0.500630\n",
      "epoch 188; iter: 0; batch classifier loss: 0.186986; batch adversarial loss: 0.628055\n",
      "epoch 189; iter: 0; batch classifier loss: 0.171069; batch adversarial loss: 0.664228\n",
      "epoch 190; iter: 0; batch classifier loss: 0.149597; batch adversarial loss: 0.708688\n",
      "epoch 191; iter: 0; batch classifier loss: 0.148132; batch adversarial loss: 0.536998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.195424; batch adversarial loss: 0.597669\n",
      "epoch 193; iter: 0; batch classifier loss: 0.175489; batch adversarial loss: 0.570800\n",
      "epoch 194; iter: 0; batch classifier loss: 0.145409; batch adversarial loss: 0.604646\n",
      "epoch 195; iter: 0; batch classifier loss: 0.090511; batch adversarial loss: 0.401447\n",
      "epoch 196; iter: 0; batch classifier loss: 0.177452; batch adversarial loss: 0.568201\n",
      "epoch 197; iter: 0; batch classifier loss: 0.113024; batch adversarial loss: 0.463084\n",
      "epoch 198; iter: 0; batch classifier loss: 0.154116; batch adversarial loss: 0.525623\n",
      "epoch 199; iter: 0; batch classifier loss: 0.144912; batch adversarial loss: 0.554680\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715298; batch adversarial loss: 0.722638\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489048; batch adversarial loss: 0.681758\n",
      "epoch 2; iter: 0; batch classifier loss: 0.366307; batch adversarial loss: 0.645098\n",
      "epoch 3; iter: 0; batch classifier loss: 0.349230; batch adversarial loss: 0.621117\n",
      "epoch 4; iter: 0; batch classifier loss: 0.415080; batch adversarial loss: 0.550748\n",
      "epoch 5; iter: 0; batch classifier loss: 0.355736; batch adversarial loss: 0.555749\n",
      "epoch 6; iter: 0; batch classifier loss: 0.238739; batch adversarial loss: 0.527865\n",
      "epoch 7; iter: 0; batch classifier loss: 0.301898; batch adversarial loss: 0.534001\n",
      "epoch 8; iter: 0; batch classifier loss: 0.264464; batch adversarial loss: 0.497433\n",
      "epoch 9; iter: 0; batch classifier loss: 0.255902; batch adversarial loss: 0.468714\n",
      "epoch 10; iter: 0; batch classifier loss: 0.201276; batch adversarial loss: 0.487188\n",
      "epoch 11; iter: 0; batch classifier loss: 0.203973; batch adversarial loss: 0.491290\n",
      "epoch 12; iter: 0; batch classifier loss: 0.170155; batch adversarial loss: 0.446491\n",
      "epoch 13; iter: 0; batch classifier loss: 0.198269; batch adversarial loss: 0.475639\n",
      "epoch 14; iter: 0; batch classifier loss: 0.201872; batch adversarial loss: 0.448299\n",
      "epoch 15; iter: 0; batch classifier loss: 0.177985; batch adversarial loss: 0.446633\n",
      "epoch 16; iter: 0; batch classifier loss: 0.141153; batch adversarial loss: 0.421658\n",
      "epoch 17; iter: 0; batch classifier loss: 0.158021; batch adversarial loss: 0.464764\n",
      "epoch 18; iter: 0; batch classifier loss: 0.144186; batch adversarial loss: 0.555917\n",
      "epoch 19; iter: 0; batch classifier loss: 0.162897; batch adversarial loss: 0.494029\n",
      "epoch 20; iter: 0; batch classifier loss: 0.158565; batch adversarial loss: 0.485991\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149251; batch adversarial loss: 0.414782\n",
      "epoch 22; iter: 0; batch classifier loss: 0.154682; batch adversarial loss: 0.479440\n",
      "epoch 23; iter: 0; batch classifier loss: 0.143307; batch adversarial loss: 0.501695\n",
      "epoch 24; iter: 0; batch classifier loss: 0.120410; batch adversarial loss: 0.506390\n",
      "epoch 25; iter: 0; batch classifier loss: 0.182763; batch adversarial loss: 0.545768\n",
      "epoch 26; iter: 0; batch classifier loss: 0.185311; batch adversarial loss: 0.524271\n",
      "epoch 27; iter: 0; batch classifier loss: 0.231044; batch adversarial loss: 0.561037\n",
      "epoch 28; iter: 0; batch classifier loss: 0.191137; batch adversarial loss: 0.465838\n",
      "epoch 29; iter: 0; batch classifier loss: 0.251559; batch adversarial loss: 0.501364\n",
      "epoch 30; iter: 0; batch classifier loss: 0.326686; batch adversarial loss: 0.515333\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438375; batch adversarial loss: 0.364439\n",
      "epoch 32; iter: 0; batch classifier loss: 0.223556; batch adversarial loss: 0.538144\n",
      "epoch 33; iter: 0; batch classifier loss: 0.130334; batch adversarial loss: 0.454644\n",
      "epoch 34; iter: 0; batch classifier loss: 0.080457; batch adversarial loss: 0.438893\n",
      "epoch 35; iter: 0; batch classifier loss: 0.101504; batch adversarial loss: 0.417257\n",
      "epoch 36; iter: 0; batch classifier loss: 0.110199; batch adversarial loss: 0.600879\n",
      "epoch 37; iter: 0; batch classifier loss: 0.078676; batch adversarial loss: 0.544885\n",
      "epoch 38; iter: 0; batch classifier loss: 0.101211; batch adversarial loss: 0.457213\n",
      "epoch 39; iter: 0; batch classifier loss: 0.085569; batch adversarial loss: 0.424398\n",
      "epoch 40; iter: 0; batch classifier loss: 0.063478; batch adversarial loss: 0.549577\n",
      "epoch 41; iter: 0; batch classifier loss: 0.075530; batch adversarial loss: 0.452064\n",
      "epoch 42; iter: 0; batch classifier loss: 0.069055; batch adversarial loss: 0.476705\n",
      "epoch 43; iter: 0; batch classifier loss: 0.065270; batch adversarial loss: 0.444319\n",
      "epoch 44; iter: 0; batch classifier loss: 0.075390; batch adversarial loss: 0.432370\n",
      "epoch 45; iter: 0; batch classifier loss: 0.072934; batch adversarial loss: 0.484645\n",
      "epoch 46; iter: 0; batch classifier loss: 0.080672; batch adversarial loss: 0.481856\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096741; batch adversarial loss: 0.421505\n",
      "epoch 48; iter: 0; batch classifier loss: 0.061911; batch adversarial loss: 0.464470\n",
      "epoch 49; iter: 0; batch classifier loss: 0.079719; batch adversarial loss: 0.506159\n",
      "epoch 50; iter: 0; batch classifier loss: 0.082985; batch adversarial loss: 0.498097\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070683; batch adversarial loss: 0.473022\n",
      "epoch 52; iter: 0; batch classifier loss: 0.063495; batch adversarial loss: 0.461302\n",
      "epoch 53; iter: 0; batch classifier loss: 0.093625; batch adversarial loss: 0.461764\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099088; batch adversarial loss: 0.423474\n",
      "epoch 55; iter: 0; batch classifier loss: 0.081582; batch adversarial loss: 0.415488\n",
      "epoch 56; iter: 0; batch classifier loss: 0.074960; batch adversarial loss: 0.378027\n",
      "epoch 57; iter: 0; batch classifier loss: 0.069660; batch adversarial loss: 0.361126\n",
      "epoch 58; iter: 0; batch classifier loss: 0.122315; batch adversarial loss: 0.557026\n",
      "epoch 59; iter: 0; batch classifier loss: 0.069392; batch adversarial loss: 0.459768\n",
      "epoch 60; iter: 0; batch classifier loss: 0.121532; batch adversarial loss: 0.454833\n",
      "epoch 61; iter: 0; batch classifier loss: 0.052459; batch adversarial loss: 0.536183\n",
      "epoch 62; iter: 0; batch classifier loss: 0.058115; batch adversarial loss: 0.497238\n",
      "epoch 63; iter: 0; batch classifier loss: 0.042744; batch adversarial loss: 0.471470\n",
      "epoch 64; iter: 0; batch classifier loss: 0.056866; batch adversarial loss: 0.533279\n",
      "epoch 65; iter: 0; batch classifier loss: 0.049825; batch adversarial loss: 0.454841\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092702; batch adversarial loss: 0.468574\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061686; batch adversarial loss: 0.441000\n",
      "epoch 68; iter: 0; batch classifier loss: 0.045282; batch adversarial loss: 0.555416\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064518; batch adversarial loss: 0.430300\n",
      "epoch 70; iter: 0; batch classifier loss: 0.054273; batch adversarial loss: 0.468847\n",
      "epoch 71; iter: 0; batch classifier loss: 0.060933; batch adversarial loss: 0.429662\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080548; batch adversarial loss: 0.447101\n",
      "epoch 73; iter: 0; batch classifier loss: 0.061158; batch adversarial loss: 0.463690\n",
      "epoch 74; iter: 0; batch classifier loss: 0.057782; batch adversarial loss: 0.481363\n",
      "epoch 75; iter: 0; batch classifier loss: 0.053318; batch adversarial loss: 0.469935\n",
      "epoch 76; iter: 0; batch classifier loss: 0.052234; batch adversarial loss: 0.455457\n",
      "epoch 77; iter: 0; batch classifier loss: 0.049965; batch adversarial loss: 0.412718\n",
      "epoch 78; iter: 0; batch classifier loss: 0.039472; batch adversarial loss: 0.453973\n",
      "epoch 79; iter: 0; batch classifier loss: 0.033622; batch adversarial loss: 0.584813\n",
      "epoch 80; iter: 0; batch classifier loss: 0.051561; batch adversarial loss: 0.455138\n",
      "epoch 81; iter: 0; batch classifier loss: 0.041725; batch adversarial loss: 0.415250\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059808; batch adversarial loss: 0.505170\n",
      "epoch 83; iter: 0; batch classifier loss: 0.087656; batch adversarial loss: 0.411921\n",
      "epoch 84; iter: 0; batch classifier loss: 0.028854; batch adversarial loss: 0.481530\n",
      "epoch 85; iter: 0; batch classifier loss: 0.038727; batch adversarial loss: 0.496344\n",
      "epoch 86; iter: 0; batch classifier loss: 0.094599; batch adversarial loss: 0.450771\n",
      "epoch 87; iter: 0; batch classifier loss: 0.063752; batch adversarial loss: 0.386406\n",
      "epoch 88; iter: 0; batch classifier loss: 0.060562; batch adversarial loss: 0.496350\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066295; batch adversarial loss: 0.466840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.076025; batch adversarial loss: 0.555812\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063141; batch adversarial loss: 0.501896\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044439; batch adversarial loss: 0.533956\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046932; batch adversarial loss: 0.417953\n",
      "epoch 94; iter: 0; batch classifier loss: 0.059584; batch adversarial loss: 0.557485\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038208; batch adversarial loss: 0.470958\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041485; batch adversarial loss: 0.495659\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065227; batch adversarial loss: 0.386002\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042426; batch adversarial loss: 0.520969\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042496; batch adversarial loss: 0.463639\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056483; batch adversarial loss: 0.419991\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055582; batch adversarial loss: 0.377560\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036052; batch adversarial loss: 0.529623\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035848; batch adversarial loss: 0.452022\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083376; batch adversarial loss: 0.383958\n",
      "epoch 105; iter: 0; batch classifier loss: 0.025314; batch adversarial loss: 0.564172\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051762; batch adversarial loss: 0.485222\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041075; batch adversarial loss: 0.530917\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054477; batch adversarial loss: 0.484735\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061396; batch adversarial loss: 0.490309\n",
      "epoch 110; iter: 0; batch classifier loss: 0.021182; batch adversarial loss: 0.443590\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051876; batch adversarial loss: 0.438556\n",
      "epoch 112; iter: 0; batch classifier loss: 0.023069; batch adversarial loss: 0.497289\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035318; batch adversarial loss: 0.429377\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028758; batch adversarial loss: 0.450483\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032162; batch adversarial loss: 0.447532\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042201; batch adversarial loss: 0.435113\n",
      "epoch 117; iter: 0; batch classifier loss: 0.015729; batch adversarial loss: 0.484787\n",
      "epoch 118; iter: 0; batch classifier loss: 0.015527; batch adversarial loss: 0.425310\n",
      "epoch 119; iter: 0; batch classifier loss: 0.082463; batch adversarial loss: 0.431600\n",
      "epoch 120; iter: 0; batch classifier loss: 0.017444; batch adversarial loss: 0.415901\n",
      "epoch 121; iter: 0; batch classifier loss: 0.016747; batch adversarial loss: 0.509618\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028257; batch adversarial loss: 0.483087\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028569; batch adversarial loss: 0.595742\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042593; batch adversarial loss: 0.454059\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025048; batch adversarial loss: 0.569087\n",
      "epoch 126; iter: 0; batch classifier loss: 0.013017; batch adversarial loss: 0.506643\n",
      "epoch 127; iter: 0; batch classifier loss: 0.038330; batch adversarial loss: 0.500021\n",
      "epoch 128; iter: 0; batch classifier loss: 0.013468; batch adversarial loss: 0.506739\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019006; batch adversarial loss: 0.412063\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028697; batch adversarial loss: 0.489879\n",
      "epoch 131; iter: 0; batch classifier loss: 0.009720; batch adversarial loss: 0.522391\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022221; batch adversarial loss: 0.417181\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022267; batch adversarial loss: 0.478112\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028301; batch adversarial loss: 0.507227\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017217; batch adversarial loss: 0.539906\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020399; batch adversarial loss: 0.459657\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015832; batch adversarial loss: 0.540894\n",
      "epoch 138; iter: 0; batch classifier loss: 0.042009; batch adversarial loss: 0.521679\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014706; batch adversarial loss: 0.400171\n",
      "epoch 140; iter: 0; batch classifier loss: 0.012511; batch adversarial loss: 0.485116\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017197; batch adversarial loss: 0.479427\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023816; batch adversarial loss: 0.465487\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037250; batch adversarial loss: 0.441785\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025718; batch adversarial loss: 0.392175\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015387; batch adversarial loss: 0.570736\n",
      "epoch 146; iter: 0; batch classifier loss: 0.014260; batch adversarial loss: 0.393329\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019940; batch adversarial loss: 0.507039\n",
      "epoch 148; iter: 0; batch classifier loss: 0.006154; batch adversarial loss: 0.454912\n",
      "epoch 149; iter: 0; batch classifier loss: 0.010168; batch adversarial loss: 0.440213\n",
      "epoch 150; iter: 0; batch classifier loss: 0.048401; batch adversarial loss: 0.424395\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023199; batch adversarial loss: 0.506210\n",
      "epoch 152; iter: 0; batch classifier loss: 0.055977; batch adversarial loss: 0.442949\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023799; batch adversarial loss: 0.473018\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016021; batch adversarial loss: 0.486329\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033659; batch adversarial loss: 0.450002\n",
      "epoch 156; iter: 0; batch classifier loss: 0.006620; batch adversarial loss: 0.507372\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025594; batch adversarial loss: 0.476418\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027381; batch adversarial loss: 0.463462\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034472; batch adversarial loss: 0.472514\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033054; batch adversarial loss: 0.665636\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015142; batch adversarial loss: 0.464756\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030795; batch adversarial loss: 0.414683\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030389; batch adversarial loss: 0.465979\n",
      "epoch 164; iter: 0; batch classifier loss: 0.040385; batch adversarial loss: 0.581153\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012621; batch adversarial loss: 0.440231\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026378; batch adversarial loss: 0.623032\n",
      "epoch 167; iter: 0; batch classifier loss: 0.038070; batch adversarial loss: 0.343230\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024912; batch adversarial loss: 0.380975\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008698; batch adversarial loss: 0.529753\n",
      "epoch 170; iter: 0; batch classifier loss: 0.003397; batch adversarial loss: 0.519648\n",
      "epoch 171; iter: 0; batch classifier loss: 0.094272; batch adversarial loss: 0.437100\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017116; batch adversarial loss: 0.525110\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019093; batch adversarial loss: 0.599098\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013199; batch adversarial loss: 0.542633\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008300; batch adversarial loss: 0.470538\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023617; batch adversarial loss: 0.493754\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010848; batch adversarial loss: 0.496367\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007363; batch adversarial loss: 0.445595\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016004; batch adversarial loss: 0.400746\n",
      "epoch 180; iter: 0; batch classifier loss: 0.005118; batch adversarial loss: 0.581632\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018523; batch adversarial loss: 0.460000\n",
      "epoch 182; iter: 0; batch classifier loss: 0.048557; batch adversarial loss: 0.450687\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019513; batch adversarial loss: 0.538536\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014350; batch adversarial loss: 0.475300\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019490; batch adversarial loss: 0.460351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.021034; batch adversarial loss: 0.554721\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018753; batch adversarial loss: 0.425711\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007963; batch adversarial loss: 0.515370\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041308; batch adversarial loss: 0.535394\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004266; batch adversarial loss: 0.421147\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034445; batch adversarial loss: 0.407292\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014650; batch adversarial loss: 0.477937\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009508; batch adversarial loss: 0.491100\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041018; batch adversarial loss: 0.407280\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027581; batch adversarial loss: 0.459481\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011654; batch adversarial loss: 0.400671\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018744; batch adversarial loss: 0.466503\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010453; batch adversarial loss: 0.473207\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025909; batch adversarial loss: 0.479462\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686733; batch adversarial loss: 0.655378\n",
      "epoch 1; iter: 0; batch classifier loss: 0.522142; batch adversarial loss: 0.659369\n",
      "epoch 2; iter: 0; batch classifier loss: 0.423133; batch adversarial loss: 0.586730\n",
      "epoch 3; iter: 0; batch classifier loss: 0.378461; batch adversarial loss: 0.550845\n",
      "epoch 4; iter: 0; batch classifier loss: 0.398444; batch adversarial loss: 0.556720\n",
      "epoch 5; iter: 0; batch classifier loss: 0.341807; batch adversarial loss: 0.551895\n",
      "epoch 6; iter: 0; batch classifier loss: 0.334403; batch adversarial loss: 0.622560\n",
      "epoch 7; iter: 0; batch classifier loss: 0.247050; batch adversarial loss: 0.546842\n",
      "epoch 8; iter: 0; batch classifier loss: 0.243108; batch adversarial loss: 0.557806\n",
      "epoch 9; iter: 0; batch classifier loss: 0.317184; batch adversarial loss: 0.441388\n",
      "epoch 10; iter: 0; batch classifier loss: 0.283124; batch adversarial loss: 0.530186\n",
      "epoch 11; iter: 0; batch classifier loss: 0.240522; batch adversarial loss: 0.473873\n",
      "epoch 12; iter: 0; batch classifier loss: 0.164386; batch adversarial loss: 0.449836\n",
      "epoch 13; iter: 0; batch classifier loss: 0.209272; batch adversarial loss: 0.439629\n",
      "epoch 14; iter: 0; batch classifier loss: 0.215437; batch adversarial loss: 0.473005\n",
      "epoch 15; iter: 0; batch classifier loss: 0.250800; batch adversarial loss: 0.474119\n",
      "epoch 16; iter: 0; batch classifier loss: 0.205670; batch adversarial loss: 0.505382\n",
      "epoch 17; iter: 0; batch classifier loss: 0.219066; batch adversarial loss: 0.442728\n",
      "epoch 18; iter: 0; batch classifier loss: 0.184516; batch adversarial loss: 0.450766\n",
      "epoch 19; iter: 0; batch classifier loss: 0.175897; batch adversarial loss: 0.463676\n",
      "epoch 20; iter: 0; batch classifier loss: 0.126944; batch adversarial loss: 0.460013\n",
      "epoch 21; iter: 0; batch classifier loss: 0.175064; batch adversarial loss: 0.511512\n",
      "epoch 22; iter: 0; batch classifier loss: 0.256482; batch adversarial loss: 0.419415\n",
      "epoch 23; iter: 0; batch classifier loss: 0.156094; batch adversarial loss: 0.485334\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159559; batch adversarial loss: 0.443885\n",
      "epoch 25; iter: 0; batch classifier loss: 0.141032; batch adversarial loss: 0.528752\n",
      "epoch 26; iter: 0; batch classifier loss: 0.145775; batch adversarial loss: 0.538199\n",
      "epoch 27; iter: 0; batch classifier loss: 0.122188; batch adversarial loss: 0.498769\n",
      "epoch 28; iter: 0; batch classifier loss: 0.140277; batch adversarial loss: 0.444987\n",
      "epoch 29; iter: 0; batch classifier loss: 0.153196; batch adversarial loss: 0.406507\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153023; batch adversarial loss: 0.497978\n",
      "epoch 31; iter: 0; batch classifier loss: 0.202934; batch adversarial loss: 0.388837\n",
      "epoch 32; iter: 0; batch classifier loss: 0.137641; batch adversarial loss: 0.542055\n",
      "epoch 33; iter: 0; batch classifier loss: 0.084861; batch adversarial loss: 0.501602\n",
      "epoch 34; iter: 0; batch classifier loss: 0.086273; batch adversarial loss: 0.470024\n",
      "epoch 35; iter: 0; batch classifier loss: 0.146532; batch adversarial loss: 0.440234\n",
      "epoch 36; iter: 0; batch classifier loss: 0.138125; batch adversarial loss: 0.415005\n",
      "epoch 37; iter: 0; batch classifier loss: 0.134308; batch adversarial loss: 0.505799\n",
      "epoch 38; iter: 0; batch classifier loss: 0.145950; batch adversarial loss: 0.347960\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106982; batch adversarial loss: 0.436616\n",
      "epoch 40; iter: 0; batch classifier loss: 0.133877; batch adversarial loss: 0.410747\n",
      "epoch 41; iter: 0; batch classifier loss: 0.077262; batch adversarial loss: 0.422010\n",
      "epoch 42; iter: 0; batch classifier loss: 0.152342; batch adversarial loss: 0.382385\n",
      "epoch 43; iter: 0; batch classifier loss: 0.154468; batch adversarial loss: 0.413151\n",
      "epoch 44; iter: 0; batch classifier loss: 0.141628; batch adversarial loss: 0.447550\n",
      "epoch 45; iter: 0; batch classifier loss: 0.159761; batch adversarial loss: 0.420580\n",
      "epoch 46; iter: 0; batch classifier loss: 0.174783; batch adversarial loss: 0.434522\n",
      "epoch 47; iter: 0; batch classifier loss: 0.138196; batch adversarial loss: 0.369528\n",
      "epoch 48; iter: 0; batch classifier loss: 0.136433; batch adversarial loss: 0.379841\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129197; batch adversarial loss: 0.445977\n",
      "epoch 50; iter: 0; batch classifier loss: 0.128730; batch adversarial loss: 0.518788\n",
      "epoch 51; iter: 0; batch classifier loss: 0.155288; batch adversarial loss: 0.407242\n",
      "epoch 52; iter: 0; batch classifier loss: 0.149952; batch adversarial loss: 0.505913\n",
      "epoch 53; iter: 0; batch classifier loss: 0.169136; batch adversarial loss: 0.411453\n",
      "epoch 54; iter: 0; batch classifier loss: 0.125484; batch adversarial loss: 0.462995\n",
      "epoch 55; iter: 0; batch classifier loss: 0.145197; batch adversarial loss: 0.426423\n",
      "epoch 56; iter: 0; batch classifier loss: 0.137628; batch adversarial loss: 0.543172\n",
      "epoch 57; iter: 0; batch classifier loss: 0.109607; batch adversarial loss: 0.510599\n",
      "epoch 58; iter: 0; batch classifier loss: 0.159405; batch adversarial loss: 0.443704\n",
      "epoch 59; iter: 0; batch classifier loss: 0.129508; batch adversarial loss: 0.581795\n",
      "epoch 60; iter: 0; batch classifier loss: 0.166810; batch adversarial loss: 0.473416\n",
      "epoch 61; iter: 0; batch classifier loss: 0.153457; batch adversarial loss: 0.476296\n",
      "epoch 62; iter: 0; batch classifier loss: 0.151815; batch adversarial loss: 0.461278\n",
      "epoch 63; iter: 0; batch classifier loss: 0.136153; batch adversarial loss: 0.400410\n",
      "epoch 64; iter: 0; batch classifier loss: 0.176281; batch adversarial loss: 0.499632\n",
      "epoch 65; iter: 0; batch classifier loss: 0.150388; batch adversarial loss: 0.497956\n",
      "epoch 66; iter: 0; batch classifier loss: 0.110728; batch adversarial loss: 0.404596\n",
      "epoch 67; iter: 0; batch classifier loss: 0.217250; batch adversarial loss: 0.355044\n",
      "epoch 68; iter: 0; batch classifier loss: 0.147201; batch adversarial loss: 0.479484\n",
      "epoch 69; iter: 0; batch classifier loss: 0.166019; batch adversarial loss: 0.496572\n",
      "epoch 70; iter: 0; batch classifier loss: 0.139148; batch adversarial loss: 0.507587\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115190; batch adversarial loss: 0.466027\n",
      "epoch 72; iter: 0; batch classifier loss: 0.183319; batch adversarial loss: 0.396131\n",
      "epoch 73; iter: 0; batch classifier loss: 0.127536; batch adversarial loss: 0.577672\n",
      "epoch 74; iter: 0; batch classifier loss: 0.129804; batch adversarial loss: 0.442576\n",
      "epoch 75; iter: 0; batch classifier loss: 0.120478; batch adversarial loss: 0.439513\n",
      "epoch 76; iter: 0; batch classifier loss: 0.161790; batch adversarial loss: 0.347231\n",
      "epoch 77; iter: 0; batch classifier loss: 0.148749; batch adversarial loss: 0.396825\n",
      "epoch 78; iter: 0; batch classifier loss: 0.131327; batch adversarial loss: 0.501744\n",
      "epoch 79; iter: 0; batch classifier loss: 0.090474; batch adversarial loss: 0.462282\n",
      "epoch 80; iter: 0; batch classifier loss: 0.148662; batch adversarial loss: 0.440229\n",
      "epoch 81; iter: 0; batch classifier loss: 0.169199; batch adversarial loss: 0.456717\n",
      "epoch 82; iter: 0; batch classifier loss: 0.150544; batch adversarial loss: 0.495296\n",
      "epoch 83; iter: 0; batch classifier loss: 0.130243; batch adversarial loss: 0.424738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.095064; batch adversarial loss: 0.415749\n",
      "epoch 85; iter: 0; batch classifier loss: 0.211665; batch adversarial loss: 0.449878\n",
      "epoch 86; iter: 0; batch classifier loss: 0.134539; batch adversarial loss: 0.557670\n",
      "epoch 87; iter: 0; batch classifier loss: 0.100554; batch adversarial loss: 0.393529\n",
      "epoch 88; iter: 0; batch classifier loss: 0.144902; batch adversarial loss: 0.529147\n",
      "epoch 89; iter: 0; batch classifier loss: 0.173615; batch adversarial loss: 0.457633\n",
      "epoch 90; iter: 0; batch classifier loss: 0.115094; batch adversarial loss: 0.536407\n",
      "epoch 91; iter: 0; batch classifier loss: 0.103356; batch adversarial loss: 0.555170\n",
      "epoch 92; iter: 0; batch classifier loss: 0.157814; batch adversarial loss: 0.478356\n",
      "epoch 93; iter: 0; batch classifier loss: 0.109994; batch adversarial loss: 0.430975\n",
      "epoch 94; iter: 0; batch classifier loss: 0.091573; batch adversarial loss: 0.455301\n",
      "epoch 95; iter: 0; batch classifier loss: 0.145162; batch adversarial loss: 0.416377\n",
      "epoch 96; iter: 0; batch classifier loss: 0.116139; batch adversarial loss: 0.432600\n",
      "epoch 97; iter: 0; batch classifier loss: 0.158829; batch adversarial loss: 0.467233\n",
      "epoch 98; iter: 0; batch classifier loss: 0.105799; batch adversarial loss: 0.426050\n",
      "epoch 99; iter: 0; batch classifier loss: 0.096277; batch adversarial loss: 0.410086\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064915; batch adversarial loss: 0.533354\n",
      "epoch 101; iter: 0; batch classifier loss: 0.140015; batch adversarial loss: 0.456067\n",
      "epoch 102; iter: 0; batch classifier loss: 0.073658; batch adversarial loss: 0.526967\n",
      "epoch 103; iter: 0; batch classifier loss: 0.068845; batch adversarial loss: 0.425949\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053180; batch adversarial loss: 0.471777\n",
      "epoch 105; iter: 0; batch classifier loss: 0.082224; batch adversarial loss: 0.495034\n",
      "epoch 106; iter: 0; batch classifier loss: 0.075482; batch adversarial loss: 0.517621\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072557; batch adversarial loss: 0.514519\n",
      "epoch 108; iter: 0; batch classifier loss: 0.085209; batch adversarial loss: 0.424468\n",
      "epoch 109; iter: 0; batch classifier loss: 0.052167; batch adversarial loss: 0.479298\n",
      "epoch 110; iter: 0; batch classifier loss: 0.121604; batch adversarial loss: 0.473981\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062284; batch adversarial loss: 0.487777\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053556; batch adversarial loss: 0.476360\n",
      "epoch 113; iter: 0; batch classifier loss: 0.101131; batch adversarial loss: 0.445958\n",
      "epoch 114; iter: 0; batch classifier loss: 0.083741; batch adversarial loss: 0.494234\n",
      "epoch 115; iter: 0; batch classifier loss: 0.075929; batch adversarial loss: 0.480438\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056534; batch adversarial loss: 0.422253\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037880; batch adversarial loss: 0.447991\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030617; batch adversarial loss: 0.481932\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055490; batch adversarial loss: 0.462473\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046051; batch adversarial loss: 0.473323\n",
      "epoch 121; iter: 0; batch classifier loss: 0.016578; batch adversarial loss: 0.444971\n",
      "epoch 122; iter: 0; batch classifier loss: 0.065158; batch adversarial loss: 0.415573\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048783; batch adversarial loss: 0.351529\n",
      "epoch 124; iter: 0; batch classifier loss: 0.060599; batch adversarial loss: 0.506979\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030808; batch adversarial loss: 0.409387\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055880; batch adversarial loss: 0.521262\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021958; batch adversarial loss: 0.452456\n",
      "epoch 128; iter: 0; batch classifier loss: 0.072102; batch adversarial loss: 0.414197\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042069; batch adversarial loss: 0.387214\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039197; batch adversarial loss: 0.480553\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026305; batch adversarial loss: 0.487186\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044508; batch adversarial loss: 0.481027\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042622; batch adversarial loss: 0.454829\n",
      "epoch 134; iter: 0; batch classifier loss: 0.059196; batch adversarial loss: 0.407668\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028075; batch adversarial loss: 0.435661\n",
      "epoch 136; iter: 0; batch classifier loss: 0.053514; batch adversarial loss: 0.484019\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028230; batch adversarial loss: 0.440557\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040210; batch adversarial loss: 0.531248\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042625; batch adversarial loss: 0.507410\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032183; batch adversarial loss: 0.499891\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045252; batch adversarial loss: 0.482711\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043899; batch adversarial loss: 0.488934\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015615; batch adversarial loss: 0.406169\n",
      "epoch 144; iter: 0; batch classifier loss: 0.015884; batch adversarial loss: 0.498639\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039178; batch adversarial loss: 0.362963\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045953; batch adversarial loss: 0.479305\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043934; batch adversarial loss: 0.452722\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019334; batch adversarial loss: 0.483768\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022354; batch adversarial loss: 0.453591\n",
      "epoch 150; iter: 0; batch classifier loss: 0.048009; batch adversarial loss: 0.519049\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038398; batch adversarial loss: 0.391961\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018167; batch adversarial loss: 0.460144\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013627; batch adversarial loss: 0.455791\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037700; batch adversarial loss: 0.441382\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018837; batch adversarial loss: 0.462443\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019641; batch adversarial loss: 0.321697\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015686; batch adversarial loss: 0.494390\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032801; batch adversarial loss: 0.460250\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010811; batch adversarial loss: 0.409714\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029425; batch adversarial loss: 0.417273\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021663; batch adversarial loss: 0.423896\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011686; batch adversarial loss: 0.393779\n",
      "epoch 163; iter: 0; batch classifier loss: 0.047509; batch adversarial loss: 0.464802\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024664; batch adversarial loss: 0.508326\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031739; batch adversarial loss: 0.520704\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021395; batch adversarial loss: 0.334011\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015314; batch adversarial loss: 0.457044\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019717; batch adversarial loss: 0.481442\n",
      "epoch 169; iter: 0; batch classifier loss: 0.039893; batch adversarial loss: 0.480534\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014815; batch adversarial loss: 0.512772\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023573; batch adversarial loss: 0.431812\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019307; batch adversarial loss: 0.501424\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032945; batch adversarial loss: 0.456142\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038624; batch adversarial loss: 0.477592\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013021; batch adversarial loss: 0.453370\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009006; batch adversarial loss: 0.478467\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015508; batch adversarial loss: 0.499083\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039491; batch adversarial loss: 0.401963\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023273; batch adversarial loss: 0.514055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.023393; batch adversarial loss: 0.467172\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037599; batch adversarial loss: 0.425034\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010465; batch adversarial loss: 0.450292\n",
      "epoch 183; iter: 0; batch classifier loss: 0.048294; batch adversarial loss: 0.417287\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016639; batch adversarial loss: 0.443751\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011476; batch adversarial loss: 0.474677\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019737; batch adversarial loss: 0.452445\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010633; batch adversarial loss: 0.516224\n",
      "epoch 188; iter: 0; batch classifier loss: 0.037689; batch adversarial loss: 0.441949\n",
      "epoch 189; iter: 0; batch classifier loss: 0.038596; batch adversarial loss: 0.432938\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037896; batch adversarial loss: 0.511397\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028030; batch adversarial loss: 0.377731\n",
      "epoch 192; iter: 0; batch classifier loss: 0.038039; batch adversarial loss: 0.438135\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025802; batch adversarial loss: 0.521307\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006297; batch adversarial loss: 0.454098\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017452; batch adversarial loss: 0.464811\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021528; batch adversarial loss: 0.393209\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029057; batch adversarial loss: 0.464010\n",
      "epoch 198; iter: 0; batch classifier loss: 0.054744; batch adversarial loss: 0.454268\n",
      "epoch 199; iter: 0; batch classifier loss: 0.047429; batch adversarial loss: 0.386995\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674791; batch adversarial loss: 0.798046\n",
      "epoch 1; iter: 0; batch classifier loss: 0.445006; batch adversarial loss: 0.757223\n",
      "epoch 2; iter: 0; batch classifier loss: 0.352884; batch adversarial loss: 0.767898\n",
      "epoch 3; iter: 0; batch classifier loss: 0.346373; batch adversarial loss: 0.719094\n",
      "epoch 4; iter: 0; batch classifier loss: 0.386956; batch adversarial loss: 0.656788\n",
      "epoch 5; iter: 0; batch classifier loss: 0.361571; batch adversarial loss: 0.628002\n",
      "epoch 6; iter: 0; batch classifier loss: 0.351344; batch adversarial loss: 0.594568\n",
      "epoch 7; iter: 0; batch classifier loss: 0.302737; batch adversarial loss: 0.568982\n",
      "epoch 8; iter: 0; batch classifier loss: 0.288905; batch adversarial loss: 0.553107\n",
      "epoch 9; iter: 0; batch classifier loss: 0.329839; batch adversarial loss: 0.527536\n",
      "epoch 10; iter: 0; batch classifier loss: 0.306165; batch adversarial loss: 0.508256\n",
      "epoch 11; iter: 0; batch classifier loss: 0.205496; batch adversarial loss: 0.456736\n",
      "epoch 12; iter: 0; batch classifier loss: 0.233738; batch adversarial loss: 0.465965\n",
      "epoch 13; iter: 0; batch classifier loss: 0.290337; batch adversarial loss: 0.561398\n",
      "epoch 14; iter: 0; batch classifier loss: 0.247764; batch adversarial loss: 0.450989\n",
      "epoch 15; iter: 0; batch classifier loss: 0.190734; batch adversarial loss: 0.459412\n",
      "epoch 16; iter: 0; batch classifier loss: 0.196295; batch adversarial loss: 0.415732\n",
      "epoch 17; iter: 0; batch classifier loss: 0.204608; batch adversarial loss: 0.422450\n",
      "epoch 18; iter: 0; batch classifier loss: 0.179722; batch adversarial loss: 0.485512\n",
      "epoch 19; iter: 0; batch classifier loss: 0.220629; batch adversarial loss: 0.442129\n",
      "epoch 20; iter: 0; batch classifier loss: 0.173456; batch adversarial loss: 0.440388\n",
      "epoch 21; iter: 0; batch classifier loss: 0.147656; batch adversarial loss: 0.406110\n",
      "epoch 22; iter: 0; batch classifier loss: 0.158310; batch adversarial loss: 0.389895\n",
      "epoch 23; iter: 0; batch classifier loss: 0.139407; batch adversarial loss: 0.431593\n",
      "epoch 24; iter: 0; batch classifier loss: 0.169803; batch adversarial loss: 0.444024\n",
      "epoch 25; iter: 0; batch classifier loss: 0.115661; batch adversarial loss: 0.429744\n",
      "epoch 26; iter: 0; batch classifier loss: 0.205327; batch adversarial loss: 0.385399\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154670; batch adversarial loss: 0.321635\n",
      "epoch 28; iter: 0; batch classifier loss: 0.181252; batch adversarial loss: 0.433330\n",
      "epoch 29; iter: 0; batch classifier loss: 0.101642; batch adversarial loss: 0.425420\n",
      "epoch 30; iter: 0; batch classifier loss: 0.113451; batch adversarial loss: 0.443451\n",
      "epoch 31; iter: 0; batch classifier loss: 0.127461; batch adversarial loss: 0.422670\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146029; batch adversarial loss: 0.489795\n",
      "epoch 33; iter: 0; batch classifier loss: 0.149873; batch adversarial loss: 0.413900\n",
      "epoch 34; iter: 0; batch classifier loss: 0.140197; batch adversarial loss: 0.443667\n",
      "epoch 35; iter: 0; batch classifier loss: 0.133903; batch adversarial loss: 0.450014\n",
      "epoch 36; iter: 0; batch classifier loss: 0.162237; batch adversarial loss: 0.423812\n",
      "epoch 37; iter: 0; batch classifier loss: 0.127117; batch adversarial loss: 0.364952\n",
      "epoch 38; iter: 0; batch classifier loss: 0.161590; batch adversarial loss: 0.331903\n",
      "epoch 39; iter: 0; batch classifier loss: 0.079966; batch adversarial loss: 0.420672\n",
      "epoch 40; iter: 0; batch classifier loss: 0.139697; batch adversarial loss: 0.461260\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142021; batch adversarial loss: 0.367398\n",
      "epoch 42; iter: 0; batch classifier loss: 0.136499; batch adversarial loss: 0.429208\n",
      "epoch 43; iter: 0; batch classifier loss: 0.128514; batch adversarial loss: 0.400293\n",
      "epoch 44; iter: 0; batch classifier loss: 0.092518; batch adversarial loss: 0.451663\n",
      "epoch 45; iter: 0; batch classifier loss: 0.069375; batch adversarial loss: 0.376599\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114217; batch adversarial loss: 0.388009\n",
      "epoch 47; iter: 0; batch classifier loss: 0.118294; batch adversarial loss: 0.404772\n",
      "epoch 48; iter: 0; batch classifier loss: 0.133744; batch adversarial loss: 0.368470\n",
      "epoch 49; iter: 0; batch classifier loss: 0.087998; batch adversarial loss: 0.416791\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094656; batch adversarial loss: 0.405401\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081439; batch adversarial loss: 0.365603\n",
      "epoch 52; iter: 0; batch classifier loss: 0.095907; batch adversarial loss: 0.466996\n",
      "epoch 53; iter: 0; batch classifier loss: 0.092015; batch adversarial loss: 0.438384\n",
      "epoch 54; iter: 0; batch classifier loss: 0.119301; batch adversarial loss: 0.454011\n",
      "epoch 55; iter: 0; batch classifier loss: 0.075324; batch adversarial loss: 0.461069\n",
      "epoch 56; iter: 0; batch classifier loss: 0.093752; batch adversarial loss: 0.345983\n",
      "epoch 57; iter: 0; batch classifier loss: 0.098202; batch adversarial loss: 0.497372\n",
      "epoch 58; iter: 0; batch classifier loss: 0.074397; batch adversarial loss: 0.480359\n",
      "epoch 59; iter: 0; batch classifier loss: 0.111783; batch adversarial loss: 0.417374\n",
      "epoch 60; iter: 0; batch classifier loss: 0.058373; batch adversarial loss: 0.415351\n",
      "epoch 61; iter: 0; batch classifier loss: 0.064194; batch adversarial loss: 0.436109\n",
      "epoch 62; iter: 0; batch classifier loss: 0.063401; batch adversarial loss: 0.414749\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098885; batch adversarial loss: 0.467179\n",
      "epoch 64; iter: 0; batch classifier loss: 0.077465; batch adversarial loss: 0.470914\n",
      "epoch 65; iter: 0; batch classifier loss: 0.093246; batch adversarial loss: 0.390999\n",
      "epoch 66; iter: 0; batch classifier loss: 0.110300; batch adversarial loss: 0.538364\n",
      "epoch 67; iter: 0; batch classifier loss: 0.084272; batch adversarial loss: 0.428305\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060903; batch adversarial loss: 0.310577\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065612; batch adversarial loss: 0.463595\n",
      "epoch 70; iter: 0; batch classifier loss: 0.087587; batch adversarial loss: 0.449289\n",
      "epoch 71; iter: 0; batch classifier loss: 0.046609; batch adversarial loss: 0.432815\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071689; batch adversarial loss: 0.383143\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090976; batch adversarial loss: 0.406102\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073231; batch adversarial loss: 0.425154\n",
      "epoch 75; iter: 0; batch classifier loss: 0.053367; batch adversarial loss: 0.336904\n",
      "epoch 76; iter: 0; batch classifier loss: 0.048143; batch adversarial loss: 0.464800\n",
      "epoch 77; iter: 0; batch classifier loss: 0.042946; batch adversarial loss: 0.424173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.050133; batch adversarial loss: 0.466722\n",
      "epoch 79; iter: 0; batch classifier loss: 0.048187; batch adversarial loss: 0.387539\n",
      "epoch 80; iter: 0; batch classifier loss: 0.044466; batch adversarial loss: 0.369103\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066992; batch adversarial loss: 0.329110\n",
      "epoch 82; iter: 0; batch classifier loss: 0.043575; batch adversarial loss: 0.526899\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061512; batch adversarial loss: 0.364628\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045384; batch adversarial loss: 0.415821\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050555; batch adversarial loss: 0.403981\n",
      "epoch 86; iter: 0; batch classifier loss: 0.033166; batch adversarial loss: 0.446234\n",
      "epoch 87; iter: 0; batch classifier loss: 0.033313; batch adversarial loss: 0.424957\n",
      "epoch 88; iter: 0; batch classifier loss: 0.066228; batch adversarial loss: 0.465840\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048259; batch adversarial loss: 0.387402\n",
      "epoch 90; iter: 0; batch classifier loss: 0.023688; batch adversarial loss: 0.441339\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048054; batch adversarial loss: 0.491999\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044473; batch adversarial loss: 0.435221\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053262; batch adversarial loss: 0.494217\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036681; batch adversarial loss: 0.437497\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039267; batch adversarial loss: 0.399849\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041097; batch adversarial loss: 0.467293\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056128; batch adversarial loss: 0.488125\n",
      "epoch 98; iter: 0; batch classifier loss: 0.034310; batch adversarial loss: 0.403183\n",
      "epoch 99; iter: 0; batch classifier loss: 0.027090; batch adversarial loss: 0.423192\n",
      "epoch 100; iter: 0; batch classifier loss: 0.022647; batch adversarial loss: 0.459399\n",
      "epoch 101; iter: 0; batch classifier loss: 0.033617; batch adversarial loss: 0.497378\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055541; batch adversarial loss: 0.481630\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033395; batch adversarial loss: 0.504047\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044762; batch adversarial loss: 0.519070\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064255; batch adversarial loss: 0.623828\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061685; batch adversarial loss: 0.470314\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066855; batch adversarial loss: 0.536301\n",
      "epoch 108; iter: 0; batch classifier loss: 0.075150; batch adversarial loss: 0.497545\n",
      "epoch 109; iter: 0; batch classifier loss: 0.093838; batch adversarial loss: 0.599074\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069558; batch adversarial loss: 0.495301\n",
      "epoch 111; iter: 0; batch classifier loss: 0.196174; batch adversarial loss: 0.783538\n",
      "epoch 112; iter: 0; batch classifier loss: 0.116842; batch adversarial loss: 0.632048\n",
      "epoch 113; iter: 0; batch classifier loss: 0.064502; batch adversarial loss: 0.544154\n",
      "epoch 114; iter: 0; batch classifier loss: 0.152715; batch adversarial loss: 0.678132\n",
      "epoch 115; iter: 0; batch classifier loss: 0.136553; batch adversarial loss: 0.654909\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054018; batch adversarial loss: 0.465931\n",
      "epoch 117; iter: 0; batch classifier loss: 0.101464; batch adversarial loss: 0.704929\n",
      "epoch 118; iter: 0; batch classifier loss: 0.138670; batch adversarial loss: 0.667071\n",
      "epoch 119; iter: 0; batch classifier loss: 0.126771; batch adversarial loss: 0.598031\n",
      "epoch 120; iter: 0; batch classifier loss: 0.136059; batch adversarial loss: 0.516700\n",
      "epoch 121; iter: 0; batch classifier loss: 0.202681; batch adversarial loss: 0.630197\n",
      "epoch 122; iter: 0; batch classifier loss: 0.120918; batch adversarial loss: 0.636309\n",
      "epoch 123; iter: 0; batch classifier loss: 0.145539; batch adversarial loss: 0.560037\n",
      "epoch 124; iter: 0; batch classifier loss: 0.150047; batch adversarial loss: 0.519975\n",
      "epoch 125; iter: 0; batch classifier loss: 0.133035; batch adversarial loss: 0.598477\n",
      "epoch 126; iter: 0; batch classifier loss: 0.189687; batch adversarial loss: 0.612598\n",
      "epoch 127; iter: 0; batch classifier loss: 0.148298; batch adversarial loss: 0.510655\n",
      "epoch 128; iter: 0; batch classifier loss: 0.130343; batch adversarial loss: 0.513789\n",
      "epoch 129; iter: 0; batch classifier loss: 0.207206; batch adversarial loss: 0.645735\n",
      "epoch 130; iter: 0; batch classifier loss: 0.120539; batch adversarial loss: 0.518467\n",
      "epoch 131; iter: 0; batch classifier loss: 0.185927; batch adversarial loss: 0.578321\n",
      "epoch 132; iter: 0; batch classifier loss: 0.081513; batch adversarial loss: 0.407616\n",
      "epoch 133; iter: 0; batch classifier loss: 0.073557; batch adversarial loss: 0.424013\n",
      "epoch 134; iter: 0; batch classifier loss: 0.163039; batch adversarial loss: 0.574145\n",
      "epoch 135; iter: 0; batch classifier loss: 0.097431; batch adversarial loss: 0.451989\n",
      "epoch 136; iter: 0; batch classifier loss: 0.141400; batch adversarial loss: 0.584680\n",
      "epoch 137; iter: 0; batch classifier loss: 0.151482; batch adversarial loss: 0.583969\n",
      "epoch 138; iter: 0; batch classifier loss: 0.075946; batch adversarial loss: 0.434454\n",
      "epoch 139; iter: 0; batch classifier loss: 0.059118; batch adversarial loss: 0.424760\n",
      "epoch 140; iter: 0; batch classifier loss: 0.079950; batch adversarial loss: 0.472547\n",
      "epoch 141; iter: 0; batch classifier loss: 0.101793; batch adversarial loss: 0.448225\n",
      "epoch 142; iter: 0; batch classifier loss: 0.081287; batch adversarial loss: 0.324808\n",
      "epoch 143; iter: 0; batch classifier loss: 0.065554; batch adversarial loss: 0.571018\n",
      "epoch 144; iter: 0; batch classifier loss: 0.084997; batch adversarial loss: 0.454779\n",
      "epoch 145; iter: 0; batch classifier loss: 0.096461; batch adversarial loss: 0.399125\n",
      "epoch 146; iter: 0; batch classifier loss: 0.108274; batch adversarial loss: 0.458031\n",
      "epoch 147; iter: 0; batch classifier loss: 0.073921; batch adversarial loss: 0.446299\n",
      "epoch 148; iter: 0; batch classifier loss: 0.078287; batch adversarial loss: 0.454437\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032599; batch adversarial loss: 0.493845\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035576; batch adversarial loss: 0.515096\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039047; batch adversarial loss: 0.397774\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036666; batch adversarial loss: 0.394612\n",
      "epoch 153; iter: 0; batch classifier loss: 0.063265; batch adversarial loss: 0.556924\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026293; batch adversarial loss: 0.476615\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023238; batch adversarial loss: 0.447867\n",
      "epoch 156; iter: 0; batch classifier loss: 0.064620; batch adversarial loss: 0.379434\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038403; batch adversarial loss: 0.508898\n",
      "epoch 158; iter: 0; batch classifier loss: 0.041432; batch adversarial loss: 0.413609\n",
      "epoch 159; iter: 0; batch classifier loss: 0.047052; batch adversarial loss: 0.453366\n",
      "epoch 160; iter: 0; batch classifier loss: 0.088370; batch adversarial loss: 0.457113\n",
      "epoch 161; iter: 0; batch classifier loss: 0.076380; batch adversarial loss: 0.506139\n",
      "epoch 162; iter: 0; batch classifier loss: 0.084594; batch adversarial loss: 0.524354\n",
      "epoch 163; iter: 0; batch classifier loss: 0.097953; batch adversarial loss: 0.482388\n",
      "epoch 164; iter: 0; batch classifier loss: 0.060048; batch adversarial loss: 0.489928\n",
      "epoch 165; iter: 0; batch classifier loss: 0.101311; batch adversarial loss: 0.476722\n",
      "epoch 166; iter: 0; batch classifier loss: 0.060249; batch adversarial loss: 0.566010\n",
      "epoch 167; iter: 0; batch classifier loss: 0.115035; batch adversarial loss: 0.364799\n",
      "epoch 168; iter: 0; batch classifier loss: 0.067302; batch adversarial loss: 0.440486\n",
      "epoch 169; iter: 0; batch classifier loss: 0.090100; batch adversarial loss: 0.480779\n",
      "epoch 170; iter: 0; batch classifier loss: 0.098237; batch adversarial loss: 0.422170\n",
      "epoch 171; iter: 0; batch classifier loss: 0.079566; batch adversarial loss: 0.490214\n",
      "epoch 172; iter: 0; batch classifier loss: 0.073877; batch adversarial loss: 0.447828\n",
      "epoch 173; iter: 0; batch classifier loss: 0.089443; batch adversarial loss: 0.452527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.066538; batch adversarial loss: 0.569045\n",
      "epoch 175; iter: 0; batch classifier loss: 0.099162; batch adversarial loss: 0.476609\n",
      "epoch 176; iter: 0; batch classifier loss: 0.073560; batch adversarial loss: 0.426840\n",
      "epoch 177; iter: 0; batch classifier loss: 0.072928; batch adversarial loss: 0.508985\n",
      "epoch 178; iter: 0; batch classifier loss: 0.089891; batch adversarial loss: 0.496632\n",
      "epoch 179; iter: 0; batch classifier loss: 0.099360; batch adversarial loss: 0.498357\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037016; batch adversarial loss: 0.491947\n",
      "epoch 181; iter: 0; batch classifier loss: 0.131149; batch adversarial loss: 0.386501\n",
      "epoch 182; iter: 0; batch classifier loss: 0.079295; batch adversarial loss: 0.496563\n",
      "epoch 183; iter: 0; batch classifier loss: 0.051651; batch adversarial loss: 0.452046\n",
      "epoch 184; iter: 0; batch classifier loss: 0.077991; batch adversarial loss: 0.514530\n",
      "epoch 185; iter: 0; batch classifier loss: 0.097914; batch adversarial loss: 0.423781\n",
      "epoch 186; iter: 0; batch classifier loss: 0.093369; batch adversarial loss: 0.427386\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040709; batch adversarial loss: 0.535281\n",
      "epoch 188; iter: 0; batch classifier loss: 0.072592; batch adversarial loss: 0.475741\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035426; batch adversarial loss: 0.478859\n",
      "epoch 190; iter: 0; batch classifier loss: 0.077405; batch adversarial loss: 0.348217\n",
      "epoch 191; iter: 0; batch classifier loss: 0.076166; batch adversarial loss: 0.458025\n",
      "epoch 192; iter: 0; batch classifier loss: 0.046889; batch adversarial loss: 0.498348\n",
      "epoch 193; iter: 0; batch classifier loss: 0.053439; batch adversarial loss: 0.422968\n",
      "epoch 194; iter: 0; batch classifier loss: 0.108405; batch adversarial loss: 0.512442\n",
      "epoch 195; iter: 0; batch classifier loss: 0.076809; batch adversarial loss: 0.472120\n",
      "epoch 196; iter: 0; batch classifier loss: 0.051719; batch adversarial loss: 0.457530\n",
      "epoch 197; iter: 0; batch classifier loss: 0.073996; batch adversarial loss: 0.513052\n",
      "epoch 198; iter: 0; batch classifier loss: 0.062484; batch adversarial loss: 0.372565\n",
      "epoch 199; iter: 0; batch classifier loss: 0.068503; batch adversarial loss: 0.511446\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675416; batch adversarial loss: 0.770332\n",
      "epoch 1; iter: 0; batch classifier loss: 0.485604; batch adversarial loss: 0.864886\n",
      "epoch 2; iter: 0; batch classifier loss: 0.330775; batch adversarial loss: 0.885554\n",
      "epoch 3; iter: 0; batch classifier loss: 0.345982; batch adversarial loss: 0.830822\n",
      "epoch 4; iter: 0; batch classifier loss: 0.378362; batch adversarial loss: 0.733193\n",
      "epoch 5; iter: 0; batch classifier loss: 0.337636; batch adversarial loss: 0.669390\n",
      "epoch 6; iter: 0; batch classifier loss: 0.295447; batch adversarial loss: 0.681254\n",
      "epoch 7; iter: 0; batch classifier loss: 0.303378; batch adversarial loss: 0.638064\n",
      "epoch 8; iter: 0; batch classifier loss: 0.297710; batch adversarial loss: 0.643030\n",
      "epoch 9; iter: 0; batch classifier loss: 0.270298; batch adversarial loss: 0.548931\n",
      "epoch 10; iter: 0; batch classifier loss: 0.306896; batch adversarial loss: 0.552010\n",
      "epoch 11; iter: 0; batch classifier loss: 0.271758; batch adversarial loss: 0.536613\n",
      "epoch 12; iter: 0; batch classifier loss: 0.221858; batch adversarial loss: 0.532991\n",
      "epoch 13; iter: 0; batch classifier loss: 0.272219; batch adversarial loss: 0.470649\n",
      "epoch 14; iter: 0; batch classifier loss: 0.206782; batch adversarial loss: 0.536133\n",
      "epoch 15; iter: 0; batch classifier loss: 0.245963; batch adversarial loss: 0.467521\n",
      "epoch 16; iter: 0; batch classifier loss: 0.182929; batch adversarial loss: 0.447005\n",
      "epoch 17; iter: 0; batch classifier loss: 0.209993; batch adversarial loss: 0.473835\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197105; batch adversarial loss: 0.426068\n",
      "epoch 19; iter: 0; batch classifier loss: 0.219174; batch adversarial loss: 0.390108\n",
      "epoch 20; iter: 0; batch classifier loss: 0.186785; batch adversarial loss: 0.457662\n",
      "epoch 21; iter: 0; batch classifier loss: 0.213041; batch adversarial loss: 0.445314\n",
      "epoch 22; iter: 0; batch classifier loss: 0.164367; batch adversarial loss: 0.396288\n",
      "epoch 23; iter: 0; batch classifier loss: 0.185182; batch adversarial loss: 0.386939\n",
      "epoch 24; iter: 0; batch classifier loss: 0.156425; batch adversarial loss: 0.452604\n",
      "epoch 25; iter: 0; batch classifier loss: 0.112303; batch adversarial loss: 0.393809\n",
      "epoch 26; iter: 0; batch classifier loss: 0.146898; batch adversarial loss: 0.470851\n",
      "epoch 27; iter: 0; batch classifier loss: 0.145932; batch adversarial loss: 0.374150\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173044; batch adversarial loss: 0.426332\n",
      "epoch 29; iter: 0; batch classifier loss: 0.100107; batch adversarial loss: 0.420965\n",
      "epoch 30; iter: 0; batch classifier loss: 0.127046; batch adversarial loss: 0.365880\n",
      "epoch 31; iter: 0; batch classifier loss: 0.112641; batch adversarial loss: 0.371896\n",
      "epoch 32; iter: 0; batch classifier loss: 0.114905; batch adversarial loss: 0.366034\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144096; batch adversarial loss: 0.410221\n",
      "epoch 34; iter: 0; batch classifier loss: 0.116121; batch adversarial loss: 0.475632\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130461; batch adversarial loss: 0.387492\n",
      "epoch 36; iter: 0; batch classifier loss: 0.096957; batch adversarial loss: 0.402107\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111035; batch adversarial loss: 0.416737\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115352; batch adversarial loss: 0.374074\n",
      "epoch 39; iter: 0; batch classifier loss: 0.102524; batch adversarial loss: 0.360568\n",
      "epoch 40; iter: 0; batch classifier loss: 0.114614; batch adversarial loss: 0.399682\n",
      "epoch 41; iter: 0; batch classifier loss: 0.101338; batch adversarial loss: 0.400057\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096847; batch adversarial loss: 0.373262\n",
      "epoch 43; iter: 0; batch classifier loss: 0.121721; batch adversarial loss: 0.427435\n",
      "epoch 44; iter: 0; batch classifier loss: 0.111539; batch adversarial loss: 0.456437\n",
      "epoch 45; iter: 0; batch classifier loss: 0.073083; batch adversarial loss: 0.473041\n",
      "epoch 46; iter: 0; batch classifier loss: 0.087416; batch adversarial loss: 0.445704\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106101; batch adversarial loss: 0.348386\n",
      "epoch 48; iter: 0; batch classifier loss: 0.127235; batch adversarial loss: 0.443924\n",
      "epoch 49; iter: 0; batch classifier loss: 0.116626; batch adversarial loss: 0.359981\n",
      "epoch 50; iter: 0; batch classifier loss: 0.085230; batch adversarial loss: 0.425157\n",
      "epoch 51; iter: 0; batch classifier loss: 0.111057; batch adversarial loss: 0.491290\n",
      "epoch 52; iter: 0; batch classifier loss: 0.092619; batch adversarial loss: 0.440705\n",
      "epoch 53; iter: 0; batch classifier loss: 0.068877; batch adversarial loss: 0.396745\n",
      "epoch 54; iter: 0; batch classifier loss: 0.100133; batch adversarial loss: 0.455709\n",
      "epoch 55; iter: 0; batch classifier loss: 0.102584; batch adversarial loss: 0.361543\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101027; batch adversarial loss: 0.454428\n",
      "epoch 57; iter: 0; batch classifier loss: 0.048165; batch adversarial loss: 0.436304\n",
      "epoch 58; iter: 0; batch classifier loss: 0.118051; batch adversarial loss: 0.460024\n",
      "epoch 59; iter: 0; batch classifier loss: 0.093815; batch adversarial loss: 0.465894\n",
      "epoch 60; iter: 0; batch classifier loss: 0.077388; batch adversarial loss: 0.449545\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087792; batch adversarial loss: 0.467469\n",
      "epoch 62; iter: 0; batch classifier loss: 0.065080; batch adversarial loss: 0.321511\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092542; batch adversarial loss: 0.470496\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083850; batch adversarial loss: 0.449241\n",
      "epoch 65; iter: 0; batch classifier loss: 0.035191; batch adversarial loss: 0.442115\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066229; batch adversarial loss: 0.421531\n",
      "epoch 67; iter: 0; batch classifier loss: 0.052779; batch adversarial loss: 0.484873\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054027; batch adversarial loss: 0.446985\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061589; batch adversarial loss: 0.410739\n",
      "epoch 70; iter: 0; batch classifier loss: 0.069085; batch adversarial loss: 0.443250\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097222; batch adversarial loss: 0.486510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.053971; batch adversarial loss: 0.404486\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083808; batch adversarial loss: 0.431053\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053741; batch adversarial loss: 0.379512\n",
      "epoch 75; iter: 0; batch classifier loss: 0.037099; batch adversarial loss: 0.393344\n",
      "epoch 76; iter: 0; batch classifier loss: 0.035146; batch adversarial loss: 0.441611\n",
      "epoch 77; iter: 0; batch classifier loss: 0.054991; batch adversarial loss: 0.522440\n",
      "epoch 78; iter: 0; batch classifier loss: 0.033860; batch adversarial loss: 0.418051\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063316; batch adversarial loss: 0.467798\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067184; batch adversarial loss: 0.466098\n",
      "epoch 81; iter: 0; batch classifier loss: 0.058616; batch adversarial loss: 0.542005\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061214; batch adversarial loss: 0.415687\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059110; batch adversarial loss: 0.514224\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060507; batch adversarial loss: 0.416198\n",
      "epoch 85; iter: 0; batch classifier loss: 0.034035; batch adversarial loss: 0.436504\n",
      "epoch 86; iter: 0; batch classifier loss: 0.030189; batch adversarial loss: 0.486756\n",
      "epoch 87; iter: 0; batch classifier loss: 0.027602; batch adversarial loss: 0.442500\n",
      "epoch 88; iter: 0; batch classifier loss: 0.053300; batch adversarial loss: 0.429291\n",
      "epoch 89; iter: 0; batch classifier loss: 0.044445; batch adversarial loss: 0.367055\n",
      "epoch 90; iter: 0; batch classifier loss: 0.036996; batch adversarial loss: 0.400620\n",
      "epoch 91; iter: 0; batch classifier loss: 0.040355; batch adversarial loss: 0.524640\n",
      "epoch 92; iter: 0; batch classifier loss: 0.025895; batch adversarial loss: 0.421709\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036698; batch adversarial loss: 0.438743\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033407; batch adversarial loss: 0.455609\n",
      "epoch 95; iter: 0; batch classifier loss: 0.034299; batch adversarial loss: 0.388296\n",
      "epoch 96; iter: 0; batch classifier loss: 0.022317; batch adversarial loss: 0.476379\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044536; batch adversarial loss: 0.451171\n",
      "epoch 98; iter: 0; batch classifier loss: 0.028370; batch adversarial loss: 0.488352\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074761; batch adversarial loss: 0.531221\n",
      "epoch 100; iter: 0; batch classifier loss: 0.022672; batch adversarial loss: 0.485514\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068467; batch adversarial loss: 0.467330\n",
      "epoch 102; iter: 0; batch classifier loss: 0.045271; batch adversarial loss: 0.493826\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062635; batch adversarial loss: 0.611287\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046959; batch adversarial loss: 0.443459\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051933; batch adversarial loss: 0.578748\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064685; batch adversarial loss: 0.570439\n",
      "epoch 107; iter: 0; batch classifier loss: 0.068499; batch adversarial loss: 0.535009\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040518; batch adversarial loss: 0.513176\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066133; batch adversarial loss: 0.383862\n",
      "epoch 110; iter: 0; batch classifier loss: 0.101221; batch adversarial loss: 0.548676\n",
      "epoch 111; iter: 0; batch classifier loss: 0.092878; batch adversarial loss: 0.555780\n",
      "epoch 112; iter: 0; batch classifier loss: 0.125814; batch adversarial loss: 0.548735\n",
      "epoch 113; iter: 0; batch classifier loss: 0.078306; batch adversarial loss: 0.561811\n",
      "epoch 114; iter: 0; batch classifier loss: 0.114900; batch adversarial loss: 0.634499\n",
      "epoch 115; iter: 0; batch classifier loss: 0.188017; batch adversarial loss: 0.648989\n",
      "epoch 116; iter: 0; batch classifier loss: 0.119238; batch adversarial loss: 0.535245\n",
      "epoch 117; iter: 0; batch classifier loss: 0.143670; batch adversarial loss: 0.587004\n",
      "epoch 118; iter: 0; batch classifier loss: 0.151500; batch adversarial loss: 0.610023\n",
      "epoch 119; iter: 0; batch classifier loss: 0.072549; batch adversarial loss: 0.608888\n",
      "epoch 120; iter: 0; batch classifier loss: 0.206712; batch adversarial loss: 0.507796\n",
      "epoch 121; iter: 0; batch classifier loss: 0.084223; batch adversarial loss: 0.608277\n",
      "epoch 122; iter: 0; batch classifier loss: 0.090554; batch adversarial loss: 0.523289\n",
      "epoch 123; iter: 0; batch classifier loss: 0.088087; batch adversarial loss: 0.487340\n",
      "epoch 124; iter: 0; batch classifier loss: 0.155504; batch adversarial loss: 0.644153\n",
      "epoch 125; iter: 0; batch classifier loss: 0.087436; batch adversarial loss: 0.587538\n",
      "epoch 126; iter: 0; batch classifier loss: 0.131590; batch adversarial loss: 0.499044\n",
      "epoch 127; iter: 0; batch classifier loss: 0.071027; batch adversarial loss: 0.459184\n",
      "epoch 128; iter: 0; batch classifier loss: 0.081864; batch adversarial loss: 0.503043\n",
      "epoch 129; iter: 0; batch classifier loss: 0.099666; batch adversarial loss: 0.458324\n",
      "epoch 130; iter: 0; batch classifier loss: 0.102594; batch adversarial loss: 0.530506\n",
      "epoch 131; iter: 0; batch classifier loss: 0.085995; batch adversarial loss: 0.454572\n",
      "epoch 132; iter: 0; batch classifier loss: 0.099371; batch adversarial loss: 0.478437\n",
      "epoch 133; iter: 0; batch classifier loss: 0.163228; batch adversarial loss: 0.551570\n",
      "epoch 134; iter: 0; batch classifier loss: 0.108004; batch adversarial loss: 0.487642\n",
      "epoch 135; iter: 0; batch classifier loss: 0.110870; batch adversarial loss: 0.405729\n",
      "epoch 136; iter: 0; batch classifier loss: 0.086103; batch adversarial loss: 0.436506\n",
      "epoch 137; iter: 0; batch classifier loss: 0.181113; batch adversarial loss: 0.567125\n",
      "epoch 138; iter: 0; batch classifier loss: 0.129723; batch adversarial loss: 0.559908\n",
      "epoch 139; iter: 0; batch classifier loss: 0.151556; batch adversarial loss: 0.602027\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041303; batch adversarial loss: 0.345004\n",
      "epoch 141; iter: 0; batch classifier loss: 0.150286; batch adversarial loss: 0.507485\n",
      "epoch 142; iter: 0; batch classifier loss: 0.067365; batch adversarial loss: 0.405046\n",
      "epoch 143; iter: 0; batch classifier loss: 0.096725; batch adversarial loss: 0.471893\n",
      "epoch 144; iter: 0; batch classifier loss: 0.081540; batch adversarial loss: 0.428121\n",
      "epoch 145; iter: 0; batch classifier loss: 0.071835; batch adversarial loss: 0.511966\n",
      "epoch 146; iter: 0; batch classifier loss: 0.096447; batch adversarial loss: 0.474720\n",
      "epoch 147; iter: 0; batch classifier loss: 0.104387; batch adversarial loss: 0.423708\n",
      "epoch 148; iter: 0; batch classifier loss: 0.115826; batch adversarial loss: 0.398005\n",
      "epoch 149; iter: 0; batch classifier loss: 0.060624; batch adversarial loss: 0.469313\n",
      "epoch 150; iter: 0; batch classifier loss: 0.057287; batch adversarial loss: 0.516111\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037064; batch adversarial loss: 0.537246\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023861; batch adversarial loss: 0.559484\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021589; batch adversarial loss: 0.455513\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026717; batch adversarial loss: 0.509265\n",
      "epoch 155; iter: 0; batch classifier loss: 0.108325; batch adversarial loss: 0.441160\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043758; batch adversarial loss: 0.418081\n",
      "epoch 157; iter: 0; batch classifier loss: 0.076203; batch adversarial loss: 0.455296\n",
      "epoch 158; iter: 0; batch classifier loss: 0.077433; batch adversarial loss: 0.483647\n",
      "epoch 159; iter: 0; batch classifier loss: 0.071634; batch adversarial loss: 0.439726\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037863; batch adversarial loss: 0.401659\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043316; batch adversarial loss: 0.444950\n",
      "epoch 162; iter: 0; batch classifier loss: 0.062011; batch adversarial loss: 0.428158\n",
      "epoch 163; iter: 0; batch classifier loss: 0.051498; batch adversarial loss: 0.437265\n",
      "epoch 164; iter: 0; batch classifier loss: 0.066897; batch adversarial loss: 0.561497\n",
      "epoch 165; iter: 0; batch classifier loss: 0.068426; batch adversarial loss: 0.442605\n",
      "epoch 166; iter: 0; batch classifier loss: 0.088185; batch adversarial loss: 0.493897\n",
      "epoch 167; iter: 0; batch classifier loss: 0.093256; batch adversarial loss: 0.474120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.029694; batch adversarial loss: 0.315107\n",
      "epoch 169; iter: 0; batch classifier loss: 0.094860; batch adversarial loss: 0.335211\n",
      "epoch 170; iter: 0; batch classifier loss: 0.059130; batch adversarial loss: 0.407968\n",
      "epoch 171; iter: 0; batch classifier loss: 0.051237; batch adversarial loss: 0.487437\n",
      "epoch 172; iter: 0; batch classifier loss: 0.062244; batch adversarial loss: 0.532618\n",
      "epoch 173; iter: 0; batch classifier loss: 0.086411; batch adversarial loss: 0.472462\n",
      "epoch 174; iter: 0; batch classifier loss: 0.051129; batch adversarial loss: 0.418036\n",
      "epoch 175; iter: 0; batch classifier loss: 0.069925; batch adversarial loss: 0.492098\n",
      "epoch 176; iter: 0; batch classifier loss: 0.077336; batch adversarial loss: 0.465018\n",
      "epoch 177; iter: 0; batch classifier loss: 0.087184; batch adversarial loss: 0.479820\n",
      "epoch 178; iter: 0; batch classifier loss: 0.106027; batch adversarial loss: 0.451660\n",
      "epoch 179; iter: 0; batch classifier loss: 0.092580; batch adversarial loss: 0.513172\n",
      "epoch 180; iter: 0; batch classifier loss: 0.068419; batch adversarial loss: 0.407850\n",
      "epoch 181; iter: 0; batch classifier loss: 0.088198; batch adversarial loss: 0.425660\n",
      "epoch 182; iter: 0; batch classifier loss: 0.123193; batch adversarial loss: 0.468718\n",
      "epoch 183; iter: 0; batch classifier loss: 0.103217; batch adversarial loss: 0.456896\n",
      "epoch 184; iter: 0; batch classifier loss: 0.085364; batch adversarial loss: 0.457992\n",
      "epoch 185; iter: 0; batch classifier loss: 0.081497; batch adversarial loss: 0.552260\n",
      "epoch 186; iter: 0; batch classifier loss: 0.068883; batch adversarial loss: 0.453754\n",
      "epoch 187; iter: 0; batch classifier loss: 0.063190; batch adversarial loss: 0.532727\n",
      "epoch 188; iter: 0; batch classifier loss: 0.054738; batch adversarial loss: 0.472695\n",
      "epoch 189; iter: 0; batch classifier loss: 0.075227; batch adversarial loss: 0.393149\n",
      "epoch 190; iter: 0; batch classifier loss: 0.107677; batch adversarial loss: 0.394969\n",
      "epoch 191; iter: 0; batch classifier loss: 0.099049; batch adversarial loss: 0.455129\n",
      "epoch 192; iter: 0; batch classifier loss: 0.083785; batch adversarial loss: 0.451148\n",
      "epoch 193; iter: 0; batch classifier loss: 0.076152; batch adversarial loss: 0.421577\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031998; batch adversarial loss: 0.393604\n",
      "epoch 195; iter: 0; batch classifier loss: 0.073803; batch adversarial loss: 0.485177\n",
      "epoch 196; iter: 0; batch classifier loss: 0.049505; batch adversarial loss: 0.468987\n",
      "epoch 197; iter: 0; batch classifier loss: 0.060984; batch adversarial loss: 0.486836\n",
      "epoch 198; iter: 0; batch classifier loss: 0.128002; batch adversarial loss: 0.402314\n",
      "epoch 199; iter: 0; batch classifier loss: 0.065320; batch adversarial loss: 0.383796\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709634; batch adversarial loss: 0.681457\n",
      "epoch 1; iter: 0; batch classifier loss: 0.564530; batch adversarial loss: 0.651110\n",
      "epoch 2; iter: 0; batch classifier loss: 0.467593; batch adversarial loss: 0.638255\n",
      "epoch 3; iter: 0; batch classifier loss: 0.547830; batch adversarial loss: 0.603631\n",
      "epoch 4; iter: 0; batch classifier loss: 0.344879; batch adversarial loss: 0.603416\n",
      "epoch 5; iter: 0; batch classifier loss: 0.394516; batch adversarial loss: 0.574268\n",
      "epoch 6; iter: 0; batch classifier loss: 0.464022; batch adversarial loss: 0.577586\n",
      "epoch 7; iter: 0; batch classifier loss: 0.394562; batch adversarial loss: 0.585191\n",
      "epoch 8; iter: 0; batch classifier loss: 0.432093; batch adversarial loss: 0.574315\n",
      "epoch 9; iter: 0; batch classifier loss: 0.334366; batch adversarial loss: 0.548923\n",
      "epoch 10; iter: 0; batch classifier loss: 0.453629; batch adversarial loss: 0.538153\n",
      "epoch 11; iter: 0; batch classifier loss: 0.381995; batch adversarial loss: 0.496676\n",
      "epoch 12; iter: 0; batch classifier loss: 0.408227; batch adversarial loss: 0.552663\n",
      "epoch 13; iter: 0; batch classifier loss: 0.344080; batch adversarial loss: 0.498661\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389149; batch adversarial loss: 0.508595\n",
      "epoch 15; iter: 0; batch classifier loss: 0.368075; batch adversarial loss: 0.438254\n",
      "epoch 16; iter: 0; batch classifier loss: 0.367437; batch adversarial loss: 0.441854\n",
      "epoch 17; iter: 0; batch classifier loss: 0.375320; batch adversarial loss: 0.529518\n",
      "epoch 18; iter: 0; batch classifier loss: 0.311788; batch adversarial loss: 0.540338\n",
      "epoch 19; iter: 0; batch classifier loss: 0.309106; batch adversarial loss: 0.457407\n",
      "epoch 20; iter: 0; batch classifier loss: 0.306559; batch adversarial loss: 0.493784\n",
      "epoch 21; iter: 0; batch classifier loss: 0.294747; batch adversarial loss: 0.524449\n",
      "epoch 22; iter: 0; batch classifier loss: 0.298704; batch adversarial loss: 0.459679\n",
      "epoch 23; iter: 0; batch classifier loss: 0.287723; batch adversarial loss: 0.443080\n",
      "epoch 24; iter: 0; batch classifier loss: 0.216640; batch adversarial loss: 0.405401\n",
      "epoch 25; iter: 0; batch classifier loss: 0.268978; batch adversarial loss: 0.484610\n",
      "epoch 26; iter: 0; batch classifier loss: 0.262903; batch adversarial loss: 0.486791\n",
      "epoch 27; iter: 0; batch classifier loss: 0.248782; batch adversarial loss: 0.483686\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173758; batch adversarial loss: 0.478874\n",
      "epoch 29; iter: 0; batch classifier loss: 0.243003; batch adversarial loss: 0.420940\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130618; batch adversarial loss: 0.564545\n",
      "epoch 31; iter: 0; batch classifier loss: 0.266603; batch adversarial loss: 0.442451\n",
      "epoch 32; iter: 0; batch classifier loss: 0.201914; batch adversarial loss: 0.413453\n",
      "epoch 33; iter: 0; batch classifier loss: 0.193253; batch adversarial loss: 0.563143\n",
      "epoch 34; iter: 0; batch classifier loss: 0.260991; batch adversarial loss: 0.448661\n",
      "epoch 35; iter: 0; batch classifier loss: 0.183823; batch adversarial loss: 0.518004\n",
      "epoch 36; iter: 0; batch classifier loss: 0.235274; batch adversarial loss: 0.484526\n",
      "epoch 37; iter: 0; batch classifier loss: 0.233013; batch adversarial loss: 0.403806\n",
      "epoch 38; iter: 0; batch classifier loss: 0.190750; batch adversarial loss: 0.438006\n",
      "epoch 39; iter: 0; batch classifier loss: 0.252240; batch adversarial loss: 0.428387\n",
      "epoch 40; iter: 0; batch classifier loss: 0.201274; batch adversarial loss: 0.535086\n",
      "epoch 41; iter: 0; batch classifier loss: 0.210547; batch adversarial loss: 0.605537\n",
      "epoch 42; iter: 0; batch classifier loss: 0.245927; batch adversarial loss: 0.473568\n",
      "epoch 43; iter: 0; batch classifier loss: 0.299414; batch adversarial loss: 0.514071\n",
      "epoch 44; iter: 0; batch classifier loss: 0.256985; batch adversarial loss: 0.438945\n",
      "epoch 45; iter: 0; batch classifier loss: 0.260109; batch adversarial loss: 0.492789\n",
      "epoch 46; iter: 0; batch classifier loss: 0.238294; batch adversarial loss: 0.471763\n",
      "epoch 47; iter: 0; batch classifier loss: 0.184616; batch adversarial loss: 0.519602\n",
      "epoch 48; iter: 0; batch classifier loss: 0.237263; batch adversarial loss: 0.435924\n",
      "epoch 49; iter: 0; batch classifier loss: 0.242553; batch adversarial loss: 0.448962\n",
      "epoch 50; iter: 0; batch classifier loss: 0.224481; batch adversarial loss: 0.483878\n",
      "epoch 51; iter: 0; batch classifier loss: 0.340762; batch adversarial loss: 0.435739\n",
      "epoch 52; iter: 0; batch classifier loss: 0.133644; batch adversarial loss: 0.447687\n",
      "epoch 53; iter: 0; batch classifier loss: 0.191526; batch adversarial loss: 0.411107\n",
      "epoch 54; iter: 0; batch classifier loss: 0.158522; batch adversarial loss: 0.494807\n",
      "epoch 55; iter: 0; batch classifier loss: 0.107441; batch adversarial loss: 0.483911\n",
      "epoch 56; iter: 0; batch classifier loss: 0.170815; batch adversarial loss: 0.394443\n",
      "epoch 57; iter: 0; batch classifier loss: 0.172306; batch adversarial loss: 0.394480\n",
      "epoch 58; iter: 0; batch classifier loss: 0.298820; batch adversarial loss: 0.394920\n",
      "epoch 59; iter: 0; batch classifier loss: 0.143466; batch adversarial loss: 0.543856\n",
      "epoch 60; iter: 0; batch classifier loss: 0.189553; batch adversarial loss: 0.422261\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105317; batch adversarial loss: 0.422572\n",
      "epoch 62; iter: 0; batch classifier loss: 0.155964; batch adversarial loss: 0.443283\n",
      "epoch 63; iter: 0; batch classifier loss: 0.187368; batch adversarial loss: 0.494521\n",
      "epoch 64; iter: 0; batch classifier loss: 0.193808; batch adversarial loss: 0.575538\n",
      "epoch 65; iter: 0; batch classifier loss: 0.172891; batch adversarial loss: 0.434708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.182426; batch adversarial loss: 0.459657\n",
      "epoch 67; iter: 0; batch classifier loss: 0.254251; batch adversarial loss: 0.434632\n",
      "epoch 68; iter: 0; batch classifier loss: 0.173119; batch adversarial loss: 0.507107\n",
      "epoch 69; iter: 0; batch classifier loss: 0.132008; batch adversarial loss: 0.506300\n",
      "epoch 70; iter: 0; batch classifier loss: 0.233598; batch adversarial loss: 0.398286\n",
      "epoch 71; iter: 0; batch classifier loss: 0.273372; batch adversarial loss: 0.496832\n",
      "epoch 72; iter: 0; batch classifier loss: 0.220405; batch adversarial loss: 0.423744\n",
      "epoch 73; iter: 0; batch classifier loss: 0.165713; batch adversarial loss: 0.397562\n",
      "epoch 74; iter: 0; batch classifier loss: 0.149557; batch adversarial loss: 0.448935\n",
      "epoch 75; iter: 0; batch classifier loss: 0.185762; batch adversarial loss: 0.434561\n",
      "epoch 76; iter: 0; batch classifier loss: 0.281342; batch adversarial loss: 0.481624\n",
      "epoch 77; iter: 0; batch classifier loss: 0.188410; batch adversarial loss: 0.506607\n",
      "epoch 78; iter: 0; batch classifier loss: 0.138507; batch adversarial loss: 0.483008\n",
      "epoch 79; iter: 0; batch classifier loss: 0.222650; batch adversarial loss: 0.484717\n",
      "epoch 80; iter: 0; batch classifier loss: 0.198125; batch adversarial loss: 0.494536\n",
      "epoch 81; iter: 0; batch classifier loss: 0.198348; batch adversarial loss: 0.422824\n",
      "epoch 82; iter: 0; batch classifier loss: 0.251696; batch adversarial loss: 0.410949\n",
      "epoch 83; iter: 0; batch classifier loss: 0.144014; batch adversarial loss: 0.519443\n",
      "epoch 84; iter: 0; batch classifier loss: 0.127351; batch adversarial loss: 0.483987\n",
      "epoch 85; iter: 0; batch classifier loss: 0.200043; batch adversarial loss: 0.508121\n",
      "epoch 86; iter: 0; batch classifier loss: 0.227930; batch adversarial loss: 0.470670\n",
      "epoch 87; iter: 0; batch classifier loss: 0.158749; batch adversarial loss: 0.422885\n",
      "epoch 88; iter: 0; batch classifier loss: 0.104205; batch adversarial loss: 0.446374\n",
      "epoch 89; iter: 0; batch classifier loss: 0.148558; batch adversarial loss: 0.395875\n",
      "epoch 90; iter: 0; batch classifier loss: 0.110479; batch adversarial loss: 0.424431\n",
      "epoch 91; iter: 0; batch classifier loss: 0.174265; batch adversarial loss: 0.559954\n",
      "epoch 92; iter: 0; batch classifier loss: 0.234005; batch adversarial loss: 0.423085\n",
      "epoch 93; iter: 0; batch classifier loss: 0.195982; batch adversarial loss: 0.588769\n",
      "epoch 94; iter: 0; batch classifier loss: 0.125787; batch adversarial loss: 0.503689\n",
      "epoch 95; iter: 0; batch classifier loss: 0.202682; batch adversarial loss: 0.432364\n",
      "epoch 96; iter: 0; batch classifier loss: 0.163339; batch adversarial loss: 0.577157\n",
      "epoch 97; iter: 0; batch classifier loss: 0.165663; batch adversarial loss: 0.486170\n",
      "epoch 98; iter: 0; batch classifier loss: 0.135217; batch adversarial loss: 0.432362\n",
      "epoch 99; iter: 0; batch classifier loss: 0.116807; batch adversarial loss: 0.489068\n",
      "epoch 100; iter: 0; batch classifier loss: 0.109627; batch adversarial loss: 0.393164\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061496; batch adversarial loss: 0.525502\n",
      "epoch 102; iter: 0; batch classifier loss: 0.083267; batch adversarial loss: 0.493185\n",
      "epoch 103; iter: 0; batch classifier loss: 0.099325; batch adversarial loss: 0.548437\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059289; batch adversarial loss: 0.500690\n",
      "epoch 105; iter: 0; batch classifier loss: 0.086543; batch adversarial loss: 0.431916\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043849; batch adversarial loss: 0.472162\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059993; batch adversarial loss: 0.521572\n",
      "epoch 108; iter: 0; batch classifier loss: 0.078864; batch adversarial loss: 0.505313\n",
      "epoch 109; iter: 0; batch classifier loss: 0.063555; batch adversarial loss: 0.378893\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053884; batch adversarial loss: 0.423978\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040997; batch adversarial loss: 0.465592\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030608; batch adversarial loss: 0.529444\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029573; batch adversarial loss: 0.524169\n",
      "epoch 114; iter: 0; batch classifier loss: 0.071454; batch adversarial loss: 0.521521\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049632; batch adversarial loss: 0.396945\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027464; batch adversarial loss: 0.419653\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048086; batch adversarial loss: 0.464537\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046633; batch adversarial loss: 0.412514\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040542; batch adversarial loss: 0.434762\n",
      "epoch 120; iter: 0; batch classifier loss: 0.077385; batch adversarial loss: 0.455422\n",
      "epoch 121; iter: 0; batch classifier loss: 0.072188; batch adversarial loss: 0.500631\n",
      "epoch 122; iter: 0; batch classifier loss: 0.072715; batch adversarial loss: 0.476534\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019809; batch adversarial loss: 0.456593\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030844; batch adversarial loss: 0.541496\n",
      "epoch 125; iter: 0; batch classifier loss: 0.055839; batch adversarial loss: 0.407050\n",
      "epoch 126; iter: 0; batch classifier loss: 0.041503; batch adversarial loss: 0.414458\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024251; batch adversarial loss: 0.446206\n",
      "epoch 128; iter: 0; batch classifier loss: 0.064608; batch adversarial loss: 0.415824\n",
      "epoch 129; iter: 0; batch classifier loss: 0.014606; batch adversarial loss: 0.516768\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044595; batch adversarial loss: 0.418924\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017555; batch adversarial loss: 0.420230\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025980; batch adversarial loss: 0.403490\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060441; batch adversarial loss: 0.485753\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042217; batch adversarial loss: 0.502462\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044896; batch adversarial loss: 0.443232\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037958; batch adversarial loss: 0.513748\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020683; batch adversarial loss: 0.432967\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018149; batch adversarial loss: 0.431402\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024607; batch adversarial loss: 0.436460\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050300; batch adversarial loss: 0.493693\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045741; batch adversarial loss: 0.460252\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035312; batch adversarial loss: 0.459242\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027221; batch adversarial loss: 0.428145\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020251; batch adversarial loss: 0.482231\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012192; batch adversarial loss: 0.410797\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015729; batch adversarial loss: 0.384675\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043624; batch adversarial loss: 0.436004\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012469; batch adversarial loss: 0.440414\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016454; batch adversarial loss: 0.465504\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018980; batch adversarial loss: 0.450342\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022189; batch adversarial loss: 0.427067\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024718; batch adversarial loss: 0.491516\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013982; batch adversarial loss: 0.439178\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046729; batch adversarial loss: 0.427005\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049449; batch adversarial loss: 0.455880\n",
      "epoch 156; iter: 0; batch classifier loss: 0.054639; batch adversarial loss: 0.540370\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029188; batch adversarial loss: 0.436774\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014984; batch adversarial loss: 0.499464\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042803; batch adversarial loss: 0.378645\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016539; batch adversarial loss: 0.588782\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016122; batch adversarial loss: 0.393262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.004998; batch adversarial loss: 0.518646\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039262; batch adversarial loss: 0.440038\n",
      "epoch 164; iter: 0; batch classifier loss: 0.046710; batch adversarial loss: 0.416750\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009277; batch adversarial loss: 0.403508\n",
      "epoch 166; iter: 0; batch classifier loss: 0.005063; batch adversarial loss: 0.470381\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010390; batch adversarial loss: 0.486720\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014979; batch adversarial loss: 0.508370\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017756; batch adversarial loss: 0.495476\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013637; batch adversarial loss: 0.470900\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005887; batch adversarial loss: 0.440086\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015155; batch adversarial loss: 0.479632\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032104; batch adversarial loss: 0.392316\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007419; batch adversarial loss: 0.442138\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021704; batch adversarial loss: 0.412068\n",
      "epoch 176; iter: 0; batch classifier loss: 0.003710; batch adversarial loss: 0.438446\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006290; batch adversarial loss: 0.454673\n",
      "epoch 178; iter: 0; batch classifier loss: 0.004037; batch adversarial loss: 0.467514\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008444; batch adversarial loss: 0.281997\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017098; batch adversarial loss: 0.582752\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023098; batch adversarial loss: 0.416005\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006879; batch adversarial loss: 0.423749\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033826; batch adversarial loss: 0.358192\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003056; batch adversarial loss: 0.428873\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017537; batch adversarial loss: 0.426172\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005760; batch adversarial loss: 0.516264\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008602; batch adversarial loss: 0.479935\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013345; batch adversarial loss: 0.385881\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012792; batch adversarial loss: 0.556014\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027462; batch adversarial loss: 0.476985\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024010; batch adversarial loss: 0.563977\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009853; batch adversarial loss: 0.474979\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015175; batch adversarial loss: 0.461898\n",
      "epoch 194; iter: 0; batch classifier loss: 0.048841; batch adversarial loss: 0.415516\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011282; batch adversarial loss: 0.470012\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015150; batch adversarial loss: 0.377516\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007021; batch adversarial loss: 0.516697\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021852; batch adversarial loss: 0.502555\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005155; batch adversarial loss: 0.489523\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705024; batch adversarial loss: 0.723784\n",
      "epoch 1; iter: 0; batch classifier loss: 0.444630; batch adversarial loss: 0.692456\n",
      "epoch 2; iter: 0; batch classifier loss: 0.425363; batch adversarial loss: 0.643833\n",
      "epoch 3; iter: 0; batch classifier loss: 0.456117; batch adversarial loss: 0.597719\n",
      "epoch 4; iter: 0; batch classifier loss: 0.409446; batch adversarial loss: 0.608102\n",
      "epoch 5; iter: 0; batch classifier loss: 0.342629; batch adversarial loss: 0.575543\n",
      "epoch 6; iter: 0; batch classifier loss: 0.324760; batch adversarial loss: 0.573695\n",
      "epoch 7; iter: 0; batch classifier loss: 0.355393; batch adversarial loss: 0.560565\n",
      "epoch 8; iter: 0; batch classifier loss: 0.357832; batch adversarial loss: 0.557487\n",
      "epoch 9; iter: 0; batch classifier loss: 0.369099; batch adversarial loss: 0.558551\n",
      "epoch 10; iter: 0; batch classifier loss: 0.351943; batch adversarial loss: 0.548810\n",
      "epoch 11; iter: 0; batch classifier loss: 0.306421; batch adversarial loss: 0.496361\n",
      "epoch 12; iter: 0; batch classifier loss: 0.302465; batch adversarial loss: 0.508296\n",
      "epoch 13; iter: 0; batch classifier loss: 0.272729; batch adversarial loss: 0.550925\n",
      "epoch 14; iter: 0; batch classifier loss: 0.372203; batch adversarial loss: 0.491538\n",
      "epoch 15; iter: 0; batch classifier loss: 0.275261; batch adversarial loss: 0.522487\n",
      "epoch 16; iter: 0; batch classifier loss: 0.301699; batch adversarial loss: 0.464163\n",
      "epoch 17; iter: 0; batch classifier loss: 0.333064; batch adversarial loss: 0.466714\n",
      "epoch 18; iter: 0; batch classifier loss: 0.263984; batch adversarial loss: 0.542634\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223570; batch adversarial loss: 0.519314\n",
      "epoch 20; iter: 0; batch classifier loss: 0.241740; batch adversarial loss: 0.492256\n",
      "epoch 21; iter: 0; batch classifier loss: 0.236919; batch adversarial loss: 0.563209\n",
      "epoch 22; iter: 0; batch classifier loss: 0.284729; batch adversarial loss: 0.554984\n",
      "epoch 23; iter: 0; batch classifier loss: 0.317392; batch adversarial loss: 0.430645\n",
      "epoch 24; iter: 0; batch classifier loss: 0.252168; batch adversarial loss: 0.499076\n",
      "epoch 25; iter: 0; batch classifier loss: 0.206782; batch adversarial loss: 0.449759\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243592; batch adversarial loss: 0.421822\n",
      "epoch 27; iter: 0; batch classifier loss: 0.277433; batch adversarial loss: 0.495921\n",
      "epoch 28; iter: 0; batch classifier loss: 0.230506; batch adversarial loss: 0.495247\n",
      "epoch 29; iter: 0; batch classifier loss: 0.240314; batch adversarial loss: 0.413896\n",
      "epoch 30; iter: 0; batch classifier loss: 0.197294; batch adversarial loss: 0.431849\n",
      "epoch 31; iter: 0; batch classifier loss: 0.225536; batch adversarial loss: 0.458444\n",
      "epoch 32; iter: 0; batch classifier loss: 0.164291; batch adversarial loss: 0.493005\n",
      "epoch 33; iter: 0; batch classifier loss: 0.192333; batch adversarial loss: 0.481827\n",
      "epoch 34; iter: 0; batch classifier loss: 0.207652; batch adversarial loss: 0.466477\n",
      "epoch 35; iter: 0; batch classifier loss: 0.210098; batch adversarial loss: 0.461121\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163527; batch adversarial loss: 0.505294\n",
      "epoch 37; iter: 0; batch classifier loss: 0.165984; batch adversarial loss: 0.536177\n",
      "epoch 38; iter: 0; batch classifier loss: 0.221056; batch adversarial loss: 0.425339\n",
      "epoch 39; iter: 0; batch classifier loss: 0.194796; batch adversarial loss: 0.493044\n",
      "epoch 40; iter: 0; batch classifier loss: 0.165116; batch adversarial loss: 0.412126\n",
      "epoch 41; iter: 0; batch classifier loss: 0.229681; batch adversarial loss: 0.469090\n",
      "epoch 42; iter: 0; batch classifier loss: 0.204680; batch adversarial loss: 0.400580\n",
      "epoch 43; iter: 0; batch classifier loss: 0.198987; batch adversarial loss: 0.564157\n",
      "epoch 44; iter: 0; batch classifier loss: 0.165581; batch adversarial loss: 0.577317\n",
      "epoch 45; iter: 0; batch classifier loss: 0.171060; batch adversarial loss: 0.498877\n",
      "epoch 46; iter: 0; batch classifier loss: 0.222044; batch adversarial loss: 0.545813\n",
      "epoch 47; iter: 0; batch classifier loss: 0.249139; batch adversarial loss: 0.453256\n",
      "epoch 48; iter: 0; batch classifier loss: 0.140083; batch adversarial loss: 0.469610\n",
      "epoch 49; iter: 0; batch classifier loss: 0.212469; batch adversarial loss: 0.491232\n",
      "epoch 50; iter: 0; batch classifier loss: 0.140462; batch adversarial loss: 0.492436\n",
      "epoch 51; iter: 0; batch classifier loss: 0.199136; batch adversarial loss: 0.422713\n",
      "epoch 52; iter: 0; batch classifier loss: 0.141886; batch adversarial loss: 0.533238\n",
      "epoch 53; iter: 0; batch classifier loss: 0.150616; batch adversarial loss: 0.447005\n",
      "epoch 54; iter: 0; batch classifier loss: 0.089607; batch adversarial loss: 0.533617\n",
      "epoch 55; iter: 0; batch classifier loss: 0.176697; batch adversarial loss: 0.445161\n",
      "epoch 56; iter: 0; batch classifier loss: 0.199232; batch adversarial loss: 0.470581\n",
      "epoch 57; iter: 0; batch classifier loss: 0.195597; batch adversarial loss: 0.407415\n",
      "epoch 58; iter: 0; batch classifier loss: 0.142201; batch adversarial loss: 0.497131\n",
      "epoch 59; iter: 0; batch classifier loss: 0.191692; batch adversarial loss: 0.529803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.217712; batch adversarial loss: 0.398386\n",
      "epoch 61; iter: 0; batch classifier loss: 0.178365; batch adversarial loss: 0.430761\n",
      "epoch 62; iter: 0; batch classifier loss: 0.130964; batch adversarial loss: 0.441428\n",
      "epoch 63; iter: 0; batch classifier loss: 0.206940; batch adversarial loss: 0.456938\n",
      "epoch 64; iter: 0; batch classifier loss: 0.164808; batch adversarial loss: 0.419713\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122504; batch adversarial loss: 0.526715\n",
      "epoch 66; iter: 0; batch classifier loss: 0.152832; batch adversarial loss: 0.427656\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100915; batch adversarial loss: 0.416510\n",
      "epoch 68; iter: 0; batch classifier loss: 0.184489; batch adversarial loss: 0.526180\n",
      "epoch 69; iter: 0; batch classifier loss: 0.164567; batch adversarial loss: 0.419492\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090454; batch adversarial loss: 0.444283\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092586; batch adversarial loss: 0.505943\n",
      "epoch 72; iter: 0; batch classifier loss: 0.152541; batch adversarial loss: 0.382454\n",
      "epoch 73; iter: 0; batch classifier loss: 0.172795; batch adversarial loss: 0.454155\n",
      "epoch 74; iter: 0; batch classifier loss: 0.109761; batch adversarial loss: 0.390806\n",
      "epoch 75; iter: 0; batch classifier loss: 0.070041; batch adversarial loss: 0.469759\n",
      "epoch 76; iter: 0; batch classifier loss: 0.138435; batch adversarial loss: 0.346003\n",
      "epoch 77; iter: 0; batch classifier loss: 0.187943; batch adversarial loss: 0.414346\n",
      "epoch 78; iter: 0; batch classifier loss: 0.111330; batch adversarial loss: 0.459045\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065606; batch adversarial loss: 0.423896\n",
      "epoch 80; iter: 0; batch classifier loss: 0.079547; batch adversarial loss: 0.410819\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083965; batch adversarial loss: 0.408554\n",
      "epoch 82; iter: 0; batch classifier loss: 0.112716; batch adversarial loss: 0.434189\n",
      "epoch 83; iter: 0; batch classifier loss: 0.087196; batch adversarial loss: 0.421529\n",
      "epoch 84; iter: 0; batch classifier loss: 0.106494; batch adversarial loss: 0.402680\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076459; batch adversarial loss: 0.499018\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064493; batch adversarial loss: 0.381982\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064705; batch adversarial loss: 0.418630\n",
      "epoch 88; iter: 0; batch classifier loss: 0.085605; batch adversarial loss: 0.426862\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080842; batch adversarial loss: 0.435147\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073746; batch adversarial loss: 0.530389\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052587; batch adversarial loss: 0.458054\n",
      "epoch 92; iter: 0; batch classifier loss: 0.035250; batch adversarial loss: 0.457552\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078621; batch adversarial loss: 0.459299\n",
      "epoch 94; iter: 0; batch classifier loss: 0.118571; batch adversarial loss: 0.447110\n",
      "epoch 95; iter: 0; batch classifier loss: 0.059626; batch adversarial loss: 0.495893\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081855; batch adversarial loss: 0.571174\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073890; batch adversarial loss: 0.513452\n",
      "epoch 98; iter: 0; batch classifier loss: 0.078543; batch adversarial loss: 0.448004\n",
      "epoch 99; iter: 0; batch classifier loss: 0.079623; batch adversarial loss: 0.450133\n",
      "epoch 100; iter: 0; batch classifier loss: 0.077296; batch adversarial loss: 0.457654\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071324; batch adversarial loss: 0.451646\n",
      "epoch 102; iter: 0; batch classifier loss: 0.035040; batch adversarial loss: 0.590572\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066759; batch adversarial loss: 0.423644\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043530; batch adversarial loss: 0.370884\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056704; batch adversarial loss: 0.484610\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058603; batch adversarial loss: 0.461129\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059656; batch adversarial loss: 0.562249\n",
      "epoch 108; iter: 0; batch classifier loss: 0.026792; batch adversarial loss: 0.488052\n",
      "epoch 109; iter: 0; batch classifier loss: 0.081947; batch adversarial loss: 0.395667\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060483; batch adversarial loss: 0.388827\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036864; batch adversarial loss: 0.461567\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047662; batch adversarial loss: 0.370971\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039097; batch adversarial loss: 0.517659\n",
      "epoch 114; iter: 0; batch classifier loss: 0.024889; batch adversarial loss: 0.572854\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050605; batch adversarial loss: 0.444093\n",
      "epoch 116; iter: 0; batch classifier loss: 0.017576; batch adversarial loss: 0.571876\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028954; batch adversarial loss: 0.538747\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035069; batch adversarial loss: 0.521406\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049566; batch adversarial loss: 0.496475\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028309; batch adversarial loss: 0.404248\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050870; batch adversarial loss: 0.379025\n",
      "epoch 122; iter: 0; batch classifier loss: 0.020496; batch adversarial loss: 0.434239\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050281; batch adversarial loss: 0.485786\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030101; batch adversarial loss: 0.506077\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040651; batch adversarial loss: 0.552544\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040496; batch adversarial loss: 0.430117\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045221; batch adversarial loss: 0.416603\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023902; batch adversarial loss: 0.452880\n",
      "epoch 129; iter: 0; batch classifier loss: 0.077628; batch adversarial loss: 0.421567\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042273; batch adversarial loss: 0.392263\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029779; batch adversarial loss: 0.463807\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048818; batch adversarial loss: 0.573060\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031134; batch adversarial loss: 0.519317\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030864; batch adversarial loss: 0.442791\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032529; batch adversarial loss: 0.471193\n",
      "epoch 136; iter: 0; batch classifier loss: 0.015029; batch adversarial loss: 0.446625\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022642; batch adversarial loss: 0.466215\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027161; batch adversarial loss: 0.539416\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026671; batch adversarial loss: 0.436450\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035026; batch adversarial loss: 0.406058\n",
      "epoch 141; iter: 0; batch classifier loss: 0.012430; batch adversarial loss: 0.439116\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025458; batch adversarial loss: 0.447287\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029284; batch adversarial loss: 0.432361\n",
      "epoch 144; iter: 0; batch classifier loss: 0.074379; batch adversarial loss: 0.464772\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031124; batch adversarial loss: 0.398736\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032596; batch adversarial loss: 0.461067\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013736; batch adversarial loss: 0.411150\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023940; batch adversarial loss: 0.395363\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024980; batch adversarial loss: 0.497823\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019252; batch adversarial loss: 0.495541\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029818; batch adversarial loss: 0.441802\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023188; batch adversarial loss: 0.478818\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029525; batch adversarial loss: 0.530456\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030620; batch adversarial loss: 0.424003\n",
      "epoch 155; iter: 0; batch classifier loss: 0.047147; batch adversarial loss: 0.403170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.023290; batch adversarial loss: 0.475528\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015220; batch adversarial loss: 0.527485\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026160; batch adversarial loss: 0.518597\n",
      "epoch 159; iter: 0; batch classifier loss: 0.046867; batch adversarial loss: 0.484349\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026120; batch adversarial loss: 0.479922\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011109; batch adversarial loss: 0.431107\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024371; batch adversarial loss: 0.492101\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024954; batch adversarial loss: 0.418650\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022014; batch adversarial loss: 0.474965\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031838; batch adversarial loss: 0.388814\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028616; batch adversarial loss: 0.469998\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012276; batch adversarial loss: 0.536284\n",
      "epoch 168; iter: 0; batch classifier loss: 0.044301; batch adversarial loss: 0.570669\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009343; batch adversarial loss: 0.454723\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015223; batch adversarial loss: 0.336073\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038132; batch adversarial loss: 0.400934\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012547; batch adversarial loss: 0.509020\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022917; batch adversarial loss: 0.468111\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016635; batch adversarial loss: 0.456190\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029605; batch adversarial loss: 0.335780\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026026; batch adversarial loss: 0.519192\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022900; batch adversarial loss: 0.530277\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036624; batch adversarial loss: 0.468960\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021740; batch adversarial loss: 0.437958\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022863; batch adversarial loss: 0.585209\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036780; batch adversarial loss: 0.411259\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028446; batch adversarial loss: 0.383846\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030387; batch adversarial loss: 0.483798\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012792; batch adversarial loss: 0.346530\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011260; batch adversarial loss: 0.418681\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025381; batch adversarial loss: 0.489866\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011687; batch adversarial loss: 0.363851\n",
      "epoch 188; iter: 0; batch classifier loss: 0.047453; batch adversarial loss: 0.465229\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014644; batch adversarial loss: 0.500272\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022393; batch adversarial loss: 0.437045\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009715; batch adversarial loss: 0.468213\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013754; batch adversarial loss: 0.523074\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014153; batch adversarial loss: 0.469829\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014969; batch adversarial loss: 0.461390\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027287; batch adversarial loss: 0.501918\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009197; batch adversarial loss: 0.507609\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009042; batch adversarial loss: 0.508783\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014319; batch adversarial loss: 0.418289\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014650; batch adversarial loss: 0.377671\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701241; batch adversarial loss: 0.574356\n",
      "epoch 1; iter: 0; batch classifier loss: 0.397302; batch adversarial loss: 0.590413\n",
      "epoch 2; iter: 0; batch classifier loss: 0.402818; batch adversarial loss: 0.590348\n",
      "epoch 3; iter: 0; batch classifier loss: 0.433371; batch adversarial loss: 0.592171\n",
      "epoch 4; iter: 0; batch classifier loss: 0.547927; batch adversarial loss: 0.587491\n",
      "epoch 5; iter: 0; batch classifier loss: 0.517038; batch adversarial loss: 0.602059\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564731; batch adversarial loss: 0.596752\n",
      "epoch 7; iter: 0; batch classifier loss: 0.455625; batch adversarial loss: 0.578224\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513630; batch adversarial loss: 0.543610\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502688; batch adversarial loss: 0.479835\n",
      "epoch 10; iter: 0; batch classifier loss: 0.413495; batch adversarial loss: 0.506837\n",
      "epoch 11; iter: 0; batch classifier loss: 0.338433; batch adversarial loss: 0.586874\n",
      "epoch 12; iter: 0; batch classifier loss: 0.279378; batch adversarial loss: 0.528047\n",
      "epoch 13; iter: 0; batch classifier loss: 0.262327; batch adversarial loss: 0.470436\n",
      "epoch 14; iter: 0; batch classifier loss: 0.279746; batch adversarial loss: 0.509274\n",
      "epoch 15; iter: 0; batch classifier loss: 0.353100; batch adversarial loss: 0.451050\n",
      "epoch 16; iter: 0; batch classifier loss: 0.330933; batch adversarial loss: 0.550958\n",
      "epoch 17; iter: 0; batch classifier loss: 0.293720; batch adversarial loss: 0.439252\n",
      "epoch 18; iter: 0; batch classifier loss: 0.213180; batch adversarial loss: 0.509128\n",
      "epoch 19; iter: 0; batch classifier loss: 0.194620; batch adversarial loss: 0.510116\n",
      "epoch 20; iter: 0; batch classifier loss: 0.196544; batch adversarial loss: 0.399612\n",
      "epoch 21; iter: 0; batch classifier loss: 0.225673; batch adversarial loss: 0.446664\n",
      "epoch 22; iter: 0; batch classifier loss: 0.266031; batch adversarial loss: 0.428953\n",
      "epoch 23; iter: 0; batch classifier loss: 0.211878; batch adversarial loss: 0.474551\n",
      "epoch 24; iter: 0; batch classifier loss: 0.241248; batch adversarial loss: 0.367001\n",
      "epoch 25; iter: 0; batch classifier loss: 0.187798; batch adversarial loss: 0.550184\n",
      "epoch 26; iter: 0; batch classifier loss: 0.210649; batch adversarial loss: 0.401761\n",
      "epoch 27; iter: 0; batch classifier loss: 0.247923; batch adversarial loss: 0.394365\n",
      "epoch 28; iter: 0; batch classifier loss: 0.155903; batch adversarial loss: 0.419220\n",
      "epoch 29; iter: 0; batch classifier loss: 0.169158; batch adversarial loss: 0.425198\n",
      "epoch 30; iter: 0; batch classifier loss: 0.159189; batch adversarial loss: 0.520029\n",
      "epoch 31; iter: 0; batch classifier loss: 0.162509; batch adversarial loss: 0.477728\n",
      "epoch 32; iter: 0; batch classifier loss: 0.188660; batch adversarial loss: 0.484819\n",
      "epoch 33; iter: 0; batch classifier loss: 0.189295; batch adversarial loss: 0.478205\n",
      "epoch 34; iter: 0; batch classifier loss: 0.158707; batch adversarial loss: 0.427553\n",
      "epoch 35; iter: 0; batch classifier loss: 0.158408; batch adversarial loss: 0.423980\n",
      "epoch 36; iter: 0; batch classifier loss: 0.154975; batch adversarial loss: 0.446644\n",
      "epoch 37; iter: 0; batch classifier loss: 0.152039; batch adversarial loss: 0.412771\n",
      "epoch 38; iter: 0; batch classifier loss: 0.181837; batch adversarial loss: 0.413683\n",
      "epoch 39; iter: 0; batch classifier loss: 0.240980; batch adversarial loss: 0.434680\n",
      "epoch 40; iter: 0; batch classifier loss: 0.169922; batch adversarial loss: 0.443337\n",
      "epoch 41; iter: 0; batch classifier loss: 0.147468; batch adversarial loss: 0.471141\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200413; batch adversarial loss: 0.457860\n",
      "epoch 43; iter: 0; batch classifier loss: 0.250380; batch adversarial loss: 0.403415\n",
      "epoch 44; iter: 0; batch classifier loss: 0.185432; batch adversarial loss: 0.419696\n",
      "epoch 45; iter: 0; batch classifier loss: 0.179051; batch adversarial loss: 0.489145\n",
      "epoch 46; iter: 0; batch classifier loss: 0.230206; batch adversarial loss: 0.384718\n",
      "epoch 47; iter: 0; batch classifier loss: 0.207006; batch adversarial loss: 0.433336\n",
      "epoch 48; iter: 0; batch classifier loss: 0.193365; batch adversarial loss: 0.461688\n",
      "epoch 49; iter: 0; batch classifier loss: 0.208353; batch adversarial loss: 0.381176\n",
      "epoch 50; iter: 0; batch classifier loss: 0.243254; batch adversarial loss: 0.409194\n",
      "epoch 51; iter: 0; batch classifier loss: 0.140422; batch adversarial loss: 0.471142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.218060; batch adversarial loss: 0.475535\n",
      "epoch 53; iter: 0; batch classifier loss: 0.150073; batch adversarial loss: 0.432180\n",
      "epoch 54; iter: 0; batch classifier loss: 0.255100; batch adversarial loss: 0.462325\n",
      "epoch 55; iter: 0; batch classifier loss: 0.200236; batch adversarial loss: 0.528883\n",
      "epoch 56; iter: 0; batch classifier loss: 0.222525; batch adversarial loss: 0.386864\n",
      "epoch 57; iter: 0; batch classifier loss: 0.230900; batch adversarial loss: 0.421250\n",
      "epoch 58; iter: 0; batch classifier loss: 0.241546; batch adversarial loss: 0.472114\n",
      "epoch 59; iter: 0; batch classifier loss: 0.229042; batch adversarial loss: 0.424913\n",
      "epoch 60; iter: 0; batch classifier loss: 0.214931; batch adversarial loss: 0.569363\n",
      "epoch 61; iter: 0; batch classifier loss: 0.223678; batch adversarial loss: 0.408073\n",
      "epoch 62; iter: 0; batch classifier loss: 0.311327; batch adversarial loss: 0.458447\n",
      "epoch 63; iter: 0; batch classifier loss: 0.338377; batch adversarial loss: 0.447188\n",
      "epoch 64; iter: 0; batch classifier loss: 0.159625; batch adversarial loss: 0.507433\n",
      "epoch 65; iter: 0; batch classifier loss: 0.274714; batch adversarial loss: 0.374373\n",
      "epoch 66; iter: 0; batch classifier loss: 0.209711; batch adversarial loss: 0.471208\n",
      "epoch 67; iter: 0; batch classifier loss: 0.205692; batch adversarial loss: 0.385382\n",
      "epoch 68; iter: 0; batch classifier loss: 0.136083; batch adversarial loss: 0.456784\n",
      "epoch 69; iter: 0; batch classifier loss: 0.164957; batch adversarial loss: 0.433731\n",
      "epoch 70; iter: 0; batch classifier loss: 0.170351; batch adversarial loss: 0.423792\n",
      "epoch 71; iter: 0; batch classifier loss: 0.130493; batch adversarial loss: 0.450433\n",
      "epoch 72; iter: 0; batch classifier loss: 0.223070; batch adversarial loss: 0.445510\n",
      "epoch 73; iter: 0; batch classifier loss: 0.283819; batch adversarial loss: 0.531450\n",
      "epoch 74; iter: 0; batch classifier loss: 0.216910; batch adversarial loss: 0.470703\n",
      "epoch 75; iter: 0; batch classifier loss: 0.245750; batch adversarial loss: 0.434395\n",
      "epoch 76; iter: 0; batch classifier loss: 0.244841; batch adversarial loss: 0.483468\n",
      "epoch 77; iter: 0; batch classifier loss: 0.173595; batch adversarial loss: 0.446480\n",
      "epoch 78; iter: 0; batch classifier loss: 0.174255; batch adversarial loss: 0.421430\n",
      "epoch 79; iter: 0; batch classifier loss: 0.092901; batch adversarial loss: 0.533855\n",
      "epoch 80; iter: 0; batch classifier loss: 0.233903; batch adversarial loss: 0.472356\n",
      "epoch 81; iter: 0; batch classifier loss: 0.230022; batch adversarial loss: 0.485239\n",
      "epoch 82; iter: 0; batch classifier loss: 0.160952; batch adversarial loss: 0.557245\n",
      "epoch 83; iter: 0; batch classifier loss: 0.205138; batch adversarial loss: 0.447417\n",
      "epoch 84; iter: 0; batch classifier loss: 0.235799; batch adversarial loss: 0.433856\n",
      "epoch 85; iter: 0; batch classifier loss: 0.165644; batch adversarial loss: 0.520816\n",
      "epoch 86; iter: 0; batch classifier loss: 0.105380; batch adversarial loss: 0.408689\n",
      "epoch 87; iter: 0; batch classifier loss: 0.214642; batch adversarial loss: 0.508704\n",
      "epoch 88; iter: 0; batch classifier loss: 0.256937; batch adversarial loss: 0.471152\n",
      "epoch 89; iter: 0; batch classifier loss: 0.202917; batch adversarial loss: 0.470569\n",
      "epoch 90; iter: 0; batch classifier loss: 0.227015; batch adversarial loss: 0.397464\n",
      "epoch 91; iter: 0; batch classifier loss: 0.228316; batch adversarial loss: 0.471160\n",
      "epoch 92; iter: 0; batch classifier loss: 0.153735; batch adversarial loss: 0.434657\n",
      "epoch 93; iter: 0; batch classifier loss: 0.254181; batch adversarial loss: 0.371930\n",
      "epoch 94; iter: 0; batch classifier loss: 0.292767; batch adversarial loss: 0.421771\n",
      "epoch 95; iter: 0; batch classifier loss: 0.140401; batch adversarial loss: 0.545124\n",
      "epoch 96; iter: 0; batch classifier loss: 0.122630; batch adversarial loss: 0.458445\n",
      "epoch 97; iter: 0; batch classifier loss: 0.325812; batch adversarial loss: 0.397852\n",
      "epoch 98; iter: 0; batch classifier loss: 0.171750; batch adversarial loss: 0.448201\n",
      "epoch 99; iter: 0; batch classifier loss: 0.183268; batch adversarial loss: 0.360780\n",
      "epoch 100; iter: 0; batch classifier loss: 0.199675; batch adversarial loss: 0.546492\n",
      "epoch 101; iter: 0; batch classifier loss: 0.145624; batch adversarial loss: 0.521151\n",
      "epoch 102; iter: 0; batch classifier loss: 0.243559; batch adversarial loss: 0.348952\n",
      "epoch 103; iter: 0; batch classifier loss: 0.211189; batch adversarial loss: 0.507740\n",
      "epoch 104; iter: 0; batch classifier loss: 0.165037; batch adversarial loss: 0.458393\n",
      "epoch 105; iter: 0; batch classifier loss: 0.146495; batch adversarial loss: 0.459065\n",
      "epoch 106; iter: 0; batch classifier loss: 0.232097; batch adversarial loss: 0.397110\n",
      "epoch 107; iter: 0; batch classifier loss: 0.182183; batch adversarial loss: 0.507889\n",
      "epoch 108; iter: 0; batch classifier loss: 0.205457; batch adversarial loss: 0.445157\n",
      "epoch 109; iter: 0; batch classifier loss: 0.264188; batch adversarial loss: 0.385125\n",
      "epoch 110; iter: 0; batch classifier loss: 0.203353; batch adversarial loss: 0.521589\n",
      "epoch 111; iter: 0; batch classifier loss: 0.127830; batch adversarial loss: 0.422297\n",
      "epoch 112; iter: 0; batch classifier loss: 0.188634; batch adversarial loss: 0.496306\n",
      "epoch 113; iter: 0; batch classifier loss: 0.172171; batch adversarial loss: 0.433924\n",
      "epoch 114; iter: 0; batch classifier loss: 0.216200; batch adversarial loss: 0.409731\n",
      "epoch 115; iter: 0; batch classifier loss: 0.154360; batch adversarial loss: 0.483683\n",
      "epoch 116; iter: 0; batch classifier loss: 0.173564; batch adversarial loss: 0.446427\n",
      "epoch 117; iter: 0; batch classifier loss: 0.161470; batch adversarial loss: 0.434199\n",
      "epoch 118; iter: 0; batch classifier loss: 0.226631; batch adversarial loss: 0.458887\n",
      "epoch 119; iter: 0; batch classifier loss: 0.141619; batch adversarial loss: 0.508411\n",
      "epoch 120; iter: 0; batch classifier loss: 0.215968; batch adversarial loss: 0.483608\n",
      "epoch 121; iter: 0; batch classifier loss: 0.222816; batch adversarial loss: 0.495887\n",
      "epoch 122; iter: 0; batch classifier loss: 0.099384; batch adversarial loss: 0.433776\n",
      "epoch 123; iter: 0; batch classifier loss: 0.096511; batch adversarial loss: 0.418685\n",
      "epoch 124; iter: 0; batch classifier loss: 0.098511; batch adversarial loss: 0.370379\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048234; batch adversarial loss: 0.424951\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039363; batch adversarial loss: 0.422720\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050433; batch adversarial loss: 0.463699\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051798; batch adversarial loss: 0.444460\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052090; batch adversarial loss: 0.485813\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050097; batch adversarial loss: 0.374812\n",
      "epoch 131; iter: 0; batch classifier loss: 0.076133; batch adversarial loss: 0.388550\n",
      "epoch 132; iter: 0; batch classifier loss: 0.080713; batch adversarial loss: 0.526492\n",
      "epoch 133; iter: 0; batch classifier loss: 0.080800; batch adversarial loss: 0.460190\n",
      "epoch 134; iter: 0; batch classifier loss: 0.066795; batch adversarial loss: 0.506604\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020568; batch adversarial loss: 0.414811\n",
      "epoch 136; iter: 0; batch classifier loss: 0.052749; batch adversarial loss: 0.525199\n",
      "epoch 137; iter: 0; batch classifier loss: 0.072667; batch adversarial loss: 0.339392\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024719; batch adversarial loss: 0.407663\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041006; batch adversarial loss: 0.443841\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045943; batch adversarial loss: 0.391204\n",
      "epoch 141; iter: 0; batch classifier loss: 0.071433; batch adversarial loss: 0.353790\n",
      "epoch 142; iter: 0; batch classifier loss: 0.051684; batch adversarial loss: 0.458950\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037886; batch adversarial loss: 0.448434\n",
      "epoch 144; iter: 0; batch classifier loss: 0.058203; batch adversarial loss: 0.412203\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043636; batch adversarial loss: 0.372414\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022429; batch adversarial loss: 0.526470\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028181; batch adversarial loss: 0.416824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.035977; batch adversarial loss: 0.471121\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038338; batch adversarial loss: 0.485514\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054241; batch adversarial loss: 0.415123\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039677; batch adversarial loss: 0.436772\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029022; batch adversarial loss: 0.508141\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028859; batch adversarial loss: 0.416131\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052718; batch adversarial loss: 0.370132\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020411; batch adversarial loss: 0.415329\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033149; batch adversarial loss: 0.482939\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033850; batch adversarial loss: 0.443397\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023734; batch adversarial loss: 0.470741\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037122; batch adversarial loss: 0.434822\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030252; batch adversarial loss: 0.347896\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019512; batch adversarial loss: 0.556377\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024577; batch adversarial loss: 0.519240\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027558; batch adversarial loss: 0.533171\n",
      "epoch 164; iter: 0; batch classifier loss: 0.073212; batch adversarial loss: 0.485234\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020802; batch adversarial loss: 0.414279\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014907; batch adversarial loss: 0.449421\n",
      "epoch 167; iter: 0; batch classifier loss: 0.037012; batch adversarial loss: 0.426644\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037662; batch adversarial loss: 0.442602\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020836; batch adversarial loss: 0.424457\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016200; batch adversarial loss: 0.534276\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024275; batch adversarial loss: 0.404740\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013937; batch adversarial loss: 0.504155\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038819; batch adversarial loss: 0.417740\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024989; batch adversarial loss: 0.518301\n",
      "epoch 175; iter: 0; batch classifier loss: 0.044959; batch adversarial loss: 0.476453\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037823; batch adversarial loss: 0.501312\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030474; batch adversarial loss: 0.429916\n",
      "epoch 178; iter: 0; batch classifier loss: 0.061573; batch adversarial loss: 0.418193\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030166; batch adversarial loss: 0.413365\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018051; batch adversarial loss: 0.544726\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029471; batch adversarial loss: 0.488932\n",
      "epoch 182; iter: 0; batch classifier loss: 0.005456; batch adversarial loss: 0.521976\n",
      "epoch 183; iter: 0; batch classifier loss: 0.044030; batch adversarial loss: 0.372875\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027535; batch adversarial loss: 0.377555\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015969; batch adversarial loss: 0.551003\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018771; batch adversarial loss: 0.512068\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030032; batch adversarial loss: 0.435045\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024671; batch adversarial loss: 0.402790\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004132; batch adversarial loss: 0.456529\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015723; batch adversarial loss: 0.341623\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023391; batch adversarial loss: 0.383418\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014572; batch adversarial loss: 0.436561\n",
      "epoch 193; iter: 0; batch classifier loss: 0.033944; batch adversarial loss: 0.483341\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006192; batch adversarial loss: 0.428098\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015256; batch adversarial loss: 0.353249\n",
      "epoch 196; iter: 0; batch classifier loss: 0.054953; batch adversarial loss: 0.398461\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026549; batch adversarial loss: 0.504979\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011171; batch adversarial loss: 0.432269\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030810; batch adversarial loss: 0.430943\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732657; batch adversarial loss: 0.601333\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556118; batch adversarial loss: 0.601540\n",
      "epoch 2; iter: 0; batch classifier loss: 0.380854; batch adversarial loss: 0.599601\n",
      "epoch 3; iter: 0; batch classifier loss: 0.350356; batch adversarial loss: 0.563537\n",
      "epoch 4; iter: 0; batch classifier loss: 0.395291; batch adversarial loss: 0.540192\n",
      "epoch 5; iter: 0; batch classifier loss: 0.308922; batch adversarial loss: 0.558790\n",
      "epoch 6; iter: 0; batch classifier loss: 0.269658; batch adversarial loss: 0.502104\n",
      "epoch 7; iter: 0; batch classifier loss: 0.239387; batch adversarial loss: 0.492942\n",
      "epoch 8; iter: 0; batch classifier loss: 0.314007; batch adversarial loss: 0.516884\n",
      "epoch 9; iter: 0; batch classifier loss: 0.295780; batch adversarial loss: 0.454042\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258422; batch adversarial loss: 0.474566\n",
      "epoch 11; iter: 0; batch classifier loss: 0.187465; batch adversarial loss: 0.482963\n",
      "epoch 12; iter: 0; batch classifier loss: 0.157694; batch adversarial loss: 0.480693\n",
      "epoch 13; iter: 0; batch classifier loss: 0.214941; batch adversarial loss: 0.460546\n",
      "epoch 14; iter: 0; batch classifier loss: 0.122931; batch adversarial loss: 0.440114\n",
      "epoch 15; iter: 0; batch classifier loss: 0.192160; batch adversarial loss: 0.463878\n",
      "epoch 16; iter: 0; batch classifier loss: 0.207686; batch adversarial loss: 0.460147\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192753; batch adversarial loss: 0.531152\n",
      "epoch 18; iter: 0; batch classifier loss: 0.222540; batch adversarial loss: 0.425520\n",
      "epoch 19; iter: 0; batch classifier loss: 0.147544; batch adversarial loss: 0.532007\n",
      "epoch 20; iter: 0; batch classifier loss: 0.219625; batch adversarial loss: 0.531930\n",
      "epoch 21; iter: 0; batch classifier loss: 0.153887; batch adversarial loss: 0.480326\n",
      "epoch 22; iter: 0; batch classifier loss: 0.188944; batch adversarial loss: 0.552633\n",
      "epoch 23; iter: 0; batch classifier loss: 0.241897; batch adversarial loss: 0.540681\n",
      "epoch 24; iter: 0; batch classifier loss: 0.238895; batch adversarial loss: 0.432651\n",
      "epoch 25; iter: 0; batch classifier loss: 0.278337; batch adversarial loss: 0.514444\n",
      "epoch 26; iter: 0; batch classifier loss: 0.205206; batch adversarial loss: 0.528813\n",
      "epoch 27; iter: 0; batch classifier loss: 0.198956; batch adversarial loss: 0.521879\n",
      "epoch 28; iter: 0; batch classifier loss: 0.207721; batch adversarial loss: 0.500326\n",
      "epoch 29; iter: 0; batch classifier loss: 0.315275; batch adversarial loss: 0.527190\n",
      "epoch 30; iter: 0; batch classifier loss: 0.291324; batch adversarial loss: 0.468730\n",
      "epoch 31; iter: 0; batch classifier loss: 0.340571; batch adversarial loss: 0.497863\n",
      "epoch 32; iter: 0; batch classifier loss: 0.361516; batch adversarial loss: 0.543211\n",
      "epoch 33; iter: 0; batch classifier loss: 0.118497; batch adversarial loss: 0.467736\n",
      "epoch 34; iter: 0; batch classifier loss: 0.119449; batch adversarial loss: 0.452473\n",
      "epoch 35; iter: 0; batch classifier loss: 0.088966; batch adversarial loss: 0.500864\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123799; batch adversarial loss: 0.499688\n",
      "epoch 37; iter: 0; batch classifier loss: 0.089346; batch adversarial loss: 0.446576\n",
      "epoch 38; iter: 0; batch classifier loss: 0.105889; batch adversarial loss: 0.474396\n",
      "epoch 39; iter: 0; batch classifier loss: 0.103611; batch adversarial loss: 0.464026\n",
      "epoch 40; iter: 0; batch classifier loss: 0.083319; batch adversarial loss: 0.471122\n",
      "epoch 41; iter: 0; batch classifier loss: 0.115237; batch adversarial loss: 0.406937\n",
      "epoch 42; iter: 0; batch classifier loss: 0.078873; batch adversarial loss: 0.590292\n",
      "epoch 43; iter: 0; batch classifier loss: 0.126351; batch adversarial loss: 0.349187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.128052; batch adversarial loss: 0.422794\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099651; batch adversarial loss: 0.513547\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104737; batch adversarial loss: 0.480018\n",
      "epoch 47; iter: 0; batch classifier loss: 0.109910; batch adversarial loss: 0.518804\n",
      "epoch 48; iter: 0; batch classifier loss: 0.093825; batch adversarial loss: 0.340659\n",
      "epoch 49; iter: 0; batch classifier loss: 0.105530; batch adversarial loss: 0.543886\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129630; batch adversarial loss: 0.493230\n",
      "epoch 51; iter: 0; batch classifier loss: 0.134299; batch adversarial loss: 0.447256\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100566; batch adversarial loss: 0.402192\n",
      "epoch 53; iter: 0; batch classifier loss: 0.179962; batch adversarial loss: 0.351649\n",
      "epoch 54; iter: 0; batch classifier loss: 0.169901; batch adversarial loss: 0.429633\n",
      "epoch 55; iter: 0; batch classifier loss: 0.183439; batch adversarial loss: 0.466660\n",
      "epoch 56; iter: 0; batch classifier loss: 0.140342; batch adversarial loss: 0.562134\n",
      "epoch 57; iter: 0; batch classifier loss: 0.168636; batch adversarial loss: 0.554379\n",
      "epoch 58; iter: 0; batch classifier loss: 0.122908; batch adversarial loss: 0.425029\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081482; batch adversarial loss: 0.458611\n",
      "epoch 60; iter: 0; batch classifier loss: 0.178109; batch adversarial loss: 0.393080\n",
      "epoch 61; iter: 0; batch classifier loss: 0.160927; batch adversarial loss: 0.591425\n",
      "epoch 62; iter: 0; batch classifier loss: 0.131194; batch adversarial loss: 0.409553\n",
      "epoch 63; iter: 0; batch classifier loss: 0.189004; batch adversarial loss: 0.467345\n",
      "epoch 64; iter: 0; batch classifier loss: 0.137668; batch adversarial loss: 0.451871\n",
      "epoch 65; iter: 0; batch classifier loss: 0.162385; batch adversarial loss: 0.443194\n",
      "epoch 66; iter: 0; batch classifier loss: 0.195802; batch adversarial loss: 0.424378\n",
      "epoch 67; iter: 0; batch classifier loss: 0.200801; batch adversarial loss: 0.440683\n",
      "epoch 68; iter: 0; batch classifier loss: 0.145418; batch adversarial loss: 0.494388\n",
      "epoch 69; iter: 0; batch classifier loss: 0.138285; batch adversarial loss: 0.455303\n",
      "epoch 70; iter: 0; batch classifier loss: 0.150103; batch adversarial loss: 0.471419\n",
      "epoch 71; iter: 0; batch classifier loss: 0.221753; batch adversarial loss: 0.462355\n",
      "epoch 72; iter: 0; batch classifier loss: 0.205365; batch adversarial loss: 0.576819\n",
      "epoch 73; iter: 0; batch classifier loss: 0.139731; batch adversarial loss: 0.441424\n",
      "epoch 74; iter: 0; batch classifier loss: 0.154229; batch adversarial loss: 0.388747\n",
      "epoch 75; iter: 0; batch classifier loss: 0.203198; batch adversarial loss: 0.406906\n",
      "epoch 76; iter: 0; batch classifier loss: 0.203828; batch adversarial loss: 0.436529\n",
      "epoch 77; iter: 0; batch classifier loss: 0.217647; batch adversarial loss: 0.451332\n",
      "epoch 78; iter: 0; batch classifier loss: 0.215730; batch adversarial loss: 0.468242\n",
      "epoch 79; iter: 0; batch classifier loss: 0.204414; batch adversarial loss: 0.499491\n",
      "epoch 80; iter: 0; batch classifier loss: 0.201897; batch adversarial loss: 0.400394\n",
      "epoch 81; iter: 0; batch classifier loss: 0.211991; batch adversarial loss: 0.422801\n",
      "epoch 82; iter: 0; batch classifier loss: 0.171172; batch adversarial loss: 0.493211\n",
      "epoch 83; iter: 0; batch classifier loss: 0.182327; batch adversarial loss: 0.497355\n",
      "epoch 84; iter: 0; batch classifier loss: 0.150094; batch adversarial loss: 0.519354\n",
      "epoch 85; iter: 0; batch classifier loss: 0.169533; batch adversarial loss: 0.482662\n",
      "epoch 86; iter: 0; batch classifier loss: 0.257473; batch adversarial loss: 0.459918\n",
      "epoch 87; iter: 0; batch classifier loss: 0.220848; batch adversarial loss: 0.544787\n",
      "epoch 88; iter: 0; batch classifier loss: 0.178755; batch adversarial loss: 0.447309\n",
      "epoch 89; iter: 0; batch classifier loss: 0.208597; batch adversarial loss: 0.471778\n",
      "epoch 90; iter: 0; batch classifier loss: 0.164258; batch adversarial loss: 0.543394\n",
      "epoch 91; iter: 0; batch classifier loss: 0.297163; batch adversarial loss: 0.434764\n",
      "epoch 92; iter: 0; batch classifier loss: 0.162773; batch adversarial loss: 0.398695\n",
      "epoch 93; iter: 0; batch classifier loss: 0.218100; batch adversarial loss: 0.386806\n",
      "epoch 94; iter: 0; batch classifier loss: 0.090866; batch adversarial loss: 0.383020\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079597; batch adversarial loss: 0.554485\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064877; batch adversarial loss: 0.428653\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056223; batch adversarial loss: 0.437966\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049840; batch adversarial loss: 0.480370\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055853; batch adversarial loss: 0.372327\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075256; batch adversarial loss: 0.395546\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051135; batch adversarial loss: 0.408861\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042216; batch adversarial loss: 0.450560\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063352; batch adversarial loss: 0.420970\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038525; batch adversarial loss: 0.432068\n",
      "epoch 105; iter: 0; batch classifier loss: 0.095263; batch adversarial loss: 0.434200\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034646; batch adversarial loss: 0.333954\n",
      "epoch 107; iter: 0; batch classifier loss: 0.043101; batch adversarial loss: 0.350285\n",
      "epoch 108; iter: 0; batch classifier loss: 0.095125; batch adversarial loss: 0.391148\n",
      "epoch 109; iter: 0; batch classifier loss: 0.072391; batch adversarial loss: 0.505325\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042558; batch adversarial loss: 0.410881\n",
      "epoch 111; iter: 0; batch classifier loss: 0.065929; batch adversarial loss: 0.417426\n",
      "epoch 112; iter: 0; batch classifier loss: 0.081750; batch adversarial loss: 0.453747\n",
      "epoch 113; iter: 0; batch classifier loss: 0.086731; batch adversarial loss: 0.381642\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056398; batch adversarial loss: 0.366278\n",
      "epoch 115; iter: 0; batch classifier loss: 0.064543; batch adversarial loss: 0.462676\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046739; batch adversarial loss: 0.439597\n",
      "epoch 117; iter: 0; batch classifier loss: 0.097256; batch adversarial loss: 0.404429\n",
      "epoch 118; iter: 0; batch classifier loss: 0.067229; batch adversarial loss: 0.484053\n",
      "epoch 119; iter: 0; batch classifier loss: 0.071919; batch adversarial loss: 0.524563\n",
      "epoch 120; iter: 0; batch classifier loss: 0.071125; batch adversarial loss: 0.467105\n",
      "epoch 121; iter: 0; batch classifier loss: 0.070409; batch adversarial loss: 0.468571\n",
      "epoch 122; iter: 0; batch classifier loss: 0.099887; batch adversarial loss: 0.445877\n",
      "epoch 123; iter: 0; batch classifier loss: 0.085025; batch adversarial loss: 0.506966\n",
      "epoch 124; iter: 0; batch classifier loss: 0.066341; batch adversarial loss: 0.468536\n",
      "epoch 125; iter: 0; batch classifier loss: 0.069224; batch adversarial loss: 0.413039\n",
      "epoch 126; iter: 0; batch classifier loss: 0.064098; batch adversarial loss: 0.447935\n",
      "epoch 127; iter: 0; batch classifier loss: 0.057127; batch adversarial loss: 0.509019\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046191; batch adversarial loss: 0.478467\n",
      "epoch 129; iter: 0; batch classifier loss: 0.066631; batch adversarial loss: 0.485212\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050439; batch adversarial loss: 0.498145\n",
      "epoch 131; iter: 0; batch classifier loss: 0.079865; batch adversarial loss: 0.432581\n",
      "epoch 132; iter: 0; batch classifier loss: 0.059938; batch adversarial loss: 0.388313\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033793; batch adversarial loss: 0.353699\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050871; batch adversarial loss: 0.401369\n",
      "epoch 135; iter: 0; batch classifier loss: 0.048706; batch adversarial loss: 0.482825\n",
      "epoch 136; iter: 0; batch classifier loss: 0.070535; batch adversarial loss: 0.419943\n",
      "epoch 137; iter: 0; batch classifier loss: 0.086044; batch adversarial loss: 0.481859\n",
      "epoch 138; iter: 0; batch classifier loss: 0.071522; batch adversarial loss: 0.417000\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044728; batch adversarial loss: 0.453655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.051242; batch adversarial loss: 0.443673\n",
      "epoch 141; iter: 0; batch classifier loss: 0.062853; batch adversarial loss: 0.432993\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048877; batch adversarial loss: 0.418531\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040202; batch adversarial loss: 0.416728\n",
      "epoch 144; iter: 0; batch classifier loss: 0.074080; batch adversarial loss: 0.444956\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044877; batch adversarial loss: 0.352728\n",
      "epoch 146; iter: 0; batch classifier loss: 0.065530; batch adversarial loss: 0.486615\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036325; batch adversarial loss: 0.383554\n",
      "epoch 148; iter: 0; batch classifier loss: 0.072996; batch adversarial loss: 0.481786\n",
      "epoch 149; iter: 0; batch classifier loss: 0.060163; batch adversarial loss: 0.540453\n",
      "epoch 150; iter: 0; batch classifier loss: 0.070766; batch adversarial loss: 0.397815\n",
      "epoch 151; iter: 0; batch classifier loss: 0.046872; batch adversarial loss: 0.434782\n",
      "epoch 152; iter: 0; batch classifier loss: 0.082757; batch adversarial loss: 0.521525\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034445; batch adversarial loss: 0.431987\n",
      "epoch 154; iter: 0; batch classifier loss: 0.074199; batch adversarial loss: 0.425834\n",
      "epoch 155; iter: 0; batch classifier loss: 0.080498; batch adversarial loss: 0.415500\n",
      "epoch 156; iter: 0; batch classifier loss: 0.046877; batch adversarial loss: 0.444666\n",
      "epoch 157; iter: 0; batch classifier loss: 0.073834; batch adversarial loss: 0.416031\n",
      "epoch 158; iter: 0; batch classifier loss: 0.084580; batch adversarial loss: 0.535736\n",
      "epoch 159; iter: 0; batch classifier loss: 0.046577; batch adversarial loss: 0.412701\n",
      "epoch 160; iter: 0; batch classifier loss: 0.082333; batch adversarial loss: 0.346041\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036785; batch adversarial loss: 0.413919\n",
      "epoch 162; iter: 0; batch classifier loss: 0.056934; batch adversarial loss: 0.446525\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039965; batch adversarial loss: 0.422211\n",
      "epoch 164; iter: 0; batch classifier loss: 0.046618; batch adversarial loss: 0.486663\n",
      "epoch 165; iter: 0; batch classifier loss: 0.051111; batch adversarial loss: 0.478896\n",
      "epoch 166; iter: 0; batch classifier loss: 0.107896; batch adversarial loss: 0.429434\n",
      "epoch 167; iter: 0; batch classifier loss: 0.073888; batch adversarial loss: 0.528536\n",
      "epoch 168; iter: 0; batch classifier loss: 0.083566; batch adversarial loss: 0.487245\n",
      "epoch 169; iter: 0; batch classifier loss: 0.053445; batch adversarial loss: 0.449648\n",
      "epoch 170; iter: 0; batch classifier loss: 0.073385; batch adversarial loss: 0.393080\n",
      "epoch 171; iter: 0; batch classifier loss: 0.060962; batch adversarial loss: 0.420012\n",
      "epoch 172; iter: 0; batch classifier loss: 0.081675; batch adversarial loss: 0.430045\n",
      "epoch 173; iter: 0; batch classifier loss: 0.047759; batch adversarial loss: 0.405079\n",
      "epoch 174; iter: 0; batch classifier loss: 0.048767; batch adversarial loss: 0.507795\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034639; batch adversarial loss: 0.382010\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045308; batch adversarial loss: 0.333326\n",
      "epoch 177; iter: 0; batch classifier loss: 0.052761; batch adversarial loss: 0.451189\n",
      "epoch 178; iter: 0; batch classifier loss: 0.084132; batch adversarial loss: 0.439175\n",
      "epoch 179; iter: 0; batch classifier loss: 0.064609; batch adversarial loss: 0.410639\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037204; batch adversarial loss: 0.345061\n",
      "epoch 181; iter: 0; batch classifier loss: 0.042858; batch adversarial loss: 0.389400\n",
      "epoch 182; iter: 0; batch classifier loss: 0.049682; batch adversarial loss: 0.389819\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032788; batch adversarial loss: 0.453024\n",
      "epoch 184; iter: 0; batch classifier loss: 0.062940; batch adversarial loss: 0.452020\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022110; batch adversarial loss: 0.417259\n",
      "epoch 186; iter: 0; batch classifier loss: 0.045983; batch adversarial loss: 0.408655\n",
      "epoch 187; iter: 0; batch classifier loss: 0.037158; batch adversarial loss: 0.400684\n",
      "epoch 188; iter: 0; batch classifier loss: 0.080553; batch adversarial loss: 0.409904\n",
      "epoch 189; iter: 0; batch classifier loss: 0.040987; batch adversarial loss: 0.493524\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038994; batch adversarial loss: 0.334440\n",
      "epoch 191; iter: 0; batch classifier loss: 0.059877; batch adversarial loss: 0.379217\n",
      "epoch 192; iter: 0; batch classifier loss: 0.046501; batch adversarial loss: 0.439933\n",
      "epoch 193; iter: 0; batch classifier loss: 0.042900; batch adversarial loss: 0.428430\n",
      "epoch 194; iter: 0; batch classifier loss: 0.050078; batch adversarial loss: 0.408591\n",
      "epoch 195; iter: 0; batch classifier loss: 0.039903; batch adversarial loss: 0.425519\n",
      "epoch 196; iter: 0; batch classifier loss: 0.042727; batch adversarial loss: 0.431337\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031242; batch adversarial loss: 0.384448\n",
      "epoch 198; iter: 0; batch classifier loss: 0.056150; batch adversarial loss: 0.495664\n",
      "epoch 199; iter: 0; batch classifier loss: 0.065699; batch adversarial loss: 0.410217\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689149; batch adversarial loss: 0.532681\n",
      "epoch 1; iter: 0; batch classifier loss: 0.412048; batch adversarial loss: 0.568425\n",
      "epoch 2; iter: 0; batch classifier loss: 0.411085; batch adversarial loss: 0.654819\n",
      "epoch 3; iter: 0; batch classifier loss: 0.300961; batch adversarial loss: 0.597846\n",
      "epoch 4; iter: 0; batch classifier loss: 0.478798; batch adversarial loss: 0.639835\n",
      "epoch 5; iter: 0; batch classifier loss: 0.455652; batch adversarial loss: 0.617597\n",
      "epoch 6; iter: 0; batch classifier loss: 0.540152; batch adversarial loss: 0.571732\n",
      "epoch 7; iter: 0; batch classifier loss: 0.585888; batch adversarial loss: 0.623526\n",
      "epoch 8; iter: 0; batch classifier loss: 0.480809; batch adversarial loss: 0.587702\n",
      "epoch 9; iter: 0; batch classifier loss: 0.462861; batch adversarial loss: 0.527673\n",
      "epoch 10; iter: 0; batch classifier loss: 0.449242; batch adversarial loss: 0.550293\n",
      "epoch 11; iter: 0; batch classifier loss: 0.375581; batch adversarial loss: 0.479274\n",
      "epoch 12; iter: 0; batch classifier loss: 0.389471; batch adversarial loss: 0.553397\n",
      "epoch 13; iter: 0; batch classifier loss: 0.338847; batch adversarial loss: 0.529393\n",
      "epoch 14; iter: 0; batch classifier loss: 0.311729; batch adversarial loss: 0.437119\n",
      "epoch 15; iter: 0; batch classifier loss: 0.214448; batch adversarial loss: 0.555010\n",
      "epoch 16; iter: 0; batch classifier loss: 0.266528; batch adversarial loss: 0.508321\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221003; batch adversarial loss: 0.563802\n",
      "epoch 18; iter: 0; batch classifier loss: 0.202011; batch adversarial loss: 0.464558\n",
      "epoch 19; iter: 0; batch classifier loss: 0.268509; batch adversarial loss: 0.464928\n",
      "epoch 20; iter: 0; batch classifier loss: 0.259984; batch adversarial loss: 0.424083\n",
      "epoch 21; iter: 0; batch classifier loss: 0.237975; batch adversarial loss: 0.426600\n",
      "epoch 22; iter: 0; batch classifier loss: 0.201633; batch adversarial loss: 0.456317\n",
      "epoch 23; iter: 0; batch classifier loss: 0.217971; batch adversarial loss: 0.484784\n",
      "epoch 24; iter: 0; batch classifier loss: 0.255391; batch adversarial loss: 0.401823\n",
      "epoch 25; iter: 0; batch classifier loss: 0.173093; batch adversarial loss: 0.383750\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194638; batch adversarial loss: 0.476172\n",
      "epoch 27; iter: 0; batch classifier loss: 0.213732; batch adversarial loss: 0.481732\n",
      "epoch 28; iter: 0; batch classifier loss: 0.222786; batch adversarial loss: 0.513355\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197948; batch adversarial loss: 0.512935\n",
      "epoch 30; iter: 0; batch classifier loss: 0.200684; batch adversarial loss: 0.373650\n",
      "epoch 31; iter: 0; batch classifier loss: 0.189976; batch adversarial loss: 0.452185\n",
      "epoch 32; iter: 0; batch classifier loss: 0.180279; batch adversarial loss: 0.449572\n",
      "epoch 33; iter: 0; batch classifier loss: 0.227944; batch adversarial loss: 0.482285\n",
      "epoch 34; iter: 0; batch classifier loss: 0.199318; batch adversarial loss: 0.445585\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160215; batch adversarial loss: 0.547953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.155019; batch adversarial loss: 0.530290\n",
      "epoch 37; iter: 0; batch classifier loss: 0.160443; batch adversarial loss: 0.506496\n",
      "epoch 38; iter: 0; batch classifier loss: 0.147664; batch adversarial loss: 0.402947\n",
      "epoch 39; iter: 0; batch classifier loss: 0.197709; batch adversarial loss: 0.388735\n",
      "epoch 40; iter: 0; batch classifier loss: 0.232558; batch adversarial loss: 0.404689\n",
      "epoch 41; iter: 0; batch classifier loss: 0.083681; batch adversarial loss: 0.523726\n",
      "epoch 42; iter: 0; batch classifier loss: 0.201052; batch adversarial loss: 0.366712\n",
      "epoch 43; iter: 0; batch classifier loss: 0.173613; batch adversarial loss: 0.459115\n",
      "epoch 44; iter: 0; batch classifier loss: 0.230883; batch adversarial loss: 0.411912\n",
      "epoch 45; iter: 0; batch classifier loss: 0.174363; batch adversarial loss: 0.466797\n",
      "epoch 46; iter: 0; batch classifier loss: 0.148368; batch adversarial loss: 0.464795\n",
      "epoch 47; iter: 0; batch classifier loss: 0.162741; batch adversarial loss: 0.394901\n",
      "epoch 48; iter: 0; batch classifier loss: 0.223946; batch adversarial loss: 0.428403\n",
      "epoch 49; iter: 0; batch classifier loss: 0.143765; batch adversarial loss: 0.438138\n",
      "epoch 50; iter: 0; batch classifier loss: 0.155361; batch adversarial loss: 0.480752\n",
      "epoch 51; iter: 0; batch classifier loss: 0.179236; batch adversarial loss: 0.408865\n",
      "epoch 52; iter: 0; batch classifier loss: 0.220721; batch adversarial loss: 0.557300\n",
      "epoch 53; iter: 0; batch classifier loss: 0.176276; batch adversarial loss: 0.445836\n",
      "epoch 54; iter: 0; batch classifier loss: 0.205237; batch adversarial loss: 0.460866\n",
      "epoch 55; iter: 0; batch classifier loss: 0.221791; batch adversarial loss: 0.415484\n",
      "epoch 56; iter: 0; batch classifier loss: 0.195893; batch adversarial loss: 0.479727\n",
      "epoch 57; iter: 0; batch classifier loss: 0.127888; batch adversarial loss: 0.438371\n",
      "epoch 58; iter: 0; batch classifier loss: 0.203358; batch adversarial loss: 0.396457\n",
      "epoch 59; iter: 0; batch classifier loss: 0.184341; batch adversarial loss: 0.421112\n",
      "epoch 60; iter: 0; batch classifier loss: 0.180521; batch adversarial loss: 0.416789\n",
      "epoch 61; iter: 0; batch classifier loss: 0.135896; batch adversarial loss: 0.560673\n",
      "epoch 62; iter: 0; batch classifier loss: 0.161719; batch adversarial loss: 0.488471\n",
      "epoch 63; iter: 0; batch classifier loss: 0.253475; batch adversarial loss: 0.432697\n",
      "epoch 64; iter: 0; batch classifier loss: 0.159971; batch adversarial loss: 0.456769\n",
      "epoch 65; iter: 0; batch classifier loss: 0.256823; batch adversarial loss: 0.410845\n",
      "epoch 66; iter: 0; batch classifier loss: 0.221088; batch adversarial loss: 0.472563\n",
      "epoch 67; iter: 0; batch classifier loss: 0.154888; batch adversarial loss: 0.494825\n",
      "epoch 68; iter: 0; batch classifier loss: 0.178125; batch adversarial loss: 0.583561\n",
      "epoch 69; iter: 0; batch classifier loss: 0.269369; batch adversarial loss: 0.434080\n",
      "epoch 70; iter: 0; batch classifier loss: 0.186926; batch adversarial loss: 0.494605\n",
      "epoch 71; iter: 0; batch classifier loss: 0.218065; batch adversarial loss: 0.408778\n",
      "epoch 72; iter: 0; batch classifier loss: 0.256417; batch adversarial loss: 0.434784\n",
      "epoch 73; iter: 0; batch classifier loss: 0.254387; batch adversarial loss: 0.373109\n",
      "epoch 74; iter: 0; batch classifier loss: 0.236736; batch adversarial loss: 0.421605\n",
      "epoch 75; iter: 0; batch classifier loss: 0.126315; batch adversarial loss: 0.409309\n",
      "epoch 76; iter: 0; batch classifier loss: 0.162080; batch adversarial loss: 0.445960\n",
      "epoch 77; iter: 0; batch classifier loss: 0.200119; batch adversarial loss: 0.509656\n",
      "epoch 78; iter: 0; batch classifier loss: 0.179287; batch adversarial loss: 0.434113\n",
      "epoch 79; iter: 0; batch classifier loss: 0.221223; batch adversarial loss: 0.422297\n",
      "epoch 80; iter: 0; batch classifier loss: 0.137051; batch adversarial loss: 0.434050\n",
      "epoch 81; iter: 0; batch classifier loss: 0.094802; batch adversarial loss: 0.420467\n",
      "epoch 82; iter: 0; batch classifier loss: 0.077535; batch adversarial loss: 0.356373\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079539; batch adversarial loss: 0.556781\n",
      "epoch 84; iter: 0; batch classifier loss: 0.102950; batch adversarial loss: 0.484592\n",
      "epoch 85; iter: 0; batch classifier loss: 0.141494; batch adversarial loss: 0.435568\n",
      "epoch 86; iter: 0; batch classifier loss: 0.148464; batch adversarial loss: 0.449091\n",
      "epoch 87; iter: 0; batch classifier loss: 0.164046; batch adversarial loss: 0.484428\n",
      "epoch 88; iter: 0; batch classifier loss: 0.091647; batch adversarial loss: 0.429738\n",
      "epoch 89; iter: 0; batch classifier loss: 0.095466; batch adversarial loss: 0.508220\n",
      "epoch 90; iter: 0; batch classifier loss: 0.072603; batch adversarial loss: 0.487899\n",
      "epoch 91; iter: 0; batch classifier loss: 0.143638; batch adversarial loss: 0.519838\n",
      "epoch 92; iter: 0; batch classifier loss: 0.149204; batch adversarial loss: 0.355674\n",
      "epoch 93; iter: 0; batch classifier loss: 0.101837; batch adversarial loss: 0.383744\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083906; batch adversarial loss: 0.447751\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087233; batch adversarial loss: 0.416654\n",
      "epoch 96; iter: 0; batch classifier loss: 0.160580; batch adversarial loss: 0.405377\n",
      "epoch 97; iter: 0; batch classifier loss: 0.094986; batch adversarial loss: 0.471868\n",
      "epoch 98; iter: 0; batch classifier loss: 0.073350; batch adversarial loss: 0.505275\n",
      "epoch 99; iter: 0; batch classifier loss: 0.079897; batch adversarial loss: 0.478975\n",
      "epoch 100; iter: 0; batch classifier loss: 0.108057; batch adversarial loss: 0.411579\n",
      "epoch 101; iter: 0; batch classifier loss: 0.084750; batch adversarial loss: 0.515252\n",
      "epoch 102; iter: 0; batch classifier loss: 0.093653; batch adversarial loss: 0.465645\n",
      "epoch 103; iter: 0; batch classifier loss: 0.069180; batch adversarial loss: 0.485332\n",
      "epoch 104; iter: 0; batch classifier loss: 0.087730; batch adversarial loss: 0.418117\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061840; batch adversarial loss: 0.482393\n",
      "epoch 106; iter: 0; batch classifier loss: 0.065193; batch adversarial loss: 0.370930\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050495; batch adversarial loss: 0.449160\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069465; batch adversarial loss: 0.541695\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051646; batch adversarial loss: 0.436047\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048474; batch adversarial loss: 0.604616\n",
      "epoch 111; iter: 0; batch classifier loss: 0.056787; batch adversarial loss: 0.447944\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060775; batch adversarial loss: 0.487413\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071562; batch adversarial loss: 0.535630\n",
      "epoch 114; iter: 0; batch classifier loss: 0.055598; batch adversarial loss: 0.430069\n",
      "epoch 115; iter: 0; batch classifier loss: 0.026024; batch adversarial loss: 0.465336\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039366; batch adversarial loss: 0.454463\n",
      "epoch 117; iter: 0; batch classifier loss: 0.089832; batch adversarial loss: 0.434018\n",
      "epoch 118; iter: 0; batch classifier loss: 0.075202; batch adversarial loss: 0.386874\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060271; batch adversarial loss: 0.335715\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041319; batch adversarial loss: 0.557751\n",
      "epoch 121; iter: 0; batch classifier loss: 0.063301; batch adversarial loss: 0.468915\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037208; batch adversarial loss: 0.486183\n",
      "epoch 123; iter: 0; batch classifier loss: 0.074800; batch adversarial loss: 0.464497\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040563; batch adversarial loss: 0.532475\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061753; batch adversarial loss: 0.441482\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044495; batch adversarial loss: 0.442678\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050148; batch adversarial loss: 0.437696\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033463; batch adversarial loss: 0.398923\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033612; batch adversarial loss: 0.428334\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040194; batch adversarial loss: 0.545837\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031870; batch adversarial loss: 0.469664\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034823; batch adversarial loss: 0.468218\n",
      "epoch 133; iter: 0; batch classifier loss: 0.074245; batch adversarial loss: 0.529881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.072759; batch adversarial loss: 0.399895\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018514; batch adversarial loss: 0.486311\n",
      "epoch 136; iter: 0; batch classifier loss: 0.012468; batch adversarial loss: 0.407795\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043004; batch adversarial loss: 0.515428\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018307; batch adversarial loss: 0.483824\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038196; batch adversarial loss: 0.394939\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031912; batch adversarial loss: 0.452233\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045753; batch adversarial loss: 0.488129\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031931; batch adversarial loss: 0.404712\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017697; batch adversarial loss: 0.450650\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013803; batch adversarial loss: 0.469997\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039347; batch adversarial loss: 0.397026\n",
      "epoch 146; iter: 0; batch classifier loss: 0.009897; batch adversarial loss: 0.469382\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039398; batch adversarial loss: 0.410698\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039412; batch adversarial loss: 0.441552\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013062; batch adversarial loss: 0.376931\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021912; batch adversarial loss: 0.393559\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020343; batch adversarial loss: 0.386895\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023871; batch adversarial loss: 0.379850\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026657; batch adversarial loss: 0.398306\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015933; batch adversarial loss: 0.401291\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035772; batch adversarial loss: 0.399704\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026506; batch adversarial loss: 0.537958\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021677; batch adversarial loss: 0.413970\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017840; batch adversarial loss: 0.405332\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011599; batch adversarial loss: 0.465586\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014464; batch adversarial loss: 0.386602\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020929; batch adversarial loss: 0.463492\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024585; batch adversarial loss: 0.433463\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032978; batch adversarial loss: 0.526829\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009636; batch adversarial loss: 0.496020\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044773; batch adversarial loss: 0.476043\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019180; batch adversarial loss: 0.524048\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027641; batch adversarial loss: 0.489060\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021966; batch adversarial loss: 0.395031\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017495; batch adversarial loss: 0.406252\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023755; batch adversarial loss: 0.382312\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023527; batch adversarial loss: 0.455832\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012381; batch adversarial loss: 0.498211\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018276; batch adversarial loss: 0.342665\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023675; batch adversarial loss: 0.539604\n",
      "epoch 175; iter: 0; batch classifier loss: 0.047084; batch adversarial loss: 0.450307\n",
      "epoch 176; iter: 0; batch classifier loss: 0.006610; batch adversarial loss: 0.489973\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027380; batch adversarial loss: 0.548519\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009743; batch adversarial loss: 0.585650\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013802; batch adversarial loss: 0.430935\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013120; batch adversarial loss: 0.422431\n",
      "epoch 181; iter: 0; batch classifier loss: 0.045186; batch adversarial loss: 0.474606\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010715; batch adversarial loss: 0.509512\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030769; batch adversarial loss: 0.481566\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026884; batch adversarial loss: 0.419774\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021446; batch adversarial loss: 0.310136\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010067; batch adversarial loss: 0.515123\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007731; batch adversarial loss: 0.432336\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005904; batch adversarial loss: 0.443997\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025733; batch adversarial loss: 0.453972\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030361; batch adversarial loss: 0.395923\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013248; batch adversarial loss: 0.467787\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005299; batch adversarial loss: 0.480876\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006178; batch adversarial loss: 0.435571\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027739; batch adversarial loss: 0.430035\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026446; batch adversarial loss: 0.432747\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016507; batch adversarial loss: 0.476899\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024270; batch adversarial loss: 0.510512\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003931; batch adversarial loss: 0.482003\n",
      "epoch 199; iter: 0; batch classifier loss: 0.045621; batch adversarial loss: 0.437412\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711795; batch adversarial loss: 0.814860\n",
      "epoch 1; iter: 0; batch classifier loss: 0.537338; batch adversarial loss: 0.742444\n",
      "epoch 2; iter: 0; batch classifier loss: 0.674904; batch adversarial loss: 0.713444\n",
      "epoch 3; iter: 0; batch classifier loss: 0.633401; batch adversarial loss: 0.648921\n",
      "epoch 4; iter: 0; batch classifier loss: 0.473637; batch adversarial loss: 0.598017\n",
      "epoch 5; iter: 0; batch classifier loss: 0.442764; batch adversarial loss: 0.578016\n",
      "epoch 6; iter: 0; batch classifier loss: 0.437181; batch adversarial loss: 0.549798\n",
      "epoch 7; iter: 0; batch classifier loss: 0.383250; batch adversarial loss: 0.539325\n",
      "epoch 8; iter: 0; batch classifier loss: 0.289089; batch adversarial loss: 0.569135\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282225; batch adversarial loss: 0.532782\n",
      "epoch 10; iter: 0; batch classifier loss: 0.373690; batch adversarial loss: 0.531511\n",
      "epoch 11; iter: 0; batch classifier loss: 0.332870; batch adversarial loss: 0.478838\n",
      "epoch 12; iter: 0; batch classifier loss: 0.288968; batch adversarial loss: 0.540813\n",
      "epoch 13; iter: 0; batch classifier loss: 0.385997; batch adversarial loss: 0.501538\n",
      "epoch 14; iter: 0; batch classifier loss: 0.191326; batch adversarial loss: 0.459264\n",
      "epoch 15; iter: 0; batch classifier loss: 0.268181; batch adversarial loss: 0.504060\n",
      "epoch 16; iter: 0; batch classifier loss: 0.224555; batch adversarial loss: 0.497969\n",
      "epoch 17; iter: 0; batch classifier loss: 0.298082; batch adversarial loss: 0.416710\n",
      "epoch 18; iter: 0; batch classifier loss: 0.225487; batch adversarial loss: 0.496581\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237887; batch adversarial loss: 0.527021\n",
      "epoch 20; iter: 0; batch classifier loss: 0.278592; batch adversarial loss: 0.462384\n",
      "epoch 21; iter: 0; batch classifier loss: 0.270600; batch adversarial loss: 0.544403\n",
      "epoch 22; iter: 0; batch classifier loss: 0.217999; batch adversarial loss: 0.467790\n",
      "epoch 23; iter: 0; batch classifier loss: 0.261839; batch adversarial loss: 0.479921\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159748; batch adversarial loss: 0.428416\n",
      "epoch 25; iter: 0; batch classifier loss: 0.241601; batch adversarial loss: 0.471096\n",
      "epoch 26; iter: 0; batch classifier loss: 0.214327; batch adversarial loss: 0.467162\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181464; batch adversarial loss: 0.400404\n",
      "epoch 28; iter: 0; batch classifier loss: 0.206212; batch adversarial loss: 0.326886\n",
      "epoch 29; iter: 0; batch classifier loss: 0.174279; batch adversarial loss: 0.476641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.168938; batch adversarial loss: 0.560747\n",
      "epoch 31; iter: 0; batch classifier loss: 0.242936; batch adversarial loss: 0.376110\n",
      "epoch 32; iter: 0; batch classifier loss: 0.183498; batch adversarial loss: 0.459050\n",
      "epoch 33; iter: 0; batch classifier loss: 0.228841; batch adversarial loss: 0.483489\n",
      "epoch 34; iter: 0; batch classifier loss: 0.174173; batch adversarial loss: 0.502395\n",
      "epoch 35; iter: 0; batch classifier loss: 0.149950; batch adversarial loss: 0.470436\n",
      "epoch 36; iter: 0; batch classifier loss: 0.194597; batch adversarial loss: 0.504263\n",
      "epoch 37; iter: 0; batch classifier loss: 0.225617; batch adversarial loss: 0.475869\n",
      "epoch 38; iter: 0; batch classifier loss: 0.174880; batch adversarial loss: 0.454227\n",
      "epoch 39; iter: 0; batch classifier loss: 0.205676; batch adversarial loss: 0.461543\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154494; batch adversarial loss: 0.467355\n",
      "epoch 41; iter: 0; batch classifier loss: 0.175524; batch adversarial loss: 0.420354\n",
      "epoch 42; iter: 0; batch classifier loss: 0.180483; batch adversarial loss: 0.428915\n",
      "epoch 43; iter: 0; batch classifier loss: 0.149247; batch adversarial loss: 0.526783\n",
      "epoch 44; iter: 0; batch classifier loss: 0.215176; batch adversarial loss: 0.430757\n",
      "epoch 45; iter: 0; batch classifier loss: 0.191429; batch adversarial loss: 0.512977\n",
      "epoch 46; iter: 0; batch classifier loss: 0.149156; batch adversarial loss: 0.534279\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119183; batch adversarial loss: 0.488721\n",
      "epoch 48; iter: 0; batch classifier loss: 0.175367; batch adversarial loss: 0.450888\n",
      "epoch 49; iter: 0; batch classifier loss: 0.180498; batch adversarial loss: 0.413638\n",
      "epoch 50; iter: 0; batch classifier loss: 0.175931; batch adversarial loss: 0.495401\n",
      "epoch 51; iter: 0; batch classifier loss: 0.145926; batch adversarial loss: 0.422534\n",
      "epoch 52; iter: 0; batch classifier loss: 0.182588; batch adversarial loss: 0.436674\n",
      "epoch 53; iter: 0; batch classifier loss: 0.137367; batch adversarial loss: 0.375828\n",
      "epoch 54; iter: 0; batch classifier loss: 0.164637; batch adversarial loss: 0.425353\n",
      "epoch 55; iter: 0; batch classifier loss: 0.227470; batch adversarial loss: 0.385008\n",
      "epoch 56; iter: 0; batch classifier loss: 0.131596; batch adversarial loss: 0.453949\n",
      "epoch 57; iter: 0; batch classifier loss: 0.122252; batch adversarial loss: 0.469886\n",
      "epoch 58; iter: 0; batch classifier loss: 0.104671; batch adversarial loss: 0.308823\n",
      "epoch 59; iter: 0; batch classifier loss: 0.142485; batch adversarial loss: 0.373340\n",
      "epoch 60; iter: 0; batch classifier loss: 0.176515; batch adversarial loss: 0.515648\n",
      "epoch 61; iter: 0; batch classifier loss: 0.153029; batch adversarial loss: 0.497638\n",
      "epoch 62; iter: 0; batch classifier loss: 0.145002; batch adversarial loss: 0.399736\n",
      "epoch 63; iter: 0; batch classifier loss: 0.195487; batch adversarial loss: 0.479144\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099570; batch adversarial loss: 0.491426\n",
      "epoch 65; iter: 0; batch classifier loss: 0.144369; batch adversarial loss: 0.441743\n",
      "epoch 66; iter: 0; batch classifier loss: 0.128041; batch adversarial loss: 0.418447\n",
      "epoch 67; iter: 0; batch classifier loss: 0.154637; batch adversarial loss: 0.485115\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109775; batch adversarial loss: 0.380393\n",
      "epoch 69; iter: 0; batch classifier loss: 0.109704; batch adversarial loss: 0.423347\n",
      "epoch 70; iter: 0; batch classifier loss: 0.121523; batch adversarial loss: 0.443068\n",
      "epoch 71; iter: 0; batch classifier loss: 0.080404; batch adversarial loss: 0.478395\n",
      "epoch 72; iter: 0; batch classifier loss: 0.103150; batch adversarial loss: 0.445167\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090784; batch adversarial loss: 0.502610\n",
      "epoch 74; iter: 0; batch classifier loss: 0.078487; batch adversarial loss: 0.497860\n",
      "epoch 75; iter: 0; batch classifier loss: 0.094003; batch adversarial loss: 0.456878\n",
      "epoch 76; iter: 0; batch classifier loss: 0.100843; batch adversarial loss: 0.473545\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094937; batch adversarial loss: 0.491569\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082793; batch adversarial loss: 0.491507\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099372; batch adversarial loss: 0.451578\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090760; batch adversarial loss: 0.478940\n",
      "epoch 81; iter: 0; batch classifier loss: 0.072499; batch adversarial loss: 0.497592\n",
      "epoch 82; iter: 0; batch classifier loss: 0.064336; batch adversarial loss: 0.425766\n",
      "epoch 83; iter: 0; batch classifier loss: 0.075362; batch adversarial loss: 0.514204\n",
      "epoch 84; iter: 0; batch classifier loss: 0.058822; batch adversarial loss: 0.420254\n",
      "epoch 85; iter: 0; batch classifier loss: 0.109325; batch adversarial loss: 0.457033\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069145; batch adversarial loss: 0.449810\n",
      "epoch 87; iter: 0; batch classifier loss: 0.090124; batch adversarial loss: 0.462142\n",
      "epoch 88; iter: 0; batch classifier loss: 0.072357; batch adversarial loss: 0.483958\n",
      "epoch 89; iter: 0; batch classifier loss: 0.040938; batch adversarial loss: 0.395571\n",
      "epoch 90; iter: 0; batch classifier loss: 0.025923; batch adversarial loss: 0.438416\n",
      "epoch 91; iter: 0; batch classifier loss: 0.031754; batch adversarial loss: 0.466247\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074588; batch adversarial loss: 0.410680\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071615; batch adversarial loss: 0.432243\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072228; batch adversarial loss: 0.374248\n",
      "epoch 95; iter: 0; batch classifier loss: 0.033009; batch adversarial loss: 0.549734\n",
      "epoch 96; iter: 0; batch classifier loss: 0.093333; batch adversarial loss: 0.324505\n",
      "epoch 97; iter: 0; batch classifier loss: 0.036392; batch adversarial loss: 0.371226\n",
      "epoch 98; iter: 0; batch classifier loss: 0.037498; batch adversarial loss: 0.442559\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037278; batch adversarial loss: 0.455978\n",
      "epoch 100; iter: 0; batch classifier loss: 0.031867; batch adversarial loss: 0.436345\n",
      "epoch 101; iter: 0; batch classifier loss: 0.028332; batch adversarial loss: 0.407298\n",
      "epoch 102; iter: 0; batch classifier loss: 0.024408; batch adversarial loss: 0.447971\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042045; batch adversarial loss: 0.457811\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053215; batch adversarial loss: 0.455928\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042567; batch adversarial loss: 0.393457\n",
      "epoch 106; iter: 0; batch classifier loss: 0.024936; batch adversarial loss: 0.429168\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044268; batch adversarial loss: 0.463561\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043153; batch adversarial loss: 0.514553\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036651; batch adversarial loss: 0.485885\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026469; batch adversarial loss: 0.432030\n",
      "epoch 111; iter: 0; batch classifier loss: 0.018023; batch adversarial loss: 0.433913\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032199; batch adversarial loss: 0.438958\n",
      "epoch 113; iter: 0; batch classifier loss: 0.030328; batch adversarial loss: 0.410282\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047358; batch adversarial loss: 0.475395\n",
      "epoch 115; iter: 0; batch classifier loss: 0.014460; batch adversarial loss: 0.382452\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036134; batch adversarial loss: 0.496219\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020707; batch adversarial loss: 0.412011\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041705; batch adversarial loss: 0.458264\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046884; batch adversarial loss: 0.465383\n",
      "epoch 120; iter: 0; batch classifier loss: 0.019640; batch adversarial loss: 0.515406\n",
      "epoch 121; iter: 0; batch classifier loss: 0.020773; batch adversarial loss: 0.426965\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031687; batch adversarial loss: 0.437668\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021006; batch adversarial loss: 0.355060\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021713; batch adversarial loss: 0.454861\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017242; batch adversarial loss: 0.565089\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025062; batch adversarial loss: 0.359518\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020185; batch adversarial loss: 0.549197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.043259; batch adversarial loss: 0.464824\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019427; batch adversarial loss: 0.532439\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057318; batch adversarial loss: 0.439000\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015541; batch adversarial loss: 0.436850\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021298; batch adversarial loss: 0.497436\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022512; batch adversarial loss: 0.404285\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027308; batch adversarial loss: 0.458439\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011568; batch adversarial loss: 0.471042\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031173; batch adversarial loss: 0.446258\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049840; batch adversarial loss: 0.380358\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022390; batch adversarial loss: 0.516788\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034352; batch adversarial loss: 0.396477\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029258; batch adversarial loss: 0.475934\n",
      "epoch 141; iter: 0; batch classifier loss: 0.012175; batch adversarial loss: 0.418129\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029649; batch adversarial loss: 0.433563\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033465; batch adversarial loss: 0.500027\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020541; batch adversarial loss: 0.399029\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037288; batch adversarial loss: 0.490084\n",
      "epoch 146; iter: 0; batch classifier loss: 0.004954; batch adversarial loss: 0.547579\n",
      "epoch 147; iter: 0; batch classifier loss: 0.007687; batch adversarial loss: 0.466516\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034305; batch adversarial loss: 0.424427\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017737; batch adversarial loss: 0.487505\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017928; batch adversarial loss: 0.513821\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012488; batch adversarial loss: 0.402215\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008616; batch adversarial loss: 0.459045\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015678; batch adversarial loss: 0.415693\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027906; batch adversarial loss: 0.486792\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019016; batch adversarial loss: 0.486728\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015520; batch adversarial loss: 0.485896\n",
      "epoch 157; iter: 0; batch classifier loss: 0.008493; batch adversarial loss: 0.357253\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029033; batch adversarial loss: 0.460232\n",
      "epoch 159; iter: 0; batch classifier loss: 0.009819; batch adversarial loss: 0.473612\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022317; batch adversarial loss: 0.453195\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013252; batch adversarial loss: 0.440544\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011080; batch adversarial loss: 0.424390\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007016; batch adversarial loss: 0.414610\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024674; batch adversarial loss: 0.500999\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008919; batch adversarial loss: 0.397530\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007475; batch adversarial loss: 0.386816\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012751; batch adversarial loss: 0.356836\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012152; batch adversarial loss: 0.452850\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029074; batch adversarial loss: 0.533901\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027516; batch adversarial loss: 0.488616\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010134; batch adversarial loss: 0.441654\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006027; batch adversarial loss: 0.483766\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024495; batch adversarial loss: 0.464446\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011625; batch adversarial loss: 0.472673\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011256; batch adversarial loss: 0.465521\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024702; batch adversarial loss: 0.393470\n",
      "epoch 177; iter: 0; batch classifier loss: 0.002099; batch adversarial loss: 0.438457\n",
      "epoch 178; iter: 0; batch classifier loss: 0.003760; batch adversarial loss: 0.405992\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033751; batch adversarial loss: 0.546151\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018096; batch adversarial loss: 0.541629\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006115; batch adversarial loss: 0.414160\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011474; batch adversarial loss: 0.451268\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019033; batch adversarial loss: 0.501307\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018447; batch adversarial loss: 0.532372\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006341; batch adversarial loss: 0.524353\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019991; batch adversarial loss: 0.447179\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006427; batch adversarial loss: 0.376408\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013883; batch adversarial loss: 0.449201\n",
      "epoch 189; iter: 0; batch classifier loss: 0.002990; batch adversarial loss: 0.370249\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031758; batch adversarial loss: 0.402699\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026324; batch adversarial loss: 0.516497\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007916; batch adversarial loss: 0.470697\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023550; batch adversarial loss: 0.520996\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004384; batch adversarial loss: 0.482781\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017267; batch adversarial loss: 0.460522\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026652; batch adversarial loss: 0.529983\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004310; batch adversarial loss: 0.458307\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032262; batch adversarial loss: 0.529022\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017415; batch adversarial loss: 0.452811\n",
      "epoch 0; iter: 0; batch classifier loss: 0.664542; batch adversarial loss: 0.951461\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582326; batch adversarial loss: 1.257757\n",
      "epoch 2; iter: 0; batch classifier loss: 0.795657; batch adversarial loss: 1.300510\n",
      "epoch 3; iter: 0; batch classifier loss: 1.057076; batch adversarial loss: 1.189046\n",
      "epoch 4; iter: 0; batch classifier loss: 1.119708; batch adversarial loss: 1.093902\n",
      "epoch 5; iter: 0; batch classifier loss: 1.201705; batch adversarial loss: 1.006512\n",
      "epoch 6; iter: 0; batch classifier loss: 1.119955; batch adversarial loss: 0.906270\n",
      "epoch 7; iter: 0; batch classifier loss: 1.133411; batch adversarial loss: 0.831874\n",
      "epoch 8; iter: 0; batch classifier loss: 1.124509; batch adversarial loss: 0.747853\n",
      "epoch 9; iter: 0; batch classifier loss: 1.159015; batch adversarial loss: 0.681953\n",
      "epoch 10; iter: 0; batch classifier loss: 1.105436; batch adversarial loss: 0.647517\n",
      "epoch 11; iter: 0; batch classifier loss: 0.896323; batch adversarial loss: 0.604137\n",
      "epoch 12; iter: 0; batch classifier loss: 0.919337; batch adversarial loss: 0.566603\n",
      "epoch 13; iter: 0; batch classifier loss: 0.710477; batch adversarial loss: 0.506702\n",
      "epoch 14; iter: 0; batch classifier loss: 0.720682; batch adversarial loss: 0.535497\n",
      "epoch 15; iter: 0; batch classifier loss: 0.385089; batch adversarial loss: 0.514395\n",
      "epoch 16; iter: 0; batch classifier loss: 0.328153; batch adversarial loss: 0.478399\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310758; batch adversarial loss: 0.486317\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214624; batch adversarial loss: 0.430360\n",
      "epoch 19; iter: 0; batch classifier loss: 0.229614; batch adversarial loss: 0.535452\n",
      "epoch 20; iter: 0; batch classifier loss: 0.215010; batch adversarial loss: 0.487399\n",
      "epoch 21; iter: 0; batch classifier loss: 0.210567; batch adversarial loss: 0.495290\n",
      "epoch 22; iter: 0; batch classifier loss: 0.167341; batch adversarial loss: 0.519390\n",
      "epoch 23; iter: 0; batch classifier loss: 0.187824; batch adversarial loss: 0.442157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.119980; batch adversarial loss: 0.421056\n",
      "epoch 25; iter: 0; batch classifier loss: 0.130408; batch adversarial loss: 0.472460\n",
      "epoch 26; iter: 0; batch classifier loss: 0.158818; batch adversarial loss: 0.449134\n",
      "epoch 27; iter: 0; batch classifier loss: 0.153751; batch adversarial loss: 0.479890\n",
      "epoch 28; iter: 0; batch classifier loss: 0.088480; batch adversarial loss: 0.432361\n",
      "epoch 29; iter: 0; batch classifier loss: 0.118435; batch adversarial loss: 0.489224\n",
      "epoch 30; iter: 0; batch classifier loss: 0.086785; batch adversarial loss: 0.446891\n",
      "epoch 31; iter: 0; batch classifier loss: 0.104780; batch adversarial loss: 0.498334\n",
      "epoch 32; iter: 0; batch classifier loss: 0.089255; batch adversarial loss: 0.453138\n",
      "epoch 33; iter: 0; batch classifier loss: 0.120894; batch adversarial loss: 0.468149\n",
      "epoch 34; iter: 0; batch classifier loss: 0.092875; batch adversarial loss: 0.463509\n",
      "epoch 35; iter: 0; batch classifier loss: 0.092540; batch adversarial loss: 0.460224\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123723; batch adversarial loss: 0.459910\n",
      "epoch 37; iter: 0; batch classifier loss: 0.154037; batch adversarial loss: 0.479031\n",
      "epoch 38; iter: 0; batch classifier loss: 0.106378; batch adversarial loss: 0.554325\n",
      "epoch 39; iter: 0; batch classifier loss: 0.181611; batch adversarial loss: 0.489292\n",
      "epoch 40; iter: 0; batch classifier loss: 0.195669; batch adversarial loss: 0.555907\n",
      "epoch 41; iter: 0; batch classifier loss: 0.168404; batch adversarial loss: 0.470290\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115593; batch adversarial loss: 0.400436\n",
      "epoch 43; iter: 0; batch classifier loss: 0.169316; batch adversarial loss: 0.401399\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124091; batch adversarial loss: 0.470194\n",
      "epoch 45; iter: 0; batch classifier loss: 0.122288; batch adversarial loss: 0.425058\n",
      "epoch 46; iter: 0; batch classifier loss: 0.180908; batch adversarial loss: 0.460293\n",
      "epoch 47; iter: 0; batch classifier loss: 0.130620; batch adversarial loss: 0.387261\n",
      "epoch 48; iter: 0; batch classifier loss: 0.153246; batch adversarial loss: 0.489634\n",
      "epoch 49; iter: 0; batch classifier loss: 0.168921; batch adversarial loss: 0.417527\n",
      "epoch 50; iter: 0; batch classifier loss: 0.112207; batch adversarial loss: 0.441988\n",
      "epoch 51; iter: 0; batch classifier loss: 0.093920; batch adversarial loss: 0.442224\n",
      "epoch 52; iter: 0; batch classifier loss: 0.131546; batch adversarial loss: 0.539964\n",
      "epoch 53; iter: 0; batch classifier loss: 0.083273; batch adversarial loss: 0.532005\n",
      "epoch 54; iter: 0; batch classifier loss: 0.154442; batch adversarial loss: 0.523924\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077135; batch adversarial loss: 0.437306\n",
      "epoch 56; iter: 0; batch classifier loss: 0.120969; batch adversarial loss: 0.366491\n",
      "epoch 57; iter: 0; batch classifier loss: 0.063612; batch adversarial loss: 0.487152\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078228; batch adversarial loss: 0.435752\n",
      "epoch 59; iter: 0; batch classifier loss: 0.094266; batch adversarial loss: 0.530638\n",
      "epoch 60; iter: 0; batch classifier loss: 0.075919; batch adversarial loss: 0.412774\n",
      "epoch 61; iter: 0; batch classifier loss: 0.075063; batch adversarial loss: 0.429044\n",
      "epoch 62; iter: 0; batch classifier loss: 0.064098; batch adversarial loss: 0.460216\n",
      "epoch 63; iter: 0; batch classifier loss: 0.084606; batch adversarial loss: 0.423951\n",
      "epoch 64; iter: 0; batch classifier loss: 0.088357; batch adversarial loss: 0.525024\n",
      "epoch 65; iter: 0; batch classifier loss: 0.047607; batch adversarial loss: 0.420950\n",
      "epoch 66; iter: 0; batch classifier loss: 0.082191; batch adversarial loss: 0.454558\n",
      "epoch 67; iter: 0; batch classifier loss: 0.136848; batch adversarial loss: 0.463691\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070555; batch adversarial loss: 0.530531\n",
      "epoch 69; iter: 0; batch classifier loss: 0.050582; batch adversarial loss: 0.461570\n",
      "epoch 70; iter: 0; batch classifier loss: 0.071122; batch adversarial loss: 0.408228\n",
      "epoch 71; iter: 0; batch classifier loss: 0.054027; batch adversarial loss: 0.437124\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087610; batch adversarial loss: 0.330114\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047626; batch adversarial loss: 0.542038\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053484; batch adversarial loss: 0.357527\n",
      "epoch 75; iter: 0; batch classifier loss: 0.057534; batch adversarial loss: 0.536439\n",
      "epoch 76; iter: 0; batch classifier loss: 0.101100; batch adversarial loss: 0.595086\n",
      "epoch 77; iter: 0; batch classifier loss: 0.049054; batch adversarial loss: 0.444897\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072571; batch adversarial loss: 0.423445\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076241; batch adversarial loss: 0.503753\n",
      "epoch 80; iter: 0; batch classifier loss: 0.059275; batch adversarial loss: 0.527818\n",
      "epoch 81; iter: 0; batch classifier loss: 0.041411; batch adversarial loss: 0.391028\n",
      "epoch 82; iter: 0; batch classifier loss: 0.109674; batch adversarial loss: 0.510843\n",
      "epoch 83; iter: 0; batch classifier loss: 0.053952; batch adversarial loss: 0.426606\n",
      "epoch 84; iter: 0; batch classifier loss: 0.032578; batch adversarial loss: 0.469016\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055479; batch adversarial loss: 0.537291\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070203; batch adversarial loss: 0.416736\n",
      "epoch 87; iter: 0; batch classifier loss: 0.075428; batch adversarial loss: 0.350456\n",
      "epoch 88; iter: 0; batch classifier loss: 0.060290; batch adversarial loss: 0.431551\n",
      "epoch 89; iter: 0; batch classifier loss: 0.045054; batch adversarial loss: 0.464221\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067955; batch adversarial loss: 0.461312\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059146; batch adversarial loss: 0.460088\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070915; batch adversarial loss: 0.459725\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063102; batch adversarial loss: 0.532930\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041999; batch adversarial loss: 0.507377\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048033; batch adversarial loss: 0.516194\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051876; batch adversarial loss: 0.482154\n",
      "epoch 97; iter: 0; batch classifier loss: 0.101452; batch adversarial loss: 0.481839\n",
      "epoch 98; iter: 0; batch classifier loss: 0.092928; batch adversarial loss: 0.345905\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067441; batch adversarial loss: 0.448063\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064868; batch adversarial loss: 0.529570\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048133; batch adversarial loss: 0.403328\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031525; batch adversarial loss: 0.510365\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063681; batch adversarial loss: 0.511662\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033227; batch adversarial loss: 0.453205\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037125; batch adversarial loss: 0.346203\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025638; batch adversarial loss: 0.485601\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047464; batch adversarial loss: 0.417048\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044791; batch adversarial loss: 0.401000\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070705; batch adversarial loss: 0.397871\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033280; batch adversarial loss: 0.460737\n",
      "epoch 111; iter: 0; batch classifier loss: 0.065528; batch adversarial loss: 0.395742\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027779; batch adversarial loss: 0.512058\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033989; batch adversarial loss: 0.464634\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047772; batch adversarial loss: 0.471577\n",
      "epoch 115; iter: 0; batch classifier loss: 0.074994; batch adversarial loss: 0.484200\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038361; batch adversarial loss: 0.397751\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048305; batch adversarial loss: 0.368429\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045909; batch adversarial loss: 0.458820\n",
      "epoch 119; iter: 0; batch classifier loss: 0.014023; batch adversarial loss: 0.466458\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047962; batch adversarial loss: 0.400251\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049043; batch adversarial loss: 0.428924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.008579; batch adversarial loss: 0.487828\n",
      "epoch 123; iter: 0; batch classifier loss: 0.054208; batch adversarial loss: 0.397501\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046554; batch adversarial loss: 0.431664\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056121; batch adversarial loss: 0.448573\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028972; batch adversarial loss: 0.508959\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030212; batch adversarial loss: 0.464281\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027709; batch adversarial loss: 0.518679\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022755; batch adversarial loss: 0.460470\n",
      "epoch 130; iter: 0; batch classifier loss: 0.075413; batch adversarial loss: 0.530982\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021119; batch adversarial loss: 0.441298\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016318; batch adversarial loss: 0.502964\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032697; batch adversarial loss: 0.483559\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016151; batch adversarial loss: 0.510518\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044768; batch adversarial loss: 0.467846\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054843; batch adversarial loss: 0.514811\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030590; batch adversarial loss: 0.426016\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028019; batch adversarial loss: 0.450995\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023867; batch adversarial loss: 0.418893\n",
      "epoch 140; iter: 0; batch classifier loss: 0.016519; batch adversarial loss: 0.569316\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030812; batch adversarial loss: 0.494234\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021652; batch adversarial loss: 0.440675\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042131; batch adversarial loss: 0.442228\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027133; batch adversarial loss: 0.423505\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021525; batch adversarial loss: 0.583904\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042182; batch adversarial loss: 0.482480\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022975; batch adversarial loss: 0.508408\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014851; batch adversarial loss: 0.496216\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021830; batch adversarial loss: 0.535484\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027246; batch adversarial loss: 0.444872\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010178; batch adversarial loss: 0.441899\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039130; batch adversarial loss: 0.392274\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010272; batch adversarial loss: 0.538270\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021359; batch adversarial loss: 0.467008\n",
      "epoch 155; iter: 0; batch classifier loss: 0.065679; batch adversarial loss: 0.386926\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022720; batch adversarial loss: 0.434502\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018044; batch adversarial loss: 0.391001\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012298; batch adversarial loss: 0.453024\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045023; batch adversarial loss: 0.546036\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028159; batch adversarial loss: 0.489656\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032184; batch adversarial loss: 0.319348\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030398; batch adversarial loss: 0.568790\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006019; batch adversarial loss: 0.494216\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027287; batch adversarial loss: 0.466822\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044909; batch adversarial loss: 0.502746\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019247; batch adversarial loss: 0.410194\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023875; batch adversarial loss: 0.443687\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007464; batch adversarial loss: 0.444684\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013087; batch adversarial loss: 0.381128\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028358; batch adversarial loss: 0.394491\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022690; batch adversarial loss: 0.477064\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024439; batch adversarial loss: 0.450978\n",
      "epoch 173; iter: 0; batch classifier loss: 0.044595; batch adversarial loss: 0.399622\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013978; batch adversarial loss: 0.470169\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025249; batch adversarial loss: 0.458851\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019911; batch adversarial loss: 0.442824\n",
      "epoch 177; iter: 0; batch classifier loss: 0.053272; batch adversarial loss: 0.533459\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009191; batch adversarial loss: 0.431878\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022098; batch adversarial loss: 0.447871\n",
      "epoch 180; iter: 0; batch classifier loss: 0.058186; batch adversarial loss: 0.428936\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013819; batch adversarial loss: 0.450145\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037828; batch adversarial loss: 0.414772\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020975; batch adversarial loss: 0.470977\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014826; batch adversarial loss: 0.495667\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020593; batch adversarial loss: 0.429757\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012572; batch adversarial loss: 0.438605\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011654; batch adversarial loss: 0.460470\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007920; batch adversarial loss: 0.436012\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009744; batch adversarial loss: 0.537335\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030409; batch adversarial loss: 0.429263\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027883; batch adversarial loss: 0.431609\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007844; batch adversarial loss: 0.407720\n",
      "epoch 193; iter: 0; batch classifier loss: 0.002965; batch adversarial loss: 0.563817\n",
      "epoch 194; iter: 0; batch classifier loss: 0.001895; batch adversarial loss: 0.514887\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011574; batch adversarial loss: 0.406205\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032209; batch adversarial loss: 0.442735\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015568; batch adversarial loss: 0.430795\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026419; batch adversarial loss: 0.551146\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020212; batch adversarial loss: 0.436626\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687861; batch adversarial loss: 0.749057\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628140; batch adversarial loss: 0.750769\n",
      "epoch 2; iter: 0; batch classifier loss: 0.658807; batch adversarial loss: 0.736034\n",
      "epoch 3; iter: 0; batch classifier loss: 0.567747; batch adversarial loss: 0.637754\n",
      "epoch 4; iter: 0; batch classifier loss: 0.453939; batch adversarial loss: 0.642473\n",
      "epoch 5; iter: 0; batch classifier loss: 0.322912; batch adversarial loss: 0.568506\n",
      "epoch 6; iter: 0; batch classifier loss: 0.394783; batch adversarial loss: 0.557436\n",
      "epoch 7; iter: 0; batch classifier loss: 0.312532; batch adversarial loss: 0.559692\n",
      "epoch 8; iter: 0; batch classifier loss: 0.275386; batch adversarial loss: 0.567575\n",
      "epoch 9; iter: 0; batch classifier loss: 0.265470; batch adversarial loss: 0.511573\n",
      "epoch 10; iter: 0; batch classifier loss: 0.321031; batch adversarial loss: 0.513200\n",
      "epoch 11; iter: 0; batch classifier loss: 0.308892; batch adversarial loss: 0.482254\n",
      "epoch 12; iter: 0; batch classifier loss: 0.300931; batch adversarial loss: 0.516060\n",
      "epoch 13; iter: 0; batch classifier loss: 0.216118; batch adversarial loss: 0.543923\n",
      "epoch 14; iter: 0; batch classifier loss: 0.210870; batch adversarial loss: 0.499265\n",
      "epoch 15; iter: 0; batch classifier loss: 0.173126; batch adversarial loss: 0.514637\n",
      "epoch 16; iter: 0; batch classifier loss: 0.158673; batch adversarial loss: 0.487733\n",
      "epoch 17; iter: 0; batch classifier loss: 0.186005; batch adversarial loss: 0.422269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.205639; batch adversarial loss: 0.545614\n",
      "epoch 19; iter: 0; batch classifier loss: 0.185278; batch adversarial loss: 0.508203\n",
      "epoch 20; iter: 0; batch classifier loss: 0.238416; batch adversarial loss: 0.529824\n",
      "epoch 21; iter: 0; batch classifier loss: 0.155986; batch adversarial loss: 0.479392\n",
      "epoch 22; iter: 0; batch classifier loss: 0.185030; batch adversarial loss: 0.434958\n",
      "epoch 23; iter: 0; batch classifier loss: 0.134946; batch adversarial loss: 0.499939\n",
      "epoch 24; iter: 0; batch classifier loss: 0.089562; batch adversarial loss: 0.514729\n",
      "epoch 25; iter: 0; batch classifier loss: 0.165663; batch adversarial loss: 0.460932\n",
      "epoch 26; iter: 0; batch classifier loss: 0.224167; batch adversarial loss: 0.461874\n",
      "epoch 27; iter: 0; batch classifier loss: 0.222424; batch adversarial loss: 0.531342\n",
      "epoch 28; iter: 0; batch classifier loss: 0.136513; batch adversarial loss: 0.457994\n",
      "epoch 29; iter: 0; batch classifier loss: 0.141554; batch adversarial loss: 0.479961\n",
      "epoch 30; iter: 0; batch classifier loss: 0.125185; batch adversarial loss: 0.492336\n",
      "epoch 31; iter: 0; batch classifier loss: 0.135585; batch adversarial loss: 0.532470\n",
      "epoch 32; iter: 0; batch classifier loss: 0.153592; batch adversarial loss: 0.459437\n",
      "epoch 33; iter: 0; batch classifier loss: 0.161724; batch adversarial loss: 0.583706\n",
      "epoch 34; iter: 0; batch classifier loss: 0.109335; batch adversarial loss: 0.437267\n",
      "epoch 35; iter: 0; batch classifier loss: 0.167754; batch adversarial loss: 0.468951\n",
      "epoch 36; iter: 0; batch classifier loss: 0.113515; batch adversarial loss: 0.514805\n",
      "epoch 37; iter: 0; batch classifier loss: 0.136833; batch adversarial loss: 0.473583\n",
      "epoch 38; iter: 0; batch classifier loss: 0.142707; batch adversarial loss: 0.519704\n",
      "epoch 39; iter: 0; batch classifier loss: 0.154576; batch adversarial loss: 0.486387\n",
      "epoch 40; iter: 0; batch classifier loss: 0.156263; batch adversarial loss: 0.519699\n",
      "epoch 41; iter: 0; batch classifier loss: 0.176615; batch adversarial loss: 0.483625\n",
      "epoch 42; iter: 0; batch classifier loss: 0.180978; batch adversarial loss: 0.416637\n",
      "epoch 43; iter: 0; batch classifier loss: 0.099748; batch adversarial loss: 0.434586\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112055; batch adversarial loss: 0.483991\n",
      "epoch 45; iter: 0; batch classifier loss: 0.154454; batch adversarial loss: 0.439432\n",
      "epoch 46; iter: 0; batch classifier loss: 0.120354; batch adversarial loss: 0.488635\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119719; batch adversarial loss: 0.530339\n",
      "epoch 48; iter: 0; batch classifier loss: 0.114572; batch adversarial loss: 0.412430\n",
      "epoch 49; iter: 0; batch classifier loss: 0.088401; batch adversarial loss: 0.586971\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101503; batch adversarial loss: 0.475189\n",
      "epoch 51; iter: 0; batch classifier loss: 0.128885; batch adversarial loss: 0.439083\n",
      "epoch 52; iter: 0; batch classifier loss: 0.107352; batch adversarial loss: 0.550327\n",
      "epoch 53; iter: 0; batch classifier loss: 0.111569; batch adversarial loss: 0.482991\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102141; batch adversarial loss: 0.386880\n",
      "epoch 55; iter: 0; batch classifier loss: 0.135920; batch adversarial loss: 0.498817\n",
      "epoch 56; iter: 0; batch classifier loss: 0.066145; batch adversarial loss: 0.619811\n",
      "epoch 57; iter: 0; batch classifier loss: 0.125573; batch adversarial loss: 0.416754\n",
      "epoch 58; iter: 0; batch classifier loss: 0.106187; batch adversarial loss: 0.402551\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087278; batch adversarial loss: 0.325576\n",
      "epoch 60; iter: 0; batch classifier loss: 0.149688; batch adversarial loss: 0.437770\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071915; batch adversarial loss: 0.446357\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120700; batch adversarial loss: 0.424014\n",
      "epoch 63; iter: 0; batch classifier loss: 0.090424; batch adversarial loss: 0.502936\n",
      "epoch 64; iter: 0; batch classifier loss: 0.117308; batch adversarial loss: 0.539372\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092489; batch adversarial loss: 0.426543\n",
      "epoch 66; iter: 0; batch classifier loss: 0.125983; batch adversarial loss: 0.402908\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098403; batch adversarial loss: 0.362221\n",
      "epoch 68; iter: 0; batch classifier loss: 0.063382; batch adversarial loss: 0.560043\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095541; batch adversarial loss: 0.434004\n",
      "epoch 70; iter: 0; batch classifier loss: 0.068556; batch adversarial loss: 0.378375\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076244; batch adversarial loss: 0.386338\n",
      "epoch 72; iter: 0; batch classifier loss: 0.104720; batch adversarial loss: 0.486005\n",
      "epoch 73; iter: 0; batch classifier loss: 0.088048; batch adversarial loss: 0.488343\n",
      "epoch 74; iter: 0; batch classifier loss: 0.091473; batch adversarial loss: 0.407714\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079106; batch adversarial loss: 0.526397\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103679; batch adversarial loss: 0.446415\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056973; batch adversarial loss: 0.430026\n",
      "epoch 78; iter: 0; batch classifier loss: 0.057157; batch adversarial loss: 0.509367\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072752; batch adversarial loss: 0.371459\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088201; batch adversarial loss: 0.361785\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055166; batch adversarial loss: 0.448115\n",
      "epoch 82; iter: 0; batch classifier loss: 0.112014; batch adversarial loss: 0.433978\n",
      "epoch 83; iter: 0; batch classifier loss: 0.093326; batch adversarial loss: 0.413128\n",
      "epoch 84; iter: 0; batch classifier loss: 0.111201; batch adversarial loss: 0.448544\n",
      "epoch 85; iter: 0; batch classifier loss: 0.054309; batch adversarial loss: 0.333227\n",
      "epoch 86; iter: 0; batch classifier loss: 0.049870; batch adversarial loss: 0.443968\n",
      "epoch 87; iter: 0; batch classifier loss: 0.084660; batch adversarial loss: 0.397246\n",
      "epoch 88; iter: 0; batch classifier loss: 0.072486; batch adversarial loss: 0.422862\n",
      "epoch 89; iter: 0; batch classifier loss: 0.110502; batch adversarial loss: 0.498079\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073197; batch adversarial loss: 0.498514\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046184; batch adversarial loss: 0.527428\n",
      "epoch 92; iter: 0; batch classifier loss: 0.054855; batch adversarial loss: 0.378666\n",
      "epoch 93; iter: 0; batch classifier loss: 0.076558; batch adversarial loss: 0.468052\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062228; batch adversarial loss: 0.447313\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040644; batch adversarial loss: 0.461862\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042066; batch adversarial loss: 0.479282\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050554; batch adversarial loss: 0.589055\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048952; batch adversarial loss: 0.440895\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054520; batch adversarial loss: 0.430066\n",
      "epoch 100; iter: 0; batch classifier loss: 0.124175; batch adversarial loss: 0.440390\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071624; batch adversarial loss: 0.453362\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067138; batch adversarial loss: 0.371328\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066979; batch adversarial loss: 0.472294\n",
      "epoch 104; iter: 0; batch classifier loss: 0.093923; batch adversarial loss: 0.371701\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062399; batch adversarial loss: 0.437341\n",
      "epoch 106; iter: 0; batch classifier loss: 0.072160; batch adversarial loss: 0.386812\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041398; batch adversarial loss: 0.463110\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059898; batch adversarial loss: 0.514248\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033529; batch adversarial loss: 0.483605\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039856; batch adversarial loss: 0.556612\n",
      "epoch 111; iter: 0; batch classifier loss: 0.017435; batch adversarial loss: 0.421351\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039934; batch adversarial loss: 0.479618\n",
      "epoch 113; iter: 0; batch classifier loss: 0.067159; batch adversarial loss: 0.458845\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046152; batch adversarial loss: 0.391105\n",
      "epoch 115; iter: 0; batch classifier loss: 0.023928; batch adversarial loss: 0.480994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.058573; batch adversarial loss: 0.428827\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020037; batch adversarial loss: 0.524646\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050631; batch adversarial loss: 0.449378\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029458; batch adversarial loss: 0.509465\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034504; batch adversarial loss: 0.487704\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024263; batch adversarial loss: 0.483481\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038112; batch adversarial loss: 0.443317\n",
      "epoch 123; iter: 0; batch classifier loss: 0.061456; batch adversarial loss: 0.444235\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048991; batch adversarial loss: 0.506431\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040043; batch adversarial loss: 0.499683\n",
      "epoch 126; iter: 0; batch classifier loss: 0.053903; batch adversarial loss: 0.523420\n",
      "epoch 127; iter: 0; batch classifier loss: 0.068859; batch adversarial loss: 0.443965\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025960; batch adversarial loss: 0.361722\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021138; batch adversarial loss: 0.495396\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037036; batch adversarial loss: 0.445404\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028228; batch adversarial loss: 0.429976\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032181; batch adversarial loss: 0.443951\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018248; batch adversarial loss: 0.583952\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025629; batch adversarial loss: 0.502431\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023315; batch adversarial loss: 0.465237\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033419; batch adversarial loss: 0.468825\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043733; batch adversarial loss: 0.470080\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036902; batch adversarial loss: 0.474117\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023275; batch adversarial loss: 0.474143\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020294; batch adversarial loss: 0.379724\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029709; batch adversarial loss: 0.462524\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014329; batch adversarial loss: 0.389730\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024257; batch adversarial loss: 0.457435\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020643; batch adversarial loss: 0.450591\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037760; batch adversarial loss: 0.405543\n",
      "epoch 146; iter: 0; batch classifier loss: 0.054145; batch adversarial loss: 0.448388\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032025; batch adversarial loss: 0.512889\n",
      "epoch 148; iter: 0; batch classifier loss: 0.060473; batch adversarial loss: 0.397284\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024475; batch adversarial loss: 0.424408\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037588; batch adversarial loss: 0.406345\n",
      "epoch 151; iter: 0; batch classifier loss: 0.054335; batch adversarial loss: 0.434080\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034288; batch adversarial loss: 0.382160\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025297; batch adversarial loss: 0.555554\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035494; batch adversarial loss: 0.446455\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044880; batch adversarial loss: 0.490205\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035463; batch adversarial loss: 0.458300\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047047; batch adversarial loss: 0.486851\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013431; batch adversarial loss: 0.460713\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015344; batch adversarial loss: 0.475325\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009490; batch adversarial loss: 0.533798\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024546; batch adversarial loss: 0.471234\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007811; batch adversarial loss: 0.472056\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011105; batch adversarial loss: 0.515810\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030592; batch adversarial loss: 0.465830\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022324; batch adversarial loss: 0.459783\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027886; batch adversarial loss: 0.454773\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016642; batch adversarial loss: 0.477921\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025166; batch adversarial loss: 0.460903\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020932; batch adversarial loss: 0.423652\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012487; batch adversarial loss: 0.451026\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028828; batch adversarial loss: 0.467586\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028390; batch adversarial loss: 0.438376\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015464; batch adversarial loss: 0.513886\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031367; batch adversarial loss: 0.544153\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015743; batch adversarial loss: 0.401533\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035562; batch adversarial loss: 0.476809\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020564; batch adversarial loss: 0.368899\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024037; batch adversarial loss: 0.456743\n",
      "epoch 179; iter: 0; batch classifier loss: 0.047945; batch adversarial loss: 0.404948\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026641; batch adversarial loss: 0.470814\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024652; batch adversarial loss: 0.430628\n",
      "epoch 182; iter: 0; batch classifier loss: 0.043064; batch adversarial loss: 0.517848\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007202; batch adversarial loss: 0.466741\n",
      "epoch 184; iter: 0; batch classifier loss: 0.054839; batch adversarial loss: 0.421552\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036302; batch adversarial loss: 0.434004\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012620; batch adversarial loss: 0.426396\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013468; batch adversarial loss: 0.342499\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003509; batch adversarial loss: 0.491117\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019729; batch adversarial loss: 0.462054\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035315; batch adversarial loss: 0.431121\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031259; batch adversarial loss: 0.441978\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014152; batch adversarial loss: 0.548789\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006749; batch adversarial loss: 0.449212\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012194; batch adversarial loss: 0.460411\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008773; batch adversarial loss: 0.387091\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016233; batch adversarial loss: 0.460019\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005983; batch adversarial loss: 0.343525\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022271; batch adversarial loss: 0.377620\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028391; batch adversarial loss: 0.471297\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694826; batch adversarial loss: 0.668801\n",
      "epoch 1; iter: 0; batch classifier loss: 0.500373; batch adversarial loss: 0.641709\n",
      "epoch 2; iter: 0; batch classifier loss: 0.429323; batch adversarial loss: 0.625377\n",
      "epoch 3; iter: 0; batch classifier loss: 0.469430; batch adversarial loss: 0.608065\n",
      "epoch 4; iter: 0; batch classifier loss: 0.468550; batch adversarial loss: 0.597900\n",
      "epoch 5; iter: 0; batch classifier loss: 0.454286; batch adversarial loss: 0.604985\n",
      "epoch 6; iter: 0; batch classifier loss: 0.469451; batch adversarial loss: 0.616913\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582964; batch adversarial loss: 0.561529\n",
      "epoch 8; iter: 0; batch classifier loss: 0.451054; batch adversarial loss: 0.562199\n",
      "epoch 9; iter: 0; batch classifier loss: 0.395967; batch adversarial loss: 0.553004\n",
      "epoch 10; iter: 0; batch classifier loss: 0.451062; batch adversarial loss: 0.536343\n",
      "epoch 11; iter: 0; batch classifier loss: 0.464447; batch adversarial loss: 0.494912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.386745; batch adversarial loss: 0.528139\n",
      "epoch 13; iter: 0; batch classifier loss: 0.258181; batch adversarial loss: 0.531195\n",
      "epoch 14; iter: 0; batch classifier loss: 0.358394; batch adversarial loss: 0.544574\n",
      "epoch 15; iter: 0; batch classifier loss: 0.333563; batch adversarial loss: 0.493042\n",
      "epoch 16; iter: 0; batch classifier loss: 0.299499; batch adversarial loss: 0.505877\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310281; batch adversarial loss: 0.417020\n",
      "epoch 18; iter: 0; batch classifier loss: 0.257910; batch adversarial loss: 0.481842\n",
      "epoch 19; iter: 0; batch classifier loss: 0.242168; batch adversarial loss: 0.501363\n",
      "epoch 20; iter: 0; batch classifier loss: 0.295476; batch adversarial loss: 0.483241\n",
      "epoch 21; iter: 0; batch classifier loss: 0.297634; batch adversarial loss: 0.470331\n",
      "epoch 22; iter: 0; batch classifier loss: 0.255446; batch adversarial loss: 0.375158\n",
      "epoch 23; iter: 0; batch classifier loss: 0.306859; batch adversarial loss: 0.432695\n",
      "epoch 24; iter: 0; batch classifier loss: 0.261279; batch adversarial loss: 0.426490\n",
      "epoch 25; iter: 0; batch classifier loss: 0.191115; batch adversarial loss: 0.484000\n",
      "epoch 26; iter: 0; batch classifier loss: 0.191462; batch adversarial loss: 0.437794\n",
      "epoch 27; iter: 0; batch classifier loss: 0.216777; batch adversarial loss: 0.519396\n",
      "epoch 28; iter: 0; batch classifier loss: 0.195612; batch adversarial loss: 0.478777\n",
      "epoch 29; iter: 0; batch classifier loss: 0.183104; batch adversarial loss: 0.432709\n",
      "epoch 30; iter: 0; batch classifier loss: 0.178885; batch adversarial loss: 0.473491\n",
      "epoch 31; iter: 0; batch classifier loss: 0.172833; batch adversarial loss: 0.481737\n",
      "epoch 32; iter: 0; batch classifier loss: 0.171893; batch adversarial loss: 0.490897\n",
      "epoch 33; iter: 0; batch classifier loss: 0.211451; batch adversarial loss: 0.505813\n",
      "epoch 34; iter: 0; batch classifier loss: 0.159608; batch adversarial loss: 0.512942\n",
      "epoch 35; iter: 0; batch classifier loss: 0.168324; batch adversarial loss: 0.550039\n",
      "epoch 36; iter: 0; batch classifier loss: 0.153491; batch adversarial loss: 0.515860\n",
      "epoch 37; iter: 0; batch classifier loss: 0.164096; batch adversarial loss: 0.406276\n",
      "epoch 38; iter: 0; batch classifier loss: 0.220429; batch adversarial loss: 0.377927\n",
      "epoch 39; iter: 0; batch classifier loss: 0.177897; batch adversarial loss: 0.454575\n",
      "epoch 40; iter: 0; batch classifier loss: 0.157715; batch adversarial loss: 0.425883\n",
      "epoch 41; iter: 0; batch classifier loss: 0.160138; batch adversarial loss: 0.547093\n",
      "epoch 42; iter: 0; batch classifier loss: 0.124035; batch adversarial loss: 0.534307\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117742; batch adversarial loss: 0.493554\n",
      "epoch 44; iter: 0; batch classifier loss: 0.182413; batch adversarial loss: 0.487336\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104051; batch adversarial loss: 0.489570\n",
      "epoch 46; iter: 0; batch classifier loss: 0.143484; batch adversarial loss: 0.489952\n",
      "epoch 47; iter: 0; batch classifier loss: 0.166432; batch adversarial loss: 0.355069\n",
      "epoch 48; iter: 0; batch classifier loss: 0.178069; batch adversarial loss: 0.375112\n",
      "epoch 49; iter: 0; batch classifier loss: 0.125342; batch adversarial loss: 0.406437\n",
      "epoch 50; iter: 0; batch classifier loss: 0.194301; batch adversarial loss: 0.420419\n",
      "epoch 51; iter: 0; batch classifier loss: 0.144519; batch adversarial loss: 0.449505\n",
      "epoch 52; iter: 0; batch classifier loss: 0.097563; batch adversarial loss: 0.441398\n",
      "epoch 53; iter: 0; batch classifier loss: 0.144894; batch adversarial loss: 0.450710\n",
      "epoch 54; iter: 0; batch classifier loss: 0.140319; batch adversarial loss: 0.447480\n",
      "epoch 55; iter: 0; batch classifier loss: 0.140240; batch adversarial loss: 0.457715\n",
      "epoch 56; iter: 0; batch classifier loss: 0.153978; batch adversarial loss: 0.456962\n",
      "epoch 57; iter: 0; batch classifier loss: 0.141618; batch adversarial loss: 0.423525\n",
      "epoch 58; iter: 0; batch classifier loss: 0.121216; batch adversarial loss: 0.436458\n",
      "epoch 59; iter: 0; batch classifier loss: 0.134574; batch adversarial loss: 0.448523\n",
      "epoch 60; iter: 0; batch classifier loss: 0.147146; batch adversarial loss: 0.492134\n",
      "epoch 61; iter: 0; batch classifier loss: 0.188085; batch adversarial loss: 0.438817\n",
      "epoch 62; iter: 0; batch classifier loss: 0.124852; batch adversarial loss: 0.435108\n",
      "epoch 63; iter: 0; batch classifier loss: 0.152376; batch adversarial loss: 0.568158\n",
      "epoch 64; iter: 0; batch classifier loss: 0.135771; batch adversarial loss: 0.518545\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122806; batch adversarial loss: 0.456066\n",
      "epoch 66; iter: 0; batch classifier loss: 0.161210; batch adversarial loss: 0.433378\n",
      "epoch 67; iter: 0; batch classifier loss: 0.054506; batch adversarial loss: 0.404233\n",
      "epoch 68; iter: 0; batch classifier loss: 0.148483; batch adversarial loss: 0.448430\n",
      "epoch 69; iter: 0; batch classifier loss: 0.126091; batch adversarial loss: 0.447329\n",
      "epoch 70; iter: 0; batch classifier loss: 0.120008; batch adversarial loss: 0.422380\n",
      "epoch 71; iter: 0; batch classifier loss: 0.151377; batch adversarial loss: 0.492404\n",
      "epoch 72; iter: 0; batch classifier loss: 0.143846; batch adversarial loss: 0.420308\n",
      "epoch 73; iter: 0; batch classifier loss: 0.138819; batch adversarial loss: 0.408226\n",
      "epoch 74; iter: 0; batch classifier loss: 0.138714; batch adversarial loss: 0.484541\n",
      "epoch 75; iter: 0; batch classifier loss: 0.156065; batch adversarial loss: 0.438522\n",
      "epoch 76; iter: 0; batch classifier loss: 0.093310; batch adversarial loss: 0.417682\n",
      "epoch 77; iter: 0; batch classifier loss: 0.140331; batch adversarial loss: 0.356460\n",
      "epoch 78; iter: 0; batch classifier loss: 0.124071; batch adversarial loss: 0.430962\n",
      "epoch 79; iter: 0; batch classifier loss: 0.204066; batch adversarial loss: 0.457932\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084779; batch adversarial loss: 0.411599\n",
      "epoch 81; iter: 0; batch classifier loss: 0.103017; batch adversarial loss: 0.484091\n",
      "epoch 82; iter: 0; batch classifier loss: 0.163678; batch adversarial loss: 0.346517\n",
      "epoch 83; iter: 0; batch classifier loss: 0.135677; batch adversarial loss: 0.446204\n",
      "epoch 84; iter: 0; batch classifier loss: 0.099145; batch adversarial loss: 0.494415\n",
      "epoch 85; iter: 0; batch classifier loss: 0.115636; batch adversarial loss: 0.466820\n",
      "epoch 86; iter: 0; batch classifier loss: 0.116551; batch adversarial loss: 0.456446\n",
      "epoch 87; iter: 0; batch classifier loss: 0.181577; batch adversarial loss: 0.447559\n",
      "epoch 88; iter: 0; batch classifier loss: 0.105712; batch adversarial loss: 0.515765\n",
      "epoch 89; iter: 0; batch classifier loss: 0.123831; batch adversarial loss: 0.496749\n",
      "epoch 90; iter: 0; batch classifier loss: 0.124479; batch adversarial loss: 0.444217\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083875; batch adversarial loss: 0.475469\n",
      "epoch 92; iter: 0; batch classifier loss: 0.110721; batch adversarial loss: 0.392448\n",
      "epoch 93; iter: 0; batch classifier loss: 0.145831; batch adversarial loss: 0.466244\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062971; batch adversarial loss: 0.400761\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047217; batch adversarial loss: 0.514730\n",
      "epoch 96; iter: 0; batch classifier loss: 0.141658; batch adversarial loss: 0.425351\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071616; batch adversarial loss: 0.441140\n",
      "epoch 98; iter: 0; batch classifier loss: 0.128565; batch adversarial loss: 0.382592\n",
      "epoch 99; iter: 0; batch classifier loss: 0.109329; batch adversarial loss: 0.512556\n",
      "epoch 100; iter: 0; batch classifier loss: 0.041924; batch adversarial loss: 0.466313\n",
      "epoch 101; iter: 0; batch classifier loss: 0.080153; batch adversarial loss: 0.522840\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079500; batch adversarial loss: 0.458414\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053729; batch adversarial loss: 0.444368\n",
      "epoch 104; iter: 0; batch classifier loss: 0.022293; batch adversarial loss: 0.542850\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038583; batch adversarial loss: 0.519238\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058552; batch adversarial loss: 0.444721\n",
      "epoch 107; iter: 0; batch classifier loss: 0.089671; batch adversarial loss: 0.398343\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033889; batch adversarial loss: 0.385113\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032072; batch adversarial loss: 0.495865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.057931; batch adversarial loss: 0.529294\n",
      "epoch 111; iter: 0; batch classifier loss: 0.068491; batch adversarial loss: 0.386816\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041066; batch adversarial loss: 0.364423\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050755; batch adversarial loss: 0.463441\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062355; batch adversarial loss: 0.337458\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059781; batch adversarial loss: 0.419640\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029111; batch adversarial loss: 0.460319\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027655; batch adversarial loss: 0.341938\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040998; batch adversarial loss: 0.476711\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043374; batch adversarial loss: 0.428020\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037340; batch adversarial loss: 0.385080\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026484; batch adversarial loss: 0.428860\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046039; batch adversarial loss: 0.423143\n",
      "epoch 123; iter: 0; batch classifier loss: 0.054966; batch adversarial loss: 0.503439\n",
      "epoch 124; iter: 0; batch classifier loss: 0.075805; batch adversarial loss: 0.472344\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026856; batch adversarial loss: 0.509132\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035665; batch adversarial loss: 0.508043\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028425; batch adversarial loss: 0.546089\n",
      "epoch 128; iter: 0; batch classifier loss: 0.067882; batch adversarial loss: 0.409934\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029191; batch adversarial loss: 0.556206\n",
      "epoch 130; iter: 0; batch classifier loss: 0.091949; batch adversarial loss: 0.437731\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044770; batch adversarial loss: 0.412843\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044583; batch adversarial loss: 0.521134\n",
      "epoch 133; iter: 0; batch classifier loss: 0.009076; batch adversarial loss: 0.398149\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021859; batch adversarial loss: 0.476456\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041343; batch adversarial loss: 0.448767\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037575; batch adversarial loss: 0.426289\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027702; batch adversarial loss: 0.444517\n",
      "epoch 138; iter: 0; batch classifier loss: 0.008906; batch adversarial loss: 0.435375\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040222; batch adversarial loss: 0.400491\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023970; batch adversarial loss: 0.428050\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018626; batch adversarial loss: 0.509623\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014083; batch adversarial loss: 0.429081\n",
      "epoch 143; iter: 0; batch classifier loss: 0.008116; batch adversarial loss: 0.491796\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012555; batch adversarial loss: 0.502256\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020506; batch adversarial loss: 0.435164\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044738; batch adversarial loss: 0.392078\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016050; batch adversarial loss: 0.410879\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021262; batch adversarial loss: 0.488636\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040762; batch adversarial loss: 0.428690\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018666; batch adversarial loss: 0.455263\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028512; batch adversarial loss: 0.453154\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040258; batch adversarial loss: 0.438139\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024535; batch adversarial loss: 0.460502\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035269; batch adversarial loss: 0.425258\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046158; batch adversarial loss: 0.401600\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011728; batch adversarial loss: 0.450578\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017404; batch adversarial loss: 0.384975\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011957; batch adversarial loss: 0.441970\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022416; batch adversarial loss: 0.463518\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013964; batch adversarial loss: 0.383308\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019502; batch adversarial loss: 0.507137\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013859; batch adversarial loss: 0.512983\n",
      "epoch 163; iter: 0; batch classifier loss: 0.005167; batch adversarial loss: 0.541564\n",
      "epoch 164; iter: 0; batch classifier loss: 0.053208; batch adversarial loss: 0.484422\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027285; batch adversarial loss: 0.449979\n",
      "epoch 166; iter: 0; batch classifier loss: 0.053181; batch adversarial loss: 0.527380\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012399; batch adversarial loss: 0.472927\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019000; batch adversarial loss: 0.423357\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030618; batch adversarial loss: 0.508574\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021935; batch adversarial loss: 0.516359\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018485; batch adversarial loss: 0.414519\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023744; batch adversarial loss: 0.452425\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023262; batch adversarial loss: 0.470890\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017442; batch adversarial loss: 0.370124\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008876; batch adversarial loss: 0.448964\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012509; batch adversarial loss: 0.471204\n",
      "epoch 177; iter: 0; batch classifier loss: 0.040498; batch adversarial loss: 0.417451\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006581; batch adversarial loss: 0.460674\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022265; batch adversarial loss: 0.576915\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012795; batch adversarial loss: 0.415885\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012112; batch adversarial loss: 0.434584\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008639; batch adversarial loss: 0.429940\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030339; batch adversarial loss: 0.538831\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011459; batch adversarial loss: 0.466178\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018587; batch adversarial loss: 0.496696\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008324; batch adversarial loss: 0.434131\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012659; batch adversarial loss: 0.528569\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032933; batch adversarial loss: 0.453336\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026937; batch adversarial loss: 0.478098\n",
      "epoch 190; iter: 0; batch classifier loss: 0.003739; batch adversarial loss: 0.437688\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029125; batch adversarial loss: 0.494621\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012525; batch adversarial loss: 0.412536\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007842; batch adversarial loss: 0.396595\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011779; batch adversarial loss: 0.461993\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009659; batch adversarial loss: 0.434677\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013630; batch adversarial loss: 0.433126\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025899; batch adversarial loss: 0.399695\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013564; batch adversarial loss: 0.525232\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005954; batch adversarial loss: 0.550496\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705270; batch adversarial loss: 0.712412\n",
      "epoch 1; iter: 0; batch classifier loss: 0.383308; batch adversarial loss: 0.658374\n",
      "epoch 2; iter: 0; batch classifier loss: 0.364609; batch adversarial loss: 0.616362\n",
      "epoch 3; iter: 0; batch classifier loss: 0.405014; batch adversarial loss: 0.592695\n",
      "epoch 4; iter: 0; batch classifier loss: 0.399919; batch adversarial loss: 0.635978\n",
      "epoch 5; iter: 0; batch classifier loss: 0.341124; batch adversarial loss: 0.599492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.432924; batch adversarial loss: 0.572458\n",
      "epoch 7; iter: 0; batch classifier loss: 0.376965; batch adversarial loss: 0.562446\n",
      "epoch 8; iter: 0; batch classifier loss: 0.357939; batch adversarial loss: 0.556673\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536928; batch adversarial loss: 0.565989\n",
      "epoch 10; iter: 0; batch classifier loss: 0.474069; batch adversarial loss: 0.538657\n",
      "epoch 11; iter: 0; batch classifier loss: 0.343931; batch adversarial loss: 0.565790\n",
      "epoch 12; iter: 0; batch classifier loss: 0.294236; batch adversarial loss: 0.509320\n",
      "epoch 13; iter: 0; batch classifier loss: 0.337106; batch adversarial loss: 0.596407\n",
      "epoch 14; iter: 0; batch classifier loss: 0.360931; batch adversarial loss: 0.537823\n",
      "epoch 15; iter: 0; batch classifier loss: 0.304321; batch adversarial loss: 0.517002\n",
      "epoch 16; iter: 0; batch classifier loss: 0.282862; batch adversarial loss: 0.512279\n",
      "epoch 17; iter: 0; batch classifier loss: 0.295965; batch adversarial loss: 0.487419\n",
      "epoch 18; iter: 0; batch classifier loss: 0.361490; batch adversarial loss: 0.433927\n",
      "epoch 19; iter: 0; batch classifier loss: 0.294703; batch adversarial loss: 0.488950\n",
      "epoch 20; iter: 0; batch classifier loss: 0.257860; batch adversarial loss: 0.435052\n",
      "epoch 21; iter: 0; batch classifier loss: 0.212967; batch adversarial loss: 0.568432\n",
      "epoch 22; iter: 0; batch classifier loss: 0.268780; batch adversarial loss: 0.564089\n",
      "epoch 23; iter: 0; batch classifier loss: 0.231871; batch adversarial loss: 0.485448\n",
      "epoch 24; iter: 0; batch classifier loss: 0.292092; batch adversarial loss: 0.440343\n",
      "epoch 25; iter: 0; batch classifier loss: 0.265130; batch adversarial loss: 0.448437\n",
      "epoch 26; iter: 0; batch classifier loss: 0.240480; batch adversarial loss: 0.470201\n",
      "epoch 27; iter: 0; batch classifier loss: 0.306163; batch adversarial loss: 0.397343\n",
      "epoch 28; iter: 0; batch classifier loss: 0.228715; batch adversarial loss: 0.444424\n",
      "epoch 29; iter: 0; batch classifier loss: 0.257537; batch adversarial loss: 0.468514\n",
      "epoch 30; iter: 0; batch classifier loss: 0.210093; batch adversarial loss: 0.466056\n",
      "epoch 31; iter: 0; batch classifier loss: 0.242449; batch adversarial loss: 0.486946\n",
      "epoch 32; iter: 0; batch classifier loss: 0.222617; batch adversarial loss: 0.427856\n",
      "epoch 33; iter: 0; batch classifier loss: 0.197050; batch adversarial loss: 0.487452\n",
      "epoch 34; iter: 0; batch classifier loss: 0.268518; batch adversarial loss: 0.456659\n",
      "epoch 35; iter: 0; batch classifier loss: 0.231300; batch adversarial loss: 0.432678\n",
      "epoch 36; iter: 0; batch classifier loss: 0.263089; batch adversarial loss: 0.386478\n",
      "epoch 37; iter: 0; batch classifier loss: 0.260104; batch adversarial loss: 0.465562\n",
      "epoch 38; iter: 0; batch classifier loss: 0.228642; batch adversarial loss: 0.434825\n",
      "epoch 39; iter: 0; batch classifier loss: 0.217505; batch adversarial loss: 0.422965\n",
      "epoch 40; iter: 0; batch classifier loss: 0.224293; batch adversarial loss: 0.436971\n",
      "epoch 41; iter: 0; batch classifier loss: 0.201090; batch adversarial loss: 0.450125\n",
      "epoch 42; iter: 0; batch classifier loss: 0.158881; batch adversarial loss: 0.531794\n",
      "epoch 43; iter: 0; batch classifier loss: 0.259929; batch adversarial loss: 0.470586\n",
      "epoch 44; iter: 0; batch classifier loss: 0.171510; batch adversarial loss: 0.425530\n",
      "epoch 45; iter: 0; batch classifier loss: 0.264978; batch adversarial loss: 0.402919\n",
      "epoch 46; iter: 0; batch classifier loss: 0.300417; batch adversarial loss: 0.413857\n",
      "epoch 47; iter: 0; batch classifier loss: 0.225176; batch adversarial loss: 0.355374\n",
      "epoch 48; iter: 0; batch classifier loss: 0.200839; batch adversarial loss: 0.529517\n",
      "epoch 49; iter: 0; batch classifier loss: 0.279965; batch adversarial loss: 0.470150\n",
      "epoch 50; iter: 0; batch classifier loss: 0.134616; batch adversarial loss: 0.448126\n",
      "epoch 51; iter: 0; batch classifier loss: 0.199270; batch adversarial loss: 0.482113\n",
      "epoch 52; iter: 0; batch classifier loss: 0.202656; batch adversarial loss: 0.497074\n",
      "epoch 53; iter: 0; batch classifier loss: 0.146108; batch adversarial loss: 0.436010\n",
      "epoch 54; iter: 0; batch classifier loss: 0.170991; batch adversarial loss: 0.399815\n",
      "epoch 55; iter: 0; batch classifier loss: 0.237154; batch adversarial loss: 0.507578\n",
      "epoch 56; iter: 0; batch classifier loss: 0.161170; batch adversarial loss: 0.482676\n",
      "epoch 57; iter: 0; batch classifier loss: 0.142191; batch adversarial loss: 0.448718\n",
      "epoch 58; iter: 0; batch classifier loss: 0.262106; batch adversarial loss: 0.471069\n",
      "epoch 59; iter: 0; batch classifier loss: 0.183985; batch adversarial loss: 0.446353\n",
      "epoch 60; iter: 0; batch classifier loss: 0.156380; batch adversarial loss: 0.506222\n",
      "epoch 61; iter: 0; batch classifier loss: 0.180676; batch adversarial loss: 0.506770\n",
      "epoch 62; iter: 0; batch classifier loss: 0.141331; batch adversarial loss: 0.507702\n",
      "epoch 63; iter: 0; batch classifier loss: 0.108024; batch adversarial loss: 0.531880\n",
      "epoch 64; iter: 0; batch classifier loss: 0.233366; batch adversarial loss: 0.448578\n",
      "epoch 65; iter: 0; batch classifier loss: 0.217735; batch adversarial loss: 0.626767\n",
      "epoch 66; iter: 0; batch classifier loss: 0.107400; batch adversarial loss: 0.541890\n",
      "epoch 67; iter: 0; batch classifier loss: 0.092950; batch adversarial loss: 0.423260\n",
      "epoch 68; iter: 0; batch classifier loss: 0.117292; batch adversarial loss: 0.489423\n",
      "epoch 69; iter: 0; batch classifier loss: 0.263447; batch adversarial loss: 0.482238\n",
      "epoch 70; iter: 0; batch classifier loss: 0.135323; batch adversarial loss: 0.410058\n",
      "epoch 71; iter: 0; batch classifier loss: 0.164974; batch adversarial loss: 0.533776\n",
      "epoch 72; iter: 0; batch classifier loss: 0.129076; batch adversarial loss: 0.606395\n",
      "epoch 73; iter: 0; batch classifier loss: 0.220602; batch adversarial loss: 0.469599\n",
      "epoch 74; iter: 0; batch classifier loss: 0.147056; batch adversarial loss: 0.495290\n",
      "epoch 75; iter: 0; batch classifier loss: 0.219618; batch adversarial loss: 0.421715\n",
      "epoch 76; iter: 0; batch classifier loss: 0.131543; batch adversarial loss: 0.458276\n",
      "epoch 77; iter: 0; batch classifier loss: 0.097453; batch adversarial loss: 0.506929\n",
      "epoch 78; iter: 0; batch classifier loss: 0.183563; batch adversarial loss: 0.434030\n",
      "epoch 79; iter: 0; batch classifier loss: 0.188867; batch adversarial loss: 0.423578\n",
      "epoch 80; iter: 0; batch classifier loss: 0.145907; batch adversarial loss: 0.530823\n",
      "epoch 81; iter: 0; batch classifier loss: 0.209173; batch adversarial loss: 0.482324\n",
      "epoch 82; iter: 0; batch classifier loss: 0.141947; batch adversarial loss: 0.421931\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086465; batch adversarial loss: 0.554995\n",
      "epoch 84; iter: 0; batch classifier loss: 0.170128; batch adversarial loss: 0.417601\n",
      "epoch 85; iter: 0; batch classifier loss: 0.119631; batch adversarial loss: 0.421825\n",
      "epoch 86; iter: 0; batch classifier loss: 0.207552; batch adversarial loss: 0.455628\n",
      "epoch 87; iter: 0; batch classifier loss: 0.133805; batch adversarial loss: 0.556197\n",
      "epoch 88; iter: 0; batch classifier loss: 0.208102; batch adversarial loss: 0.510837\n",
      "epoch 89; iter: 0; batch classifier loss: 0.122719; batch adversarial loss: 0.495208\n",
      "epoch 90; iter: 0; batch classifier loss: 0.106843; batch adversarial loss: 0.552450\n",
      "epoch 91; iter: 0; batch classifier loss: 0.106288; batch adversarial loss: 0.456483\n",
      "epoch 92; iter: 0; batch classifier loss: 0.093981; batch adversarial loss: 0.402988\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072872; batch adversarial loss: 0.474855\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061012; batch adversarial loss: 0.480232\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051880; batch adversarial loss: 0.499044\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041293; batch adversarial loss: 0.508460\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080644; batch adversarial loss: 0.528472\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044352; batch adversarial loss: 0.505308\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057362; batch adversarial loss: 0.447277\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037545; batch adversarial loss: 0.397486\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083727; batch adversarial loss: 0.471517\n",
      "epoch 102; iter: 0; batch classifier loss: 0.061349; batch adversarial loss: 0.462007\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059075; batch adversarial loss: 0.431581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.043970; batch adversarial loss: 0.537421\n",
      "epoch 105; iter: 0; batch classifier loss: 0.032156; batch adversarial loss: 0.468332\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042448; batch adversarial loss: 0.394996\n",
      "epoch 107; iter: 0; batch classifier loss: 0.071183; batch adversarial loss: 0.495458\n",
      "epoch 108; iter: 0; batch classifier loss: 0.066138; batch adversarial loss: 0.494840\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043258; batch adversarial loss: 0.439344\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036473; batch adversarial loss: 0.478734\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033371; batch adversarial loss: 0.477334\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035405; batch adversarial loss: 0.490811\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041788; batch adversarial loss: 0.324243\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037216; batch adversarial loss: 0.507763\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024976; batch adversarial loss: 0.381669\n",
      "epoch 116; iter: 0; batch classifier loss: 0.015755; batch adversarial loss: 0.460637\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035078; batch adversarial loss: 0.440294\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044611; batch adversarial loss: 0.447220\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025932; batch adversarial loss: 0.542222\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035032; batch adversarial loss: 0.517469\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027496; batch adversarial loss: 0.352742\n",
      "epoch 122; iter: 0; batch classifier loss: 0.020031; batch adversarial loss: 0.396926\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029582; batch adversarial loss: 0.504423\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032189; batch adversarial loss: 0.460467\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018737; batch adversarial loss: 0.466407\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023737; batch adversarial loss: 0.424462\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025464; batch adversarial loss: 0.403747\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034297; batch adversarial loss: 0.458560\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032987; batch adversarial loss: 0.484865\n",
      "epoch 130; iter: 0; batch classifier loss: 0.013385; batch adversarial loss: 0.478511\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038694; batch adversarial loss: 0.447656\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028199; batch adversarial loss: 0.513535\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015653; batch adversarial loss: 0.457525\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018110; batch adversarial loss: 0.413095\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043383; batch adversarial loss: 0.414822\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027646; batch adversarial loss: 0.436600\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035373; batch adversarial loss: 0.491143\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016927; batch adversarial loss: 0.468346\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029137; batch adversarial loss: 0.502239\n",
      "epoch 140; iter: 0; batch classifier loss: 0.043128; batch adversarial loss: 0.462107\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042375; batch adversarial loss: 0.424502\n",
      "epoch 142; iter: 0; batch classifier loss: 0.011172; batch adversarial loss: 0.391480\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015113; batch adversarial loss: 0.443084\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028095; batch adversarial loss: 0.469978\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021065; batch adversarial loss: 0.483253\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031803; batch adversarial loss: 0.574006\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017339; batch adversarial loss: 0.424697\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021126; batch adversarial loss: 0.541519\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014009; batch adversarial loss: 0.443350\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018007; batch adversarial loss: 0.543969\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017518; batch adversarial loss: 0.481190\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018143; batch adversarial loss: 0.454834\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010617; batch adversarial loss: 0.500469\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024238; batch adversarial loss: 0.460991\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009038; batch adversarial loss: 0.480648\n",
      "epoch 156; iter: 0; batch classifier loss: 0.006914; batch adversarial loss: 0.430546\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027540; batch adversarial loss: 0.508646\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007899; batch adversarial loss: 0.403911\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022160; batch adversarial loss: 0.437832\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016082; batch adversarial loss: 0.497015\n",
      "epoch 161; iter: 0; batch classifier loss: 0.041978; batch adversarial loss: 0.415009\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012057; batch adversarial loss: 0.501469\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017482; batch adversarial loss: 0.443563\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034812; batch adversarial loss: 0.501523\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009534; batch adversarial loss: 0.494623\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025132; batch adversarial loss: 0.479078\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013968; batch adversarial loss: 0.371680\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040575; batch adversarial loss: 0.358043\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026934; batch adversarial loss: 0.460892\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010121; batch adversarial loss: 0.468170\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005956; batch adversarial loss: 0.407083\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006161; batch adversarial loss: 0.450586\n",
      "epoch 173; iter: 0; batch classifier loss: 0.002140; batch adversarial loss: 0.504527\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012529; batch adversarial loss: 0.491909\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012772; batch adversarial loss: 0.492597\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012898; batch adversarial loss: 0.434644\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008795; batch adversarial loss: 0.475114\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025138; batch adversarial loss: 0.517500\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032111; batch adversarial loss: 0.357296\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024446; batch adversarial loss: 0.375338\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026248; batch adversarial loss: 0.534163\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012413; batch adversarial loss: 0.417136\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015932; batch adversarial loss: 0.464769\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034688; batch adversarial loss: 0.456104\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007507; batch adversarial loss: 0.425085\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015666; batch adversarial loss: 0.515751\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026488; batch adversarial loss: 0.434071\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009431; batch adversarial loss: 0.496516\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019451; batch adversarial loss: 0.512301\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011845; batch adversarial loss: 0.507564\n",
      "epoch 191; iter: 0; batch classifier loss: 0.002437; batch adversarial loss: 0.508846\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014845; batch adversarial loss: 0.517614\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027404; batch adversarial loss: 0.412824\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030394; batch adversarial loss: 0.427804\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026688; batch adversarial loss: 0.436061\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028205; batch adversarial loss: 0.531394\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008169; batch adversarial loss: 0.492350\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010810; batch adversarial loss: 0.507416\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023775; batch adversarial loss: 0.420032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.711923; batch adversarial loss: 0.517875\n",
      "epoch 1; iter: 0; batch classifier loss: 0.415830; batch adversarial loss: 0.577130\n",
      "epoch 2; iter: 0; batch classifier loss: 0.382652; batch adversarial loss: 0.547208\n",
      "epoch 3; iter: 0; batch classifier loss: 0.409687; batch adversarial loss: 0.612341\n",
      "epoch 4; iter: 0; batch classifier loss: 0.251098; batch adversarial loss: 0.566606\n",
      "epoch 5; iter: 0; batch classifier loss: 0.328583; batch adversarial loss: 0.569049\n",
      "epoch 6; iter: 0; batch classifier loss: 0.386649; batch adversarial loss: 0.530228\n",
      "epoch 7; iter: 0; batch classifier loss: 0.345857; batch adversarial loss: 0.590454\n",
      "epoch 8; iter: 0; batch classifier loss: 0.361805; batch adversarial loss: 0.589038\n",
      "epoch 9; iter: 0; batch classifier loss: 0.445969; batch adversarial loss: 0.547823\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515761; batch adversarial loss: 0.519980\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545265; batch adversarial loss: 0.532495\n",
      "epoch 12; iter: 0; batch classifier loss: 0.470966; batch adversarial loss: 0.490540\n",
      "epoch 13; iter: 0; batch classifier loss: 0.348319; batch adversarial loss: 0.543973\n",
      "epoch 14; iter: 0; batch classifier loss: 0.251498; batch adversarial loss: 0.461854\n",
      "epoch 15; iter: 0; batch classifier loss: 0.237231; batch adversarial loss: 0.436562\n",
      "epoch 16; iter: 0; batch classifier loss: 0.258433; batch adversarial loss: 0.473165\n",
      "epoch 17; iter: 0; batch classifier loss: 0.244071; batch adversarial loss: 0.529451\n",
      "epoch 18; iter: 0; batch classifier loss: 0.247090; batch adversarial loss: 0.500826\n",
      "epoch 19; iter: 0; batch classifier loss: 0.242078; batch adversarial loss: 0.484910\n",
      "epoch 20; iter: 0; batch classifier loss: 0.190907; batch adversarial loss: 0.485518\n",
      "epoch 21; iter: 0; batch classifier loss: 0.254170; batch adversarial loss: 0.483337\n",
      "epoch 22; iter: 0; batch classifier loss: 0.180318; batch adversarial loss: 0.486371\n",
      "epoch 23; iter: 0; batch classifier loss: 0.220879; batch adversarial loss: 0.428464\n",
      "epoch 24; iter: 0; batch classifier loss: 0.206433; batch adversarial loss: 0.483684\n",
      "epoch 25; iter: 0; batch classifier loss: 0.195724; batch adversarial loss: 0.418506\n",
      "epoch 26; iter: 0; batch classifier loss: 0.149533; batch adversarial loss: 0.398501\n",
      "epoch 27; iter: 0; batch classifier loss: 0.207673; batch adversarial loss: 0.503045\n",
      "epoch 28; iter: 0; batch classifier loss: 0.158235; batch adversarial loss: 0.507263\n",
      "epoch 29; iter: 0; batch classifier loss: 0.198216; batch adversarial loss: 0.541573\n",
      "epoch 30; iter: 0; batch classifier loss: 0.170862; batch adversarial loss: 0.471485\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156495; batch adversarial loss: 0.504840\n",
      "epoch 32; iter: 0; batch classifier loss: 0.125841; batch adversarial loss: 0.462629\n",
      "epoch 33; iter: 0; batch classifier loss: 0.116032; batch adversarial loss: 0.466100\n",
      "epoch 34; iter: 0; batch classifier loss: 0.141658; batch adversarial loss: 0.411575\n",
      "epoch 35; iter: 0; batch classifier loss: 0.134679; batch adversarial loss: 0.497379\n",
      "epoch 36; iter: 0; batch classifier loss: 0.115249; batch adversarial loss: 0.398030\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166347; batch adversarial loss: 0.474579\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127956; batch adversarial loss: 0.488618\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143043; batch adversarial loss: 0.419077\n",
      "epoch 40; iter: 0; batch classifier loss: 0.180599; batch adversarial loss: 0.407521\n",
      "epoch 41; iter: 0; batch classifier loss: 0.112993; batch adversarial loss: 0.377350\n",
      "epoch 42; iter: 0; batch classifier loss: 0.155972; batch adversarial loss: 0.505580\n",
      "epoch 43; iter: 0; batch classifier loss: 0.093339; batch adversarial loss: 0.526838\n",
      "epoch 44; iter: 0; batch classifier loss: 0.140613; batch adversarial loss: 0.548138\n",
      "epoch 45; iter: 0; batch classifier loss: 0.149475; batch adversarial loss: 0.571704\n",
      "epoch 46; iter: 0; batch classifier loss: 0.122240; batch adversarial loss: 0.445929\n",
      "epoch 47; iter: 0; batch classifier loss: 0.145025; batch adversarial loss: 0.468113\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141558; batch adversarial loss: 0.420343\n",
      "epoch 49; iter: 0; batch classifier loss: 0.117745; batch adversarial loss: 0.485335\n",
      "epoch 50; iter: 0; batch classifier loss: 0.179598; batch adversarial loss: 0.435415\n",
      "epoch 51; iter: 0; batch classifier loss: 0.142848; batch adversarial loss: 0.460931\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101960; batch adversarial loss: 0.450178\n",
      "epoch 53; iter: 0; batch classifier loss: 0.175658; batch adversarial loss: 0.471457\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079522; batch adversarial loss: 0.379338\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079729; batch adversarial loss: 0.461634\n",
      "epoch 56; iter: 0; batch classifier loss: 0.077267; batch adversarial loss: 0.447090\n",
      "epoch 57; iter: 0; batch classifier loss: 0.143868; batch adversarial loss: 0.527941\n",
      "epoch 58; iter: 0; batch classifier loss: 0.108428; batch adversarial loss: 0.497925\n",
      "epoch 59; iter: 0; batch classifier loss: 0.156984; batch adversarial loss: 0.496799\n",
      "epoch 60; iter: 0; batch classifier loss: 0.127652; batch adversarial loss: 0.443053\n",
      "epoch 61; iter: 0; batch classifier loss: 0.151893; batch adversarial loss: 0.447023\n",
      "epoch 62; iter: 0; batch classifier loss: 0.088479; batch adversarial loss: 0.580905\n",
      "epoch 63; iter: 0; batch classifier loss: 0.138280; batch adversarial loss: 0.464374\n",
      "epoch 64; iter: 0; batch classifier loss: 0.096856; batch adversarial loss: 0.487697\n",
      "epoch 65; iter: 0; batch classifier loss: 0.105896; batch adversarial loss: 0.405032\n",
      "epoch 66; iter: 0; batch classifier loss: 0.115573; batch adversarial loss: 0.407149\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130478; batch adversarial loss: 0.496004\n",
      "epoch 68; iter: 0; batch classifier loss: 0.157244; batch adversarial loss: 0.501633\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064738; batch adversarial loss: 0.466472\n",
      "epoch 70; iter: 0; batch classifier loss: 0.125239; batch adversarial loss: 0.411980\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076865; batch adversarial loss: 0.576701\n",
      "epoch 72; iter: 0; batch classifier loss: 0.115121; batch adversarial loss: 0.482678\n",
      "epoch 73; iter: 0; batch classifier loss: 0.126699; batch adversarial loss: 0.471609\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066472; batch adversarial loss: 0.423597\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083941; batch adversarial loss: 0.479405\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076264; batch adversarial loss: 0.432007\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090972; batch adversarial loss: 0.549332\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072642; batch adversarial loss: 0.473486\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093846; batch adversarial loss: 0.583889\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090400; batch adversarial loss: 0.398917\n",
      "epoch 81; iter: 0; batch classifier loss: 0.109807; batch adversarial loss: 0.540010\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072278; batch adversarial loss: 0.509908\n",
      "epoch 83; iter: 0; batch classifier loss: 0.077975; batch adversarial loss: 0.452279\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068301; batch adversarial loss: 0.475208\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084797; batch adversarial loss: 0.648543\n",
      "epoch 86; iter: 0; batch classifier loss: 0.093714; batch adversarial loss: 0.472272\n",
      "epoch 87; iter: 0; batch classifier loss: 0.084873; batch adversarial loss: 0.462415\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076214; batch adversarial loss: 0.510196\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047510; batch adversarial loss: 0.583443\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057218; batch adversarial loss: 0.538083\n",
      "epoch 91; iter: 0; batch classifier loss: 0.092885; batch adversarial loss: 0.402268\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064935; batch adversarial loss: 0.512837\n",
      "epoch 93; iter: 0; batch classifier loss: 0.085818; batch adversarial loss: 0.534421\n",
      "epoch 94; iter: 0; batch classifier loss: 0.055127; batch adversarial loss: 0.509222\n",
      "epoch 95; iter: 0; batch classifier loss: 0.089501; batch adversarial loss: 0.424094\n",
      "epoch 96; iter: 0; batch classifier loss: 0.181154; batch adversarial loss: 0.462884\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065771; batch adversarial loss: 0.429830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.039885; batch adversarial loss: 0.533712\n",
      "epoch 99; iter: 0; batch classifier loss: 0.076259; batch adversarial loss: 0.452832\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054029; batch adversarial loss: 0.479224\n",
      "epoch 101; iter: 0; batch classifier loss: 0.113286; batch adversarial loss: 0.532138\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049420; batch adversarial loss: 0.416803\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040810; batch adversarial loss: 0.389519\n",
      "epoch 104; iter: 0; batch classifier loss: 0.090721; batch adversarial loss: 0.414099\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043596; batch adversarial loss: 0.487668\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067567; batch adversarial loss: 0.501384\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031733; batch adversarial loss: 0.503320\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044126; batch adversarial loss: 0.434164\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051993; batch adversarial loss: 0.426071\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065390; batch adversarial loss: 0.349950\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032256; batch adversarial loss: 0.489907\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063176; batch adversarial loss: 0.379958\n",
      "epoch 113; iter: 0; batch classifier loss: 0.079783; batch adversarial loss: 0.518590\n",
      "epoch 114; iter: 0; batch classifier loss: 0.064913; batch adversarial loss: 0.501410\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042712; batch adversarial loss: 0.460876\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055755; batch adversarial loss: 0.462912\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029682; batch adversarial loss: 0.406652\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045063; batch adversarial loss: 0.491353\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020424; batch adversarial loss: 0.589762\n",
      "epoch 120; iter: 0; batch classifier loss: 0.070228; batch adversarial loss: 0.554838\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040494; batch adversarial loss: 0.460138\n",
      "epoch 122; iter: 0; batch classifier loss: 0.019280; batch adversarial loss: 0.469781\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053133; batch adversarial loss: 0.460181\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037360; batch adversarial loss: 0.490353\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023217; batch adversarial loss: 0.442286\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022879; batch adversarial loss: 0.501984\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034150; batch adversarial loss: 0.471486\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046188; batch adversarial loss: 0.542442\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043988; batch adversarial loss: 0.433116\n",
      "epoch 130; iter: 0; batch classifier loss: 0.064963; batch adversarial loss: 0.385459\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023100; batch adversarial loss: 0.467975\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029117; batch adversarial loss: 0.418586\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035067; batch adversarial loss: 0.492736\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031270; batch adversarial loss: 0.520164\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033639; batch adversarial loss: 0.535978\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027201; batch adversarial loss: 0.436606\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038416; batch adversarial loss: 0.490762\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024879; batch adversarial loss: 0.409152\n",
      "epoch 139; iter: 0; batch classifier loss: 0.058144; batch adversarial loss: 0.481762\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014946; batch adversarial loss: 0.461380\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020186; batch adversarial loss: 0.500659\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023705; batch adversarial loss: 0.331116\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039268; batch adversarial loss: 0.586896\n",
      "epoch 144; iter: 0; batch classifier loss: 0.060739; batch adversarial loss: 0.432895\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022205; batch adversarial loss: 0.399690\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028896; batch adversarial loss: 0.450966\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022524; batch adversarial loss: 0.428030\n",
      "epoch 148; iter: 0; batch classifier loss: 0.008567; batch adversarial loss: 0.416944\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012611; batch adversarial loss: 0.418332\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022250; batch adversarial loss: 0.390914\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024155; batch adversarial loss: 0.543049\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024053; batch adversarial loss: 0.444128\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025656; batch adversarial loss: 0.504517\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024193; batch adversarial loss: 0.466919\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014008; batch adversarial loss: 0.513743\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020859; batch adversarial loss: 0.482643\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028384; batch adversarial loss: 0.466755\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037276; batch adversarial loss: 0.576806\n",
      "epoch 159; iter: 0; batch classifier loss: 0.050637; batch adversarial loss: 0.526018\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022242; batch adversarial loss: 0.349823\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043003; batch adversarial loss: 0.424244\n",
      "epoch 162; iter: 0; batch classifier loss: 0.064532; batch adversarial loss: 0.463219\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011579; batch adversarial loss: 0.423214\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012987; batch adversarial loss: 0.472965\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010877; batch adversarial loss: 0.555918\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032576; batch adversarial loss: 0.427311\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029177; batch adversarial loss: 0.469113\n",
      "epoch 168; iter: 0; batch classifier loss: 0.050939; batch adversarial loss: 0.445369\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010912; batch adversarial loss: 0.480478\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016908; batch adversarial loss: 0.485441\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014374; batch adversarial loss: 0.384608\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008469; batch adversarial loss: 0.482967\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011864; batch adversarial loss: 0.362913\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020370; batch adversarial loss: 0.463860\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015148; batch adversarial loss: 0.450054\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010975; batch adversarial loss: 0.448961\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034420; batch adversarial loss: 0.513371\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024045; batch adversarial loss: 0.473986\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020418; batch adversarial loss: 0.454491\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021341; batch adversarial loss: 0.463513\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020678; batch adversarial loss: 0.380768\n",
      "epoch 182; iter: 0; batch classifier loss: 0.046833; batch adversarial loss: 0.434557\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022062; batch adversarial loss: 0.528215\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034379; batch adversarial loss: 0.474936\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014628; batch adversarial loss: 0.456656\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012927; batch adversarial loss: 0.417828\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026625; batch adversarial loss: 0.504135\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020635; batch adversarial loss: 0.431193\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008000; batch adversarial loss: 0.424715\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011671; batch adversarial loss: 0.450157\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006570; batch adversarial loss: 0.572672\n",
      "epoch 192; iter: 0; batch classifier loss: 0.038623; batch adversarial loss: 0.458088\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027829; batch adversarial loss: 0.498880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.015288; batch adversarial loss: 0.489917\n",
      "epoch 195; iter: 0; batch classifier loss: 0.040775; batch adversarial loss: 0.471436\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029958; batch adversarial loss: 0.486796\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034429; batch adversarial loss: 0.461415\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030267; batch adversarial loss: 0.473536\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020954; batch adversarial loss: 0.462012\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688779; batch adversarial loss: 0.537154\n",
      "epoch 1; iter: 0; batch classifier loss: 0.425634; batch adversarial loss: 0.572772\n",
      "epoch 2; iter: 0; batch classifier loss: 0.311344; batch adversarial loss: 0.598442\n",
      "epoch 3; iter: 0; batch classifier loss: 0.388196; batch adversarial loss: 0.569971\n",
      "epoch 4; iter: 0; batch classifier loss: 0.369310; batch adversarial loss: 0.597797\n",
      "epoch 5; iter: 0; batch classifier loss: 0.423238; batch adversarial loss: 0.548054\n",
      "epoch 6; iter: 0; batch classifier loss: 0.308815; batch adversarial loss: 0.534077\n",
      "epoch 7; iter: 0; batch classifier loss: 0.405482; batch adversarial loss: 0.474786\n",
      "epoch 8; iter: 0; batch classifier loss: 0.394023; batch adversarial loss: 0.581959\n",
      "epoch 9; iter: 0; batch classifier loss: 0.394307; batch adversarial loss: 0.560133\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484998; batch adversarial loss: 0.550433\n",
      "epoch 11; iter: 0; batch classifier loss: 0.474306; batch adversarial loss: 0.541281\n",
      "epoch 12; iter: 0; batch classifier loss: 0.579334; batch adversarial loss: 0.518855\n",
      "epoch 13; iter: 0; batch classifier loss: 0.492003; batch adversarial loss: 0.558258\n",
      "epoch 14; iter: 0; batch classifier loss: 0.346938; batch adversarial loss: 0.520215\n",
      "epoch 15; iter: 0; batch classifier loss: 0.294800; batch adversarial loss: 0.513128\n",
      "epoch 16; iter: 0; batch classifier loss: 0.263184; batch adversarial loss: 0.504882\n",
      "epoch 17; iter: 0; batch classifier loss: 0.256928; batch adversarial loss: 0.539027\n",
      "epoch 18; iter: 0; batch classifier loss: 0.252702; batch adversarial loss: 0.476029\n",
      "epoch 19; iter: 0; batch classifier loss: 0.227529; batch adversarial loss: 0.465282\n",
      "epoch 20; iter: 0; batch classifier loss: 0.207066; batch adversarial loss: 0.507272\n",
      "epoch 21; iter: 0; batch classifier loss: 0.204564; batch adversarial loss: 0.456586\n",
      "epoch 22; iter: 0; batch classifier loss: 0.209264; batch adversarial loss: 0.411435\n",
      "epoch 23; iter: 0; batch classifier loss: 0.169349; batch adversarial loss: 0.486053\n",
      "epoch 24; iter: 0; batch classifier loss: 0.143814; batch adversarial loss: 0.429860\n",
      "epoch 25; iter: 0; batch classifier loss: 0.223140; batch adversarial loss: 0.479292\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208956; batch adversarial loss: 0.458836\n",
      "epoch 27; iter: 0; batch classifier loss: 0.150971; batch adversarial loss: 0.386563\n",
      "epoch 28; iter: 0; batch classifier loss: 0.132401; batch adversarial loss: 0.427275\n",
      "epoch 29; iter: 0; batch classifier loss: 0.110609; batch adversarial loss: 0.423840\n",
      "epoch 30; iter: 0; batch classifier loss: 0.157766; batch adversarial loss: 0.449878\n",
      "epoch 31; iter: 0; batch classifier loss: 0.125791; batch adversarial loss: 0.377832\n",
      "epoch 32; iter: 0; batch classifier loss: 0.067145; batch adversarial loss: 0.486454\n",
      "epoch 33; iter: 0; batch classifier loss: 0.114581; batch adversarial loss: 0.396813\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122607; batch adversarial loss: 0.491649\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137068; batch adversarial loss: 0.503880\n",
      "epoch 36; iter: 0; batch classifier loss: 0.146445; batch adversarial loss: 0.496307\n",
      "epoch 37; iter: 0; batch classifier loss: 0.122350; batch adversarial loss: 0.470583\n",
      "epoch 38; iter: 0; batch classifier loss: 0.128392; batch adversarial loss: 0.481484\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131233; batch adversarial loss: 0.523196\n",
      "epoch 40; iter: 0; batch classifier loss: 0.100948; batch adversarial loss: 0.465130\n",
      "epoch 41; iter: 0; batch classifier loss: 0.156285; batch adversarial loss: 0.468523\n",
      "epoch 42; iter: 0; batch classifier loss: 0.122394; batch adversarial loss: 0.502292\n",
      "epoch 43; iter: 0; batch classifier loss: 0.122695; batch adversarial loss: 0.382837\n",
      "epoch 44; iter: 0; batch classifier loss: 0.099282; batch adversarial loss: 0.441073\n",
      "epoch 45; iter: 0; batch classifier loss: 0.101610; batch adversarial loss: 0.471330\n",
      "epoch 46; iter: 0; batch classifier loss: 0.091215; batch adversarial loss: 0.434525\n",
      "epoch 47; iter: 0; batch classifier loss: 0.151507; batch adversarial loss: 0.442237\n",
      "epoch 48; iter: 0; batch classifier loss: 0.091603; batch adversarial loss: 0.463936\n",
      "epoch 49; iter: 0; batch classifier loss: 0.111276; batch adversarial loss: 0.472515\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094247; batch adversarial loss: 0.520476\n",
      "epoch 51; iter: 0; batch classifier loss: 0.161256; batch adversarial loss: 0.411477\n",
      "epoch 52; iter: 0; batch classifier loss: 0.118761; batch adversarial loss: 0.285698\n",
      "epoch 53; iter: 0; batch classifier loss: 0.107256; batch adversarial loss: 0.430749\n",
      "epoch 54; iter: 0; batch classifier loss: 0.128674; batch adversarial loss: 0.456377\n",
      "epoch 55; iter: 0; batch classifier loss: 0.076460; batch adversarial loss: 0.551550\n",
      "epoch 56; iter: 0; batch classifier loss: 0.097535; batch adversarial loss: 0.461038\n",
      "epoch 57; iter: 0; batch classifier loss: 0.129064; batch adversarial loss: 0.529410\n",
      "epoch 58; iter: 0; batch classifier loss: 0.086024; batch adversarial loss: 0.402177\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102681; batch adversarial loss: 0.387850\n",
      "epoch 60; iter: 0; batch classifier loss: 0.073691; batch adversarial loss: 0.486822\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103686; batch adversarial loss: 0.412476\n",
      "epoch 62; iter: 0; batch classifier loss: 0.099587; batch adversarial loss: 0.476348\n",
      "epoch 63; iter: 0; batch classifier loss: 0.126201; batch adversarial loss: 0.470450\n",
      "epoch 64; iter: 0; batch classifier loss: 0.126600; batch adversarial loss: 0.365944\n",
      "epoch 65; iter: 0; batch classifier loss: 0.127008; batch adversarial loss: 0.478448\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087985; batch adversarial loss: 0.435794\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088999; batch adversarial loss: 0.369258\n",
      "epoch 68; iter: 0; batch classifier loss: 0.055079; batch adversarial loss: 0.400621\n",
      "epoch 69; iter: 0; batch classifier loss: 0.125618; batch adversarial loss: 0.500129\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098036; batch adversarial loss: 0.360652\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067280; batch adversarial loss: 0.421777\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071453; batch adversarial loss: 0.375095\n",
      "epoch 73; iter: 0; batch classifier loss: 0.104705; batch adversarial loss: 0.450240\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075875; batch adversarial loss: 0.345683\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067606; batch adversarial loss: 0.508364\n",
      "epoch 76; iter: 0; batch classifier loss: 0.105203; batch adversarial loss: 0.492485\n",
      "epoch 77; iter: 0; batch classifier loss: 0.079530; batch adversarial loss: 0.486169\n",
      "epoch 78; iter: 0; batch classifier loss: 0.111716; batch adversarial loss: 0.448590\n",
      "epoch 79; iter: 0; batch classifier loss: 0.094297; batch adversarial loss: 0.445698\n",
      "epoch 80; iter: 0; batch classifier loss: 0.107441; batch adversarial loss: 0.450211\n",
      "epoch 81; iter: 0; batch classifier loss: 0.070728; batch adversarial loss: 0.467562\n",
      "epoch 82; iter: 0; batch classifier loss: 0.104221; batch adversarial loss: 0.396515\n",
      "epoch 83; iter: 0; batch classifier loss: 0.077162; batch adversarial loss: 0.479386\n",
      "epoch 84; iter: 0; batch classifier loss: 0.072998; batch adversarial loss: 0.471962\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068379; batch adversarial loss: 0.485689\n",
      "epoch 86; iter: 0; batch classifier loss: 0.059029; batch adversarial loss: 0.495198\n",
      "epoch 87; iter: 0; batch classifier loss: 0.081383; batch adversarial loss: 0.439906\n",
      "epoch 88; iter: 0; batch classifier loss: 0.091592; batch adversarial loss: 0.400580\n",
      "epoch 89; iter: 0; batch classifier loss: 0.079139; batch adversarial loss: 0.392220\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067393; batch adversarial loss: 0.490325\n",
      "epoch 91; iter: 0; batch classifier loss: 0.087459; batch adversarial loss: 0.473378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.106988; batch adversarial loss: 0.472481\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060757; batch adversarial loss: 0.370217\n",
      "epoch 94; iter: 0; batch classifier loss: 0.085861; batch adversarial loss: 0.368309\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087235; batch adversarial loss: 0.393785\n",
      "epoch 96; iter: 0; batch classifier loss: 0.077909; batch adversarial loss: 0.490958\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051272; batch adversarial loss: 0.479890\n",
      "epoch 98; iter: 0; batch classifier loss: 0.082303; batch adversarial loss: 0.450155\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065720; batch adversarial loss: 0.424262\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050540; batch adversarial loss: 0.459972\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037041; batch adversarial loss: 0.442236\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068721; batch adversarial loss: 0.435959\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076411; batch adversarial loss: 0.404777\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062459; batch adversarial loss: 0.406004\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084950; batch adversarial loss: 0.495216\n",
      "epoch 106; iter: 0; batch classifier loss: 0.073598; batch adversarial loss: 0.425455\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058777; batch adversarial loss: 0.427550\n",
      "epoch 108; iter: 0; batch classifier loss: 0.080078; batch adversarial loss: 0.436193\n",
      "epoch 109; iter: 0; batch classifier loss: 0.122027; batch adversarial loss: 0.324831\n",
      "epoch 110; iter: 0; batch classifier loss: 0.077093; batch adversarial loss: 0.456177\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064095; batch adversarial loss: 0.412472\n",
      "epoch 112; iter: 0; batch classifier loss: 0.119090; batch adversarial loss: 0.426890\n",
      "epoch 113; iter: 0; batch classifier loss: 0.060718; batch adversarial loss: 0.463049\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049343; batch adversarial loss: 0.460142\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022758; batch adversarial loss: 0.524859\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051075; batch adversarial loss: 0.455414\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033719; batch adversarial loss: 0.535077\n",
      "epoch 118; iter: 0; batch classifier loss: 0.115318; batch adversarial loss: 0.410739\n",
      "epoch 119; iter: 0; batch classifier loss: 0.076968; batch adversarial loss: 0.439365\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025942; batch adversarial loss: 0.491657\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027031; batch adversarial loss: 0.415219\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048824; batch adversarial loss: 0.505163\n",
      "epoch 123; iter: 0; batch classifier loss: 0.066026; batch adversarial loss: 0.455450\n",
      "epoch 124; iter: 0; batch classifier loss: 0.095132; batch adversarial loss: 0.367976\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032683; batch adversarial loss: 0.418454\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030601; batch adversarial loss: 0.524133\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039146; batch adversarial loss: 0.438156\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022460; batch adversarial loss: 0.477797\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051680; batch adversarial loss: 0.539295\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044530; batch adversarial loss: 0.397552\n",
      "epoch 131; iter: 0; batch classifier loss: 0.061790; batch adversarial loss: 0.360056\n",
      "epoch 132; iter: 0; batch classifier loss: 0.062012; batch adversarial loss: 0.437857\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051479; batch adversarial loss: 0.450371\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030539; batch adversarial loss: 0.440266\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042337; batch adversarial loss: 0.499024\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022651; batch adversarial loss: 0.476682\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022051; batch adversarial loss: 0.427207\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044563; batch adversarial loss: 0.525116\n",
      "epoch 139; iter: 0; batch classifier loss: 0.057068; batch adversarial loss: 0.447642\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051299; batch adversarial loss: 0.458781\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046899; batch adversarial loss: 0.508108\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026875; batch adversarial loss: 0.448797\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020202; batch adversarial loss: 0.489983\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025480; batch adversarial loss: 0.427547\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036348; batch adversarial loss: 0.408882\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038089; batch adversarial loss: 0.476024\n",
      "epoch 147; iter: 0; batch classifier loss: 0.048550; batch adversarial loss: 0.363765\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054944; batch adversarial loss: 0.392252\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056102; batch adversarial loss: 0.484948\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025964; batch adversarial loss: 0.435754\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030721; batch adversarial loss: 0.446098\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018229; batch adversarial loss: 0.444265\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022264; batch adversarial loss: 0.442403\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039181; batch adversarial loss: 0.471170\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042934; batch adversarial loss: 0.425168\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050587; batch adversarial loss: 0.435749\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019581; batch adversarial loss: 0.459611\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030990; batch adversarial loss: 0.482263\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029683; batch adversarial loss: 0.348953\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045906; batch adversarial loss: 0.513902\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028290; batch adversarial loss: 0.507963\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017965; batch adversarial loss: 0.441976\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034255; batch adversarial loss: 0.479877\n",
      "epoch 164; iter: 0; batch classifier loss: 0.065647; batch adversarial loss: 0.410286\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038191; batch adversarial loss: 0.438977\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020218; batch adversarial loss: 0.477200\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018930; batch adversarial loss: 0.442067\n",
      "epoch 168; iter: 0; batch classifier loss: 0.039104; batch adversarial loss: 0.502568\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028765; batch adversarial loss: 0.442140\n",
      "epoch 170; iter: 0; batch classifier loss: 0.048776; batch adversarial loss: 0.386209\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019729; batch adversarial loss: 0.407209\n",
      "epoch 172; iter: 0; batch classifier loss: 0.058726; batch adversarial loss: 0.510852\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017238; batch adversarial loss: 0.476798\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011601; batch adversarial loss: 0.507975\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018554; batch adversarial loss: 0.387859\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032168; batch adversarial loss: 0.454793\n",
      "epoch 177; iter: 0; batch classifier loss: 0.052695; batch adversarial loss: 0.423916\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035504; batch adversarial loss: 0.458623\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019039; batch adversarial loss: 0.495964\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029529; batch adversarial loss: 0.415780\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025136; batch adversarial loss: 0.468124\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013915; batch adversarial loss: 0.492547\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019179; batch adversarial loss: 0.504968\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035728; batch adversarial loss: 0.418820\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035326; batch adversarial loss: 0.519153\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029255; batch adversarial loss: 0.445337\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033599; batch adversarial loss: 0.416859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.026660; batch adversarial loss: 0.476862\n",
      "epoch 189; iter: 0; batch classifier loss: 0.044547; batch adversarial loss: 0.388240\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030105; batch adversarial loss: 0.497681\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026860; batch adversarial loss: 0.448666\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037010; batch adversarial loss: 0.527002\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030878; batch adversarial loss: 0.407914\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007285; batch adversarial loss: 0.331068\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019166; batch adversarial loss: 0.387856\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024825; batch adversarial loss: 0.464898\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019039; batch adversarial loss: 0.523354\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025344; batch adversarial loss: 0.453393\n",
      "epoch 199; iter: 0; batch classifier loss: 0.048147; batch adversarial loss: 0.427284\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705856; batch adversarial loss: 0.628602\n",
      "epoch 1; iter: 0; batch classifier loss: 0.408045; batch adversarial loss: 0.613862\n",
      "epoch 2; iter: 0; batch classifier loss: 0.287888; batch adversarial loss: 0.594724\n",
      "epoch 3; iter: 0; batch classifier loss: 0.283679; batch adversarial loss: 0.570976\n",
      "epoch 4; iter: 0; batch classifier loss: 0.412743; batch adversarial loss: 0.540384\n",
      "epoch 5; iter: 0; batch classifier loss: 0.356459; batch adversarial loss: 0.510101\n",
      "epoch 6; iter: 0; batch classifier loss: 0.258118; batch adversarial loss: 0.514486\n",
      "epoch 7; iter: 0; batch classifier loss: 0.264085; batch adversarial loss: 0.506701\n",
      "epoch 8; iter: 0; batch classifier loss: 0.232124; batch adversarial loss: 0.514141\n",
      "epoch 9; iter: 0; batch classifier loss: 0.275371; batch adversarial loss: 0.513815\n",
      "epoch 10; iter: 0; batch classifier loss: 0.296281; batch adversarial loss: 0.518746\n",
      "epoch 11; iter: 0; batch classifier loss: 0.251092; batch adversarial loss: 0.428853\n",
      "epoch 12; iter: 0; batch classifier loss: 0.250399; batch adversarial loss: 0.464226\n",
      "epoch 13; iter: 0; batch classifier loss: 0.192987; batch adversarial loss: 0.465816\n",
      "epoch 14; iter: 0; batch classifier loss: 0.214729; batch adversarial loss: 0.515558\n",
      "epoch 15; iter: 0; batch classifier loss: 0.207529; batch adversarial loss: 0.501292\n",
      "epoch 16; iter: 0; batch classifier loss: 0.203028; batch adversarial loss: 0.532054\n",
      "epoch 17; iter: 0; batch classifier loss: 0.194107; batch adversarial loss: 0.525023\n",
      "epoch 18; iter: 0; batch classifier loss: 0.226952; batch adversarial loss: 0.540811\n",
      "epoch 19; iter: 0; batch classifier loss: 0.242431; batch adversarial loss: 0.546820\n",
      "epoch 20; iter: 0; batch classifier loss: 0.263038; batch adversarial loss: 0.514770\n",
      "epoch 21; iter: 0; batch classifier loss: 0.266253; batch adversarial loss: 0.525427\n",
      "epoch 22; iter: 0; batch classifier loss: 0.240705; batch adversarial loss: 0.442806\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285811; batch adversarial loss: 0.540671\n",
      "epoch 24; iter: 0; batch classifier loss: 0.402634; batch adversarial loss: 0.551070\n",
      "epoch 25; iter: 0; batch classifier loss: 0.262991; batch adversarial loss: 0.459109\n",
      "epoch 26; iter: 0; batch classifier loss: 0.289787; batch adversarial loss: 0.413939\n",
      "epoch 27; iter: 0; batch classifier loss: 0.186648; batch adversarial loss: 0.530993\n",
      "epoch 28; iter: 0; batch classifier loss: 0.111302; batch adversarial loss: 0.413324\n",
      "epoch 29; iter: 0; batch classifier loss: 0.177377; batch adversarial loss: 0.472577\n",
      "epoch 30; iter: 0; batch classifier loss: 0.125574; batch adversarial loss: 0.458887\n",
      "epoch 31; iter: 0; batch classifier loss: 0.135146; batch adversarial loss: 0.479624\n",
      "epoch 32; iter: 0; batch classifier loss: 0.127421; batch adversarial loss: 0.458667\n",
      "epoch 33; iter: 0; batch classifier loss: 0.172531; batch adversarial loss: 0.538407\n",
      "epoch 34; iter: 0; batch classifier loss: 0.123529; batch adversarial loss: 0.472148\n",
      "epoch 35; iter: 0; batch classifier loss: 0.188568; batch adversarial loss: 0.421678\n",
      "epoch 36; iter: 0; batch classifier loss: 0.073727; batch adversarial loss: 0.453615\n",
      "epoch 37; iter: 0; batch classifier loss: 0.098644; batch adversarial loss: 0.480575\n",
      "epoch 38; iter: 0; batch classifier loss: 0.157731; batch adversarial loss: 0.446197\n",
      "epoch 39; iter: 0; batch classifier loss: 0.117256; batch adversarial loss: 0.389138\n",
      "epoch 40; iter: 0; batch classifier loss: 0.155308; batch adversarial loss: 0.559372\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125654; batch adversarial loss: 0.405937\n",
      "epoch 42; iter: 0; batch classifier loss: 0.083437; batch adversarial loss: 0.435987\n",
      "epoch 43; iter: 0; batch classifier loss: 0.072232; batch adversarial loss: 0.528633\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136770; batch adversarial loss: 0.417606\n",
      "epoch 45; iter: 0; batch classifier loss: 0.135287; batch adversarial loss: 0.384476\n",
      "epoch 46; iter: 0; batch classifier loss: 0.129208; batch adversarial loss: 0.453250\n",
      "epoch 47; iter: 0; batch classifier loss: 0.121108; batch adversarial loss: 0.491134\n",
      "epoch 48; iter: 0; batch classifier loss: 0.124907; batch adversarial loss: 0.536200\n",
      "epoch 49; iter: 0; batch classifier loss: 0.179946; batch adversarial loss: 0.337959\n",
      "epoch 50; iter: 0; batch classifier loss: 0.116953; batch adversarial loss: 0.558343\n",
      "epoch 51; iter: 0; batch classifier loss: 0.130693; batch adversarial loss: 0.485443\n",
      "epoch 52; iter: 0; batch classifier loss: 0.128786; batch adversarial loss: 0.428304\n",
      "epoch 53; iter: 0; batch classifier loss: 0.132365; batch adversarial loss: 0.577969\n",
      "epoch 54; iter: 0; batch classifier loss: 0.111651; batch adversarial loss: 0.457559\n",
      "epoch 55; iter: 0; batch classifier loss: 0.107859; batch adversarial loss: 0.441380\n",
      "epoch 56; iter: 0; batch classifier loss: 0.156126; batch adversarial loss: 0.477441\n",
      "epoch 57; iter: 0; batch classifier loss: 0.158066; batch adversarial loss: 0.442048\n",
      "epoch 58; iter: 0; batch classifier loss: 0.152430; batch adversarial loss: 0.470592\n",
      "epoch 59; iter: 0; batch classifier loss: 0.220007; batch adversarial loss: 0.509500\n",
      "epoch 60; iter: 0; batch classifier loss: 0.128354; batch adversarial loss: 0.527651\n",
      "epoch 61; iter: 0; batch classifier loss: 0.142935; batch adversarial loss: 0.506533\n",
      "epoch 62; iter: 0; batch classifier loss: 0.180588; batch adversarial loss: 0.411839\n",
      "epoch 63; iter: 0; batch classifier loss: 0.129382; batch adversarial loss: 0.468420\n",
      "epoch 64; iter: 0; batch classifier loss: 0.182937; batch adversarial loss: 0.400197\n",
      "epoch 65; iter: 0; batch classifier loss: 0.120773; batch adversarial loss: 0.392465\n",
      "epoch 66; iter: 0; batch classifier loss: 0.119306; batch adversarial loss: 0.477060\n",
      "epoch 67; iter: 0; batch classifier loss: 0.128409; batch adversarial loss: 0.467065\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082816; batch adversarial loss: 0.527609\n",
      "epoch 69; iter: 0; batch classifier loss: 0.127085; batch adversarial loss: 0.405358\n",
      "epoch 70; iter: 0; batch classifier loss: 0.124983; batch adversarial loss: 0.545005\n",
      "epoch 71; iter: 0; batch classifier loss: 0.109494; batch adversarial loss: 0.513234\n",
      "epoch 72; iter: 0; batch classifier loss: 0.166994; batch adversarial loss: 0.522706\n",
      "epoch 73; iter: 0; batch classifier loss: 0.098274; batch adversarial loss: 0.442693\n",
      "epoch 74; iter: 0; batch classifier loss: 0.164262; batch adversarial loss: 0.386028\n",
      "epoch 75; iter: 0; batch classifier loss: 0.159311; batch adversarial loss: 0.487644\n",
      "epoch 76; iter: 0; batch classifier loss: 0.114488; batch adversarial loss: 0.469062\n",
      "epoch 77; iter: 0; batch classifier loss: 0.133814; batch adversarial loss: 0.571313\n",
      "epoch 78; iter: 0; batch classifier loss: 0.178477; batch adversarial loss: 0.495955\n",
      "epoch 79; iter: 0; batch classifier loss: 0.176202; batch adversarial loss: 0.419132\n",
      "epoch 80; iter: 0; batch classifier loss: 0.171672; batch adversarial loss: 0.477216\n",
      "epoch 81; iter: 0; batch classifier loss: 0.153208; batch adversarial loss: 0.499528\n",
      "epoch 82; iter: 0; batch classifier loss: 0.177582; batch adversarial loss: 0.384701\n",
      "epoch 83; iter: 0; batch classifier loss: 0.191499; batch adversarial loss: 0.433160\n",
      "epoch 84; iter: 0; batch classifier loss: 0.170404; batch adversarial loss: 0.440760\n",
      "epoch 85; iter: 0; batch classifier loss: 0.147648; batch adversarial loss: 0.567514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.115962; batch adversarial loss: 0.484715\n",
      "epoch 87; iter: 0; batch classifier loss: 0.199959; batch adversarial loss: 0.402746\n",
      "epoch 88; iter: 0; batch classifier loss: 0.156987; batch adversarial loss: 0.559021\n",
      "epoch 89; iter: 0; batch classifier loss: 0.137044; batch adversarial loss: 0.400537\n",
      "epoch 90; iter: 0; batch classifier loss: 0.140176; batch adversarial loss: 0.516806\n",
      "epoch 91; iter: 0; batch classifier loss: 0.164570; batch adversarial loss: 0.417978\n",
      "epoch 92; iter: 0; batch classifier loss: 0.104283; batch adversarial loss: 0.463187\n",
      "epoch 93; iter: 0; batch classifier loss: 0.112810; batch adversarial loss: 0.496520\n",
      "epoch 94; iter: 0; batch classifier loss: 0.185312; batch adversarial loss: 0.420633\n",
      "epoch 95; iter: 0; batch classifier loss: 0.170301; batch adversarial loss: 0.557639\n",
      "epoch 96; iter: 0; batch classifier loss: 0.091306; batch adversarial loss: 0.496330\n",
      "epoch 97; iter: 0; batch classifier loss: 0.153545; batch adversarial loss: 0.434135\n",
      "epoch 98; iter: 0; batch classifier loss: 0.135879; batch adversarial loss: 0.534731\n",
      "epoch 99; iter: 0; batch classifier loss: 0.143995; batch adversarial loss: 0.517564\n",
      "epoch 100; iter: 0; batch classifier loss: 0.119396; batch adversarial loss: 0.509892\n",
      "epoch 101; iter: 0; batch classifier loss: 0.163444; batch adversarial loss: 0.482609\n",
      "epoch 102; iter: 0; batch classifier loss: 0.139675; batch adversarial loss: 0.409577\n",
      "epoch 103; iter: 0; batch classifier loss: 0.127027; batch adversarial loss: 0.482162\n",
      "epoch 104; iter: 0; batch classifier loss: 0.168763; batch adversarial loss: 0.401842\n",
      "epoch 105; iter: 0; batch classifier loss: 0.136232; batch adversarial loss: 0.452280\n",
      "epoch 106; iter: 0; batch classifier loss: 0.077867; batch adversarial loss: 0.384788\n",
      "epoch 107; iter: 0; batch classifier loss: 0.076504; batch adversarial loss: 0.458303\n",
      "epoch 108; iter: 0; batch classifier loss: 0.085172; batch adversarial loss: 0.479431\n",
      "epoch 109; iter: 0; batch classifier loss: 0.084527; batch adversarial loss: 0.482781\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052816; batch adversarial loss: 0.600538\n",
      "epoch 111; iter: 0; batch classifier loss: 0.120033; batch adversarial loss: 0.494377\n",
      "epoch 112; iter: 0; batch classifier loss: 0.101653; batch adversarial loss: 0.431073\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046017; batch adversarial loss: 0.495420\n",
      "epoch 114; iter: 0; batch classifier loss: 0.091183; batch adversarial loss: 0.403520\n",
      "epoch 115; iter: 0; batch classifier loss: 0.083516; batch adversarial loss: 0.462367\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050654; batch adversarial loss: 0.476548\n",
      "epoch 117; iter: 0; batch classifier loss: 0.158505; batch adversarial loss: 0.476379\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024581; batch adversarial loss: 0.411644\n",
      "epoch 119; iter: 0; batch classifier loss: 0.063022; batch adversarial loss: 0.462630\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041401; batch adversarial loss: 0.523863\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048345; batch adversarial loss: 0.455845\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045466; batch adversarial loss: 0.376528\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037145; batch adversarial loss: 0.477809\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046879; batch adversarial loss: 0.349579\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046770; batch adversarial loss: 0.427033\n",
      "epoch 126; iter: 0; batch classifier loss: 0.110979; batch adversarial loss: 0.425828\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042524; batch adversarial loss: 0.441694\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023019; batch adversarial loss: 0.425757\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042979; batch adversarial loss: 0.475866\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045821; batch adversarial loss: 0.436693\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032889; batch adversarial loss: 0.581481\n",
      "epoch 132; iter: 0; batch classifier loss: 0.055301; batch adversarial loss: 0.362335\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021180; batch adversarial loss: 0.453764\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045663; batch adversarial loss: 0.517768\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057877; batch adversarial loss: 0.430478\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040296; batch adversarial loss: 0.452683\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019527; batch adversarial loss: 0.390247\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039073; batch adversarial loss: 0.448972\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042903; batch adversarial loss: 0.509830\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030566; batch adversarial loss: 0.450035\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038147; batch adversarial loss: 0.470027\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049427; batch adversarial loss: 0.441875\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039883; batch adversarial loss: 0.423209\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049485; batch adversarial loss: 0.445330\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027184; batch adversarial loss: 0.497176\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017937; batch adversarial loss: 0.578387\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034488; batch adversarial loss: 0.368765\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026819; batch adversarial loss: 0.415689\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038409; batch adversarial loss: 0.476643\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029882; batch adversarial loss: 0.417530\n",
      "epoch 151; iter: 0; batch classifier loss: 0.062087; batch adversarial loss: 0.465827\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031522; batch adversarial loss: 0.581303\n",
      "epoch 153; iter: 0; batch classifier loss: 0.051550; batch adversarial loss: 0.477643\n",
      "epoch 154; iter: 0; batch classifier loss: 0.057830; batch adversarial loss: 0.396502\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040637; batch adversarial loss: 0.480486\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017670; batch adversarial loss: 0.491484\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025944; batch adversarial loss: 0.395767\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035664; batch adversarial loss: 0.518057\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033718; batch adversarial loss: 0.483981\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044315; batch adversarial loss: 0.374476\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032647; batch adversarial loss: 0.425898\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013285; batch adversarial loss: 0.445018\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017550; batch adversarial loss: 0.461663\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014254; batch adversarial loss: 0.490683\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041405; batch adversarial loss: 0.509287\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021427; batch adversarial loss: 0.464324\n",
      "epoch 167; iter: 0; batch classifier loss: 0.037326; batch adversarial loss: 0.409897\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022156; batch adversarial loss: 0.414822\n",
      "epoch 169; iter: 0; batch classifier loss: 0.053845; batch adversarial loss: 0.373028\n",
      "epoch 170; iter: 0; batch classifier loss: 0.045551; batch adversarial loss: 0.411461\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047304; batch adversarial loss: 0.398948\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036876; batch adversarial loss: 0.443896\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020259; batch adversarial loss: 0.379486\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022342; batch adversarial loss: 0.411137\n",
      "epoch 175; iter: 0; batch classifier loss: 0.063215; batch adversarial loss: 0.569204\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023610; batch adversarial loss: 0.395474\n",
      "epoch 177; iter: 0; batch classifier loss: 0.041791; batch adversarial loss: 0.551000\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034847; batch adversarial loss: 0.470129\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034548; batch adversarial loss: 0.374302\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018070; batch adversarial loss: 0.451370\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034995; batch adversarial loss: 0.394214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.012617; batch adversarial loss: 0.475973\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011746; batch adversarial loss: 0.459399\n",
      "epoch 184; iter: 0; batch classifier loss: 0.048067; batch adversarial loss: 0.412581\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026361; batch adversarial loss: 0.549470\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012179; batch adversarial loss: 0.495415\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025655; batch adversarial loss: 0.422151\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017493; batch adversarial loss: 0.519494\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033550; batch adversarial loss: 0.492624\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029294; batch adversarial loss: 0.540661\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007526; batch adversarial loss: 0.473849\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023345; batch adversarial loss: 0.493881\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030231; batch adversarial loss: 0.390202\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013554; batch adversarial loss: 0.470308\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014523; batch adversarial loss: 0.480732\n",
      "epoch 196; iter: 0; batch classifier loss: 0.002653; batch adversarial loss: 0.404223\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020432; batch adversarial loss: 0.473726\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016464; batch adversarial loss: 0.446387\n",
      "epoch 199; iter: 0; batch classifier loss: 0.042629; batch adversarial loss: 0.354595\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694639; batch adversarial loss: 0.795951\n",
      "epoch 1; iter: 0; batch classifier loss: 0.402333; batch adversarial loss: 0.766780\n",
      "epoch 2; iter: 0; batch classifier loss: 0.344249; batch adversarial loss: 0.772840\n",
      "epoch 3; iter: 0; batch classifier loss: 0.388479; batch adversarial loss: 0.722712\n",
      "epoch 4; iter: 0; batch classifier loss: 0.306877; batch adversarial loss: 0.665002\n",
      "epoch 5; iter: 0; batch classifier loss: 0.359083; batch adversarial loss: 0.641178\n",
      "epoch 6; iter: 0; batch classifier loss: 0.328823; batch adversarial loss: 0.627554\n",
      "epoch 7; iter: 0; batch classifier loss: 0.221631; batch adversarial loss: 0.615508\n",
      "epoch 8; iter: 0; batch classifier loss: 0.276002; batch adversarial loss: 0.560871\n",
      "epoch 9; iter: 0; batch classifier loss: 0.278776; batch adversarial loss: 0.549089\n",
      "epoch 10; iter: 0; batch classifier loss: 0.274009; batch adversarial loss: 0.512346\n",
      "epoch 11; iter: 0; batch classifier loss: 0.252744; batch adversarial loss: 0.478593\n",
      "epoch 12; iter: 0; batch classifier loss: 0.284402; batch adversarial loss: 0.513241\n",
      "epoch 13; iter: 0; batch classifier loss: 0.267224; batch adversarial loss: 0.484855\n",
      "epoch 14; iter: 0; batch classifier loss: 0.214698; batch adversarial loss: 0.472412\n",
      "epoch 15; iter: 0; batch classifier loss: 0.219276; batch adversarial loss: 0.427630\n",
      "epoch 16; iter: 0; batch classifier loss: 0.207153; batch adversarial loss: 0.399024\n",
      "epoch 17; iter: 0; batch classifier loss: 0.203335; batch adversarial loss: 0.401146\n",
      "epoch 18; iter: 0; batch classifier loss: 0.205184; batch adversarial loss: 0.461655\n",
      "epoch 19; iter: 0; batch classifier loss: 0.209062; batch adversarial loss: 0.379887\n",
      "epoch 20; iter: 0; batch classifier loss: 0.205167; batch adversarial loss: 0.436433\n",
      "epoch 21; iter: 0; batch classifier loss: 0.224555; batch adversarial loss: 0.413938\n",
      "epoch 22; iter: 0; batch classifier loss: 0.156591; batch adversarial loss: 0.433516\n",
      "epoch 23; iter: 0; batch classifier loss: 0.172666; batch adversarial loss: 0.406788\n",
      "epoch 24; iter: 0; batch classifier loss: 0.122387; batch adversarial loss: 0.450749\n",
      "epoch 25; iter: 0; batch classifier loss: 0.168633; batch adversarial loss: 0.438680\n",
      "epoch 26; iter: 0; batch classifier loss: 0.178283; batch adversarial loss: 0.430164\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181436; batch adversarial loss: 0.369719\n",
      "epoch 28; iter: 0; batch classifier loss: 0.143316; batch adversarial loss: 0.419710\n",
      "epoch 29; iter: 0; batch classifier loss: 0.145256; batch adversarial loss: 0.432559\n",
      "epoch 30; iter: 0; batch classifier loss: 0.132311; batch adversarial loss: 0.388147\n",
      "epoch 31; iter: 0; batch classifier loss: 0.161745; batch adversarial loss: 0.409600\n",
      "epoch 32; iter: 0; batch classifier loss: 0.166837; batch adversarial loss: 0.428492\n",
      "epoch 33; iter: 0; batch classifier loss: 0.186449; batch adversarial loss: 0.411488\n",
      "epoch 34; iter: 0; batch classifier loss: 0.120537; batch adversarial loss: 0.433740\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140680; batch adversarial loss: 0.370808\n",
      "epoch 36; iter: 0; batch classifier loss: 0.157598; batch adversarial loss: 0.360433\n",
      "epoch 37; iter: 0; batch classifier loss: 0.121657; batch adversarial loss: 0.390039\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115709; batch adversarial loss: 0.401486\n",
      "epoch 39; iter: 0; batch classifier loss: 0.130114; batch adversarial loss: 0.335994\n",
      "epoch 40; iter: 0; batch classifier loss: 0.170090; batch adversarial loss: 0.391983\n",
      "epoch 41; iter: 0; batch classifier loss: 0.118194; batch adversarial loss: 0.339300\n",
      "epoch 42; iter: 0; batch classifier loss: 0.108765; batch adversarial loss: 0.393100\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117139; batch adversarial loss: 0.411355\n",
      "epoch 44; iter: 0; batch classifier loss: 0.111233; batch adversarial loss: 0.385494\n",
      "epoch 45; iter: 0; batch classifier loss: 0.169877; batch adversarial loss: 0.364824\n",
      "epoch 46; iter: 0; batch classifier loss: 0.135082; batch adversarial loss: 0.317458\n",
      "epoch 47; iter: 0; batch classifier loss: 0.118322; batch adversarial loss: 0.420877\n",
      "epoch 48; iter: 0; batch classifier loss: 0.110958; batch adversarial loss: 0.433357\n",
      "epoch 49; iter: 0; batch classifier loss: 0.095637; batch adversarial loss: 0.381803\n",
      "epoch 50; iter: 0; batch classifier loss: 0.071348; batch adversarial loss: 0.397439\n",
      "epoch 51; iter: 0; batch classifier loss: 0.119499; batch adversarial loss: 0.439764\n",
      "epoch 52; iter: 0; batch classifier loss: 0.075732; batch adversarial loss: 0.448085\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076977; batch adversarial loss: 0.465322\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103499; batch adversarial loss: 0.417469\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103822; batch adversarial loss: 0.408288\n",
      "epoch 56; iter: 0; batch classifier loss: 0.093045; batch adversarial loss: 0.409421\n",
      "epoch 57; iter: 0; batch classifier loss: 0.067397; batch adversarial loss: 0.457841\n",
      "epoch 58; iter: 0; batch classifier loss: 0.119803; batch adversarial loss: 0.456481\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084455; batch adversarial loss: 0.393915\n",
      "epoch 60; iter: 0; batch classifier loss: 0.100291; batch adversarial loss: 0.362003\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099794; batch adversarial loss: 0.424035\n",
      "epoch 62; iter: 0; batch classifier loss: 0.091690; batch adversarial loss: 0.395552\n",
      "epoch 63; iter: 0; batch classifier loss: 0.101966; batch adversarial loss: 0.402570\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076030; batch adversarial loss: 0.371065\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087267; batch adversarial loss: 0.365191\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091547; batch adversarial loss: 0.425891\n",
      "epoch 67; iter: 0; batch classifier loss: 0.060845; batch adversarial loss: 0.394032\n",
      "epoch 68; iter: 0; batch classifier loss: 0.064157; batch adversarial loss: 0.416191\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078546; batch adversarial loss: 0.445799\n",
      "epoch 70; iter: 0; batch classifier loss: 0.083275; batch adversarial loss: 0.433525\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076682; batch adversarial loss: 0.470564\n",
      "epoch 72; iter: 0; batch classifier loss: 0.040247; batch adversarial loss: 0.461051\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055321; batch adversarial loss: 0.389999\n",
      "epoch 74; iter: 0; batch classifier loss: 0.039556; batch adversarial loss: 0.387553\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073627; batch adversarial loss: 0.393936\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046584; batch adversarial loss: 0.452500\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069140; batch adversarial loss: 0.434488\n",
      "epoch 78; iter: 0; batch classifier loss: 0.030064; batch adversarial loss: 0.445112\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053168; batch adversarial loss: 0.346418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.048949; batch adversarial loss: 0.368403\n",
      "epoch 81; iter: 0; batch classifier loss: 0.046789; batch adversarial loss: 0.481564\n",
      "epoch 82; iter: 0; batch classifier loss: 0.036255; batch adversarial loss: 0.485530\n",
      "epoch 83; iter: 0; batch classifier loss: 0.046977; batch adversarial loss: 0.457401\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048618; batch adversarial loss: 0.503772\n",
      "epoch 85; iter: 0; batch classifier loss: 0.024058; batch adversarial loss: 0.547115\n",
      "epoch 86; iter: 0; batch classifier loss: 0.031715; batch adversarial loss: 0.404430\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048983; batch adversarial loss: 0.397222\n",
      "epoch 88; iter: 0; batch classifier loss: 0.020440; batch adversarial loss: 0.357215\n",
      "epoch 89; iter: 0; batch classifier loss: 0.031028; batch adversarial loss: 0.465880\n",
      "epoch 90; iter: 0; batch classifier loss: 0.037159; batch adversarial loss: 0.333918\n",
      "epoch 91; iter: 0; batch classifier loss: 0.034844; batch adversarial loss: 0.437378\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048360; batch adversarial loss: 0.565093\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041718; batch adversarial loss: 0.540701\n",
      "epoch 94; iter: 0; batch classifier loss: 0.059277; batch adversarial loss: 0.446135\n",
      "epoch 95; iter: 0; batch classifier loss: 0.099629; batch adversarial loss: 0.600157\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082823; batch adversarial loss: 0.510740\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076786; batch adversarial loss: 0.468520\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042947; batch adversarial loss: 0.441335\n",
      "epoch 99; iter: 0; batch classifier loss: 0.133552; batch adversarial loss: 0.575493\n",
      "epoch 100; iter: 0; batch classifier loss: 0.093682; batch adversarial loss: 0.454267\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075342; batch adversarial loss: 0.487830\n",
      "epoch 102; iter: 0; batch classifier loss: 0.120383; batch adversarial loss: 0.517361\n",
      "epoch 103; iter: 0; batch classifier loss: 0.142870; batch adversarial loss: 0.595978\n",
      "epoch 104; iter: 0; batch classifier loss: 0.103941; batch adversarial loss: 0.661171\n",
      "epoch 105; iter: 0; batch classifier loss: 0.124484; batch adversarial loss: 0.547279\n",
      "epoch 106; iter: 0; batch classifier loss: 0.133279; batch adversarial loss: 0.560182\n",
      "epoch 107; iter: 0; batch classifier loss: 0.117516; batch adversarial loss: 0.592654\n",
      "epoch 108; iter: 0; batch classifier loss: 0.175031; batch adversarial loss: 0.640458\n",
      "epoch 109; iter: 0; batch classifier loss: 0.095294; batch adversarial loss: 0.524695\n",
      "epoch 110; iter: 0; batch classifier loss: 0.148560; batch adversarial loss: 0.552327\n",
      "epoch 111; iter: 0; batch classifier loss: 0.154729; batch adversarial loss: 0.541877\n",
      "epoch 112; iter: 0; batch classifier loss: 0.086304; batch adversarial loss: 0.406858\n",
      "epoch 113; iter: 0; batch classifier loss: 0.107658; batch adversarial loss: 0.445525\n",
      "epoch 114; iter: 0; batch classifier loss: 0.076352; batch adversarial loss: 0.466219\n",
      "epoch 115; iter: 0; batch classifier loss: 0.126584; batch adversarial loss: 0.557748\n",
      "epoch 116; iter: 0; batch classifier loss: 0.144569; batch adversarial loss: 0.528138\n",
      "epoch 117; iter: 0; batch classifier loss: 0.138761; batch adversarial loss: 0.543988\n",
      "epoch 118; iter: 0; batch classifier loss: 0.115952; batch adversarial loss: 0.488532\n",
      "epoch 119; iter: 0; batch classifier loss: 0.067570; batch adversarial loss: 0.392233\n",
      "epoch 120; iter: 0; batch classifier loss: 0.143813; batch adversarial loss: 0.525226\n",
      "epoch 121; iter: 0; batch classifier loss: 0.128399; batch adversarial loss: 0.484034\n",
      "epoch 122; iter: 0; batch classifier loss: 0.069678; batch adversarial loss: 0.485283\n",
      "epoch 123; iter: 0; batch classifier loss: 0.113162; batch adversarial loss: 0.562888\n",
      "epoch 124; iter: 0; batch classifier loss: 0.157710; batch adversarial loss: 0.540827\n",
      "epoch 125; iter: 0; batch classifier loss: 0.098170; batch adversarial loss: 0.529463\n",
      "epoch 126; iter: 0; batch classifier loss: 0.103976; batch adversarial loss: 0.429637\n",
      "epoch 127; iter: 0; batch classifier loss: 0.079114; batch adversarial loss: 0.499762\n",
      "epoch 128; iter: 0; batch classifier loss: 0.097555; batch adversarial loss: 0.419033\n",
      "epoch 129; iter: 0; batch classifier loss: 0.085391; batch adversarial loss: 0.410074\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034859; batch adversarial loss: 0.460315\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025549; batch adversarial loss: 0.346687\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043898; batch adversarial loss: 0.390112\n",
      "epoch 133; iter: 0; batch classifier loss: 0.017923; batch adversarial loss: 0.431312\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027467; batch adversarial loss: 0.441921\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030112; batch adversarial loss: 0.378146\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047431; batch adversarial loss: 0.455683\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030642; batch adversarial loss: 0.508144\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019608; batch adversarial loss: 0.563884\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020445; batch adversarial loss: 0.394507\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041390; batch adversarial loss: 0.431214\n",
      "epoch 141; iter: 0; batch classifier loss: 0.073311; batch adversarial loss: 0.400586\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037827; batch adversarial loss: 0.560490\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043720; batch adversarial loss: 0.499719\n",
      "epoch 144; iter: 0; batch classifier loss: 0.073765; batch adversarial loss: 0.382984\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022428; batch adversarial loss: 0.440819\n",
      "epoch 146; iter: 0; batch classifier loss: 0.120083; batch adversarial loss: 0.424793\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052401; batch adversarial loss: 0.446799\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032502; batch adversarial loss: 0.563157\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037743; batch adversarial loss: 0.481398\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035704; batch adversarial loss: 0.490981\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039013; batch adversarial loss: 0.515065\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035643; batch adversarial loss: 0.462494\n",
      "epoch 153; iter: 0; batch classifier loss: 0.052875; batch adversarial loss: 0.411169\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026366; batch adversarial loss: 0.480559\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052453; batch adversarial loss: 0.465715\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045216; batch adversarial loss: 0.394136\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033628; batch adversarial loss: 0.517984\n",
      "epoch 158; iter: 0; batch classifier loss: 0.043211; batch adversarial loss: 0.466300\n",
      "epoch 159; iter: 0; batch classifier loss: 0.085288; batch adversarial loss: 0.476430\n",
      "epoch 160; iter: 0; batch classifier loss: 0.063106; batch adversarial loss: 0.372455\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016382; batch adversarial loss: 0.349320\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037020; batch adversarial loss: 0.518350\n",
      "epoch 163; iter: 0; batch classifier loss: 0.057174; batch adversarial loss: 0.485634\n",
      "epoch 164; iter: 0; batch classifier loss: 0.079989; batch adversarial loss: 0.480056\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029069; batch adversarial loss: 0.476758\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031197; batch adversarial loss: 0.413431\n",
      "epoch 167; iter: 0; batch classifier loss: 0.047811; batch adversarial loss: 0.479217\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013705; batch adversarial loss: 0.384330\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023252; batch adversarial loss: 0.469597\n",
      "epoch 170; iter: 0; batch classifier loss: 0.041628; batch adversarial loss: 0.453371\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022190; batch adversarial loss: 0.399606\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020765; batch adversarial loss: 0.439398\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017032; batch adversarial loss: 0.452958\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039105; batch adversarial loss: 0.472834\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036610; batch adversarial loss: 0.519181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.031603; batch adversarial loss: 0.512018\n",
      "epoch 177; iter: 0; batch classifier loss: 0.045303; batch adversarial loss: 0.448334\n",
      "epoch 178; iter: 0; batch classifier loss: 0.041050; batch adversarial loss: 0.542076\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022519; batch adversarial loss: 0.479224\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020276; batch adversarial loss: 0.427403\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033123; batch adversarial loss: 0.426835\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037394; batch adversarial loss: 0.435783\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016454; batch adversarial loss: 0.512648\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037004; batch adversarial loss: 0.433645\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015805; batch adversarial loss: 0.410051\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029178; batch adversarial loss: 0.564347\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039520; batch adversarial loss: 0.472098\n",
      "epoch 188; iter: 0; batch classifier loss: 0.066987; batch adversarial loss: 0.392826\n",
      "epoch 189; iter: 0; batch classifier loss: 0.054900; batch adversarial loss: 0.512997\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025797; batch adversarial loss: 0.467019\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020375; batch adversarial loss: 0.469753\n",
      "epoch 192; iter: 0; batch classifier loss: 0.044134; batch adversarial loss: 0.551215\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018705; batch adversarial loss: 0.379763\n",
      "epoch 194; iter: 0; batch classifier loss: 0.043630; batch adversarial loss: 0.530948\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027312; batch adversarial loss: 0.322676\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024041; batch adversarial loss: 0.471787\n",
      "epoch 197; iter: 0; batch classifier loss: 0.030078; batch adversarial loss: 0.460690\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017746; batch adversarial loss: 0.481598\n",
      "epoch 199; iter: 0; batch classifier loss: 0.071807; batch adversarial loss: 0.453220\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704805; batch adversarial loss: 0.725250\n",
      "epoch 1; iter: 0; batch classifier loss: 0.496707; batch adversarial loss: 0.681354\n",
      "epoch 2; iter: 0; batch classifier loss: 0.413437; batch adversarial loss: 0.638486\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393007; batch adversarial loss: 0.613454\n",
      "epoch 4; iter: 0; batch classifier loss: 0.394504; batch adversarial loss: 0.613028\n",
      "epoch 5; iter: 0; batch classifier loss: 0.350072; batch adversarial loss: 0.588040\n",
      "epoch 6; iter: 0; batch classifier loss: 0.370053; batch adversarial loss: 0.573619\n",
      "epoch 7; iter: 0; batch classifier loss: 0.340219; batch adversarial loss: 0.601576\n",
      "epoch 8; iter: 0; batch classifier loss: 0.374701; batch adversarial loss: 0.530855\n",
      "epoch 9; iter: 0; batch classifier loss: 0.389851; batch adversarial loss: 0.541839\n",
      "epoch 10; iter: 0; batch classifier loss: 0.363454; batch adversarial loss: 0.548387\n",
      "epoch 11; iter: 0; batch classifier loss: 0.456390; batch adversarial loss: 0.504069\n",
      "epoch 12; iter: 0; batch classifier loss: 0.569228; batch adversarial loss: 0.533541\n",
      "epoch 13; iter: 0; batch classifier loss: 0.339853; batch adversarial loss: 0.494596\n",
      "epoch 14; iter: 0; batch classifier loss: 0.407373; batch adversarial loss: 0.536241\n",
      "epoch 15; iter: 0; batch classifier loss: 0.359815; batch adversarial loss: 0.509595\n",
      "epoch 16; iter: 0; batch classifier loss: 0.303964; batch adversarial loss: 0.543753\n",
      "epoch 17; iter: 0; batch classifier loss: 0.324026; batch adversarial loss: 0.496882\n",
      "epoch 18; iter: 0; batch classifier loss: 0.296197; batch adversarial loss: 0.494154\n",
      "epoch 19; iter: 0; batch classifier loss: 0.312488; batch adversarial loss: 0.424633\n",
      "epoch 20; iter: 0; batch classifier loss: 0.388774; batch adversarial loss: 0.455921\n",
      "epoch 21; iter: 0; batch classifier loss: 0.264118; batch adversarial loss: 0.564726\n",
      "epoch 22; iter: 0; batch classifier loss: 0.320827; batch adversarial loss: 0.429621\n",
      "epoch 23; iter: 0; batch classifier loss: 0.273298; batch adversarial loss: 0.446080\n",
      "epoch 24; iter: 0; batch classifier loss: 0.284005; batch adversarial loss: 0.536635\n",
      "epoch 25; iter: 0; batch classifier loss: 0.300866; batch adversarial loss: 0.430607\n",
      "epoch 26; iter: 0; batch classifier loss: 0.298597; batch adversarial loss: 0.483408\n",
      "epoch 27; iter: 0; batch classifier loss: 0.234877; batch adversarial loss: 0.426078\n",
      "epoch 28; iter: 0; batch classifier loss: 0.328583; batch adversarial loss: 0.473986\n",
      "epoch 29; iter: 0; batch classifier loss: 0.248317; batch adversarial loss: 0.407981\n",
      "epoch 30; iter: 0; batch classifier loss: 0.268242; batch adversarial loss: 0.433574\n",
      "epoch 31; iter: 0; batch classifier loss: 0.236003; batch adversarial loss: 0.468393\n",
      "epoch 32; iter: 0; batch classifier loss: 0.262172; batch adversarial loss: 0.483725\n",
      "epoch 33; iter: 0; batch classifier loss: 0.268618; batch adversarial loss: 0.494437\n",
      "epoch 34; iter: 0; batch classifier loss: 0.205230; batch adversarial loss: 0.512489\n",
      "epoch 35; iter: 0; batch classifier loss: 0.247361; batch adversarial loss: 0.428309\n",
      "epoch 36; iter: 0; batch classifier loss: 0.240358; batch adversarial loss: 0.581996\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166537; batch adversarial loss: 0.460035\n",
      "epoch 38; iter: 0; batch classifier loss: 0.323550; batch adversarial loss: 0.435645\n",
      "epoch 39; iter: 0; batch classifier loss: 0.179670; batch adversarial loss: 0.448746\n",
      "epoch 40; iter: 0; batch classifier loss: 0.228065; batch adversarial loss: 0.481627\n",
      "epoch 41; iter: 0; batch classifier loss: 0.211574; batch adversarial loss: 0.534404\n",
      "epoch 42; iter: 0; batch classifier loss: 0.198940; batch adversarial loss: 0.483679\n",
      "epoch 43; iter: 0; batch classifier loss: 0.215610; batch adversarial loss: 0.437018\n",
      "epoch 44; iter: 0; batch classifier loss: 0.220673; batch adversarial loss: 0.449350\n",
      "epoch 45; iter: 0; batch classifier loss: 0.312744; batch adversarial loss: 0.461063\n",
      "epoch 46; iter: 0; batch classifier loss: 0.263291; batch adversarial loss: 0.436762\n",
      "epoch 47; iter: 0; batch classifier loss: 0.234994; batch adversarial loss: 0.494501\n",
      "epoch 48; iter: 0; batch classifier loss: 0.314699; batch adversarial loss: 0.448127\n",
      "epoch 49; iter: 0; batch classifier loss: 0.186329; batch adversarial loss: 0.424881\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129907; batch adversarial loss: 0.528711\n",
      "epoch 51; iter: 0; batch classifier loss: 0.211752; batch adversarial loss: 0.458857\n",
      "epoch 52; iter: 0; batch classifier loss: 0.127273; batch adversarial loss: 0.520211\n",
      "epoch 53; iter: 0; batch classifier loss: 0.223052; batch adversarial loss: 0.470805\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129922; batch adversarial loss: 0.529633\n",
      "epoch 55; iter: 0; batch classifier loss: 0.217463; batch adversarial loss: 0.448222\n",
      "epoch 56; iter: 0; batch classifier loss: 0.262411; batch adversarial loss: 0.470816\n",
      "epoch 57; iter: 0; batch classifier loss: 0.099784; batch adversarial loss: 0.541325\n",
      "epoch 58; iter: 0; batch classifier loss: 0.095693; batch adversarial loss: 0.375237\n",
      "epoch 59; iter: 0; batch classifier loss: 0.147352; batch adversarial loss: 0.493992\n",
      "epoch 60; iter: 0; batch classifier loss: 0.313427; batch adversarial loss: 0.400508\n",
      "epoch 61; iter: 0; batch classifier loss: 0.101318; batch adversarial loss: 0.340419\n",
      "epoch 62; iter: 0; batch classifier loss: 0.145592; batch adversarial loss: 0.410829\n",
      "epoch 63; iter: 0; batch classifier loss: 0.162079; batch adversarial loss: 0.496905\n",
      "epoch 64; iter: 0; batch classifier loss: 0.194568; batch adversarial loss: 0.483717\n",
      "epoch 65; iter: 0; batch classifier loss: 0.184839; batch adversarial loss: 0.435935\n",
      "epoch 66; iter: 0; batch classifier loss: 0.165596; batch adversarial loss: 0.411944\n",
      "epoch 67; iter: 0; batch classifier loss: 0.220811; batch adversarial loss: 0.601921\n",
      "epoch 68; iter: 0; batch classifier loss: 0.196304; batch adversarial loss: 0.399191\n",
      "epoch 69; iter: 0; batch classifier loss: 0.195834; batch adversarial loss: 0.518231\n",
      "epoch 70; iter: 0; batch classifier loss: 0.140055; batch adversarial loss: 0.530574\n",
      "epoch 71; iter: 0; batch classifier loss: 0.171270; batch adversarial loss: 0.447192\n",
      "epoch 72; iter: 0; batch classifier loss: 0.250211; batch adversarial loss: 0.399616\n",
      "epoch 73; iter: 0; batch classifier loss: 0.082736; batch adversarial loss: 0.482990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.075935; batch adversarial loss: 0.446124\n",
      "epoch 75; iter: 0; batch classifier loss: 0.086131; batch adversarial loss: 0.467708\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064361; batch adversarial loss: 0.420845\n",
      "epoch 77; iter: 0; batch classifier loss: 0.138761; batch adversarial loss: 0.508521\n",
      "epoch 78; iter: 0; batch classifier loss: 0.122708; batch adversarial loss: 0.492277\n",
      "epoch 79; iter: 0; batch classifier loss: 0.189165; batch adversarial loss: 0.509878\n",
      "epoch 80; iter: 0; batch classifier loss: 0.168803; batch adversarial loss: 0.494621\n",
      "epoch 81; iter: 0; batch classifier loss: 0.225806; batch adversarial loss: 0.446017\n",
      "epoch 82; iter: 0; batch classifier loss: 0.189424; batch adversarial loss: 0.473003\n",
      "epoch 83; iter: 0; batch classifier loss: 0.204574; batch adversarial loss: 0.491508\n",
      "epoch 84; iter: 0; batch classifier loss: 0.144200; batch adversarial loss: 0.448776\n",
      "epoch 85; iter: 0; batch classifier loss: 0.159621; batch adversarial loss: 0.454388\n",
      "epoch 86; iter: 0; batch classifier loss: 0.163196; batch adversarial loss: 0.514275\n",
      "epoch 87; iter: 0; batch classifier loss: 0.109475; batch adversarial loss: 0.351657\n",
      "epoch 88; iter: 0; batch classifier loss: 0.119542; batch adversarial loss: 0.379789\n",
      "epoch 89; iter: 0; batch classifier loss: 0.122429; batch adversarial loss: 0.506425\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055362; batch adversarial loss: 0.447045\n",
      "epoch 91; iter: 0; batch classifier loss: 0.086649; batch adversarial loss: 0.476432\n",
      "epoch 92; iter: 0; batch classifier loss: 0.113132; batch adversarial loss: 0.477682\n",
      "epoch 93; iter: 0; batch classifier loss: 0.125565; batch adversarial loss: 0.341014\n",
      "epoch 94; iter: 0; batch classifier loss: 0.080884; batch adversarial loss: 0.525343\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050255; batch adversarial loss: 0.545951\n",
      "epoch 96; iter: 0; batch classifier loss: 0.089062; batch adversarial loss: 0.548442\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069468; batch adversarial loss: 0.411499\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063334; batch adversarial loss: 0.442884\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039128; batch adversarial loss: 0.389592\n",
      "epoch 100; iter: 0; batch classifier loss: 0.078936; batch adversarial loss: 0.464598\n",
      "epoch 101; iter: 0; batch classifier loss: 0.060516; batch adversarial loss: 0.371552\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060669; batch adversarial loss: 0.382900\n",
      "epoch 103; iter: 0; batch classifier loss: 0.089589; batch adversarial loss: 0.436527\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031469; batch adversarial loss: 0.475264\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043555; batch adversarial loss: 0.438097\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034421; batch adversarial loss: 0.482722\n",
      "epoch 107; iter: 0; batch classifier loss: 0.067217; batch adversarial loss: 0.466640\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052947; batch adversarial loss: 0.445387\n",
      "epoch 109; iter: 0; batch classifier loss: 0.028003; batch adversarial loss: 0.470295\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061511; batch adversarial loss: 0.450429\n",
      "epoch 111; iter: 0; batch classifier loss: 0.026687; batch adversarial loss: 0.504544\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032512; batch adversarial loss: 0.424024\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052203; batch adversarial loss: 0.503295\n",
      "epoch 114; iter: 0; batch classifier loss: 0.021309; batch adversarial loss: 0.463462\n",
      "epoch 115; iter: 0; batch classifier loss: 0.025571; batch adversarial loss: 0.466611\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034134; batch adversarial loss: 0.418537\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030829; batch adversarial loss: 0.415984\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033737; batch adversarial loss: 0.463718\n",
      "epoch 119; iter: 0; batch classifier loss: 0.024975; batch adversarial loss: 0.421503\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038431; batch adversarial loss: 0.421495\n",
      "epoch 121; iter: 0; batch classifier loss: 0.079833; batch adversarial loss: 0.431009\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029368; batch adversarial loss: 0.440322\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019347; batch adversarial loss: 0.521731\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054127; batch adversarial loss: 0.448808\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020378; batch adversarial loss: 0.535413\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022174; batch adversarial loss: 0.508364\n",
      "epoch 127; iter: 0; batch classifier loss: 0.038670; batch adversarial loss: 0.475392\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038517; batch adversarial loss: 0.437501\n",
      "epoch 129; iter: 0; batch classifier loss: 0.013246; batch adversarial loss: 0.557750\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020153; batch adversarial loss: 0.443361\n",
      "epoch 131; iter: 0; batch classifier loss: 0.010449; batch adversarial loss: 0.524132\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026621; batch adversarial loss: 0.439390\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042537; batch adversarial loss: 0.405634\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021466; batch adversarial loss: 0.606530\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013987; batch adversarial loss: 0.540997\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028248; batch adversarial loss: 0.425473\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027500; batch adversarial loss: 0.485787\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011696; batch adversarial loss: 0.479430\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034731; batch adversarial loss: 0.413219\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034292; batch adversarial loss: 0.498711\n",
      "epoch 141; iter: 0; batch classifier loss: 0.005392; batch adversarial loss: 0.405435\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013275; batch adversarial loss: 0.443713\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017457; batch adversarial loss: 0.463819\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031498; batch adversarial loss: 0.436599\n",
      "epoch 145; iter: 0; batch classifier loss: 0.010805; batch adversarial loss: 0.532786\n",
      "epoch 146; iter: 0; batch classifier loss: 0.014274; batch adversarial loss: 0.410285\n",
      "epoch 147; iter: 0; batch classifier loss: 0.008637; batch adversarial loss: 0.416921\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022566; batch adversarial loss: 0.414324\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035802; batch adversarial loss: 0.335355\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019955; batch adversarial loss: 0.408708\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009703; batch adversarial loss: 0.440255\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022167; batch adversarial loss: 0.477236\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042386; batch adversarial loss: 0.468398\n",
      "epoch 154; iter: 0; batch classifier loss: 0.006345; batch adversarial loss: 0.490425\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011391; batch adversarial loss: 0.505863\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016171; batch adversarial loss: 0.426382\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011497; batch adversarial loss: 0.416226\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010180; batch adversarial loss: 0.485750\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007738; batch adversarial loss: 0.466685\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017896; batch adversarial loss: 0.409114\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015740; batch adversarial loss: 0.471911\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015764; batch adversarial loss: 0.449288\n",
      "epoch 163; iter: 0; batch classifier loss: 0.005526; batch adversarial loss: 0.417395\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028066; batch adversarial loss: 0.462282\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007646; batch adversarial loss: 0.532976\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022498; batch adversarial loss: 0.377214\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014083; batch adversarial loss: 0.455146\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022251; batch adversarial loss: 0.537829\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013053; batch adversarial loss: 0.454000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.009022; batch adversarial loss: 0.498772\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022129; batch adversarial loss: 0.413902\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007560; batch adversarial loss: 0.434479\n",
      "epoch 173; iter: 0; batch classifier loss: 0.005577; batch adversarial loss: 0.445051\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019462; batch adversarial loss: 0.558632\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022408; batch adversarial loss: 0.480847\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007648; batch adversarial loss: 0.445578\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026020; batch adversarial loss: 0.483291\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025204; batch adversarial loss: 0.419342\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009998; batch adversarial loss: 0.465340\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023140; batch adversarial loss: 0.523396\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007148; batch adversarial loss: 0.481641\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014776; batch adversarial loss: 0.432841\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008009; batch adversarial loss: 0.382842\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020656; batch adversarial loss: 0.477550\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006824; batch adversarial loss: 0.387035\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023377; batch adversarial loss: 0.555202\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011500; batch adversarial loss: 0.397776\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010291; batch adversarial loss: 0.522401\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015632; batch adversarial loss: 0.472618\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027960; batch adversarial loss: 0.416275\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005772; batch adversarial loss: 0.446098\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013651; batch adversarial loss: 0.403644\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011813; batch adversarial loss: 0.440576\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005585; batch adversarial loss: 0.437497\n",
      "epoch 195; iter: 0; batch classifier loss: 0.003129; batch adversarial loss: 0.448996\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013612; batch adversarial loss: 0.456156\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026020; batch adversarial loss: 0.482724\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025161; batch adversarial loss: 0.334637\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010839; batch adversarial loss: 0.579949\n",
      "epoch 0; iter: 0; batch classifier loss: 0.661198; batch adversarial loss: 0.672875\n",
      "epoch 1; iter: 0; batch classifier loss: 0.420404; batch adversarial loss: 0.667479\n",
      "epoch 2; iter: 0; batch classifier loss: 0.405727; batch adversarial loss: 0.563382\n",
      "epoch 3; iter: 0; batch classifier loss: 0.397723; batch adversarial loss: 0.617895\n",
      "epoch 4; iter: 0; batch classifier loss: 0.361782; batch adversarial loss: 0.557438\n",
      "epoch 5; iter: 0; batch classifier loss: 0.335191; batch adversarial loss: 0.547382\n",
      "epoch 6; iter: 0; batch classifier loss: 0.334998; batch adversarial loss: 0.549487\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306535; batch adversarial loss: 0.548079\n",
      "epoch 8; iter: 0; batch classifier loss: 0.294310; batch adversarial loss: 0.468054\n",
      "epoch 9; iter: 0; batch classifier loss: 0.246532; batch adversarial loss: 0.478196\n",
      "epoch 10; iter: 0; batch classifier loss: 0.251625; batch adversarial loss: 0.493626\n",
      "epoch 11; iter: 0; batch classifier loss: 0.233679; batch adversarial loss: 0.598149\n",
      "epoch 12; iter: 0; batch classifier loss: 0.262742; batch adversarial loss: 0.445226\n",
      "epoch 13; iter: 0; batch classifier loss: 0.235716; batch adversarial loss: 0.564846\n",
      "epoch 14; iter: 0; batch classifier loss: 0.199438; batch adversarial loss: 0.468761\n",
      "epoch 15; iter: 0; batch classifier loss: 0.196757; batch adversarial loss: 0.497389\n",
      "epoch 16; iter: 0; batch classifier loss: 0.230598; batch adversarial loss: 0.438611\n",
      "epoch 17; iter: 0; batch classifier loss: 0.222246; batch adversarial loss: 0.448370\n",
      "epoch 18; iter: 0; batch classifier loss: 0.195432; batch adversarial loss: 0.505327\n",
      "epoch 19; iter: 0; batch classifier loss: 0.205399; batch adversarial loss: 0.495970\n",
      "epoch 20; iter: 0; batch classifier loss: 0.211231; batch adversarial loss: 0.473943\n",
      "epoch 21; iter: 0; batch classifier loss: 0.182920; batch adversarial loss: 0.490763\n",
      "epoch 22; iter: 0; batch classifier loss: 0.242165; batch adversarial loss: 0.432713\n",
      "epoch 23; iter: 0; batch classifier loss: 0.192944; batch adversarial loss: 0.514046\n",
      "epoch 24; iter: 0; batch classifier loss: 0.150118; batch adversarial loss: 0.402801\n",
      "epoch 25; iter: 0; batch classifier loss: 0.168570; batch adversarial loss: 0.521228\n",
      "epoch 26; iter: 0; batch classifier loss: 0.163492; batch adversarial loss: 0.414596\n",
      "epoch 27; iter: 0; batch classifier loss: 0.145371; batch adversarial loss: 0.514422\n",
      "epoch 28; iter: 0; batch classifier loss: 0.130532; batch adversarial loss: 0.451038\n",
      "epoch 29; iter: 0; batch classifier loss: 0.134616; batch adversarial loss: 0.415280\n",
      "epoch 30; iter: 0; batch classifier loss: 0.136250; batch adversarial loss: 0.400880\n",
      "epoch 31; iter: 0; batch classifier loss: 0.148481; batch adversarial loss: 0.490331\n",
      "epoch 32; iter: 0; batch classifier loss: 0.163720; batch adversarial loss: 0.476633\n",
      "epoch 33; iter: 0; batch classifier loss: 0.151670; batch adversarial loss: 0.521419\n",
      "epoch 34; iter: 0; batch classifier loss: 0.192061; batch adversarial loss: 0.388458\n",
      "epoch 35; iter: 0; batch classifier loss: 0.188084; batch adversarial loss: 0.397869\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140702; batch adversarial loss: 0.452833\n",
      "epoch 37; iter: 0; batch classifier loss: 0.133880; batch adversarial loss: 0.392800\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122521; batch adversarial loss: 0.433551\n",
      "epoch 39; iter: 0; batch classifier loss: 0.157387; batch adversarial loss: 0.536674\n",
      "epoch 40; iter: 0; batch classifier loss: 0.133305; batch adversarial loss: 0.466199\n",
      "epoch 41; iter: 0; batch classifier loss: 0.197673; batch adversarial loss: 0.394041\n",
      "epoch 42; iter: 0; batch classifier loss: 0.138992; batch adversarial loss: 0.486268\n",
      "epoch 43; iter: 0; batch classifier loss: 0.158259; batch adversarial loss: 0.451067\n",
      "epoch 44; iter: 0; batch classifier loss: 0.133924; batch adversarial loss: 0.460444\n",
      "epoch 45; iter: 0; batch classifier loss: 0.122826; batch adversarial loss: 0.457583\n",
      "epoch 46; iter: 0; batch classifier loss: 0.120404; batch adversarial loss: 0.469061\n",
      "epoch 47; iter: 0; batch classifier loss: 0.166960; batch adversarial loss: 0.451454\n",
      "epoch 48; iter: 0; batch classifier loss: 0.147865; batch adversarial loss: 0.391002\n",
      "epoch 49; iter: 0; batch classifier loss: 0.097177; batch adversarial loss: 0.383269\n",
      "epoch 50; iter: 0; batch classifier loss: 0.068306; batch adversarial loss: 0.462877\n",
      "epoch 51; iter: 0; batch classifier loss: 0.140396; batch adversarial loss: 0.339265\n",
      "epoch 52; iter: 0; batch classifier loss: 0.127319; batch adversarial loss: 0.402462\n",
      "epoch 53; iter: 0; batch classifier loss: 0.099679; batch adversarial loss: 0.417597\n",
      "epoch 54; iter: 0; batch classifier loss: 0.069728; batch adversarial loss: 0.487367\n",
      "epoch 55; iter: 0; batch classifier loss: 0.106148; batch adversarial loss: 0.412551\n",
      "epoch 56; iter: 0; batch classifier loss: 0.057957; batch adversarial loss: 0.489362\n",
      "epoch 57; iter: 0; batch classifier loss: 0.115533; batch adversarial loss: 0.357445\n",
      "epoch 58; iter: 0; batch classifier loss: 0.124590; batch adversarial loss: 0.505480\n",
      "epoch 59; iter: 0; batch classifier loss: 0.096006; batch adversarial loss: 0.510849\n",
      "epoch 60; iter: 0; batch classifier loss: 0.099328; batch adversarial loss: 0.521528\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090565; batch adversarial loss: 0.501057\n",
      "epoch 62; iter: 0; batch classifier loss: 0.119981; batch adversarial loss: 0.339209\n",
      "epoch 63; iter: 0; batch classifier loss: 0.082802; batch adversarial loss: 0.504687\n",
      "epoch 64; iter: 0; batch classifier loss: 0.128751; batch adversarial loss: 0.465592\n",
      "epoch 65; iter: 0; batch classifier loss: 0.167494; batch adversarial loss: 0.407882\n",
      "epoch 66; iter: 0; batch classifier loss: 0.064319; batch adversarial loss: 0.499757\n",
      "epoch 67; iter: 0; batch classifier loss: 0.075296; batch adversarial loss: 0.497023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.095912; batch adversarial loss: 0.430557\n",
      "epoch 69; iter: 0; batch classifier loss: 0.171125; batch adversarial loss: 0.490961\n",
      "epoch 70; iter: 0; batch classifier loss: 0.077737; batch adversarial loss: 0.441914\n",
      "epoch 71; iter: 0; batch classifier loss: 0.072525; batch adversarial loss: 0.488039\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077711; batch adversarial loss: 0.523024\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079333; batch adversarial loss: 0.490914\n",
      "epoch 74; iter: 0; batch classifier loss: 0.149030; batch adversarial loss: 0.486237\n",
      "epoch 75; iter: 0; batch classifier loss: 0.078595; batch adversarial loss: 0.338448\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069786; batch adversarial loss: 0.483706\n",
      "epoch 77; iter: 0; batch classifier loss: 0.066421; batch adversarial loss: 0.438531\n",
      "epoch 78; iter: 0; batch classifier loss: 0.087000; batch adversarial loss: 0.486917\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072049; batch adversarial loss: 0.376210\n",
      "epoch 80; iter: 0; batch classifier loss: 0.059938; batch adversarial loss: 0.414587\n",
      "epoch 81; iter: 0; batch classifier loss: 0.082735; batch adversarial loss: 0.480207\n",
      "epoch 82; iter: 0; batch classifier loss: 0.036868; batch adversarial loss: 0.484170\n",
      "epoch 83; iter: 0; batch classifier loss: 0.058699; batch adversarial loss: 0.438914\n",
      "epoch 84; iter: 0; batch classifier loss: 0.095068; batch adversarial loss: 0.516075\n",
      "epoch 85; iter: 0; batch classifier loss: 0.087994; batch adversarial loss: 0.457282\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074120; batch adversarial loss: 0.490056\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106093; batch adversarial loss: 0.502008\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088582; batch adversarial loss: 0.483436\n",
      "epoch 89; iter: 0; batch classifier loss: 0.093464; batch adversarial loss: 0.400948\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056273; batch adversarial loss: 0.458663\n",
      "epoch 91; iter: 0; batch classifier loss: 0.033068; batch adversarial loss: 0.496906\n",
      "epoch 92; iter: 0; batch classifier loss: 0.109784; batch adversarial loss: 0.414819\n",
      "epoch 93; iter: 0; batch classifier loss: 0.027455; batch adversarial loss: 0.477244\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048899; batch adversarial loss: 0.471790\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048880; batch adversarial loss: 0.475906\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059762; batch adversarial loss: 0.480996\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065324; batch adversarial loss: 0.417221\n",
      "epoch 98; iter: 0; batch classifier loss: 0.083877; batch adversarial loss: 0.397064\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049735; batch adversarial loss: 0.458520\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051026; batch adversarial loss: 0.536526\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043234; batch adversarial loss: 0.390899\n",
      "epoch 102; iter: 0; batch classifier loss: 0.035443; batch adversarial loss: 0.486388\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054710; batch adversarial loss: 0.437551\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044584; batch adversarial loss: 0.411803\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049778; batch adversarial loss: 0.498029\n",
      "epoch 106; iter: 0; batch classifier loss: 0.023226; batch adversarial loss: 0.437049\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024199; batch adversarial loss: 0.541469\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059688; batch adversarial loss: 0.443290\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030140; batch adversarial loss: 0.417645\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030739; batch adversarial loss: 0.464134\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058905; batch adversarial loss: 0.448660\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055224; batch adversarial loss: 0.442380\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038735; batch adversarial loss: 0.478676\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041430; batch adversarial loss: 0.370933\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049672; batch adversarial loss: 0.418844\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040663; batch adversarial loss: 0.360055\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043716; batch adversarial loss: 0.431991\n",
      "epoch 118; iter: 0; batch classifier loss: 0.027512; batch adversarial loss: 0.445356\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029230; batch adversarial loss: 0.432340\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034406; batch adversarial loss: 0.473815\n",
      "epoch 121; iter: 0; batch classifier loss: 0.015706; batch adversarial loss: 0.551713\n",
      "epoch 122; iter: 0; batch classifier loss: 0.022089; batch adversarial loss: 0.389504\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053310; batch adversarial loss: 0.470570\n",
      "epoch 124; iter: 0; batch classifier loss: 0.072765; batch adversarial loss: 0.433576\n",
      "epoch 125; iter: 0; batch classifier loss: 0.013536; batch adversarial loss: 0.426080\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027664; batch adversarial loss: 0.370524\n",
      "epoch 127; iter: 0; batch classifier loss: 0.055474; batch adversarial loss: 0.445719\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051012; batch adversarial loss: 0.430857\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031386; batch adversarial loss: 0.499331\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018350; batch adversarial loss: 0.429476\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032919; batch adversarial loss: 0.471960\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045848; batch adversarial loss: 0.389295\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026361; batch adversarial loss: 0.333121\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030339; batch adversarial loss: 0.403903\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022687; batch adversarial loss: 0.492785\n",
      "epoch 136; iter: 0; batch classifier loss: 0.052103; batch adversarial loss: 0.452073\n",
      "epoch 137; iter: 0; batch classifier loss: 0.057849; batch adversarial loss: 0.454507\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011341; batch adversarial loss: 0.423922\n",
      "epoch 139; iter: 0; batch classifier loss: 0.012977; batch adversarial loss: 0.472348\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022885; batch adversarial loss: 0.352226\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043758; batch adversarial loss: 0.420263\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023255; batch adversarial loss: 0.513145\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016161; batch adversarial loss: 0.490604\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021378; batch adversarial loss: 0.495816\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044166; batch adversarial loss: 0.495524\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019951; batch adversarial loss: 0.490306\n",
      "epoch 147; iter: 0; batch classifier loss: 0.060073; batch adversarial loss: 0.587135\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019693; batch adversarial loss: 0.541610\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023551; batch adversarial loss: 0.398003\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037853; batch adversarial loss: 0.429563\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025674; batch adversarial loss: 0.427646\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032394; batch adversarial loss: 0.410292\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017790; batch adversarial loss: 0.410945\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044005; batch adversarial loss: 0.511819\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017850; batch adversarial loss: 0.427906\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041855; batch adversarial loss: 0.462987\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025970; batch adversarial loss: 0.431807\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036196; batch adversarial loss: 0.388960\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020154; batch adversarial loss: 0.443507\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023230; batch adversarial loss: 0.375426\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038278; batch adversarial loss: 0.423745\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013063; batch adversarial loss: 0.332383\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024615; batch adversarial loss: 0.416191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.025892; batch adversarial loss: 0.558222\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023568; batch adversarial loss: 0.398448\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017492; batch adversarial loss: 0.468204\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025692; batch adversarial loss: 0.395495\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013921; batch adversarial loss: 0.459093\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009343; batch adversarial loss: 0.437570\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024877; batch adversarial loss: 0.419881\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032847; batch adversarial loss: 0.486358\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007563; batch adversarial loss: 0.407807\n",
      "epoch 173; iter: 0; batch classifier loss: 0.051941; batch adversarial loss: 0.377881\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020595; batch adversarial loss: 0.391017\n",
      "epoch 175; iter: 0; batch classifier loss: 0.047788; batch adversarial loss: 0.465710\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014711; batch adversarial loss: 0.548432\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013796; batch adversarial loss: 0.440516\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012396; batch adversarial loss: 0.480276\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033050; batch adversarial loss: 0.370152\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016385; batch adversarial loss: 0.482092\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016401; batch adversarial loss: 0.429855\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024970; batch adversarial loss: 0.469479\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021602; batch adversarial loss: 0.417410\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022430; batch adversarial loss: 0.444595\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018778; batch adversarial loss: 0.524330\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019268; batch adversarial loss: 0.437265\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012492; batch adversarial loss: 0.418417\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011728; batch adversarial loss: 0.434935\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020031; batch adversarial loss: 0.500900\n",
      "epoch 190; iter: 0; batch classifier loss: 0.052179; batch adversarial loss: 0.472602\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012143; batch adversarial loss: 0.468643\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026296; batch adversarial loss: 0.468955\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013074; batch adversarial loss: 0.560698\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009494; batch adversarial loss: 0.440291\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012235; batch adversarial loss: 0.400821\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023120; batch adversarial loss: 0.462994\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032104; batch adversarial loss: 0.436252\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014127; batch adversarial loss: 0.433486\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031796; batch adversarial loss: 0.400721\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673447; batch adversarial loss: 0.641034\n",
      "epoch 1; iter: 0; batch classifier loss: 0.370021; batch adversarial loss: 0.616738\n",
      "epoch 2; iter: 0; batch classifier loss: 0.330362; batch adversarial loss: 0.597753\n",
      "epoch 3; iter: 0; batch classifier loss: 0.359795; batch adversarial loss: 0.622896\n",
      "epoch 4; iter: 0; batch classifier loss: 0.330570; batch adversarial loss: 0.575792\n",
      "epoch 5; iter: 0; batch classifier loss: 0.297508; batch adversarial loss: 0.554993\n",
      "epoch 6; iter: 0; batch classifier loss: 0.289775; batch adversarial loss: 0.508870\n",
      "epoch 7; iter: 0; batch classifier loss: 0.283384; batch adversarial loss: 0.571099\n",
      "epoch 8; iter: 0; batch classifier loss: 0.310762; batch adversarial loss: 0.505175\n",
      "epoch 9; iter: 0; batch classifier loss: 0.453157; batch adversarial loss: 0.570247\n",
      "epoch 10; iter: 0; batch classifier loss: 0.528763; batch adversarial loss: 0.573189\n",
      "epoch 11; iter: 0; batch classifier loss: 0.590292; batch adversarial loss: 0.534532\n",
      "epoch 12; iter: 0; batch classifier loss: 0.614845; batch adversarial loss: 0.492110\n",
      "epoch 13; iter: 0; batch classifier loss: 0.482923; batch adversarial loss: 0.545094\n",
      "epoch 14; iter: 0; batch classifier loss: 0.345726; batch adversarial loss: 0.508458\n",
      "epoch 15; iter: 0; batch classifier loss: 0.326218; batch adversarial loss: 0.471926\n",
      "epoch 16; iter: 0; batch classifier loss: 0.323045; batch adversarial loss: 0.478281\n",
      "epoch 17; iter: 0; batch classifier loss: 0.272297; batch adversarial loss: 0.551578\n",
      "epoch 18; iter: 0; batch classifier loss: 0.254012; batch adversarial loss: 0.453450\n",
      "epoch 19; iter: 0; batch classifier loss: 0.178962; batch adversarial loss: 0.565258\n",
      "epoch 20; iter: 0; batch classifier loss: 0.260011; batch adversarial loss: 0.429177\n",
      "epoch 21; iter: 0; batch classifier loss: 0.224353; batch adversarial loss: 0.469547\n",
      "epoch 22; iter: 0; batch classifier loss: 0.219151; batch adversarial loss: 0.497746\n",
      "epoch 23; iter: 0; batch classifier loss: 0.229575; batch adversarial loss: 0.529586\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182232; batch adversarial loss: 0.417486\n",
      "epoch 25; iter: 0; batch classifier loss: 0.192901; batch adversarial loss: 0.392743\n",
      "epoch 26; iter: 0; batch classifier loss: 0.210242; batch adversarial loss: 0.452591\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181414; batch adversarial loss: 0.412177\n",
      "epoch 28; iter: 0; batch classifier loss: 0.224341; batch adversarial loss: 0.457309\n",
      "epoch 29; iter: 0; batch classifier loss: 0.200907; batch adversarial loss: 0.485341\n",
      "epoch 30; iter: 0; batch classifier loss: 0.188556; batch adversarial loss: 0.478227\n",
      "epoch 31; iter: 0; batch classifier loss: 0.188411; batch adversarial loss: 0.426017\n",
      "epoch 32; iter: 0; batch classifier loss: 0.173491; batch adversarial loss: 0.440740\n",
      "epoch 33; iter: 0; batch classifier loss: 0.194618; batch adversarial loss: 0.424277\n",
      "epoch 34; iter: 0; batch classifier loss: 0.175411; batch adversarial loss: 0.390713\n",
      "epoch 35; iter: 0; batch classifier loss: 0.167106; batch adversarial loss: 0.413979\n",
      "epoch 36; iter: 0; batch classifier loss: 0.213933; batch adversarial loss: 0.468337\n",
      "epoch 37; iter: 0; batch classifier loss: 0.191817; batch adversarial loss: 0.414818\n",
      "epoch 38; iter: 0; batch classifier loss: 0.209360; batch adversarial loss: 0.429780\n",
      "epoch 39; iter: 0; batch classifier loss: 0.185194; batch adversarial loss: 0.436259\n",
      "epoch 40; iter: 0; batch classifier loss: 0.191785; batch adversarial loss: 0.453752\n",
      "epoch 41; iter: 0; batch classifier loss: 0.218384; batch adversarial loss: 0.447736\n",
      "epoch 42; iter: 0; batch classifier loss: 0.188848; batch adversarial loss: 0.436120\n",
      "epoch 43; iter: 0; batch classifier loss: 0.198837; batch adversarial loss: 0.525094\n",
      "epoch 44; iter: 0; batch classifier loss: 0.217077; batch adversarial loss: 0.444438\n",
      "epoch 45; iter: 0; batch classifier loss: 0.202267; batch adversarial loss: 0.502909\n",
      "epoch 46; iter: 0; batch classifier loss: 0.188535; batch adversarial loss: 0.424167\n",
      "epoch 47; iter: 0; batch classifier loss: 0.169012; batch adversarial loss: 0.568551\n",
      "epoch 48; iter: 0; batch classifier loss: 0.286462; batch adversarial loss: 0.415117\n",
      "epoch 49; iter: 0; batch classifier loss: 0.205101; batch adversarial loss: 0.468650\n",
      "epoch 50; iter: 0; batch classifier loss: 0.258640; batch adversarial loss: 0.491356\n",
      "epoch 51; iter: 0; batch classifier loss: 0.201501; batch adversarial loss: 0.483454\n",
      "epoch 52; iter: 0; batch classifier loss: 0.277242; batch adversarial loss: 0.493289\n",
      "epoch 53; iter: 0; batch classifier loss: 0.232878; batch adversarial loss: 0.423880\n",
      "epoch 54; iter: 0; batch classifier loss: 0.194662; batch adversarial loss: 0.496732\n",
      "epoch 55; iter: 0; batch classifier loss: 0.253397; batch adversarial loss: 0.541722\n",
      "epoch 56; iter: 0; batch classifier loss: 0.158475; batch adversarial loss: 0.519262\n",
      "epoch 57; iter: 0; batch classifier loss: 0.235929; batch adversarial loss: 0.458324\n",
      "epoch 58; iter: 0; batch classifier loss: 0.259240; batch adversarial loss: 0.422491\n",
      "epoch 59; iter: 0; batch classifier loss: 0.259982; batch adversarial loss: 0.506912\n",
      "epoch 60; iter: 0; batch classifier loss: 0.265241; batch adversarial loss: 0.434754\n",
      "epoch 61; iter: 0; batch classifier loss: 0.254460; batch adversarial loss: 0.458843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.151658; batch adversarial loss: 0.495063\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103674; batch adversarial loss: 0.444247\n",
      "epoch 64; iter: 0; batch classifier loss: 0.128434; batch adversarial loss: 0.506299\n",
      "epoch 65; iter: 0; batch classifier loss: 0.100362; batch adversarial loss: 0.469334\n",
      "epoch 66; iter: 0; batch classifier loss: 0.155808; batch adversarial loss: 0.495443\n",
      "epoch 67; iter: 0; batch classifier loss: 0.288382; batch adversarial loss: 0.469884\n",
      "epoch 68; iter: 0; batch classifier loss: 0.156164; batch adversarial loss: 0.510078\n",
      "epoch 69; iter: 0; batch classifier loss: 0.145103; batch adversarial loss: 0.470801\n",
      "epoch 70; iter: 0; batch classifier loss: 0.178171; batch adversarial loss: 0.509949\n",
      "epoch 71; iter: 0; batch classifier loss: 0.156453; batch adversarial loss: 0.457342\n",
      "epoch 72; iter: 0; batch classifier loss: 0.227307; batch adversarial loss: 0.325929\n",
      "epoch 73; iter: 0; batch classifier loss: 0.188732; batch adversarial loss: 0.433028\n",
      "epoch 74; iter: 0; batch classifier loss: 0.164017; batch adversarial loss: 0.495446\n",
      "epoch 75; iter: 0; batch classifier loss: 0.197386; batch adversarial loss: 0.422414\n",
      "epoch 76; iter: 0; batch classifier loss: 0.160329; batch adversarial loss: 0.483347\n",
      "epoch 77; iter: 0; batch classifier loss: 0.150218; batch adversarial loss: 0.470571\n",
      "epoch 78; iter: 0; batch classifier loss: 0.122620; batch adversarial loss: 0.498646\n",
      "epoch 79; iter: 0; batch classifier loss: 0.183474; batch adversarial loss: 0.471280\n",
      "epoch 80; iter: 0; batch classifier loss: 0.205242; batch adversarial loss: 0.446390\n",
      "epoch 81; iter: 0; batch classifier loss: 0.146403; batch adversarial loss: 0.435315\n",
      "epoch 82; iter: 0; batch classifier loss: 0.217034; batch adversarial loss: 0.435971\n",
      "epoch 83; iter: 0; batch classifier loss: 0.165991; batch adversarial loss: 0.335915\n",
      "epoch 84; iter: 0; batch classifier loss: 0.129772; batch adversarial loss: 0.493915\n",
      "epoch 85; iter: 0; batch classifier loss: 0.130975; batch adversarial loss: 0.447023\n",
      "epoch 86; iter: 0; batch classifier loss: 0.168630; batch adversarial loss: 0.495577\n",
      "epoch 87; iter: 0; batch classifier loss: 0.174555; batch adversarial loss: 0.581591\n",
      "epoch 88; iter: 0; batch classifier loss: 0.183656; batch adversarial loss: 0.336243\n",
      "epoch 89; iter: 0; batch classifier loss: 0.105738; batch adversarial loss: 0.422882\n",
      "epoch 90; iter: 0; batch classifier loss: 0.151904; batch adversarial loss: 0.400365\n",
      "epoch 91; iter: 0; batch classifier loss: 0.217500; batch adversarial loss: 0.400301\n",
      "epoch 92; iter: 0; batch classifier loss: 0.143063; batch adversarial loss: 0.420553\n",
      "epoch 93; iter: 0; batch classifier loss: 0.119468; batch adversarial loss: 0.533314\n",
      "epoch 94; iter: 0; batch classifier loss: 0.104643; batch adversarial loss: 0.490497\n",
      "epoch 95; iter: 0; batch classifier loss: 0.125293; batch adversarial loss: 0.375114\n",
      "epoch 96; iter: 0; batch classifier loss: 0.111396; batch adversarial loss: 0.467893\n",
      "epoch 97; iter: 0; batch classifier loss: 0.090637; batch adversarial loss: 0.562869\n",
      "epoch 98; iter: 0; batch classifier loss: 0.100190; batch adversarial loss: 0.479093\n",
      "epoch 99; iter: 0; batch classifier loss: 0.104163; batch adversarial loss: 0.532134\n",
      "epoch 100; iter: 0; batch classifier loss: 0.110112; batch adversarial loss: 0.483470\n",
      "epoch 101; iter: 0; batch classifier loss: 0.101590; batch adversarial loss: 0.482510\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079596; batch adversarial loss: 0.447656\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050922; batch adversarial loss: 0.520224\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083940; batch adversarial loss: 0.472962\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052310; batch adversarial loss: 0.496358\n",
      "epoch 106; iter: 0; batch classifier loss: 0.092278; batch adversarial loss: 0.408512\n",
      "epoch 107; iter: 0; batch classifier loss: 0.086893; batch adversarial loss: 0.491290\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059202; batch adversarial loss: 0.368938\n",
      "epoch 109; iter: 0; batch classifier loss: 0.091863; batch adversarial loss: 0.475996\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031969; batch adversarial loss: 0.469714\n",
      "epoch 111; iter: 0; batch classifier loss: 0.068812; batch adversarial loss: 0.475468\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046911; batch adversarial loss: 0.433417\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056385; batch adversarial loss: 0.483123\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061213; batch adversarial loss: 0.352621\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038019; batch adversarial loss: 0.466695\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035590; batch adversarial loss: 0.430122\n",
      "epoch 117; iter: 0; batch classifier loss: 0.018638; batch adversarial loss: 0.372748\n",
      "epoch 118; iter: 0; batch classifier loss: 0.023354; batch adversarial loss: 0.509570\n",
      "epoch 119; iter: 0; batch classifier loss: 0.018370; batch adversarial loss: 0.542296\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042892; batch adversarial loss: 0.401658\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028684; batch adversarial loss: 0.515949\n",
      "epoch 122; iter: 0; batch classifier loss: 0.018225; batch adversarial loss: 0.590248\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036975; batch adversarial loss: 0.518290\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029060; batch adversarial loss: 0.492460\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058029; batch adversarial loss: 0.368763\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040276; batch adversarial loss: 0.493055\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025220; batch adversarial loss: 0.480842\n",
      "epoch 128; iter: 0; batch classifier loss: 0.066164; batch adversarial loss: 0.474135\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023929; batch adversarial loss: 0.345985\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024340; batch adversarial loss: 0.500804\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047749; batch adversarial loss: 0.332858\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057117; batch adversarial loss: 0.395151\n",
      "epoch 133; iter: 0; batch classifier loss: 0.064788; batch adversarial loss: 0.498634\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039652; batch adversarial loss: 0.460390\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021420; batch adversarial loss: 0.441943\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016699; batch adversarial loss: 0.491578\n",
      "epoch 137; iter: 0; batch classifier loss: 0.013551; batch adversarial loss: 0.514160\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032189; batch adversarial loss: 0.497941\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029377; batch adversarial loss: 0.416842\n",
      "epoch 140; iter: 0; batch classifier loss: 0.009626; batch adversarial loss: 0.452093\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024555; batch adversarial loss: 0.481030\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026583; batch adversarial loss: 0.376888\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029099; batch adversarial loss: 0.517980\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026336; batch adversarial loss: 0.451613\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027727; batch adversarial loss: 0.435106\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030735; batch adversarial loss: 0.459159\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027329; batch adversarial loss: 0.463570\n",
      "epoch 148; iter: 0; batch classifier loss: 0.068573; batch adversarial loss: 0.481909\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015422; batch adversarial loss: 0.476785\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029077; batch adversarial loss: 0.496817\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011723; batch adversarial loss: 0.500580\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010727; batch adversarial loss: 0.404978\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025217; batch adversarial loss: 0.440126\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017415; batch adversarial loss: 0.512282\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020032; batch adversarial loss: 0.464541\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013577; batch adversarial loss: 0.404077\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011676; batch adversarial loss: 0.447464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.028828; batch adversarial loss: 0.423015\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010466; batch adversarial loss: 0.401126\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033217; batch adversarial loss: 0.388281\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009964; batch adversarial loss: 0.496277\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023788; batch adversarial loss: 0.488045\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020957; batch adversarial loss: 0.518898\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018525; batch adversarial loss: 0.542830\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032052; batch adversarial loss: 0.394430\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045418; batch adversarial loss: 0.394079\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015349; batch adversarial loss: 0.478741\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013142; batch adversarial loss: 0.458758\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009502; batch adversarial loss: 0.416540\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010015; batch adversarial loss: 0.557824\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033857; batch adversarial loss: 0.499805\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006501; batch adversarial loss: 0.410261\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010315; batch adversarial loss: 0.458626\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011108; batch adversarial loss: 0.539480\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017255; batch adversarial loss: 0.401937\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014462; batch adversarial loss: 0.468971\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025644; batch adversarial loss: 0.522852\n",
      "epoch 178; iter: 0; batch classifier loss: 0.045345; batch adversarial loss: 0.518374\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014214; batch adversarial loss: 0.580036\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024720; batch adversarial loss: 0.466689\n",
      "epoch 181; iter: 0; batch classifier loss: 0.047619; batch adversarial loss: 0.472232\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023527; batch adversarial loss: 0.448642\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010919; batch adversarial loss: 0.397291\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026558; batch adversarial loss: 0.405630\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023759; batch adversarial loss: 0.542039\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010190; batch adversarial loss: 0.418774\n",
      "epoch 187; iter: 0; batch classifier loss: 0.004263; batch adversarial loss: 0.413980\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023512; batch adversarial loss: 0.453518\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008677; batch adversarial loss: 0.483846\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016465; batch adversarial loss: 0.551115\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008215; batch adversarial loss: 0.527800\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020589; batch adversarial loss: 0.458929\n",
      "epoch 193; iter: 0; batch classifier loss: 0.003662; batch adversarial loss: 0.542034\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008073; batch adversarial loss: 0.503561\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006512; batch adversarial loss: 0.521811\n",
      "epoch 196; iter: 0; batch classifier loss: 0.002224; batch adversarial loss: 0.490565\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014482; batch adversarial loss: 0.465138\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010866; batch adversarial loss: 0.507215\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013084; batch adversarial loss: 0.463285\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702583; batch adversarial loss: 0.561111\n",
      "epoch 1; iter: 0; batch classifier loss: 0.457257; batch adversarial loss: 0.609807\n",
      "epoch 2; iter: 0; batch classifier loss: 0.459758; batch adversarial loss: 0.569919\n",
      "epoch 3; iter: 0; batch classifier loss: 0.356336; batch adversarial loss: 0.607441\n",
      "epoch 4; iter: 0; batch classifier loss: 0.314314; batch adversarial loss: 0.567048\n",
      "epoch 5; iter: 0; batch classifier loss: 0.383395; batch adversarial loss: 0.547352\n",
      "epoch 6; iter: 0; batch classifier loss: 0.255557; batch adversarial loss: 0.556479\n",
      "epoch 7; iter: 0; batch classifier loss: 0.401483; batch adversarial loss: 0.569187\n",
      "epoch 8; iter: 0; batch classifier loss: 0.314877; batch adversarial loss: 0.540958\n",
      "epoch 9; iter: 0; batch classifier loss: 0.315476; batch adversarial loss: 0.478693\n",
      "epoch 10; iter: 0; batch classifier loss: 0.314125; batch adversarial loss: 0.523168\n",
      "epoch 11; iter: 0; batch classifier loss: 0.430153; batch adversarial loss: 0.535874\n",
      "epoch 12; iter: 0; batch classifier loss: 0.441742; batch adversarial loss: 0.530384\n",
      "epoch 13; iter: 0; batch classifier loss: 0.508353; batch adversarial loss: 0.498422\n",
      "epoch 14; iter: 0; batch classifier loss: 0.465010; batch adversarial loss: 0.521565\n",
      "epoch 15; iter: 0; batch classifier loss: 0.436769; batch adversarial loss: 0.487028\n",
      "epoch 16; iter: 0; batch classifier loss: 0.317135; batch adversarial loss: 0.518192\n",
      "epoch 17; iter: 0; batch classifier loss: 0.238038; batch adversarial loss: 0.495956\n",
      "epoch 18; iter: 0; batch classifier loss: 0.204594; batch adversarial loss: 0.482778\n",
      "epoch 19; iter: 0; batch classifier loss: 0.280069; batch adversarial loss: 0.499399\n",
      "epoch 20; iter: 0; batch classifier loss: 0.200364; batch adversarial loss: 0.444956\n",
      "epoch 21; iter: 0; batch classifier loss: 0.273957; batch adversarial loss: 0.474710\n",
      "epoch 22; iter: 0; batch classifier loss: 0.219844; batch adversarial loss: 0.406749\n",
      "epoch 23; iter: 0; batch classifier loss: 0.188557; batch adversarial loss: 0.488576\n",
      "epoch 24; iter: 0; batch classifier loss: 0.178427; batch adversarial loss: 0.477946\n",
      "epoch 25; iter: 0; batch classifier loss: 0.199040; batch adversarial loss: 0.431401\n",
      "epoch 26; iter: 0; batch classifier loss: 0.158279; batch adversarial loss: 0.531456\n",
      "epoch 27; iter: 0; batch classifier loss: 0.196098; batch adversarial loss: 0.536771\n",
      "epoch 28; iter: 0; batch classifier loss: 0.187377; batch adversarial loss: 0.463480\n",
      "epoch 29; iter: 0; batch classifier loss: 0.204402; batch adversarial loss: 0.389016\n",
      "epoch 30; iter: 0; batch classifier loss: 0.176042; batch adversarial loss: 0.470198\n",
      "epoch 31; iter: 0; batch classifier loss: 0.154183; batch adversarial loss: 0.441273\n",
      "epoch 32; iter: 0; batch classifier loss: 0.157474; batch adversarial loss: 0.370644\n",
      "epoch 33; iter: 0; batch classifier loss: 0.148414; batch adversarial loss: 0.447140\n",
      "epoch 34; iter: 0; batch classifier loss: 0.141087; batch adversarial loss: 0.427810\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153988; batch adversarial loss: 0.448851\n",
      "epoch 36; iter: 0; batch classifier loss: 0.122360; batch adversarial loss: 0.429673\n",
      "epoch 37; iter: 0; batch classifier loss: 0.139079; batch adversarial loss: 0.437751\n",
      "epoch 38; iter: 0; batch classifier loss: 0.172387; batch adversarial loss: 0.410819\n",
      "epoch 39; iter: 0; batch classifier loss: 0.090118; batch adversarial loss: 0.412949\n",
      "epoch 40; iter: 0; batch classifier loss: 0.128151; batch adversarial loss: 0.390384\n",
      "epoch 41; iter: 0; batch classifier loss: 0.133342; batch adversarial loss: 0.396615\n",
      "epoch 42; iter: 0; batch classifier loss: 0.170245; batch adversarial loss: 0.414233\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110248; batch adversarial loss: 0.414687\n",
      "epoch 44; iter: 0; batch classifier loss: 0.133766; batch adversarial loss: 0.358194\n",
      "epoch 45; iter: 0; batch classifier loss: 0.228624; batch adversarial loss: 0.388997\n",
      "epoch 46; iter: 0; batch classifier loss: 0.184336; batch adversarial loss: 0.414514\n",
      "epoch 47; iter: 0; batch classifier loss: 0.165663; batch adversarial loss: 0.428335\n",
      "epoch 48; iter: 0; batch classifier loss: 0.101547; batch adversarial loss: 0.343829\n",
      "epoch 49; iter: 0; batch classifier loss: 0.133155; batch adversarial loss: 0.445465\n",
      "epoch 50; iter: 0; batch classifier loss: 0.131385; batch adversarial loss: 0.374628\n",
      "epoch 51; iter: 0; batch classifier loss: 0.124811; batch adversarial loss: 0.470108\n",
      "epoch 52; iter: 0; batch classifier loss: 0.121719; batch adversarial loss: 0.413788\n",
      "epoch 53; iter: 0; batch classifier loss: 0.145705; batch adversarial loss: 0.462835\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110658; batch adversarial loss: 0.369968\n",
      "epoch 55; iter: 0; batch classifier loss: 0.138014; batch adversarial loss: 0.395876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.126095; batch adversarial loss: 0.378576\n",
      "epoch 57; iter: 0; batch classifier loss: 0.138272; batch adversarial loss: 0.472527\n",
      "epoch 58; iter: 0; batch classifier loss: 0.180482; batch adversarial loss: 0.475348\n",
      "epoch 59; iter: 0; batch classifier loss: 0.145661; batch adversarial loss: 0.433551\n",
      "epoch 60; iter: 0; batch classifier loss: 0.123283; batch adversarial loss: 0.508630\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099089; batch adversarial loss: 0.419573\n",
      "epoch 62; iter: 0; batch classifier loss: 0.130539; batch adversarial loss: 0.481622\n",
      "epoch 63; iter: 0; batch classifier loss: 0.101121; batch adversarial loss: 0.437497\n",
      "epoch 64; iter: 0; batch classifier loss: 0.157725; batch adversarial loss: 0.411774\n",
      "epoch 65; iter: 0; batch classifier loss: 0.157607; batch adversarial loss: 0.503958\n",
      "epoch 66; iter: 0; batch classifier loss: 0.134010; batch adversarial loss: 0.443977\n",
      "epoch 67; iter: 0; batch classifier loss: 0.129522; batch adversarial loss: 0.391385\n",
      "epoch 68; iter: 0; batch classifier loss: 0.168391; batch adversarial loss: 0.491038\n",
      "epoch 69; iter: 0; batch classifier loss: 0.099913; batch adversarial loss: 0.472139\n",
      "epoch 70; iter: 0; batch classifier loss: 0.116287; batch adversarial loss: 0.493459\n",
      "epoch 71; iter: 0; batch classifier loss: 0.167148; batch adversarial loss: 0.396950\n",
      "epoch 72; iter: 0; batch classifier loss: 0.217718; batch adversarial loss: 0.475863\n",
      "epoch 73; iter: 0; batch classifier loss: 0.154314; batch adversarial loss: 0.549032\n",
      "epoch 74; iter: 0; batch classifier loss: 0.127911; batch adversarial loss: 0.483812\n",
      "epoch 75; iter: 0; batch classifier loss: 0.171068; batch adversarial loss: 0.379557\n",
      "epoch 76; iter: 0; batch classifier loss: 0.158407; batch adversarial loss: 0.500153\n",
      "epoch 77; iter: 0; batch classifier loss: 0.138363; batch adversarial loss: 0.395663\n",
      "epoch 78; iter: 0; batch classifier loss: 0.130711; batch adversarial loss: 0.432951\n",
      "epoch 79; iter: 0; batch classifier loss: 0.122056; batch adversarial loss: 0.396354\n",
      "epoch 80; iter: 0; batch classifier loss: 0.161551; batch adversarial loss: 0.450097\n",
      "epoch 81; iter: 0; batch classifier loss: 0.181211; batch adversarial loss: 0.503596\n",
      "epoch 82; iter: 0; batch classifier loss: 0.155907; batch adversarial loss: 0.481731\n",
      "epoch 83; iter: 0; batch classifier loss: 0.175177; batch adversarial loss: 0.443639\n",
      "epoch 84; iter: 0; batch classifier loss: 0.102904; batch adversarial loss: 0.471259\n",
      "epoch 85; iter: 0; batch classifier loss: 0.110358; batch adversarial loss: 0.382965\n",
      "epoch 86; iter: 0; batch classifier loss: 0.159369; batch adversarial loss: 0.500296\n",
      "epoch 87; iter: 0; batch classifier loss: 0.153658; batch adversarial loss: 0.459410\n",
      "epoch 88; iter: 0; batch classifier loss: 0.134456; batch adversarial loss: 0.369891\n",
      "epoch 89; iter: 0; batch classifier loss: 0.171640; batch adversarial loss: 0.620955\n",
      "epoch 90; iter: 0; batch classifier loss: 0.114693; batch adversarial loss: 0.469820\n",
      "epoch 91; iter: 0; batch classifier loss: 0.153508; batch adversarial loss: 0.396739\n",
      "epoch 92; iter: 0; batch classifier loss: 0.128980; batch adversarial loss: 0.506153\n",
      "epoch 93; iter: 0; batch classifier loss: 0.128552; batch adversarial loss: 0.471820\n",
      "epoch 94; iter: 0; batch classifier loss: 0.140385; batch adversarial loss: 0.485538\n",
      "epoch 95; iter: 0; batch classifier loss: 0.147748; batch adversarial loss: 0.384361\n",
      "epoch 96; iter: 0; batch classifier loss: 0.184262; batch adversarial loss: 0.454727\n",
      "epoch 97; iter: 0; batch classifier loss: 0.149969; batch adversarial loss: 0.509447\n",
      "epoch 98; iter: 0; batch classifier loss: 0.104518; batch adversarial loss: 0.468176\n",
      "epoch 99; iter: 0; batch classifier loss: 0.142613; batch adversarial loss: 0.568034\n",
      "epoch 100; iter: 0; batch classifier loss: 0.094508; batch adversarial loss: 0.464286\n",
      "epoch 101; iter: 0; batch classifier loss: 0.149678; batch adversarial loss: 0.485818\n",
      "epoch 102; iter: 0; batch classifier loss: 0.167054; batch adversarial loss: 0.551318\n",
      "epoch 103; iter: 0; batch classifier loss: 0.091796; batch adversarial loss: 0.446537\n",
      "epoch 104; iter: 0; batch classifier loss: 0.154182; batch adversarial loss: 0.442578\n",
      "epoch 105; iter: 0; batch classifier loss: 0.094628; batch adversarial loss: 0.498808\n",
      "epoch 106; iter: 0; batch classifier loss: 0.120288; batch adversarial loss: 0.487123\n",
      "epoch 107; iter: 0; batch classifier loss: 0.155811; batch adversarial loss: 0.411748\n",
      "epoch 108; iter: 0; batch classifier loss: 0.121305; batch adversarial loss: 0.393832\n",
      "epoch 109; iter: 0; batch classifier loss: 0.111021; batch adversarial loss: 0.417247\n",
      "epoch 110; iter: 0; batch classifier loss: 0.139366; batch adversarial loss: 0.422570\n",
      "epoch 111; iter: 0; batch classifier loss: 0.137954; batch adversarial loss: 0.367582\n",
      "epoch 112; iter: 0; batch classifier loss: 0.093411; batch adversarial loss: 0.521651\n",
      "epoch 113; iter: 0; batch classifier loss: 0.146452; batch adversarial loss: 0.384577\n",
      "epoch 114; iter: 0; batch classifier loss: 0.135031; batch adversarial loss: 0.445117\n",
      "epoch 115; iter: 0; batch classifier loss: 0.096324; batch adversarial loss: 0.511272\n",
      "epoch 116; iter: 0; batch classifier loss: 0.120325; batch adversarial loss: 0.471761\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060354; batch adversarial loss: 0.455994\n",
      "epoch 118; iter: 0; batch classifier loss: 0.132865; batch adversarial loss: 0.468775\n",
      "epoch 119; iter: 0; batch classifier loss: 0.082855; batch adversarial loss: 0.419277\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051359; batch adversarial loss: 0.545018\n",
      "epoch 121; iter: 0; batch classifier loss: 0.117791; batch adversarial loss: 0.431289\n",
      "epoch 122; iter: 0; batch classifier loss: 0.074626; batch adversarial loss: 0.467200\n",
      "epoch 123; iter: 0; batch classifier loss: 0.098133; batch adversarial loss: 0.453871\n",
      "epoch 124; iter: 0; batch classifier loss: 0.104241; batch adversarial loss: 0.442320\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056492; batch adversarial loss: 0.462365\n",
      "epoch 126; iter: 0; batch classifier loss: 0.067523; batch adversarial loss: 0.447524\n",
      "epoch 127; iter: 0; batch classifier loss: 0.062121; batch adversarial loss: 0.477265\n",
      "epoch 128; iter: 0; batch classifier loss: 0.110427; batch adversarial loss: 0.477773\n",
      "epoch 129; iter: 0; batch classifier loss: 0.065962; batch adversarial loss: 0.432492\n",
      "epoch 130; iter: 0; batch classifier loss: 0.052289; batch adversarial loss: 0.377357\n",
      "epoch 131; iter: 0; batch classifier loss: 0.060155; batch adversarial loss: 0.442885\n",
      "epoch 132; iter: 0; batch classifier loss: 0.061247; batch adversarial loss: 0.463017\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045845; batch adversarial loss: 0.485392\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045220; batch adversarial loss: 0.395040\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038642; batch adversarial loss: 0.495529\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036377; batch adversarial loss: 0.497472\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026725; batch adversarial loss: 0.455607\n",
      "epoch 138; iter: 0; batch classifier loss: 0.043558; batch adversarial loss: 0.471136\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049197; batch adversarial loss: 0.373879\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034221; batch adversarial loss: 0.502127\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043996; batch adversarial loss: 0.403523\n",
      "epoch 142; iter: 0; batch classifier loss: 0.058978; batch adversarial loss: 0.441375\n",
      "epoch 143; iter: 0; batch classifier loss: 0.059763; batch adversarial loss: 0.477234\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030827; batch adversarial loss: 0.447765\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035405; batch adversarial loss: 0.409746\n",
      "epoch 146; iter: 0; batch classifier loss: 0.036490; batch adversarial loss: 0.397573\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029078; batch adversarial loss: 0.453803\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038106; batch adversarial loss: 0.414196\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056833; batch adversarial loss: 0.394524\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042469; batch adversarial loss: 0.519022\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038087; batch adversarial loss: 0.311937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.030956; batch adversarial loss: 0.421000\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025553; batch adversarial loss: 0.479647\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046079; batch adversarial loss: 0.480337\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040799; batch adversarial loss: 0.429095\n",
      "epoch 156; iter: 0; batch classifier loss: 0.062206; batch adversarial loss: 0.494542\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028286; batch adversarial loss: 0.477636\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025806; batch adversarial loss: 0.568610\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033959; batch adversarial loss: 0.470714\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025371; batch adversarial loss: 0.462552\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027148; batch adversarial loss: 0.354255\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022860; batch adversarial loss: 0.520159\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020934; batch adversarial loss: 0.369337\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026336; batch adversarial loss: 0.475689\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021059; batch adversarial loss: 0.492397\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019205; batch adversarial loss: 0.478700\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025117; batch adversarial loss: 0.425062\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016791; batch adversarial loss: 0.495529\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011112; batch adversarial loss: 0.435260\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017067; batch adversarial loss: 0.491134\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036417; batch adversarial loss: 0.431338\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030999; batch adversarial loss: 0.445232\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017102; batch adversarial loss: 0.401325\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037358; batch adversarial loss: 0.396401\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014767; batch adversarial loss: 0.550504\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013489; batch adversarial loss: 0.382541\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019638; batch adversarial loss: 0.454198\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030319; batch adversarial loss: 0.431066\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011961; batch adversarial loss: 0.452838\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025231; batch adversarial loss: 0.466332\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039952; batch adversarial loss: 0.443146\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029281; batch adversarial loss: 0.373728\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007900; batch adversarial loss: 0.377978\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038673; batch adversarial loss: 0.552895\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035087; batch adversarial loss: 0.469908\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012956; batch adversarial loss: 0.423703\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016396; batch adversarial loss: 0.406705\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022269; batch adversarial loss: 0.426718\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004636; batch adversarial loss: 0.391299\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015083; batch adversarial loss: 0.440865\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022909; batch adversarial loss: 0.402350\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011062; batch adversarial loss: 0.481184\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032006; batch adversarial loss: 0.416853\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020742; batch adversarial loss: 0.495294\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018375; batch adversarial loss: 0.483217\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012696; batch adversarial loss: 0.371066\n",
      "epoch 197; iter: 0; batch classifier loss: 0.035984; batch adversarial loss: 0.431345\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013733; batch adversarial loss: 0.428009\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008726; batch adversarial loss: 0.423848\n",
      "epoch 0; iter: 0; batch classifier loss: 0.651423; batch adversarial loss: 0.553655\n",
      "epoch 1; iter: 0; batch classifier loss: 0.411422; batch adversarial loss: 0.611259\n",
      "epoch 2; iter: 0; batch classifier loss: 0.354741; batch adversarial loss: 0.612177\n",
      "epoch 3; iter: 0; batch classifier loss: 0.283970; batch adversarial loss: 0.568041\n",
      "epoch 4; iter: 0; batch classifier loss: 0.271772; batch adversarial loss: 0.555858\n",
      "epoch 5; iter: 0; batch classifier loss: 0.348232; batch adversarial loss: 0.480303\n",
      "epoch 6; iter: 0; batch classifier loss: 0.238450; batch adversarial loss: 0.502368\n",
      "epoch 7; iter: 0; batch classifier loss: 0.286481; batch adversarial loss: 0.481561\n",
      "epoch 8; iter: 0; batch classifier loss: 0.249779; batch adversarial loss: 0.575257\n",
      "epoch 9; iter: 0; batch classifier loss: 0.202377; batch adversarial loss: 0.501583\n",
      "epoch 10; iter: 0; batch classifier loss: 0.234480; batch adversarial loss: 0.508748\n",
      "epoch 11; iter: 0; batch classifier loss: 0.307757; batch adversarial loss: 0.588687\n",
      "epoch 12; iter: 0; batch classifier loss: 0.237658; batch adversarial loss: 0.531255\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232327; batch adversarial loss: 0.610378\n",
      "epoch 14; iter: 0; batch classifier loss: 0.217288; batch adversarial loss: 0.519883\n",
      "epoch 15; iter: 0; batch classifier loss: 0.269489; batch adversarial loss: 0.537854\n",
      "epoch 16; iter: 0; batch classifier loss: 0.256143; batch adversarial loss: 0.478037\n",
      "epoch 17; iter: 0; batch classifier loss: 0.245285; batch adversarial loss: 0.498642\n",
      "epoch 18; iter: 0; batch classifier loss: 0.253894; batch adversarial loss: 0.421125\n",
      "epoch 19; iter: 0; batch classifier loss: 0.188257; batch adversarial loss: 0.510005\n",
      "epoch 20; iter: 0; batch classifier loss: 0.236195; batch adversarial loss: 0.468561\n",
      "epoch 21; iter: 0; batch classifier loss: 0.271257; batch adversarial loss: 0.493247\n",
      "epoch 22; iter: 0; batch classifier loss: 0.289204; batch adversarial loss: 0.562767\n",
      "epoch 23; iter: 0; batch classifier loss: 0.424450; batch adversarial loss: 0.539900\n",
      "epoch 24; iter: 0; batch classifier loss: 0.387198; batch adversarial loss: 0.417060\n",
      "epoch 25; iter: 0; batch classifier loss: 0.267428; batch adversarial loss: 0.452986\n",
      "epoch 26; iter: 0; batch classifier loss: 0.212003; batch adversarial loss: 0.485253\n",
      "epoch 27; iter: 0; batch classifier loss: 0.161179; batch adversarial loss: 0.535590\n",
      "epoch 28; iter: 0; batch classifier loss: 0.131681; batch adversarial loss: 0.539696\n",
      "epoch 29; iter: 0; batch classifier loss: 0.130163; batch adversarial loss: 0.376642\n",
      "epoch 30; iter: 0; batch classifier loss: 0.136739; batch adversarial loss: 0.431988\n",
      "epoch 31; iter: 0; batch classifier loss: 0.155777; batch adversarial loss: 0.434581\n",
      "epoch 32; iter: 0; batch classifier loss: 0.120504; batch adversarial loss: 0.495941\n",
      "epoch 33; iter: 0; batch classifier loss: 0.127054; batch adversarial loss: 0.441247\n",
      "epoch 34; iter: 0; batch classifier loss: 0.183212; batch adversarial loss: 0.516127\n",
      "epoch 35; iter: 0; batch classifier loss: 0.089495; batch adversarial loss: 0.418610\n",
      "epoch 36; iter: 0; batch classifier loss: 0.203826; batch adversarial loss: 0.478124\n",
      "epoch 37; iter: 0; batch classifier loss: 0.179863; batch adversarial loss: 0.351699\n",
      "epoch 38; iter: 0; batch classifier loss: 0.147036; batch adversarial loss: 0.460373\n",
      "epoch 39; iter: 0; batch classifier loss: 0.151863; batch adversarial loss: 0.434393\n",
      "epoch 40; iter: 0; batch classifier loss: 0.140989; batch adversarial loss: 0.477079\n",
      "epoch 41; iter: 0; batch classifier loss: 0.136205; batch adversarial loss: 0.441966\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131685; batch adversarial loss: 0.448064\n",
      "epoch 43; iter: 0; batch classifier loss: 0.125098; batch adversarial loss: 0.389282\n",
      "epoch 44; iter: 0; batch classifier loss: 0.132101; batch adversarial loss: 0.456410\n",
      "epoch 45; iter: 0; batch classifier loss: 0.093229; batch adversarial loss: 0.373152\n",
      "epoch 46; iter: 0; batch classifier loss: 0.091690; batch adversarial loss: 0.388859\n",
      "epoch 47; iter: 0; batch classifier loss: 0.160761; batch adversarial loss: 0.444759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.092253; batch adversarial loss: 0.486644\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114451; batch adversarial loss: 0.463935\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111515; batch adversarial loss: 0.494613\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096289; batch adversarial loss: 0.526466\n",
      "epoch 52; iter: 0; batch classifier loss: 0.148849; batch adversarial loss: 0.434261\n",
      "epoch 53; iter: 0; batch classifier loss: 0.149909; batch adversarial loss: 0.436445\n",
      "epoch 54; iter: 0; batch classifier loss: 0.147129; batch adversarial loss: 0.438011\n",
      "epoch 55; iter: 0; batch classifier loss: 0.148572; batch adversarial loss: 0.434221\n",
      "epoch 56; iter: 0; batch classifier loss: 0.133234; batch adversarial loss: 0.485847\n",
      "epoch 57; iter: 0; batch classifier loss: 0.158836; batch adversarial loss: 0.499515\n",
      "epoch 58; iter: 0; batch classifier loss: 0.102262; batch adversarial loss: 0.401513\n",
      "epoch 59; iter: 0; batch classifier loss: 0.159825; batch adversarial loss: 0.537868\n",
      "epoch 60; iter: 0; batch classifier loss: 0.132931; batch adversarial loss: 0.538018\n",
      "epoch 61; iter: 0; batch classifier loss: 0.148323; batch adversarial loss: 0.478895\n",
      "epoch 62; iter: 0; batch classifier loss: 0.105194; batch adversarial loss: 0.455000\n",
      "epoch 63; iter: 0; batch classifier loss: 0.113900; batch adversarial loss: 0.562030\n",
      "epoch 64; iter: 0; batch classifier loss: 0.177424; batch adversarial loss: 0.540005\n",
      "epoch 65; iter: 0; batch classifier loss: 0.196663; batch adversarial loss: 0.455625\n",
      "epoch 66; iter: 0; batch classifier loss: 0.139884; batch adversarial loss: 0.557671\n",
      "epoch 67; iter: 0; batch classifier loss: 0.210996; batch adversarial loss: 0.430155\n",
      "epoch 68; iter: 0; batch classifier loss: 0.144226; batch adversarial loss: 0.449615\n",
      "epoch 69; iter: 0; batch classifier loss: 0.140455; batch adversarial loss: 0.473623\n",
      "epoch 70; iter: 0; batch classifier loss: 0.187477; batch adversarial loss: 0.386514\n",
      "epoch 71; iter: 0; batch classifier loss: 0.121644; batch adversarial loss: 0.479465\n",
      "epoch 72; iter: 0; batch classifier loss: 0.137655; batch adversarial loss: 0.479516\n",
      "epoch 73; iter: 0; batch classifier loss: 0.168413; batch adversarial loss: 0.442189\n",
      "epoch 74; iter: 0; batch classifier loss: 0.140258; batch adversarial loss: 0.500619\n",
      "epoch 75; iter: 0; batch classifier loss: 0.171928; batch adversarial loss: 0.462248\n",
      "epoch 76; iter: 0; batch classifier loss: 0.179763; batch adversarial loss: 0.373466\n",
      "epoch 77; iter: 0; batch classifier loss: 0.096098; batch adversarial loss: 0.386589\n",
      "epoch 78; iter: 0; batch classifier loss: 0.163718; batch adversarial loss: 0.456671\n",
      "epoch 79; iter: 0; batch classifier loss: 0.152994; batch adversarial loss: 0.559009\n",
      "epoch 80; iter: 0; batch classifier loss: 0.153432; batch adversarial loss: 0.447269\n",
      "epoch 81; iter: 0; batch classifier loss: 0.149371; batch adversarial loss: 0.469372\n",
      "epoch 82; iter: 0; batch classifier loss: 0.156490; batch adversarial loss: 0.479529\n",
      "epoch 83; iter: 0; batch classifier loss: 0.229341; batch adversarial loss: 0.507465\n",
      "epoch 84; iter: 0; batch classifier loss: 0.167531; batch adversarial loss: 0.415205\n",
      "epoch 85; iter: 0; batch classifier loss: 0.118554; batch adversarial loss: 0.484212\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084341; batch adversarial loss: 0.466152\n",
      "epoch 87; iter: 0; batch classifier loss: 0.219399; batch adversarial loss: 0.457918\n",
      "epoch 88; iter: 0; batch classifier loss: 0.158869; batch adversarial loss: 0.441234\n",
      "epoch 89; iter: 0; batch classifier loss: 0.150917; batch adversarial loss: 0.500305\n",
      "epoch 90; iter: 0; batch classifier loss: 0.209093; batch adversarial loss: 0.492852\n",
      "epoch 91; iter: 0; batch classifier loss: 0.128682; batch adversarial loss: 0.521877\n",
      "epoch 92; iter: 0; batch classifier loss: 0.121902; batch adversarial loss: 0.494412\n",
      "epoch 93; iter: 0; batch classifier loss: 0.121964; batch adversarial loss: 0.550173\n",
      "epoch 94; iter: 0; batch classifier loss: 0.104121; batch adversarial loss: 0.468662\n",
      "epoch 95; iter: 0; batch classifier loss: 0.145178; batch adversarial loss: 0.520282\n",
      "epoch 96; iter: 0; batch classifier loss: 0.124645; batch adversarial loss: 0.505861\n",
      "epoch 97; iter: 0; batch classifier loss: 0.084728; batch adversarial loss: 0.425694\n",
      "epoch 98; iter: 0; batch classifier loss: 0.230001; batch adversarial loss: 0.477352\n",
      "epoch 99; iter: 0; batch classifier loss: 0.161892; batch adversarial loss: 0.461669\n",
      "epoch 100; iter: 0; batch classifier loss: 0.149223; batch adversarial loss: 0.469357\n",
      "epoch 101; iter: 0; batch classifier loss: 0.170655; batch adversarial loss: 0.480013\n",
      "epoch 102; iter: 0; batch classifier loss: 0.153253; batch adversarial loss: 0.475381\n",
      "epoch 103; iter: 0; batch classifier loss: 0.120573; batch adversarial loss: 0.506186\n",
      "epoch 104; iter: 0; batch classifier loss: 0.097298; batch adversarial loss: 0.473795\n",
      "epoch 105; iter: 0; batch classifier loss: 0.237563; batch adversarial loss: 0.417513\n",
      "epoch 106; iter: 0; batch classifier loss: 0.136407; batch adversarial loss: 0.420945\n",
      "epoch 107; iter: 0; batch classifier loss: 0.163880; batch adversarial loss: 0.434974\n",
      "epoch 108; iter: 0; batch classifier loss: 0.167565; batch adversarial loss: 0.384973\n",
      "epoch 109; iter: 0; batch classifier loss: 0.234192; batch adversarial loss: 0.407687\n",
      "epoch 110; iter: 0; batch classifier loss: 0.152648; batch adversarial loss: 0.472329\n",
      "epoch 111; iter: 0; batch classifier loss: 0.114652; batch adversarial loss: 0.517830\n",
      "epoch 112; iter: 0; batch classifier loss: 0.116985; batch adversarial loss: 0.433067\n",
      "epoch 113; iter: 0; batch classifier loss: 0.159012; batch adversarial loss: 0.424417\n",
      "epoch 114; iter: 0; batch classifier loss: 0.122633; batch adversarial loss: 0.423029\n",
      "epoch 115; iter: 0; batch classifier loss: 0.158914; batch adversarial loss: 0.524392\n",
      "epoch 116; iter: 0; batch classifier loss: 0.096489; batch adversarial loss: 0.566965\n",
      "epoch 117; iter: 0; batch classifier loss: 0.149564; batch adversarial loss: 0.395500\n",
      "epoch 118; iter: 0; batch classifier loss: 0.084716; batch adversarial loss: 0.529975\n",
      "epoch 119; iter: 0; batch classifier loss: 0.149061; batch adversarial loss: 0.449569\n",
      "epoch 120; iter: 0; batch classifier loss: 0.160613; batch adversarial loss: 0.401118\n",
      "epoch 121; iter: 0; batch classifier loss: 0.122180; batch adversarial loss: 0.382863\n",
      "epoch 122; iter: 0; batch classifier loss: 0.087472; batch adversarial loss: 0.431279\n",
      "epoch 123; iter: 0; batch classifier loss: 0.080622; batch adversarial loss: 0.470404\n",
      "epoch 124; iter: 0; batch classifier loss: 0.094307; batch adversarial loss: 0.407519\n",
      "epoch 125; iter: 0; batch classifier loss: 0.114676; batch adversarial loss: 0.517368\n",
      "epoch 126; iter: 0; batch classifier loss: 0.061744; batch adversarial loss: 0.414430\n",
      "epoch 127; iter: 0; batch classifier loss: 0.071855; batch adversarial loss: 0.613416\n",
      "epoch 128; iter: 0; batch classifier loss: 0.077315; batch adversarial loss: 0.439311\n",
      "epoch 129; iter: 0; batch classifier loss: 0.049577; batch adversarial loss: 0.373961\n",
      "epoch 130; iter: 0; batch classifier loss: 0.075364; batch adversarial loss: 0.452082\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048499; batch adversarial loss: 0.427525\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041770; batch adversarial loss: 0.463661\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060735; batch adversarial loss: 0.425301\n",
      "epoch 134; iter: 0; batch classifier loss: 0.091917; batch adversarial loss: 0.448919\n",
      "epoch 135; iter: 0; batch classifier loss: 0.048530; batch adversarial loss: 0.482803\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056907; batch adversarial loss: 0.378857\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048541; batch adversarial loss: 0.452013\n",
      "epoch 138; iter: 0; batch classifier loss: 0.058320; batch adversarial loss: 0.566890\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045201; batch adversarial loss: 0.496804\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029586; batch adversarial loss: 0.432833\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022827; batch adversarial loss: 0.543453\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028527; batch adversarial loss: 0.429333\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053471; batch adversarial loss: 0.512743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.079651; batch adversarial loss: 0.490512\n",
      "epoch 145; iter: 0; batch classifier loss: 0.053865; batch adversarial loss: 0.508204\n",
      "epoch 146; iter: 0; batch classifier loss: 0.050639; batch adversarial loss: 0.421968\n",
      "epoch 147; iter: 0; batch classifier loss: 0.081726; batch adversarial loss: 0.505393\n",
      "epoch 148; iter: 0; batch classifier loss: 0.051894; batch adversarial loss: 0.490473\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023318; batch adversarial loss: 0.338697\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026532; batch adversarial loss: 0.365071\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012631; batch adversarial loss: 0.510443\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030066; batch adversarial loss: 0.357871\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042908; batch adversarial loss: 0.321986\n",
      "epoch 154; iter: 0; batch classifier loss: 0.045949; batch adversarial loss: 0.531361\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027157; batch adversarial loss: 0.457891\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019413; batch adversarial loss: 0.379848\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021660; batch adversarial loss: 0.476801\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037091; batch adversarial loss: 0.382044\n",
      "epoch 159; iter: 0; batch classifier loss: 0.059146; batch adversarial loss: 0.461745\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031999; batch adversarial loss: 0.458447\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024902; batch adversarial loss: 0.450310\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040601; batch adversarial loss: 0.413257\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023882; batch adversarial loss: 0.436601\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036810; batch adversarial loss: 0.432172\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042844; batch adversarial loss: 0.506724\n",
      "epoch 166; iter: 0; batch classifier loss: 0.042787; batch adversarial loss: 0.457846\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017762; batch adversarial loss: 0.417133\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040384; batch adversarial loss: 0.419690\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038719; batch adversarial loss: 0.484871\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024071; batch adversarial loss: 0.468817\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019481; batch adversarial loss: 0.471878\n",
      "epoch 172; iter: 0; batch classifier loss: 0.042262; batch adversarial loss: 0.473327\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016161; batch adversarial loss: 0.430147\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031917; batch adversarial loss: 0.504653\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017979; batch adversarial loss: 0.413745\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011951; batch adversarial loss: 0.486871\n",
      "epoch 177; iter: 0; batch classifier loss: 0.041253; batch adversarial loss: 0.464245\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024147; batch adversarial loss: 0.305983\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020813; batch adversarial loss: 0.414557\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017381; batch adversarial loss: 0.459628\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018598; batch adversarial loss: 0.432199\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015916; batch adversarial loss: 0.532145\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032060; batch adversarial loss: 0.403097\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014637; batch adversarial loss: 0.466223\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025356; batch adversarial loss: 0.498714\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016373; batch adversarial loss: 0.476457\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010308; batch adversarial loss: 0.444908\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013615; batch adversarial loss: 0.536267\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009954; batch adversarial loss: 0.423464\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012527; batch adversarial loss: 0.502253\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024182; batch adversarial loss: 0.400532\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013409; batch adversarial loss: 0.363814\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023522; batch adversarial loss: 0.412634\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030377; batch adversarial loss: 0.487374\n",
      "epoch 195; iter: 0; batch classifier loss: 0.048385; batch adversarial loss: 0.363857\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014774; batch adversarial loss: 0.468597\n",
      "epoch 197; iter: 0; batch classifier loss: 0.070156; batch adversarial loss: 0.473591\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017066; batch adversarial loss: 0.455490\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019565; batch adversarial loss: 0.480517\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709943; batch adversarial loss: 0.727963\n",
      "epoch 1; iter: 0; batch classifier loss: 0.460517; batch adversarial loss: 0.673710\n",
      "epoch 2; iter: 0; batch classifier loss: 0.387304; batch adversarial loss: 0.618658\n",
      "epoch 3; iter: 0; batch classifier loss: 0.414607; batch adversarial loss: 0.611965\n",
      "epoch 4; iter: 0; batch classifier loss: 0.424983; batch adversarial loss: 0.601172\n",
      "epoch 5; iter: 0; batch classifier loss: 0.341305; batch adversarial loss: 0.554148\n",
      "epoch 6; iter: 0; batch classifier loss: 0.356928; batch adversarial loss: 0.586182\n",
      "epoch 7; iter: 0; batch classifier loss: 0.352927; batch adversarial loss: 0.538085\n",
      "epoch 8; iter: 0; batch classifier loss: 0.225428; batch adversarial loss: 0.563813\n",
      "epoch 9; iter: 0; batch classifier loss: 0.438298; batch adversarial loss: 0.541386\n",
      "epoch 10; iter: 0; batch classifier loss: 0.261043; batch adversarial loss: 0.526243\n",
      "epoch 11; iter: 0; batch classifier loss: 0.328561; batch adversarial loss: 0.558366\n",
      "epoch 12; iter: 0; batch classifier loss: 0.291466; batch adversarial loss: 0.553069\n",
      "epoch 13; iter: 0; batch classifier loss: 0.313680; batch adversarial loss: 0.486152\n",
      "epoch 14; iter: 0; batch classifier loss: 0.432252; batch adversarial loss: 0.508038\n",
      "epoch 15; iter: 0; batch classifier loss: 0.318884; batch adversarial loss: 0.490924\n",
      "epoch 16; iter: 0; batch classifier loss: 0.298359; batch adversarial loss: 0.469155\n",
      "epoch 17; iter: 0; batch classifier loss: 0.297948; batch adversarial loss: 0.500639\n",
      "epoch 18; iter: 0; batch classifier loss: 0.298961; batch adversarial loss: 0.457904\n",
      "epoch 19; iter: 0; batch classifier loss: 0.301328; batch adversarial loss: 0.413912\n",
      "epoch 20; iter: 0; batch classifier loss: 0.269251; batch adversarial loss: 0.472116\n",
      "epoch 21; iter: 0; batch classifier loss: 0.257700; batch adversarial loss: 0.527047\n",
      "epoch 22; iter: 0; batch classifier loss: 0.287330; batch adversarial loss: 0.529077\n",
      "epoch 23; iter: 0; batch classifier loss: 0.279060; batch adversarial loss: 0.510968\n",
      "epoch 24; iter: 0; batch classifier loss: 0.208255; batch adversarial loss: 0.484134\n",
      "epoch 25; iter: 0; batch classifier loss: 0.186344; batch adversarial loss: 0.498499\n",
      "epoch 26; iter: 0; batch classifier loss: 0.228726; batch adversarial loss: 0.481031\n",
      "epoch 27; iter: 0; batch classifier loss: 0.234284; batch adversarial loss: 0.499410\n",
      "epoch 28; iter: 0; batch classifier loss: 0.220952; batch adversarial loss: 0.449703\n",
      "epoch 29; iter: 0; batch classifier loss: 0.259270; batch adversarial loss: 0.455718\n",
      "epoch 30; iter: 0; batch classifier loss: 0.241730; batch adversarial loss: 0.454325\n",
      "epoch 31; iter: 0; batch classifier loss: 0.237222; batch adversarial loss: 0.494090\n",
      "epoch 32; iter: 0; batch classifier loss: 0.244184; batch adversarial loss: 0.492168\n",
      "epoch 33; iter: 0; batch classifier loss: 0.211393; batch adversarial loss: 0.452786\n",
      "epoch 34; iter: 0; batch classifier loss: 0.189490; batch adversarial loss: 0.450523\n",
      "epoch 35; iter: 0; batch classifier loss: 0.230142; batch adversarial loss: 0.513949\n",
      "epoch 36; iter: 0; batch classifier loss: 0.184923; batch adversarial loss: 0.497805\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166738; batch adversarial loss: 0.508701\n",
      "epoch 38; iter: 0; batch classifier loss: 0.169645; batch adversarial loss: 0.556520\n",
      "epoch 39; iter: 0; batch classifier loss: 0.172675; batch adversarial loss: 0.506122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.207943; batch adversarial loss: 0.517427\n",
      "epoch 41; iter: 0; batch classifier loss: 0.185642; batch adversarial loss: 0.443948\n",
      "epoch 42; iter: 0; batch classifier loss: 0.193623; batch adversarial loss: 0.404049\n",
      "epoch 43; iter: 0; batch classifier loss: 0.219809; batch adversarial loss: 0.437176\n",
      "epoch 44; iter: 0; batch classifier loss: 0.175779; batch adversarial loss: 0.468375\n",
      "epoch 45; iter: 0; batch classifier loss: 0.223085; batch adversarial loss: 0.526552\n",
      "epoch 46; iter: 0; batch classifier loss: 0.245590; batch adversarial loss: 0.387770\n",
      "epoch 47; iter: 0; batch classifier loss: 0.254515; batch adversarial loss: 0.426535\n",
      "epoch 48; iter: 0; batch classifier loss: 0.233537; batch adversarial loss: 0.424203\n",
      "epoch 49; iter: 0; batch classifier loss: 0.145359; batch adversarial loss: 0.401680\n",
      "epoch 50; iter: 0; batch classifier loss: 0.169666; batch adversarial loss: 0.435007\n",
      "epoch 51; iter: 0; batch classifier loss: 0.172414; batch adversarial loss: 0.542587\n",
      "epoch 52; iter: 0; batch classifier loss: 0.259848; batch adversarial loss: 0.422740\n",
      "epoch 53; iter: 0; batch classifier loss: 0.143248; batch adversarial loss: 0.506554\n",
      "epoch 54; iter: 0; batch classifier loss: 0.091725; batch adversarial loss: 0.459099\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084613; batch adversarial loss: 0.459464\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081345; batch adversarial loss: 0.481925\n",
      "epoch 57; iter: 0; batch classifier loss: 0.074719; batch adversarial loss: 0.394978\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064042; batch adversarial loss: 0.455399\n",
      "epoch 59; iter: 0; batch classifier loss: 0.060849; batch adversarial loss: 0.467583\n",
      "epoch 60; iter: 0; batch classifier loss: 0.067806; batch adversarial loss: 0.453797\n",
      "epoch 61; iter: 0; batch classifier loss: 0.081079; batch adversarial loss: 0.501420\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084576; batch adversarial loss: 0.462017\n",
      "epoch 63; iter: 0; batch classifier loss: 0.101835; batch adversarial loss: 0.470545\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090653; batch adversarial loss: 0.413833\n",
      "epoch 65; iter: 0; batch classifier loss: 0.085945; batch adversarial loss: 0.503047\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096683; batch adversarial loss: 0.523919\n",
      "epoch 67; iter: 0; batch classifier loss: 0.052076; batch adversarial loss: 0.418389\n",
      "epoch 68; iter: 0; batch classifier loss: 0.041137; batch adversarial loss: 0.472583\n",
      "epoch 69; iter: 0; batch classifier loss: 0.093705; batch adversarial loss: 0.362566\n",
      "epoch 70; iter: 0; batch classifier loss: 0.100527; batch adversarial loss: 0.426395\n",
      "epoch 71; iter: 0; batch classifier loss: 0.114156; batch adversarial loss: 0.425385\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071342; batch adversarial loss: 0.572023\n",
      "epoch 73; iter: 0; batch classifier loss: 0.097901; batch adversarial loss: 0.441429\n",
      "epoch 74; iter: 0; batch classifier loss: 0.051121; batch adversarial loss: 0.426001\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075898; batch adversarial loss: 0.439201\n",
      "epoch 76; iter: 0; batch classifier loss: 0.052677; batch adversarial loss: 0.420358\n",
      "epoch 77; iter: 0; batch classifier loss: 0.033994; batch adversarial loss: 0.566455\n",
      "epoch 78; iter: 0; batch classifier loss: 0.043001; batch adversarial loss: 0.560741\n",
      "epoch 79; iter: 0; batch classifier loss: 0.050201; batch adversarial loss: 0.463697\n",
      "epoch 80; iter: 0; batch classifier loss: 0.059105; batch adversarial loss: 0.438571\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066034; batch adversarial loss: 0.445398\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073329; batch adversarial loss: 0.449357\n",
      "epoch 83; iter: 0; batch classifier loss: 0.076031; batch adversarial loss: 0.433659\n",
      "epoch 84; iter: 0; batch classifier loss: 0.084658; batch adversarial loss: 0.545943\n",
      "epoch 85; iter: 0; batch classifier loss: 0.040576; batch adversarial loss: 0.421479\n",
      "epoch 86; iter: 0; batch classifier loss: 0.041216; batch adversarial loss: 0.535067\n",
      "epoch 87; iter: 0; batch classifier loss: 0.077899; batch adversarial loss: 0.416565\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049263; batch adversarial loss: 0.397793\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059016; batch adversarial loss: 0.385495\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042199; batch adversarial loss: 0.484715\n",
      "epoch 91; iter: 0; batch classifier loss: 0.076523; batch adversarial loss: 0.457517\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077776; batch adversarial loss: 0.445410\n",
      "epoch 93; iter: 0; batch classifier loss: 0.045236; batch adversarial loss: 0.538060\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033254; batch adversarial loss: 0.431534\n",
      "epoch 95; iter: 0; batch classifier loss: 0.031842; batch adversarial loss: 0.501878\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056477; batch adversarial loss: 0.468809\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037653; batch adversarial loss: 0.469669\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063867; batch adversarial loss: 0.497787\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041041; batch adversarial loss: 0.422380\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039062; batch adversarial loss: 0.421608\n",
      "epoch 101; iter: 0; batch classifier loss: 0.029161; batch adversarial loss: 0.454308\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043750; batch adversarial loss: 0.401392\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048327; batch adversarial loss: 0.461725\n",
      "epoch 104; iter: 0; batch classifier loss: 0.070088; batch adversarial loss: 0.441367\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053717; batch adversarial loss: 0.449501\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041152; batch adversarial loss: 0.437465\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051072; batch adversarial loss: 0.532485\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052966; batch adversarial loss: 0.471005\n",
      "epoch 109; iter: 0; batch classifier loss: 0.008800; batch adversarial loss: 0.504392\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031374; batch adversarial loss: 0.441176\n",
      "epoch 111; iter: 0; batch classifier loss: 0.020657; batch adversarial loss: 0.520987\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035589; batch adversarial loss: 0.450520\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034440; batch adversarial loss: 0.409831\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029280; batch adversarial loss: 0.507892\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041559; batch adversarial loss: 0.417375\n",
      "epoch 116; iter: 0; batch classifier loss: 0.015587; batch adversarial loss: 0.418733\n",
      "epoch 117; iter: 0; batch classifier loss: 0.062486; batch adversarial loss: 0.414576\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024477; batch adversarial loss: 0.467953\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027330; batch adversarial loss: 0.500853\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027435; batch adversarial loss: 0.460795\n",
      "epoch 121; iter: 0; batch classifier loss: 0.019639; batch adversarial loss: 0.468511\n",
      "epoch 122; iter: 0; batch classifier loss: 0.007764; batch adversarial loss: 0.477582\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035948; batch adversarial loss: 0.514262\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025829; batch adversarial loss: 0.444356\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033851; batch adversarial loss: 0.416328\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034619; batch adversarial loss: 0.468687\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034040; batch adversarial loss: 0.428718\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055640; batch adversarial loss: 0.400970\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040549; batch adversarial loss: 0.494421\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035409; batch adversarial loss: 0.439890\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026484; batch adversarial loss: 0.468014\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033312; batch adversarial loss: 0.559541\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021241; batch adversarial loss: 0.353435\n",
      "epoch 134; iter: 0; batch classifier loss: 0.009330; batch adversarial loss: 0.506351\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019077; batch adversarial loss: 0.383878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.025534; batch adversarial loss: 0.468411\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029856; batch adversarial loss: 0.499198\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056365; batch adversarial loss: 0.407040\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026932; batch adversarial loss: 0.423038\n",
      "epoch 140; iter: 0; batch classifier loss: 0.007101; batch adversarial loss: 0.401766\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026992; batch adversarial loss: 0.379344\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039295; batch adversarial loss: 0.515267\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016468; batch adversarial loss: 0.417354\n",
      "epoch 144; iter: 0; batch classifier loss: 0.007085; batch adversarial loss: 0.437309\n",
      "epoch 145; iter: 0; batch classifier loss: 0.007132; batch adversarial loss: 0.433391\n",
      "epoch 146; iter: 0; batch classifier loss: 0.065567; batch adversarial loss: 0.556439\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028909; batch adversarial loss: 0.477910\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023719; batch adversarial loss: 0.514473\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017463; batch adversarial loss: 0.514736\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015009; batch adversarial loss: 0.492351\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015638; batch adversarial loss: 0.408867\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023198; batch adversarial loss: 0.465862\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037736; batch adversarial loss: 0.511665\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022483; batch adversarial loss: 0.456853\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018477; batch adversarial loss: 0.451120\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016930; batch adversarial loss: 0.454339\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022787; batch adversarial loss: 0.405826\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036561; batch adversarial loss: 0.399178\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034585; batch adversarial loss: 0.461425\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016802; batch adversarial loss: 0.451448\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029130; batch adversarial loss: 0.450745\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034609; batch adversarial loss: 0.416549\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018454; batch adversarial loss: 0.469105\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027831; batch adversarial loss: 0.499212\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019295; batch adversarial loss: 0.351495\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007372; batch adversarial loss: 0.448564\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035004; batch adversarial loss: 0.435580\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017626; batch adversarial loss: 0.380561\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007544; batch adversarial loss: 0.456303\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021375; batch adversarial loss: 0.350746\n",
      "epoch 171; iter: 0; batch classifier loss: 0.006920; batch adversarial loss: 0.502603\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019638; batch adversarial loss: 0.418832\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014884; batch adversarial loss: 0.488829\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014505; batch adversarial loss: 0.494380\n",
      "epoch 175; iter: 0; batch classifier loss: 0.059085; batch adversarial loss: 0.574481\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021831; batch adversarial loss: 0.506872\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008873; batch adversarial loss: 0.348940\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007170; batch adversarial loss: 0.443381\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018654; batch adversarial loss: 0.475412\n",
      "epoch 180; iter: 0; batch classifier loss: 0.003016; batch adversarial loss: 0.484605\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020702; batch adversarial loss: 0.531292\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014640; batch adversarial loss: 0.502441\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009080; batch adversarial loss: 0.391582\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035569; batch adversarial loss: 0.378230\n",
      "epoch 185; iter: 0; batch classifier loss: 0.005421; batch adversarial loss: 0.495833\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008557; batch adversarial loss: 0.444467\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006301; batch adversarial loss: 0.393869\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006573; batch adversarial loss: 0.409839\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006163; batch adversarial loss: 0.465640\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015460; batch adversarial loss: 0.532406\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005856; batch adversarial loss: 0.373349\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005245; batch adversarial loss: 0.462977\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012604; batch adversarial loss: 0.415496\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016511; batch adversarial loss: 0.485746\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020853; batch adversarial loss: 0.441662\n",
      "epoch 196; iter: 0; batch classifier loss: 0.003930; batch adversarial loss: 0.420539\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016359; batch adversarial loss: 0.395075\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010086; batch adversarial loss: 0.414353\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013362; batch adversarial loss: 0.481263\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724714; batch adversarial loss: 0.899101\n",
      "epoch 1; iter: 0; batch classifier loss: 0.455934; batch adversarial loss: 0.814438\n",
      "epoch 2; iter: 0; batch classifier loss: 0.566987; batch adversarial loss: 0.809265\n",
      "epoch 3; iter: 0; batch classifier loss: 0.827694; batch adversarial loss: 0.769668\n",
      "epoch 4; iter: 0; batch classifier loss: 0.839186; batch adversarial loss: 0.704037\n",
      "epoch 5; iter: 0; batch classifier loss: 0.853979; batch adversarial loss: 0.623367\n",
      "epoch 6; iter: 0; batch classifier loss: 0.452069; batch adversarial loss: 0.588542\n",
      "epoch 7; iter: 0; batch classifier loss: 0.389618; batch adversarial loss: 0.560827\n",
      "epoch 8; iter: 0; batch classifier loss: 0.449475; batch adversarial loss: 0.540035\n",
      "epoch 9; iter: 0; batch classifier loss: 0.313624; batch adversarial loss: 0.540748\n",
      "epoch 10; iter: 0; batch classifier loss: 0.308944; batch adversarial loss: 0.517409\n",
      "epoch 11; iter: 0; batch classifier loss: 0.348723; batch adversarial loss: 0.512407\n",
      "epoch 12; iter: 0; batch classifier loss: 0.444692; batch adversarial loss: 0.527233\n",
      "epoch 13; iter: 0; batch classifier loss: 0.301713; batch adversarial loss: 0.520027\n",
      "epoch 14; iter: 0; batch classifier loss: 0.343630; batch adversarial loss: 0.509423\n",
      "epoch 15; iter: 0; batch classifier loss: 0.389598; batch adversarial loss: 0.548139\n",
      "epoch 16; iter: 0; batch classifier loss: 0.415613; batch adversarial loss: 0.497693\n",
      "epoch 17; iter: 0; batch classifier loss: 0.314506; batch adversarial loss: 0.496903\n",
      "epoch 18; iter: 0; batch classifier loss: 0.322138; batch adversarial loss: 0.539767\n",
      "epoch 19; iter: 0; batch classifier loss: 0.397279; batch adversarial loss: 0.504461\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313171; batch adversarial loss: 0.495625\n",
      "epoch 21; iter: 0; batch classifier loss: 0.449012; batch adversarial loss: 0.518142\n",
      "epoch 22; iter: 0; batch classifier loss: 0.338228; batch adversarial loss: 0.542228\n",
      "epoch 23; iter: 0; batch classifier loss: 0.341393; batch adversarial loss: 0.517866\n",
      "epoch 24; iter: 0; batch classifier loss: 0.373543; batch adversarial loss: 0.408195\n",
      "epoch 25; iter: 0; batch classifier loss: 0.346230; batch adversarial loss: 0.522777\n",
      "epoch 26; iter: 0; batch classifier loss: 0.332939; batch adversarial loss: 0.460812\n",
      "epoch 27; iter: 0; batch classifier loss: 0.317535; batch adversarial loss: 0.433179\n",
      "epoch 28; iter: 0; batch classifier loss: 0.318498; batch adversarial loss: 0.457817\n",
      "epoch 29; iter: 0; batch classifier loss: 0.292544; batch adversarial loss: 0.497476\n",
      "epoch 30; iter: 0; batch classifier loss: 0.265233; batch adversarial loss: 0.416469\n",
      "epoch 31; iter: 0; batch classifier loss: 0.275224; batch adversarial loss: 0.462242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.297960; batch adversarial loss: 0.484285\n",
      "epoch 33; iter: 0; batch classifier loss: 0.224230; batch adversarial loss: 0.450475\n",
      "epoch 34; iter: 0; batch classifier loss: 0.300413; batch adversarial loss: 0.545205\n",
      "epoch 35; iter: 0; batch classifier loss: 0.351240; batch adversarial loss: 0.365504\n",
      "epoch 36; iter: 0; batch classifier loss: 0.228162; batch adversarial loss: 0.440456\n",
      "epoch 37; iter: 0; batch classifier loss: 0.227380; batch adversarial loss: 0.450314\n",
      "epoch 38; iter: 0; batch classifier loss: 0.254300; batch adversarial loss: 0.477544\n",
      "epoch 39; iter: 0; batch classifier loss: 0.198963; batch adversarial loss: 0.474456\n",
      "epoch 40; iter: 0; batch classifier loss: 0.203168; batch adversarial loss: 0.452604\n",
      "epoch 41; iter: 0; batch classifier loss: 0.267219; batch adversarial loss: 0.417329\n",
      "epoch 42; iter: 0; batch classifier loss: 0.204580; batch adversarial loss: 0.474571\n",
      "epoch 43; iter: 0; batch classifier loss: 0.255425; batch adversarial loss: 0.483585\n",
      "epoch 44; iter: 0; batch classifier loss: 0.283963; batch adversarial loss: 0.402727\n",
      "epoch 45; iter: 0; batch classifier loss: 0.262564; batch adversarial loss: 0.450624\n",
      "epoch 46; iter: 0; batch classifier loss: 0.237469; batch adversarial loss: 0.425252\n",
      "epoch 47; iter: 0; batch classifier loss: 0.180720; batch adversarial loss: 0.471744\n",
      "epoch 48; iter: 0; batch classifier loss: 0.177634; batch adversarial loss: 0.447174\n",
      "epoch 49; iter: 0; batch classifier loss: 0.209220; batch adversarial loss: 0.421974\n",
      "epoch 50; iter: 0; batch classifier loss: 0.227467; batch adversarial loss: 0.459851\n",
      "epoch 51; iter: 0; batch classifier loss: 0.210074; batch adversarial loss: 0.480576\n",
      "epoch 52; iter: 0; batch classifier loss: 0.218511; batch adversarial loss: 0.471843\n",
      "epoch 53; iter: 0; batch classifier loss: 0.182474; batch adversarial loss: 0.402136\n",
      "epoch 54; iter: 0; batch classifier loss: 0.225458; batch adversarial loss: 0.435959\n",
      "epoch 55; iter: 0; batch classifier loss: 0.227241; batch adversarial loss: 0.460433\n",
      "epoch 56; iter: 0; batch classifier loss: 0.167449; batch adversarial loss: 0.412365\n",
      "epoch 57; iter: 0; batch classifier loss: 0.239861; batch adversarial loss: 0.445565\n",
      "epoch 58; iter: 0; batch classifier loss: 0.205872; batch adversarial loss: 0.399449\n",
      "epoch 59; iter: 0; batch classifier loss: 0.251529; batch adversarial loss: 0.448534\n",
      "epoch 60; iter: 0; batch classifier loss: 0.169123; batch adversarial loss: 0.434440\n",
      "epoch 61; iter: 0; batch classifier loss: 0.249946; batch adversarial loss: 0.385898\n",
      "epoch 62; iter: 0; batch classifier loss: 0.205327; batch adversarial loss: 0.421922\n",
      "epoch 63; iter: 0; batch classifier loss: 0.136623; batch adversarial loss: 0.531109\n",
      "epoch 64; iter: 0; batch classifier loss: 0.175895; batch adversarial loss: 0.482304\n",
      "epoch 65; iter: 0; batch classifier loss: 0.219429; batch adversarial loss: 0.459267\n",
      "epoch 66; iter: 0; batch classifier loss: 0.255609; batch adversarial loss: 0.410309\n",
      "epoch 67; iter: 0; batch classifier loss: 0.208667; batch adversarial loss: 0.397850\n",
      "epoch 68; iter: 0; batch classifier loss: 0.159085; batch adversarial loss: 0.447401\n",
      "epoch 69; iter: 0; batch classifier loss: 0.143834; batch adversarial loss: 0.520041\n",
      "epoch 70; iter: 0; batch classifier loss: 0.123338; batch adversarial loss: 0.384765\n",
      "epoch 71; iter: 0; batch classifier loss: 0.174019; batch adversarial loss: 0.421930\n",
      "epoch 72; iter: 0; batch classifier loss: 0.198349; batch adversarial loss: 0.397208\n",
      "epoch 73; iter: 0; batch classifier loss: 0.245545; batch adversarial loss: 0.507612\n",
      "epoch 74; iter: 0; batch classifier loss: 0.153153; batch adversarial loss: 0.446244\n",
      "epoch 75; iter: 0; batch classifier loss: 0.190660; batch adversarial loss: 0.409603\n",
      "epoch 76; iter: 0; batch classifier loss: 0.246220; batch adversarial loss: 0.507947\n",
      "epoch 77; iter: 0; batch classifier loss: 0.191618; batch adversarial loss: 0.495603\n",
      "epoch 78; iter: 0; batch classifier loss: 0.100382; batch adversarial loss: 0.593552\n",
      "epoch 79; iter: 0; batch classifier loss: 0.138603; batch adversarial loss: 0.444450\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074597; batch adversarial loss: 0.498150\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071123; batch adversarial loss: 0.503691\n",
      "epoch 82; iter: 0; batch classifier loss: 0.136930; batch adversarial loss: 0.450334\n",
      "epoch 83; iter: 0; batch classifier loss: 0.146876; batch adversarial loss: 0.486047\n",
      "epoch 84; iter: 0; batch classifier loss: 0.109231; batch adversarial loss: 0.495128\n",
      "epoch 85; iter: 0; batch classifier loss: 0.087365; batch adversarial loss: 0.473505\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089035; batch adversarial loss: 0.521436\n",
      "epoch 87; iter: 0; batch classifier loss: 0.161112; batch adversarial loss: 0.407510\n",
      "epoch 88; iter: 0; batch classifier loss: 0.141085; batch adversarial loss: 0.422321\n",
      "epoch 89; iter: 0; batch classifier loss: 0.112662; batch adversarial loss: 0.367960\n",
      "epoch 90; iter: 0; batch classifier loss: 0.080849; batch adversarial loss: 0.402372\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077849; batch adversarial loss: 0.446612\n",
      "epoch 92; iter: 0; batch classifier loss: 0.083624; batch adversarial loss: 0.424816\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072258; batch adversarial loss: 0.436637\n",
      "epoch 94; iter: 0; batch classifier loss: 0.108012; batch adversarial loss: 0.437583\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042730; batch adversarial loss: 0.496974\n",
      "epoch 96; iter: 0; batch classifier loss: 0.086348; batch adversarial loss: 0.496418\n",
      "epoch 97; iter: 0; batch classifier loss: 0.107422; batch adversarial loss: 0.541005\n",
      "epoch 98; iter: 0; batch classifier loss: 0.070122; batch adversarial loss: 0.517317\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069199; batch adversarial loss: 0.361738\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056279; batch adversarial loss: 0.440256\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063667; batch adversarial loss: 0.529617\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059289; batch adversarial loss: 0.512346\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062324; batch adversarial loss: 0.386820\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037423; batch adversarial loss: 0.479346\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053534; batch adversarial loss: 0.533618\n",
      "epoch 106; iter: 0; batch classifier loss: 0.069262; batch adversarial loss: 0.427474\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041707; batch adversarial loss: 0.478178\n",
      "epoch 108; iter: 0; batch classifier loss: 0.079728; batch adversarial loss: 0.393879\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059545; batch adversarial loss: 0.415433\n",
      "epoch 110; iter: 0; batch classifier loss: 0.098510; batch adversarial loss: 0.379989\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034261; batch adversarial loss: 0.401583\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024394; batch adversarial loss: 0.511351\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047772; batch adversarial loss: 0.488820\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039071; batch adversarial loss: 0.532910\n",
      "epoch 115; iter: 0; batch classifier loss: 0.019388; batch adversarial loss: 0.541964\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050672; batch adversarial loss: 0.443278\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035284; batch adversarial loss: 0.491388\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048153; batch adversarial loss: 0.413093\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026748; batch adversarial loss: 0.503228\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037175; batch adversarial loss: 0.425206\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048129; batch adversarial loss: 0.453588\n",
      "epoch 122; iter: 0; batch classifier loss: 0.077908; batch adversarial loss: 0.521438\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047846; batch adversarial loss: 0.472037\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035586; batch adversarial loss: 0.511613\n",
      "epoch 125; iter: 0; batch classifier loss: 0.007282; batch adversarial loss: 0.462507\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052293; batch adversarial loss: 0.448071\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022070; batch adversarial loss: 0.457393\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017138; batch adversarial loss: 0.432097\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032656; batch adversarial loss: 0.414971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.045813; batch adversarial loss: 0.394292\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015891; batch adversarial loss: 0.515140\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042374; batch adversarial loss: 0.428515\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024023; batch adversarial loss: 0.482979\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027006; batch adversarial loss: 0.462582\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027191; batch adversarial loss: 0.414915\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020713; batch adversarial loss: 0.421653\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027730; batch adversarial loss: 0.460070\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034786; batch adversarial loss: 0.441405\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014036; batch adversarial loss: 0.453452\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031359; batch adversarial loss: 0.536265\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022834; batch adversarial loss: 0.471039\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030544; batch adversarial loss: 0.452124\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033935; batch adversarial loss: 0.434295\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027694; batch adversarial loss: 0.415622\n",
      "epoch 145; iter: 0; batch classifier loss: 0.007762; batch adversarial loss: 0.453037\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015510; batch adversarial loss: 0.434039\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014564; batch adversarial loss: 0.500221\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019621; batch adversarial loss: 0.441231\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029596; batch adversarial loss: 0.569900\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013639; batch adversarial loss: 0.412529\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020766; batch adversarial loss: 0.421746\n",
      "epoch 152; iter: 0; batch classifier loss: 0.012691; batch adversarial loss: 0.461664\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027507; batch adversarial loss: 0.456903\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017576; batch adversarial loss: 0.478091\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015769; batch adversarial loss: 0.398683\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022191; batch adversarial loss: 0.543488\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022491; batch adversarial loss: 0.448926\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009325; batch adversarial loss: 0.480001\n",
      "epoch 159; iter: 0; batch classifier loss: 0.048993; batch adversarial loss: 0.395363\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023589; batch adversarial loss: 0.476713\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025065; batch adversarial loss: 0.575735\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019182; batch adversarial loss: 0.437346\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018674; batch adversarial loss: 0.501987\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010263; batch adversarial loss: 0.445329\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009953; batch adversarial loss: 0.376551\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020162; batch adversarial loss: 0.606223\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012151; batch adversarial loss: 0.453395\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020423; batch adversarial loss: 0.359087\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007715; batch adversarial loss: 0.499447\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010070; batch adversarial loss: 0.461287\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015350; batch adversarial loss: 0.410113\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019431; batch adversarial loss: 0.423262\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013624; batch adversarial loss: 0.455220\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012498; batch adversarial loss: 0.403675\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022502; batch adversarial loss: 0.485837\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026467; batch adversarial loss: 0.375891\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008650; batch adversarial loss: 0.448335\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010900; batch adversarial loss: 0.476191\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006685; batch adversarial loss: 0.365952\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012305; batch adversarial loss: 0.521093\n",
      "epoch 181; iter: 0; batch classifier loss: 0.004806; batch adversarial loss: 0.482414\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024772; batch adversarial loss: 0.504190\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025883; batch adversarial loss: 0.489860\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011764; batch adversarial loss: 0.428515\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009269; batch adversarial loss: 0.407435\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026629; batch adversarial loss: 0.487645\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010413; batch adversarial loss: 0.426193\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029363; batch adversarial loss: 0.423299\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010173; batch adversarial loss: 0.372055\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017330; batch adversarial loss: 0.412480\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006019; batch adversarial loss: 0.443204\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021472; batch adversarial loss: 0.457070\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023318; batch adversarial loss: 0.408625\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024939; batch adversarial loss: 0.458315\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006861; batch adversarial loss: 0.364817\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027316; batch adversarial loss: 0.516572\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006156; batch adversarial loss: 0.409991\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029867; batch adversarial loss: 0.470360\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007994; batch adversarial loss: 0.446690\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701935; batch adversarial loss: 0.694621\n",
      "epoch 1; iter: 0; batch classifier loss: 0.500278; batch adversarial loss: 0.658155\n",
      "epoch 2; iter: 0; batch classifier loss: 0.436590; batch adversarial loss: 0.623165\n",
      "epoch 3; iter: 0; batch classifier loss: 0.375745; batch adversarial loss: 0.606391\n",
      "epoch 4; iter: 0; batch classifier loss: 0.264745; batch adversarial loss: 0.582607\n",
      "epoch 5; iter: 0; batch classifier loss: 0.296094; batch adversarial loss: 0.553914\n",
      "epoch 6; iter: 0; batch classifier loss: 0.209319; batch adversarial loss: 0.541773\n",
      "epoch 7; iter: 0; batch classifier loss: 0.249189; batch adversarial loss: 0.516005\n",
      "epoch 8; iter: 0; batch classifier loss: 0.188502; batch adversarial loss: 0.493548\n",
      "epoch 9; iter: 0; batch classifier loss: 0.213979; batch adversarial loss: 0.505337\n",
      "epoch 10; iter: 0; batch classifier loss: 0.225275; batch adversarial loss: 0.452977\n",
      "epoch 11; iter: 0; batch classifier loss: 0.172003; batch adversarial loss: 0.479086\n",
      "epoch 12; iter: 0; batch classifier loss: 0.182258; batch adversarial loss: 0.484994\n",
      "epoch 13; iter: 0; batch classifier loss: 0.185678; batch adversarial loss: 0.458531\n",
      "epoch 14; iter: 0; batch classifier loss: 0.156720; batch adversarial loss: 0.534909\n",
      "epoch 15; iter: 0; batch classifier loss: 0.165158; batch adversarial loss: 0.561590\n",
      "epoch 16; iter: 0; batch classifier loss: 0.166278; batch adversarial loss: 0.437804\n",
      "epoch 17; iter: 0; batch classifier loss: 0.218669; batch adversarial loss: 0.501523\n",
      "epoch 18; iter: 0; batch classifier loss: 0.167571; batch adversarial loss: 0.554652\n",
      "epoch 19; iter: 0; batch classifier loss: 0.131270; batch adversarial loss: 0.499077\n",
      "epoch 20; iter: 0; batch classifier loss: 0.175842; batch adversarial loss: 0.495218\n",
      "epoch 21; iter: 0; batch classifier loss: 0.145480; batch adversarial loss: 0.513649\n",
      "epoch 22; iter: 0; batch classifier loss: 0.217538; batch adversarial loss: 0.480258\n",
      "epoch 23; iter: 0; batch classifier loss: 0.194992; batch adversarial loss: 0.456090\n",
      "epoch 24; iter: 0; batch classifier loss: 0.181659; batch adversarial loss: 0.482640\n",
      "epoch 25; iter: 0; batch classifier loss: 0.190447; batch adversarial loss: 0.483030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.206924; batch adversarial loss: 0.558126\n",
      "epoch 27; iter: 0; batch classifier loss: 0.330473; batch adversarial loss: 0.482166\n",
      "epoch 28; iter: 0; batch classifier loss: 0.311413; batch adversarial loss: 0.489262\n",
      "epoch 29; iter: 0; batch classifier loss: 0.411843; batch adversarial loss: 0.447689\n",
      "epoch 30; iter: 0; batch classifier loss: 0.196987; batch adversarial loss: 0.427193\n",
      "epoch 31; iter: 0; batch classifier loss: 0.150789; batch adversarial loss: 0.469724\n",
      "epoch 32; iter: 0; batch classifier loss: 0.112105; batch adversarial loss: 0.464412\n",
      "epoch 33; iter: 0; batch classifier loss: 0.108563; batch adversarial loss: 0.511795\n",
      "epoch 34; iter: 0; batch classifier loss: 0.098013; batch adversarial loss: 0.479242\n",
      "epoch 35; iter: 0; batch classifier loss: 0.133862; batch adversarial loss: 0.422057\n",
      "epoch 36; iter: 0; batch classifier loss: 0.112289; batch adversarial loss: 0.434410\n",
      "epoch 37; iter: 0; batch classifier loss: 0.081175; batch adversarial loss: 0.503660\n",
      "epoch 38; iter: 0; batch classifier loss: 0.069668; batch adversarial loss: 0.497996\n",
      "epoch 39; iter: 0; batch classifier loss: 0.083343; batch adversarial loss: 0.493007\n",
      "epoch 40; iter: 0; batch classifier loss: 0.081231; batch adversarial loss: 0.479602\n",
      "epoch 41; iter: 0; batch classifier loss: 0.075965; batch adversarial loss: 0.411792\n",
      "epoch 42; iter: 0; batch classifier loss: 0.093665; batch adversarial loss: 0.476836\n",
      "epoch 43; iter: 0; batch classifier loss: 0.136839; batch adversarial loss: 0.460503\n",
      "epoch 44; iter: 0; batch classifier loss: 0.071614; batch adversarial loss: 0.500238\n",
      "epoch 45; iter: 0; batch classifier loss: 0.049254; batch adversarial loss: 0.508672\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086526; batch adversarial loss: 0.461963\n",
      "epoch 47; iter: 0; batch classifier loss: 0.080895; batch adversarial loss: 0.415670\n",
      "epoch 48; iter: 0; batch classifier loss: 0.106359; batch adversarial loss: 0.472565\n",
      "epoch 49; iter: 0; batch classifier loss: 0.073941; batch adversarial loss: 0.562385\n",
      "epoch 50; iter: 0; batch classifier loss: 0.065619; batch adversarial loss: 0.542728\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073462; batch adversarial loss: 0.522888\n",
      "epoch 52; iter: 0; batch classifier loss: 0.106534; batch adversarial loss: 0.410428\n",
      "epoch 53; iter: 0; batch classifier loss: 0.045933; batch adversarial loss: 0.376539\n",
      "epoch 54; iter: 0; batch classifier loss: 0.115834; batch adversarial loss: 0.384200\n",
      "epoch 55; iter: 0; batch classifier loss: 0.131178; batch adversarial loss: 0.457643\n",
      "epoch 56; iter: 0; batch classifier loss: 0.057733; batch adversarial loss: 0.479991\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073514; batch adversarial loss: 0.500023\n",
      "epoch 58; iter: 0; batch classifier loss: 0.052743; batch adversarial loss: 0.542913\n",
      "epoch 59; iter: 0; batch classifier loss: 0.057824; batch adversarial loss: 0.426405\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076618; batch adversarial loss: 0.361564\n",
      "epoch 61; iter: 0; batch classifier loss: 0.058157; batch adversarial loss: 0.460415\n",
      "epoch 62; iter: 0; batch classifier loss: 0.097164; batch adversarial loss: 0.505480\n",
      "epoch 63; iter: 0; batch classifier loss: 0.053107; batch adversarial loss: 0.450969\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076887; batch adversarial loss: 0.471530\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065899; batch adversarial loss: 0.548829\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073399; batch adversarial loss: 0.531100\n",
      "epoch 67; iter: 0; batch classifier loss: 0.055092; batch adversarial loss: 0.459672\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059194; batch adversarial loss: 0.467178\n",
      "epoch 69; iter: 0; batch classifier loss: 0.050542; batch adversarial loss: 0.465781\n",
      "epoch 70; iter: 0; batch classifier loss: 0.040878; batch adversarial loss: 0.474255\n",
      "epoch 71; iter: 0; batch classifier loss: 0.138685; batch adversarial loss: 0.401303\n",
      "epoch 72; iter: 0; batch classifier loss: 0.105441; batch adversarial loss: 0.439359\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090602; batch adversarial loss: 0.399824\n",
      "epoch 74; iter: 0; batch classifier loss: 0.052114; batch adversarial loss: 0.627544\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067872; batch adversarial loss: 0.426125\n",
      "epoch 76; iter: 0; batch classifier loss: 0.052964; batch adversarial loss: 0.521357\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063462; batch adversarial loss: 0.499666\n",
      "epoch 78; iter: 0; batch classifier loss: 0.026544; batch adversarial loss: 0.424378\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075396; batch adversarial loss: 0.502738\n",
      "epoch 80; iter: 0; batch classifier loss: 0.047352; batch adversarial loss: 0.505033\n",
      "epoch 81; iter: 0; batch classifier loss: 0.035257; batch adversarial loss: 0.482939\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063865; batch adversarial loss: 0.439294\n",
      "epoch 83; iter: 0; batch classifier loss: 0.093079; batch adversarial loss: 0.441270\n",
      "epoch 84; iter: 0; batch classifier loss: 0.040659; batch adversarial loss: 0.542903\n",
      "epoch 85; iter: 0; batch classifier loss: 0.053708; batch adversarial loss: 0.419454\n",
      "epoch 86; iter: 0; batch classifier loss: 0.027252; batch adversarial loss: 0.423981\n",
      "epoch 87; iter: 0; batch classifier loss: 0.060667; batch adversarial loss: 0.441883\n",
      "epoch 88; iter: 0; batch classifier loss: 0.052399; batch adversarial loss: 0.508389\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047761; batch adversarial loss: 0.566351\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050993; batch adversarial loss: 0.479604\n",
      "epoch 91; iter: 0; batch classifier loss: 0.017142; batch adversarial loss: 0.488278\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051123; batch adversarial loss: 0.535863\n",
      "epoch 93; iter: 0; batch classifier loss: 0.042577; batch adversarial loss: 0.503685\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039116; batch adversarial loss: 0.500639\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043711; batch adversarial loss: 0.475699\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070458; batch adversarial loss: 0.593195\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050222; batch adversarial loss: 0.489458\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059894; batch adversarial loss: 0.443848\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059207; batch adversarial loss: 0.513883\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043207; batch adversarial loss: 0.490598\n",
      "epoch 101; iter: 0; batch classifier loss: 0.032588; batch adversarial loss: 0.415576\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043558; batch adversarial loss: 0.505228\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049682; batch adversarial loss: 0.435221\n",
      "epoch 104; iter: 0; batch classifier loss: 0.072614; batch adversarial loss: 0.454970\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062187; batch adversarial loss: 0.470410\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059852; batch adversarial loss: 0.530728\n",
      "epoch 107; iter: 0; batch classifier loss: 0.064294; batch adversarial loss: 0.379156\n",
      "epoch 108; iter: 0; batch classifier loss: 0.021281; batch adversarial loss: 0.441652\n",
      "epoch 109; iter: 0; batch classifier loss: 0.069076; batch adversarial loss: 0.405125\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035586; batch adversarial loss: 0.489833\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029472; batch adversarial loss: 0.374337\n",
      "epoch 112; iter: 0; batch classifier loss: 0.021909; batch adversarial loss: 0.530993\n",
      "epoch 113; iter: 0; batch classifier loss: 0.073195; batch adversarial loss: 0.430354\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052858; batch adversarial loss: 0.448276\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031527; batch adversarial loss: 0.406094\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042815; batch adversarial loss: 0.409462\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045730; batch adversarial loss: 0.472459\n",
      "epoch 118; iter: 0; batch classifier loss: 0.023802; batch adversarial loss: 0.497479\n",
      "epoch 119; iter: 0; batch classifier loss: 0.058534; batch adversarial loss: 0.529078\n",
      "epoch 120; iter: 0; batch classifier loss: 0.015209; batch adversarial loss: 0.469898\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023065; batch adversarial loss: 0.469194\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039360; batch adversarial loss: 0.400457\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043725; batch adversarial loss: 0.477253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.021303; batch adversarial loss: 0.523274\n",
      "epoch 125; iter: 0; batch classifier loss: 0.066041; batch adversarial loss: 0.384596\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017837; batch adversarial loss: 0.596269\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028558; batch adversarial loss: 0.542267\n",
      "epoch 128; iter: 0; batch classifier loss: 0.015368; batch adversarial loss: 0.515507\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021386; batch adversarial loss: 0.454210\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032352; batch adversarial loss: 0.449065\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019372; batch adversarial loss: 0.391430\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015831; batch adversarial loss: 0.465748\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037176; batch adversarial loss: 0.475222\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050692; batch adversarial loss: 0.421921\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017316; batch adversarial loss: 0.444307\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033288; batch adversarial loss: 0.479865\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015317; batch adversarial loss: 0.515395\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023228; batch adversarial loss: 0.469397\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039294; batch adversarial loss: 0.573866\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038113; batch adversarial loss: 0.407893\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033989; batch adversarial loss: 0.496272\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026865; batch adversarial loss: 0.513081\n",
      "epoch 143; iter: 0; batch classifier loss: 0.044103; batch adversarial loss: 0.495769\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019030; batch adversarial loss: 0.469592\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013403; batch adversarial loss: 0.458670\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017063; batch adversarial loss: 0.485381\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023723; batch adversarial loss: 0.463084\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022579; batch adversarial loss: 0.414200\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034797; batch adversarial loss: 0.397243\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010304; batch adversarial loss: 0.490973\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015823; batch adversarial loss: 0.484838\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030836; batch adversarial loss: 0.552149\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010662; batch adversarial loss: 0.461561\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024326; batch adversarial loss: 0.514797\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023877; batch adversarial loss: 0.452532\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029406; batch adversarial loss: 0.425241\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013573; batch adversarial loss: 0.511771\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027400; batch adversarial loss: 0.364276\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023001; batch adversarial loss: 0.477387\n",
      "epoch 160; iter: 0; batch classifier loss: 0.065173; batch adversarial loss: 0.481327\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008726; batch adversarial loss: 0.516216\n",
      "epoch 162; iter: 0; batch classifier loss: 0.053478; batch adversarial loss: 0.461430\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023557; batch adversarial loss: 0.505719\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015139; batch adversarial loss: 0.387627\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008031; batch adversarial loss: 0.575958\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030171; batch adversarial loss: 0.460903\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022083; batch adversarial loss: 0.480450\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012116; batch adversarial loss: 0.512472\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028110; batch adversarial loss: 0.439897\n",
      "epoch 170; iter: 0; batch classifier loss: 0.044626; batch adversarial loss: 0.433888\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020426; batch adversarial loss: 0.406480\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021219; batch adversarial loss: 0.437653\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028122; batch adversarial loss: 0.405999\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024042; batch adversarial loss: 0.400697\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021004; batch adversarial loss: 0.418289\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020888; batch adversarial loss: 0.520244\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011688; batch adversarial loss: 0.293896\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008003; batch adversarial loss: 0.463273\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015927; batch adversarial loss: 0.457615\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021502; batch adversarial loss: 0.540720\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008534; batch adversarial loss: 0.487508\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011141; batch adversarial loss: 0.477201\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023639; batch adversarial loss: 0.472678\n",
      "epoch 184; iter: 0; batch classifier loss: 0.053878; batch adversarial loss: 0.444757\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015093; batch adversarial loss: 0.437387\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014452; batch adversarial loss: 0.438050\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019350; batch adversarial loss: 0.455819\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024436; batch adversarial loss: 0.504755\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014493; batch adversarial loss: 0.354331\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011026; batch adversarial loss: 0.461378\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016555; batch adversarial loss: 0.596850\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018488; batch adversarial loss: 0.466536\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011414; batch adversarial loss: 0.505504\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023701; batch adversarial loss: 0.400446\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009534; batch adversarial loss: 0.492404\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017733; batch adversarial loss: 0.498652\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028506; batch adversarial loss: 0.399397\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038566; batch adversarial loss: 0.518651\n",
      "epoch 199; iter: 0; batch classifier loss: 0.041841; batch adversarial loss: 0.594143\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678811; batch adversarial loss: 0.611193\n",
      "epoch 1; iter: 0; batch classifier loss: 0.446305; batch adversarial loss: 0.621547\n",
      "epoch 2; iter: 0; batch classifier loss: 0.372380; batch adversarial loss: 0.603157\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393155; batch adversarial loss: 0.594322\n",
      "epoch 4; iter: 0; batch classifier loss: 0.489275; batch adversarial loss: 0.637711\n",
      "epoch 5; iter: 0; batch classifier loss: 0.415017; batch adversarial loss: 0.566998\n",
      "epoch 6; iter: 0; batch classifier loss: 0.356848; batch adversarial loss: 0.633102\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578012; batch adversarial loss: 0.553549\n",
      "epoch 8; iter: 0; batch classifier loss: 0.677313; batch adversarial loss: 0.597667\n",
      "epoch 9; iter: 0; batch classifier loss: 0.701501; batch adversarial loss: 0.528381\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472476; batch adversarial loss: 0.517362\n",
      "epoch 11; iter: 0; batch classifier loss: 0.339399; batch adversarial loss: 0.501415\n",
      "epoch 12; iter: 0; batch classifier loss: 0.312855; batch adversarial loss: 0.513658\n",
      "epoch 13; iter: 0; batch classifier loss: 0.273747; batch adversarial loss: 0.505455\n",
      "epoch 14; iter: 0; batch classifier loss: 0.298715; batch adversarial loss: 0.488008\n",
      "epoch 15; iter: 0; batch classifier loss: 0.323405; batch adversarial loss: 0.488210\n",
      "epoch 16; iter: 0; batch classifier loss: 0.228175; batch adversarial loss: 0.525489\n",
      "epoch 17; iter: 0; batch classifier loss: 0.273463; batch adversarial loss: 0.464800\n",
      "epoch 18; iter: 0; batch classifier loss: 0.184699; batch adversarial loss: 0.532258\n",
      "epoch 19; iter: 0; batch classifier loss: 0.235169; batch adversarial loss: 0.447523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.203297; batch adversarial loss: 0.447057\n",
      "epoch 21; iter: 0; batch classifier loss: 0.212338; batch adversarial loss: 0.503940\n",
      "epoch 22; iter: 0; batch classifier loss: 0.221961; batch adversarial loss: 0.471684\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203932; batch adversarial loss: 0.449422\n",
      "epoch 24; iter: 0; batch classifier loss: 0.177202; batch adversarial loss: 0.495057\n",
      "epoch 25; iter: 0; batch classifier loss: 0.171879; batch adversarial loss: 0.469332\n",
      "epoch 26; iter: 0; batch classifier loss: 0.164922; batch adversarial loss: 0.465272\n",
      "epoch 27; iter: 0; batch classifier loss: 0.213917; batch adversarial loss: 0.506875\n",
      "epoch 28; iter: 0; batch classifier loss: 0.210205; batch adversarial loss: 0.424300\n",
      "epoch 29; iter: 0; batch classifier loss: 0.160985; batch adversarial loss: 0.448074\n",
      "epoch 30; iter: 0; batch classifier loss: 0.177510; batch adversarial loss: 0.347475\n",
      "epoch 31; iter: 0; batch classifier loss: 0.137654; batch adversarial loss: 0.475644\n",
      "epoch 32; iter: 0; batch classifier loss: 0.114782; batch adversarial loss: 0.469929\n",
      "epoch 33; iter: 0; batch classifier loss: 0.152246; batch adversarial loss: 0.490772\n",
      "epoch 34; iter: 0; batch classifier loss: 0.102853; batch adversarial loss: 0.524247\n",
      "epoch 35; iter: 0; batch classifier loss: 0.218101; batch adversarial loss: 0.501438\n",
      "epoch 36; iter: 0; batch classifier loss: 0.130960; batch adversarial loss: 0.451088\n",
      "epoch 37; iter: 0; batch classifier loss: 0.147556; batch adversarial loss: 0.441457\n",
      "epoch 38; iter: 0; batch classifier loss: 0.202616; batch adversarial loss: 0.394768\n",
      "epoch 39; iter: 0; batch classifier loss: 0.145944; batch adversarial loss: 0.480470\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116276; batch adversarial loss: 0.374078\n",
      "epoch 41; iter: 0; batch classifier loss: 0.129554; batch adversarial loss: 0.405251\n",
      "epoch 42; iter: 0; batch classifier loss: 0.101510; batch adversarial loss: 0.498179\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112111; batch adversarial loss: 0.392621\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107214; batch adversarial loss: 0.370208\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124754; batch adversarial loss: 0.420060\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104028; batch adversarial loss: 0.481737\n",
      "epoch 47; iter: 0; batch classifier loss: 0.072852; batch adversarial loss: 0.476074\n",
      "epoch 48; iter: 0; batch classifier loss: 0.096263; batch adversarial loss: 0.438194\n",
      "epoch 49; iter: 0; batch classifier loss: 0.156393; batch adversarial loss: 0.373735\n",
      "epoch 50; iter: 0; batch classifier loss: 0.070108; batch adversarial loss: 0.456161\n",
      "epoch 51; iter: 0; batch classifier loss: 0.131105; batch adversarial loss: 0.438910\n",
      "epoch 52; iter: 0; batch classifier loss: 0.130222; batch adversarial loss: 0.426253\n",
      "epoch 53; iter: 0; batch classifier loss: 0.138299; batch adversarial loss: 0.377481\n",
      "epoch 54; iter: 0; batch classifier loss: 0.087933; batch adversarial loss: 0.501536\n",
      "epoch 55; iter: 0; batch classifier loss: 0.109700; batch adversarial loss: 0.461085\n",
      "epoch 56; iter: 0; batch classifier loss: 0.104911; batch adversarial loss: 0.564721\n",
      "epoch 57; iter: 0; batch classifier loss: 0.088441; batch adversarial loss: 0.424741\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090911; batch adversarial loss: 0.475120\n",
      "epoch 59; iter: 0; batch classifier loss: 0.148336; batch adversarial loss: 0.468985\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070126; batch adversarial loss: 0.558162\n",
      "epoch 61; iter: 0; batch classifier loss: 0.102272; batch adversarial loss: 0.396589\n",
      "epoch 62; iter: 0; batch classifier loss: 0.063260; batch adversarial loss: 0.430649\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093615; batch adversarial loss: 0.459849\n",
      "epoch 64; iter: 0; batch classifier loss: 0.091544; batch adversarial loss: 0.421679\n",
      "epoch 65; iter: 0; batch classifier loss: 0.071973; batch adversarial loss: 0.438289\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086316; batch adversarial loss: 0.509810\n",
      "epoch 67; iter: 0; batch classifier loss: 0.057190; batch adversarial loss: 0.516008\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094099; batch adversarial loss: 0.437787\n",
      "epoch 69; iter: 0; batch classifier loss: 0.054179; batch adversarial loss: 0.458036\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082609; batch adversarial loss: 0.395789\n",
      "epoch 71; iter: 0; batch classifier loss: 0.086120; batch adversarial loss: 0.470793\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087598; batch adversarial loss: 0.519958\n",
      "epoch 73; iter: 0; batch classifier loss: 0.064951; batch adversarial loss: 0.418932\n",
      "epoch 74; iter: 0; batch classifier loss: 0.068474; batch adversarial loss: 0.387729\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066506; batch adversarial loss: 0.373838\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076137; batch adversarial loss: 0.515836\n",
      "epoch 77; iter: 0; batch classifier loss: 0.073831; batch adversarial loss: 0.605064\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061584; batch adversarial loss: 0.501744\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061196; batch adversarial loss: 0.451564\n",
      "epoch 80; iter: 0; batch classifier loss: 0.101944; batch adversarial loss: 0.494107\n",
      "epoch 81; iter: 0; batch classifier loss: 0.058534; batch adversarial loss: 0.493374\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066792; batch adversarial loss: 0.488679\n",
      "epoch 83; iter: 0; batch classifier loss: 0.047218; batch adversarial loss: 0.426935\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079330; batch adversarial loss: 0.368830\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088323; batch adversarial loss: 0.453469\n",
      "epoch 86; iter: 0; batch classifier loss: 0.059396; batch adversarial loss: 0.466639\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046039; batch adversarial loss: 0.389787\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050596; batch adversarial loss: 0.440518\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057803; batch adversarial loss: 0.489739\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062395; batch adversarial loss: 0.383097\n",
      "epoch 91; iter: 0; batch classifier loss: 0.061721; batch adversarial loss: 0.507183\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057323; batch adversarial loss: 0.431970\n",
      "epoch 93; iter: 0; batch classifier loss: 0.086595; batch adversarial loss: 0.426390\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068119; batch adversarial loss: 0.496579\n",
      "epoch 95; iter: 0; batch classifier loss: 0.059405; batch adversarial loss: 0.464982\n",
      "epoch 96; iter: 0; batch classifier loss: 0.038674; batch adversarial loss: 0.478997\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065357; batch adversarial loss: 0.440539\n",
      "epoch 98; iter: 0; batch classifier loss: 0.027039; batch adversarial loss: 0.390319\n",
      "epoch 99; iter: 0; batch classifier loss: 0.029004; batch adversarial loss: 0.444077\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049099; batch adversarial loss: 0.335536\n",
      "epoch 101; iter: 0; batch classifier loss: 0.072619; batch adversarial loss: 0.391436\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033817; batch adversarial loss: 0.522327\n",
      "epoch 103; iter: 0; batch classifier loss: 0.031907; batch adversarial loss: 0.419831\n",
      "epoch 104; iter: 0; batch classifier loss: 0.088501; batch adversarial loss: 0.516327\n",
      "epoch 105; iter: 0; batch classifier loss: 0.077613; batch adversarial loss: 0.580510\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043486; batch adversarial loss: 0.377465\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024034; batch adversarial loss: 0.542128\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073366; batch adversarial loss: 0.421475\n",
      "epoch 109; iter: 0; batch classifier loss: 0.025540; batch adversarial loss: 0.348448\n",
      "epoch 110; iter: 0; batch classifier loss: 0.070744; batch adversarial loss: 0.453149\n",
      "epoch 111; iter: 0; batch classifier loss: 0.072934; batch adversarial loss: 0.498124\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057724; batch adversarial loss: 0.421270\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027640; batch adversarial loss: 0.462439\n",
      "epoch 114; iter: 0; batch classifier loss: 0.055959; batch adversarial loss: 0.471059\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031594; batch adversarial loss: 0.484200\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060645; batch adversarial loss: 0.514758\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067534; batch adversarial loss: 0.483937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.041173; batch adversarial loss: 0.450289\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030182; batch adversarial loss: 0.502619\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051144; batch adversarial loss: 0.425739\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029077; batch adversarial loss: 0.409497\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017913; batch adversarial loss: 0.475290\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031540; batch adversarial loss: 0.515779\n",
      "epoch 124; iter: 0; batch classifier loss: 0.093387; batch adversarial loss: 0.455742\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050552; batch adversarial loss: 0.556496\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049419; batch adversarial loss: 0.479338\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040601; batch adversarial loss: 0.488207\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049324; batch adversarial loss: 0.522418\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042411; batch adversarial loss: 0.408509\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040990; batch adversarial loss: 0.467334\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024320; batch adversarial loss: 0.446921\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057334; batch adversarial loss: 0.454518\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024223; batch adversarial loss: 0.445781\n",
      "epoch 134; iter: 0; batch classifier loss: 0.006127; batch adversarial loss: 0.539682\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028297; batch adversarial loss: 0.533925\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057497; batch adversarial loss: 0.489962\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025271; batch adversarial loss: 0.472995\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020778; batch adversarial loss: 0.474463\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031393; batch adversarial loss: 0.368555\n",
      "epoch 140; iter: 0; batch classifier loss: 0.058302; batch adversarial loss: 0.464606\n",
      "epoch 141; iter: 0; batch classifier loss: 0.013979; batch adversarial loss: 0.417875\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029954; batch adversarial loss: 0.431656\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023752; batch adversarial loss: 0.422768\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029849; batch adversarial loss: 0.407745\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014992; batch adversarial loss: 0.630094\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018474; batch adversarial loss: 0.316348\n",
      "epoch 147; iter: 0; batch classifier loss: 0.009128; batch adversarial loss: 0.490690\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017029; batch adversarial loss: 0.472778\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036224; batch adversarial loss: 0.504443\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024591; batch adversarial loss: 0.421934\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022897; batch adversarial loss: 0.481258\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017681; batch adversarial loss: 0.423600\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016851; batch adversarial loss: 0.578559\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041115; batch adversarial loss: 0.426862\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032967; batch adversarial loss: 0.386660\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017529; batch adversarial loss: 0.461716\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027858; batch adversarial loss: 0.332693\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028164; batch adversarial loss: 0.505034\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019798; batch adversarial loss: 0.468356\n",
      "epoch 160; iter: 0; batch classifier loss: 0.073393; batch adversarial loss: 0.395226\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019662; batch adversarial loss: 0.457394\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018276; batch adversarial loss: 0.533303\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030500; batch adversarial loss: 0.443621\n",
      "epoch 164; iter: 0; batch classifier loss: 0.040587; batch adversarial loss: 0.390870\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008352; batch adversarial loss: 0.431223\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035519; batch adversarial loss: 0.502140\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035594; batch adversarial loss: 0.495692\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013863; batch adversarial loss: 0.590420\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025331; batch adversarial loss: 0.434837\n",
      "epoch 170; iter: 0; batch classifier loss: 0.046731; batch adversarial loss: 0.479629\n",
      "epoch 171; iter: 0; batch classifier loss: 0.068482; batch adversarial loss: 0.547420\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012872; batch adversarial loss: 0.473117\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009876; batch adversarial loss: 0.441359\n",
      "epoch 174; iter: 0; batch classifier loss: 0.052072; batch adversarial loss: 0.408418\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036653; batch adversarial loss: 0.457261\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010962; batch adversarial loss: 0.499825\n",
      "epoch 177; iter: 0; batch classifier loss: 0.045630; batch adversarial loss: 0.506845\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033551; batch adversarial loss: 0.430139\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015762; batch adversarial loss: 0.417163\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014853; batch adversarial loss: 0.344171\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016761; batch adversarial loss: 0.460251\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016544; batch adversarial loss: 0.413711\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020378; batch adversarial loss: 0.488832\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009056; batch adversarial loss: 0.420271\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028905; batch adversarial loss: 0.559583\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018758; batch adversarial loss: 0.576021\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040781; batch adversarial loss: 0.475017\n",
      "epoch 188; iter: 0; batch classifier loss: 0.053638; batch adversarial loss: 0.413239\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022042; batch adversarial loss: 0.431415\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015353; batch adversarial loss: 0.477883\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017650; batch adversarial loss: 0.438994\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027130; batch adversarial loss: 0.442900\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020737; batch adversarial loss: 0.411633\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020530; batch adversarial loss: 0.436246\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022378; batch adversarial loss: 0.488238\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037966; batch adversarial loss: 0.386983\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013171; batch adversarial loss: 0.507139\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026931; batch adversarial loss: 0.455988\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015836; batch adversarial loss: 0.464722\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670203; batch adversarial loss: 0.736738\n",
      "epoch 1; iter: 0; batch classifier loss: 0.455054; batch adversarial loss: 0.665105\n",
      "epoch 2; iter: 0; batch classifier loss: 0.460984; batch adversarial loss: 0.643048\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374964; batch adversarial loss: 0.574958\n",
      "epoch 4; iter: 0; batch classifier loss: 0.388178; batch adversarial loss: 0.600022\n",
      "epoch 5; iter: 0; batch classifier loss: 0.326121; batch adversarial loss: 0.561262\n",
      "epoch 6; iter: 0; batch classifier loss: 0.337759; batch adversarial loss: 0.553617\n",
      "epoch 7; iter: 0; batch classifier loss: 0.359231; batch adversarial loss: 0.570606\n",
      "epoch 8; iter: 0; batch classifier loss: 0.262407; batch adversarial loss: 0.505888\n",
      "epoch 9; iter: 0; batch classifier loss: 0.365834; batch adversarial loss: 0.571404\n",
      "epoch 10; iter: 0; batch classifier loss: 0.297853; batch adversarial loss: 0.521796\n",
      "epoch 11; iter: 0; batch classifier loss: 0.265666; batch adversarial loss: 0.482191\n",
      "epoch 12; iter: 0; batch classifier loss: 0.303131; batch adversarial loss: 0.519240\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346093; batch adversarial loss: 0.472517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.309373; batch adversarial loss: 0.505823\n",
      "epoch 15; iter: 0; batch classifier loss: 0.298698; batch adversarial loss: 0.512673\n",
      "epoch 16; iter: 0; batch classifier loss: 0.273813; batch adversarial loss: 0.490401\n",
      "epoch 17; iter: 0; batch classifier loss: 0.261817; batch adversarial loss: 0.485061\n",
      "epoch 18; iter: 0; batch classifier loss: 0.322199; batch adversarial loss: 0.449605\n",
      "epoch 19; iter: 0; batch classifier loss: 0.241565; batch adversarial loss: 0.495708\n",
      "epoch 20; iter: 0; batch classifier loss: 0.195065; batch adversarial loss: 0.511414\n",
      "epoch 21; iter: 0; batch classifier loss: 0.289573; batch adversarial loss: 0.502712\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254672; batch adversarial loss: 0.575616\n",
      "epoch 23; iter: 0; batch classifier loss: 0.307912; batch adversarial loss: 0.457115\n",
      "epoch 24; iter: 0; batch classifier loss: 0.250675; batch adversarial loss: 0.500393\n",
      "epoch 25; iter: 0; batch classifier loss: 0.194724; batch adversarial loss: 0.497471\n",
      "epoch 26; iter: 0; batch classifier loss: 0.226139; batch adversarial loss: 0.440966\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178346; batch adversarial loss: 0.527565\n",
      "epoch 28; iter: 0; batch classifier loss: 0.183237; batch adversarial loss: 0.416301\n",
      "epoch 29; iter: 0; batch classifier loss: 0.168648; batch adversarial loss: 0.372383\n",
      "epoch 30; iter: 0; batch classifier loss: 0.221048; batch adversarial loss: 0.451568\n",
      "epoch 31; iter: 0; batch classifier loss: 0.253451; batch adversarial loss: 0.485314\n",
      "epoch 32; iter: 0; batch classifier loss: 0.196863; batch adversarial loss: 0.459511\n",
      "epoch 33; iter: 0; batch classifier loss: 0.223471; batch adversarial loss: 0.429374\n",
      "epoch 34; iter: 0; batch classifier loss: 0.182337; batch adversarial loss: 0.368614\n",
      "epoch 35; iter: 0; batch classifier loss: 0.213759; batch adversarial loss: 0.405940\n",
      "epoch 36; iter: 0; batch classifier loss: 0.221968; batch adversarial loss: 0.409556\n",
      "epoch 37; iter: 0; batch classifier loss: 0.241107; batch adversarial loss: 0.529595\n",
      "epoch 38; iter: 0; batch classifier loss: 0.212119; batch adversarial loss: 0.399356\n",
      "epoch 39; iter: 0; batch classifier loss: 0.175383; batch adversarial loss: 0.443680\n",
      "epoch 40; iter: 0; batch classifier loss: 0.182251; batch adversarial loss: 0.376005\n",
      "epoch 41; iter: 0; batch classifier loss: 0.180229; batch adversarial loss: 0.476082\n",
      "epoch 42; iter: 0; batch classifier loss: 0.221305; batch adversarial loss: 0.443965\n",
      "epoch 43; iter: 0; batch classifier loss: 0.203916; batch adversarial loss: 0.422391\n",
      "epoch 44; iter: 0; batch classifier loss: 0.226810; batch adversarial loss: 0.408100\n",
      "epoch 45; iter: 0; batch classifier loss: 0.248343; batch adversarial loss: 0.383800\n",
      "epoch 46; iter: 0; batch classifier loss: 0.269757; batch adversarial loss: 0.565163\n",
      "epoch 47; iter: 0; batch classifier loss: 0.181728; batch adversarial loss: 0.499486\n",
      "epoch 48; iter: 0; batch classifier loss: 0.207145; batch adversarial loss: 0.449156\n",
      "epoch 49; iter: 0; batch classifier loss: 0.224346; batch adversarial loss: 0.510970\n",
      "epoch 50; iter: 0; batch classifier loss: 0.224299; batch adversarial loss: 0.415546\n",
      "epoch 51; iter: 0; batch classifier loss: 0.230494; batch adversarial loss: 0.368520\n",
      "epoch 52; iter: 0; batch classifier loss: 0.330115; batch adversarial loss: 0.411720\n",
      "epoch 53; iter: 0; batch classifier loss: 0.200815; batch adversarial loss: 0.353540\n",
      "epoch 54; iter: 0; batch classifier loss: 0.224631; batch adversarial loss: 0.544272\n",
      "epoch 55; iter: 0; batch classifier loss: 0.244677; batch adversarial loss: 0.494396\n",
      "epoch 56; iter: 0; batch classifier loss: 0.258973; batch adversarial loss: 0.446355\n",
      "epoch 57; iter: 0; batch classifier loss: 0.211625; batch adversarial loss: 0.447139\n",
      "epoch 58; iter: 0; batch classifier loss: 0.169339; batch adversarial loss: 0.507909\n",
      "epoch 59; iter: 0; batch classifier loss: 0.203568; batch adversarial loss: 0.446800\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122909; batch adversarial loss: 0.519116\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080470; batch adversarial loss: 0.605729\n",
      "epoch 62; iter: 0; batch classifier loss: 0.129328; batch adversarial loss: 0.308423\n",
      "epoch 63; iter: 0; batch classifier loss: 0.212659; batch adversarial loss: 0.483267\n",
      "epoch 64; iter: 0; batch classifier loss: 0.141334; batch adversarial loss: 0.434473\n",
      "epoch 65; iter: 0; batch classifier loss: 0.158648; batch adversarial loss: 0.535241\n",
      "epoch 66; iter: 0; batch classifier loss: 0.225814; batch adversarial loss: 0.483593\n",
      "epoch 67; iter: 0; batch classifier loss: 0.173486; batch adversarial loss: 0.446995\n",
      "epoch 68; iter: 0; batch classifier loss: 0.135791; batch adversarial loss: 0.433545\n",
      "epoch 69; iter: 0; batch classifier loss: 0.204565; batch adversarial loss: 0.396795\n",
      "epoch 70; iter: 0; batch classifier loss: 0.132304; batch adversarial loss: 0.372714\n",
      "epoch 71; iter: 0; batch classifier loss: 0.077102; batch adversarial loss: 0.380434\n",
      "epoch 72; iter: 0; batch classifier loss: 0.089613; batch adversarial loss: 0.418151\n",
      "epoch 73; iter: 0; batch classifier loss: 0.059984; batch adversarial loss: 0.541857\n",
      "epoch 74; iter: 0; batch classifier loss: 0.057970; batch adversarial loss: 0.439714\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079038; batch adversarial loss: 0.552879\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059200; batch adversarial loss: 0.491981\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056679; batch adversarial loss: 0.450891\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071621; batch adversarial loss: 0.405010\n",
      "epoch 79; iter: 0; batch classifier loss: 0.036997; batch adversarial loss: 0.582968\n",
      "epoch 80; iter: 0; batch classifier loss: 0.048373; batch adversarial loss: 0.405934\n",
      "epoch 81; iter: 0; batch classifier loss: 0.036118; batch adversarial loss: 0.362924\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065478; batch adversarial loss: 0.519231\n",
      "epoch 83; iter: 0; batch classifier loss: 0.047668; batch adversarial loss: 0.401633\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067974; batch adversarial loss: 0.400140\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080666; batch adversarial loss: 0.523421\n",
      "epoch 86; iter: 0; batch classifier loss: 0.041955; batch adversarial loss: 0.499654\n",
      "epoch 87; iter: 0; batch classifier loss: 0.051092; batch adversarial loss: 0.470795\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041762; batch adversarial loss: 0.386721\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074179; batch adversarial loss: 0.531555\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068068; batch adversarial loss: 0.458815\n",
      "epoch 91; iter: 0; batch classifier loss: 0.041387; batch adversarial loss: 0.332736\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060758; batch adversarial loss: 0.422893\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067332; batch adversarial loss: 0.378061\n",
      "epoch 94; iter: 0; batch classifier loss: 0.080577; batch adversarial loss: 0.523381\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083564; batch adversarial loss: 0.481802\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070543; batch adversarial loss: 0.431035\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061362; batch adversarial loss: 0.429942\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052192; batch adversarial loss: 0.534159\n",
      "epoch 99; iter: 0; batch classifier loss: 0.090402; batch adversarial loss: 0.357747\n",
      "epoch 100; iter: 0; batch classifier loss: 0.072224; batch adversarial loss: 0.393504\n",
      "epoch 101; iter: 0; batch classifier loss: 0.076742; batch adversarial loss: 0.370136\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079085; batch adversarial loss: 0.361512\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041211; batch adversarial loss: 0.413752\n",
      "epoch 104; iter: 0; batch classifier loss: 0.076177; batch adversarial loss: 0.424404\n",
      "epoch 105; iter: 0; batch classifier loss: 0.077798; batch adversarial loss: 0.443618\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051258; batch adversarial loss: 0.416134\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049294; batch adversarial loss: 0.495850\n",
      "epoch 108; iter: 0; batch classifier loss: 0.050215; batch adversarial loss: 0.322266\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036500; batch adversarial loss: 0.395303\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049010; batch adversarial loss: 0.326576\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066391; batch adversarial loss: 0.509704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.041860; batch adversarial loss: 0.389074\n",
      "epoch 113; iter: 0; batch classifier loss: 0.082900; batch adversarial loss: 0.488895\n",
      "epoch 114; iter: 0; batch classifier loss: 0.096863; batch adversarial loss: 0.460080\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057088; batch adversarial loss: 0.390336\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050093; batch adversarial loss: 0.389814\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049384; batch adversarial loss: 0.425259\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025899; batch adversarial loss: 0.324438\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055979; batch adversarial loss: 0.393480\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048233; batch adversarial loss: 0.441097\n",
      "epoch 121; iter: 0; batch classifier loss: 0.082422; batch adversarial loss: 0.364441\n",
      "epoch 122; iter: 0; batch classifier loss: 0.076335; batch adversarial loss: 0.444192\n",
      "epoch 123; iter: 0; batch classifier loss: 0.062336; batch adversarial loss: 0.452896\n",
      "epoch 124; iter: 0; batch classifier loss: 0.102846; batch adversarial loss: 0.482805\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050712; batch adversarial loss: 0.474417\n",
      "epoch 126; iter: 0; batch classifier loss: 0.058319; batch adversarial loss: 0.437511\n",
      "epoch 127; iter: 0; batch classifier loss: 0.056568; batch adversarial loss: 0.370065\n",
      "epoch 128; iter: 0; batch classifier loss: 0.065956; batch adversarial loss: 0.454567\n",
      "epoch 129; iter: 0; batch classifier loss: 0.058021; batch adversarial loss: 0.539530\n",
      "epoch 130; iter: 0; batch classifier loss: 0.088447; batch adversarial loss: 0.397908\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054934; batch adversarial loss: 0.413352\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057640; batch adversarial loss: 0.517158\n",
      "epoch 133; iter: 0; batch classifier loss: 0.063219; batch adversarial loss: 0.425825\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062448; batch adversarial loss: 0.445226\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046472; batch adversarial loss: 0.513624\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041481; batch adversarial loss: 0.443478\n",
      "epoch 137; iter: 0; batch classifier loss: 0.075070; batch adversarial loss: 0.355536\n",
      "epoch 138; iter: 0; batch classifier loss: 0.065691; batch adversarial loss: 0.485339\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044275; batch adversarial loss: 0.472359\n",
      "epoch 140; iter: 0; batch classifier loss: 0.074760; batch adversarial loss: 0.483578\n",
      "epoch 141; iter: 0; batch classifier loss: 0.104830; batch adversarial loss: 0.360602\n",
      "epoch 142; iter: 0; batch classifier loss: 0.090250; batch adversarial loss: 0.410166\n",
      "epoch 143; iter: 0; batch classifier loss: 0.068041; batch adversarial loss: 0.363579\n",
      "epoch 144; iter: 0; batch classifier loss: 0.051005; batch adversarial loss: 0.528268\n",
      "epoch 145; iter: 0; batch classifier loss: 0.056252; batch adversarial loss: 0.429290\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039367; batch adversarial loss: 0.353910\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027550; batch adversarial loss: 0.380292\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045604; batch adversarial loss: 0.437408\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056142; batch adversarial loss: 0.432659\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038065; batch adversarial loss: 0.396392\n",
      "epoch 151; iter: 0; batch classifier loss: 0.058332; batch adversarial loss: 0.394862\n",
      "epoch 152; iter: 0; batch classifier loss: 0.054108; batch adversarial loss: 0.383780\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036323; batch adversarial loss: 0.450319\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038881; batch adversarial loss: 0.367635\n",
      "epoch 155; iter: 0; batch classifier loss: 0.068914; batch adversarial loss: 0.364108\n",
      "epoch 156; iter: 0; batch classifier loss: 0.047061; batch adversarial loss: 0.475389\n",
      "epoch 157; iter: 0; batch classifier loss: 0.061689; batch adversarial loss: 0.330299\n",
      "epoch 158; iter: 0; batch classifier loss: 0.056321; batch adversarial loss: 0.458865\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049692; batch adversarial loss: 0.433812\n",
      "epoch 160; iter: 0; batch classifier loss: 0.052080; batch adversarial loss: 0.443139\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032956; batch adversarial loss: 0.414603\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037304; batch adversarial loss: 0.437112\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022014; batch adversarial loss: 0.400385\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037201; batch adversarial loss: 0.439881\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042973; batch adversarial loss: 0.439354\n",
      "epoch 166; iter: 0; batch classifier loss: 0.069848; batch adversarial loss: 0.427737\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029747; batch adversarial loss: 0.406229\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037460; batch adversarial loss: 0.467228\n",
      "epoch 169; iter: 0; batch classifier loss: 0.052714; batch adversarial loss: 0.421070\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022989; batch adversarial loss: 0.490887\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027632; batch adversarial loss: 0.465066\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019014; batch adversarial loss: 0.444507\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021548; batch adversarial loss: 0.440549\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023184; batch adversarial loss: 0.473911\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025088; batch adversarial loss: 0.367046\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029079; batch adversarial loss: 0.453298\n",
      "epoch 177; iter: 0; batch classifier loss: 0.039997; batch adversarial loss: 0.525282\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035351; batch adversarial loss: 0.395345\n",
      "epoch 179; iter: 0; batch classifier loss: 0.055582; batch adversarial loss: 0.437870\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026801; batch adversarial loss: 0.445027\n",
      "epoch 181; iter: 0; batch classifier loss: 0.056983; batch adversarial loss: 0.484312\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042900; batch adversarial loss: 0.387195\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025939; batch adversarial loss: 0.406662\n",
      "epoch 184; iter: 0; batch classifier loss: 0.047919; batch adversarial loss: 0.415611\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020735; batch adversarial loss: 0.502534\n",
      "epoch 186; iter: 0; batch classifier loss: 0.047093; batch adversarial loss: 0.404180\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035335; batch adversarial loss: 0.445223\n",
      "epoch 188; iter: 0; batch classifier loss: 0.036127; batch adversarial loss: 0.388377\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027419; batch adversarial loss: 0.482584\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028538; batch adversarial loss: 0.474801\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033182; batch adversarial loss: 0.544582\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037049; batch adversarial loss: 0.533791\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023939; batch adversarial loss: 0.386007\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041099; batch adversarial loss: 0.486038\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021645; batch adversarial loss: 0.484100\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024749; batch adversarial loss: 0.512707\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034046; batch adversarial loss: 0.408280\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016508; batch adversarial loss: 0.405709\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023664; batch adversarial loss: 0.475297\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689251; batch adversarial loss: 0.739111\n",
      "epoch 1; iter: 0; batch classifier loss: 0.503463; batch adversarial loss: 0.695385\n",
      "epoch 2; iter: 0; batch classifier loss: 0.419385; batch adversarial loss: 0.681991\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339848; batch adversarial loss: 0.636648\n",
      "epoch 4; iter: 0; batch classifier loss: 0.400542; batch adversarial loss: 0.599104\n",
      "epoch 5; iter: 0; batch classifier loss: 0.390696; batch adversarial loss: 0.576889\n",
      "epoch 6; iter: 0; batch classifier loss: 0.303565; batch adversarial loss: 0.557427\n",
      "epoch 7; iter: 0; batch classifier loss: 0.316213; batch adversarial loss: 0.511416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.210383; batch adversarial loss: 0.528130\n",
      "epoch 9; iter: 0; batch classifier loss: 0.230587; batch adversarial loss: 0.561480\n",
      "epoch 10; iter: 0; batch classifier loss: 0.198839; batch adversarial loss: 0.500294\n",
      "epoch 11; iter: 0; batch classifier loss: 0.187773; batch adversarial loss: 0.544366\n",
      "epoch 12; iter: 0; batch classifier loss: 0.233896; batch adversarial loss: 0.500046\n",
      "epoch 13; iter: 0; batch classifier loss: 0.215443; batch adversarial loss: 0.446719\n",
      "epoch 14; iter: 0; batch classifier loss: 0.194453; batch adversarial loss: 0.462473\n",
      "epoch 15; iter: 0; batch classifier loss: 0.165514; batch adversarial loss: 0.408475\n",
      "epoch 16; iter: 0; batch classifier loss: 0.114838; batch adversarial loss: 0.427916\n",
      "epoch 17; iter: 0; batch classifier loss: 0.215119; batch adversarial loss: 0.393973\n",
      "epoch 18; iter: 0; batch classifier loss: 0.175179; batch adversarial loss: 0.375125\n",
      "epoch 19; iter: 0; batch classifier loss: 0.197085; batch adversarial loss: 0.402852\n",
      "epoch 20; iter: 0; batch classifier loss: 0.129889; batch adversarial loss: 0.409280\n",
      "epoch 21; iter: 0; batch classifier loss: 0.182095; batch adversarial loss: 0.440268\n",
      "epoch 22; iter: 0; batch classifier loss: 0.212484; batch adversarial loss: 0.396053\n",
      "epoch 23; iter: 0; batch classifier loss: 0.151290; batch adversarial loss: 0.440974\n",
      "epoch 24; iter: 0; batch classifier loss: 0.160984; batch adversarial loss: 0.355884\n",
      "epoch 25; iter: 0; batch classifier loss: 0.125327; batch adversarial loss: 0.472504\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187319; batch adversarial loss: 0.393730\n",
      "epoch 27; iter: 0; batch classifier loss: 0.196237; batch adversarial loss: 0.403347\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184746; batch adversarial loss: 0.346149\n",
      "epoch 29; iter: 0; batch classifier loss: 0.155794; batch adversarial loss: 0.425275\n",
      "epoch 30; iter: 0; batch classifier loss: 0.081920; batch adversarial loss: 0.389942\n",
      "epoch 31; iter: 0; batch classifier loss: 0.114754; batch adversarial loss: 0.484571\n",
      "epoch 32; iter: 0; batch classifier loss: 0.124853; batch adversarial loss: 0.363823\n",
      "epoch 33; iter: 0; batch classifier loss: 0.118736; batch adversarial loss: 0.420709\n",
      "epoch 34; iter: 0; batch classifier loss: 0.085560; batch adversarial loss: 0.429854\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121930; batch adversarial loss: 0.408101\n",
      "epoch 36; iter: 0; batch classifier loss: 0.117728; batch adversarial loss: 0.376465\n",
      "epoch 37; iter: 0; batch classifier loss: 0.140528; batch adversarial loss: 0.436519\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126787; batch adversarial loss: 0.480324\n",
      "epoch 39; iter: 0; batch classifier loss: 0.082905; batch adversarial loss: 0.396722\n",
      "epoch 40; iter: 0; batch classifier loss: 0.138275; batch adversarial loss: 0.495405\n",
      "epoch 41; iter: 0; batch classifier loss: 0.158359; batch adversarial loss: 0.410569\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096411; batch adversarial loss: 0.425422\n",
      "epoch 43; iter: 0; batch classifier loss: 0.124954; batch adversarial loss: 0.332322\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136224; batch adversarial loss: 0.448291\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103939; batch adversarial loss: 0.398597\n",
      "epoch 46; iter: 0; batch classifier loss: 0.070648; batch adversarial loss: 0.383412\n",
      "epoch 47; iter: 0; batch classifier loss: 0.060997; batch adversarial loss: 0.386961\n",
      "epoch 48; iter: 0; batch classifier loss: 0.097832; batch adversarial loss: 0.351590\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074538; batch adversarial loss: 0.408918\n",
      "epoch 50; iter: 0; batch classifier loss: 0.107320; batch adversarial loss: 0.483398\n",
      "epoch 51; iter: 0; batch classifier loss: 0.087289; batch adversarial loss: 0.352619\n",
      "epoch 52; iter: 0; batch classifier loss: 0.048661; batch adversarial loss: 0.436686\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088412; batch adversarial loss: 0.417406\n",
      "epoch 54; iter: 0; batch classifier loss: 0.076530; batch adversarial loss: 0.427240\n",
      "epoch 55; iter: 0; batch classifier loss: 0.095375; batch adversarial loss: 0.485248\n",
      "epoch 56; iter: 0; batch classifier loss: 0.108877; batch adversarial loss: 0.440363\n",
      "epoch 57; iter: 0; batch classifier loss: 0.117627; batch adversarial loss: 0.463219\n",
      "epoch 58; iter: 0; batch classifier loss: 0.063346; batch adversarial loss: 0.439716\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070298; batch adversarial loss: 0.437685\n",
      "epoch 60; iter: 0; batch classifier loss: 0.049637; batch adversarial loss: 0.450993\n",
      "epoch 61; iter: 0; batch classifier loss: 0.126776; batch adversarial loss: 0.396756\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078259; batch adversarial loss: 0.461770\n",
      "epoch 63; iter: 0; batch classifier loss: 0.063913; batch adversarial loss: 0.444501\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078847; batch adversarial loss: 0.459834\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087990; batch adversarial loss: 0.394580\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093329; batch adversarial loss: 0.415313\n",
      "epoch 67; iter: 0; batch classifier loss: 0.078250; batch adversarial loss: 0.428070\n",
      "epoch 68; iter: 0; batch classifier loss: 0.063435; batch adversarial loss: 0.417274\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073388; batch adversarial loss: 0.385169\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066428; batch adversarial loss: 0.395783\n",
      "epoch 71; iter: 0; batch classifier loss: 0.060203; batch adversarial loss: 0.385947\n",
      "epoch 72; iter: 0; batch classifier loss: 0.083809; batch adversarial loss: 0.489503\n",
      "epoch 73; iter: 0; batch classifier loss: 0.038169; batch adversarial loss: 0.515761\n",
      "epoch 74; iter: 0; batch classifier loss: 0.049257; batch adversarial loss: 0.454229\n",
      "epoch 75; iter: 0; batch classifier loss: 0.037002; batch adversarial loss: 0.428510\n",
      "epoch 76; iter: 0; batch classifier loss: 0.078372; batch adversarial loss: 0.502280\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069357; batch adversarial loss: 0.379597\n",
      "epoch 78; iter: 0; batch classifier loss: 0.055830; batch adversarial loss: 0.514909\n",
      "epoch 79; iter: 0; batch classifier loss: 0.089338; batch adversarial loss: 0.495498\n",
      "epoch 80; iter: 0; batch classifier loss: 0.080109; batch adversarial loss: 0.355577\n",
      "epoch 81; iter: 0; batch classifier loss: 0.086426; batch adversarial loss: 0.458611\n",
      "epoch 82; iter: 0; batch classifier loss: 0.121623; batch adversarial loss: 0.394016\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070351; batch adversarial loss: 0.526014\n",
      "epoch 84; iter: 0; batch classifier loss: 0.072007; batch adversarial loss: 0.471795\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068376; batch adversarial loss: 0.438279\n",
      "epoch 86; iter: 0; batch classifier loss: 0.043070; batch adversarial loss: 0.359893\n",
      "epoch 87; iter: 0; batch classifier loss: 0.086651; batch adversarial loss: 0.475995\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057530; batch adversarial loss: 0.394554\n",
      "epoch 89; iter: 0; batch classifier loss: 0.077949; batch adversarial loss: 0.492887\n",
      "epoch 90; iter: 0; batch classifier loss: 0.072485; batch adversarial loss: 0.405018\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060348; batch adversarial loss: 0.374940\n",
      "epoch 92; iter: 0; batch classifier loss: 0.036898; batch adversarial loss: 0.449796\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062575; batch adversarial loss: 0.377800\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061212; batch adversarial loss: 0.355592\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056347; batch adversarial loss: 0.435451\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048734; batch adversarial loss: 0.443105\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057406; batch adversarial loss: 0.511650\n",
      "epoch 98; iter: 0; batch classifier loss: 0.029155; batch adversarial loss: 0.457440\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046776; batch adversarial loss: 0.559459\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062663; batch adversarial loss: 0.488873\n",
      "epoch 101; iter: 0; batch classifier loss: 0.021918; batch adversarial loss: 0.322992\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048340; batch adversarial loss: 0.448851\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033864; batch adversarial loss: 0.405648\n",
      "epoch 104; iter: 0; batch classifier loss: 0.032957; batch adversarial loss: 0.441583\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052745; batch adversarial loss: 0.477932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.080073; batch adversarial loss: 0.392586\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025351; batch adversarial loss: 0.373784\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030366; batch adversarial loss: 0.464007\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041462; batch adversarial loss: 0.341683\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039634; batch adversarial loss: 0.442540\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032018; batch adversarial loss: 0.440610\n",
      "epoch 112; iter: 0; batch classifier loss: 0.019735; batch adversarial loss: 0.506376\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039279; batch adversarial loss: 0.480640\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035032; batch adversarial loss: 0.448175\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035340; batch adversarial loss: 0.430803\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055753; batch adversarial loss: 0.459624\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041319; batch adversarial loss: 0.462114\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033767; batch adversarial loss: 0.477360\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040059; batch adversarial loss: 0.461208\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028723; batch adversarial loss: 0.508263\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026419; batch adversarial loss: 0.537823\n",
      "epoch 122; iter: 0; batch classifier loss: 0.070658; batch adversarial loss: 0.614185\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024317; batch adversarial loss: 0.529117\n",
      "epoch 124; iter: 0; batch classifier loss: 0.090916; batch adversarial loss: 0.618942\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058064; batch adversarial loss: 0.567833\n",
      "epoch 126; iter: 0; batch classifier loss: 0.091072; batch adversarial loss: 0.486408\n",
      "epoch 127; iter: 0; batch classifier loss: 0.126866; batch adversarial loss: 0.665067\n",
      "epoch 128; iter: 0; batch classifier loss: 0.132025; batch adversarial loss: 0.688060\n",
      "epoch 129; iter: 0; batch classifier loss: 0.131565; batch adversarial loss: 0.675849\n",
      "epoch 130; iter: 0; batch classifier loss: 0.113606; batch adversarial loss: 0.627545\n",
      "epoch 131; iter: 0; batch classifier loss: 0.094721; batch adversarial loss: 0.566140\n",
      "epoch 132; iter: 0; batch classifier loss: 0.161464; batch adversarial loss: 0.758061\n",
      "epoch 133; iter: 0; batch classifier loss: 0.257368; batch adversarial loss: 0.713461\n",
      "epoch 134; iter: 0; batch classifier loss: 0.131120; batch adversarial loss: 0.611912\n",
      "epoch 135; iter: 0; batch classifier loss: 0.149205; batch adversarial loss: 0.589945\n",
      "epoch 136; iter: 0; batch classifier loss: 0.158061; batch adversarial loss: 0.716509\n",
      "epoch 137; iter: 0; batch classifier loss: 0.111041; batch adversarial loss: 0.632528\n",
      "epoch 138; iter: 0; batch classifier loss: 0.147761; batch adversarial loss: 0.642806\n",
      "epoch 139; iter: 0; batch classifier loss: 0.133766; batch adversarial loss: 0.602883\n",
      "epoch 140; iter: 0; batch classifier loss: 0.160589; batch adversarial loss: 0.592010\n",
      "epoch 141; iter: 0; batch classifier loss: 0.181896; batch adversarial loss: 0.686537\n",
      "epoch 142; iter: 0; batch classifier loss: 0.210568; batch adversarial loss: 0.714937\n",
      "epoch 143; iter: 0; batch classifier loss: 0.226955; batch adversarial loss: 0.803591\n",
      "epoch 144; iter: 0; batch classifier loss: 0.139958; batch adversarial loss: 0.656516\n",
      "epoch 145; iter: 0; batch classifier loss: 0.134309; batch adversarial loss: 0.500620\n",
      "epoch 146; iter: 0; batch classifier loss: 0.166018; batch adversarial loss: 0.562946\n",
      "epoch 147; iter: 0; batch classifier loss: 0.234890; batch adversarial loss: 0.746533\n",
      "epoch 148; iter: 0; batch classifier loss: 0.127457; batch adversarial loss: 0.509022\n",
      "epoch 149; iter: 0; batch classifier loss: 0.125689; batch adversarial loss: 0.586291\n",
      "epoch 150; iter: 0; batch classifier loss: 0.181812; batch adversarial loss: 0.590552\n",
      "epoch 151; iter: 0; batch classifier loss: 0.188219; batch adversarial loss: 0.599072\n",
      "epoch 152; iter: 0; batch classifier loss: 0.229639; batch adversarial loss: 0.628877\n",
      "epoch 153; iter: 0; batch classifier loss: 0.126554; batch adversarial loss: 0.486262\n",
      "epoch 154; iter: 0; batch classifier loss: 0.119228; batch adversarial loss: 0.472929\n",
      "epoch 155; iter: 0; batch classifier loss: 0.133793; batch adversarial loss: 0.522347\n",
      "epoch 156; iter: 0; batch classifier loss: 0.152184; batch adversarial loss: 0.552367\n",
      "epoch 157; iter: 0; batch classifier loss: 0.126766; batch adversarial loss: 0.506858\n",
      "epoch 158; iter: 0; batch classifier loss: 0.147383; batch adversarial loss: 0.485416\n",
      "epoch 159; iter: 0; batch classifier loss: 0.194025; batch adversarial loss: 0.512242\n",
      "epoch 160; iter: 0; batch classifier loss: 0.125867; batch adversarial loss: 0.472226\n",
      "epoch 161; iter: 0; batch classifier loss: 0.126954; batch adversarial loss: 0.448478\n",
      "epoch 162; iter: 0; batch classifier loss: 0.094441; batch adversarial loss: 0.527314\n",
      "epoch 163; iter: 0; batch classifier loss: 0.170229; batch adversarial loss: 0.561671\n",
      "epoch 164; iter: 0; batch classifier loss: 0.142732; batch adversarial loss: 0.535893\n",
      "epoch 165; iter: 0; batch classifier loss: 0.135499; batch adversarial loss: 0.528278\n",
      "epoch 166; iter: 0; batch classifier loss: 0.195668; batch adversarial loss: 0.522449\n",
      "epoch 167; iter: 0; batch classifier loss: 0.129833; batch adversarial loss: 0.509184\n",
      "epoch 168; iter: 0; batch classifier loss: 0.138281; batch adversarial loss: 0.557292\n",
      "epoch 169; iter: 0; batch classifier loss: 0.165859; batch adversarial loss: 0.525668\n",
      "epoch 170; iter: 0; batch classifier loss: 0.111839; batch adversarial loss: 0.559410\n",
      "epoch 171; iter: 0; batch classifier loss: 0.132945; batch adversarial loss: 0.522715\n",
      "epoch 172; iter: 0; batch classifier loss: 0.147422; batch adversarial loss: 0.460045\n",
      "epoch 173; iter: 0; batch classifier loss: 0.069711; batch adversarial loss: 0.479393\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019983; batch adversarial loss: 0.483588\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027969; batch adversarial loss: 0.455344\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030263; batch adversarial loss: 0.411641\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030597; batch adversarial loss: 0.439667\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015052; batch adversarial loss: 0.550556\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015352; batch adversarial loss: 0.454629\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034955; batch adversarial loss: 0.413589\n",
      "epoch 181; iter: 0; batch classifier loss: 0.031203; batch adversarial loss: 0.479790\n",
      "epoch 182; iter: 0; batch classifier loss: 0.067914; batch adversarial loss: 0.370605\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031374; batch adversarial loss: 0.504090\n",
      "epoch 184; iter: 0; batch classifier loss: 0.041657; batch adversarial loss: 0.468826\n",
      "epoch 185; iter: 0; batch classifier loss: 0.060061; batch adversarial loss: 0.429591\n",
      "epoch 186; iter: 0; batch classifier loss: 0.093598; batch adversarial loss: 0.454746\n",
      "epoch 187; iter: 0; batch classifier loss: 0.045841; batch adversarial loss: 0.464917\n",
      "epoch 188; iter: 0; batch classifier loss: 0.048838; batch adversarial loss: 0.446930\n",
      "epoch 189; iter: 0; batch classifier loss: 0.071414; batch adversarial loss: 0.441965\n",
      "epoch 190; iter: 0; batch classifier loss: 0.064485; batch adversarial loss: 0.407464\n",
      "epoch 191; iter: 0; batch classifier loss: 0.098863; batch adversarial loss: 0.414111\n",
      "epoch 192; iter: 0; batch classifier loss: 0.145256; batch adversarial loss: 0.528117\n",
      "epoch 193; iter: 0; batch classifier loss: 0.060009; batch adversarial loss: 0.510868\n",
      "epoch 194; iter: 0; batch classifier loss: 0.089203; batch adversarial loss: 0.440103\n",
      "epoch 195; iter: 0; batch classifier loss: 0.126844; batch adversarial loss: 0.400564\n",
      "epoch 196; iter: 0; batch classifier loss: 0.096130; batch adversarial loss: 0.472139\n",
      "epoch 197; iter: 0; batch classifier loss: 0.076060; batch adversarial loss: 0.451829\n",
      "epoch 198; iter: 0; batch classifier loss: 0.113710; batch adversarial loss: 0.443507\n",
      "epoch 199; iter: 0; batch classifier loss: 0.172763; batch adversarial loss: 0.399229\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680570; batch adversarial loss: 0.892670\n",
      "epoch 1; iter: 0; batch classifier loss: 0.535550; batch adversarial loss: 0.925018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.777604; batch adversarial loss: 0.952600\n",
      "epoch 3; iter: 0; batch classifier loss: 1.002720; batch adversarial loss: 0.896542\n",
      "epoch 4; iter: 0; batch classifier loss: 0.961166; batch adversarial loss: 0.795379\n",
      "epoch 5; iter: 0; batch classifier loss: 1.065064; batch adversarial loss: 0.718142\n",
      "epoch 6; iter: 0; batch classifier loss: 0.987903; batch adversarial loss: 0.646150\n",
      "epoch 7; iter: 0; batch classifier loss: 0.623543; batch adversarial loss: 0.603511\n",
      "epoch 8; iter: 0; batch classifier loss: 0.466740; batch adversarial loss: 0.597412\n",
      "epoch 9; iter: 0; batch classifier loss: 0.306302; batch adversarial loss: 0.517552\n",
      "epoch 10; iter: 0; batch classifier loss: 0.286396; batch adversarial loss: 0.564370\n",
      "epoch 11; iter: 0; batch classifier loss: 0.333316; batch adversarial loss: 0.513790\n",
      "epoch 12; iter: 0; batch classifier loss: 0.296298; batch adversarial loss: 0.522238\n",
      "epoch 13; iter: 0; batch classifier loss: 0.226440; batch adversarial loss: 0.546919\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263413; batch adversarial loss: 0.507226\n",
      "epoch 15; iter: 0; batch classifier loss: 0.372971; batch adversarial loss: 0.471052\n",
      "epoch 16; iter: 0; batch classifier loss: 0.173675; batch adversarial loss: 0.494877\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217852; batch adversarial loss: 0.495714\n",
      "epoch 18; iter: 0; batch classifier loss: 0.245978; batch adversarial loss: 0.499723\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277541; batch adversarial loss: 0.466848\n",
      "epoch 20; iter: 0; batch classifier loss: 0.238631; batch adversarial loss: 0.501158\n",
      "epoch 21; iter: 0; batch classifier loss: 0.236259; batch adversarial loss: 0.432769\n",
      "epoch 22; iter: 0; batch classifier loss: 0.246072; batch adversarial loss: 0.462141\n",
      "epoch 23; iter: 0; batch classifier loss: 0.269229; batch adversarial loss: 0.447367\n",
      "epoch 24; iter: 0; batch classifier loss: 0.222807; batch adversarial loss: 0.500621\n",
      "epoch 25; iter: 0; batch classifier loss: 0.211928; batch adversarial loss: 0.513375\n",
      "epoch 26; iter: 0; batch classifier loss: 0.163993; batch adversarial loss: 0.499718\n",
      "epoch 27; iter: 0; batch classifier loss: 0.180432; batch adversarial loss: 0.450042\n",
      "epoch 28; iter: 0; batch classifier loss: 0.167646; batch adversarial loss: 0.539387\n",
      "epoch 29; iter: 0; batch classifier loss: 0.196776; batch adversarial loss: 0.511746\n",
      "epoch 30; iter: 0; batch classifier loss: 0.221459; batch adversarial loss: 0.475332\n",
      "epoch 31; iter: 0; batch classifier loss: 0.127168; batch adversarial loss: 0.497237\n",
      "epoch 32; iter: 0; batch classifier loss: 0.178920; batch adversarial loss: 0.452567\n",
      "epoch 33; iter: 0; batch classifier loss: 0.166822; batch adversarial loss: 0.433726\n",
      "epoch 34; iter: 0; batch classifier loss: 0.128556; batch adversarial loss: 0.496237\n",
      "epoch 35; iter: 0; batch classifier loss: 0.141724; batch adversarial loss: 0.514381\n",
      "epoch 36; iter: 0; batch classifier loss: 0.166440; batch adversarial loss: 0.418229\n",
      "epoch 37; iter: 0; batch classifier loss: 0.181842; batch adversarial loss: 0.551872\n",
      "epoch 38; iter: 0; batch classifier loss: 0.156996; batch adversarial loss: 0.459986\n",
      "epoch 39; iter: 0; batch classifier loss: 0.136877; batch adversarial loss: 0.468800\n",
      "epoch 40; iter: 0; batch classifier loss: 0.139355; batch adversarial loss: 0.527586\n",
      "epoch 41; iter: 0; batch classifier loss: 0.155785; batch adversarial loss: 0.535849\n",
      "epoch 42; iter: 0; batch classifier loss: 0.138426; batch adversarial loss: 0.489312\n",
      "epoch 43; iter: 0; batch classifier loss: 0.128474; batch adversarial loss: 0.503374\n",
      "epoch 44; iter: 0; batch classifier loss: 0.199437; batch adversarial loss: 0.512236\n",
      "epoch 45; iter: 0; batch classifier loss: 0.133775; batch adversarial loss: 0.467239\n",
      "epoch 46; iter: 0; batch classifier loss: 0.140202; batch adversarial loss: 0.458510\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103135; batch adversarial loss: 0.485805\n",
      "epoch 48; iter: 0; batch classifier loss: 0.136406; batch adversarial loss: 0.450013\n",
      "epoch 49; iter: 0; batch classifier loss: 0.106961; batch adversarial loss: 0.478746\n",
      "epoch 50; iter: 0; batch classifier loss: 0.139612; batch adversarial loss: 0.432399\n",
      "epoch 51; iter: 0; batch classifier loss: 0.102790; batch adversarial loss: 0.551810\n",
      "epoch 52; iter: 0; batch classifier loss: 0.108197; batch adversarial loss: 0.534691\n",
      "epoch 53; iter: 0; batch classifier loss: 0.090838; batch adversarial loss: 0.465278\n",
      "epoch 54; iter: 0; batch classifier loss: 0.180221; batch adversarial loss: 0.445902\n",
      "epoch 55; iter: 0; batch classifier loss: 0.121164; batch adversarial loss: 0.429063\n",
      "epoch 56; iter: 0; batch classifier loss: 0.143632; batch adversarial loss: 0.445607\n",
      "epoch 57; iter: 0; batch classifier loss: 0.115258; batch adversarial loss: 0.529865\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103889; batch adversarial loss: 0.572635\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067444; batch adversarial loss: 0.521770\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122762; batch adversarial loss: 0.451911\n",
      "epoch 61; iter: 0; batch classifier loss: 0.062165; batch adversarial loss: 0.472114\n",
      "epoch 62; iter: 0; batch classifier loss: 0.109337; batch adversarial loss: 0.641803\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070163; batch adversarial loss: 0.445470\n",
      "epoch 64; iter: 0; batch classifier loss: 0.129857; batch adversarial loss: 0.518200\n",
      "epoch 65; iter: 0; batch classifier loss: 0.071316; batch adversarial loss: 0.625755\n",
      "epoch 66; iter: 0; batch classifier loss: 0.101565; batch adversarial loss: 0.406027\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091343; batch adversarial loss: 0.415353\n",
      "epoch 68; iter: 0; batch classifier loss: 0.114723; batch adversarial loss: 0.398856\n",
      "epoch 69; iter: 0; batch classifier loss: 0.127312; batch adversarial loss: 0.481615\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090775; batch adversarial loss: 0.551430\n",
      "epoch 71; iter: 0; batch classifier loss: 0.088706; batch adversarial loss: 0.392663\n",
      "epoch 72; iter: 0; batch classifier loss: 0.121254; batch adversarial loss: 0.437718\n",
      "epoch 73; iter: 0; batch classifier loss: 0.107873; batch adversarial loss: 0.422684\n",
      "epoch 74; iter: 0; batch classifier loss: 0.085560; batch adversarial loss: 0.460218\n",
      "epoch 75; iter: 0; batch classifier loss: 0.113062; batch adversarial loss: 0.403064\n",
      "epoch 76; iter: 0; batch classifier loss: 0.053503; batch adversarial loss: 0.556665\n",
      "epoch 77; iter: 0; batch classifier loss: 0.131886; batch adversarial loss: 0.470207\n",
      "epoch 78; iter: 0; batch classifier loss: 0.083614; batch adversarial loss: 0.375664\n",
      "epoch 79; iter: 0; batch classifier loss: 0.062908; batch adversarial loss: 0.393960\n",
      "epoch 80; iter: 0; batch classifier loss: 0.101006; batch adversarial loss: 0.498681\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071378; batch adversarial loss: 0.483603\n",
      "epoch 82; iter: 0; batch classifier loss: 0.085304; batch adversarial loss: 0.504262\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062924; batch adversarial loss: 0.455990\n",
      "epoch 84; iter: 0; batch classifier loss: 0.050857; batch adversarial loss: 0.434558\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065696; batch adversarial loss: 0.508839\n",
      "epoch 86; iter: 0; batch classifier loss: 0.110925; batch adversarial loss: 0.338105\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042842; batch adversarial loss: 0.423092\n",
      "epoch 88; iter: 0; batch classifier loss: 0.167995; batch adversarial loss: 0.489956\n",
      "epoch 89; iter: 0; batch classifier loss: 0.072905; batch adversarial loss: 0.475079\n",
      "epoch 90; iter: 0; batch classifier loss: 0.032432; batch adversarial loss: 0.460062\n",
      "epoch 91; iter: 0; batch classifier loss: 0.103611; batch adversarial loss: 0.420743\n",
      "epoch 92; iter: 0; batch classifier loss: 0.029675; batch adversarial loss: 0.404800\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036349; batch adversarial loss: 0.488317\n",
      "epoch 94; iter: 0; batch classifier loss: 0.059435; batch adversarial loss: 0.390963\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060892; batch adversarial loss: 0.475102\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051516; batch adversarial loss: 0.385889\n",
      "epoch 97; iter: 0; batch classifier loss: 0.036232; batch adversarial loss: 0.455745\n",
      "epoch 98; iter: 0; batch classifier loss: 0.066020; batch adversarial loss: 0.504962\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067142; batch adversarial loss: 0.474055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.033448; batch adversarial loss: 0.478236\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047525; batch adversarial loss: 0.453564\n",
      "epoch 102; iter: 0; batch classifier loss: 0.023333; batch adversarial loss: 0.504573\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062908; batch adversarial loss: 0.440811\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057814; batch adversarial loss: 0.500258\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054574; batch adversarial loss: 0.393302\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025441; batch adversarial loss: 0.421433\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050269; batch adversarial loss: 0.468392\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044944; batch adversarial loss: 0.471354\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038995; batch adversarial loss: 0.457117\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042228; batch adversarial loss: 0.476026\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037804; batch adversarial loss: 0.424762\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051490; batch adversarial loss: 0.430354\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044818; batch adversarial loss: 0.485492\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037253; batch adversarial loss: 0.501724\n",
      "epoch 115; iter: 0; batch classifier loss: 0.019187; batch adversarial loss: 0.467912\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045077; batch adversarial loss: 0.494006\n",
      "epoch 117; iter: 0; batch classifier loss: 0.012774; batch adversarial loss: 0.480186\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059361; batch adversarial loss: 0.470057\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038116; batch adversarial loss: 0.449149\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020057; batch adversarial loss: 0.567136\n",
      "epoch 121; iter: 0; batch classifier loss: 0.067894; batch adversarial loss: 0.480669\n",
      "epoch 122; iter: 0; batch classifier loss: 0.018631; batch adversarial loss: 0.514381\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027606; batch adversarial loss: 0.420062\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040806; batch adversarial loss: 0.418317\n",
      "epoch 125; iter: 0; batch classifier loss: 0.014403; batch adversarial loss: 0.443541\n",
      "epoch 126; iter: 0; batch classifier loss: 0.015429; batch adversarial loss: 0.422053\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019125; batch adversarial loss: 0.362077\n",
      "epoch 128; iter: 0; batch classifier loss: 0.012675; batch adversarial loss: 0.502774\n",
      "epoch 129; iter: 0; batch classifier loss: 0.044368; batch adversarial loss: 0.406523\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059130; batch adversarial loss: 0.415052\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040468; batch adversarial loss: 0.470539\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040318; batch adversarial loss: 0.420358\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049373; batch adversarial loss: 0.497905\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023900; batch adversarial loss: 0.419991\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046605; batch adversarial loss: 0.438895\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036800; batch adversarial loss: 0.448623\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025907; batch adversarial loss: 0.520745\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028678; batch adversarial loss: 0.485676\n",
      "epoch 139; iter: 0; batch classifier loss: 0.052674; batch adversarial loss: 0.458439\n",
      "epoch 140; iter: 0; batch classifier loss: 0.007888; batch adversarial loss: 0.543790\n",
      "epoch 141; iter: 0; batch classifier loss: 0.015709; batch adversarial loss: 0.439360\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043830; batch adversarial loss: 0.468845\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034714; batch adversarial loss: 0.374130\n",
      "epoch 144; iter: 0; batch classifier loss: 0.042139; batch adversarial loss: 0.471139\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021954; batch adversarial loss: 0.489103\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029568; batch adversarial loss: 0.470772\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020074; batch adversarial loss: 0.456459\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011729; batch adversarial loss: 0.486688\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034669; batch adversarial loss: 0.481277\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021038; batch adversarial loss: 0.387481\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044747; batch adversarial loss: 0.458280\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034545; batch adversarial loss: 0.462642\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011072; batch adversarial loss: 0.519997\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038512; batch adversarial loss: 0.483765\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018693; batch adversarial loss: 0.443231\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039116; batch adversarial loss: 0.340624\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026299; batch adversarial loss: 0.447593\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017714; batch adversarial loss: 0.524347\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010160; batch adversarial loss: 0.463246\n",
      "epoch 160; iter: 0; batch classifier loss: 0.011159; batch adversarial loss: 0.442236\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025604; batch adversarial loss: 0.432943\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009679; batch adversarial loss: 0.416982\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028114; batch adversarial loss: 0.463579\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028142; batch adversarial loss: 0.494036\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022484; batch adversarial loss: 0.435367\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020703; batch adversarial loss: 0.521057\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022302; batch adversarial loss: 0.444018\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032981; batch adversarial loss: 0.478435\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010346; batch adversarial loss: 0.408534\n",
      "epoch 170; iter: 0; batch classifier loss: 0.043757; batch adversarial loss: 0.445955\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028778; batch adversarial loss: 0.396937\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034075; batch adversarial loss: 0.531960\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014262; batch adversarial loss: 0.507260\n",
      "epoch 174; iter: 0; batch classifier loss: 0.074419; batch adversarial loss: 0.485801\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016656; batch adversarial loss: 0.528228\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045142; batch adversarial loss: 0.437290\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026176; batch adversarial loss: 0.408655\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019878; batch adversarial loss: 0.470411\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016542; batch adversarial loss: 0.470212\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029625; batch adversarial loss: 0.387056\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022820; batch adversarial loss: 0.473947\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013617; batch adversarial loss: 0.465683\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030134; batch adversarial loss: 0.424652\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015669; batch adversarial loss: 0.506104\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024746; batch adversarial loss: 0.456360\n",
      "epoch 186; iter: 0; batch classifier loss: 0.046543; batch adversarial loss: 0.444440\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017596; batch adversarial loss: 0.477590\n",
      "epoch 188; iter: 0; batch classifier loss: 0.036170; batch adversarial loss: 0.472947\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010224; batch adversarial loss: 0.432801\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014968; batch adversarial loss: 0.420680\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007799; batch adversarial loss: 0.442377\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010476; batch adversarial loss: 0.502183\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022329; batch adversarial loss: 0.459247\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033450; batch adversarial loss: 0.421149\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011997; batch adversarial loss: 0.443414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.019649; batch adversarial loss: 0.500420\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027530; batch adversarial loss: 0.400358\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026109; batch adversarial loss: 0.510095\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015225; batch adversarial loss: 0.370379\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695365; batch adversarial loss: 0.914967\n",
      "epoch 1; iter: 0; batch classifier loss: 0.584685; batch adversarial loss: 0.969937\n",
      "epoch 2; iter: 0; batch classifier loss: 0.917541; batch adversarial loss: 1.042272\n",
      "epoch 3; iter: 0; batch classifier loss: 1.009696; batch adversarial loss: 0.933438\n",
      "epoch 4; iter: 0; batch classifier loss: 1.130577; batch adversarial loss: 0.855966\n",
      "epoch 5; iter: 0; batch classifier loss: 1.124894; batch adversarial loss: 0.771746\n",
      "epoch 6; iter: 0; batch classifier loss: 0.944265; batch adversarial loss: 0.692240\n",
      "epoch 7; iter: 0; batch classifier loss: 0.872724; batch adversarial loss: 0.626720\n",
      "epoch 8; iter: 0; batch classifier loss: 0.659967; batch adversarial loss: 0.600145\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551896; batch adversarial loss: 0.560978\n",
      "epoch 10; iter: 0; batch classifier loss: 0.324537; batch adversarial loss: 0.570091\n",
      "epoch 11; iter: 0; batch classifier loss: 0.359377; batch adversarial loss: 0.525354\n",
      "epoch 12; iter: 0; batch classifier loss: 0.326556; batch adversarial loss: 0.494464\n",
      "epoch 13; iter: 0; batch classifier loss: 0.293636; batch adversarial loss: 0.554876\n",
      "epoch 14; iter: 0; batch classifier loss: 0.344065; batch adversarial loss: 0.496658\n",
      "epoch 15; iter: 0; batch classifier loss: 0.372772; batch adversarial loss: 0.429687\n",
      "epoch 16; iter: 0; batch classifier loss: 0.287841; batch adversarial loss: 0.507786\n",
      "epoch 17; iter: 0; batch classifier loss: 0.266736; batch adversarial loss: 0.445903\n",
      "epoch 18; iter: 0; batch classifier loss: 0.283405; batch adversarial loss: 0.509544\n",
      "epoch 19; iter: 0; batch classifier loss: 0.200834; batch adversarial loss: 0.508764\n",
      "epoch 20; iter: 0; batch classifier loss: 0.335717; batch adversarial loss: 0.430376\n",
      "epoch 21; iter: 0; batch classifier loss: 0.332429; batch adversarial loss: 0.470884\n",
      "epoch 22; iter: 0; batch classifier loss: 0.207739; batch adversarial loss: 0.455538\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171191; batch adversarial loss: 0.470900\n",
      "epoch 24; iter: 0; batch classifier loss: 0.245689; batch adversarial loss: 0.476166\n",
      "epoch 25; iter: 0; batch classifier loss: 0.238903; batch adversarial loss: 0.455018\n",
      "epoch 26; iter: 0; batch classifier loss: 0.327969; batch adversarial loss: 0.419432\n",
      "epoch 27; iter: 0; batch classifier loss: 0.161891; batch adversarial loss: 0.434791\n",
      "epoch 28; iter: 0; batch classifier loss: 0.170857; batch adversarial loss: 0.471052\n",
      "epoch 29; iter: 0; batch classifier loss: 0.237322; batch adversarial loss: 0.476511\n",
      "epoch 30; iter: 0; batch classifier loss: 0.235243; batch adversarial loss: 0.437989\n",
      "epoch 31; iter: 0; batch classifier loss: 0.223976; batch adversarial loss: 0.478241\n",
      "epoch 32; iter: 0; batch classifier loss: 0.196674; batch adversarial loss: 0.437748\n",
      "epoch 33; iter: 0; batch classifier loss: 0.236155; batch adversarial loss: 0.470165\n",
      "epoch 34; iter: 0; batch classifier loss: 0.241680; batch adversarial loss: 0.497828\n",
      "epoch 35; iter: 0; batch classifier loss: 0.176119; batch adversarial loss: 0.425102\n",
      "epoch 36; iter: 0; batch classifier loss: 0.207061; batch adversarial loss: 0.419146\n",
      "epoch 37; iter: 0; batch classifier loss: 0.185496; batch adversarial loss: 0.503239\n",
      "epoch 38; iter: 0; batch classifier loss: 0.151775; batch adversarial loss: 0.499992\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131635; batch adversarial loss: 0.403185\n",
      "epoch 40; iter: 0; batch classifier loss: 0.110759; batch adversarial loss: 0.561523\n",
      "epoch 41; iter: 0; batch classifier loss: 0.144920; batch adversarial loss: 0.433758\n",
      "epoch 42; iter: 0; batch classifier loss: 0.170132; batch adversarial loss: 0.436247\n",
      "epoch 43; iter: 0; batch classifier loss: 0.193812; batch adversarial loss: 0.405637\n",
      "epoch 44; iter: 0; batch classifier loss: 0.102855; batch adversarial loss: 0.409359\n",
      "epoch 45; iter: 0; batch classifier loss: 0.110094; batch adversarial loss: 0.451135\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126815; batch adversarial loss: 0.601867\n",
      "epoch 47; iter: 0; batch classifier loss: 0.134542; batch adversarial loss: 0.434963\n",
      "epoch 48; iter: 0; batch classifier loss: 0.131858; batch adversarial loss: 0.399768\n",
      "epoch 49; iter: 0; batch classifier loss: 0.137207; batch adversarial loss: 0.502117\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111628; batch adversarial loss: 0.522083\n",
      "epoch 51; iter: 0; batch classifier loss: 0.145369; batch adversarial loss: 0.468545\n",
      "epoch 52; iter: 0; batch classifier loss: 0.106445; batch adversarial loss: 0.463717\n",
      "epoch 53; iter: 0; batch classifier loss: 0.121885; batch adversarial loss: 0.499326\n",
      "epoch 54; iter: 0; batch classifier loss: 0.178208; batch adversarial loss: 0.420243\n",
      "epoch 55; iter: 0; batch classifier loss: 0.109368; batch adversarial loss: 0.358130\n",
      "epoch 56; iter: 0; batch classifier loss: 0.097362; batch adversarial loss: 0.405924\n",
      "epoch 57; iter: 0; batch classifier loss: 0.139835; batch adversarial loss: 0.454930\n",
      "epoch 58; iter: 0; batch classifier loss: 0.071159; batch adversarial loss: 0.461264\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099663; batch adversarial loss: 0.432679\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087541; batch adversarial loss: 0.509008\n",
      "epoch 61; iter: 0; batch classifier loss: 0.060767; batch adversarial loss: 0.567738\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069702; batch adversarial loss: 0.407332\n",
      "epoch 63; iter: 0; batch classifier loss: 0.122180; batch adversarial loss: 0.442638\n",
      "epoch 64; iter: 0; batch classifier loss: 0.126905; batch adversarial loss: 0.504282\n",
      "epoch 65; iter: 0; batch classifier loss: 0.060904; batch adversarial loss: 0.401686\n",
      "epoch 66; iter: 0; batch classifier loss: 0.046420; batch adversarial loss: 0.427103\n",
      "epoch 67; iter: 0; batch classifier loss: 0.064632; batch adversarial loss: 0.532465\n",
      "epoch 68; iter: 0; batch classifier loss: 0.118658; batch adversarial loss: 0.459323\n",
      "epoch 69; iter: 0; batch classifier loss: 0.165298; batch adversarial loss: 0.449787\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098806; batch adversarial loss: 0.377095\n",
      "epoch 71; iter: 0; batch classifier loss: 0.086462; batch adversarial loss: 0.414391\n",
      "epoch 72; iter: 0; batch classifier loss: 0.073173; batch adversarial loss: 0.371219\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079476; batch adversarial loss: 0.535995\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081879; batch adversarial loss: 0.484054\n",
      "epoch 75; iter: 0; batch classifier loss: 0.060682; batch adversarial loss: 0.553338\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086966; batch adversarial loss: 0.464455\n",
      "epoch 77; iter: 0; batch classifier loss: 0.054789; batch adversarial loss: 0.372191\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074819; batch adversarial loss: 0.442014\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044759; batch adversarial loss: 0.437564\n",
      "epoch 80; iter: 0; batch classifier loss: 0.051130; batch adversarial loss: 0.414498\n",
      "epoch 81; iter: 0; batch classifier loss: 0.049136; batch adversarial loss: 0.495062\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076704; batch adversarial loss: 0.478557\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070540; batch adversarial loss: 0.449390\n",
      "epoch 84; iter: 0; batch classifier loss: 0.030527; batch adversarial loss: 0.409547\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073680; batch adversarial loss: 0.436204\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051085; batch adversarial loss: 0.491184\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082513; batch adversarial loss: 0.470256\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042357; batch adversarial loss: 0.398242\n",
      "epoch 89; iter: 0; batch classifier loss: 0.126822; batch adversarial loss: 0.399022\n",
      "epoch 90; iter: 0; batch classifier loss: 0.035278; batch adversarial loss: 0.441736\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063289; batch adversarial loss: 0.552416\n",
      "epoch 92; iter: 0; batch classifier loss: 0.067020; batch adversarial loss: 0.524763\n",
      "epoch 93; iter: 0; batch classifier loss: 0.033292; batch adversarial loss: 0.455848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.056800; batch adversarial loss: 0.429184\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044298; batch adversarial loss: 0.431029\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063925; batch adversarial loss: 0.458604\n",
      "epoch 97; iter: 0; batch classifier loss: 0.023438; batch adversarial loss: 0.521626\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045501; batch adversarial loss: 0.470012\n",
      "epoch 99; iter: 0; batch classifier loss: 0.083415; batch adversarial loss: 0.469272\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064652; batch adversarial loss: 0.499195\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056845; batch adversarial loss: 0.463946\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058225; batch adversarial loss: 0.447453\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060359; batch adversarial loss: 0.401419\n",
      "epoch 104; iter: 0; batch classifier loss: 0.021229; batch adversarial loss: 0.449692\n",
      "epoch 105; iter: 0; batch classifier loss: 0.033058; batch adversarial loss: 0.508912\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047123; batch adversarial loss: 0.463958\n",
      "epoch 107; iter: 0; batch classifier loss: 0.074036; batch adversarial loss: 0.448512\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036905; batch adversarial loss: 0.513749\n",
      "epoch 109; iter: 0; batch classifier loss: 0.025835; batch adversarial loss: 0.487879\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060921; batch adversarial loss: 0.452897\n",
      "epoch 111; iter: 0; batch classifier loss: 0.071114; batch adversarial loss: 0.512943\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035715; batch adversarial loss: 0.487633\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047142; batch adversarial loss: 0.439651\n",
      "epoch 114; iter: 0; batch classifier loss: 0.018642; batch adversarial loss: 0.489996\n",
      "epoch 115; iter: 0; batch classifier loss: 0.026991; batch adversarial loss: 0.518526\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051608; batch adversarial loss: 0.499223\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036551; batch adversarial loss: 0.409396\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063388; batch adversarial loss: 0.442284\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037959; batch adversarial loss: 0.407894\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036150; batch adversarial loss: 0.439721\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033492; batch adversarial loss: 0.393903\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032573; batch adversarial loss: 0.460104\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017838; batch adversarial loss: 0.530247\n",
      "epoch 124; iter: 0; batch classifier loss: 0.014914; batch adversarial loss: 0.455599\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031003; batch adversarial loss: 0.511253\n",
      "epoch 126; iter: 0; batch classifier loss: 0.015124; batch adversarial loss: 0.410796\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050963; batch adversarial loss: 0.430565\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027270; batch adversarial loss: 0.471487\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032315; batch adversarial loss: 0.479935\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040813; batch adversarial loss: 0.456295\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049961; batch adversarial loss: 0.430171\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028344; batch adversarial loss: 0.436604\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044789; batch adversarial loss: 0.474845\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021029; batch adversarial loss: 0.438425\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041385; batch adversarial loss: 0.451356\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043385; batch adversarial loss: 0.397300\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025189; batch adversarial loss: 0.329157\n",
      "epoch 138; iter: 0; batch classifier loss: 0.015300; batch adversarial loss: 0.451523\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016912; batch adversarial loss: 0.588128\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028184; batch adversarial loss: 0.446245\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017655; batch adversarial loss: 0.456414\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024996; batch adversarial loss: 0.524549\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026820; batch adversarial loss: 0.435489\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024203; batch adversarial loss: 0.419471\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036539; batch adversarial loss: 0.461325\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035606; batch adversarial loss: 0.422307\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011175; batch adversarial loss: 0.486129\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025643; batch adversarial loss: 0.473630\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018781; batch adversarial loss: 0.484845\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015646; batch adversarial loss: 0.452935\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009703; batch adversarial loss: 0.430887\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014806; batch adversarial loss: 0.471780\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013200; batch adversarial loss: 0.480442\n",
      "epoch 154; iter: 0; batch classifier loss: 0.053274; batch adversarial loss: 0.376809\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037700; batch adversarial loss: 0.404249\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035872; batch adversarial loss: 0.485878\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020529; batch adversarial loss: 0.485537\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008304; batch adversarial loss: 0.416396\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041887; batch adversarial loss: 0.507523\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018990; batch adversarial loss: 0.479096\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017493; batch adversarial loss: 0.426510\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007080; batch adversarial loss: 0.472262\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025745; batch adversarial loss: 0.357196\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020067; batch adversarial loss: 0.446631\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011103; batch adversarial loss: 0.411966\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013306; batch adversarial loss: 0.478342\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024099; batch adversarial loss: 0.451892\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036863; batch adversarial loss: 0.454397\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028698; batch adversarial loss: 0.370653\n",
      "epoch 170; iter: 0; batch classifier loss: 0.059803; batch adversarial loss: 0.435510\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009429; batch adversarial loss: 0.518430\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024925; batch adversarial loss: 0.454441\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006541; batch adversarial loss: 0.416005\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015047; batch adversarial loss: 0.487608\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022972; batch adversarial loss: 0.509797\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012886; batch adversarial loss: 0.462572\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015531; batch adversarial loss: 0.425826\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021181; batch adversarial loss: 0.428429\n",
      "epoch 179; iter: 0; batch classifier loss: 0.003240; batch adversarial loss: 0.481571\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007879; batch adversarial loss: 0.430373\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017754; batch adversarial loss: 0.425823\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006449; batch adversarial loss: 0.527343\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009482; batch adversarial loss: 0.450516\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021838; batch adversarial loss: 0.421218\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019352; batch adversarial loss: 0.482229\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008577; batch adversarial loss: 0.472233\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023541; batch adversarial loss: 0.418149\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015285; batch adversarial loss: 0.507218\n",
      "epoch 189; iter: 0; batch classifier loss: 0.003514; batch adversarial loss: 0.515139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.004648; batch adversarial loss: 0.486923\n",
      "epoch 191; iter: 0; batch classifier loss: 0.004344; batch adversarial loss: 0.491398\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010510; batch adversarial loss: 0.426543\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004781; batch adversarial loss: 0.495874\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009798; batch adversarial loss: 0.431153\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005112; batch adversarial loss: 0.441258\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028973; batch adversarial loss: 0.523535\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015260; batch adversarial loss: 0.479501\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006370; batch adversarial loss: 0.427357\n",
      "epoch 199; iter: 0; batch classifier loss: 0.045102; batch adversarial loss: 0.411665\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689359; batch adversarial loss: 0.731295\n",
      "epoch 1; iter: 0; batch classifier loss: 0.484161; batch adversarial loss: 0.649104\n",
      "epoch 2; iter: 0; batch classifier loss: 0.393095; batch adversarial loss: 0.590866\n",
      "epoch 3; iter: 0; batch classifier loss: 0.439185; batch adversarial loss: 0.622684\n",
      "epoch 4; iter: 0; batch classifier loss: 0.300019; batch adversarial loss: 0.612084\n",
      "epoch 5; iter: 0; batch classifier loss: 0.332067; batch adversarial loss: 0.556503\n",
      "epoch 6; iter: 0; batch classifier loss: 0.309385; batch adversarial loss: 0.567384\n",
      "epoch 7; iter: 0; batch classifier loss: 0.357540; batch adversarial loss: 0.558572\n",
      "epoch 8; iter: 0; batch classifier loss: 0.309704; batch adversarial loss: 0.608252\n",
      "epoch 9; iter: 0; batch classifier loss: 0.338888; batch adversarial loss: 0.563619\n",
      "epoch 10; iter: 0; batch classifier loss: 0.240424; batch adversarial loss: 0.495355\n",
      "epoch 11; iter: 0; batch classifier loss: 0.323848; batch adversarial loss: 0.432170\n",
      "epoch 12; iter: 0; batch classifier loss: 0.275483; batch adversarial loss: 0.555239\n",
      "epoch 13; iter: 0; batch classifier loss: 0.257094; batch adversarial loss: 0.506131\n",
      "epoch 14; iter: 0; batch classifier loss: 0.272164; batch adversarial loss: 0.489242\n",
      "epoch 15; iter: 0; batch classifier loss: 0.211186; batch adversarial loss: 0.453867\n",
      "epoch 16; iter: 0; batch classifier loss: 0.210643; batch adversarial loss: 0.477570\n",
      "epoch 17; iter: 0; batch classifier loss: 0.202256; batch adversarial loss: 0.428827\n",
      "epoch 18; iter: 0; batch classifier loss: 0.179427; batch adversarial loss: 0.445393\n",
      "epoch 19; iter: 0; batch classifier loss: 0.208839; batch adversarial loss: 0.474482\n",
      "epoch 20; iter: 0; batch classifier loss: 0.154672; batch adversarial loss: 0.472765\n",
      "epoch 21; iter: 0; batch classifier loss: 0.163795; batch adversarial loss: 0.497756\n",
      "epoch 22; iter: 0; batch classifier loss: 0.233906; batch adversarial loss: 0.461502\n",
      "epoch 23; iter: 0; batch classifier loss: 0.131435; batch adversarial loss: 0.454617\n",
      "epoch 24; iter: 0; batch classifier loss: 0.161281; batch adversarial loss: 0.505512\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179595; batch adversarial loss: 0.377361\n",
      "epoch 26; iter: 0; batch classifier loss: 0.142254; batch adversarial loss: 0.435667\n",
      "epoch 27; iter: 0; batch classifier loss: 0.163507; batch adversarial loss: 0.483474\n",
      "epoch 28; iter: 0; batch classifier loss: 0.132252; batch adversarial loss: 0.461880\n",
      "epoch 29; iter: 0; batch classifier loss: 0.111941; batch adversarial loss: 0.493191\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167385; batch adversarial loss: 0.400972\n",
      "epoch 31; iter: 0; batch classifier loss: 0.158303; batch adversarial loss: 0.475624\n",
      "epoch 32; iter: 0; batch classifier loss: 0.129465; batch adversarial loss: 0.456363\n",
      "epoch 33; iter: 0; batch classifier loss: 0.147336; batch adversarial loss: 0.492279\n",
      "epoch 34; iter: 0; batch classifier loss: 0.105748; batch adversarial loss: 0.436841\n",
      "epoch 35; iter: 0; batch classifier loss: 0.101004; batch adversarial loss: 0.480714\n",
      "epoch 36; iter: 0; batch classifier loss: 0.115216; batch adversarial loss: 0.437376\n",
      "epoch 37; iter: 0; batch classifier loss: 0.130042; batch adversarial loss: 0.433332\n",
      "epoch 38; iter: 0; batch classifier loss: 0.138999; batch adversarial loss: 0.372908\n",
      "epoch 39; iter: 0; batch classifier loss: 0.119652; batch adversarial loss: 0.474250\n",
      "epoch 40; iter: 0; batch classifier loss: 0.187272; batch adversarial loss: 0.425625\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104411; batch adversarial loss: 0.517353\n",
      "epoch 42; iter: 0; batch classifier loss: 0.099567; batch adversarial loss: 0.441810\n",
      "epoch 43; iter: 0; batch classifier loss: 0.185664; batch adversarial loss: 0.457025\n",
      "epoch 44; iter: 0; batch classifier loss: 0.166201; batch adversarial loss: 0.397465\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117861; batch adversarial loss: 0.482215\n",
      "epoch 46; iter: 0; batch classifier loss: 0.164909; batch adversarial loss: 0.419344\n",
      "epoch 47; iter: 0; batch classifier loss: 0.110460; batch adversarial loss: 0.446339\n",
      "epoch 48; iter: 0; batch classifier loss: 0.139124; batch adversarial loss: 0.377582\n",
      "epoch 49; iter: 0; batch classifier loss: 0.103218; batch adversarial loss: 0.300706\n",
      "epoch 50; iter: 0; batch classifier loss: 0.051678; batch adversarial loss: 0.430917\n",
      "epoch 51; iter: 0; batch classifier loss: 0.102020; batch adversarial loss: 0.376762\n",
      "epoch 52; iter: 0; batch classifier loss: 0.147143; batch adversarial loss: 0.464641\n",
      "epoch 53; iter: 0; batch classifier loss: 0.059388; batch adversarial loss: 0.411313\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097841; batch adversarial loss: 0.477254\n",
      "epoch 55; iter: 0; batch classifier loss: 0.045049; batch adversarial loss: 0.521735\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101803; batch adversarial loss: 0.430921\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061087; batch adversarial loss: 0.435359\n",
      "epoch 58; iter: 0; batch classifier loss: 0.081420; batch adversarial loss: 0.362706\n",
      "epoch 59; iter: 0; batch classifier loss: 0.154144; batch adversarial loss: 0.445479\n",
      "epoch 60; iter: 0; batch classifier loss: 0.045340; batch adversarial loss: 0.463874\n",
      "epoch 61; iter: 0; batch classifier loss: 0.042866; batch adversarial loss: 0.496266\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094586; batch adversarial loss: 0.387373\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078907; batch adversarial loss: 0.419570\n",
      "epoch 64; iter: 0; batch classifier loss: 0.075218; batch adversarial loss: 0.415435\n",
      "epoch 65; iter: 0; batch classifier loss: 0.124976; batch adversarial loss: 0.434147\n",
      "epoch 66; iter: 0; batch classifier loss: 0.082536; batch adversarial loss: 0.434688\n",
      "epoch 67; iter: 0; batch classifier loss: 0.071665; batch adversarial loss: 0.436070\n",
      "epoch 68; iter: 0; batch classifier loss: 0.058840; batch adversarial loss: 0.497006\n",
      "epoch 69; iter: 0; batch classifier loss: 0.097720; batch adversarial loss: 0.472663\n",
      "epoch 70; iter: 0; batch classifier loss: 0.058342; batch adversarial loss: 0.495790\n",
      "epoch 71; iter: 0; batch classifier loss: 0.077873; batch adversarial loss: 0.505330\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100029; batch adversarial loss: 0.416531\n",
      "epoch 73; iter: 0; batch classifier loss: 0.051552; batch adversarial loss: 0.403429\n",
      "epoch 74; iter: 0; batch classifier loss: 0.112308; batch adversarial loss: 0.501693\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076416; batch adversarial loss: 0.510508\n",
      "epoch 76; iter: 0; batch classifier loss: 0.074146; batch adversarial loss: 0.502921\n",
      "epoch 77; iter: 0; batch classifier loss: 0.098131; batch adversarial loss: 0.353699\n",
      "epoch 78; iter: 0; batch classifier loss: 0.103305; batch adversarial loss: 0.359653\n",
      "epoch 79; iter: 0; batch classifier loss: 0.111073; batch adversarial loss: 0.460457\n",
      "epoch 80; iter: 0; batch classifier loss: 0.069610; batch adversarial loss: 0.494552\n",
      "epoch 81; iter: 0; batch classifier loss: 0.104954; batch adversarial loss: 0.425309\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091416; batch adversarial loss: 0.444164\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061812; batch adversarial loss: 0.475111\n",
      "epoch 84; iter: 0; batch classifier loss: 0.084595; batch adversarial loss: 0.437148\n",
      "epoch 85; iter: 0; batch classifier loss: 0.099112; batch adversarial loss: 0.435855\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064690; batch adversarial loss: 0.455746\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054560; batch adversarial loss: 0.513929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.032224; batch adversarial loss: 0.438415\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063920; batch adversarial loss: 0.392830\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057106; batch adversarial loss: 0.428468\n",
      "epoch 91; iter: 0; batch classifier loss: 0.087218; batch adversarial loss: 0.434042\n",
      "epoch 92; iter: 0; batch classifier loss: 0.037802; batch adversarial loss: 0.524711\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065131; batch adversarial loss: 0.383789\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050270; batch adversarial loss: 0.496446\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068466; batch adversarial loss: 0.488437\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042218; batch adversarial loss: 0.332206\n",
      "epoch 97; iter: 0; batch classifier loss: 0.029299; batch adversarial loss: 0.509473\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079960; batch adversarial loss: 0.489374\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063153; batch adversarial loss: 0.440610\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035189; batch adversarial loss: 0.494586\n",
      "epoch 101; iter: 0; batch classifier loss: 0.059614; batch adversarial loss: 0.505150\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057021; batch adversarial loss: 0.319505\n",
      "epoch 103; iter: 0; batch classifier loss: 0.019753; batch adversarial loss: 0.459966\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036301; batch adversarial loss: 0.422205\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061052; batch adversarial loss: 0.478871\n",
      "epoch 106; iter: 0; batch classifier loss: 0.029023; batch adversarial loss: 0.396294\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066710; batch adversarial loss: 0.416219\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041824; batch adversarial loss: 0.416590\n",
      "epoch 109; iter: 0; batch classifier loss: 0.090567; batch adversarial loss: 0.499398\n",
      "epoch 110; iter: 0; batch classifier loss: 0.062046; batch adversarial loss: 0.464982\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029536; batch adversarial loss: 0.427194\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045954; batch adversarial loss: 0.355326\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038917; batch adversarial loss: 0.537625\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072058; batch adversarial loss: 0.399655\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039376; batch adversarial loss: 0.481371\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030545; batch adversarial loss: 0.503229\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050892; batch adversarial loss: 0.404141\n",
      "epoch 118; iter: 0; batch classifier loss: 0.038473; batch adversarial loss: 0.402226\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055436; batch adversarial loss: 0.452684\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074803; batch adversarial loss: 0.432493\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065902; batch adversarial loss: 0.361695\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034000; batch adversarial loss: 0.397230\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053535; batch adversarial loss: 0.368695\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027781; batch adversarial loss: 0.552468\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047243; batch adversarial loss: 0.394628\n",
      "epoch 126; iter: 0; batch classifier loss: 0.076787; batch adversarial loss: 0.488680\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050280; batch adversarial loss: 0.368022\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022111; batch adversarial loss: 0.418499\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027527; batch adversarial loss: 0.496295\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021083; batch adversarial loss: 0.516697\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025404; batch adversarial loss: 0.478368\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033308; batch adversarial loss: 0.520223\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037284; batch adversarial loss: 0.420739\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015624; batch adversarial loss: 0.384567\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047344; batch adversarial loss: 0.388709\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032068; batch adversarial loss: 0.402306\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046972; batch adversarial loss: 0.503609\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035919; batch adversarial loss: 0.389829\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046194; batch adversarial loss: 0.444556\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014264; batch adversarial loss: 0.414663\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018819; batch adversarial loss: 0.453088\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027246; batch adversarial loss: 0.397972\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043124; batch adversarial loss: 0.446534\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030764; batch adversarial loss: 0.496724\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043746; batch adversarial loss: 0.450394\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031583; batch adversarial loss: 0.393474\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031725; batch adversarial loss: 0.476976\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012317; batch adversarial loss: 0.460042\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038810; batch adversarial loss: 0.469735\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044310; batch adversarial loss: 0.477997\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039006; batch adversarial loss: 0.371983\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032662; batch adversarial loss: 0.469170\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015242; batch adversarial loss: 0.451466\n",
      "epoch 154; iter: 0; batch classifier loss: 0.009182; batch adversarial loss: 0.511642\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040362; batch adversarial loss: 0.425326\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032027; batch adversarial loss: 0.463745\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034848; batch adversarial loss: 0.491284\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020664; batch adversarial loss: 0.411709\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024688; batch adversarial loss: 0.362039\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022626; batch adversarial loss: 0.421391\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022650; batch adversarial loss: 0.468925\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033404; batch adversarial loss: 0.408936\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018914; batch adversarial loss: 0.392583\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014948; batch adversarial loss: 0.508647\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011298; batch adversarial loss: 0.503117\n",
      "epoch 166; iter: 0; batch classifier loss: 0.008934; batch adversarial loss: 0.466169\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012756; batch adversarial loss: 0.434493\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037825; batch adversarial loss: 0.398545\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023196; batch adversarial loss: 0.435195\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007966; batch adversarial loss: 0.377620\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017593; batch adversarial loss: 0.456677\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018653; batch adversarial loss: 0.402294\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034014; batch adversarial loss: 0.477734\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020811; batch adversarial loss: 0.426060\n",
      "epoch 175; iter: 0; batch classifier loss: 0.005136; batch adversarial loss: 0.450985\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026529; batch adversarial loss: 0.454892\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026635; batch adversarial loss: 0.516229\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031555; batch adversarial loss: 0.464797\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013951; batch adversarial loss: 0.499867\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009630; batch adversarial loss: 0.417075\n",
      "epoch 181; iter: 0; batch classifier loss: 0.005685; batch adversarial loss: 0.459931\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017401; batch adversarial loss: 0.499820\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027992; batch adversarial loss: 0.392246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.009406; batch adversarial loss: 0.452690\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025291; batch adversarial loss: 0.430701\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040125; batch adversarial loss: 0.439674\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009714; batch adversarial loss: 0.460847\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021273; batch adversarial loss: 0.420916\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021334; batch adversarial loss: 0.299718\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031460; batch adversarial loss: 0.349764\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010101; batch adversarial loss: 0.483335\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013380; batch adversarial loss: 0.563977\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012429; batch adversarial loss: 0.443476\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025130; batch adversarial loss: 0.411569\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016702; batch adversarial loss: 0.461346\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030379; batch adversarial loss: 0.375029\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012080; batch adversarial loss: 0.450541\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011483; batch adversarial loss: 0.467913\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013552; batch adversarial loss: 0.525656\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691079; batch adversarial loss: 0.867346\n",
      "epoch 1; iter: 0; batch classifier loss: 0.615666; batch adversarial loss: 0.906848\n",
      "epoch 2; iter: 0; batch classifier loss: 0.766234; batch adversarial loss: 0.879952\n",
      "epoch 3; iter: 0; batch classifier loss: 0.874877; batch adversarial loss: 0.820055\n",
      "epoch 4; iter: 0; batch classifier loss: 0.877647; batch adversarial loss: 0.735718\n",
      "epoch 5; iter: 0; batch classifier loss: 1.062043; batch adversarial loss: 0.675391\n",
      "epoch 6; iter: 0; batch classifier loss: 0.846100; batch adversarial loss: 0.599699\n",
      "epoch 7; iter: 0; batch classifier loss: 0.466749; batch adversarial loss: 0.576843\n",
      "epoch 8; iter: 0; batch classifier loss: 0.293965; batch adversarial loss: 0.577397\n",
      "epoch 9; iter: 0; batch classifier loss: 0.390914; batch adversarial loss: 0.543946\n",
      "epoch 10; iter: 0; batch classifier loss: 0.330845; batch adversarial loss: 0.536304\n",
      "epoch 11; iter: 0; batch classifier loss: 0.322518; batch adversarial loss: 0.541038\n",
      "epoch 12; iter: 0; batch classifier loss: 0.375338; batch adversarial loss: 0.533262\n",
      "epoch 13; iter: 0; batch classifier loss: 0.392190; batch adversarial loss: 0.529752\n",
      "epoch 14; iter: 0; batch classifier loss: 0.340542; batch adversarial loss: 0.451606\n",
      "epoch 15; iter: 0; batch classifier loss: 0.292384; batch adversarial loss: 0.545511\n",
      "epoch 16; iter: 0; batch classifier loss: 0.352645; batch adversarial loss: 0.476475\n",
      "epoch 17; iter: 0; batch classifier loss: 0.352011; batch adversarial loss: 0.484009\n",
      "epoch 18; iter: 0; batch classifier loss: 0.304281; batch adversarial loss: 0.541631\n",
      "epoch 19; iter: 0; batch classifier loss: 0.330120; batch adversarial loss: 0.468666\n",
      "epoch 20; iter: 0; batch classifier loss: 0.265326; batch adversarial loss: 0.459229\n",
      "epoch 21; iter: 0; batch classifier loss: 0.328190; batch adversarial loss: 0.455586\n",
      "epoch 22; iter: 0; batch classifier loss: 0.295238; batch adversarial loss: 0.501641\n",
      "epoch 23; iter: 0; batch classifier loss: 0.282311; batch adversarial loss: 0.466833\n",
      "epoch 24; iter: 0; batch classifier loss: 0.300538; batch adversarial loss: 0.498004\n",
      "epoch 25; iter: 0; batch classifier loss: 0.308772; batch adversarial loss: 0.503535\n",
      "epoch 26; iter: 0; batch classifier loss: 0.219909; batch adversarial loss: 0.448637\n",
      "epoch 27; iter: 0; batch classifier loss: 0.333957; batch adversarial loss: 0.435752\n",
      "epoch 28; iter: 0; batch classifier loss: 0.289462; batch adversarial loss: 0.473154\n",
      "epoch 29; iter: 0; batch classifier loss: 0.295532; batch adversarial loss: 0.401971\n",
      "epoch 30; iter: 0; batch classifier loss: 0.217261; batch adversarial loss: 0.510984\n",
      "epoch 31; iter: 0; batch classifier loss: 0.204787; batch adversarial loss: 0.452680\n",
      "epoch 32; iter: 0; batch classifier loss: 0.204619; batch adversarial loss: 0.523467\n",
      "epoch 33; iter: 0; batch classifier loss: 0.275554; batch adversarial loss: 0.509508\n",
      "epoch 34; iter: 0; batch classifier loss: 0.214154; batch adversarial loss: 0.478452\n",
      "epoch 35; iter: 0; batch classifier loss: 0.217437; batch adversarial loss: 0.458956\n",
      "epoch 36; iter: 0; batch classifier loss: 0.278055; batch adversarial loss: 0.396352\n",
      "epoch 37; iter: 0; batch classifier loss: 0.214968; batch adversarial loss: 0.430283\n",
      "epoch 38; iter: 0; batch classifier loss: 0.222484; batch adversarial loss: 0.463116\n",
      "epoch 39; iter: 0; batch classifier loss: 0.269944; batch adversarial loss: 0.483333\n",
      "epoch 40; iter: 0; batch classifier loss: 0.202494; batch adversarial loss: 0.442032\n",
      "epoch 41; iter: 0; batch classifier loss: 0.155728; batch adversarial loss: 0.420401\n",
      "epoch 42; iter: 0; batch classifier loss: 0.179138; batch adversarial loss: 0.458328\n",
      "epoch 43; iter: 0; batch classifier loss: 0.136056; batch adversarial loss: 0.465180\n",
      "epoch 44; iter: 0; batch classifier loss: 0.132580; batch adversarial loss: 0.504753\n",
      "epoch 45; iter: 0; batch classifier loss: 0.142486; batch adversarial loss: 0.415451\n",
      "epoch 46; iter: 0; batch classifier loss: 0.155240; batch adversarial loss: 0.448503\n",
      "epoch 47; iter: 0; batch classifier loss: 0.186793; batch adversarial loss: 0.423782\n",
      "epoch 48; iter: 0; batch classifier loss: 0.152851; batch adversarial loss: 0.450535\n",
      "epoch 49; iter: 0; batch classifier loss: 0.154981; batch adversarial loss: 0.413738\n",
      "epoch 50; iter: 0; batch classifier loss: 0.235633; batch adversarial loss: 0.413561\n",
      "epoch 51; iter: 0; batch classifier loss: 0.226717; batch adversarial loss: 0.352886\n",
      "epoch 52; iter: 0; batch classifier loss: 0.106828; batch adversarial loss: 0.422299\n",
      "epoch 53; iter: 0; batch classifier loss: 0.152564; batch adversarial loss: 0.422418\n",
      "epoch 54; iter: 0; batch classifier loss: 0.126162; batch adversarial loss: 0.463759\n",
      "epoch 55; iter: 0; batch classifier loss: 0.160228; batch adversarial loss: 0.442838\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119422; batch adversarial loss: 0.483297\n",
      "epoch 57; iter: 0; batch classifier loss: 0.141604; batch adversarial loss: 0.522384\n",
      "epoch 58; iter: 0; batch classifier loss: 0.137093; batch adversarial loss: 0.477699\n",
      "epoch 59; iter: 0; batch classifier loss: 0.124710; batch adversarial loss: 0.526570\n",
      "epoch 60; iter: 0; batch classifier loss: 0.144004; batch adversarial loss: 0.442842\n",
      "epoch 61; iter: 0; batch classifier loss: 0.127038; batch adversarial loss: 0.489674\n",
      "epoch 62; iter: 0; batch classifier loss: 0.122164; batch adversarial loss: 0.360465\n",
      "epoch 63; iter: 0; batch classifier loss: 0.162063; batch adversarial loss: 0.461462\n",
      "epoch 64; iter: 0; batch classifier loss: 0.126062; batch adversarial loss: 0.483283\n",
      "epoch 65; iter: 0; batch classifier loss: 0.109675; batch adversarial loss: 0.429838\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088182; batch adversarial loss: 0.469803\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098850; batch adversarial loss: 0.502390\n",
      "epoch 68; iter: 0; batch classifier loss: 0.151762; batch adversarial loss: 0.515190\n",
      "epoch 69; iter: 0; batch classifier loss: 0.092667; batch adversarial loss: 0.559760\n",
      "epoch 70; iter: 0; batch classifier loss: 0.151508; batch adversarial loss: 0.416653\n",
      "epoch 71; iter: 0; batch classifier loss: 0.086831; batch adversarial loss: 0.425752\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077136; batch adversarial loss: 0.517771\n",
      "epoch 73; iter: 0; batch classifier loss: 0.129416; batch adversarial loss: 0.452824\n",
      "epoch 74; iter: 0; batch classifier loss: 0.143308; batch adversarial loss: 0.461660\n",
      "epoch 75; iter: 0; batch classifier loss: 0.087740; batch adversarial loss: 0.485017\n",
      "epoch 76; iter: 0; batch classifier loss: 0.084953; batch adversarial loss: 0.379878\n",
      "epoch 77; iter: 0; batch classifier loss: 0.143589; batch adversarial loss: 0.438408\n",
      "epoch 78; iter: 0; batch classifier loss: 0.170323; batch adversarial loss: 0.430523\n",
      "epoch 79; iter: 0; batch classifier loss: 0.084287; batch adversarial loss: 0.505478\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083151; batch adversarial loss: 0.405192\n",
      "epoch 81; iter: 0; batch classifier loss: 0.126093; batch adversarial loss: 0.444054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.085229; batch adversarial loss: 0.574677\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114386; batch adversarial loss: 0.392265\n",
      "epoch 84; iter: 0; batch classifier loss: 0.107026; batch adversarial loss: 0.412155\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076337; batch adversarial loss: 0.458262\n",
      "epoch 86; iter: 0; batch classifier loss: 0.110026; batch adversarial loss: 0.540982\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064129; batch adversarial loss: 0.456173\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075054; batch adversarial loss: 0.354765\n",
      "epoch 89; iter: 0; batch classifier loss: 0.143883; batch adversarial loss: 0.470536\n",
      "epoch 90; iter: 0; batch classifier loss: 0.081602; batch adversarial loss: 0.505256\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056766; batch adversarial loss: 0.392087\n",
      "epoch 92; iter: 0; batch classifier loss: 0.073813; batch adversarial loss: 0.394413\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062434; batch adversarial loss: 0.425000\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067258; batch adversarial loss: 0.600957\n",
      "epoch 95; iter: 0; batch classifier loss: 0.100237; batch adversarial loss: 0.480339\n",
      "epoch 96; iter: 0; batch classifier loss: 0.052338; batch adversarial loss: 0.388810\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044267; batch adversarial loss: 0.500139\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044546; batch adversarial loss: 0.486793\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037741; batch adversarial loss: 0.429219\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034345; batch adversarial loss: 0.400204\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062525; batch adversarial loss: 0.496257\n",
      "epoch 102; iter: 0; batch classifier loss: 0.015948; batch adversarial loss: 0.480473\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047963; batch adversarial loss: 0.476559\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066362; batch adversarial loss: 0.541385\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045725; batch adversarial loss: 0.491004\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052281; batch adversarial loss: 0.416534\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024607; batch adversarial loss: 0.564334\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040574; batch adversarial loss: 0.435556\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043875; batch adversarial loss: 0.506273\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049439; batch adversarial loss: 0.414345\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032998; batch adversarial loss: 0.490974\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033416; batch adversarial loss: 0.477599\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071743; batch adversarial loss: 0.469092\n",
      "epoch 114; iter: 0; batch classifier loss: 0.067943; batch adversarial loss: 0.455478\n",
      "epoch 115; iter: 0; batch classifier loss: 0.025181; batch adversarial loss: 0.454295\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051165; batch adversarial loss: 0.488931\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028058; batch adversarial loss: 0.451475\n",
      "epoch 118; iter: 0; batch classifier loss: 0.020332; batch adversarial loss: 0.526447\n",
      "epoch 119; iter: 0; batch classifier loss: 0.016486; batch adversarial loss: 0.443680\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037286; batch adversarial loss: 0.449048\n",
      "epoch 121; iter: 0; batch classifier loss: 0.013287; batch adversarial loss: 0.422708\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029630; batch adversarial loss: 0.432090\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030109; batch adversarial loss: 0.414795\n",
      "epoch 124; iter: 0; batch classifier loss: 0.008599; batch adversarial loss: 0.442934\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035784; batch adversarial loss: 0.528751\n",
      "epoch 126; iter: 0; batch classifier loss: 0.008846; batch adversarial loss: 0.453904\n",
      "epoch 127; iter: 0; batch classifier loss: 0.014176; batch adversarial loss: 0.411839\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043272; batch adversarial loss: 0.542227\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021999; batch adversarial loss: 0.428635\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030925; batch adversarial loss: 0.501670\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029847; batch adversarial loss: 0.408643\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020696; batch adversarial loss: 0.523605\n",
      "epoch 133; iter: 0; batch classifier loss: 0.050396; batch adversarial loss: 0.574646\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029659; batch adversarial loss: 0.537897\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035674; batch adversarial loss: 0.466676\n",
      "epoch 136; iter: 0; batch classifier loss: 0.063223; batch adversarial loss: 0.504114\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017854; batch adversarial loss: 0.494974\n",
      "epoch 138; iter: 0; batch classifier loss: 0.009385; batch adversarial loss: 0.364607\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014901; batch adversarial loss: 0.406147\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044789; batch adversarial loss: 0.397843\n",
      "epoch 141; iter: 0; batch classifier loss: 0.008774; batch adversarial loss: 0.518628\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027206; batch adversarial loss: 0.413178\n",
      "epoch 143; iter: 0; batch classifier loss: 0.008024; batch adversarial loss: 0.387802\n",
      "epoch 144; iter: 0; batch classifier loss: 0.010738; batch adversarial loss: 0.467109\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024387; batch adversarial loss: 0.523034\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022218; batch adversarial loss: 0.456669\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017193; batch adversarial loss: 0.402065\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015436; batch adversarial loss: 0.401332\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016700; batch adversarial loss: 0.433926\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014476; batch adversarial loss: 0.468690\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041110; batch adversarial loss: 0.415047\n",
      "epoch 152; iter: 0; batch classifier loss: 0.009871; batch adversarial loss: 0.477310\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026951; batch adversarial loss: 0.423542\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052726; batch adversarial loss: 0.493693\n",
      "epoch 155; iter: 0; batch classifier loss: 0.006256; batch adversarial loss: 0.512925\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018996; batch adversarial loss: 0.467165\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023784; batch adversarial loss: 0.416848\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037586; batch adversarial loss: 0.455249\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012494; batch adversarial loss: 0.477050\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018919; batch adversarial loss: 0.468832\n",
      "epoch 161; iter: 0; batch classifier loss: 0.002433; batch adversarial loss: 0.487578\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017838; batch adversarial loss: 0.387275\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018352; batch adversarial loss: 0.447309\n",
      "epoch 164; iter: 0; batch classifier loss: 0.007307; batch adversarial loss: 0.381511\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014131; batch adversarial loss: 0.431978\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030870; batch adversarial loss: 0.490179\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016748; batch adversarial loss: 0.516016\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023841; batch adversarial loss: 0.448648\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020138; batch adversarial loss: 0.489755\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018793; batch adversarial loss: 0.465156\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030564; batch adversarial loss: 0.469503\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015883; batch adversarial loss: 0.487214\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010402; batch adversarial loss: 0.483262\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012679; batch adversarial loss: 0.487486\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028928; batch adversarial loss: 0.595199\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013246; batch adversarial loss: 0.466819\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018251; batch adversarial loss: 0.589605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.007136; batch adversarial loss: 0.399210\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011630; batch adversarial loss: 0.498863\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017981; batch adversarial loss: 0.399922\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007590; batch adversarial loss: 0.483374\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006170; batch adversarial loss: 0.431421\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006987; batch adversarial loss: 0.456035\n",
      "epoch 184; iter: 0; batch classifier loss: 0.005901; batch adversarial loss: 0.474916\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014243; batch adversarial loss: 0.489927\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012209; batch adversarial loss: 0.404547\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035231; batch adversarial loss: 0.409754\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024932; batch adversarial loss: 0.447653\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021073; batch adversarial loss: 0.362358\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011302; batch adversarial loss: 0.426725\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016073; batch adversarial loss: 0.402506\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028596; batch adversarial loss: 0.471652\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013218; batch adversarial loss: 0.462727\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007728; batch adversarial loss: 0.503883\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012461; batch adversarial loss: 0.472187\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009235; batch adversarial loss: 0.514525\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004930; batch adversarial loss: 0.351983\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004239; batch adversarial loss: 0.527869\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025683; batch adversarial loss: 0.405539\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687032; batch adversarial loss: 0.713160\n",
      "epoch 1; iter: 0; batch classifier loss: 0.519448; batch adversarial loss: 0.695179\n",
      "epoch 2; iter: 0; batch classifier loss: 0.403298; batch adversarial loss: 0.652356\n",
      "epoch 3; iter: 0; batch classifier loss: 0.384439; batch adversarial loss: 0.641180\n",
      "epoch 4; iter: 0; batch classifier loss: 0.371047; batch adversarial loss: 0.578737\n",
      "epoch 5; iter: 0; batch classifier loss: 0.256245; batch adversarial loss: 0.566488\n",
      "epoch 6; iter: 0; batch classifier loss: 0.311761; batch adversarial loss: 0.528790\n",
      "epoch 7; iter: 0; batch classifier loss: 0.274329; batch adversarial loss: 0.507006\n",
      "epoch 8; iter: 0; batch classifier loss: 0.226163; batch adversarial loss: 0.562653\n",
      "epoch 9; iter: 0; batch classifier loss: 0.199224; batch adversarial loss: 0.497821\n",
      "epoch 10; iter: 0; batch classifier loss: 0.293414; batch adversarial loss: 0.530949\n",
      "epoch 11; iter: 0; batch classifier loss: 0.164981; batch adversarial loss: 0.490684\n",
      "epoch 12; iter: 0; batch classifier loss: 0.218592; batch adversarial loss: 0.498891\n",
      "epoch 13; iter: 0; batch classifier loss: 0.231620; batch adversarial loss: 0.508943\n",
      "epoch 14; iter: 0; batch classifier loss: 0.143795; batch adversarial loss: 0.511979\n",
      "epoch 15; iter: 0; batch classifier loss: 0.196601; batch adversarial loss: 0.471591\n",
      "epoch 16; iter: 0; batch classifier loss: 0.169360; batch adversarial loss: 0.504735\n",
      "epoch 17; iter: 0; batch classifier loss: 0.197911; batch adversarial loss: 0.447324\n",
      "epoch 18; iter: 0; batch classifier loss: 0.106571; batch adversarial loss: 0.530400\n",
      "epoch 19; iter: 0; batch classifier loss: 0.186995; batch adversarial loss: 0.489055\n",
      "epoch 20; iter: 0; batch classifier loss: 0.129622; batch adversarial loss: 0.512046\n",
      "epoch 21; iter: 0; batch classifier loss: 0.228637; batch adversarial loss: 0.464278\n",
      "epoch 22; iter: 0; batch classifier loss: 0.159414; batch adversarial loss: 0.623110\n",
      "epoch 23; iter: 0; batch classifier loss: 0.145192; batch adversarial loss: 0.524899\n",
      "epoch 24; iter: 0; batch classifier loss: 0.171949; batch adversarial loss: 0.551155\n",
      "epoch 25; iter: 0; batch classifier loss: 0.181072; batch adversarial loss: 0.532428\n",
      "epoch 26; iter: 0; batch classifier loss: 0.190259; batch adversarial loss: 0.470033\n",
      "epoch 27; iter: 0; batch classifier loss: 0.195561; batch adversarial loss: 0.493654\n",
      "epoch 28; iter: 0; batch classifier loss: 0.301678; batch adversarial loss: 0.554139\n",
      "epoch 29; iter: 0; batch classifier loss: 0.269221; batch adversarial loss: 0.386778\n",
      "epoch 30; iter: 0; batch classifier loss: 0.345698; batch adversarial loss: 0.485254\n",
      "epoch 31; iter: 0; batch classifier loss: 0.350608; batch adversarial loss: 0.461109\n",
      "epoch 32; iter: 0; batch classifier loss: 0.145777; batch adversarial loss: 0.466056\n",
      "epoch 33; iter: 0; batch classifier loss: 0.118770; batch adversarial loss: 0.369048\n",
      "epoch 34; iter: 0; batch classifier loss: 0.098346; batch adversarial loss: 0.493230\n",
      "epoch 35; iter: 0; batch classifier loss: 0.074926; batch adversarial loss: 0.387775\n",
      "epoch 36; iter: 0; batch classifier loss: 0.108065; batch adversarial loss: 0.637114\n",
      "epoch 37; iter: 0; batch classifier loss: 0.108936; batch adversarial loss: 0.395538\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127822; batch adversarial loss: 0.515430\n",
      "epoch 39; iter: 0; batch classifier loss: 0.104007; batch adversarial loss: 0.392215\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124801; batch adversarial loss: 0.464105\n",
      "epoch 41; iter: 0; batch classifier loss: 0.078764; batch adversarial loss: 0.444440\n",
      "epoch 42; iter: 0; batch classifier loss: 0.090055; batch adversarial loss: 0.520869\n",
      "epoch 43; iter: 0; batch classifier loss: 0.051336; batch adversarial loss: 0.507814\n",
      "epoch 44; iter: 0; batch classifier loss: 0.075497; batch adversarial loss: 0.502016\n",
      "epoch 45; iter: 0; batch classifier loss: 0.069361; batch adversarial loss: 0.526271\n",
      "epoch 46; iter: 0; batch classifier loss: 0.061696; batch adversarial loss: 0.455369\n",
      "epoch 47; iter: 0; batch classifier loss: 0.109942; batch adversarial loss: 0.460726\n",
      "epoch 48; iter: 0; batch classifier loss: 0.091737; batch adversarial loss: 0.440028\n",
      "epoch 49; iter: 0; batch classifier loss: 0.103753; batch adversarial loss: 0.429201\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108211; batch adversarial loss: 0.447082\n",
      "epoch 51; iter: 0; batch classifier loss: 0.050895; batch adversarial loss: 0.409012\n",
      "epoch 52; iter: 0; batch classifier loss: 0.092595; batch adversarial loss: 0.395821\n",
      "epoch 53; iter: 0; batch classifier loss: 0.066155; batch adversarial loss: 0.588989\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079896; batch adversarial loss: 0.441712\n",
      "epoch 55; iter: 0; batch classifier loss: 0.070467; batch adversarial loss: 0.438215\n",
      "epoch 56; iter: 0; batch classifier loss: 0.091010; batch adversarial loss: 0.528278\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061512; batch adversarial loss: 0.442985\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090374; batch adversarial loss: 0.493360\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076866; batch adversarial loss: 0.395121\n",
      "epoch 60; iter: 0; batch classifier loss: 0.059079; batch adversarial loss: 0.501111\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071226; batch adversarial loss: 0.393808\n",
      "epoch 62; iter: 0; batch classifier loss: 0.056942; batch adversarial loss: 0.534911\n",
      "epoch 63; iter: 0; batch classifier loss: 0.048207; batch adversarial loss: 0.443075\n",
      "epoch 64; iter: 0; batch classifier loss: 0.043830; batch adversarial loss: 0.424286\n",
      "epoch 65; iter: 0; batch classifier loss: 0.062394; batch adversarial loss: 0.430522\n",
      "epoch 66; iter: 0; batch classifier loss: 0.061378; batch adversarial loss: 0.465122\n",
      "epoch 67; iter: 0; batch classifier loss: 0.074141; batch adversarial loss: 0.545771\n",
      "epoch 68; iter: 0; batch classifier loss: 0.097494; batch adversarial loss: 0.510450\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082810; batch adversarial loss: 0.460778\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067833; batch adversarial loss: 0.479260\n",
      "epoch 71; iter: 0; batch classifier loss: 0.053442; batch adversarial loss: 0.405285\n",
      "epoch 72; iter: 0; batch classifier loss: 0.021035; batch adversarial loss: 0.542044\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079828; batch adversarial loss: 0.450067\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066783; batch adversarial loss: 0.491486\n",
      "epoch 75; iter: 0; batch classifier loss: 0.084067; batch adversarial loss: 0.536016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.063834; batch adversarial loss: 0.562388\n",
      "epoch 77; iter: 0; batch classifier loss: 0.081519; batch adversarial loss: 0.425616\n",
      "epoch 78; iter: 0; batch classifier loss: 0.104886; batch adversarial loss: 0.453409\n",
      "epoch 79; iter: 0; batch classifier loss: 0.031296; batch adversarial loss: 0.420029\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060738; batch adversarial loss: 0.454567\n",
      "epoch 81; iter: 0; batch classifier loss: 0.035891; batch adversarial loss: 0.486849\n",
      "epoch 82; iter: 0; batch classifier loss: 0.087857; batch adversarial loss: 0.434096\n",
      "epoch 83; iter: 0; batch classifier loss: 0.055250; batch adversarial loss: 0.456132\n",
      "epoch 84; iter: 0; batch classifier loss: 0.078967; batch adversarial loss: 0.442420\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046173; batch adversarial loss: 0.373731\n",
      "epoch 86; iter: 0; batch classifier loss: 0.094519; batch adversarial loss: 0.502865\n",
      "epoch 87; iter: 0; batch classifier loss: 0.032844; batch adversarial loss: 0.449638\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050353; batch adversarial loss: 0.492005\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060539; batch adversarial loss: 0.429985\n",
      "epoch 90; iter: 0; batch classifier loss: 0.069560; batch adversarial loss: 0.412011\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068776; batch adversarial loss: 0.427232\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050655; batch adversarial loss: 0.505726\n",
      "epoch 93; iter: 0; batch classifier loss: 0.030027; batch adversarial loss: 0.466951\n",
      "epoch 94; iter: 0; batch classifier loss: 0.069083; batch adversarial loss: 0.450905\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077550; batch adversarial loss: 0.469661\n",
      "epoch 96; iter: 0; batch classifier loss: 0.029905; batch adversarial loss: 0.491017\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048087; batch adversarial loss: 0.509288\n",
      "epoch 98; iter: 0; batch classifier loss: 0.068852; batch adversarial loss: 0.407673\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052414; batch adversarial loss: 0.488312\n",
      "epoch 100; iter: 0; batch classifier loss: 0.052836; batch adversarial loss: 0.472715\n",
      "epoch 101; iter: 0; batch classifier loss: 0.027035; batch adversarial loss: 0.453517\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046348; batch adversarial loss: 0.431657\n",
      "epoch 103; iter: 0; batch classifier loss: 0.034719; batch adversarial loss: 0.373789\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069370; batch adversarial loss: 0.296140\n",
      "epoch 105; iter: 0; batch classifier loss: 0.070240; batch adversarial loss: 0.463097\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045398; batch adversarial loss: 0.511053\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044126; batch adversarial loss: 0.458704\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030014; batch adversarial loss: 0.464379\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044641; batch adversarial loss: 0.501151\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033608; batch adversarial loss: 0.461270\n",
      "epoch 111; iter: 0; batch classifier loss: 0.011126; batch adversarial loss: 0.456275\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031488; batch adversarial loss: 0.445800\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028464; batch adversarial loss: 0.395966\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030780; batch adversarial loss: 0.404015\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033808; batch adversarial loss: 0.418910\n",
      "epoch 116; iter: 0; batch classifier loss: 0.065030; batch adversarial loss: 0.449221\n",
      "epoch 117; iter: 0; batch classifier loss: 0.084945; batch adversarial loss: 0.441042\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032395; batch adversarial loss: 0.525390\n",
      "epoch 119; iter: 0; batch classifier loss: 0.012025; batch adversarial loss: 0.405954\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025099; batch adversarial loss: 0.420875\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039756; batch adversarial loss: 0.480560\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041385; batch adversarial loss: 0.455336\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031956; batch adversarial loss: 0.453564\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022259; batch adversarial loss: 0.389609\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030127; batch adversarial loss: 0.441330\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034441; batch adversarial loss: 0.422702\n",
      "epoch 127; iter: 0; batch classifier loss: 0.016006; batch adversarial loss: 0.427034\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044809; batch adversarial loss: 0.421582\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032644; batch adversarial loss: 0.508103\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039394; batch adversarial loss: 0.523151\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021402; batch adversarial loss: 0.483703\n",
      "epoch 132; iter: 0; batch classifier loss: 0.054887; batch adversarial loss: 0.507828\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014506; batch adversarial loss: 0.432888\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031147; batch adversarial loss: 0.519101\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020181; batch adversarial loss: 0.400909\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024905; batch adversarial loss: 0.520463\n",
      "epoch 137; iter: 0; batch classifier loss: 0.063451; batch adversarial loss: 0.489943\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023238; batch adversarial loss: 0.525285\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031409; batch adversarial loss: 0.378059\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017097; batch adversarial loss: 0.475696\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022010; batch adversarial loss: 0.544652\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036651; batch adversarial loss: 0.505468\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022861; batch adversarial loss: 0.480635\n",
      "epoch 144; iter: 0; batch classifier loss: 0.011848; batch adversarial loss: 0.351360\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032337; batch adversarial loss: 0.428928\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022581; batch adversarial loss: 0.459782\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036896; batch adversarial loss: 0.424048\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043991; batch adversarial loss: 0.361935\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036334; batch adversarial loss: 0.520186\n",
      "epoch 150; iter: 0; batch classifier loss: 0.050359; batch adversarial loss: 0.525487\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038166; batch adversarial loss: 0.438363\n",
      "epoch 152; iter: 0; batch classifier loss: 0.050804; batch adversarial loss: 0.471431\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036824; batch adversarial loss: 0.466990\n",
      "epoch 154; iter: 0; batch classifier loss: 0.060860; batch adversarial loss: 0.515325\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024753; batch adversarial loss: 0.443850\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016515; batch adversarial loss: 0.557582\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011626; batch adversarial loss: 0.452466\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044191; batch adversarial loss: 0.480586\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018569; batch adversarial loss: 0.464460\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012900; batch adversarial loss: 0.471420\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014590; batch adversarial loss: 0.458446\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052424; batch adversarial loss: 0.428225\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036688; batch adversarial loss: 0.387687\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019186; batch adversarial loss: 0.450309\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033345; batch adversarial loss: 0.415788\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023563; batch adversarial loss: 0.456767\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032136; batch adversarial loss: 0.512613\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038207; batch adversarial loss: 0.437112\n",
      "epoch 169; iter: 0; batch classifier loss: 0.005329; batch adversarial loss: 0.415375\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023573; batch adversarial loss: 0.445484\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009456; batch adversarial loss: 0.500481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.010986; batch adversarial loss: 0.481869\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021787; batch adversarial loss: 0.420017\n",
      "epoch 174; iter: 0; batch classifier loss: 0.005665; batch adversarial loss: 0.502986\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006394; batch adversarial loss: 0.456735\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017035; batch adversarial loss: 0.378355\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023046; batch adversarial loss: 0.532023\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007094; batch adversarial loss: 0.407795\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044743; batch adversarial loss: 0.336373\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016038; batch adversarial loss: 0.501712\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033476; batch adversarial loss: 0.494301\n",
      "epoch 182; iter: 0; batch classifier loss: 0.035043; batch adversarial loss: 0.386958\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014231; batch adversarial loss: 0.516097\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009668; batch adversarial loss: 0.381309\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006039; batch adversarial loss: 0.521727\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019505; batch adversarial loss: 0.506963\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012546; batch adversarial loss: 0.411405\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028821; batch adversarial loss: 0.544642\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029824; batch adversarial loss: 0.497966\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011269; batch adversarial loss: 0.540148\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021797; batch adversarial loss: 0.430342\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013308; batch adversarial loss: 0.390198\n",
      "epoch 193; iter: 0; batch classifier loss: 0.040230; batch adversarial loss: 0.522492\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031222; batch adversarial loss: 0.483026\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024726; batch adversarial loss: 0.476003\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020529; batch adversarial loss: 0.388696\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012570; batch adversarial loss: 0.432302\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002770; batch adversarial loss: 0.461851\n",
      "epoch 199; iter: 0; batch classifier loss: 0.003001; batch adversarial loss: 0.532053\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694759; batch adversarial loss: 0.572302\n",
      "epoch 1; iter: 0; batch classifier loss: 0.439428; batch adversarial loss: 0.600576\n",
      "epoch 2; iter: 0; batch classifier loss: 0.399734; batch adversarial loss: 0.575336\n",
      "epoch 3; iter: 0; batch classifier loss: 0.355594; batch adversarial loss: 0.545250\n",
      "epoch 4; iter: 0; batch classifier loss: 0.325075; batch adversarial loss: 0.565485\n",
      "epoch 5; iter: 0; batch classifier loss: 0.370845; batch adversarial loss: 0.608928\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322860; batch adversarial loss: 0.570689\n",
      "epoch 7; iter: 0; batch classifier loss: 0.361185; batch adversarial loss: 0.594627\n",
      "epoch 8; iter: 0; batch classifier loss: 0.340369; batch adversarial loss: 0.603601\n",
      "epoch 9; iter: 0; batch classifier loss: 0.437717; batch adversarial loss: 0.533614\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558230; batch adversarial loss: 0.525998\n",
      "epoch 11; iter: 0; batch classifier loss: 0.480186; batch adversarial loss: 0.518286\n",
      "epoch 12; iter: 0; batch classifier loss: 0.468087; batch adversarial loss: 0.530158\n",
      "epoch 13; iter: 0; batch classifier loss: 0.328195; batch adversarial loss: 0.518215\n",
      "epoch 14; iter: 0; batch classifier loss: 0.351475; batch adversarial loss: 0.459628\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289217; batch adversarial loss: 0.519231\n",
      "epoch 16; iter: 0; batch classifier loss: 0.298938; batch adversarial loss: 0.462390\n",
      "epoch 17; iter: 0; batch classifier loss: 0.247616; batch adversarial loss: 0.474157\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246923; batch adversarial loss: 0.490497\n",
      "epoch 19; iter: 0; batch classifier loss: 0.161905; batch adversarial loss: 0.464678\n",
      "epoch 20; iter: 0; batch classifier loss: 0.214336; batch adversarial loss: 0.416342\n",
      "epoch 21; iter: 0; batch classifier loss: 0.265114; batch adversarial loss: 0.457192\n",
      "epoch 22; iter: 0; batch classifier loss: 0.147546; batch adversarial loss: 0.534692\n",
      "epoch 23; iter: 0; batch classifier loss: 0.244544; batch adversarial loss: 0.503364\n",
      "epoch 24; iter: 0; batch classifier loss: 0.139594; batch adversarial loss: 0.436795\n",
      "epoch 25; iter: 0; batch classifier loss: 0.145444; batch adversarial loss: 0.501218\n",
      "epoch 26; iter: 0; batch classifier loss: 0.134348; batch adversarial loss: 0.493485\n",
      "epoch 27; iter: 0; batch classifier loss: 0.167654; batch adversarial loss: 0.473935\n",
      "epoch 28; iter: 0; batch classifier loss: 0.161167; batch adversarial loss: 0.495861\n",
      "epoch 29; iter: 0; batch classifier loss: 0.144354; batch adversarial loss: 0.451566\n",
      "epoch 30; iter: 0; batch classifier loss: 0.148194; batch adversarial loss: 0.497880\n",
      "epoch 31; iter: 0; batch classifier loss: 0.160819; batch adversarial loss: 0.474759\n",
      "epoch 32; iter: 0; batch classifier loss: 0.133708; batch adversarial loss: 0.518944\n",
      "epoch 33; iter: 0; batch classifier loss: 0.184933; batch adversarial loss: 0.359901\n",
      "epoch 34; iter: 0; batch classifier loss: 0.144985; batch adversarial loss: 0.491969\n",
      "epoch 35; iter: 0; batch classifier loss: 0.132678; batch adversarial loss: 0.514010\n",
      "epoch 36; iter: 0; batch classifier loss: 0.134251; batch adversarial loss: 0.368280\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145471; batch adversarial loss: 0.501040\n",
      "epoch 38; iter: 0; batch classifier loss: 0.112880; batch adversarial loss: 0.509552\n",
      "epoch 39; iter: 0; batch classifier loss: 0.094097; batch adversarial loss: 0.548506\n",
      "epoch 40; iter: 0; batch classifier loss: 0.176542; batch adversarial loss: 0.443404\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109525; batch adversarial loss: 0.450951\n",
      "epoch 42; iter: 0; batch classifier loss: 0.155729; batch adversarial loss: 0.533281\n",
      "epoch 43; iter: 0; batch classifier loss: 0.130775; batch adversarial loss: 0.491957\n",
      "epoch 44; iter: 0; batch classifier loss: 0.166026; batch adversarial loss: 0.459150\n",
      "epoch 45; iter: 0; batch classifier loss: 0.105617; batch adversarial loss: 0.497908\n",
      "epoch 46; iter: 0; batch classifier loss: 0.182614; batch adversarial loss: 0.390427\n",
      "epoch 47; iter: 0; batch classifier loss: 0.135480; batch adversarial loss: 0.539897\n",
      "epoch 48; iter: 0; batch classifier loss: 0.127622; batch adversarial loss: 0.388048\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119538; batch adversarial loss: 0.378807\n",
      "epoch 50; iter: 0; batch classifier loss: 0.123542; batch adversarial loss: 0.500087\n",
      "epoch 51; iter: 0; batch classifier loss: 0.180887; batch adversarial loss: 0.493083\n",
      "epoch 52; iter: 0; batch classifier loss: 0.113932; batch adversarial loss: 0.443139\n",
      "epoch 53; iter: 0; batch classifier loss: 0.221844; batch adversarial loss: 0.476863\n",
      "epoch 54; iter: 0; batch classifier loss: 0.149621; batch adversarial loss: 0.456414\n",
      "epoch 55; iter: 0; batch classifier loss: 0.206166; batch adversarial loss: 0.436531\n",
      "epoch 56; iter: 0; batch classifier loss: 0.168968; batch adversarial loss: 0.503916\n",
      "epoch 57; iter: 0; batch classifier loss: 0.140128; batch adversarial loss: 0.495077\n",
      "epoch 58; iter: 0; batch classifier loss: 0.117983; batch adversarial loss: 0.563675\n",
      "epoch 59; iter: 0; batch classifier loss: 0.139381; batch adversarial loss: 0.415688\n",
      "epoch 60; iter: 0; batch classifier loss: 0.091687; batch adversarial loss: 0.464404\n",
      "epoch 61; iter: 0; batch classifier loss: 0.118368; batch adversarial loss: 0.506444\n",
      "epoch 62; iter: 0; batch classifier loss: 0.241601; batch adversarial loss: 0.420952\n",
      "epoch 63; iter: 0; batch classifier loss: 0.169279; batch adversarial loss: 0.463788\n",
      "epoch 64; iter: 0; batch classifier loss: 0.165414; batch adversarial loss: 0.421926\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122527; batch adversarial loss: 0.409165\n",
      "epoch 66; iter: 0; batch classifier loss: 0.215736; batch adversarial loss: 0.509152\n",
      "epoch 67; iter: 0; batch classifier loss: 0.179051; batch adversarial loss: 0.409507\n",
      "epoch 68; iter: 0; batch classifier loss: 0.151281; batch adversarial loss: 0.518049\n",
      "epoch 69; iter: 0; batch classifier loss: 0.167397; batch adversarial loss: 0.517772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.134343; batch adversarial loss: 0.457831\n",
      "epoch 71; iter: 0; batch classifier loss: 0.206326; batch adversarial loss: 0.532587\n",
      "epoch 72; iter: 0; batch classifier loss: 0.177912; batch adversarial loss: 0.666782\n",
      "epoch 73; iter: 0; batch classifier loss: 0.139751; batch adversarial loss: 0.532216\n",
      "epoch 74; iter: 0; batch classifier loss: 0.170182; batch adversarial loss: 0.518794\n",
      "epoch 75; iter: 0; batch classifier loss: 0.179223; batch adversarial loss: 0.547541\n",
      "epoch 76; iter: 0; batch classifier loss: 0.198110; batch adversarial loss: 0.438464\n",
      "epoch 77; iter: 0; batch classifier loss: 0.150882; batch adversarial loss: 0.386736\n",
      "epoch 78; iter: 0; batch classifier loss: 0.207824; batch adversarial loss: 0.389288\n",
      "epoch 79; iter: 0; batch classifier loss: 0.202379; batch adversarial loss: 0.511342\n",
      "epoch 80; iter: 0; batch classifier loss: 0.133502; batch adversarial loss: 0.498928\n",
      "epoch 81; iter: 0; batch classifier loss: 0.186011; batch adversarial loss: 0.457091\n",
      "epoch 82; iter: 0; batch classifier loss: 0.229237; batch adversarial loss: 0.525621\n",
      "epoch 83; iter: 0; batch classifier loss: 0.140968; batch adversarial loss: 0.448051\n",
      "epoch 84; iter: 0; batch classifier loss: 0.191430; batch adversarial loss: 0.480565\n",
      "epoch 85; iter: 0; batch classifier loss: 0.153225; batch adversarial loss: 0.552428\n",
      "epoch 86; iter: 0; batch classifier loss: 0.193000; batch adversarial loss: 0.469513\n",
      "epoch 87; iter: 0; batch classifier loss: 0.212338; batch adversarial loss: 0.387171\n",
      "epoch 88; iter: 0; batch classifier loss: 0.183390; batch adversarial loss: 0.574418\n",
      "epoch 89; iter: 0; batch classifier loss: 0.216373; batch adversarial loss: 0.448300\n",
      "epoch 90; iter: 0; batch classifier loss: 0.172042; batch adversarial loss: 0.469599\n",
      "epoch 91; iter: 0; batch classifier loss: 0.144226; batch adversarial loss: 0.480984\n",
      "epoch 92; iter: 0; batch classifier loss: 0.156002; batch adversarial loss: 0.483988\n",
      "epoch 93; iter: 0; batch classifier loss: 0.221336; batch adversarial loss: 0.458700\n",
      "epoch 94; iter: 0; batch classifier loss: 0.173531; batch adversarial loss: 0.422967\n",
      "epoch 95; iter: 0; batch classifier loss: 0.182830; batch adversarial loss: 0.480390\n",
      "epoch 96; iter: 0; batch classifier loss: 0.174831; batch adversarial loss: 0.462317\n",
      "epoch 97; iter: 0; batch classifier loss: 0.155787; batch adversarial loss: 0.506959\n",
      "epoch 98; iter: 0; batch classifier loss: 0.140116; batch adversarial loss: 0.518425\n",
      "epoch 99; iter: 0; batch classifier loss: 0.154037; batch adversarial loss: 0.624280\n",
      "epoch 100; iter: 0; batch classifier loss: 0.167377; batch adversarial loss: 0.483116\n",
      "epoch 101; iter: 0; batch classifier loss: 0.153285; batch adversarial loss: 0.400876\n",
      "epoch 102; iter: 0; batch classifier loss: 0.164092; batch adversarial loss: 0.401492\n",
      "epoch 103; iter: 0; batch classifier loss: 0.239716; batch adversarial loss: 0.399792\n",
      "epoch 104; iter: 0; batch classifier loss: 0.162920; batch adversarial loss: 0.574546\n",
      "epoch 105; iter: 0; batch classifier loss: 0.169898; batch adversarial loss: 0.515485\n",
      "epoch 106; iter: 0; batch classifier loss: 0.147405; batch adversarial loss: 0.390127\n",
      "epoch 107; iter: 0; batch classifier loss: 0.194623; batch adversarial loss: 0.447778\n",
      "epoch 108; iter: 0; batch classifier loss: 0.173723; batch adversarial loss: 0.553567\n",
      "epoch 109; iter: 0; batch classifier loss: 0.167246; batch adversarial loss: 0.505693\n",
      "epoch 110; iter: 0; batch classifier loss: 0.152806; batch adversarial loss: 0.472440\n",
      "epoch 111; iter: 0; batch classifier loss: 0.185165; batch adversarial loss: 0.318999\n",
      "epoch 112; iter: 0; batch classifier loss: 0.224684; batch adversarial loss: 0.505857\n",
      "epoch 113; iter: 0; batch classifier loss: 0.177753; batch adversarial loss: 0.482744\n",
      "epoch 114; iter: 0; batch classifier loss: 0.193675; batch adversarial loss: 0.495134\n",
      "epoch 115; iter: 0; batch classifier loss: 0.181585; batch adversarial loss: 0.517505\n",
      "epoch 116; iter: 0; batch classifier loss: 0.228278; batch adversarial loss: 0.436057\n",
      "epoch 117; iter: 0; batch classifier loss: 0.098694; batch adversarial loss: 0.518183\n",
      "epoch 118; iter: 0; batch classifier loss: 0.156264; batch adversarial loss: 0.458887\n",
      "epoch 119; iter: 0; batch classifier loss: 0.190642; batch adversarial loss: 0.482219\n",
      "epoch 120; iter: 0; batch classifier loss: 0.196408; batch adversarial loss: 0.434566\n",
      "epoch 121; iter: 0; batch classifier loss: 0.211018; batch adversarial loss: 0.422900\n",
      "epoch 122; iter: 0; batch classifier loss: 0.199944; batch adversarial loss: 0.506404\n",
      "epoch 123; iter: 0; batch classifier loss: 0.178712; batch adversarial loss: 0.493687\n",
      "epoch 124; iter: 0; batch classifier loss: 0.182819; batch adversarial loss: 0.506444\n",
      "epoch 125; iter: 0; batch classifier loss: 0.163699; batch adversarial loss: 0.446710\n",
      "epoch 126; iter: 0; batch classifier loss: 0.199034; batch adversarial loss: 0.434658\n",
      "epoch 127; iter: 0; batch classifier loss: 0.161204; batch adversarial loss: 0.470447\n",
      "epoch 128; iter: 0; batch classifier loss: 0.205457; batch adversarial loss: 0.492187\n",
      "epoch 129; iter: 0; batch classifier loss: 0.136684; batch adversarial loss: 0.471272\n",
      "epoch 130; iter: 0; batch classifier loss: 0.162578; batch adversarial loss: 0.505448\n",
      "epoch 131; iter: 0; batch classifier loss: 0.171440; batch adversarial loss: 0.506685\n",
      "epoch 132; iter: 0; batch classifier loss: 0.172012; batch adversarial loss: 0.447940\n",
      "epoch 133; iter: 0; batch classifier loss: 0.158037; batch adversarial loss: 0.450675\n",
      "epoch 134; iter: 0; batch classifier loss: 0.171446; batch adversarial loss: 0.542571\n",
      "epoch 135; iter: 0; batch classifier loss: 0.128238; batch adversarial loss: 0.388677\n",
      "epoch 136; iter: 0; batch classifier loss: 0.168691; batch adversarial loss: 0.541594\n",
      "epoch 137; iter: 0; batch classifier loss: 0.170520; batch adversarial loss: 0.552073\n",
      "epoch 138; iter: 0; batch classifier loss: 0.196479; batch adversarial loss: 0.506749\n",
      "epoch 139; iter: 0; batch classifier loss: 0.211833; batch adversarial loss: 0.471364\n",
      "epoch 140; iter: 0; batch classifier loss: 0.197030; batch adversarial loss: 0.422377\n",
      "epoch 141; iter: 0; batch classifier loss: 0.226598; batch adversarial loss: 0.434640\n",
      "epoch 142; iter: 0; batch classifier loss: 0.137546; batch adversarial loss: 0.435192\n",
      "epoch 143; iter: 0; batch classifier loss: 0.120851; batch adversarial loss: 0.613831\n",
      "epoch 144; iter: 0; batch classifier loss: 0.139645; batch adversarial loss: 0.542739\n",
      "epoch 145; iter: 0; batch classifier loss: 0.133871; batch adversarial loss: 0.495921\n",
      "epoch 146; iter: 0; batch classifier loss: 0.141521; batch adversarial loss: 0.459373\n",
      "epoch 147; iter: 0; batch classifier loss: 0.153679; batch adversarial loss: 0.505242\n",
      "epoch 148; iter: 0; batch classifier loss: 0.197506; batch adversarial loss: 0.436376\n",
      "epoch 149; iter: 0; batch classifier loss: 0.154242; batch adversarial loss: 0.447513\n",
      "epoch 150; iter: 0; batch classifier loss: 0.176481; batch adversarial loss: 0.445670\n",
      "epoch 151; iter: 0; batch classifier loss: 0.164131; batch adversarial loss: 0.555203\n",
      "epoch 152; iter: 0; batch classifier loss: 0.173804; batch adversarial loss: 0.481525\n",
      "epoch 153; iter: 0; batch classifier loss: 0.120620; batch adversarial loss: 0.470077\n",
      "epoch 154; iter: 0; batch classifier loss: 0.074628; batch adversarial loss: 0.418882\n",
      "epoch 155; iter: 0; batch classifier loss: 0.107104; batch adversarial loss: 0.444647\n",
      "epoch 156; iter: 0; batch classifier loss: 0.102118; batch adversarial loss: 0.492445\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038441; batch adversarial loss: 0.481093\n",
      "epoch 158; iter: 0; batch classifier loss: 0.088851; batch adversarial loss: 0.480291\n",
      "epoch 159; iter: 0; batch classifier loss: 0.067225; batch adversarial loss: 0.441757\n",
      "epoch 160; iter: 0; batch classifier loss: 0.057249; batch adversarial loss: 0.459376\n",
      "epoch 161; iter: 0; batch classifier loss: 0.057570; batch adversarial loss: 0.440917\n",
      "epoch 162; iter: 0; batch classifier loss: 0.051667; batch adversarial loss: 0.490925\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034500; batch adversarial loss: 0.495263\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021351; batch adversarial loss: 0.522658\n",
      "epoch 165; iter: 0; batch classifier loss: 0.043750; batch adversarial loss: 0.372705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.040867; batch adversarial loss: 0.429451\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039128; batch adversarial loss: 0.464939\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019551; batch adversarial loss: 0.502028\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028572; batch adversarial loss: 0.469625\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025044; batch adversarial loss: 0.511590\n",
      "epoch 171; iter: 0; batch classifier loss: 0.051983; batch adversarial loss: 0.480192\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033139; batch adversarial loss: 0.413983\n",
      "epoch 173; iter: 0; batch classifier loss: 0.055965; batch adversarial loss: 0.411073\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031872; batch adversarial loss: 0.458644\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011249; batch adversarial loss: 0.470227\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016361; batch adversarial loss: 0.486564\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021376; batch adversarial loss: 0.498913\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027189; batch adversarial loss: 0.457001\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023712; batch adversarial loss: 0.449927\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031717; batch adversarial loss: 0.469922\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014910; batch adversarial loss: 0.534626\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029810; batch adversarial loss: 0.466804\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011489; batch adversarial loss: 0.483390\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021527; batch adversarial loss: 0.575991\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020956; batch adversarial loss: 0.478260\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025330; batch adversarial loss: 0.476305\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015845; batch adversarial loss: 0.414344\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008429; batch adversarial loss: 0.409787\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020879; batch adversarial loss: 0.497517\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008169; batch adversarial loss: 0.461880\n",
      "epoch 191; iter: 0; batch classifier loss: 0.040882; batch adversarial loss: 0.405487\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026119; batch adversarial loss: 0.524351\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016755; batch adversarial loss: 0.476069\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008397; batch adversarial loss: 0.475532\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021618; batch adversarial loss: 0.469391\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005073; batch adversarial loss: 0.431303\n",
      "epoch 197; iter: 0; batch classifier loss: 0.042779; batch adversarial loss: 0.472024\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017118; batch adversarial loss: 0.467319\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016140; batch adversarial loss: 0.376896\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727383; batch adversarial loss: 0.492118\n",
      "epoch 1; iter: 0; batch classifier loss: 0.463241; batch adversarial loss: 0.585488\n",
      "epoch 2; iter: 0; batch classifier loss: 0.423455; batch adversarial loss: 0.568368\n",
      "epoch 3; iter: 0; batch classifier loss: 0.388751; batch adversarial loss: 0.541709\n",
      "epoch 4; iter: 0; batch classifier loss: 0.325569; batch adversarial loss: 0.586102\n",
      "epoch 5; iter: 0; batch classifier loss: 0.404581; batch adversarial loss: 0.522293\n",
      "epoch 6; iter: 0; batch classifier loss: 0.373649; batch adversarial loss: 0.512843\n",
      "epoch 7; iter: 0; batch classifier loss: 0.339711; batch adversarial loss: 0.523171\n",
      "epoch 8; iter: 0; batch classifier loss: 0.336572; batch adversarial loss: 0.536366\n",
      "epoch 9; iter: 0; batch classifier loss: 0.419181; batch adversarial loss: 0.610529\n",
      "epoch 10; iter: 0; batch classifier loss: 0.325519; batch adversarial loss: 0.595653\n",
      "epoch 11; iter: 0; batch classifier loss: 0.298027; batch adversarial loss: 0.539524\n",
      "epoch 12; iter: 0; batch classifier loss: 0.378387; batch adversarial loss: 0.521985\n",
      "epoch 13; iter: 0; batch classifier loss: 0.465904; batch adversarial loss: 0.573781\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487533; batch adversarial loss: 0.493450\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505139; batch adversarial loss: 0.560931\n",
      "epoch 16; iter: 0; batch classifier loss: 0.366170; batch adversarial loss: 0.467453\n",
      "epoch 17; iter: 0; batch classifier loss: 0.297333; batch adversarial loss: 0.499246\n",
      "epoch 18; iter: 0; batch classifier loss: 0.233250; batch adversarial loss: 0.536331\n",
      "epoch 19; iter: 0; batch classifier loss: 0.197985; batch adversarial loss: 0.465126\n",
      "epoch 20; iter: 0; batch classifier loss: 0.259743; batch adversarial loss: 0.409256\n",
      "epoch 21; iter: 0; batch classifier loss: 0.160962; batch adversarial loss: 0.467304\n",
      "epoch 22; iter: 0; batch classifier loss: 0.267571; batch adversarial loss: 0.395136\n",
      "epoch 23; iter: 0; batch classifier loss: 0.130811; batch adversarial loss: 0.424522\n",
      "epoch 24; iter: 0; batch classifier loss: 0.149646; batch adversarial loss: 0.352598\n",
      "epoch 25; iter: 0; batch classifier loss: 0.129467; batch adversarial loss: 0.440296\n",
      "epoch 26; iter: 0; batch classifier loss: 0.198740; batch adversarial loss: 0.503199\n",
      "epoch 27; iter: 0; batch classifier loss: 0.121010; batch adversarial loss: 0.499794\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160083; batch adversarial loss: 0.415271\n",
      "epoch 29; iter: 0; batch classifier loss: 0.162881; batch adversarial loss: 0.366197\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172306; batch adversarial loss: 0.384422\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156037; batch adversarial loss: 0.496535\n",
      "epoch 32; iter: 0; batch classifier loss: 0.115065; batch adversarial loss: 0.348076\n",
      "epoch 33; iter: 0; batch classifier loss: 0.140028; batch adversarial loss: 0.438244\n",
      "epoch 34; iter: 0; batch classifier loss: 0.108835; batch adversarial loss: 0.561789\n",
      "epoch 35; iter: 0; batch classifier loss: 0.127330; batch adversarial loss: 0.422791\n",
      "epoch 36; iter: 0; batch classifier loss: 0.101539; batch adversarial loss: 0.399930\n",
      "epoch 37; iter: 0; batch classifier loss: 0.084961; batch adversarial loss: 0.458962\n",
      "epoch 38; iter: 0; batch classifier loss: 0.155994; batch adversarial loss: 0.411498\n",
      "epoch 39; iter: 0; batch classifier loss: 0.176151; batch adversarial loss: 0.359934\n",
      "epoch 40; iter: 0; batch classifier loss: 0.115133; batch adversarial loss: 0.441708\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098738; batch adversarial loss: 0.465913\n",
      "epoch 42; iter: 0; batch classifier loss: 0.114428; batch adversarial loss: 0.490440\n",
      "epoch 43; iter: 0; batch classifier loss: 0.149583; batch adversarial loss: 0.410084\n",
      "epoch 44; iter: 0; batch classifier loss: 0.051483; batch adversarial loss: 0.544060\n",
      "epoch 45; iter: 0; batch classifier loss: 0.121067; batch adversarial loss: 0.337811\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131735; batch adversarial loss: 0.551375\n",
      "epoch 47; iter: 0; batch classifier loss: 0.131946; batch adversarial loss: 0.453855\n",
      "epoch 48; iter: 0; batch classifier loss: 0.101368; batch adversarial loss: 0.394929\n",
      "epoch 49; iter: 0; batch classifier loss: 0.072530; batch adversarial loss: 0.472596\n",
      "epoch 50; iter: 0; batch classifier loss: 0.085606; batch adversarial loss: 0.512729\n",
      "epoch 51; iter: 0; batch classifier loss: 0.078631; batch adversarial loss: 0.529771\n",
      "epoch 52; iter: 0; batch classifier loss: 0.108274; batch adversarial loss: 0.389081\n",
      "epoch 53; iter: 0; batch classifier loss: 0.059961; batch adversarial loss: 0.425632\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095473; batch adversarial loss: 0.486765\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072206; batch adversarial loss: 0.475749\n",
      "epoch 56; iter: 0; batch classifier loss: 0.133138; batch adversarial loss: 0.442840\n",
      "epoch 57; iter: 0; batch classifier loss: 0.118080; batch adversarial loss: 0.450133\n",
      "epoch 58; iter: 0; batch classifier loss: 0.061410; batch adversarial loss: 0.562470\n",
      "epoch 59; iter: 0; batch classifier loss: 0.120416; batch adversarial loss: 0.384899\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118134; batch adversarial loss: 0.452501\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071731; batch adversarial loss: 0.506335\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120408; batch adversarial loss: 0.415373\n",
      "epoch 63; iter: 0; batch classifier loss: 0.114652; batch adversarial loss: 0.522851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.048813; batch adversarial loss: 0.473882\n",
      "epoch 65; iter: 0; batch classifier loss: 0.089806; batch adversarial loss: 0.539413\n",
      "epoch 66; iter: 0; batch classifier loss: 0.041163; batch adversarial loss: 0.450270\n",
      "epoch 67; iter: 0; batch classifier loss: 0.067950; batch adversarial loss: 0.387190\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054715; batch adversarial loss: 0.415928\n",
      "epoch 69; iter: 0; batch classifier loss: 0.058107; batch adversarial loss: 0.553395\n",
      "epoch 70; iter: 0; batch classifier loss: 0.052665; batch adversarial loss: 0.450566\n",
      "epoch 71; iter: 0; batch classifier loss: 0.066540; batch adversarial loss: 0.507232\n",
      "epoch 72; iter: 0; batch classifier loss: 0.045291; batch adversarial loss: 0.396781\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076894; batch adversarial loss: 0.423748\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081440; batch adversarial loss: 0.493110\n",
      "epoch 75; iter: 0; batch classifier loss: 0.099188; batch adversarial loss: 0.369951\n",
      "epoch 76; iter: 0; batch classifier loss: 0.042701; batch adversarial loss: 0.472803\n",
      "epoch 77; iter: 0; batch classifier loss: 0.085291; batch adversarial loss: 0.379680\n",
      "epoch 78; iter: 0; batch classifier loss: 0.041442; batch adversarial loss: 0.564847\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065817; batch adversarial loss: 0.358206\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067490; batch adversarial loss: 0.435298\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065660; batch adversarial loss: 0.367173\n",
      "epoch 82; iter: 0; batch classifier loss: 0.111514; batch adversarial loss: 0.459237\n",
      "epoch 83; iter: 0; batch classifier loss: 0.103385; batch adversarial loss: 0.476855\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060838; batch adversarial loss: 0.533700\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073552; batch adversarial loss: 0.499042\n",
      "epoch 86; iter: 0; batch classifier loss: 0.078800; batch adversarial loss: 0.398248\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073639; batch adversarial loss: 0.432476\n",
      "epoch 88; iter: 0; batch classifier loss: 0.031788; batch adversarial loss: 0.482713\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035671; batch adversarial loss: 0.522488\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045834; batch adversarial loss: 0.514213\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067359; batch adversarial loss: 0.551160\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065232; batch adversarial loss: 0.417944\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043593; batch adversarial loss: 0.456471\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048355; batch adversarial loss: 0.451239\n",
      "epoch 95; iter: 0; batch classifier loss: 0.059228; batch adversarial loss: 0.419915\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070582; batch adversarial loss: 0.525191\n",
      "epoch 97; iter: 0; batch classifier loss: 0.041810; batch adversarial loss: 0.415432\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058947; batch adversarial loss: 0.484574\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042113; batch adversarial loss: 0.373491\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054909; batch adversarial loss: 0.394836\n",
      "epoch 101; iter: 0; batch classifier loss: 0.027074; batch adversarial loss: 0.375971\n",
      "epoch 102; iter: 0; batch classifier loss: 0.094065; batch adversarial loss: 0.418691\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048257; batch adversarial loss: 0.496669\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034834; batch adversarial loss: 0.438324\n",
      "epoch 105; iter: 0; batch classifier loss: 0.039229; batch adversarial loss: 0.416691\n",
      "epoch 106; iter: 0; batch classifier loss: 0.077112; batch adversarial loss: 0.400817\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069079; batch adversarial loss: 0.522620\n",
      "epoch 108; iter: 0; batch classifier loss: 0.019906; batch adversarial loss: 0.442555\n",
      "epoch 109; iter: 0; batch classifier loss: 0.098011; batch adversarial loss: 0.409430\n",
      "epoch 110; iter: 0; batch classifier loss: 0.032270; batch adversarial loss: 0.480264\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032143; batch adversarial loss: 0.592494\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041620; batch adversarial loss: 0.430794\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052104; batch adversarial loss: 0.470441\n",
      "epoch 114; iter: 0; batch classifier loss: 0.055332; batch adversarial loss: 0.528136\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042030; batch adversarial loss: 0.446620\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058138; batch adversarial loss: 0.408387\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030362; batch adversarial loss: 0.404334\n",
      "epoch 118; iter: 0; batch classifier loss: 0.015686; batch adversarial loss: 0.368881\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070237; batch adversarial loss: 0.340837\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074695; batch adversarial loss: 0.458128\n",
      "epoch 121; iter: 0; batch classifier loss: 0.055586; batch adversarial loss: 0.388420\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051564; batch adversarial loss: 0.351664\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019637; batch adversarial loss: 0.448877\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035239; batch adversarial loss: 0.417119\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053236; batch adversarial loss: 0.369334\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030876; batch adversarial loss: 0.502371\n",
      "epoch 127; iter: 0; batch classifier loss: 0.087357; batch adversarial loss: 0.389034\n",
      "epoch 128; iter: 0; batch classifier loss: 0.057755; batch adversarial loss: 0.488601\n",
      "epoch 129; iter: 0; batch classifier loss: 0.058410; batch adversarial loss: 0.453397\n",
      "epoch 130; iter: 0; batch classifier loss: 0.049743; batch adversarial loss: 0.367826\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045382; batch adversarial loss: 0.445188\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028494; batch adversarial loss: 0.443230\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032084; batch adversarial loss: 0.456850\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025995; batch adversarial loss: 0.457902\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020844; batch adversarial loss: 0.401262\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057621; batch adversarial loss: 0.504424\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042984; batch adversarial loss: 0.464324\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023789; batch adversarial loss: 0.433715\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018977; batch adversarial loss: 0.468228\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026600; batch adversarial loss: 0.577179\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021291; batch adversarial loss: 0.453394\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018634; batch adversarial loss: 0.484526\n",
      "epoch 143; iter: 0; batch classifier loss: 0.048495; batch adversarial loss: 0.384413\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018539; batch adversarial loss: 0.352623\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030318; batch adversarial loss: 0.454105\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038540; batch adversarial loss: 0.424184\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014889; batch adversarial loss: 0.519179\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020378; batch adversarial loss: 0.437682\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014727; batch adversarial loss: 0.494019\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025528; batch adversarial loss: 0.440316\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026782; batch adversarial loss: 0.490944\n",
      "epoch 152; iter: 0; batch classifier loss: 0.009598; batch adversarial loss: 0.384125\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032387; batch adversarial loss: 0.516484\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039716; batch adversarial loss: 0.541048\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017356; batch adversarial loss: 0.393315\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024550; batch adversarial loss: 0.472601\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019897; batch adversarial loss: 0.449292\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030487; batch adversarial loss: 0.437215\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043145; batch adversarial loss: 0.425190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.028697; batch adversarial loss: 0.383233\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025130; batch adversarial loss: 0.379227\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040600; batch adversarial loss: 0.368426\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020109; batch adversarial loss: 0.491168\n",
      "epoch 164; iter: 0; batch classifier loss: 0.042346; batch adversarial loss: 0.478919\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024715; batch adversarial loss: 0.468750\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037319; batch adversarial loss: 0.398003\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017536; batch adversarial loss: 0.413899\n",
      "epoch 168; iter: 0; batch classifier loss: 0.046958; batch adversarial loss: 0.382769\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010686; batch adversarial loss: 0.463042\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018680; batch adversarial loss: 0.407932\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015340; batch adversarial loss: 0.502366\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007769; batch adversarial loss: 0.435728\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030104; batch adversarial loss: 0.448855\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007161; batch adversarial loss: 0.495767\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020770; batch adversarial loss: 0.475391\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018786; batch adversarial loss: 0.416694\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012631; batch adversarial loss: 0.459995\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019289; batch adversarial loss: 0.481706\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017141; batch adversarial loss: 0.496392\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021751; batch adversarial loss: 0.408912\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017400; batch adversarial loss: 0.494471\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016721; batch adversarial loss: 0.365964\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009173; batch adversarial loss: 0.521760\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031125; batch adversarial loss: 0.494351\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022296; batch adversarial loss: 0.413754\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024532; batch adversarial loss: 0.395094\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019853; batch adversarial loss: 0.418299\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025201; batch adversarial loss: 0.514629\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022022; batch adversarial loss: 0.410300\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028758; batch adversarial loss: 0.449083\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013351; batch adversarial loss: 0.452583\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027954; batch adversarial loss: 0.466683\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011721; batch adversarial loss: 0.482184\n",
      "epoch 194; iter: 0; batch classifier loss: 0.037862; batch adversarial loss: 0.448049\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024089; batch adversarial loss: 0.392848\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005252; batch adversarial loss: 0.431769\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025923; batch adversarial loss: 0.472711\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023762; batch adversarial loss: 0.386183\n",
      "epoch 199; iter: 0; batch classifier loss: 0.062325; batch adversarial loss: 0.406979\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692597; batch adversarial loss: 0.838897\n",
      "epoch 1; iter: 0; batch classifier loss: 0.630987; batch adversarial loss: 0.821436\n",
      "epoch 2; iter: 0; batch classifier loss: 0.830303; batch adversarial loss: 0.838072\n",
      "epoch 3; iter: 0; batch classifier loss: 0.743393; batch adversarial loss: 0.724638\n",
      "epoch 4; iter: 0; batch classifier loss: 0.660449; batch adversarial loss: 0.691377\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577795; batch adversarial loss: 0.632897\n",
      "epoch 6; iter: 0; batch classifier loss: 0.367937; batch adversarial loss: 0.529358\n",
      "epoch 7; iter: 0; batch classifier loss: 0.301788; batch adversarial loss: 0.505418\n",
      "epoch 8; iter: 0; batch classifier loss: 0.293859; batch adversarial loss: 0.573649\n",
      "epoch 9; iter: 0; batch classifier loss: 0.261652; batch adversarial loss: 0.572144\n",
      "epoch 10; iter: 0; batch classifier loss: 0.287545; batch adversarial loss: 0.535019\n",
      "epoch 11; iter: 0; batch classifier loss: 0.258688; batch adversarial loss: 0.517442\n",
      "epoch 12; iter: 0; batch classifier loss: 0.255020; batch adversarial loss: 0.491276\n",
      "epoch 13; iter: 0; batch classifier loss: 0.206468; batch adversarial loss: 0.464379\n",
      "epoch 14; iter: 0; batch classifier loss: 0.234443; batch adversarial loss: 0.439941\n",
      "epoch 15; iter: 0; batch classifier loss: 0.179339; batch adversarial loss: 0.478455\n",
      "epoch 16; iter: 0; batch classifier loss: 0.212153; batch adversarial loss: 0.499021\n",
      "epoch 17; iter: 0; batch classifier loss: 0.237067; batch adversarial loss: 0.502534\n",
      "epoch 18; iter: 0; batch classifier loss: 0.208358; batch adversarial loss: 0.436106\n",
      "epoch 19; iter: 0; batch classifier loss: 0.256604; batch adversarial loss: 0.465803\n",
      "epoch 20; iter: 0; batch classifier loss: 0.173210; batch adversarial loss: 0.482910\n",
      "epoch 21; iter: 0; batch classifier loss: 0.191669; batch adversarial loss: 0.537222\n",
      "epoch 22; iter: 0; batch classifier loss: 0.149986; batch adversarial loss: 0.449991\n",
      "epoch 23; iter: 0; batch classifier loss: 0.134459; batch adversarial loss: 0.449735\n",
      "epoch 24; iter: 0; batch classifier loss: 0.189500; batch adversarial loss: 0.502100\n",
      "epoch 25; iter: 0; batch classifier loss: 0.161293; batch adversarial loss: 0.475152\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165864; batch adversarial loss: 0.536891\n",
      "epoch 27; iter: 0; batch classifier loss: 0.173397; batch adversarial loss: 0.564048\n",
      "epoch 28; iter: 0; batch classifier loss: 0.135206; batch adversarial loss: 0.504440\n",
      "epoch 29; iter: 0; batch classifier loss: 0.102982; batch adversarial loss: 0.550467\n",
      "epoch 30; iter: 0; batch classifier loss: 0.124498; batch adversarial loss: 0.425471\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141215; batch adversarial loss: 0.431442\n",
      "epoch 32; iter: 0; batch classifier loss: 0.160889; batch adversarial loss: 0.386563\n",
      "epoch 33; iter: 0; batch classifier loss: 0.132397; batch adversarial loss: 0.527736\n",
      "epoch 34; iter: 0; batch classifier loss: 0.144775; batch adversarial loss: 0.433638\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142904; batch adversarial loss: 0.524737\n",
      "epoch 36; iter: 0; batch classifier loss: 0.103031; batch adversarial loss: 0.467370\n",
      "epoch 37; iter: 0; batch classifier loss: 0.165619; batch adversarial loss: 0.557089\n",
      "epoch 38; iter: 0; batch classifier loss: 0.133770; batch adversarial loss: 0.484221\n",
      "epoch 39; iter: 0; batch classifier loss: 0.103993; batch adversarial loss: 0.520656\n",
      "epoch 40; iter: 0; batch classifier loss: 0.133116; batch adversarial loss: 0.420333\n",
      "epoch 41; iter: 0; batch classifier loss: 0.174718; batch adversarial loss: 0.476845\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103091; batch adversarial loss: 0.605841\n",
      "epoch 43; iter: 0; batch classifier loss: 0.102690; batch adversarial loss: 0.419768\n",
      "epoch 44; iter: 0; batch classifier loss: 0.116568; batch adversarial loss: 0.443321\n",
      "epoch 45; iter: 0; batch classifier loss: 0.120744; batch adversarial loss: 0.410551\n",
      "epoch 46; iter: 0; batch classifier loss: 0.096834; batch adversarial loss: 0.440990\n",
      "epoch 47; iter: 0; batch classifier loss: 0.133520; batch adversarial loss: 0.469790\n",
      "epoch 48; iter: 0; batch classifier loss: 0.160350; batch adversarial loss: 0.460623\n",
      "epoch 49; iter: 0; batch classifier loss: 0.076445; batch adversarial loss: 0.526055\n",
      "epoch 50; iter: 0; batch classifier loss: 0.105278; batch adversarial loss: 0.528343\n",
      "epoch 51; iter: 0; batch classifier loss: 0.066583; batch adversarial loss: 0.495372\n",
      "epoch 52; iter: 0; batch classifier loss: 0.061386; batch adversarial loss: 0.429770\n",
      "epoch 53; iter: 0; batch classifier loss: 0.107323; batch adversarial loss: 0.449811\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114098; batch adversarial loss: 0.427373\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079773; batch adversarial loss: 0.402741\n",
      "epoch 56; iter: 0; batch classifier loss: 0.078211; batch adversarial loss: 0.442233\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073350; batch adversarial loss: 0.469161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.122349; batch adversarial loss: 0.477444\n",
      "epoch 59; iter: 0; batch classifier loss: 0.120543; batch adversarial loss: 0.403030\n",
      "epoch 60; iter: 0; batch classifier loss: 0.082429; batch adversarial loss: 0.537900\n",
      "epoch 61; iter: 0; batch classifier loss: 0.096384; batch adversarial loss: 0.458457\n",
      "epoch 62; iter: 0; batch classifier loss: 0.077370; batch adversarial loss: 0.476222\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093665; batch adversarial loss: 0.426360\n",
      "epoch 64; iter: 0; batch classifier loss: 0.113387; batch adversarial loss: 0.448060\n",
      "epoch 65; iter: 0; batch classifier loss: 0.051449; batch adversarial loss: 0.463658\n",
      "epoch 66; iter: 0; batch classifier loss: 0.074471; batch adversarial loss: 0.445458\n",
      "epoch 67; iter: 0; batch classifier loss: 0.070945; batch adversarial loss: 0.426044\n",
      "epoch 68; iter: 0; batch classifier loss: 0.069329; batch adversarial loss: 0.459265\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075563; batch adversarial loss: 0.511323\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110647; batch adversarial loss: 0.489772\n",
      "epoch 71; iter: 0; batch classifier loss: 0.088079; batch adversarial loss: 0.352739\n",
      "epoch 72; iter: 0; batch classifier loss: 0.079934; batch adversarial loss: 0.477190\n",
      "epoch 73; iter: 0; batch classifier loss: 0.073282; batch adversarial loss: 0.471654\n",
      "epoch 74; iter: 0; batch classifier loss: 0.105926; batch adversarial loss: 0.502608\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066359; batch adversarial loss: 0.517683\n",
      "epoch 76; iter: 0; batch classifier loss: 0.084602; batch adversarial loss: 0.479290\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069482; batch adversarial loss: 0.461874\n",
      "epoch 78; iter: 0; batch classifier loss: 0.093201; batch adversarial loss: 0.496053\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063643; batch adversarial loss: 0.396623\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076676; batch adversarial loss: 0.460959\n",
      "epoch 81; iter: 0; batch classifier loss: 0.053487; batch adversarial loss: 0.498575\n",
      "epoch 82; iter: 0; batch classifier loss: 0.089079; batch adversarial loss: 0.463413\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049672; batch adversarial loss: 0.493403\n",
      "epoch 84; iter: 0; batch classifier loss: 0.033627; batch adversarial loss: 0.433144\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080957; batch adversarial loss: 0.486026\n",
      "epoch 86; iter: 0; batch classifier loss: 0.086857; batch adversarial loss: 0.462623\n",
      "epoch 87; iter: 0; batch classifier loss: 0.038981; batch adversarial loss: 0.452202\n",
      "epoch 88; iter: 0; batch classifier loss: 0.030563; batch adversarial loss: 0.421607\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073155; batch adversarial loss: 0.451341\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047542; batch adversarial loss: 0.431333\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066793; batch adversarial loss: 0.516308\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079915; batch adversarial loss: 0.461059\n",
      "epoch 93; iter: 0; batch classifier loss: 0.124890; batch adversarial loss: 0.439164\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070820; batch adversarial loss: 0.503654\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048025; batch adversarial loss: 0.475113\n",
      "epoch 96; iter: 0; batch classifier loss: 0.083114; batch adversarial loss: 0.457723\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053942; batch adversarial loss: 0.393037\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052773; batch adversarial loss: 0.443177\n",
      "epoch 99; iter: 0; batch classifier loss: 0.034507; batch adversarial loss: 0.403603\n",
      "epoch 100; iter: 0; batch classifier loss: 0.070010; batch adversarial loss: 0.463929\n",
      "epoch 101; iter: 0; batch classifier loss: 0.079151; batch adversarial loss: 0.433325\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067490; batch adversarial loss: 0.468768\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047594; batch adversarial loss: 0.436864\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034430; batch adversarial loss: 0.475309\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056020; batch adversarial loss: 0.477162\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063315; batch adversarial loss: 0.455189\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053404; batch adversarial loss: 0.392830\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077495; batch adversarial loss: 0.397192\n",
      "epoch 109; iter: 0; batch classifier loss: 0.035560; batch adversarial loss: 0.464198\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054386; batch adversarial loss: 0.451679\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033958; batch adversarial loss: 0.444444\n",
      "epoch 112; iter: 0; batch classifier loss: 0.028555; batch adversarial loss: 0.458746\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046022; batch adversarial loss: 0.419399\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059247; batch adversarial loss: 0.531708\n",
      "epoch 115; iter: 0; batch classifier loss: 0.020590; batch adversarial loss: 0.463384\n",
      "epoch 116; iter: 0; batch classifier loss: 0.013164; batch adversarial loss: 0.557669\n",
      "epoch 117; iter: 0; batch classifier loss: 0.022705; batch adversarial loss: 0.474765\n",
      "epoch 118; iter: 0; batch classifier loss: 0.034148; batch adversarial loss: 0.467573\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030377; batch adversarial loss: 0.477087\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027074; batch adversarial loss: 0.351588\n",
      "epoch 121; iter: 0; batch classifier loss: 0.055500; batch adversarial loss: 0.425857\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043459; batch adversarial loss: 0.372456\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036440; batch adversarial loss: 0.435030\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026922; batch adversarial loss: 0.419935\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042849; batch adversarial loss: 0.473007\n",
      "epoch 126; iter: 0; batch classifier loss: 0.012894; batch adversarial loss: 0.382374\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027702; batch adversarial loss: 0.525030\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063747; batch adversarial loss: 0.535805\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031698; batch adversarial loss: 0.441833\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018364; batch adversarial loss: 0.541891\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031754; batch adversarial loss: 0.418742\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028201; batch adversarial loss: 0.432419\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025930; batch adversarial loss: 0.422174\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032528; batch adversarial loss: 0.393219\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031299; batch adversarial loss: 0.470645\n",
      "epoch 136; iter: 0; batch classifier loss: 0.059915; batch adversarial loss: 0.483396\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052043; batch adversarial loss: 0.411961\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021672; batch adversarial loss: 0.524838\n",
      "epoch 139; iter: 0; batch classifier loss: 0.011620; batch adversarial loss: 0.502463\n",
      "epoch 140; iter: 0; batch classifier loss: 0.016580; batch adversarial loss: 0.407944\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016529; batch adversarial loss: 0.483643\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016425; batch adversarial loss: 0.441665\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038106; batch adversarial loss: 0.430649\n",
      "epoch 144; iter: 0; batch classifier loss: 0.009300; batch adversarial loss: 0.478670\n",
      "epoch 145; iter: 0; batch classifier loss: 0.003686; batch adversarial loss: 0.463523\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010721; batch adversarial loss: 0.431850\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025792; batch adversarial loss: 0.384164\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020399; batch adversarial loss: 0.382740\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032180; batch adversarial loss: 0.519328\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035146; batch adversarial loss: 0.522997\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032200; batch adversarial loss: 0.440855\n",
      "epoch 152; iter: 0; batch classifier loss: 0.050767; batch adversarial loss: 0.475079\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010048; batch adversarial loss: 0.415270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.028573; batch adversarial loss: 0.461304\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037143; batch adversarial loss: 0.633637\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012788; batch adversarial loss: 0.493421\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038524; batch adversarial loss: 0.513551\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013452; batch adversarial loss: 0.398915\n",
      "epoch 159; iter: 0; batch classifier loss: 0.008836; batch adversarial loss: 0.475157\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019930; batch adversarial loss: 0.506057\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020912; batch adversarial loss: 0.448759\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015456; batch adversarial loss: 0.479162\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014216; batch adversarial loss: 0.429496\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021874; batch adversarial loss: 0.457083\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016063; batch adversarial loss: 0.557537\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014523; batch adversarial loss: 0.474705\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016077; batch adversarial loss: 0.482543\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031780; batch adversarial loss: 0.378222\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016940; batch adversarial loss: 0.458046\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019552; batch adversarial loss: 0.441345\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015846; batch adversarial loss: 0.441135\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013660; batch adversarial loss: 0.390685\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019456; batch adversarial loss: 0.444629\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032024; batch adversarial loss: 0.436885\n",
      "epoch 175; iter: 0; batch classifier loss: 0.051430; batch adversarial loss: 0.550688\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023823; batch adversarial loss: 0.384270\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022901; batch adversarial loss: 0.443994\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012555; batch adversarial loss: 0.464995\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012919; batch adversarial loss: 0.382502\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011599; batch adversarial loss: 0.491218\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020995; batch adversarial loss: 0.453972\n",
      "epoch 182; iter: 0; batch classifier loss: 0.004474; batch adversarial loss: 0.436087\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018946; batch adversarial loss: 0.573223\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004989; batch adversarial loss: 0.472653\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015589; batch adversarial loss: 0.459324\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009622; batch adversarial loss: 0.414380\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016468; batch adversarial loss: 0.448217\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024598; batch adversarial loss: 0.420501\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020096; batch adversarial loss: 0.455103\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012019; batch adversarial loss: 0.476737\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018905; batch adversarial loss: 0.513693\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035963; batch adversarial loss: 0.441262\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007008; batch adversarial loss: 0.542522\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019779; batch adversarial loss: 0.434838\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012739; batch adversarial loss: 0.367367\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014020; batch adversarial loss: 0.447416\n",
      "epoch 197; iter: 0; batch classifier loss: 0.044545; batch adversarial loss: 0.368128\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006915; batch adversarial loss: 0.517938\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025226; batch adversarial loss: 0.504612\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699590; batch adversarial loss: 0.570955\n",
      "epoch 1; iter: 0; batch classifier loss: 0.477504; batch adversarial loss: 0.624854\n",
      "epoch 2; iter: 0; batch classifier loss: 0.465489; batch adversarial loss: 0.610380\n",
      "epoch 3; iter: 0; batch classifier loss: 0.445505; batch adversarial loss: 0.602511\n",
      "epoch 4; iter: 0; batch classifier loss: 0.388094; batch adversarial loss: 0.607782\n",
      "epoch 5; iter: 0; batch classifier loss: 0.446578; batch adversarial loss: 0.572585\n",
      "epoch 6; iter: 0; batch classifier loss: 0.589841; batch adversarial loss: 0.596725\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583763; batch adversarial loss: 0.541875\n",
      "epoch 8; iter: 0; batch classifier loss: 0.658351; batch adversarial loss: 0.593316\n",
      "epoch 9; iter: 0; batch classifier loss: 0.512586; batch adversarial loss: 0.571684\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559215; batch adversarial loss: 0.510554\n",
      "epoch 11; iter: 0; batch classifier loss: 0.315153; batch adversarial loss: 0.477500\n",
      "epoch 12; iter: 0; batch classifier loss: 0.431128; batch adversarial loss: 0.502273\n",
      "epoch 13; iter: 0; batch classifier loss: 0.293145; batch adversarial loss: 0.508664\n",
      "epoch 14; iter: 0; batch classifier loss: 0.306074; batch adversarial loss: 0.551074\n",
      "epoch 15; iter: 0; batch classifier loss: 0.247094; batch adversarial loss: 0.421919\n",
      "epoch 16; iter: 0; batch classifier loss: 0.239833; batch adversarial loss: 0.441193\n",
      "epoch 17; iter: 0; batch classifier loss: 0.223395; batch adversarial loss: 0.504466\n",
      "epoch 18; iter: 0; batch classifier loss: 0.287734; batch adversarial loss: 0.393535\n",
      "epoch 19; iter: 0; batch classifier loss: 0.303230; batch adversarial loss: 0.465119\n",
      "epoch 20; iter: 0; batch classifier loss: 0.291370; batch adversarial loss: 0.499137\n",
      "epoch 21; iter: 0; batch classifier loss: 0.239380; batch adversarial loss: 0.403382\n",
      "epoch 22; iter: 0; batch classifier loss: 0.227423; batch adversarial loss: 0.458513\n",
      "epoch 23; iter: 0; batch classifier loss: 0.217693; batch adversarial loss: 0.387802\n",
      "epoch 24; iter: 0; batch classifier loss: 0.196801; batch adversarial loss: 0.467209\n",
      "epoch 25; iter: 0; batch classifier loss: 0.242217; batch adversarial loss: 0.451410\n",
      "epoch 26; iter: 0; batch classifier loss: 0.219672; batch adversarial loss: 0.408596\n",
      "epoch 27; iter: 0; batch classifier loss: 0.244506; batch adversarial loss: 0.495099\n",
      "epoch 28; iter: 0; batch classifier loss: 0.194041; batch adversarial loss: 0.563448\n",
      "epoch 29; iter: 0; batch classifier loss: 0.206896; batch adversarial loss: 0.400359\n",
      "epoch 30; iter: 0; batch classifier loss: 0.243303; batch adversarial loss: 0.413285\n",
      "epoch 31; iter: 0; batch classifier loss: 0.239479; batch adversarial loss: 0.523848\n",
      "epoch 32; iter: 0; batch classifier loss: 0.205414; batch adversarial loss: 0.432899\n",
      "epoch 33; iter: 0; batch classifier loss: 0.223555; batch adversarial loss: 0.415216\n",
      "epoch 34; iter: 0; batch classifier loss: 0.153055; batch adversarial loss: 0.520177\n",
      "epoch 35; iter: 0; batch classifier loss: 0.231587; batch adversarial loss: 0.424178\n",
      "epoch 36; iter: 0; batch classifier loss: 0.202426; batch adversarial loss: 0.409297\n",
      "epoch 37; iter: 0; batch classifier loss: 0.155529; batch adversarial loss: 0.418648\n",
      "epoch 38; iter: 0; batch classifier loss: 0.191469; batch adversarial loss: 0.480936\n",
      "epoch 39; iter: 0; batch classifier loss: 0.181730; batch adversarial loss: 0.421709\n",
      "epoch 40; iter: 0; batch classifier loss: 0.163826; batch adversarial loss: 0.492102\n",
      "epoch 41; iter: 0; batch classifier loss: 0.143166; batch adversarial loss: 0.462114\n",
      "epoch 42; iter: 0; batch classifier loss: 0.216082; batch adversarial loss: 0.425088\n",
      "epoch 43; iter: 0; batch classifier loss: 0.170802; batch adversarial loss: 0.503726\n",
      "epoch 44; iter: 0; batch classifier loss: 0.211343; batch adversarial loss: 0.492460\n",
      "epoch 45; iter: 0; batch classifier loss: 0.241409; batch adversarial loss: 0.371433\n",
      "epoch 46; iter: 0; batch classifier loss: 0.188599; batch adversarial loss: 0.464621\n",
      "epoch 47; iter: 0; batch classifier loss: 0.159468; batch adversarial loss: 0.580324\n",
      "epoch 48; iter: 0; batch classifier loss: 0.166358; batch adversarial loss: 0.425927\n",
      "epoch 49; iter: 0; batch classifier loss: 0.173999; batch adversarial loss: 0.561397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.109567; batch adversarial loss: 0.482871\n",
      "epoch 51; iter: 0; batch classifier loss: 0.184107; batch adversarial loss: 0.400641\n",
      "epoch 52; iter: 0; batch classifier loss: 0.146001; batch adversarial loss: 0.411290\n",
      "epoch 53; iter: 0; batch classifier loss: 0.137298; batch adversarial loss: 0.482476\n",
      "epoch 54; iter: 0; batch classifier loss: 0.162081; batch adversarial loss: 0.396899\n",
      "epoch 55; iter: 0; batch classifier loss: 0.155970; batch adversarial loss: 0.391752\n",
      "epoch 56; iter: 0; batch classifier loss: 0.197082; batch adversarial loss: 0.403396\n",
      "epoch 57; iter: 0; batch classifier loss: 0.195806; batch adversarial loss: 0.407697\n",
      "epoch 58; iter: 0; batch classifier loss: 0.137069; batch adversarial loss: 0.437576\n",
      "epoch 59; iter: 0; batch classifier loss: 0.228000; batch adversarial loss: 0.433583\n",
      "epoch 60; iter: 0; batch classifier loss: 0.132833; batch adversarial loss: 0.522838\n",
      "epoch 61; iter: 0; batch classifier loss: 0.188639; batch adversarial loss: 0.485258\n",
      "epoch 62; iter: 0; batch classifier loss: 0.158779; batch adversarial loss: 0.444542\n",
      "epoch 63; iter: 0; batch classifier loss: 0.167438; batch adversarial loss: 0.430527\n",
      "epoch 64; iter: 0; batch classifier loss: 0.136269; batch adversarial loss: 0.407586\n",
      "epoch 65; iter: 0; batch classifier loss: 0.230067; batch adversarial loss: 0.417950\n",
      "epoch 66; iter: 0; batch classifier loss: 0.272201; batch adversarial loss: 0.356874\n",
      "epoch 67; iter: 0; batch classifier loss: 0.208776; batch adversarial loss: 0.458801\n",
      "epoch 68; iter: 0; batch classifier loss: 0.145145; batch adversarial loss: 0.367816\n",
      "epoch 69; iter: 0; batch classifier loss: 0.160733; batch adversarial loss: 0.391059\n",
      "epoch 70; iter: 0; batch classifier loss: 0.136193; batch adversarial loss: 0.433271\n",
      "epoch 71; iter: 0; batch classifier loss: 0.136748; batch adversarial loss: 0.472925\n",
      "epoch 72; iter: 0; batch classifier loss: 0.142180; batch adversarial loss: 0.447867\n",
      "epoch 73; iter: 0; batch classifier loss: 0.152394; batch adversarial loss: 0.293969\n",
      "epoch 74; iter: 0; batch classifier loss: 0.165273; batch adversarial loss: 0.544639\n",
      "epoch 75; iter: 0; batch classifier loss: 0.137337; batch adversarial loss: 0.496723\n",
      "epoch 76; iter: 0; batch classifier loss: 0.211140; batch adversarial loss: 0.636893\n",
      "epoch 77; iter: 0; batch classifier loss: 0.182265; batch adversarial loss: 0.422001\n",
      "epoch 78; iter: 0; batch classifier loss: 0.111508; batch adversarial loss: 0.467591\n",
      "epoch 79; iter: 0; batch classifier loss: 0.144847; batch adversarial loss: 0.393936\n",
      "epoch 80; iter: 0; batch classifier loss: 0.104143; batch adversarial loss: 0.420278\n",
      "epoch 81; iter: 0; batch classifier loss: 0.116694; batch adversarial loss: 0.459849\n",
      "epoch 82; iter: 0; batch classifier loss: 0.207509; batch adversarial loss: 0.393128\n",
      "epoch 83; iter: 0; batch classifier loss: 0.132202; batch adversarial loss: 0.444351\n",
      "epoch 84; iter: 0; batch classifier loss: 0.128589; batch adversarial loss: 0.470532\n",
      "epoch 85; iter: 0; batch classifier loss: 0.110022; batch adversarial loss: 0.455370\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083994; batch adversarial loss: 0.380518\n",
      "epoch 87; iter: 0; batch classifier loss: 0.122221; batch adversarial loss: 0.422980\n",
      "epoch 88; iter: 0; batch classifier loss: 0.118053; batch adversarial loss: 0.441195\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075764; batch adversarial loss: 0.397166\n",
      "epoch 90; iter: 0; batch classifier loss: 0.105362; batch adversarial loss: 0.455884\n",
      "epoch 91; iter: 0; batch classifier loss: 0.150318; batch adversarial loss: 0.457601\n",
      "epoch 92; iter: 0; batch classifier loss: 0.111568; batch adversarial loss: 0.403864\n",
      "epoch 93; iter: 0; batch classifier loss: 0.092019; batch adversarial loss: 0.383765\n",
      "epoch 94; iter: 0; batch classifier loss: 0.112824; batch adversarial loss: 0.372881\n",
      "epoch 95; iter: 0; batch classifier loss: 0.116649; batch adversarial loss: 0.381296\n",
      "epoch 96; iter: 0; batch classifier loss: 0.054643; batch adversarial loss: 0.548616\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071952; batch adversarial loss: 0.422444\n",
      "epoch 98; iter: 0; batch classifier loss: 0.099582; batch adversarial loss: 0.428317\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078790; batch adversarial loss: 0.403563\n",
      "epoch 100; iter: 0; batch classifier loss: 0.128441; batch adversarial loss: 0.365901\n",
      "epoch 101; iter: 0; batch classifier loss: 0.100573; batch adversarial loss: 0.388332\n",
      "epoch 102; iter: 0; batch classifier loss: 0.107849; batch adversarial loss: 0.407379\n",
      "epoch 103; iter: 0; batch classifier loss: 0.075593; batch adversarial loss: 0.503927\n",
      "epoch 104; iter: 0; batch classifier loss: 0.052381; batch adversarial loss: 0.434364\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035566; batch adversarial loss: 0.570451\n",
      "epoch 106; iter: 0; batch classifier loss: 0.080811; batch adversarial loss: 0.381398\n",
      "epoch 107; iter: 0; batch classifier loss: 0.068231; batch adversarial loss: 0.354117\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043018; batch adversarial loss: 0.472290\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062910; batch adversarial loss: 0.438258\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047137; batch adversarial loss: 0.522746\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057831; batch adversarial loss: 0.329053\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054354; batch adversarial loss: 0.471999\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039677; batch adversarial loss: 0.518362\n",
      "epoch 114; iter: 0; batch classifier loss: 0.063310; batch adversarial loss: 0.478600\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034410; batch adversarial loss: 0.492331\n",
      "epoch 116; iter: 0; batch classifier loss: 0.078082; batch adversarial loss: 0.318729\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037684; batch adversarial loss: 0.497317\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049205; batch adversarial loss: 0.403311\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054466; batch adversarial loss: 0.465911\n",
      "epoch 120; iter: 0; batch classifier loss: 0.071230; batch adversarial loss: 0.432411\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048547; batch adversarial loss: 0.487138\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050800; batch adversarial loss: 0.470875\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028955; batch adversarial loss: 0.428376\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039017; batch adversarial loss: 0.558292\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023574; batch adversarial loss: 0.494002\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020039; batch adversarial loss: 0.410850\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047796; batch adversarial loss: 0.492012\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027810; batch adversarial loss: 0.406438\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047402; batch adversarial loss: 0.406511\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034994; batch adversarial loss: 0.425659\n",
      "epoch 131; iter: 0; batch classifier loss: 0.058957; batch adversarial loss: 0.499191\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033016; batch adversarial loss: 0.506591\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041860; batch adversarial loss: 0.427959\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031269; batch adversarial loss: 0.431835\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039563; batch adversarial loss: 0.333505\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044452; batch adversarial loss: 0.499715\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025459; batch adversarial loss: 0.388096\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032462; batch adversarial loss: 0.387322\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028611; batch adversarial loss: 0.431038\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027710; batch adversarial loss: 0.463010\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016607; batch adversarial loss: 0.500034\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029926; batch adversarial loss: 0.473571\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038307; batch adversarial loss: 0.372866\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027009; batch adversarial loss: 0.466640\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028967; batch adversarial loss: 0.433724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.028566; batch adversarial loss: 0.459973\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041161; batch adversarial loss: 0.487050\n",
      "epoch 148; iter: 0; batch classifier loss: 0.079479; batch adversarial loss: 0.459506\n",
      "epoch 149; iter: 0; batch classifier loss: 0.006444; batch adversarial loss: 0.488055\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017834; batch adversarial loss: 0.542620\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016477; batch adversarial loss: 0.445681\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033087; batch adversarial loss: 0.344235\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029710; batch adversarial loss: 0.595562\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028566; batch adversarial loss: 0.452531\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036053; batch adversarial loss: 0.330242\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036750; batch adversarial loss: 0.448031\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027037; batch adversarial loss: 0.501243\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035165; batch adversarial loss: 0.405309\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021436; batch adversarial loss: 0.464941\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019748; batch adversarial loss: 0.410465\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026941; batch adversarial loss: 0.385726\n",
      "epoch 162; iter: 0; batch classifier loss: 0.060094; batch adversarial loss: 0.503629\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026856; batch adversarial loss: 0.463165\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028103; batch adversarial loss: 0.496128\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009716; batch adversarial loss: 0.523984\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036271; batch adversarial loss: 0.455230\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020956; batch adversarial loss: 0.315986\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012517; batch adversarial loss: 0.477391\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028632; batch adversarial loss: 0.413943\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037918; batch adversarial loss: 0.459630\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022343; batch adversarial loss: 0.346068\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015219; batch adversarial loss: 0.510687\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029807; batch adversarial loss: 0.495378\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019932; batch adversarial loss: 0.465231\n",
      "epoch 175; iter: 0; batch classifier loss: 0.043564; batch adversarial loss: 0.347396\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014950; batch adversarial loss: 0.517343\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007177; batch adversarial loss: 0.470479\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013747; batch adversarial loss: 0.413286\n",
      "epoch 179; iter: 0; batch classifier loss: 0.077294; batch adversarial loss: 0.385178\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013840; batch adversarial loss: 0.366536\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023675; batch adversarial loss: 0.338551\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016792; batch adversarial loss: 0.526268\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013084; batch adversarial loss: 0.423485\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013223; batch adversarial loss: 0.362422\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009339; batch adversarial loss: 0.348268\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031033; batch adversarial loss: 0.462430\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025175; batch adversarial loss: 0.488969\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017658; batch adversarial loss: 0.463383\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015171; batch adversarial loss: 0.557811\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026633; batch adversarial loss: 0.487021\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015157; batch adversarial loss: 0.419979\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031709; batch adversarial loss: 0.548325\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009897; batch adversarial loss: 0.406001\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008111; batch adversarial loss: 0.390408\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011738; batch adversarial loss: 0.369692\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024844; batch adversarial loss: 0.475245\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019425; batch adversarial loss: 0.554108\n",
      "epoch 198; iter: 0; batch classifier loss: 0.056508; batch adversarial loss: 0.418028\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009811; batch adversarial loss: 0.483333\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691139; batch adversarial loss: 1.249835\n",
      "epoch 1; iter: 0; batch classifier loss: 0.749307; batch adversarial loss: 1.799655\n",
      "epoch 2; iter: 0; batch classifier loss: 0.986823; batch adversarial loss: 1.722225\n",
      "epoch 3; iter: 0; batch classifier loss: 1.180060; batch adversarial loss: 1.592974\n",
      "epoch 4; iter: 0; batch classifier loss: 1.163029; batch adversarial loss: 1.471678\n",
      "epoch 5; iter: 0; batch classifier loss: 1.168987; batch adversarial loss: 1.358199\n",
      "epoch 6; iter: 0; batch classifier loss: 1.145206; batch adversarial loss: 1.232908\n",
      "epoch 7; iter: 0; batch classifier loss: 1.135773; batch adversarial loss: 1.144620\n",
      "epoch 8; iter: 0; batch classifier loss: 1.138632; batch adversarial loss: 1.038843\n",
      "epoch 9; iter: 0; batch classifier loss: 1.154107; batch adversarial loss: 0.953769\n",
      "epoch 10; iter: 0; batch classifier loss: 1.112195; batch adversarial loss: 0.886816\n",
      "epoch 11; iter: 0; batch classifier loss: 1.304926; batch adversarial loss: 0.790412\n",
      "epoch 12; iter: 0; batch classifier loss: 1.243106; batch adversarial loss: 0.745228\n",
      "epoch 13; iter: 0; batch classifier loss: 1.232999; batch adversarial loss: 0.742562\n",
      "epoch 14; iter: 0; batch classifier loss: 1.100898; batch adversarial loss: 0.672225\n",
      "epoch 15; iter: 0; batch classifier loss: 1.020452; batch adversarial loss: 0.614694\n",
      "epoch 16; iter: 0; batch classifier loss: 1.148323; batch adversarial loss: 0.605510\n",
      "epoch 17; iter: 0; batch classifier loss: 0.923480; batch adversarial loss: 0.573667\n",
      "epoch 18; iter: 0; batch classifier loss: 0.873399; batch adversarial loss: 0.575790\n",
      "epoch 19; iter: 0; batch classifier loss: 0.740250; batch adversarial loss: 0.530041\n",
      "epoch 20; iter: 0; batch classifier loss: 0.711630; batch adversarial loss: 0.481960\n",
      "epoch 21; iter: 0; batch classifier loss: 0.745449; batch adversarial loss: 0.475370\n",
      "epoch 22; iter: 0; batch classifier loss: 0.413847; batch adversarial loss: 0.466665\n",
      "epoch 23; iter: 0; batch classifier loss: 0.319743; batch adversarial loss: 0.444347\n",
      "epoch 24; iter: 0; batch classifier loss: 0.281620; batch adversarial loss: 0.448210\n",
      "epoch 25; iter: 0; batch classifier loss: 0.242662; batch adversarial loss: 0.442057\n",
      "epoch 26; iter: 0; batch classifier loss: 0.204368; batch adversarial loss: 0.438661\n",
      "epoch 27; iter: 0; batch classifier loss: 0.200994; batch adversarial loss: 0.492965\n",
      "epoch 28; iter: 0; batch classifier loss: 0.127457; batch adversarial loss: 0.466929\n",
      "epoch 29; iter: 0; batch classifier loss: 0.127954; batch adversarial loss: 0.438321\n",
      "epoch 30; iter: 0; batch classifier loss: 0.209287; batch adversarial loss: 0.512532\n",
      "epoch 31; iter: 0; batch classifier loss: 0.177470; batch adversarial loss: 0.470124\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159963; batch adversarial loss: 0.477523\n",
      "epoch 33; iter: 0; batch classifier loss: 0.106663; batch adversarial loss: 0.420906\n",
      "epoch 34; iter: 0; batch classifier loss: 0.096737; batch adversarial loss: 0.419345\n",
      "epoch 35; iter: 0; batch classifier loss: 0.103658; batch adversarial loss: 0.443719\n",
      "epoch 36; iter: 0; batch classifier loss: 0.074187; batch adversarial loss: 0.509311\n",
      "epoch 37; iter: 0; batch classifier loss: 0.076974; batch adversarial loss: 0.423998\n",
      "epoch 38; iter: 0; batch classifier loss: 0.075630; batch adversarial loss: 0.439564\n",
      "epoch 39; iter: 0; batch classifier loss: 0.088438; batch adversarial loss: 0.442478\n",
      "epoch 40; iter: 0; batch classifier loss: 0.098983; batch adversarial loss: 0.403589\n",
      "epoch 41; iter: 0; batch classifier loss: 0.115978; batch adversarial loss: 0.437330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.091673; batch adversarial loss: 0.443957\n",
      "epoch 43; iter: 0; batch classifier loss: 0.082290; batch adversarial loss: 0.456505\n",
      "epoch 44; iter: 0; batch classifier loss: 0.073773; batch adversarial loss: 0.460120\n",
      "epoch 45; iter: 0; batch classifier loss: 0.083903; batch adversarial loss: 0.460527\n",
      "epoch 46; iter: 0; batch classifier loss: 0.048864; batch adversarial loss: 0.446623\n",
      "epoch 47; iter: 0; batch classifier loss: 0.075118; batch adversarial loss: 0.368192\n",
      "epoch 48; iter: 0; batch classifier loss: 0.042659; batch adversarial loss: 0.533160\n",
      "epoch 49; iter: 0; batch classifier loss: 0.059103; batch adversarial loss: 0.509181\n",
      "epoch 50; iter: 0; batch classifier loss: 0.060124; batch adversarial loss: 0.396068\n",
      "epoch 51; iter: 0; batch classifier loss: 0.055282; batch adversarial loss: 0.433597\n",
      "epoch 52; iter: 0; batch classifier loss: 0.081045; batch adversarial loss: 0.385897\n",
      "epoch 53; iter: 0; batch classifier loss: 0.051755; batch adversarial loss: 0.403835\n",
      "epoch 54; iter: 0; batch classifier loss: 0.069211; batch adversarial loss: 0.425103\n",
      "epoch 55; iter: 0; batch classifier loss: 0.066930; batch adversarial loss: 0.451321\n",
      "epoch 56; iter: 0; batch classifier loss: 0.056654; batch adversarial loss: 0.406192\n",
      "epoch 57; iter: 0; batch classifier loss: 0.047147; batch adversarial loss: 0.482411\n",
      "epoch 58; iter: 0; batch classifier loss: 0.028963; batch adversarial loss: 0.407675\n",
      "epoch 59; iter: 0; batch classifier loss: 0.045814; batch adversarial loss: 0.364138\n",
      "epoch 60; iter: 0; batch classifier loss: 0.055249; batch adversarial loss: 0.573316\n",
      "epoch 61; iter: 0; batch classifier loss: 0.045673; batch adversarial loss: 0.461510\n",
      "epoch 62; iter: 0; batch classifier loss: 0.030970; batch adversarial loss: 0.470118\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088534; batch adversarial loss: 0.527435\n",
      "epoch 64; iter: 0; batch classifier loss: 0.048377; batch adversarial loss: 0.397631\n",
      "epoch 65; iter: 0; batch classifier loss: 0.054444; batch adversarial loss: 0.389330\n",
      "epoch 66; iter: 0; batch classifier loss: 0.024546; batch adversarial loss: 0.466788\n",
      "epoch 67; iter: 0; batch classifier loss: 0.043669; batch adversarial loss: 0.454543\n",
      "epoch 68; iter: 0; batch classifier loss: 0.037967; batch adversarial loss: 0.331525\n",
      "epoch 69; iter: 0; batch classifier loss: 0.032094; batch adversarial loss: 0.556626\n",
      "epoch 70; iter: 0; batch classifier loss: 0.028933; batch adversarial loss: 0.456400\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069090; batch adversarial loss: 0.486380\n",
      "epoch 72; iter: 0; batch classifier loss: 0.069212; batch adversarial loss: 0.421915\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077584; batch adversarial loss: 0.433433\n",
      "epoch 74; iter: 0; batch classifier loss: 0.027403; batch adversarial loss: 0.424481\n",
      "epoch 75; iter: 0; batch classifier loss: 0.074802; batch adversarial loss: 0.456727\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046728; batch adversarial loss: 0.452155\n",
      "epoch 77; iter: 0; batch classifier loss: 0.019032; batch adversarial loss: 0.385100\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064559; batch adversarial loss: 0.568510\n",
      "epoch 79; iter: 0; batch classifier loss: 0.037312; batch adversarial loss: 0.477474\n",
      "epoch 80; iter: 0; batch classifier loss: 0.028891; batch adversarial loss: 0.444373\n",
      "epoch 81; iter: 0; batch classifier loss: 0.032867; batch adversarial loss: 0.418532\n",
      "epoch 82; iter: 0; batch classifier loss: 0.039907; batch adversarial loss: 0.503700\n",
      "epoch 83; iter: 0; batch classifier loss: 0.034442; batch adversarial loss: 0.423856\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045787; batch adversarial loss: 0.466992\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076266; batch adversarial loss: 0.435461\n",
      "epoch 86; iter: 0; batch classifier loss: 0.033101; batch adversarial loss: 0.429884\n",
      "epoch 87; iter: 0; batch classifier loss: 0.023694; batch adversarial loss: 0.356849\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049759; batch adversarial loss: 0.448555\n",
      "epoch 89; iter: 0; batch classifier loss: 0.041102; batch adversarial loss: 0.501228\n",
      "epoch 90; iter: 0; batch classifier loss: 0.038235; batch adversarial loss: 0.407491\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057381; batch adversarial loss: 0.493667\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051355; batch adversarial loss: 0.411145\n",
      "epoch 93; iter: 0; batch classifier loss: 0.037996; batch adversarial loss: 0.477830\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053532; batch adversarial loss: 0.414683\n",
      "epoch 95; iter: 0; batch classifier loss: 0.027307; batch adversarial loss: 0.438136\n",
      "epoch 96; iter: 0; batch classifier loss: 0.026966; batch adversarial loss: 0.439698\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042015; batch adversarial loss: 0.431825\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039276; batch adversarial loss: 0.423388\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052743; batch adversarial loss: 0.517913\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056202; batch adversarial loss: 0.405832\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041158; batch adversarial loss: 0.499901\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037038; batch adversarial loss: 0.335342\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032300; batch adversarial loss: 0.457215\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027370; batch adversarial loss: 0.430129\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036974; batch adversarial loss: 0.397858\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044469; batch adversarial loss: 0.390528\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059787; batch adversarial loss: 0.422283\n",
      "epoch 108; iter: 0; batch classifier loss: 0.027386; batch adversarial loss: 0.435778\n",
      "epoch 109; iter: 0; batch classifier loss: 0.025988; batch adversarial loss: 0.457090\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044962; batch adversarial loss: 0.516753\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064874; batch adversarial loss: 0.433102\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043991; batch adversarial loss: 0.389948\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042086; batch adversarial loss: 0.420735\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036187; batch adversarial loss: 0.421523\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059720; batch adversarial loss: 0.440343\n",
      "epoch 116; iter: 0; batch classifier loss: 0.047189; batch adversarial loss: 0.454913\n",
      "epoch 117; iter: 0; batch classifier loss: 0.016899; batch adversarial loss: 0.477170\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039528; batch adversarial loss: 0.502098\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022502; batch adversarial loss: 0.369005\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038780; batch adversarial loss: 0.437573\n",
      "epoch 121; iter: 0; batch classifier loss: 0.022686; batch adversarial loss: 0.410007\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030498; batch adversarial loss: 0.433595\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055303; batch adversarial loss: 0.500343\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026219; batch adversarial loss: 0.436736\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068175; batch adversarial loss: 0.565237\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027768; batch adversarial loss: 0.347818\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037142; batch adversarial loss: 0.408940\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047574; batch adversarial loss: 0.539507\n",
      "epoch 129; iter: 0; batch classifier loss: 0.079850; batch adversarial loss: 0.548087\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057395; batch adversarial loss: 0.500292\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036104; batch adversarial loss: 0.459845\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030385; batch adversarial loss: 0.411330\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053855; batch adversarial loss: 0.446348\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031987; batch adversarial loss: 0.459736\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040713; batch adversarial loss: 0.516851\n",
      "epoch 136; iter: 0; batch classifier loss: 0.077939; batch adversarial loss: 0.532800\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052322; batch adversarial loss: 0.424973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.035666; batch adversarial loss: 0.443028\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041938; batch adversarial loss: 0.485971\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018804; batch adversarial loss: 0.445850\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038798; batch adversarial loss: 0.515941\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023599; batch adversarial loss: 0.506167\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011957; batch adversarial loss: 0.397163\n",
      "epoch 144; iter: 0; batch classifier loss: 0.015996; batch adversarial loss: 0.465530\n",
      "epoch 145; iter: 0; batch classifier loss: 0.065190; batch adversarial loss: 0.507539\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037125; batch adversarial loss: 0.497139\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023911; batch adversarial loss: 0.475211\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035272; batch adversarial loss: 0.378322\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044542; batch adversarial loss: 0.399313\n",
      "epoch 150; iter: 0; batch classifier loss: 0.050651; batch adversarial loss: 0.474872\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029533; batch adversarial loss: 0.395172\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045326; batch adversarial loss: 0.391057\n",
      "epoch 153; iter: 0; batch classifier loss: 0.051276; batch adversarial loss: 0.384068\n",
      "epoch 154; iter: 0; batch classifier loss: 0.045771; batch adversarial loss: 0.486251\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025087; batch adversarial loss: 0.408345\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031874; batch adversarial loss: 0.360177\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027103; batch adversarial loss: 0.469243\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048151; batch adversarial loss: 0.576532\n",
      "epoch 159; iter: 0; batch classifier loss: 0.053171; batch adversarial loss: 0.379279\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015941; batch adversarial loss: 0.546789\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036359; batch adversarial loss: 0.418292\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027592; batch adversarial loss: 0.464740\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032486; batch adversarial loss: 0.405136\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018894; batch adversarial loss: 0.385364\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040778; batch adversarial loss: 0.463239\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031063; batch adversarial loss: 0.387860\n",
      "epoch 167; iter: 0; batch classifier loss: 0.040206; batch adversarial loss: 0.498800\n",
      "epoch 168; iter: 0; batch classifier loss: 0.062481; batch adversarial loss: 0.437326\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019670; batch adversarial loss: 0.453841\n",
      "epoch 170; iter: 0; batch classifier loss: 0.089377; batch adversarial loss: 0.561580\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038433; batch adversarial loss: 0.369539\n",
      "epoch 172; iter: 0; batch classifier loss: 0.053521; batch adversarial loss: 0.513563\n",
      "epoch 173; iter: 0; batch classifier loss: 0.046306; batch adversarial loss: 0.458154\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018785; batch adversarial loss: 0.406221\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023862; batch adversarial loss: 0.395450\n",
      "epoch 176; iter: 0; batch classifier loss: 0.057871; batch adversarial loss: 0.474983\n",
      "epoch 177; iter: 0; batch classifier loss: 0.044627; batch adversarial loss: 0.461789\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015716; batch adversarial loss: 0.381487\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013724; batch adversarial loss: 0.473396\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028641; batch adversarial loss: 0.371335\n",
      "epoch 181; iter: 0; batch classifier loss: 0.050613; batch adversarial loss: 0.442785\n",
      "epoch 182; iter: 0; batch classifier loss: 0.048799; batch adversarial loss: 0.416398\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042557; batch adversarial loss: 0.442627\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031122; batch adversarial loss: 0.519334\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038777; batch adversarial loss: 0.417427\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024968; batch adversarial loss: 0.405978\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035826; batch adversarial loss: 0.481019\n",
      "epoch 188; iter: 0; batch classifier loss: 0.044118; batch adversarial loss: 0.443608\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011235; batch adversarial loss: 0.408355\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020306; batch adversarial loss: 0.443906\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026739; batch adversarial loss: 0.411407\n",
      "epoch 192; iter: 0; batch classifier loss: 0.043462; batch adversarial loss: 0.450938\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028425; batch adversarial loss: 0.401258\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025100; batch adversarial loss: 0.429739\n",
      "epoch 195; iter: 0; batch classifier loss: 0.055163; batch adversarial loss: 0.491402\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024243; batch adversarial loss: 0.361879\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026458; batch adversarial loss: 0.400263\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023399; batch adversarial loss: 0.481153\n",
      "epoch 199; iter: 0; batch classifier loss: 0.045239; batch adversarial loss: 0.539599\n",
      "epoch 0; iter: 0; batch classifier loss: 0.661560; batch adversarial loss: 0.515128\n",
      "epoch 1; iter: 0; batch classifier loss: 0.408215; batch adversarial loss: 0.568398\n",
      "epoch 2; iter: 0; batch classifier loss: 0.392487; batch adversarial loss: 0.534957\n",
      "epoch 3; iter: 0; batch classifier loss: 0.398842; batch adversarial loss: 0.576308\n",
      "epoch 4; iter: 0; batch classifier loss: 0.279553; batch adversarial loss: 0.564635\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343227; batch adversarial loss: 0.602404\n",
      "epoch 6; iter: 0; batch classifier loss: 0.374074; batch adversarial loss: 0.629176\n",
      "epoch 7; iter: 0; batch classifier loss: 0.486608; batch adversarial loss: 0.601358\n",
      "epoch 8; iter: 0; batch classifier loss: 0.437955; batch adversarial loss: 0.542456\n",
      "epoch 9; iter: 0; batch classifier loss: 0.438507; batch adversarial loss: 0.618543\n",
      "epoch 10; iter: 0; batch classifier loss: 0.612465; batch adversarial loss: 0.595610\n",
      "epoch 11; iter: 0; batch classifier loss: 0.516980; batch adversarial loss: 0.541356\n",
      "epoch 12; iter: 0; batch classifier loss: 0.421806; batch adversarial loss: 0.542008\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373224; batch adversarial loss: 0.577507\n",
      "epoch 14; iter: 0; batch classifier loss: 0.222781; batch adversarial loss: 0.513996\n",
      "epoch 15; iter: 0; batch classifier loss: 0.226798; batch adversarial loss: 0.510440\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242008; batch adversarial loss: 0.550424\n",
      "epoch 17; iter: 0; batch classifier loss: 0.235951; batch adversarial loss: 0.522430\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214968; batch adversarial loss: 0.490402\n",
      "epoch 19; iter: 0; batch classifier loss: 0.201105; batch adversarial loss: 0.431187\n",
      "epoch 20; iter: 0; batch classifier loss: 0.299094; batch adversarial loss: 0.440494\n",
      "epoch 21; iter: 0; batch classifier loss: 0.221006; batch adversarial loss: 0.556657\n",
      "epoch 22; iter: 0; batch classifier loss: 0.150176; batch adversarial loss: 0.505670\n",
      "epoch 23; iter: 0; batch classifier loss: 0.150971; batch adversarial loss: 0.430959\n",
      "epoch 24; iter: 0; batch classifier loss: 0.231607; batch adversarial loss: 0.549588\n",
      "epoch 25; iter: 0; batch classifier loss: 0.126602; batch adversarial loss: 0.456445\n",
      "epoch 26; iter: 0; batch classifier loss: 0.198323; batch adversarial loss: 0.458024\n",
      "epoch 27; iter: 0; batch classifier loss: 0.251943; batch adversarial loss: 0.474394\n",
      "epoch 28; iter: 0; batch classifier loss: 0.209740; batch adversarial loss: 0.519083\n",
      "epoch 29; iter: 0; batch classifier loss: 0.183581; batch adversarial loss: 0.450634\n",
      "epoch 30; iter: 0; batch classifier loss: 0.135235; batch adversarial loss: 0.547168\n",
      "epoch 31; iter: 0; batch classifier loss: 0.175285; batch adversarial loss: 0.458985\n",
      "epoch 32; iter: 0; batch classifier loss: 0.160492; batch adversarial loss: 0.439283\n",
      "epoch 33; iter: 0; batch classifier loss: 0.160379; batch adversarial loss: 0.505730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.168239; batch adversarial loss: 0.421561\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140261; batch adversarial loss: 0.401702\n",
      "epoch 36; iter: 0; batch classifier loss: 0.152298; batch adversarial loss: 0.525279\n",
      "epoch 37; iter: 0; batch classifier loss: 0.178452; batch adversarial loss: 0.347976\n",
      "epoch 38; iter: 0; batch classifier loss: 0.166097; batch adversarial loss: 0.478731\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106523; batch adversarial loss: 0.474638\n",
      "epoch 40; iter: 0; batch classifier loss: 0.276386; batch adversarial loss: 0.425140\n",
      "epoch 41; iter: 0; batch classifier loss: 0.155825; batch adversarial loss: 0.516208\n",
      "epoch 42; iter: 0; batch classifier loss: 0.153373; batch adversarial loss: 0.408748\n",
      "epoch 43; iter: 0; batch classifier loss: 0.173515; batch adversarial loss: 0.417337\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112853; batch adversarial loss: 0.491359\n",
      "epoch 45; iter: 0; batch classifier loss: 0.144474; batch adversarial loss: 0.515389\n",
      "epoch 46; iter: 0; batch classifier loss: 0.181725; batch adversarial loss: 0.451340\n",
      "epoch 47; iter: 0; batch classifier loss: 0.190630; batch adversarial loss: 0.526125\n",
      "epoch 48; iter: 0; batch classifier loss: 0.163130; batch adversarial loss: 0.453812\n",
      "epoch 49; iter: 0; batch classifier loss: 0.164485; batch adversarial loss: 0.459629\n",
      "epoch 50; iter: 0; batch classifier loss: 0.253742; batch adversarial loss: 0.394726\n",
      "epoch 51; iter: 0; batch classifier loss: 0.169406; batch adversarial loss: 0.464560\n",
      "epoch 52; iter: 0; batch classifier loss: 0.213953; batch adversarial loss: 0.493947\n",
      "epoch 53; iter: 0; batch classifier loss: 0.189072; batch adversarial loss: 0.457523\n",
      "epoch 54; iter: 0; batch classifier loss: 0.306213; batch adversarial loss: 0.445075\n",
      "epoch 55; iter: 0; batch classifier loss: 0.210256; batch adversarial loss: 0.412510\n",
      "epoch 56; iter: 0; batch classifier loss: 0.167691; batch adversarial loss: 0.459965\n",
      "epoch 57; iter: 0; batch classifier loss: 0.164824; batch adversarial loss: 0.550930\n",
      "epoch 58; iter: 0; batch classifier loss: 0.193564; batch adversarial loss: 0.472837\n",
      "epoch 59; iter: 0; batch classifier loss: 0.225411; batch adversarial loss: 0.416102\n",
      "epoch 60; iter: 0; batch classifier loss: 0.216981; batch adversarial loss: 0.482087\n",
      "epoch 61; iter: 0; batch classifier loss: 0.226218; batch adversarial loss: 0.577288\n",
      "epoch 62; iter: 0; batch classifier loss: 0.235320; batch adversarial loss: 0.398148\n",
      "epoch 63; iter: 0; batch classifier loss: 0.149035; batch adversarial loss: 0.483530\n",
      "epoch 64; iter: 0; batch classifier loss: 0.242695; batch adversarial loss: 0.542560\n",
      "epoch 65; iter: 0; batch classifier loss: 0.266267; batch adversarial loss: 0.589518\n",
      "epoch 66; iter: 0; batch classifier loss: 0.197963; batch adversarial loss: 0.399661\n",
      "epoch 67; iter: 0; batch classifier loss: 0.250676; batch adversarial loss: 0.435000\n",
      "epoch 68; iter: 0; batch classifier loss: 0.146309; batch adversarial loss: 0.471169\n",
      "epoch 69; iter: 0; batch classifier loss: 0.220937; batch adversarial loss: 0.518971\n",
      "epoch 70; iter: 0; batch classifier loss: 0.221312; batch adversarial loss: 0.458392\n",
      "epoch 71; iter: 0; batch classifier loss: 0.246710; batch adversarial loss: 0.555056\n",
      "epoch 72; iter: 0; batch classifier loss: 0.149458; batch adversarial loss: 0.508048\n",
      "epoch 73; iter: 0; batch classifier loss: 0.100819; batch adversarial loss: 0.408685\n",
      "epoch 74; iter: 0; batch classifier loss: 0.219715; batch adversarial loss: 0.447435\n",
      "epoch 75; iter: 0; batch classifier loss: 0.181541; batch adversarial loss: 0.448633\n",
      "epoch 76; iter: 0; batch classifier loss: 0.119093; batch adversarial loss: 0.493419\n",
      "epoch 77; iter: 0; batch classifier loss: 0.211283; batch adversarial loss: 0.481600\n",
      "epoch 78; iter: 0; batch classifier loss: 0.184261; batch adversarial loss: 0.486036\n",
      "epoch 79; iter: 0; batch classifier loss: 0.217314; batch adversarial loss: 0.483621\n",
      "epoch 80; iter: 0; batch classifier loss: 0.174034; batch adversarial loss: 0.471273\n",
      "epoch 81; iter: 0; batch classifier loss: 0.202772; batch adversarial loss: 0.495083\n",
      "epoch 82; iter: 0; batch classifier loss: 0.160257; batch adversarial loss: 0.495427\n",
      "epoch 83; iter: 0; batch classifier loss: 0.172868; batch adversarial loss: 0.495299\n",
      "epoch 84; iter: 0; batch classifier loss: 0.153374; batch adversarial loss: 0.373635\n",
      "epoch 85; iter: 0; batch classifier loss: 0.199989; batch adversarial loss: 0.556822\n",
      "epoch 86; iter: 0; batch classifier loss: 0.177558; batch adversarial loss: 0.410880\n",
      "epoch 87; iter: 0; batch classifier loss: 0.305312; batch adversarial loss: 0.446754\n",
      "epoch 88; iter: 0; batch classifier loss: 0.250347; batch adversarial loss: 0.483361\n",
      "epoch 89; iter: 0; batch classifier loss: 0.176189; batch adversarial loss: 0.398865\n",
      "epoch 90; iter: 0; batch classifier loss: 0.112175; batch adversarial loss: 0.458714\n",
      "epoch 91; iter: 0; batch classifier loss: 0.103185; batch adversarial loss: 0.422120\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060543; batch adversarial loss: 0.359194\n",
      "epoch 93; iter: 0; batch classifier loss: 0.102928; batch adversarial loss: 0.427336\n",
      "epoch 94; iter: 0; batch classifier loss: 0.057622; batch adversarial loss: 0.502116\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057968; batch adversarial loss: 0.478014\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058998; batch adversarial loss: 0.411064\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064829; batch adversarial loss: 0.396843\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061990; batch adversarial loss: 0.538930\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054928; batch adversarial loss: 0.463312\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059702; batch adversarial loss: 0.481022\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068576; batch adversarial loss: 0.493440\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058439; batch adversarial loss: 0.473866\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062679; batch adversarial loss: 0.474531\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073094; batch adversarial loss: 0.498435\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055450; batch adversarial loss: 0.415610\n",
      "epoch 106; iter: 0; batch classifier loss: 0.090071; batch adversarial loss: 0.456181\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036176; batch adversarial loss: 0.442379\n",
      "epoch 108; iter: 0; batch classifier loss: 0.071008; batch adversarial loss: 0.418750\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058012; batch adversarial loss: 0.469581\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065167; batch adversarial loss: 0.432288\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039877; batch adversarial loss: 0.466157\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052027; batch adversarial loss: 0.397390\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044096; batch adversarial loss: 0.414646\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052223; batch adversarial loss: 0.475752\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046396; batch adversarial loss: 0.490152\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052395; batch adversarial loss: 0.443139\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061987; batch adversarial loss: 0.393838\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048733; batch adversarial loss: 0.454040\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057837; batch adversarial loss: 0.426334\n",
      "epoch 120; iter: 0; batch classifier loss: 0.052881; batch adversarial loss: 0.500883\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024491; batch adversarial loss: 0.434755\n",
      "epoch 122; iter: 0; batch classifier loss: 0.061886; batch adversarial loss: 0.624612\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047720; batch adversarial loss: 0.414334\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055582; batch adversarial loss: 0.479201\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040283; batch adversarial loss: 0.434426\n",
      "epoch 126; iter: 0; batch classifier loss: 0.073708; batch adversarial loss: 0.439407\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030035; batch adversarial loss: 0.482362\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047520; batch adversarial loss: 0.331220\n",
      "epoch 129; iter: 0; batch classifier loss: 0.068130; batch adversarial loss: 0.405186\n",
      "epoch 130; iter: 0; batch classifier loss: 0.054824; batch adversarial loss: 0.467707\n",
      "epoch 131; iter: 0; batch classifier loss: 0.060811; batch adversarial loss: 0.420507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.061058; batch adversarial loss: 0.533408\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036439; batch adversarial loss: 0.482609\n",
      "epoch 134; iter: 0; batch classifier loss: 0.060445; batch adversarial loss: 0.464127\n",
      "epoch 135; iter: 0; batch classifier loss: 0.052834; batch adversarial loss: 0.388870\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022617; batch adversarial loss: 0.421372\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036723; batch adversarial loss: 0.422528\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021373; batch adversarial loss: 0.549805\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041661; batch adversarial loss: 0.459608\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019182; batch adversarial loss: 0.454303\n",
      "epoch 141; iter: 0; batch classifier loss: 0.055636; batch adversarial loss: 0.494359\n",
      "epoch 142; iter: 0; batch classifier loss: 0.078665; batch adversarial loss: 0.489642\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014483; batch adversarial loss: 0.459741\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047392; batch adversarial loss: 0.446186\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043139; batch adversarial loss: 0.486959\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019553; batch adversarial loss: 0.492018\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031062; batch adversarial loss: 0.476573\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032335; batch adversarial loss: 0.502357\n",
      "epoch 149; iter: 0; batch classifier loss: 0.043639; batch adversarial loss: 0.481343\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044558; batch adversarial loss: 0.359150\n",
      "epoch 151; iter: 0; batch classifier loss: 0.060485; batch adversarial loss: 0.403093\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035804; batch adversarial loss: 0.361478\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013057; batch adversarial loss: 0.405096\n",
      "epoch 154; iter: 0; batch classifier loss: 0.053411; batch adversarial loss: 0.400008\n",
      "epoch 155; iter: 0; batch classifier loss: 0.069361; batch adversarial loss: 0.427795\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033859; batch adversarial loss: 0.436722\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012338; batch adversarial loss: 0.501095\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038438; batch adversarial loss: 0.572568\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034175; batch adversarial loss: 0.366148\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015368; batch adversarial loss: 0.387325\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012743; batch adversarial loss: 0.466567\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038172; batch adversarial loss: 0.518336\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032244; batch adversarial loss: 0.386610\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026741; batch adversarial loss: 0.416450\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022060; batch adversarial loss: 0.495519\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023228; batch adversarial loss: 0.530691\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017208; batch adversarial loss: 0.479445\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029773; batch adversarial loss: 0.403001\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015919; batch adversarial loss: 0.403324\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037693; batch adversarial loss: 0.464944\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028726; batch adversarial loss: 0.537549\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020955; batch adversarial loss: 0.493260\n",
      "epoch 173; iter: 0; batch classifier loss: 0.046732; batch adversarial loss: 0.460495\n",
      "epoch 174; iter: 0; batch classifier loss: 0.057411; batch adversarial loss: 0.461681\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017363; batch adversarial loss: 0.390266\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034397; batch adversarial loss: 0.531307\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029928; batch adversarial loss: 0.382450\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015211; batch adversarial loss: 0.476622\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038724; batch adversarial loss: 0.469362\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025909; batch adversarial loss: 0.517199\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021820; batch adversarial loss: 0.462510\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008571; batch adversarial loss: 0.483464\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032155; batch adversarial loss: 0.429766\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031965; batch adversarial loss: 0.566506\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021435; batch adversarial loss: 0.528167\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010141; batch adversarial loss: 0.399963\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020464; batch adversarial loss: 0.481491\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020402; batch adversarial loss: 0.488881\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015880; batch adversarial loss: 0.385856\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036785; batch adversarial loss: 0.490639\n",
      "epoch 191; iter: 0; batch classifier loss: 0.041775; batch adversarial loss: 0.441135\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019660; batch adversarial loss: 0.389235\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008985; batch adversarial loss: 0.472562\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019415; batch adversarial loss: 0.444505\n",
      "epoch 195; iter: 0; batch classifier loss: 0.038578; batch adversarial loss: 0.436409\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019001; batch adversarial loss: 0.517476\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026803; batch adversarial loss: 0.417154\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019859; batch adversarial loss: 0.416816\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009593; batch adversarial loss: 0.379787\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693505; batch adversarial loss: 0.577130\n",
      "epoch 1; iter: 0; batch classifier loss: 0.425509; batch adversarial loss: 0.608046\n",
      "epoch 2; iter: 0; batch classifier loss: 0.404125; batch adversarial loss: 0.542790\n",
      "epoch 3; iter: 0; batch classifier loss: 0.353577; batch adversarial loss: 0.606644\n",
      "epoch 4; iter: 0; batch classifier loss: 0.374686; batch adversarial loss: 0.564336\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362209; batch adversarial loss: 0.514575\n",
      "epoch 6; iter: 0; batch classifier loss: 0.312739; batch adversarial loss: 0.535646\n",
      "epoch 7; iter: 0; batch classifier loss: 0.350906; batch adversarial loss: 0.586420\n",
      "epoch 8; iter: 0; batch classifier loss: 0.426520; batch adversarial loss: 0.509195\n",
      "epoch 9; iter: 0; batch classifier loss: 0.394144; batch adversarial loss: 0.551072\n",
      "epoch 10; iter: 0; batch classifier loss: 0.293365; batch adversarial loss: 0.542198\n",
      "epoch 11; iter: 0; batch classifier loss: 0.359414; batch adversarial loss: 0.481362\n",
      "epoch 12; iter: 0; batch classifier loss: 0.273811; batch adversarial loss: 0.516730\n",
      "epoch 13; iter: 0; batch classifier loss: 0.198124; batch adversarial loss: 0.464977\n",
      "epoch 14; iter: 0; batch classifier loss: 0.220070; batch adversarial loss: 0.475926\n",
      "epoch 15; iter: 0; batch classifier loss: 0.254208; batch adversarial loss: 0.473607\n",
      "epoch 16; iter: 0; batch classifier loss: 0.316339; batch adversarial loss: 0.439070\n",
      "epoch 17; iter: 0; batch classifier loss: 0.218316; batch adversarial loss: 0.444613\n",
      "epoch 18; iter: 0; batch classifier loss: 0.236613; batch adversarial loss: 0.472761\n",
      "epoch 19; iter: 0; batch classifier loss: 0.252232; batch adversarial loss: 0.495838\n",
      "epoch 20; iter: 0; batch classifier loss: 0.163636; batch adversarial loss: 0.442257\n",
      "epoch 21; iter: 0; batch classifier loss: 0.178589; batch adversarial loss: 0.483645\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224999; batch adversarial loss: 0.443609\n",
      "epoch 23; iter: 0; batch classifier loss: 0.160741; batch adversarial loss: 0.473406\n",
      "epoch 24; iter: 0; batch classifier loss: 0.160928; batch adversarial loss: 0.403615\n",
      "epoch 25; iter: 0; batch classifier loss: 0.205203; batch adversarial loss: 0.496034\n",
      "epoch 26; iter: 0; batch classifier loss: 0.178295; batch adversarial loss: 0.357985\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171529; batch adversarial loss: 0.438648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.093078; batch adversarial loss: 0.471821\n",
      "epoch 29; iter: 0; batch classifier loss: 0.101286; batch adversarial loss: 0.488243\n",
      "epoch 30; iter: 0; batch classifier loss: 0.140710; batch adversarial loss: 0.444341\n",
      "epoch 31; iter: 0; batch classifier loss: 0.129700; batch adversarial loss: 0.596063\n",
      "epoch 32; iter: 0; batch classifier loss: 0.223245; batch adversarial loss: 0.460706\n",
      "epoch 33; iter: 0; batch classifier loss: 0.150741; batch adversarial loss: 0.511711\n",
      "epoch 34; iter: 0; batch classifier loss: 0.140628; batch adversarial loss: 0.501522\n",
      "epoch 35; iter: 0; batch classifier loss: 0.094179; batch adversarial loss: 0.413475\n",
      "epoch 36; iter: 0; batch classifier loss: 0.135552; batch adversarial loss: 0.376602\n",
      "epoch 37; iter: 0; batch classifier loss: 0.163098; batch adversarial loss: 0.405609\n",
      "epoch 38; iter: 0; batch classifier loss: 0.138443; batch adversarial loss: 0.444378\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143719; batch adversarial loss: 0.437226\n",
      "epoch 40; iter: 0; batch classifier loss: 0.183615; batch adversarial loss: 0.365794\n",
      "epoch 41; iter: 0; batch classifier loss: 0.102889; batch adversarial loss: 0.404009\n",
      "epoch 42; iter: 0; batch classifier loss: 0.079395; batch adversarial loss: 0.472198\n",
      "epoch 43; iter: 0; batch classifier loss: 0.122524; batch adversarial loss: 0.451984\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124910; batch adversarial loss: 0.481881\n",
      "epoch 45; iter: 0; batch classifier loss: 0.085981; batch adversarial loss: 0.406432\n",
      "epoch 46; iter: 0; batch classifier loss: 0.100709; batch adversarial loss: 0.479175\n",
      "epoch 47; iter: 0; batch classifier loss: 0.123119; batch adversarial loss: 0.429224\n",
      "epoch 48; iter: 0; batch classifier loss: 0.090302; batch adversarial loss: 0.509045\n",
      "epoch 49; iter: 0; batch classifier loss: 0.155009; batch adversarial loss: 0.450065\n",
      "epoch 50; iter: 0; batch classifier loss: 0.090781; batch adversarial loss: 0.496895\n",
      "epoch 51; iter: 0; batch classifier loss: 0.078872; batch adversarial loss: 0.505253\n",
      "epoch 52; iter: 0; batch classifier loss: 0.104639; batch adversarial loss: 0.428140\n",
      "epoch 53; iter: 0; batch classifier loss: 0.124817; batch adversarial loss: 0.498428\n",
      "epoch 54; iter: 0; batch classifier loss: 0.089207; batch adversarial loss: 0.406664\n",
      "epoch 55; iter: 0; batch classifier loss: 0.150088; batch adversarial loss: 0.534878\n",
      "epoch 56; iter: 0; batch classifier loss: 0.117331; batch adversarial loss: 0.419053\n",
      "epoch 57; iter: 0; batch classifier loss: 0.121004; batch adversarial loss: 0.406448\n",
      "epoch 58; iter: 0; batch classifier loss: 0.045695; batch adversarial loss: 0.527420\n",
      "epoch 59; iter: 0; batch classifier loss: 0.120929; batch adversarial loss: 0.429755\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076918; batch adversarial loss: 0.493541\n",
      "epoch 61; iter: 0; batch classifier loss: 0.137261; batch adversarial loss: 0.346363\n",
      "epoch 62; iter: 0; batch classifier loss: 0.134739; batch adversarial loss: 0.475716\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076971; batch adversarial loss: 0.462760\n",
      "epoch 64; iter: 0; batch classifier loss: 0.130375; batch adversarial loss: 0.513095\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065814; batch adversarial loss: 0.418736\n",
      "epoch 66; iter: 0; batch classifier loss: 0.109359; batch adversarial loss: 0.458089\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110878; batch adversarial loss: 0.529706\n",
      "epoch 68; iter: 0; batch classifier loss: 0.099404; batch adversarial loss: 0.409232\n",
      "epoch 69; iter: 0; batch classifier loss: 0.149919; batch adversarial loss: 0.437959\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091962; batch adversarial loss: 0.443233\n",
      "epoch 71; iter: 0; batch classifier loss: 0.164463; batch adversarial loss: 0.385501\n",
      "epoch 72; iter: 0; batch classifier loss: 0.109181; batch adversarial loss: 0.494102\n",
      "epoch 73; iter: 0; batch classifier loss: 0.098007; batch adversarial loss: 0.502811\n",
      "epoch 74; iter: 0; batch classifier loss: 0.098546; batch adversarial loss: 0.473985\n",
      "epoch 75; iter: 0; batch classifier loss: 0.094664; batch adversarial loss: 0.431973\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103771; batch adversarial loss: 0.428186\n",
      "epoch 77; iter: 0; batch classifier loss: 0.105795; batch adversarial loss: 0.450460\n",
      "epoch 78; iter: 0; batch classifier loss: 0.122352; batch adversarial loss: 0.481915\n",
      "epoch 79; iter: 0; batch classifier loss: 0.042142; batch adversarial loss: 0.465116\n",
      "epoch 80; iter: 0; batch classifier loss: 0.097071; batch adversarial loss: 0.467885\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077752; batch adversarial loss: 0.543195\n",
      "epoch 82; iter: 0; batch classifier loss: 0.099095; batch adversarial loss: 0.509426\n",
      "epoch 83; iter: 0; batch classifier loss: 0.091799; batch adversarial loss: 0.445618\n",
      "epoch 84; iter: 0; batch classifier loss: 0.164670; batch adversarial loss: 0.387663\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074517; batch adversarial loss: 0.461925\n",
      "epoch 86; iter: 0; batch classifier loss: 0.116235; batch adversarial loss: 0.418473\n",
      "epoch 87; iter: 0; batch classifier loss: 0.112300; batch adversarial loss: 0.429845\n",
      "epoch 88; iter: 0; batch classifier loss: 0.143819; batch adversarial loss: 0.581935\n",
      "epoch 89; iter: 0; batch classifier loss: 0.064097; batch adversarial loss: 0.543281\n",
      "epoch 90; iter: 0; batch classifier loss: 0.089087; batch adversarial loss: 0.472246\n",
      "epoch 91; iter: 0; batch classifier loss: 0.089175; batch adversarial loss: 0.487508\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050857; batch adversarial loss: 0.412759\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039540; batch adversarial loss: 0.488759\n",
      "epoch 94; iter: 0; batch classifier loss: 0.102690; batch adversarial loss: 0.456578\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065058; batch adversarial loss: 0.476852\n",
      "epoch 96; iter: 0; batch classifier loss: 0.085028; batch adversarial loss: 0.479315\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039788; batch adversarial loss: 0.362595\n",
      "epoch 98; iter: 0; batch classifier loss: 0.071742; batch adversarial loss: 0.523006\n",
      "epoch 99; iter: 0; batch classifier loss: 0.066491; batch adversarial loss: 0.534072\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037185; batch adversarial loss: 0.410026\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049745; batch adversarial loss: 0.550211\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060911; batch adversarial loss: 0.496548\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042853; batch adversarial loss: 0.446155\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069208; batch adversarial loss: 0.513031\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061136; batch adversarial loss: 0.428944\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062340; batch adversarial loss: 0.524492\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046527; batch adversarial loss: 0.493953\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052229; batch adversarial loss: 0.404452\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036333; batch adversarial loss: 0.494579\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047692; batch adversarial loss: 0.504658\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031592; batch adversarial loss: 0.472373\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032233; batch adversarial loss: 0.518746\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063386; batch adversarial loss: 0.472184\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044999; batch adversarial loss: 0.534162\n",
      "epoch 115; iter: 0; batch classifier loss: 0.064807; batch adversarial loss: 0.428433\n",
      "epoch 116; iter: 0; batch classifier loss: 0.074134; batch adversarial loss: 0.495738\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037823; batch adversarial loss: 0.482174\n",
      "epoch 118; iter: 0; batch classifier loss: 0.027482; batch adversarial loss: 0.492798\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036958; batch adversarial loss: 0.381665\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046099; batch adversarial loss: 0.455608\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040650; batch adversarial loss: 0.464190\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042840; batch adversarial loss: 0.523558\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023165; batch adversarial loss: 0.466089\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050528; batch adversarial loss: 0.399675\n",
      "epoch 125; iter: 0; batch classifier loss: 0.077042; batch adversarial loss: 0.556272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.039004; batch adversarial loss: 0.561633\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027681; batch adversarial loss: 0.446843\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037462; batch adversarial loss: 0.416176\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047807; batch adversarial loss: 0.440614\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037000; batch adversarial loss: 0.449081\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029052; batch adversarial loss: 0.449386\n",
      "epoch 132; iter: 0; batch classifier loss: 0.009550; batch adversarial loss: 0.550944\n",
      "epoch 133; iter: 0; batch classifier loss: 0.017478; batch adversarial loss: 0.342340\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017368; batch adversarial loss: 0.406257\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020963; batch adversarial loss: 0.393358\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032608; batch adversarial loss: 0.511664\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043083; batch adversarial loss: 0.451916\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011818; batch adversarial loss: 0.423696\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024688; batch adversarial loss: 0.499572\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019393; batch adversarial loss: 0.434443\n",
      "epoch 141; iter: 0; batch classifier loss: 0.069742; batch adversarial loss: 0.491050\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020720; batch adversarial loss: 0.537345\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033366; batch adversarial loss: 0.338752\n",
      "epoch 144; iter: 0; batch classifier loss: 0.058109; batch adversarial loss: 0.427502\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017823; batch adversarial loss: 0.451919\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039209; batch adversarial loss: 0.444426\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021894; batch adversarial loss: 0.420150\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017743; batch adversarial loss: 0.498947\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053976; batch adversarial loss: 0.427924\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029640; batch adversarial loss: 0.462523\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027536; batch adversarial loss: 0.484576\n",
      "epoch 152; iter: 0; batch classifier loss: 0.047519; batch adversarial loss: 0.403872\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027584; batch adversarial loss: 0.480120\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026523; batch adversarial loss: 0.409214\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020435; batch adversarial loss: 0.452110\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022409; batch adversarial loss: 0.517359\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024296; batch adversarial loss: 0.502589\n",
      "epoch 158; iter: 0; batch classifier loss: 0.041673; batch adversarial loss: 0.436102\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029027; batch adversarial loss: 0.443557\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036568; batch adversarial loss: 0.463177\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017164; batch adversarial loss: 0.399921\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026953; batch adversarial loss: 0.515321\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036931; batch adversarial loss: 0.517168\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031096; batch adversarial loss: 0.439976\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027781; batch adversarial loss: 0.450881\n",
      "epoch 166; iter: 0; batch classifier loss: 0.006850; batch adversarial loss: 0.491442\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034448; batch adversarial loss: 0.545383\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032917; batch adversarial loss: 0.353457\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032867; batch adversarial loss: 0.517494\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021950; batch adversarial loss: 0.447353\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007846; batch adversarial loss: 0.451484\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029536; batch adversarial loss: 0.427254\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023767; batch adversarial loss: 0.551986\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017471; batch adversarial loss: 0.493866\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014654; batch adversarial loss: 0.431196\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022968; batch adversarial loss: 0.486280\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016721; batch adversarial loss: 0.491089\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033953; batch adversarial loss: 0.494391\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011299; batch adversarial loss: 0.576533\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017174; batch adversarial loss: 0.460413\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025362; batch adversarial loss: 0.540317\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017442; batch adversarial loss: 0.457296\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024343; batch adversarial loss: 0.413967\n",
      "epoch 184; iter: 0; batch classifier loss: 0.057626; batch adversarial loss: 0.489492\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029573; batch adversarial loss: 0.452495\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022920; batch adversarial loss: 0.436625\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011902; batch adversarial loss: 0.441001\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007897; batch adversarial loss: 0.473998\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019846; batch adversarial loss: 0.402392\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029147; batch adversarial loss: 0.396009\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019718; batch adversarial loss: 0.386217\n",
      "epoch 192; iter: 0; batch classifier loss: 0.045981; batch adversarial loss: 0.496224\n",
      "epoch 193; iter: 0; batch classifier loss: 0.047190; batch adversarial loss: 0.605754\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025242; batch adversarial loss: 0.426950\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019026; batch adversarial loss: 0.440727\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030171; batch adversarial loss: 0.509799\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015121; batch adversarial loss: 0.517960\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037075; batch adversarial loss: 0.536142\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020095; batch adversarial loss: 0.440122\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695166; batch adversarial loss: 0.702592\n",
      "epoch 1; iter: 0; batch classifier loss: 0.472166; batch adversarial loss: 0.641827\n",
      "epoch 2; iter: 0; batch classifier loss: 0.413429; batch adversarial loss: 0.691527\n",
      "epoch 3; iter: 0; batch classifier loss: 0.293800; batch adversarial loss: 0.560058\n",
      "epoch 4; iter: 0; batch classifier loss: 0.295470; batch adversarial loss: 0.598957\n",
      "epoch 5; iter: 0; batch classifier loss: 0.375881; batch adversarial loss: 0.538524\n",
      "epoch 6; iter: 0; batch classifier loss: 0.319952; batch adversarial loss: 0.559089\n",
      "epoch 7; iter: 0; batch classifier loss: 0.245700; batch adversarial loss: 0.537887\n",
      "epoch 8; iter: 0; batch classifier loss: 0.335014; batch adversarial loss: 0.466583\n",
      "epoch 9; iter: 0; batch classifier loss: 0.236080; batch adversarial loss: 0.535013\n",
      "epoch 10; iter: 0; batch classifier loss: 0.280589; batch adversarial loss: 0.527104\n",
      "epoch 11; iter: 0; batch classifier loss: 0.209114; batch adversarial loss: 0.476708\n",
      "epoch 12; iter: 0; batch classifier loss: 0.215966; batch adversarial loss: 0.564576\n",
      "epoch 13; iter: 0; batch classifier loss: 0.198237; batch adversarial loss: 0.573725\n",
      "epoch 14; iter: 0; batch classifier loss: 0.296999; batch adversarial loss: 0.478503\n",
      "epoch 15; iter: 0; batch classifier loss: 0.165777; batch adversarial loss: 0.524526\n",
      "epoch 16; iter: 0; batch classifier loss: 0.268539; batch adversarial loss: 0.518637\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217547; batch adversarial loss: 0.525335\n",
      "epoch 18; iter: 0; batch classifier loss: 0.248266; batch adversarial loss: 0.586679\n",
      "epoch 19; iter: 0; batch classifier loss: 0.227019; batch adversarial loss: 0.471504\n",
      "epoch 20; iter: 0; batch classifier loss: 0.170326; batch adversarial loss: 0.430511\n",
      "epoch 21; iter: 0; batch classifier loss: 0.174901; batch adversarial loss: 0.459333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.153056; batch adversarial loss: 0.446014\n",
      "epoch 23; iter: 0; batch classifier loss: 0.139510; batch adversarial loss: 0.419479\n",
      "epoch 24; iter: 0; batch classifier loss: 0.171270; batch adversarial loss: 0.473075\n",
      "epoch 25; iter: 0; batch classifier loss: 0.146147; batch adversarial loss: 0.419924\n",
      "epoch 26; iter: 0; batch classifier loss: 0.160168; batch adversarial loss: 0.469009\n",
      "epoch 27; iter: 0; batch classifier loss: 0.123516; batch adversarial loss: 0.496172\n",
      "epoch 28; iter: 0; batch classifier loss: 0.175560; batch adversarial loss: 0.424958\n",
      "epoch 29; iter: 0; batch classifier loss: 0.165024; batch adversarial loss: 0.460131\n",
      "epoch 30; iter: 0; batch classifier loss: 0.159258; batch adversarial loss: 0.419360\n",
      "epoch 31; iter: 0; batch classifier loss: 0.144771; batch adversarial loss: 0.403778\n",
      "epoch 32; iter: 0; batch classifier loss: 0.163930; batch adversarial loss: 0.485714\n",
      "epoch 33; iter: 0; batch classifier loss: 0.115169; batch adversarial loss: 0.562955\n",
      "epoch 34; iter: 0; batch classifier loss: 0.132887; batch adversarial loss: 0.502763\n",
      "epoch 35; iter: 0; batch classifier loss: 0.147822; batch adversarial loss: 0.457397\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109286; batch adversarial loss: 0.461726\n",
      "epoch 37; iter: 0; batch classifier loss: 0.134105; batch adversarial loss: 0.405810\n",
      "epoch 38; iter: 0; batch classifier loss: 0.081525; batch adversarial loss: 0.562210\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126196; batch adversarial loss: 0.422561\n",
      "epoch 40; iter: 0; batch classifier loss: 0.088723; batch adversarial loss: 0.435961\n",
      "epoch 41; iter: 0; batch classifier loss: 0.127317; batch adversarial loss: 0.482211\n",
      "epoch 42; iter: 0; batch classifier loss: 0.062012; batch adversarial loss: 0.466165\n",
      "epoch 43; iter: 0; batch classifier loss: 0.099073; batch adversarial loss: 0.489749\n",
      "epoch 44; iter: 0; batch classifier loss: 0.083304; batch adversarial loss: 0.388411\n",
      "epoch 45; iter: 0; batch classifier loss: 0.130184; batch adversarial loss: 0.435370\n",
      "epoch 46; iter: 0; batch classifier loss: 0.141040; batch adversarial loss: 0.480776\n",
      "epoch 47; iter: 0; batch classifier loss: 0.116424; batch adversarial loss: 0.506000\n",
      "epoch 48; iter: 0; batch classifier loss: 0.087761; batch adversarial loss: 0.487284\n",
      "epoch 49; iter: 0; batch classifier loss: 0.121789; batch adversarial loss: 0.413854\n",
      "epoch 50; iter: 0; batch classifier loss: 0.116694; batch adversarial loss: 0.517749\n",
      "epoch 51; iter: 0; batch classifier loss: 0.107521; batch adversarial loss: 0.510290\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103285; batch adversarial loss: 0.412592\n",
      "epoch 53; iter: 0; batch classifier loss: 0.118365; batch adversarial loss: 0.416084\n",
      "epoch 54; iter: 0; batch classifier loss: 0.181917; batch adversarial loss: 0.397521\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083113; batch adversarial loss: 0.407818\n",
      "epoch 56; iter: 0; batch classifier loss: 0.133831; batch adversarial loss: 0.365213\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095632; batch adversarial loss: 0.519000\n",
      "epoch 58; iter: 0; batch classifier loss: 0.117541; batch adversarial loss: 0.452761\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070550; batch adversarial loss: 0.517647\n",
      "epoch 60; iter: 0; batch classifier loss: 0.093306; batch adversarial loss: 0.470805\n",
      "epoch 61; iter: 0; batch classifier loss: 0.122297; batch adversarial loss: 0.433512\n",
      "epoch 62; iter: 0; batch classifier loss: 0.095078; batch adversarial loss: 0.481320\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097533; batch adversarial loss: 0.440877\n",
      "epoch 64; iter: 0; batch classifier loss: 0.095179; batch adversarial loss: 0.421834\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092851; batch adversarial loss: 0.457990\n",
      "epoch 66; iter: 0; batch classifier loss: 0.115463; batch adversarial loss: 0.393976\n",
      "epoch 67; iter: 0; batch classifier loss: 0.092782; batch adversarial loss: 0.450631\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109752; batch adversarial loss: 0.545108\n",
      "epoch 69; iter: 0; batch classifier loss: 0.131989; batch adversarial loss: 0.536402\n",
      "epoch 70; iter: 0; batch classifier loss: 0.051680; batch adversarial loss: 0.475568\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097833; batch adversarial loss: 0.454418\n",
      "epoch 72; iter: 0; batch classifier loss: 0.089035; batch adversarial loss: 0.482221\n",
      "epoch 73; iter: 0; batch classifier loss: 0.136469; batch adversarial loss: 0.487718\n",
      "epoch 74; iter: 0; batch classifier loss: 0.068094; batch adversarial loss: 0.485357\n",
      "epoch 75; iter: 0; batch classifier loss: 0.088779; batch adversarial loss: 0.458988\n",
      "epoch 76; iter: 0; batch classifier loss: 0.098515; batch adversarial loss: 0.409323\n",
      "epoch 77; iter: 0; batch classifier loss: 0.086306; batch adversarial loss: 0.431876\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064802; batch adversarial loss: 0.541814\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065163; batch adversarial loss: 0.443114\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090137; batch adversarial loss: 0.511172\n",
      "epoch 81; iter: 0; batch classifier loss: 0.051347; batch adversarial loss: 0.551068\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071479; batch adversarial loss: 0.489665\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066895; batch adversarial loss: 0.498959\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067662; batch adversarial loss: 0.448237\n",
      "epoch 85; iter: 0; batch classifier loss: 0.103129; batch adversarial loss: 0.464057\n",
      "epoch 86; iter: 0; batch classifier loss: 0.075506; batch adversarial loss: 0.508011\n",
      "epoch 87; iter: 0; batch classifier loss: 0.075192; batch adversarial loss: 0.460171\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078399; batch adversarial loss: 0.508155\n",
      "epoch 89; iter: 0; batch classifier loss: 0.049007; batch adversarial loss: 0.588688\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060359; batch adversarial loss: 0.465413\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060424; batch adversarial loss: 0.527308\n",
      "epoch 92; iter: 0; batch classifier loss: 0.087873; batch adversarial loss: 0.504757\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054986; batch adversarial loss: 0.475517\n",
      "epoch 94; iter: 0; batch classifier loss: 0.040620; batch adversarial loss: 0.480878\n",
      "epoch 95; iter: 0; batch classifier loss: 0.069947; batch adversarial loss: 0.412076\n",
      "epoch 96; iter: 0; batch classifier loss: 0.040908; batch adversarial loss: 0.515318\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049594; batch adversarial loss: 0.478992\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052708; batch adversarial loss: 0.429238\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056570; batch adversarial loss: 0.493275\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062800; batch adversarial loss: 0.425657\n",
      "epoch 101; iter: 0; batch classifier loss: 0.035707; batch adversarial loss: 0.592115\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055434; batch adversarial loss: 0.415762\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062111; batch adversarial loss: 0.394813\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073274; batch adversarial loss: 0.405629\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052307; batch adversarial loss: 0.489317\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057921; batch adversarial loss: 0.445145\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031942; batch adversarial loss: 0.458947\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045717; batch adversarial loss: 0.432983\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041053; batch adversarial loss: 0.443509\n",
      "epoch 110; iter: 0; batch classifier loss: 0.070719; batch adversarial loss: 0.537161\n",
      "epoch 111; iter: 0; batch classifier loss: 0.015607; batch adversarial loss: 0.430749\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053492; batch adversarial loss: 0.401844\n",
      "epoch 113; iter: 0; batch classifier loss: 0.085587; batch adversarial loss: 0.592765\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059022; batch adversarial loss: 0.394572\n",
      "epoch 115; iter: 0; batch classifier loss: 0.090527; batch adversarial loss: 0.414040\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040364; batch adversarial loss: 0.478417\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031442; batch adversarial loss: 0.440784\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049181; batch adversarial loss: 0.473403\n",
      "epoch 119; iter: 0; batch classifier loss: 0.062280; batch adversarial loss: 0.452326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.026584; batch adversarial loss: 0.514749\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031442; batch adversarial loss: 0.502918\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026210; batch adversarial loss: 0.544135\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017461; batch adversarial loss: 0.499508\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022099; batch adversarial loss: 0.436039\n",
      "epoch 125; iter: 0; batch classifier loss: 0.059039; batch adversarial loss: 0.573083\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036161; batch adversarial loss: 0.455965\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034058; batch adversarial loss: 0.542054\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033124; batch adversarial loss: 0.487981\n",
      "epoch 129; iter: 0; batch classifier loss: 0.057041; batch adversarial loss: 0.523204\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018832; batch adversarial loss: 0.503774\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032066; batch adversarial loss: 0.431481\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014839; batch adversarial loss: 0.448332\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037022; batch adversarial loss: 0.479805\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025160; batch adversarial loss: 0.470654\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026453; batch adversarial loss: 0.391998\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043240; batch adversarial loss: 0.377603\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018142; batch adversarial loss: 0.459606\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029398; batch adversarial loss: 0.479140\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029036; batch adversarial loss: 0.396658\n",
      "epoch 140; iter: 0; batch classifier loss: 0.011655; batch adversarial loss: 0.374166\n",
      "epoch 141; iter: 0; batch classifier loss: 0.060301; batch adversarial loss: 0.495797\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032743; batch adversarial loss: 0.453871\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017272; batch adversarial loss: 0.475858\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025701; batch adversarial loss: 0.538408\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018398; batch adversarial loss: 0.384251\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011397; batch adversarial loss: 0.349013\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025393; batch adversarial loss: 0.506798\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017002; batch adversarial loss: 0.400089\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015865; batch adversarial loss: 0.448655\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040486; batch adversarial loss: 0.445580\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025265; batch adversarial loss: 0.505509\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030299; batch adversarial loss: 0.456370\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032576; batch adversarial loss: 0.475470\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032412; batch adversarial loss: 0.404104\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016707; batch adversarial loss: 0.440694\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010734; batch adversarial loss: 0.412138\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017164; batch adversarial loss: 0.541960\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023977; batch adversarial loss: 0.511919\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039579; batch adversarial loss: 0.519375\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025266; batch adversarial loss: 0.418679\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021425; batch adversarial loss: 0.397435\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028176; batch adversarial loss: 0.563554\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021632; batch adversarial loss: 0.440607\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016014; batch adversarial loss: 0.396169\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011647; batch adversarial loss: 0.433467\n",
      "epoch 166; iter: 0; batch classifier loss: 0.006631; batch adversarial loss: 0.523794\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010413; batch adversarial loss: 0.478788\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017386; batch adversarial loss: 0.472621\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021001; batch adversarial loss: 0.561878\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023049; batch adversarial loss: 0.450176\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018089; batch adversarial loss: 0.476128\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007475; batch adversarial loss: 0.450765\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024683; batch adversarial loss: 0.501799\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033240; batch adversarial loss: 0.377735\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011418; batch adversarial loss: 0.440419\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017727; batch adversarial loss: 0.475996\n",
      "epoch 177; iter: 0; batch classifier loss: 0.044189; batch adversarial loss: 0.426241\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011242; batch adversarial loss: 0.442500\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007614; batch adversarial loss: 0.391708\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014002; batch adversarial loss: 0.414611\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008383; batch adversarial loss: 0.528077\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027933; batch adversarial loss: 0.405747\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042226; batch adversarial loss: 0.480561\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007702; batch adversarial loss: 0.425482\n",
      "epoch 185; iter: 0; batch classifier loss: 0.002194; batch adversarial loss: 0.603799\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014444; batch adversarial loss: 0.519430\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011046; batch adversarial loss: 0.423303\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022802; batch adversarial loss: 0.402391\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004489; batch adversarial loss: 0.535705\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012962; batch adversarial loss: 0.453796\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006920; batch adversarial loss: 0.436159\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027221; batch adversarial loss: 0.396596\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010122; batch adversarial loss: 0.468144\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009279; batch adversarial loss: 0.540026\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021839; batch adversarial loss: 0.421018\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009933; batch adversarial loss: 0.471296\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018714; batch adversarial loss: 0.382649\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013298; batch adversarial loss: 0.406399\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009204; batch adversarial loss: 0.568125\n",
      "epoch 0; iter: 0; batch classifier loss: 0.665662; batch adversarial loss: 0.623639\n",
      "epoch 1; iter: 0; batch classifier loss: 0.346503; batch adversarial loss: 0.640323\n",
      "epoch 2; iter: 0; batch classifier loss: 0.310934; batch adversarial loss: 0.601506\n",
      "epoch 3; iter: 0; batch classifier loss: 0.363562; batch adversarial loss: 0.549630\n",
      "epoch 4; iter: 0; batch classifier loss: 0.297648; batch adversarial loss: 0.535853\n",
      "epoch 5; iter: 0; batch classifier loss: 0.277306; batch adversarial loss: 0.545591\n",
      "epoch 6; iter: 0; batch classifier loss: 0.282999; batch adversarial loss: 0.524640\n",
      "epoch 7; iter: 0; batch classifier loss: 0.274229; batch adversarial loss: 0.458385\n",
      "epoch 8; iter: 0; batch classifier loss: 0.306502; batch adversarial loss: 0.516942\n",
      "epoch 9; iter: 0; batch classifier loss: 0.245299; batch adversarial loss: 0.487611\n",
      "epoch 10; iter: 0; batch classifier loss: 0.259586; batch adversarial loss: 0.484011\n",
      "epoch 11; iter: 0; batch classifier loss: 0.193290; batch adversarial loss: 0.498780\n",
      "epoch 12; iter: 0; batch classifier loss: 0.199107; batch adversarial loss: 0.440616\n",
      "epoch 13; iter: 0; batch classifier loss: 0.228498; batch adversarial loss: 0.498501\n",
      "epoch 14; iter: 0; batch classifier loss: 0.224045; batch adversarial loss: 0.482454\n",
      "epoch 15; iter: 0; batch classifier loss: 0.232098; batch adversarial loss: 0.521486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.216481; batch adversarial loss: 0.603107\n",
      "epoch 17; iter: 0; batch classifier loss: 0.231883; batch adversarial loss: 0.486814\n",
      "epoch 18; iter: 0; batch classifier loss: 0.247715; batch adversarial loss: 0.566667\n",
      "epoch 19; iter: 0; batch classifier loss: 0.163241; batch adversarial loss: 0.427460\n",
      "epoch 20; iter: 0; batch classifier loss: 0.256270; batch adversarial loss: 0.467068\n",
      "epoch 21; iter: 0; batch classifier loss: 0.288875; batch adversarial loss: 0.526207\n",
      "epoch 22; iter: 0; batch classifier loss: 0.336466; batch adversarial loss: 0.587054\n",
      "epoch 23; iter: 0; batch classifier loss: 0.375499; batch adversarial loss: 0.553666\n",
      "epoch 24; iter: 0; batch classifier loss: 0.423012; batch adversarial loss: 0.461732\n",
      "epoch 25; iter: 0; batch classifier loss: 0.393512; batch adversarial loss: 0.520018\n",
      "epoch 26; iter: 0; batch classifier loss: 0.266185; batch adversarial loss: 0.505085\n",
      "epoch 27; iter: 0; batch classifier loss: 0.207493; batch adversarial loss: 0.492092\n",
      "epoch 28; iter: 0; batch classifier loss: 0.110551; batch adversarial loss: 0.441565\n",
      "epoch 29; iter: 0; batch classifier loss: 0.144840; batch adversarial loss: 0.436310\n",
      "epoch 30; iter: 0; batch classifier loss: 0.098161; batch adversarial loss: 0.442388\n",
      "epoch 31; iter: 0; batch classifier loss: 0.153555; batch adversarial loss: 0.458996\n",
      "epoch 32; iter: 0; batch classifier loss: 0.148694; batch adversarial loss: 0.456912\n",
      "epoch 33; iter: 0; batch classifier loss: 0.114878; batch adversarial loss: 0.421458\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149428; batch adversarial loss: 0.427681\n",
      "epoch 35; iter: 0; batch classifier loss: 0.093897; batch adversarial loss: 0.428855\n",
      "epoch 36; iter: 0; batch classifier loss: 0.133730; batch adversarial loss: 0.471795\n",
      "epoch 37; iter: 0; batch classifier loss: 0.102593; batch adversarial loss: 0.400251\n",
      "epoch 38; iter: 0; batch classifier loss: 0.101940; batch adversarial loss: 0.428592\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132437; batch adversarial loss: 0.450153\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099222; batch adversarial loss: 0.483840\n",
      "epoch 41; iter: 0; batch classifier loss: 0.096592; batch adversarial loss: 0.464226\n",
      "epoch 42; iter: 0; batch classifier loss: 0.122233; batch adversarial loss: 0.456856\n",
      "epoch 43; iter: 0; batch classifier loss: 0.071446; batch adversarial loss: 0.559297\n",
      "epoch 44; iter: 0; batch classifier loss: 0.096428; batch adversarial loss: 0.399344\n",
      "epoch 45; iter: 0; batch classifier loss: 0.130423; batch adversarial loss: 0.431679\n",
      "epoch 46; iter: 0; batch classifier loss: 0.091001; batch adversarial loss: 0.486862\n",
      "epoch 47; iter: 0; batch classifier loss: 0.094452; batch adversarial loss: 0.389487\n",
      "epoch 48; iter: 0; batch classifier loss: 0.074119; batch adversarial loss: 0.459443\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113926; batch adversarial loss: 0.378572\n",
      "epoch 50; iter: 0; batch classifier loss: 0.110217; batch adversarial loss: 0.445121\n",
      "epoch 51; iter: 0; batch classifier loss: 0.179804; batch adversarial loss: 0.393830\n",
      "epoch 52; iter: 0; batch classifier loss: 0.086903; batch adversarial loss: 0.451206\n",
      "epoch 53; iter: 0; batch classifier loss: 0.139409; batch adversarial loss: 0.550141\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097514; batch adversarial loss: 0.535044\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098423; batch adversarial loss: 0.552060\n",
      "epoch 56; iter: 0; batch classifier loss: 0.126733; batch adversarial loss: 0.473405\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095291; batch adversarial loss: 0.449083\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072308; batch adversarial loss: 0.492879\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102275; batch adversarial loss: 0.430029\n",
      "epoch 60; iter: 0; batch classifier loss: 0.067564; batch adversarial loss: 0.512478\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074720; batch adversarial loss: 0.438621\n",
      "epoch 62; iter: 0; batch classifier loss: 0.160078; batch adversarial loss: 0.505022\n",
      "epoch 63; iter: 0; batch classifier loss: 0.074816; batch adversarial loss: 0.575826\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084637; batch adversarial loss: 0.464108\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110145; batch adversarial loss: 0.400982\n",
      "epoch 66; iter: 0; batch classifier loss: 0.059318; batch adversarial loss: 0.430122\n",
      "epoch 67; iter: 0; batch classifier loss: 0.136317; batch adversarial loss: 0.372826\n",
      "epoch 68; iter: 0; batch classifier loss: 0.077387; batch adversarial loss: 0.438861\n",
      "epoch 69; iter: 0; batch classifier loss: 0.090622; batch adversarial loss: 0.437400\n",
      "epoch 70; iter: 0; batch classifier loss: 0.145529; batch adversarial loss: 0.466665\n",
      "epoch 71; iter: 0; batch classifier loss: 0.072247; batch adversarial loss: 0.447034\n",
      "epoch 72; iter: 0; batch classifier loss: 0.101234; batch adversarial loss: 0.345038\n",
      "epoch 73; iter: 0; batch classifier loss: 0.129284; batch adversarial loss: 0.459166\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082237; batch adversarial loss: 0.554976\n",
      "epoch 75; iter: 0; batch classifier loss: 0.091105; batch adversarial loss: 0.437632\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085331; batch adversarial loss: 0.495776\n",
      "epoch 77; iter: 0; batch classifier loss: 0.113390; batch adversarial loss: 0.437820\n",
      "epoch 78; iter: 0; batch classifier loss: 0.078744; batch adversarial loss: 0.444462\n",
      "epoch 79; iter: 0; batch classifier loss: 0.050158; batch adversarial loss: 0.400327\n",
      "epoch 80; iter: 0; batch classifier loss: 0.105345; batch adversarial loss: 0.438865\n",
      "epoch 81; iter: 0; batch classifier loss: 0.062608; batch adversarial loss: 0.521259\n",
      "epoch 82; iter: 0; batch classifier loss: 0.108347; batch adversarial loss: 0.468306\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064671; batch adversarial loss: 0.368988\n",
      "epoch 84; iter: 0; batch classifier loss: 0.130762; batch adversarial loss: 0.509274\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074536; batch adversarial loss: 0.496869\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070842; batch adversarial loss: 0.443204\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071867; batch adversarial loss: 0.420737\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073938; batch adversarial loss: 0.429062\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059172; batch adversarial loss: 0.561834\n",
      "epoch 90; iter: 0; batch classifier loss: 0.088922; batch adversarial loss: 0.504779\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045106; batch adversarial loss: 0.491528\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068172; batch adversarial loss: 0.499040\n",
      "epoch 93; iter: 0; batch classifier loss: 0.103825; batch adversarial loss: 0.421059\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044831; batch adversarial loss: 0.494984\n",
      "epoch 95; iter: 0; batch classifier loss: 0.094959; batch adversarial loss: 0.415066\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063969; batch adversarial loss: 0.472328\n",
      "epoch 97; iter: 0; batch classifier loss: 0.084285; batch adversarial loss: 0.441115\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058936; batch adversarial loss: 0.476349\n",
      "epoch 99; iter: 0; batch classifier loss: 0.060156; batch adversarial loss: 0.410163\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051276; batch adversarial loss: 0.509654\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043007; batch adversarial loss: 0.411674\n",
      "epoch 102; iter: 0; batch classifier loss: 0.061511; batch adversarial loss: 0.377309\n",
      "epoch 103; iter: 0; batch classifier loss: 0.080549; batch adversarial loss: 0.384544\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058904; batch adversarial loss: 0.438173\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075944; batch adversarial loss: 0.388233\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043591; batch adversarial loss: 0.413556\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061957; batch adversarial loss: 0.567672\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032496; batch adversarial loss: 0.502351\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034502; batch adversarial loss: 0.472891\n",
      "epoch 110; iter: 0; batch classifier loss: 0.063053; batch adversarial loss: 0.454751\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044128; batch adversarial loss: 0.427051\n",
      "epoch 112; iter: 0; batch classifier loss: 0.058683; batch adversarial loss: 0.467431\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048824; batch adversarial loss: 0.516348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.057001; batch adversarial loss: 0.480607\n",
      "epoch 115; iter: 0; batch classifier loss: 0.018963; batch adversarial loss: 0.400654\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044280; batch adversarial loss: 0.366519\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051854; batch adversarial loss: 0.415288\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033798; batch adversarial loss: 0.507186\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041450; batch adversarial loss: 0.436022\n",
      "epoch 120; iter: 0; batch classifier loss: 0.015841; batch adversarial loss: 0.526782\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032679; batch adversarial loss: 0.428738\n",
      "epoch 122; iter: 0; batch classifier loss: 0.061492; batch adversarial loss: 0.447547\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043215; batch adversarial loss: 0.431045\n",
      "epoch 124; iter: 0; batch classifier loss: 0.047763; batch adversarial loss: 0.462179\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054489; batch adversarial loss: 0.409241\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024391; batch adversarial loss: 0.390255\n",
      "epoch 127; iter: 0; batch classifier loss: 0.065490; batch adversarial loss: 0.474154\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035081; batch adversarial loss: 0.486400\n",
      "epoch 129; iter: 0; batch classifier loss: 0.066276; batch adversarial loss: 0.415905\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061911; batch adversarial loss: 0.428268\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041748; batch adversarial loss: 0.387473\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035544; batch adversarial loss: 0.621850\n",
      "epoch 133; iter: 0; batch classifier loss: 0.059498; batch adversarial loss: 0.527884\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038636; batch adversarial loss: 0.502369\n",
      "epoch 135; iter: 0; batch classifier loss: 0.065561; batch adversarial loss: 0.466044\n",
      "epoch 136; iter: 0; batch classifier loss: 0.060022; batch adversarial loss: 0.439305\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049480; batch adversarial loss: 0.535588\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021945; batch adversarial loss: 0.436922\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010650; batch adversarial loss: 0.433677\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041957; batch adversarial loss: 0.499384\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034344; batch adversarial loss: 0.477025\n",
      "epoch 142; iter: 0; batch classifier loss: 0.059540; batch adversarial loss: 0.440361\n",
      "epoch 143; iter: 0; batch classifier loss: 0.066427; batch adversarial loss: 0.387274\n",
      "epoch 144; iter: 0; batch classifier loss: 0.062383; batch adversarial loss: 0.377304\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025046; batch adversarial loss: 0.427565\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045486; batch adversarial loss: 0.432112\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027273; batch adversarial loss: 0.422588\n",
      "epoch 148; iter: 0; batch classifier loss: 0.007060; batch adversarial loss: 0.454738\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017479; batch adversarial loss: 0.483142\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037601; batch adversarial loss: 0.436485\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015753; batch adversarial loss: 0.539592\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022722; batch adversarial loss: 0.488259\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019390; batch adversarial loss: 0.437501\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026087; batch adversarial loss: 0.455977\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041951; batch adversarial loss: 0.450181\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018777; batch adversarial loss: 0.400503\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040161; batch adversarial loss: 0.454606\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011245; batch adversarial loss: 0.475050\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032972; batch adversarial loss: 0.409739\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022088; batch adversarial loss: 0.388585\n",
      "epoch 161; iter: 0; batch classifier loss: 0.046333; batch adversarial loss: 0.427568\n",
      "epoch 162; iter: 0; batch classifier loss: 0.035123; batch adversarial loss: 0.488664\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028541; batch adversarial loss: 0.465632\n",
      "epoch 164; iter: 0; batch classifier loss: 0.057710; batch adversarial loss: 0.415110\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029568; batch adversarial loss: 0.543709\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036616; batch adversarial loss: 0.449809\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028833; batch adversarial loss: 0.448213\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026348; batch adversarial loss: 0.421813\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018272; batch adversarial loss: 0.453266\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040062; batch adversarial loss: 0.468841\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011236; batch adversarial loss: 0.439294\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016811; batch adversarial loss: 0.457596\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031707; batch adversarial loss: 0.461000\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024243; batch adversarial loss: 0.537181\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020584; batch adversarial loss: 0.411371\n",
      "epoch 176; iter: 0; batch classifier loss: 0.054503; batch adversarial loss: 0.443437\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012816; batch adversarial loss: 0.394753\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038086; batch adversarial loss: 0.384374\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032136; batch adversarial loss: 0.450147\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026586; batch adversarial loss: 0.503901\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026668; batch adversarial loss: 0.477179\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019453; batch adversarial loss: 0.400132\n",
      "epoch 183; iter: 0; batch classifier loss: 0.044892; batch adversarial loss: 0.471615\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004797; batch adversarial loss: 0.517280\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018069; batch adversarial loss: 0.410801\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024535; batch adversarial loss: 0.450813\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017869; batch adversarial loss: 0.403191\n",
      "epoch 188; iter: 0; batch classifier loss: 0.068307; batch adversarial loss: 0.429459\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018834; batch adversarial loss: 0.494450\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023847; batch adversarial loss: 0.526723\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036433; batch adversarial loss: 0.480711\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031259; batch adversarial loss: 0.434846\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015893; batch adversarial loss: 0.467234\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009508; batch adversarial loss: 0.396562\n",
      "epoch 195; iter: 0; batch classifier loss: 0.054345; batch adversarial loss: 0.490909\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028739; batch adversarial loss: 0.504574\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016464; batch adversarial loss: 0.376869\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032344; batch adversarial loss: 0.585641\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027808; batch adversarial loss: 0.513607\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688250; batch adversarial loss: 0.544332\n",
      "epoch 1; iter: 0; batch classifier loss: 0.420964; batch adversarial loss: 0.621948\n",
      "epoch 2; iter: 0; batch classifier loss: 0.422349; batch adversarial loss: 0.566372\n",
      "epoch 3; iter: 0; batch classifier loss: 0.345205; batch adversarial loss: 0.585758\n",
      "epoch 4; iter: 0; batch classifier loss: 0.377813; batch adversarial loss: 0.611257\n",
      "epoch 5; iter: 0; batch classifier loss: 0.293555; batch adversarial loss: 0.613770\n",
      "epoch 6; iter: 0; batch classifier loss: 0.364924; batch adversarial loss: 0.520979\n",
      "epoch 7; iter: 0; batch classifier loss: 0.253542; batch adversarial loss: 0.614045\n",
      "epoch 8; iter: 0; batch classifier loss: 0.306247; batch adversarial loss: 0.557879\n",
      "epoch 9; iter: 0; batch classifier loss: 0.347206; batch adversarial loss: 0.489736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.276599; batch adversarial loss: 0.560095\n",
      "epoch 11; iter: 0; batch classifier loss: 0.270289; batch adversarial loss: 0.525985\n",
      "epoch 12; iter: 0; batch classifier loss: 0.332449; batch adversarial loss: 0.549579\n",
      "epoch 13; iter: 0; batch classifier loss: 0.451333; batch adversarial loss: 0.506737\n",
      "epoch 14; iter: 0; batch classifier loss: 0.310993; batch adversarial loss: 0.559514\n",
      "epoch 15; iter: 0; batch classifier loss: 0.468599; batch adversarial loss: 0.536502\n",
      "epoch 16; iter: 0; batch classifier loss: 0.530238; batch adversarial loss: 0.504698\n",
      "epoch 17; iter: 0; batch classifier loss: 0.313418; batch adversarial loss: 0.484888\n",
      "epoch 18; iter: 0; batch classifier loss: 0.249390; batch adversarial loss: 0.451291\n",
      "epoch 19; iter: 0; batch classifier loss: 0.226892; batch adversarial loss: 0.415355\n",
      "epoch 20; iter: 0; batch classifier loss: 0.209283; batch adversarial loss: 0.438895\n",
      "epoch 21; iter: 0; batch classifier loss: 0.239981; batch adversarial loss: 0.426947\n",
      "epoch 22; iter: 0; batch classifier loss: 0.173063; batch adversarial loss: 0.503473\n",
      "epoch 23; iter: 0; batch classifier loss: 0.181695; batch adversarial loss: 0.479132\n",
      "epoch 24; iter: 0; batch classifier loss: 0.175771; batch adversarial loss: 0.402251\n",
      "epoch 25; iter: 0; batch classifier loss: 0.158393; batch adversarial loss: 0.478434\n",
      "epoch 26; iter: 0; batch classifier loss: 0.207023; batch adversarial loss: 0.450693\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151321; batch adversarial loss: 0.507703\n",
      "epoch 28; iter: 0; batch classifier loss: 0.111973; batch adversarial loss: 0.408840\n",
      "epoch 29; iter: 0; batch classifier loss: 0.173970; batch adversarial loss: 0.418408\n",
      "epoch 30; iter: 0; batch classifier loss: 0.108901; batch adversarial loss: 0.500714\n",
      "epoch 31; iter: 0; batch classifier loss: 0.110618; batch adversarial loss: 0.483133\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126826; batch adversarial loss: 0.374632\n",
      "epoch 33; iter: 0; batch classifier loss: 0.136282; batch adversarial loss: 0.431200\n",
      "epoch 34; iter: 0; batch classifier loss: 0.111499; batch adversarial loss: 0.472585\n",
      "epoch 35; iter: 0; batch classifier loss: 0.156794; batch adversarial loss: 0.504493\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128611; batch adversarial loss: 0.462868\n",
      "epoch 37; iter: 0; batch classifier loss: 0.148351; batch adversarial loss: 0.393779\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126248; batch adversarial loss: 0.377771\n",
      "epoch 39; iter: 0; batch classifier loss: 0.121017; batch adversarial loss: 0.419749\n",
      "epoch 40; iter: 0; batch classifier loss: 0.127189; batch adversarial loss: 0.406609\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142394; batch adversarial loss: 0.503036\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115262; batch adversarial loss: 0.391714\n",
      "epoch 43; iter: 0; batch classifier loss: 0.191317; batch adversarial loss: 0.455242\n",
      "epoch 44; iter: 0; batch classifier loss: 0.147941; batch adversarial loss: 0.474578\n",
      "epoch 45; iter: 0; batch classifier loss: 0.096947; batch adversarial loss: 0.450897\n",
      "epoch 46; iter: 0; batch classifier loss: 0.186878; batch adversarial loss: 0.506036\n",
      "epoch 47; iter: 0; batch classifier loss: 0.170564; batch adversarial loss: 0.575949\n",
      "epoch 48; iter: 0; batch classifier loss: 0.134817; batch adversarial loss: 0.479240\n",
      "epoch 49; iter: 0; batch classifier loss: 0.077521; batch adversarial loss: 0.427576\n",
      "epoch 50; iter: 0; batch classifier loss: 0.141371; batch adversarial loss: 0.471782\n",
      "epoch 51; iter: 0; batch classifier loss: 0.153761; batch adversarial loss: 0.403540\n",
      "epoch 52; iter: 0; batch classifier loss: 0.120936; batch adversarial loss: 0.534949\n",
      "epoch 53; iter: 0; batch classifier loss: 0.105226; batch adversarial loss: 0.501408\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099286; batch adversarial loss: 0.540452\n",
      "epoch 55; iter: 0; batch classifier loss: 0.170710; batch adversarial loss: 0.402699\n",
      "epoch 56; iter: 0; batch classifier loss: 0.125113; batch adversarial loss: 0.437595\n",
      "epoch 57; iter: 0; batch classifier loss: 0.164488; batch adversarial loss: 0.508631\n",
      "epoch 58; iter: 0; batch classifier loss: 0.082947; batch adversarial loss: 0.418790\n",
      "epoch 59; iter: 0; batch classifier loss: 0.185570; batch adversarial loss: 0.420373\n",
      "epoch 60; iter: 0; batch classifier loss: 0.230263; batch adversarial loss: 0.543748\n",
      "epoch 61; iter: 0; batch classifier loss: 0.111693; batch adversarial loss: 0.483613\n",
      "epoch 62; iter: 0; batch classifier loss: 0.180990; batch adversarial loss: 0.439930\n",
      "epoch 63; iter: 0; batch classifier loss: 0.156937; batch adversarial loss: 0.363022\n",
      "epoch 64; iter: 0; batch classifier loss: 0.182823; batch adversarial loss: 0.449202\n",
      "epoch 65; iter: 0; batch classifier loss: 0.175704; batch adversarial loss: 0.416066\n",
      "epoch 66; iter: 0; batch classifier loss: 0.236240; batch adversarial loss: 0.403838\n",
      "epoch 67; iter: 0; batch classifier loss: 0.194717; batch adversarial loss: 0.478308\n",
      "epoch 68; iter: 0; batch classifier loss: 0.183267; batch adversarial loss: 0.398512\n",
      "epoch 69; iter: 0; batch classifier loss: 0.184878; batch adversarial loss: 0.410882\n",
      "epoch 70; iter: 0; batch classifier loss: 0.149332; batch adversarial loss: 0.495478\n",
      "epoch 71; iter: 0; batch classifier loss: 0.119659; batch adversarial loss: 0.408436\n",
      "epoch 72; iter: 0; batch classifier loss: 0.156477; batch adversarial loss: 0.413979\n",
      "epoch 73; iter: 0; batch classifier loss: 0.158865; batch adversarial loss: 0.525637\n",
      "epoch 74; iter: 0; batch classifier loss: 0.203495; batch adversarial loss: 0.416555\n",
      "epoch 75; iter: 0; batch classifier loss: 0.198587; batch adversarial loss: 0.454448\n",
      "epoch 76; iter: 0; batch classifier loss: 0.207083; batch adversarial loss: 0.480458\n",
      "epoch 77; iter: 0; batch classifier loss: 0.121225; batch adversarial loss: 0.438440\n",
      "epoch 78; iter: 0; batch classifier loss: 0.153645; batch adversarial loss: 0.468223\n",
      "epoch 79; iter: 0; batch classifier loss: 0.160831; batch adversarial loss: 0.429477\n",
      "epoch 80; iter: 0; batch classifier loss: 0.219427; batch adversarial loss: 0.395626\n",
      "epoch 81; iter: 0; batch classifier loss: 0.223240; batch adversarial loss: 0.521629\n",
      "epoch 82; iter: 0; batch classifier loss: 0.222417; batch adversarial loss: 0.531873\n",
      "epoch 83; iter: 0; batch classifier loss: 0.227959; batch adversarial loss: 0.430964\n",
      "epoch 84; iter: 0; batch classifier loss: 0.262349; batch adversarial loss: 0.485417\n",
      "epoch 85; iter: 0; batch classifier loss: 0.241009; batch adversarial loss: 0.479262\n",
      "epoch 86; iter: 0; batch classifier loss: 0.228860; batch adversarial loss: 0.443951\n",
      "epoch 87; iter: 0; batch classifier loss: 0.214779; batch adversarial loss: 0.461364\n",
      "epoch 88; iter: 0; batch classifier loss: 0.202764; batch adversarial loss: 0.444752\n",
      "epoch 89; iter: 0; batch classifier loss: 0.208434; batch adversarial loss: 0.432585\n",
      "epoch 90; iter: 0; batch classifier loss: 0.181580; batch adversarial loss: 0.419527\n",
      "epoch 91; iter: 0; batch classifier loss: 0.221557; batch adversarial loss: 0.469685\n",
      "epoch 92; iter: 0; batch classifier loss: 0.203736; batch adversarial loss: 0.493806\n",
      "epoch 93; iter: 0; batch classifier loss: 0.253215; batch adversarial loss: 0.432702\n",
      "epoch 94; iter: 0; batch classifier loss: 0.240320; batch adversarial loss: 0.421034\n",
      "epoch 95; iter: 0; batch classifier loss: 0.189761; batch adversarial loss: 0.364904\n",
      "epoch 96; iter: 0; batch classifier loss: 0.160602; batch adversarial loss: 0.409366\n",
      "epoch 97; iter: 0; batch classifier loss: 0.212044; batch adversarial loss: 0.419839\n",
      "epoch 98; iter: 0; batch classifier loss: 0.223131; batch adversarial loss: 0.459557\n",
      "epoch 99; iter: 0; batch classifier loss: 0.221492; batch adversarial loss: 0.409966\n",
      "epoch 100; iter: 0; batch classifier loss: 0.301861; batch adversarial loss: 0.422642\n",
      "epoch 101; iter: 0; batch classifier loss: 0.324509; batch adversarial loss: 0.447205\n",
      "epoch 102; iter: 0; batch classifier loss: 0.248013; batch adversarial loss: 0.386898\n",
      "epoch 103; iter: 0; batch classifier loss: 0.203562; batch adversarial loss: 0.458099\n",
      "epoch 104; iter: 0; batch classifier loss: 0.281021; batch adversarial loss: 0.411179\n",
      "epoch 105; iter: 0; batch classifier loss: 0.179432; batch adversarial loss: 0.362792\n",
      "epoch 106; iter: 0; batch classifier loss: 0.160740; batch adversarial loss: 0.470546\n",
      "epoch 107; iter: 0; batch classifier loss: 0.118696; batch adversarial loss: 0.470535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.129752; batch adversarial loss: 0.398105\n",
      "epoch 109; iter: 0; batch classifier loss: 0.257072; batch adversarial loss: 0.460147\n",
      "epoch 110; iter: 0; batch classifier loss: 0.244911; batch adversarial loss: 0.568391\n",
      "epoch 111; iter: 0; batch classifier loss: 0.246969; batch adversarial loss: 0.457643\n",
      "epoch 112; iter: 0; batch classifier loss: 0.207938; batch adversarial loss: 0.445615\n",
      "epoch 113; iter: 0; batch classifier loss: 0.163171; batch adversarial loss: 0.445060\n",
      "epoch 114; iter: 0; batch classifier loss: 0.259793; batch adversarial loss: 0.483292\n",
      "epoch 115; iter: 0; batch classifier loss: 0.205274; batch adversarial loss: 0.580589\n",
      "epoch 116; iter: 0; batch classifier loss: 0.296596; batch adversarial loss: 0.374951\n",
      "epoch 117; iter: 0; batch classifier loss: 0.273842; batch adversarial loss: 0.447308\n",
      "epoch 118; iter: 0; batch classifier loss: 0.219004; batch adversarial loss: 0.494531\n",
      "epoch 119; iter: 0; batch classifier loss: 0.206690; batch adversarial loss: 0.398434\n",
      "epoch 120; iter: 0; batch classifier loss: 0.210650; batch adversarial loss: 0.446678\n",
      "epoch 121; iter: 0; batch classifier loss: 0.062332; batch adversarial loss: 0.555679\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044043; batch adversarial loss: 0.517116\n",
      "epoch 123; iter: 0; batch classifier loss: 0.056566; batch adversarial loss: 0.463189\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059241; batch adversarial loss: 0.406983\n",
      "epoch 125; iter: 0; batch classifier loss: 0.107323; batch adversarial loss: 0.439576\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039238; batch adversarial loss: 0.374421\n",
      "epoch 127; iter: 0; batch classifier loss: 0.070907; batch adversarial loss: 0.527011\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046137; batch adversarial loss: 0.388989\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059144; batch adversarial loss: 0.457253\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019337; batch adversarial loss: 0.396097\n",
      "epoch 131; iter: 0; batch classifier loss: 0.065487; batch adversarial loss: 0.440149\n",
      "epoch 132; iter: 0; batch classifier loss: 0.082732; batch adversarial loss: 0.424296\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040089; batch adversarial loss: 0.436744\n",
      "epoch 134; iter: 0; batch classifier loss: 0.096728; batch adversarial loss: 0.469586\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044643; batch adversarial loss: 0.395800\n",
      "epoch 136; iter: 0; batch classifier loss: 0.085510; batch adversarial loss: 0.371366\n",
      "epoch 137; iter: 0; batch classifier loss: 0.058344; batch adversarial loss: 0.396709\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049161; batch adversarial loss: 0.443509\n",
      "epoch 139; iter: 0; batch classifier loss: 0.059735; batch adversarial loss: 0.345295\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053182; batch adversarial loss: 0.428195\n",
      "epoch 141; iter: 0; batch classifier loss: 0.060700; batch adversarial loss: 0.399598\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035079; batch adversarial loss: 0.386414\n",
      "epoch 143; iter: 0; batch classifier loss: 0.104746; batch adversarial loss: 0.358368\n",
      "epoch 144; iter: 0; batch classifier loss: 0.073709; batch adversarial loss: 0.442041\n",
      "epoch 145; iter: 0; batch classifier loss: 0.051339; batch adversarial loss: 0.468991\n",
      "epoch 146; iter: 0; batch classifier loss: 0.060696; batch adversarial loss: 0.480176\n",
      "epoch 147; iter: 0; batch classifier loss: 0.055431; batch adversarial loss: 0.456659\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045354; batch adversarial loss: 0.541940\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056672; batch adversarial loss: 0.410941\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042481; batch adversarial loss: 0.412980\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038716; batch adversarial loss: 0.512656\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038946; batch adversarial loss: 0.397410\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027364; batch adversarial loss: 0.456753\n",
      "epoch 154; iter: 0; batch classifier loss: 0.067443; batch adversarial loss: 0.491493\n",
      "epoch 155; iter: 0; batch classifier loss: 0.054982; batch adversarial loss: 0.427000\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041443; batch adversarial loss: 0.478746\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046718; batch adversarial loss: 0.423682\n",
      "epoch 158; iter: 0; batch classifier loss: 0.065931; batch adversarial loss: 0.322313\n",
      "epoch 159; iter: 0; batch classifier loss: 0.044063; batch adversarial loss: 0.491586\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037777; batch adversarial loss: 0.488126\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032867; batch adversarial loss: 0.449902\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020411; batch adversarial loss: 0.347935\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042392; batch adversarial loss: 0.350610\n",
      "epoch 164; iter: 0; batch classifier loss: 0.062863; batch adversarial loss: 0.514929\n",
      "epoch 165; iter: 0; batch classifier loss: 0.076591; batch adversarial loss: 0.436639\n",
      "epoch 166; iter: 0; batch classifier loss: 0.068907; batch adversarial loss: 0.382354\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028367; batch adversarial loss: 0.470553\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032007; batch adversarial loss: 0.380413\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037589; batch adversarial loss: 0.508353\n",
      "epoch 170; iter: 0; batch classifier loss: 0.062264; batch adversarial loss: 0.551283\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029523; batch adversarial loss: 0.415309\n",
      "epoch 172; iter: 0; batch classifier loss: 0.043330; batch adversarial loss: 0.449002\n",
      "epoch 173; iter: 0; batch classifier loss: 0.094773; batch adversarial loss: 0.492065\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033010; batch adversarial loss: 0.318076\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037661; batch adversarial loss: 0.332395\n",
      "epoch 176; iter: 0; batch classifier loss: 0.067237; batch adversarial loss: 0.476308\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022044; batch adversarial loss: 0.421246\n",
      "epoch 178; iter: 0; batch classifier loss: 0.057744; batch adversarial loss: 0.383184\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026578; batch adversarial loss: 0.490633\n",
      "epoch 180; iter: 0; batch classifier loss: 0.051187; batch adversarial loss: 0.460192\n",
      "epoch 181; iter: 0; batch classifier loss: 0.049885; batch adversarial loss: 0.431249\n",
      "epoch 182; iter: 0; batch classifier loss: 0.045692; batch adversarial loss: 0.395877\n",
      "epoch 183; iter: 0; batch classifier loss: 0.054681; batch adversarial loss: 0.472120\n",
      "epoch 184; iter: 0; batch classifier loss: 0.042169; batch adversarial loss: 0.409150\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029182; batch adversarial loss: 0.480090\n",
      "epoch 186; iter: 0; batch classifier loss: 0.036105; batch adversarial loss: 0.388318\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035649; batch adversarial loss: 0.373917\n",
      "epoch 188; iter: 0; batch classifier loss: 0.058300; batch adversarial loss: 0.424431\n",
      "epoch 189; iter: 0; batch classifier loss: 0.046236; batch adversarial loss: 0.511472\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028234; batch adversarial loss: 0.357682\n",
      "epoch 191; iter: 0; batch classifier loss: 0.056481; batch adversarial loss: 0.395142\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035959; batch adversarial loss: 0.557362\n",
      "epoch 193; iter: 0; batch classifier loss: 0.057634; batch adversarial loss: 0.499340\n",
      "epoch 194; iter: 0; batch classifier loss: 0.046982; batch adversarial loss: 0.394006\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027907; batch adversarial loss: 0.403919\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018845; batch adversarial loss: 0.425684\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037895; batch adversarial loss: 0.418902\n",
      "epoch 198; iter: 0; batch classifier loss: 0.047932; batch adversarial loss: 0.443822\n",
      "epoch 199; iter: 0; batch classifier loss: 0.042977; batch adversarial loss: 0.413676\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713414; batch adversarial loss: 0.924771\n",
      "epoch 1; iter: 0; batch classifier loss: 0.674684; batch adversarial loss: 1.037990\n",
      "epoch 2; iter: 0; batch classifier loss: 0.913351; batch adversarial loss: 1.058165\n",
      "epoch 3; iter: 0; batch classifier loss: 0.945580; batch adversarial loss: 0.959605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.932752; batch adversarial loss: 0.852723\n",
      "epoch 5; iter: 0; batch classifier loss: 0.897440; batch adversarial loss: 0.767683\n",
      "epoch 6; iter: 0; batch classifier loss: 0.991085; batch adversarial loss: 0.721837\n",
      "epoch 7; iter: 0; batch classifier loss: 0.800451; batch adversarial loss: 0.659759\n",
      "epoch 8; iter: 0; batch classifier loss: 0.778117; batch adversarial loss: 0.620803\n",
      "epoch 9; iter: 0; batch classifier loss: 0.570214; batch adversarial loss: 0.587472\n",
      "epoch 10; iter: 0; batch classifier loss: 0.326146; batch adversarial loss: 0.563275\n",
      "epoch 11; iter: 0; batch classifier loss: 0.344427; batch adversarial loss: 0.549348\n",
      "epoch 12; iter: 0; batch classifier loss: 0.369155; batch adversarial loss: 0.518788\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331807; batch adversarial loss: 0.539727\n",
      "epoch 14; iter: 0; batch classifier loss: 0.310910; batch adversarial loss: 0.517327\n",
      "epoch 15; iter: 0; batch classifier loss: 0.320192; batch adversarial loss: 0.514344\n",
      "epoch 16; iter: 0; batch classifier loss: 0.333783; batch adversarial loss: 0.511282\n",
      "epoch 17; iter: 0; batch classifier loss: 0.335370; batch adversarial loss: 0.550956\n",
      "epoch 18; iter: 0; batch classifier loss: 0.361622; batch adversarial loss: 0.497856\n",
      "epoch 19; iter: 0; batch classifier loss: 0.303085; batch adversarial loss: 0.471515\n",
      "epoch 20; iter: 0; batch classifier loss: 0.270731; batch adversarial loss: 0.470213\n",
      "epoch 21; iter: 0; batch classifier loss: 0.381896; batch adversarial loss: 0.529163\n",
      "epoch 22; iter: 0; batch classifier loss: 0.280499; batch adversarial loss: 0.530809\n",
      "epoch 23; iter: 0; batch classifier loss: 0.271181; batch adversarial loss: 0.477308\n",
      "epoch 24; iter: 0; batch classifier loss: 0.270842; batch adversarial loss: 0.481096\n",
      "epoch 25; iter: 0; batch classifier loss: 0.294456; batch adversarial loss: 0.436176\n",
      "epoch 26; iter: 0; batch classifier loss: 0.249211; batch adversarial loss: 0.486486\n",
      "epoch 27; iter: 0; batch classifier loss: 0.285126; batch adversarial loss: 0.520251\n",
      "epoch 28; iter: 0; batch classifier loss: 0.315670; batch adversarial loss: 0.436398\n",
      "epoch 29; iter: 0; batch classifier loss: 0.281597; batch adversarial loss: 0.473100\n",
      "epoch 30; iter: 0; batch classifier loss: 0.346395; batch adversarial loss: 0.451695\n",
      "epoch 31; iter: 0; batch classifier loss: 0.255770; batch adversarial loss: 0.495693\n",
      "epoch 32; iter: 0; batch classifier loss: 0.265405; batch adversarial loss: 0.471932\n",
      "epoch 33; iter: 0; batch classifier loss: 0.348618; batch adversarial loss: 0.477875\n",
      "epoch 34; iter: 0; batch classifier loss: 0.257394; batch adversarial loss: 0.427901\n",
      "epoch 35; iter: 0; batch classifier loss: 0.306627; batch adversarial loss: 0.472710\n",
      "epoch 36; iter: 0; batch classifier loss: 0.252675; batch adversarial loss: 0.537320\n",
      "epoch 37; iter: 0; batch classifier loss: 0.260089; batch adversarial loss: 0.448248\n",
      "epoch 38; iter: 0; batch classifier loss: 0.311588; batch adversarial loss: 0.508919\n",
      "epoch 39; iter: 0; batch classifier loss: 0.259016; batch adversarial loss: 0.442698\n",
      "epoch 40; iter: 0; batch classifier loss: 0.247652; batch adversarial loss: 0.472463\n",
      "epoch 41; iter: 0; batch classifier loss: 0.309470; batch adversarial loss: 0.563198\n",
      "epoch 42; iter: 0; batch classifier loss: 0.381372; batch adversarial loss: 0.460253\n",
      "epoch 43; iter: 0; batch classifier loss: 0.213224; batch adversarial loss: 0.510587\n",
      "epoch 44; iter: 0; batch classifier loss: 0.213396; batch adversarial loss: 0.428518\n",
      "epoch 45; iter: 0; batch classifier loss: 0.267204; batch adversarial loss: 0.481779\n",
      "epoch 46; iter: 0; batch classifier loss: 0.284218; batch adversarial loss: 0.409227\n",
      "epoch 47; iter: 0; batch classifier loss: 0.247364; batch adversarial loss: 0.506667\n",
      "epoch 48; iter: 0; batch classifier loss: 0.188733; batch adversarial loss: 0.438510\n",
      "epoch 49; iter: 0; batch classifier loss: 0.222243; batch adversarial loss: 0.401608\n",
      "epoch 50; iter: 0; batch classifier loss: 0.243104; batch adversarial loss: 0.445255\n",
      "epoch 51; iter: 0; batch classifier loss: 0.218112; batch adversarial loss: 0.531249\n",
      "epoch 52; iter: 0; batch classifier loss: 0.176940; batch adversarial loss: 0.417670\n",
      "epoch 53; iter: 0; batch classifier loss: 0.290148; batch adversarial loss: 0.461870\n",
      "epoch 54; iter: 0; batch classifier loss: 0.224305; batch adversarial loss: 0.421690\n",
      "epoch 55; iter: 0; batch classifier loss: 0.234849; batch adversarial loss: 0.413443\n",
      "epoch 56; iter: 0; batch classifier loss: 0.198761; batch adversarial loss: 0.448413\n",
      "epoch 57; iter: 0; batch classifier loss: 0.169311; batch adversarial loss: 0.540032\n",
      "epoch 58; iter: 0; batch classifier loss: 0.201907; batch adversarial loss: 0.402588\n",
      "epoch 59; iter: 0; batch classifier loss: 0.153416; batch adversarial loss: 0.556721\n",
      "epoch 60; iter: 0; batch classifier loss: 0.249148; batch adversarial loss: 0.399780\n",
      "epoch 61; iter: 0; batch classifier loss: 0.195320; batch adversarial loss: 0.493274\n",
      "epoch 62; iter: 0; batch classifier loss: 0.160450; batch adversarial loss: 0.517639\n",
      "epoch 63; iter: 0; batch classifier loss: 0.188853; batch adversarial loss: 0.496156\n",
      "epoch 64; iter: 0; batch classifier loss: 0.303819; batch adversarial loss: 0.480567\n",
      "epoch 65; iter: 0; batch classifier loss: 0.264766; batch adversarial loss: 0.528190\n",
      "epoch 66; iter: 0; batch classifier loss: 0.248209; batch adversarial loss: 0.410655\n",
      "epoch 67; iter: 0; batch classifier loss: 0.142867; batch adversarial loss: 0.555031\n",
      "epoch 68; iter: 0; batch classifier loss: 0.163647; batch adversarial loss: 0.462260\n",
      "epoch 69; iter: 0; batch classifier loss: 0.231523; batch adversarial loss: 0.481834\n",
      "epoch 70; iter: 0; batch classifier loss: 0.211328; batch adversarial loss: 0.412278\n",
      "epoch 71; iter: 0; batch classifier loss: 0.242939; batch adversarial loss: 0.493853\n",
      "epoch 72; iter: 0; batch classifier loss: 0.254558; batch adversarial loss: 0.471747\n",
      "epoch 73; iter: 0; batch classifier loss: 0.229244; batch adversarial loss: 0.518440\n",
      "epoch 74; iter: 0; batch classifier loss: 0.189569; batch adversarial loss: 0.518453\n",
      "epoch 75; iter: 0; batch classifier loss: 0.304161; batch adversarial loss: 0.484086\n",
      "epoch 76; iter: 0; batch classifier loss: 0.215051; batch adversarial loss: 0.518846\n",
      "epoch 77; iter: 0; batch classifier loss: 0.173634; batch adversarial loss: 0.458837\n",
      "epoch 78; iter: 0; batch classifier loss: 0.322587; batch adversarial loss: 0.423796\n",
      "epoch 79; iter: 0; batch classifier loss: 0.177721; batch adversarial loss: 0.399337\n",
      "epoch 80; iter: 0; batch classifier loss: 0.160639; batch adversarial loss: 0.398134\n",
      "epoch 81; iter: 0; batch classifier loss: 0.103282; batch adversarial loss: 0.350570\n",
      "epoch 82; iter: 0; batch classifier loss: 0.156170; batch adversarial loss: 0.410034\n",
      "epoch 83; iter: 0; batch classifier loss: 0.175459; batch adversarial loss: 0.506860\n",
      "epoch 84; iter: 0; batch classifier loss: 0.212694; batch adversarial loss: 0.470628\n",
      "epoch 85; iter: 0; batch classifier loss: 0.183184; batch adversarial loss: 0.484122\n",
      "epoch 86; iter: 0; batch classifier loss: 0.174943; batch adversarial loss: 0.411683\n",
      "epoch 87; iter: 0; batch classifier loss: 0.192675; batch adversarial loss: 0.541866\n",
      "epoch 88; iter: 0; batch classifier loss: 0.196314; batch adversarial loss: 0.530645\n",
      "epoch 89; iter: 0; batch classifier loss: 0.245226; batch adversarial loss: 0.519536\n",
      "epoch 90; iter: 0; batch classifier loss: 0.273457; batch adversarial loss: 0.387237\n",
      "epoch 91; iter: 0; batch classifier loss: 0.230646; batch adversarial loss: 0.446882\n",
      "epoch 92; iter: 0; batch classifier loss: 0.193014; batch adversarial loss: 0.446363\n",
      "epoch 93; iter: 0; batch classifier loss: 0.190003; batch adversarial loss: 0.554279\n",
      "epoch 94; iter: 0; batch classifier loss: 0.239823; batch adversarial loss: 0.530403\n",
      "epoch 95; iter: 0; batch classifier loss: 0.102626; batch adversarial loss: 0.494674\n",
      "epoch 96; iter: 0; batch classifier loss: 0.165670; batch adversarial loss: 0.508106\n",
      "epoch 97; iter: 0; batch classifier loss: 0.150427; batch adversarial loss: 0.482474\n",
      "epoch 98; iter: 0; batch classifier loss: 0.127677; batch adversarial loss: 0.390243\n",
      "epoch 99; iter: 0; batch classifier loss: 0.286399; batch adversarial loss: 0.432796\n",
      "epoch 100; iter: 0; batch classifier loss: 0.263312; batch adversarial loss: 0.470470\n",
      "epoch 101; iter: 0; batch classifier loss: 0.207042; batch adversarial loss: 0.614144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.164246; batch adversarial loss: 0.458754\n",
      "epoch 103; iter: 0; batch classifier loss: 0.261488; batch adversarial loss: 0.517901\n",
      "epoch 104; iter: 0; batch classifier loss: 0.179554; batch adversarial loss: 0.412621\n",
      "epoch 105; iter: 0; batch classifier loss: 0.135743; batch adversarial loss: 0.495318\n",
      "epoch 106; iter: 0; batch classifier loss: 0.233533; batch adversarial loss: 0.482240\n",
      "epoch 107; iter: 0; batch classifier loss: 0.252823; batch adversarial loss: 0.447099\n",
      "epoch 108; iter: 0; batch classifier loss: 0.155652; batch adversarial loss: 0.518606\n",
      "epoch 109; iter: 0; batch classifier loss: 0.229596; batch adversarial loss: 0.470607\n",
      "epoch 110; iter: 0; batch classifier loss: 0.187519; batch adversarial loss: 0.411235\n",
      "epoch 111; iter: 0; batch classifier loss: 0.218166; batch adversarial loss: 0.434470\n",
      "epoch 112; iter: 0; batch classifier loss: 0.211245; batch adversarial loss: 0.518891\n",
      "epoch 113; iter: 0; batch classifier loss: 0.234390; batch adversarial loss: 0.470903\n",
      "epoch 114; iter: 0; batch classifier loss: 0.207461; batch adversarial loss: 0.411104\n",
      "epoch 115; iter: 0; batch classifier loss: 0.069454; batch adversarial loss: 0.470705\n",
      "epoch 116; iter: 0; batch classifier loss: 0.067291; batch adversarial loss: 0.480967\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055908; batch adversarial loss: 0.538297\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051862; batch adversarial loss: 0.577793\n",
      "epoch 119; iter: 0; batch classifier loss: 0.068135; batch adversarial loss: 0.418803\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036742; batch adversarial loss: 0.444381\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040492; batch adversarial loss: 0.452450\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051314; batch adversarial loss: 0.457264\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040369; batch adversarial loss: 0.445993\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035715; batch adversarial loss: 0.467086\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041678; batch adversarial loss: 0.395114\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031084; batch adversarial loss: 0.533350\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035688; batch adversarial loss: 0.404570\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025249; batch adversarial loss: 0.472150\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047747; batch adversarial loss: 0.476793\n",
      "epoch 130; iter: 0; batch classifier loss: 0.053728; batch adversarial loss: 0.499205\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031889; batch adversarial loss: 0.461557\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050922; batch adversarial loss: 0.476063\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035787; batch adversarial loss: 0.424241\n",
      "epoch 134; iter: 0; batch classifier loss: 0.065762; batch adversarial loss: 0.441345\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050349; batch adversarial loss: 0.455785\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030457; batch adversarial loss: 0.449028\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024286; batch adversarial loss: 0.421136\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022429; batch adversarial loss: 0.353445\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037632; batch adversarial loss: 0.417369\n",
      "epoch 140; iter: 0; batch classifier loss: 0.066848; batch adversarial loss: 0.422856\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022957; batch adversarial loss: 0.515332\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031278; batch adversarial loss: 0.519261\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042325; batch adversarial loss: 0.546125\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022995; batch adversarial loss: 0.491103\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048454; batch adversarial loss: 0.363804\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021326; batch adversarial loss: 0.460066\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037253; batch adversarial loss: 0.473610\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016172; batch adversarial loss: 0.486862\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018667; batch adversarial loss: 0.373980\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013029; batch adversarial loss: 0.441551\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040951; batch adversarial loss: 0.442564\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022740; batch adversarial loss: 0.492101\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016806; batch adversarial loss: 0.504687\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031228; batch adversarial loss: 0.451754\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015906; batch adversarial loss: 0.483013\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028196; batch adversarial loss: 0.540077\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014645; batch adversarial loss: 0.497536\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019662; batch adversarial loss: 0.397233\n",
      "epoch 159; iter: 0; batch classifier loss: 0.046780; batch adversarial loss: 0.509020\n",
      "epoch 160; iter: 0; batch classifier loss: 0.050677; batch adversarial loss: 0.460073\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042153; batch adversarial loss: 0.567775\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019786; batch adversarial loss: 0.454582\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017781; batch adversarial loss: 0.416653\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009507; batch adversarial loss: 0.371454\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038544; batch adversarial loss: 0.450697\n",
      "epoch 166; iter: 0; batch classifier loss: 0.057287; batch adversarial loss: 0.456653\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013421; batch adversarial loss: 0.549763\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026384; batch adversarial loss: 0.505690\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021787; batch adversarial loss: 0.482109\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011968; batch adversarial loss: 0.490735\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009415; batch adversarial loss: 0.383488\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006869; batch adversarial loss: 0.452407\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007069; batch adversarial loss: 0.484443\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030703; batch adversarial loss: 0.503240\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019583; batch adversarial loss: 0.435317\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016795; batch adversarial loss: 0.473614\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017343; batch adversarial loss: 0.592521\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024903; batch adversarial loss: 0.453648\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019952; batch adversarial loss: 0.497469\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017337; batch adversarial loss: 0.606946\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011432; batch adversarial loss: 0.516759\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032316; batch adversarial loss: 0.461321\n",
      "epoch 183; iter: 0; batch classifier loss: 0.049514; batch adversarial loss: 0.454126\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009641; batch adversarial loss: 0.360169\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023362; batch adversarial loss: 0.527403\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009750; batch adversarial loss: 0.421870\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021851; batch adversarial loss: 0.409025\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022211; batch adversarial loss: 0.460583\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008166; batch adversarial loss: 0.454718\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017139; batch adversarial loss: 0.452547\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023862; batch adversarial loss: 0.444145\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021463; batch adversarial loss: 0.456393\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011741; batch adversarial loss: 0.416403\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011169; batch adversarial loss: 0.521356\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010034; batch adversarial loss: 0.452366\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029171; batch adversarial loss: 0.474882\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026691; batch adversarial loss: 0.488341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.011678; batch adversarial loss: 0.408516\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018625; batch adversarial loss: 0.469235\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701461; batch adversarial loss: 0.758840\n",
      "epoch 1; iter: 0; batch classifier loss: 0.528255; batch adversarial loss: 0.715442\n",
      "epoch 2; iter: 0; batch classifier loss: 0.404363; batch adversarial loss: 0.706811\n",
      "epoch 3; iter: 0; batch classifier loss: 0.377563; batch adversarial loss: 0.676246\n",
      "epoch 4; iter: 0; batch classifier loss: 0.373884; batch adversarial loss: 0.608752\n",
      "epoch 5; iter: 0; batch classifier loss: 0.245642; batch adversarial loss: 0.610466\n",
      "epoch 6; iter: 0; batch classifier loss: 0.346004; batch adversarial loss: 0.577205\n",
      "epoch 7; iter: 0; batch classifier loss: 0.282493; batch adversarial loss: 0.553735\n",
      "epoch 8; iter: 0; batch classifier loss: 0.256516; batch adversarial loss: 0.534837\n",
      "epoch 9; iter: 0; batch classifier loss: 0.371431; batch adversarial loss: 0.480600\n",
      "epoch 10; iter: 0; batch classifier loss: 0.224248; batch adversarial loss: 0.497147\n",
      "epoch 11; iter: 0; batch classifier loss: 0.225052; batch adversarial loss: 0.475195\n",
      "epoch 12; iter: 0; batch classifier loss: 0.250786; batch adversarial loss: 0.487438\n",
      "epoch 13; iter: 0; batch classifier loss: 0.155037; batch adversarial loss: 0.462433\n",
      "epoch 14; iter: 0; batch classifier loss: 0.203945; batch adversarial loss: 0.463312\n",
      "epoch 15; iter: 0; batch classifier loss: 0.131608; batch adversarial loss: 0.509650\n",
      "epoch 16; iter: 0; batch classifier loss: 0.181663; batch adversarial loss: 0.482137\n",
      "epoch 17; iter: 0; batch classifier loss: 0.172461; batch adversarial loss: 0.461825\n",
      "epoch 18; iter: 0; batch classifier loss: 0.170413; batch adversarial loss: 0.449034\n",
      "epoch 19; iter: 0; batch classifier loss: 0.132734; batch adversarial loss: 0.425893\n",
      "epoch 20; iter: 0; batch classifier loss: 0.147869; batch adversarial loss: 0.413771\n",
      "epoch 21; iter: 0; batch classifier loss: 0.164265; batch adversarial loss: 0.474550\n",
      "epoch 22; iter: 0; batch classifier loss: 0.163188; batch adversarial loss: 0.399626\n",
      "epoch 23; iter: 0; batch classifier loss: 0.151864; batch adversarial loss: 0.385911\n",
      "epoch 24; iter: 0; batch classifier loss: 0.139481; batch adversarial loss: 0.493116\n",
      "epoch 25; iter: 0; batch classifier loss: 0.159935; batch adversarial loss: 0.450658\n",
      "epoch 26; iter: 0; batch classifier loss: 0.137535; batch adversarial loss: 0.450418\n",
      "epoch 27; iter: 0; batch classifier loss: 0.124554; batch adversarial loss: 0.481390\n",
      "epoch 28; iter: 0; batch classifier loss: 0.115329; batch adversarial loss: 0.406332\n",
      "epoch 29; iter: 0; batch classifier loss: 0.143077; batch adversarial loss: 0.394271\n",
      "epoch 30; iter: 0; batch classifier loss: 0.129948; batch adversarial loss: 0.399908\n",
      "epoch 31; iter: 0; batch classifier loss: 0.120880; batch adversarial loss: 0.460041\n",
      "epoch 32; iter: 0; batch classifier loss: 0.123956; batch adversarial loss: 0.391546\n",
      "epoch 33; iter: 0; batch classifier loss: 0.149582; batch adversarial loss: 0.410587\n",
      "epoch 34; iter: 0; batch classifier loss: 0.126969; batch adversarial loss: 0.413177\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129033; batch adversarial loss: 0.405101\n",
      "epoch 36; iter: 0; batch classifier loss: 0.160416; batch adversarial loss: 0.382619\n",
      "epoch 37; iter: 0; batch classifier loss: 0.144334; batch adversarial loss: 0.409673\n",
      "epoch 38; iter: 0; batch classifier loss: 0.113892; batch adversarial loss: 0.373509\n",
      "epoch 39; iter: 0; batch classifier loss: 0.094082; batch adversarial loss: 0.392474\n",
      "epoch 40; iter: 0; batch classifier loss: 0.113745; batch adversarial loss: 0.351930\n",
      "epoch 41; iter: 0; batch classifier loss: 0.092232; batch adversarial loss: 0.475964\n",
      "epoch 42; iter: 0; batch classifier loss: 0.127597; batch adversarial loss: 0.398563\n",
      "epoch 43; iter: 0; batch classifier loss: 0.153606; batch adversarial loss: 0.386786\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105608; batch adversarial loss: 0.387514\n",
      "epoch 45; iter: 0; batch classifier loss: 0.083194; batch adversarial loss: 0.431607\n",
      "epoch 46; iter: 0; batch classifier loss: 0.138125; batch adversarial loss: 0.464812\n",
      "epoch 47; iter: 0; batch classifier loss: 0.102253; batch adversarial loss: 0.422429\n",
      "epoch 48; iter: 0; batch classifier loss: 0.101902; batch adversarial loss: 0.348951\n",
      "epoch 49; iter: 0; batch classifier loss: 0.112049; batch adversarial loss: 0.368723\n",
      "epoch 50; iter: 0; batch classifier loss: 0.157673; batch adversarial loss: 0.433001\n",
      "epoch 51; iter: 0; batch classifier loss: 0.114254; batch adversarial loss: 0.378996\n",
      "epoch 52; iter: 0; batch classifier loss: 0.133296; batch adversarial loss: 0.420995\n",
      "epoch 53; iter: 0; batch classifier loss: 0.115947; batch adversarial loss: 0.364918\n",
      "epoch 54; iter: 0; batch classifier loss: 0.062061; batch adversarial loss: 0.462766\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084881; batch adversarial loss: 0.465226\n",
      "epoch 56; iter: 0; batch classifier loss: 0.059074; batch adversarial loss: 0.520128\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112631; batch adversarial loss: 0.359489\n",
      "epoch 58; iter: 0; batch classifier loss: 0.098169; batch adversarial loss: 0.466203\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074900; batch adversarial loss: 0.360624\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097839; batch adversarial loss: 0.463810\n",
      "epoch 61; iter: 0; batch classifier loss: 0.070271; batch adversarial loss: 0.439246\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092866; batch adversarial loss: 0.422906\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095656; batch adversarial loss: 0.403150\n",
      "epoch 64; iter: 0; batch classifier loss: 0.094749; batch adversarial loss: 0.447316\n",
      "epoch 65; iter: 0; batch classifier loss: 0.056258; batch adversarial loss: 0.396713\n",
      "epoch 66; iter: 0; batch classifier loss: 0.067498; batch adversarial loss: 0.453964\n",
      "epoch 67; iter: 0; batch classifier loss: 0.070904; batch adversarial loss: 0.511629\n",
      "epoch 68; iter: 0; batch classifier loss: 0.101871; batch adversarial loss: 0.423245\n",
      "epoch 69; iter: 0; batch classifier loss: 0.052299; batch adversarial loss: 0.467298\n",
      "epoch 70; iter: 0; batch classifier loss: 0.081894; batch adversarial loss: 0.439678\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071484; batch adversarial loss: 0.408637\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070544; batch adversarial loss: 0.342386\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062774; batch adversarial loss: 0.427175\n",
      "epoch 74; iter: 0; batch classifier loss: 0.088467; batch adversarial loss: 0.460316\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069549; batch adversarial loss: 0.450701\n",
      "epoch 76; iter: 0; batch classifier loss: 0.054401; batch adversarial loss: 0.486722\n",
      "epoch 77; iter: 0; batch classifier loss: 0.034335; batch adversarial loss: 0.446984\n",
      "epoch 78; iter: 0; batch classifier loss: 0.068608; batch adversarial loss: 0.427407\n",
      "epoch 79; iter: 0; batch classifier loss: 0.034815; batch adversarial loss: 0.470482\n",
      "epoch 80; iter: 0; batch classifier loss: 0.038558; batch adversarial loss: 0.490320\n",
      "epoch 81; iter: 0; batch classifier loss: 0.059945; batch adversarial loss: 0.423908\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060988; batch adversarial loss: 0.419893\n",
      "epoch 83; iter: 0; batch classifier loss: 0.040261; batch adversarial loss: 0.449290\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046553; batch adversarial loss: 0.443022\n",
      "epoch 85; iter: 0; batch classifier loss: 0.027341; batch adversarial loss: 0.492891\n",
      "epoch 86; iter: 0; batch classifier loss: 0.055230; batch adversarial loss: 0.491770\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053637; batch adversarial loss: 0.421531\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059825; batch adversarial loss: 0.442401\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048845; batch adversarial loss: 0.473437\n",
      "epoch 90; iter: 0; batch classifier loss: 0.043401; batch adversarial loss: 0.404167\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043821; batch adversarial loss: 0.497856\n",
      "epoch 92; iter: 0; batch classifier loss: 0.036316; batch adversarial loss: 0.410111\n",
      "epoch 93; iter: 0; batch classifier loss: 0.029889; batch adversarial loss: 0.532584\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033663; batch adversarial loss: 0.430369\n",
      "epoch 95; iter: 0; batch classifier loss: 0.028337; batch adversarial loss: 0.464816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.028808; batch adversarial loss: 0.473592\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053946; batch adversarial loss: 0.449973\n",
      "epoch 98; iter: 0; batch classifier loss: 0.018935; batch adversarial loss: 0.402710\n",
      "epoch 99; iter: 0; batch classifier loss: 0.035676; batch adversarial loss: 0.579380\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067476; batch adversarial loss: 0.397782\n",
      "epoch 101; iter: 0; batch classifier loss: 0.127555; batch adversarial loss: 0.609940\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066288; batch adversarial loss: 0.521076\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058796; batch adversarial loss: 0.583670\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043288; batch adversarial loss: 0.457673\n",
      "epoch 105; iter: 0; batch classifier loss: 0.147403; batch adversarial loss: 0.713175\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063937; batch adversarial loss: 0.531011\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072500; batch adversarial loss: 0.485214\n",
      "epoch 108; iter: 0; batch classifier loss: 0.130481; batch adversarial loss: 0.486745\n",
      "epoch 109; iter: 0; batch classifier loss: 0.114064; batch adversarial loss: 0.634576\n",
      "epoch 110; iter: 0; batch classifier loss: 0.092644; batch adversarial loss: 0.445504\n",
      "epoch 111; iter: 0; batch classifier loss: 0.168582; batch adversarial loss: 0.652319\n",
      "epoch 112; iter: 0; batch classifier loss: 0.172251; batch adversarial loss: 0.720192\n",
      "epoch 113; iter: 0; batch classifier loss: 0.145672; batch adversarial loss: 0.568882\n",
      "epoch 114; iter: 0; batch classifier loss: 0.169476; batch adversarial loss: 0.577911\n",
      "epoch 115; iter: 0; batch classifier loss: 0.132473; batch adversarial loss: 0.665898\n",
      "epoch 116; iter: 0; batch classifier loss: 0.114241; batch adversarial loss: 0.604466\n",
      "epoch 117; iter: 0; batch classifier loss: 0.211848; batch adversarial loss: 0.678089\n",
      "epoch 118; iter: 0; batch classifier loss: 0.106980; batch adversarial loss: 0.524711\n",
      "epoch 119; iter: 0; batch classifier loss: 0.165561; batch adversarial loss: 0.599023\n",
      "epoch 120; iter: 0; batch classifier loss: 0.153491; batch adversarial loss: 0.524698\n",
      "epoch 121; iter: 0; batch classifier loss: 0.192688; batch adversarial loss: 0.659565\n",
      "epoch 122; iter: 0; batch classifier loss: 0.206033; batch adversarial loss: 0.638892\n",
      "epoch 123; iter: 0; batch classifier loss: 0.157063; batch adversarial loss: 0.533565\n",
      "epoch 124; iter: 0; batch classifier loss: 0.178096; batch adversarial loss: 0.570731\n",
      "epoch 125; iter: 0; batch classifier loss: 0.155032; batch adversarial loss: 0.562476\n",
      "epoch 126; iter: 0; batch classifier loss: 0.152462; batch adversarial loss: 0.559551\n",
      "epoch 127; iter: 0; batch classifier loss: 0.149067; batch adversarial loss: 0.509772\n",
      "epoch 128; iter: 0; batch classifier loss: 0.102924; batch adversarial loss: 0.529543\n",
      "epoch 129; iter: 0; batch classifier loss: 0.115767; batch adversarial loss: 0.569415\n",
      "epoch 130; iter: 0; batch classifier loss: 0.145612; batch adversarial loss: 0.536637\n",
      "epoch 131; iter: 0; batch classifier loss: 0.131051; batch adversarial loss: 0.559421\n",
      "epoch 132; iter: 0; batch classifier loss: 0.091592; batch adversarial loss: 0.382934\n",
      "epoch 133; iter: 0; batch classifier loss: 0.169279; batch adversarial loss: 0.513531\n",
      "epoch 134; iter: 0; batch classifier loss: 0.098617; batch adversarial loss: 0.440498\n",
      "epoch 135; iter: 0; batch classifier loss: 0.111987; batch adversarial loss: 0.473700\n",
      "epoch 136; iter: 0; batch classifier loss: 0.114484; batch adversarial loss: 0.505450\n",
      "epoch 137; iter: 0; batch classifier loss: 0.135934; batch adversarial loss: 0.455459\n",
      "epoch 138; iter: 0; batch classifier loss: 0.118899; batch adversarial loss: 0.484668\n",
      "epoch 139; iter: 0; batch classifier loss: 0.135852; batch adversarial loss: 0.546257\n",
      "epoch 140; iter: 0; batch classifier loss: 0.115625; batch adversarial loss: 0.525713\n",
      "epoch 141; iter: 0; batch classifier loss: 0.117301; batch adversarial loss: 0.512057\n",
      "epoch 142; iter: 0; batch classifier loss: 0.122033; batch adversarial loss: 0.495717\n",
      "epoch 143; iter: 0; batch classifier loss: 0.166354; batch adversarial loss: 0.375249\n",
      "epoch 144; iter: 0; batch classifier loss: 0.051183; batch adversarial loss: 0.479103\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037028; batch adversarial loss: 0.443398\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021532; batch adversarial loss: 0.406597\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021221; batch adversarial loss: 0.484174\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029382; batch adversarial loss: 0.484449\n",
      "epoch 149; iter: 0; batch classifier loss: 0.082376; batch adversarial loss: 0.467161\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020899; batch adversarial loss: 0.550539\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040571; batch adversarial loss: 0.485677\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015786; batch adversarial loss: 0.471215\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040015; batch adversarial loss: 0.448236\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037097; batch adversarial loss: 0.546214\n",
      "epoch 155; iter: 0; batch classifier loss: 0.114618; batch adversarial loss: 0.433974\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042121; batch adversarial loss: 0.465774\n",
      "epoch 157; iter: 0; batch classifier loss: 0.051570; batch adversarial loss: 0.480733\n",
      "epoch 158; iter: 0; batch classifier loss: 0.072163; batch adversarial loss: 0.510737\n",
      "epoch 159; iter: 0; batch classifier loss: 0.119348; batch adversarial loss: 0.476195\n",
      "epoch 160; iter: 0; batch classifier loss: 0.099821; batch adversarial loss: 0.418952\n",
      "epoch 161; iter: 0; batch classifier loss: 0.049737; batch adversarial loss: 0.472255\n",
      "epoch 162; iter: 0; batch classifier loss: 0.092358; batch adversarial loss: 0.429108\n",
      "epoch 163; iter: 0; batch classifier loss: 0.093289; batch adversarial loss: 0.442888\n",
      "epoch 164; iter: 0; batch classifier loss: 0.073951; batch adversarial loss: 0.502199\n",
      "epoch 165; iter: 0; batch classifier loss: 0.097146; batch adversarial loss: 0.472476\n",
      "epoch 166; iter: 0; batch classifier loss: 0.051909; batch adversarial loss: 0.515714\n",
      "epoch 167; iter: 0; batch classifier loss: 0.082409; batch adversarial loss: 0.463252\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038334; batch adversarial loss: 0.430807\n",
      "epoch 169; iter: 0; batch classifier loss: 0.107960; batch adversarial loss: 0.457312\n",
      "epoch 170; iter: 0; batch classifier loss: 0.070212; batch adversarial loss: 0.544097\n",
      "epoch 171; iter: 0; batch classifier loss: 0.083505; batch adversarial loss: 0.478997\n",
      "epoch 172; iter: 0; batch classifier loss: 0.123513; batch adversarial loss: 0.537598\n",
      "epoch 173; iter: 0; batch classifier loss: 0.062229; batch adversarial loss: 0.364758\n",
      "epoch 174; iter: 0; batch classifier loss: 0.088378; batch adversarial loss: 0.514377\n",
      "epoch 175; iter: 0; batch classifier loss: 0.167647; batch adversarial loss: 0.564823\n",
      "epoch 176; iter: 0; batch classifier loss: 0.119551; batch adversarial loss: 0.489605\n",
      "epoch 177; iter: 0; batch classifier loss: 0.107949; batch adversarial loss: 0.413726\n",
      "epoch 178; iter: 0; batch classifier loss: 0.081691; batch adversarial loss: 0.498252\n",
      "epoch 179; iter: 0; batch classifier loss: 0.059408; batch adversarial loss: 0.433408\n",
      "epoch 180; iter: 0; batch classifier loss: 0.051801; batch adversarial loss: 0.495086\n",
      "epoch 181; iter: 0; batch classifier loss: 0.069771; batch adversarial loss: 0.487053\n",
      "epoch 182; iter: 0; batch classifier loss: 0.144780; batch adversarial loss: 0.425609\n",
      "epoch 183; iter: 0; batch classifier loss: 0.071131; batch adversarial loss: 0.390036\n",
      "epoch 184; iter: 0; batch classifier loss: 0.082903; batch adversarial loss: 0.424872\n",
      "epoch 185; iter: 0; batch classifier loss: 0.101405; batch adversarial loss: 0.441654\n",
      "epoch 186; iter: 0; batch classifier loss: 0.069417; batch adversarial loss: 0.362339\n",
      "epoch 187; iter: 0; batch classifier loss: 0.077317; batch adversarial loss: 0.424821\n",
      "epoch 188; iter: 0; batch classifier loss: 0.153165; batch adversarial loss: 0.454291\n",
      "epoch 189; iter: 0; batch classifier loss: 0.070282; batch adversarial loss: 0.495228\n",
      "epoch 190; iter: 0; batch classifier loss: 0.087362; batch adversarial loss: 0.519839\n",
      "epoch 191; iter: 0; batch classifier loss: 0.086778; batch adversarial loss: 0.491144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.070026; batch adversarial loss: 0.486474\n",
      "epoch 193; iter: 0; batch classifier loss: 0.068545; batch adversarial loss: 0.567161\n",
      "epoch 194; iter: 0; batch classifier loss: 0.045434; batch adversarial loss: 0.506501\n",
      "epoch 195; iter: 0; batch classifier loss: 0.045930; batch adversarial loss: 0.500736\n",
      "epoch 196; iter: 0; batch classifier loss: 0.099555; batch adversarial loss: 0.421331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033624; batch adversarial loss: 0.424798\n",
      "epoch 198; iter: 0; batch classifier loss: 0.096611; batch adversarial loss: 0.461350\n",
      "epoch 199; iter: 0; batch classifier loss: 0.078841; batch adversarial loss: 0.546322\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710333; batch adversarial loss: 0.667080\n",
      "epoch 1; iter: 0; batch classifier loss: 0.368212; batch adversarial loss: 0.638584\n",
      "epoch 2; iter: 0; batch classifier loss: 0.339649; batch adversarial loss: 0.608616\n",
      "epoch 3; iter: 0; batch classifier loss: 0.355421; batch adversarial loss: 0.609788\n",
      "epoch 4; iter: 0; batch classifier loss: 0.293692; batch adversarial loss: 0.604516\n",
      "epoch 5; iter: 0; batch classifier loss: 0.337239; batch adversarial loss: 0.578406\n",
      "epoch 6; iter: 0; batch classifier loss: 0.261783; batch adversarial loss: 0.511031\n",
      "epoch 7; iter: 0; batch classifier loss: 0.254641; batch adversarial loss: 0.546656\n",
      "epoch 8; iter: 0; batch classifier loss: 0.280873; batch adversarial loss: 0.556754\n",
      "epoch 9; iter: 0; batch classifier loss: 0.215311; batch adversarial loss: 0.489607\n",
      "epoch 10; iter: 0; batch classifier loss: 0.259582; batch adversarial loss: 0.554348\n",
      "epoch 11; iter: 0; batch classifier loss: 0.255862; batch adversarial loss: 0.499564\n",
      "epoch 12; iter: 0; batch classifier loss: 0.267639; batch adversarial loss: 0.493594\n",
      "epoch 13; iter: 0; batch classifier loss: 0.255118; batch adversarial loss: 0.488355\n",
      "epoch 14; iter: 0; batch classifier loss: 0.271562; batch adversarial loss: 0.516223\n",
      "epoch 15; iter: 0; batch classifier loss: 0.323038; batch adversarial loss: 0.542708\n",
      "epoch 16; iter: 0; batch classifier loss: 0.368596; batch adversarial loss: 0.585661\n",
      "epoch 17; iter: 0; batch classifier loss: 0.539575; batch adversarial loss: 0.489141\n",
      "epoch 18; iter: 0; batch classifier loss: 0.405020; batch adversarial loss: 0.570696\n",
      "epoch 19; iter: 0; batch classifier loss: 0.331766; batch adversarial loss: 0.570777\n",
      "epoch 20; iter: 0; batch classifier loss: 0.246959; batch adversarial loss: 0.479509\n",
      "epoch 21; iter: 0; batch classifier loss: 0.176957; batch adversarial loss: 0.467955\n",
      "epoch 22; iter: 0; batch classifier loss: 0.198652; batch adversarial loss: 0.499260\n",
      "epoch 23; iter: 0; batch classifier loss: 0.155633; batch adversarial loss: 0.453313\n",
      "epoch 24; iter: 0; batch classifier loss: 0.161323; batch adversarial loss: 0.430771\n",
      "epoch 25; iter: 0; batch classifier loss: 0.173739; batch adversarial loss: 0.519257\n",
      "epoch 26; iter: 0; batch classifier loss: 0.149292; batch adversarial loss: 0.407929\n",
      "epoch 27; iter: 0; batch classifier loss: 0.185804; batch adversarial loss: 0.403617\n",
      "epoch 28; iter: 0; batch classifier loss: 0.154313; batch adversarial loss: 0.569054\n",
      "epoch 29; iter: 0; batch classifier loss: 0.143791; batch adversarial loss: 0.500851\n",
      "epoch 30; iter: 0; batch classifier loss: 0.103798; batch adversarial loss: 0.488600\n",
      "epoch 31; iter: 0; batch classifier loss: 0.173703; batch adversarial loss: 0.399810\n",
      "epoch 32; iter: 0; batch classifier loss: 0.121447; batch adversarial loss: 0.498442\n",
      "epoch 33; iter: 0; batch classifier loss: 0.156456; batch adversarial loss: 0.553817\n",
      "epoch 34; iter: 0; batch classifier loss: 0.138193; batch adversarial loss: 0.495386\n",
      "epoch 35; iter: 0; batch classifier loss: 0.115475; batch adversarial loss: 0.457281\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141460; batch adversarial loss: 0.450625\n",
      "epoch 37; iter: 0; batch classifier loss: 0.112795; batch adversarial loss: 0.506152\n",
      "epoch 38; iter: 0; batch classifier loss: 0.086491; batch adversarial loss: 0.424018\n",
      "epoch 39; iter: 0; batch classifier loss: 0.133366; batch adversarial loss: 0.497505\n",
      "epoch 40; iter: 0; batch classifier loss: 0.105715; batch adversarial loss: 0.455423\n",
      "epoch 41; iter: 0; batch classifier loss: 0.136538; batch adversarial loss: 0.487526\n",
      "epoch 42; iter: 0; batch classifier loss: 0.077015; batch adversarial loss: 0.448781\n",
      "epoch 43; iter: 0; batch classifier loss: 0.133675; batch adversarial loss: 0.486512\n",
      "epoch 44; iter: 0; batch classifier loss: 0.155741; batch adversarial loss: 0.462688\n",
      "epoch 45; iter: 0; batch classifier loss: 0.170876; batch adversarial loss: 0.490495\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116819; batch adversarial loss: 0.451871\n",
      "epoch 47; iter: 0; batch classifier loss: 0.149975; batch adversarial loss: 0.466918\n",
      "epoch 48; iter: 0; batch classifier loss: 0.128072; batch adversarial loss: 0.549935\n",
      "epoch 49; iter: 0; batch classifier loss: 0.088315; batch adversarial loss: 0.409569\n",
      "epoch 50; iter: 0; batch classifier loss: 0.089260; batch adversarial loss: 0.420188\n",
      "epoch 51; iter: 0; batch classifier loss: 0.099538; batch adversarial loss: 0.464498\n",
      "epoch 52; iter: 0; batch classifier loss: 0.113583; batch adversarial loss: 0.406951\n",
      "epoch 53; iter: 0; batch classifier loss: 0.117146; batch adversarial loss: 0.528347\n",
      "epoch 54; iter: 0; batch classifier loss: 0.150550; batch adversarial loss: 0.494989\n",
      "epoch 55; iter: 0; batch classifier loss: 0.160885; batch adversarial loss: 0.445556\n",
      "epoch 56; iter: 0; batch classifier loss: 0.179976; batch adversarial loss: 0.545567\n",
      "epoch 57; iter: 0; batch classifier loss: 0.125771; batch adversarial loss: 0.394011\n",
      "epoch 58; iter: 0; batch classifier loss: 0.156079; batch adversarial loss: 0.422765\n",
      "epoch 59; iter: 0; batch classifier loss: 0.066922; batch adversarial loss: 0.483512\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087572; batch adversarial loss: 0.477767\n",
      "epoch 61; iter: 0; batch classifier loss: 0.119837; batch adversarial loss: 0.448010\n",
      "epoch 62; iter: 0; batch classifier loss: 0.071580; batch adversarial loss: 0.513897\n",
      "epoch 63; iter: 0; batch classifier loss: 0.114079; batch adversarial loss: 0.498538\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106611; batch adversarial loss: 0.488043\n",
      "epoch 65; iter: 0; batch classifier loss: 0.132473; batch adversarial loss: 0.444956\n",
      "epoch 66; iter: 0; batch classifier loss: 0.119696; batch adversarial loss: 0.485133\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101156; batch adversarial loss: 0.490483\n",
      "epoch 68; iter: 0; batch classifier loss: 0.111514; batch adversarial loss: 0.398854\n",
      "epoch 69; iter: 0; batch classifier loss: 0.111820; batch adversarial loss: 0.491278\n",
      "epoch 70; iter: 0; batch classifier loss: 0.172270; batch adversarial loss: 0.380322\n",
      "epoch 71; iter: 0; batch classifier loss: 0.155479; batch adversarial loss: 0.522902\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097093; batch adversarial loss: 0.463730\n",
      "epoch 73; iter: 0; batch classifier loss: 0.137461; batch adversarial loss: 0.504608\n",
      "epoch 74; iter: 0; batch classifier loss: 0.088480; batch adversarial loss: 0.411465\n",
      "epoch 75; iter: 0; batch classifier loss: 0.085069; batch adversarial loss: 0.457132\n",
      "epoch 76; iter: 0; batch classifier loss: 0.122358; batch adversarial loss: 0.472175\n",
      "epoch 77; iter: 0; batch classifier loss: 0.136515; batch adversarial loss: 0.450749\n",
      "epoch 78; iter: 0; batch classifier loss: 0.060270; batch adversarial loss: 0.495367\n",
      "epoch 79; iter: 0; batch classifier loss: 0.133377; batch adversarial loss: 0.413175\n",
      "epoch 80; iter: 0; batch classifier loss: 0.107082; batch adversarial loss: 0.493272\n",
      "epoch 81; iter: 0; batch classifier loss: 0.123812; batch adversarial loss: 0.519532\n",
      "epoch 82; iter: 0; batch classifier loss: 0.092213; batch adversarial loss: 0.387809\n",
      "epoch 83; iter: 0; batch classifier loss: 0.116917; batch adversarial loss: 0.438105\n",
      "epoch 84; iter: 0; batch classifier loss: 0.112523; batch adversarial loss: 0.588390\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061281; batch adversarial loss: 0.514466\n",
      "epoch 86; iter: 0; batch classifier loss: 0.162684; batch adversarial loss: 0.402748\n",
      "epoch 87; iter: 0; batch classifier loss: 0.107247; batch adversarial loss: 0.521926\n",
      "epoch 88; iter: 0; batch classifier loss: 0.157794; batch adversarial loss: 0.449242\n",
      "epoch 89; iter: 0; batch classifier loss: 0.090744; batch adversarial loss: 0.404618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.100464; batch adversarial loss: 0.464494\n",
      "epoch 91; iter: 0; batch classifier loss: 0.085277; batch adversarial loss: 0.334903\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047767; batch adversarial loss: 0.394530\n",
      "epoch 93; iter: 0; batch classifier loss: 0.068841; batch adversarial loss: 0.451482\n",
      "epoch 94; iter: 0; batch classifier loss: 0.085739; batch adversarial loss: 0.571350\n",
      "epoch 95; iter: 0; batch classifier loss: 0.090309; batch adversarial loss: 0.500610\n",
      "epoch 96; iter: 0; batch classifier loss: 0.117084; batch adversarial loss: 0.487023\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039745; batch adversarial loss: 0.419082\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050691; batch adversarial loss: 0.344402\n",
      "epoch 99; iter: 0; batch classifier loss: 0.120907; batch adversarial loss: 0.466183\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057668; batch adversarial loss: 0.466079\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065380; batch adversarial loss: 0.469456\n",
      "epoch 102; iter: 0; batch classifier loss: 0.077625; batch adversarial loss: 0.443841\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056966; batch adversarial loss: 0.405659\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060608; batch adversarial loss: 0.473981\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055260; batch adversarial loss: 0.448156\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071526; batch adversarial loss: 0.489990\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055190; batch adversarial loss: 0.433334\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048626; batch adversarial loss: 0.453900\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066203; batch adversarial loss: 0.387781\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033486; batch adversarial loss: 0.441534\n",
      "epoch 111; iter: 0; batch classifier loss: 0.068318; batch adversarial loss: 0.447995\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052965; batch adversarial loss: 0.557647\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033523; batch adversarial loss: 0.488206\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027104; batch adversarial loss: 0.443678\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062938; batch adversarial loss: 0.502600\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041800; batch adversarial loss: 0.405216\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038202; batch adversarial loss: 0.485935\n",
      "epoch 118; iter: 0; batch classifier loss: 0.008755; batch adversarial loss: 0.605130\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052191; batch adversarial loss: 0.407509\n",
      "epoch 120; iter: 0; batch classifier loss: 0.023497; batch adversarial loss: 0.405495\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042367; batch adversarial loss: 0.475371\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036621; batch adversarial loss: 0.493816\n",
      "epoch 123; iter: 0; batch classifier loss: 0.107564; batch adversarial loss: 0.541869\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024335; batch adversarial loss: 0.441194\n",
      "epoch 125; iter: 0; batch classifier loss: 0.063439; batch adversarial loss: 0.444944\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024503; batch adversarial loss: 0.507011\n",
      "epoch 127; iter: 0; batch classifier loss: 0.069458; batch adversarial loss: 0.394887\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043149; batch adversarial loss: 0.544903\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031848; batch adversarial loss: 0.539305\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034604; batch adversarial loss: 0.509086\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029441; batch adversarial loss: 0.500727\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034645; batch adversarial loss: 0.572966\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060951; batch adversarial loss: 0.525952\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042227; batch adversarial loss: 0.504679\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043761; batch adversarial loss: 0.418557\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023246; batch adversarial loss: 0.522921\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031863; batch adversarial loss: 0.399066\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025228; batch adversarial loss: 0.462637\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018446; batch adversarial loss: 0.480128\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053711; batch adversarial loss: 0.431622\n",
      "epoch 141; iter: 0; batch classifier loss: 0.056237; batch adversarial loss: 0.554814\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016468; batch adversarial loss: 0.550008\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030909; batch adversarial loss: 0.446667\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031948; batch adversarial loss: 0.532239\n",
      "epoch 145; iter: 0; batch classifier loss: 0.009151; batch adversarial loss: 0.404428\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045857; batch adversarial loss: 0.457247\n",
      "epoch 147; iter: 0; batch classifier loss: 0.069467; batch adversarial loss: 0.466779\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021872; batch adversarial loss: 0.431665\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034873; batch adversarial loss: 0.380783\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010993; batch adversarial loss: 0.597730\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034538; batch adversarial loss: 0.496456\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035848; batch adversarial loss: 0.476667\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015793; batch adversarial loss: 0.478139\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016071; batch adversarial loss: 0.532986\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016503; batch adversarial loss: 0.459797\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036038; batch adversarial loss: 0.553711\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013121; batch adversarial loss: 0.354548\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018618; batch adversarial loss: 0.513574\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023516; batch adversarial loss: 0.536546\n",
      "epoch 160; iter: 0; batch classifier loss: 0.004347; batch adversarial loss: 0.453303\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016913; batch adversarial loss: 0.501714\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015385; batch adversarial loss: 0.453466\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013778; batch adversarial loss: 0.451411\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016978; batch adversarial loss: 0.514624\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036359; batch adversarial loss: 0.515837\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022582; batch adversarial loss: 0.547240\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025500; batch adversarial loss: 0.327606\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028608; batch adversarial loss: 0.469914\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027689; batch adversarial loss: 0.468039\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014182; batch adversarial loss: 0.433870\n",
      "epoch 171; iter: 0; batch classifier loss: 0.043153; batch adversarial loss: 0.430196\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031705; batch adversarial loss: 0.489658\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012520; batch adversarial loss: 0.470811\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019862; batch adversarial loss: 0.425140\n",
      "epoch 175; iter: 0; batch classifier loss: 0.050245; batch adversarial loss: 0.459353\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010058; batch adversarial loss: 0.401338\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026381; batch adversarial loss: 0.505060\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007928; batch adversarial loss: 0.453282\n",
      "epoch 179; iter: 0; batch classifier loss: 0.067554; batch adversarial loss: 0.558297\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041627; batch adversarial loss: 0.441255\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011222; batch adversarial loss: 0.459548\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023917; batch adversarial loss: 0.492557\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018294; batch adversarial loss: 0.524975\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024876; batch adversarial loss: 0.421055\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026532; batch adversarial loss: 0.409414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.034885; batch adversarial loss: 0.532790\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023143; batch adversarial loss: 0.464798\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027508; batch adversarial loss: 0.500511\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022025; batch adversarial loss: 0.421447\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013944; batch adversarial loss: 0.408589\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008850; batch adversarial loss: 0.416194\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018359; batch adversarial loss: 0.378663\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014865; batch adversarial loss: 0.548958\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032189; batch adversarial loss: 0.477566\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011765; batch adversarial loss: 0.486387\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005617; batch adversarial loss: 0.466261\n",
      "epoch 197; iter: 0; batch classifier loss: 0.042361; batch adversarial loss: 0.485890\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008519; batch adversarial loss: 0.453312\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005214; batch adversarial loss: 0.526756\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716375; batch adversarial loss: 0.692630\n",
      "epoch 1; iter: 0; batch classifier loss: 0.460577; batch adversarial loss: 0.669259\n",
      "epoch 2; iter: 0; batch classifier loss: 0.373488; batch adversarial loss: 0.635139\n",
      "epoch 3; iter: 0; batch classifier loss: 0.403138; batch adversarial loss: 0.588283\n",
      "epoch 4; iter: 0; batch classifier loss: 0.304843; batch adversarial loss: 0.552739\n",
      "epoch 5; iter: 0; batch classifier loss: 0.380214; batch adversarial loss: 0.531997\n",
      "epoch 6; iter: 0; batch classifier loss: 0.342702; batch adversarial loss: 0.487204\n",
      "epoch 7; iter: 0; batch classifier loss: 0.324322; batch adversarial loss: 0.556593\n",
      "epoch 8; iter: 0; batch classifier loss: 0.379264; batch adversarial loss: 0.473610\n",
      "epoch 9; iter: 0; batch classifier loss: 0.246835; batch adversarial loss: 0.488217\n",
      "epoch 10; iter: 0; batch classifier loss: 0.248014; batch adversarial loss: 0.494133\n",
      "epoch 11; iter: 0; batch classifier loss: 0.227577; batch adversarial loss: 0.498002\n",
      "epoch 12; iter: 0; batch classifier loss: 0.200850; batch adversarial loss: 0.454639\n",
      "epoch 13; iter: 0; batch classifier loss: 0.241259; batch adversarial loss: 0.481350\n",
      "epoch 14; iter: 0; batch classifier loss: 0.161034; batch adversarial loss: 0.454692\n",
      "epoch 15; iter: 0; batch classifier loss: 0.224919; batch adversarial loss: 0.486087\n",
      "epoch 16; iter: 0; batch classifier loss: 0.193387; batch adversarial loss: 0.509539\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192667; batch adversarial loss: 0.478045\n",
      "epoch 18; iter: 0; batch classifier loss: 0.147783; batch adversarial loss: 0.522556\n",
      "epoch 19; iter: 0; batch classifier loss: 0.197983; batch adversarial loss: 0.629687\n",
      "epoch 20; iter: 0; batch classifier loss: 0.150652; batch adversarial loss: 0.563237\n",
      "epoch 21; iter: 0; batch classifier loss: 0.267529; batch adversarial loss: 0.538940\n",
      "epoch 22; iter: 0; batch classifier loss: 0.217752; batch adversarial loss: 0.579846\n",
      "epoch 23; iter: 0; batch classifier loss: 0.273373; batch adversarial loss: 0.565980\n",
      "epoch 24; iter: 0; batch classifier loss: 0.292314; batch adversarial loss: 0.540211\n",
      "epoch 25; iter: 0; batch classifier loss: 0.304765; batch adversarial loss: 0.470117\n",
      "epoch 26; iter: 0; batch classifier loss: 0.347942; batch adversarial loss: 0.453112\n",
      "epoch 27; iter: 0; batch classifier loss: 0.217300; batch adversarial loss: 0.422744\n",
      "epoch 28; iter: 0; batch classifier loss: 0.182422; batch adversarial loss: 0.476946\n",
      "epoch 29; iter: 0; batch classifier loss: 0.123705; batch adversarial loss: 0.482413\n",
      "epoch 30; iter: 0; batch classifier loss: 0.098593; batch adversarial loss: 0.428305\n",
      "epoch 31; iter: 0; batch classifier loss: 0.100914; batch adversarial loss: 0.491421\n",
      "epoch 32; iter: 0; batch classifier loss: 0.109564; batch adversarial loss: 0.503498\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128029; batch adversarial loss: 0.502959\n",
      "epoch 34; iter: 0; batch classifier loss: 0.099154; batch adversarial loss: 0.459951\n",
      "epoch 35; iter: 0; batch classifier loss: 0.117987; batch adversarial loss: 0.462681\n",
      "epoch 36; iter: 0; batch classifier loss: 0.129910; batch adversarial loss: 0.491766\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110198; batch adversarial loss: 0.445259\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127122; batch adversarial loss: 0.495393\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148793; batch adversarial loss: 0.416497\n",
      "epoch 40; iter: 0; batch classifier loss: 0.123564; batch adversarial loss: 0.447163\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109452; batch adversarial loss: 0.439819\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113518; batch adversarial loss: 0.489288\n",
      "epoch 43; iter: 0; batch classifier loss: 0.102006; batch adversarial loss: 0.478865\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107836; batch adversarial loss: 0.470605\n",
      "epoch 45; iter: 0; batch classifier loss: 0.094120; batch adversarial loss: 0.458573\n",
      "epoch 46; iter: 0; batch classifier loss: 0.075604; batch adversarial loss: 0.498994\n",
      "epoch 47; iter: 0; batch classifier loss: 0.074295; batch adversarial loss: 0.446907\n",
      "epoch 48; iter: 0; batch classifier loss: 0.106139; batch adversarial loss: 0.351285\n",
      "epoch 49; iter: 0; batch classifier loss: 0.104640; batch adversarial loss: 0.443435\n",
      "epoch 50; iter: 0; batch classifier loss: 0.071988; batch adversarial loss: 0.469817\n",
      "epoch 51; iter: 0; batch classifier loss: 0.089866; batch adversarial loss: 0.429211\n",
      "epoch 52; iter: 0; batch classifier loss: 0.091923; batch adversarial loss: 0.545822\n",
      "epoch 53; iter: 0; batch classifier loss: 0.081019; batch adversarial loss: 0.434085\n",
      "epoch 54; iter: 0; batch classifier loss: 0.088048; batch adversarial loss: 0.440671\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072891; batch adversarial loss: 0.520490\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065440; batch adversarial loss: 0.535401\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079698; batch adversarial loss: 0.441861\n",
      "epoch 58; iter: 0; batch classifier loss: 0.076875; batch adversarial loss: 0.467221\n",
      "epoch 59; iter: 0; batch classifier loss: 0.078395; batch adversarial loss: 0.495805\n",
      "epoch 60; iter: 0; batch classifier loss: 0.094291; batch adversarial loss: 0.468220\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099659; batch adversarial loss: 0.390868\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085474; batch adversarial loss: 0.446382\n",
      "epoch 63; iter: 0; batch classifier loss: 0.055058; batch adversarial loss: 0.443407\n",
      "epoch 64; iter: 0; batch classifier loss: 0.112954; batch adversarial loss: 0.436815\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065143; batch adversarial loss: 0.570448\n",
      "epoch 66; iter: 0; batch classifier loss: 0.111454; batch adversarial loss: 0.455224\n",
      "epoch 67; iter: 0; batch classifier loss: 0.117796; batch adversarial loss: 0.446216\n",
      "epoch 68; iter: 0; batch classifier loss: 0.067814; batch adversarial loss: 0.381628\n",
      "epoch 69; iter: 0; batch classifier loss: 0.054870; batch adversarial loss: 0.479976\n",
      "epoch 70; iter: 0; batch classifier loss: 0.081912; batch adversarial loss: 0.413261\n",
      "epoch 71; iter: 0; batch classifier loss: 0.080133; batch adversarial loss: 0.447868\n",
      "epoch 72; iter: 0; batch classifier loss: 0.151848; batch adversarial loss: 0.545812\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062290; batch adversarial loss: 0.393326\n",
      "epoch 74; iter: 0; batch classifier loss: 0.049204; batch adversarial loss: 0.385606\n",
      "epoch 75; iter: 0; batch classifier loss: 0.078693; batch adversarial loss: 0.521734\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076048; batch adversarial loss: 0.450736\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069047; batch adversarial loss: 0.468256\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080337; batch adversarial loss: 0.404370\n",
      "epoch 79; iter: 0; batch classifier loss: 0.050750; batch adversarial loss: 0.400081\n",
      "epoch 80; iter: 0; batch classifier loss: 0.029239; batch adversarial loss: 0.541280\n",
      "epoch 81; iter: 0; batch classifier loss: 0.091978; batch adversarial loss: 0.429512\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073573; batch adversarial loss: 0.477946\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054263; batch adversarial loss: 0.453215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.057236; batch adversarial loss: 0.405615\n",
      "epoch 85; iter: 0; batch classifier loss: 0.035659; batch adversarial loss: 0.474825\n",
      "epoch 86; iter: 0; batch classifier loss: 0.113947; batch adversarial loss: 0.440864\n",
      "epoch 87; iter: 0; batch classifier loss: 0.034395; batch adversarial loss: 0.508355\n",
      "epoch 88; iter: 0; batch classifier loss: 0.080497; batch adversarial loss: 0.534575\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047073; batch adversarial loss: 0.399841\n",
      "epoch 90; iter: 0; batch classifier loss: 0.069707; batch adversarial loss: 0.544354\n",
      "epoch 91; iter: 0; batch classifier loss: 0.042357; batch adversarial loss: 0.452020\n",
      "epoch 92; iter: 0; batch classifier loss: 0.033582; batch adversarial loss: 0.501272\n",
      "epoch 93; iter: 0; batch classifier loss: 0.038631; batch adversarial loss: 0.457942\n",
      "epoch 94; iter: 0; batch classifier loss: 0.054171; batch adversarial loss: 0.410647\n",
      "epoch 95; iter: 0; batch classifier loss: 0.026194; batch adversarial loss: 0.509437\n",
      "epoch 96; iter: 0; batch classifier loss: 0.067198; batch adversarial loss: 0.437587\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037208; batch adversarial loss: 0.451679\n",
      "epoch 98; iter: 0; batch classifier loss: 0.031000; batch adversarial loss: 0.445203\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045037; batch adversarial loss: 0.531740\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051550; batch adversarial loss: 0.382041\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055386; batch adversarial loss: 0.462069\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032698; batch adversarial loss: 0.496547\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042816; batch adversarial loss: 0.459182\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031233; batch adversarial loss: 0.499070\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044903; batch adversarial loss: 0.502049\n",
      "epoch 106; iter: 0; batch classifier loss: 0.017075; batch adversarial loss: 0.462136\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052989; batch adversarial loss: 0.455943\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055760; batch adversarial loss: 0.489506\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066289; batch adversarial loss: 0.513931\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035069; batch adversarial loss: 0.466472\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045809; batch adversarial loss: 0.476647\n",
      "epoch 112; iter: 0; batch classifier loss: 0.022796; batch adversarial loss: 0.430842\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029631; batch adversarial loss: 0.462967\n",
      "epoch 114; iter: 0; batch classifier loss: 0.025885; batch adversarial loss: 0.425122\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037233; batch adversarial loss: 0.479838\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028905; batch adversarial loss: 0.495473\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048043; batch adversarial loss: 0.467571\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059386; batch adversarial loss: 0.394767\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025996; batch adversarial loss: 0.425157\n",
      "epoch 120; iter: 0; batch classifier loss: 0.023634; batch adversarial loss: 0.477971\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041865; batch adversarial loss: 0.410206\n",
      "epoch 122; iter: 0; batch classifier loss: 0.014916; batch adversarial loss: 0.431174\n",
      "epoch 123; iter: 0; batch classifier loss: 0.132394; batch adversarial loss: 0.449970\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037439; batch adversarial loss: 0.501728\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022148; batch adversarial loss: 0.404568\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037907; batch adversarial loss: 0.488096\n",
      "epoch 127; iter: 0; batch classifier loss: 0.049758; batch adversarial loss: 0.421404\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027694; batch adversarial loss: 0.506131\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016734; batch adversarial loss: 0.483410\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030853; batch adversarial loss: 0.442945\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031857; batch adversarial loss: 0.486889\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036357; batch adversarial loss: 0.387285\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042787; batch adversarial loss: 0.347060\n",
      "epoch 134; iter: 0; batch classifier loss: 0.041744; batch adversarial loss: 0.467597\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037100; batch adversarial loss: 0.348807\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031309; batch adversarial loss: 0.462984\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036806; batch adversarial loss: 0.588541\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024585; batch adversarial loss: 0.431323\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014483; batch adversarial loss: 0.523621\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020972; batch adversarial loss: 0.402634\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018848; batch adversarial loss: 0.434591\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036294; batch adversarial loss: 0.542345\n",
      "epoch 143; iter: 0; batch classifier loss: 0.012741; batch adversarial loss: 0.309606\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036034; batch adversarial loss: 0.383727\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016618; batch adversarial loss: 0.390010\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028382; batch adversarial loss: 0.441796\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017150; batch adversarial loss: 0.462056\n",
      "epoch 148; iter: 0; batch classifier loss: 0.005661; batch adversarial loss: 0.511147\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031620; batch adversarial loss: 0.490853\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024731; batch adversarial loss: 0.452407\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017828; batch adversarial loss: 0.356062\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013496; batch adversarial loss: 0.545305\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034462; batch adversarial loss: 0.507661\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028577; batch adversarial loss: 0.464162\n",
      "epoch 155; iter: 0; batch classifier loss: 0.008188; batch adversarial loss: 0.462265\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022763; batch adversarial loss: 0.392599\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028256; batch adversarial loss: 0.458348\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027864; batch adversarial loss: 0.402769\n",
      "epoch 159; iter: 0; batch classifier loss: 0.053712; batch adversarial loss: 0.503166\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016797; batch adversarial loss: 0.434235\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023778; batch adversarial loss: 0.406857\n",
      "epoch 162; iter: 0; batch classifier loss: 0.058040; batch adversarial loss: 0.410629\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024195; batch adversarial loss: 0.527072\n",
      "epoch 164; iter: 0; batch classifier loss: 0.049658; batch adversarial loss: 0.482680\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011492; batch adversarial loss: 0.430218\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013071; batch adversarial loss: 0.513662\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030035; batch adversarial loss: 0.420281\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014981; batch adversarial loss: 0.552682\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017219; batch adversarial loss: 0.436759\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038044; batch adversarial loss: 0.436397\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030680; batch adversarial loss: 0.444284\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011902; batch adversarial loss: 0.460363\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019054; batch adversarial loss: 0.444736\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015620; batch adversarial loss: 0.477521\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014886; batch adversarial loss: 0.467545\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031490; batch adversarial loss: 0.423114\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046523; batch adversarial loss: 0.464826\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016447; batch adversarial loss: 0.424686\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017754; batch adversarial loss: 0.419651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.007510; batch adversarial loss: 0.419097\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020328; batch adversarial loss: 0.510271\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037652; batch adversarial loss: 0.526495\n",
      "epoch 183; iter: 0; batch classifier loss: 0.035474; batch adversarial loss: 0.498251\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008446; batch adversarial loss: 0.507166\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014313; batch adversarial loss: 0.456281\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008395; batch adversarial loss: 0.428078\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033189; batch adversarial loss: 0.394264\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033106; batch adversarial loss: 0.354335\n",
      "epoch 189; iter: 0; batch classifier loss: 0.063271; batch adversarial loss: 0.469473\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014877; batch adversarial loss: 0.502026\n",
      "epoch 191; iter: 0; batch classifier loss: 0.035574; batch adversarial loss: 0.508697\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018491; batch adversarial loss: 0.381623\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020609; batch adversarial loss: 0.449285\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033105; batch adversarial loss: 0.455823\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026096; batch adversarial loss: 0.453164\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020669; batch adversarial loss: 0.468635\n",
      "epoch 197; iter: 0; batch classifier loss: 0.041201; batch adversarial loss: 0.466118\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012652; batch adversarial loss: 0.533036\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017722; batch adversarial loss: 0.387538\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690334; batch adversarial loss: 0.775565\n",
      "epoch 1; iter: 0; batch classifier loss: 0.572080; batch adversarial loss: 0.724241\n",
      "epoch 2; iter: 0; batch classifier loss: 0.758804; batch adversarial loss: 0.752336\n",
      "epoch 3; iter: 0; batch classifier loss: 0.678514; batch adversarial loss: 0.671704\n",
      "epoch 4; iter: 0; batch classifier loss: 0.529140; batch adversarial loss: 0.585037\n",
      "epoch 5; iter: 0; batch classifier loss: 0.415676; batch adversarial loss: 0.562289\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331777; batch adversarial loss: 0.532113\n",
      "epoch 7; iter: 0; batch classifier loss: 0.379686; batch adversarial loss: 0.546018\n",
      "epoch 8; iter: 0; batch classifier loss: 0.304008; batch adversarial loss: 0.543576\n",
      "epoch 9; iter: 0; batch classifier loss: 0.284319; batch adversarial loss: 0.573261\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258808; batch adversarial loss: 0.562345\n",
      "epoch 11; iter: 0; batch classifier loss: 0.364120; batch adversarial loss: 0.466570\n",
      "epoch 12; iter: 0; batch classifier loss: 0.213189; batch adversarial loss: 0.576954\n",
      "epoch 13; iter: 0; batch classifier loss: 0.250151; batch adversarial loss: 0.461481\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263751; batch adversarial loss: 0.554061\n",
      "epoch 15; iter: 0; batch classifier loss: 0.231904; batch adversarial loss: 0.514463\n",
      "epoch 16; iter: 0; batch classifier loss: 0.209255; batch adversarial loss: 0.473182\n",
      "epoch 17; iter: 0; batch classifier loss: 0.202008; batch adversarial loss: 0.514139\n",
      "epoch 18; iter: 0; batch classifier loss: 0.174605; batch adversarial loss: 0.462069\n",
      "epoch 19; iter: 0; batch classifier loss: 0.260720; batch adversarial loss: 0.530618\n",
      "epoch 20; iter: 0; batch classifier loss: 0.179396; batch adversarial loss: 0.516804\n",
      "epoch 21; iter: 0; batch classifier loss: 0.226590; batch adversarial loss: 0.520951\n",
      "epoch 22; iter: 0; batch classifier loss: 0.125137; batch adversarial loss: 0.561709\n",
      "epoch 23; iter: 0; batch classifier loss: 0.242037; batch adversarial loss: 0.545779\n",
      "epoch 24; iter: 0; batch classifier loss: 0.220439; batch adversarial loss: 0.407445\n",
      "epoch 25; iter: 0; batch classifier loss: 0.250507; batch adversarial loss: 0.473410\n",
      "epoch 26; iter: 0; batch classifier loss: 0.201332; batch adversarial loss: 0.462610\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171763; batch adversarial loss: 0.457095\n",
      "epoch 28; iter: 0; batch classifier loss: 0.220834; batch adversarial loss: 0.428716\n",
      "epoch 29; iter: 0; batch classifier loss: 0.224296; batch adversarial loss: 0.479287\n",
      "epoch 30; iter: 0; batch classifier loss: 0.233179; batch adversarial loss: 0.519192\n",
      "epoch 31; iter: 0; batch classifier loss: 0.131986; batch adversarial loss: 0.450888\n",
      "epoch 32; iter: 0; batch classifier loss: 0.115490; batch adversarial loss: 0.521957\n",
      "epoch 33; iter: 0; batch classifier loss: 0.140656; batch adversarial loss: 0.436338\n",
      "epoch 34; iter: 0; batch classifier loss: 0.137790; batch adversarial loss: 0.413526\n",
      "epoch 35; iter: 0; batch classifier loss: 0.147568; batch adversarial loss: 0.554740\n",
      "epoch 36; iter: 0; batch classifier loss: 0.154512; batch adversarial loss: 0.422887\n",
      "epoch 37; iter: 0; batch classifier loss: 0.121422; batch adversarial loss: 0.487200\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117406; batch adversarial loss: 0.409102\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148277; batch adversarial loss: 0.490895\n",
      "epoch 40; iter: 0; batch classifier loss: 0.126335; batch adversarial loss: 0.512134\n",
      "epoch 41; iter: 0; batch classifier loss: 0.103482; batch adversarial loss: 0.399545\n",
      "epoch 42; iter: 0; batch classifier loss: 0.114068; batch adversarial loss: 0.415445\n",
      "epoch 43; iter: 0; batch classifier loss: 0.073747; batch adversarial loss: 0.535890\n",
      "epoch 44; iter: 0; batch classifier loss: 0.091724; batch adversarial loss: 0.493815\n",
      "epoch 45; iter: 0; batch classifier loss: 0.074932; batch adversarial loss: 0.503977\n",
      "epoch 46; iter: 0; batch classifier loss: 0.148109; batch adversarial loss: 0.419868\n",
      "epoch 47; iter: 0; batch classifier loss: 0.126572; batch adversarial loss: 0.380068\n",
      "epoch 48; iter: 0; batch classifier loss: 0.084416; batch adversarial loss: 0.447029\n",
      "epoch 49; iter: 0; batch classifier loss: 0.100543; batch adversarial loss: 0.405984\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119818; batch adversarial loss: 0.486056\n",
      "epoch 51; iter: 0; batch classifier loss: 0.107581; batch adversarial loss: 0.501199\n",
      "epoch 52; iter: 0; batch classifier loss: 0.088786; batch adversarial loss: 0.386639\n",
      "epoch 53; iter: 0; batch classifier loss: 0.071657; batch adversarial loss: 0.468446\n",
      "epoch 54; iter: 0; batch classifier loss: 0.156465; batch adversarial loss: 0.445052\n",
      "epoch 55; iter: 0; batch classifier loss: 0.105944; batch adversarial loss: 0.424510\n",
      "epoch 56; iter: 0; batch classifier loss: 0.111739; batch adversarial loss: 0.366505\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107817; batch adversarial loss: 0.406609\n",
      "epoch 58; iter: 0; batch classifier loss: 0.048912; batch adversarial loss: 0.516753\n",
      "epoch 59; iter: 0; batch classifier loss: 0.078868; batch adversarial loss: 0.429126\n",
      "epoch 60; iter: 0; batch classifier loss: 0.110849; batch adversarial loss: 0.407318\n",
      "epoch 61; iter: 0; batch classifier loss: 0.077637; batch adversarial loss: 0.492919\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078130; batch adversarial loss: 0.510096\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088586; batch adversarial loss: 0.404188\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083809; batch adversarial loss: 0.470391\n",
      "epoch 65; iter: 0; batch classifier loss: 0.101595; batch adversarial loss: 0.422030\n",
      "epoch 66; iter: 0; batch classifier loss: 0.081943; batch adversarial loss: 0.471026\n",
      "epoch 67; iter: 0; batch classifier loss: 0.086174; batch adversarial loss: 0.415981\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084667; batch adversarial loss: 0.499554\n",
      "epoch 69; iter: 0; batch classifier loss: 0.106998; batch adversarial loss: 0.404582\n",
      "epoch 70; iter: 0; batch classifier loss: 0.099976; batch adversarial loss: 0.448845\n",
      "epoch 71; iter: 0; batch classifier loss: 0.074214; batch adversarial loss: 0.450898\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081480; batch adversarial loss: 0.421175\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079985; batch adversarial loss: 0.541650\n",
      "epoch 74; iter: 0; batch classifier loss: 0.103543; batch adversarial loss: 0.443750\n",
      "epoch 75; iter: 0; batch classifier loss: 0.107524; batch adversarial loss: 0.408340\n",
      "epoch 76; iter: 0; batch classifier loss: 0.080819; batch adversarial loss: 0.604421\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055806; batch adversarial loss: 0.457227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.080109; batch adversarial loss: 0.384481\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064503; batch adversarial loss: 0.444808\n",
      "epoch 80; iter: 0; batch classifier loss: 0.092873; batch adversarial loss: 0.476012\n",
      "epoch 81; iter: 0; batch classifier loss: 0.052333; batch adversarial loss: 0.462812\n",
      "epoch 82; iter: 0; batch classifier loss: 0.028673; batch adversarial loss: 0.432566\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035932; batch adversarial loss: 0.535344\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047506; batch adversarial loss: 0.338274\n",
      "epoch 85; iter: 0; batch classifier loss: 0.099345; batch adversarial loss: 0.387315\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052560; batch adversarial loss: 0.402043\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049712; batch adversarial loss: 0.345963\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058147; batch adversarial loss: 0.477618\n",
      "epoch 89; iter: 0; batch classifier loss: 0.046466; batch adversarial loss: 0.393015\n",
      "epoch 90; iter: 0; batch classifier loss: 0.077372; batch adversarial loss: 0.461832\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055088; batch adversarial loss: 0.528153\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041392; batch adversarial loss: 0.484407\n",
      "epoch 93; iter: 0; batch classifier loss: 0.032690; batch adversarial loss: 0.515555\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042242; batch adversarial loss: 0.383773\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066074; batch adversarial loss: 0.518408\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045092; batch adversarial loss: 0.550771\n",
      "epoch 97; iter: 0; batch classifier loss: 0.028983; batch adversarial loss: 0.511392\n",
      "epoch 98; iter: 0; batch classifier loss: 0.040887; batch adversarial loss: 0.403990\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055425; batch adversarial loss: 0.596004\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045197; batch adversarial loss: 0.486259\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048272; batch adversarial loss: 0.534785\n",
      "epoch 102; iter: 0; batch classifier loss: 0.064917; batch adversarial loss: 0.375518\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053368; batch adversarial loss: 0.395661\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041768; batch adversarial loss: 0.457176\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038861; batch adversarial loss: 0.470531\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049840; batch adversarial loss: 0.422096\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033249; batch adversarial loss: 0.558617\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046031; batch adversarial loss: 0.425267\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027384; batch adversarial loss: 0.368586\n",
      "epoch 110; iter: 0; batch classifier loss: 0.024271; batch adversarial loss: 0.363616\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051633; batch adversarial loss: 0.383340\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040931; batch adversarial loss: 0.544337\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033646; batch adversarial loss: 0.344953\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032326; batch adversarial loss: 0.404703\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053217; batch adversarial loss: 0.432543\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045198; batch adversarial loss: 0.331862\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025760; batch adversarial loss: 0.502071\n",
      "epoch 118; iter: 0; batch classifier loss: 0.023219; batch adversarial loss: 0.404798\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030550; batch adversarial loss: 0.437778\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031495; batch adversarial loss: 0.400607\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023913; batch adversarial loss: 0.380212\n",
      "epoch 122; iter: 0; batch classifier loss: 0.022462; batch adversarial loss: 0.447292\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044907; batch adversarial loss: 0.517303\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020279; batch adversarial loss: 0.384886\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039414; batch adversarial loss: 0.490594\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029703; batch adversarial loss: 0.475552\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040215; batch adversarial loss: 0.497190\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039904; batch adversarial loss: 0.513834\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023974; batch adversarial loss: 0.338078\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028196; batch adversarial loss: 0.466713\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037915; batch adversarial loss: 0.371603\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019918; batch adversarial loss: 0.448920\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033689; batch adversarial loss: 0.475553\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054818; batch adversarial loss: 0.362660\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043636; batch adversarial loss: 0.426736\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057952; batch adversarial loss: 0.469217\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035771; batch adversarial loss: 0.413717\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014576; batch adversarial loss: 0.424836\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029576; batch adversarial loss: 0.420707\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017776; batch adversarial loss: 0.491285\n",
      "epoch 141; iter: 0; batch classifier loss: 0.010152; batch adversarial loss: 0.457405\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029404; batch adversarial loss: 0.468630\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013509; batch adversarial loss: 0.463451\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022509; batch adversarial loss: 0.464989\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045026; batch adversarial loss: 0.479432\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016495; batch adversarial loss: 0.382311\n",
      "epoch 147; iter: 0; batch classifier loss: 0.007508; batch adversarial loss: 0.385596\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022495; batch adversarial loss: 0.531838\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038797; batch adversarial loss: 0.444567\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024296; batch adversarial loss: 0.495088\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027390; batch adversarial loss: 0.430310\n",
      "epoch 152; iter: 0; batch classifier loss: 0.049602; batch adversarial loss: 0.387863\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021612; batch adversarial loss: 0.552679\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026721; batch adversarial loss: 0.463346\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034154; batch adversarial loss: 0.500681\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034044; batch adversarial loss: 0.404414\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015164; batch adversarial loss: 0.484997\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021720; batch adversarial loss: 0.489520\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022072; batch adversarial loss: 0.398849\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026016; batch adversarial loss: 0.504579\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033210; batch adversarial loss: 0.378163\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015272; batch adversarial loss: 0.421324\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007510; batch adversarial loss: 0.466831\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009177; batch adversarial loss: 0.449952\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021086; batch adversarial loss: 0.451349\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017613; batch adversarial loss: 0.466649\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022646; batch adversarial loss: 0.499294\n",
      "epoch 168; iter: 0; batch classifier loss: 0.042623; batch adversarial loss: 0.451446\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026578; batch adversarial loss: 0.481144\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010368; batch adversarial loss: 0.555998\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030434; batch adversarial loss: 0.402525\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016273; batch adversarial loss: 0.414835\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014645; batch adversarial loss: 0.511978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.024906; batch adversarial loss: 0.522461\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022528; batch adversarial loss: 0.429038\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014100; batch adversarial loss: 0.475133\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017841; batch adversarial loss: 0.411161\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005163; batch adversarial loss: 0.516147\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032583; batch adversarial loss: 0.463771\n",
      "epoch 180; iter: 0; batch classifier loss: 0.048817; batch adversarial loss: 0.453298\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009320; batch adversarial loss: 0.579076\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034108; batch adversarial loss: 0.496169\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006007; batch adversarial loss: 0.441540\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016752; batch adversarial loss: 0.463930\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017047; batch adversarial loss: 0.477972\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035955; batch adversarial loss: 0.425493\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013025; batch adversarial loss: 0.483388\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027520; batch adversarial loss: 0.401055\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017018; batch adversarial loss: 0.433230\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012211; batch adversarial loss: 0.375116\n",
      "epoch 191; iter: 0; batch classifier loss: 0.041097; batch adversarial loss: 0.489503\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035469; batch adversarial loss: 0.429190\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008997; batch adversarial loss: 0.394859\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017459; batch adversarial loss: 0.351356\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006401; batch adversarial loss: 0.498191\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011319; batch adversarial loss: 0.405288\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020360; batch adversarial loss: 0.423240\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031893; batch adversarial loss: 0.408078\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022860; batch adversarial loss: 0.387810\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667305; batch adversarial loss: 0.623751\n",
      "epoch 1; iter: 0; batch classifier loss: 0.361692; batch adversarial loss: 0.632769\n",
      "epoch 2; iter: 0; batch classifier loss: 0.429087; batch adversarial loss: 0.593953\n",
      "epoch 3; iter: 0; batch classifier loss: 0.384487; batch adversarial loss: 0.573183\n",
      "epoch 4; iter: 0; batch classifier loss: 0.284963; batch adversarial loss: 0.561253\n",
      "epoch 5; iter: 0; batch classifier loss: 0.243876; batch adversarial loss: 0.532625\n",
      "epoch 6; iter: 0; batch classifier loss: 0.236134; batch adversarial loss: 0.494599\n",
      "epoch 7; iter: 0; batch classifier loss: 0.319281; batch adversarial loss: 0.518098\n",
      "epoch 8; iter: 0; batch classifier loss: 0.401219; batch adversarial loss: 0.524152\n",
      "epoch 9; iter: 0; batch classifier loss: 0.269038; batch adversarial loss: 0.525039\n",
      "epoch 10; iter: 0; batch classifier loss: 0.224666; batch adversarial loss: 0.512167\n",
      "epoch 11; iter: 0; batch classifier loss: 0.246847; batch adversarial loss: 0.525959\n",
      "epoch 12; iter: 0; batch classifier loss: 0.234765; batch adversarial loss: 0.489866\n",
      "epoch 13; iter: 0; batch classifier loss: 0.260739; batch adversarial loss: 0.550112\n",
      "epoch 14; iter: 0; batch classifier loss: 0.301463; batch adversarial loss: 0.521510\n",
      "epoch 15; iter: 0; batch classifier loss: 0.190464; batch adversarial loss: 0.515870\n",
      "epoch 16; iter: 0; batch classifier loss: 0.153269; batch adversarial loss: 0.517375\n",
      "epoch 17; iter: 0; batch classifier loss: 0.233102; batch adversarial loss: 0.621875\n",
      "epoch 18; iter: 0; batch classifier loss: 0.272093; batch adversarial loss: 0.616187\n",
      "epoch 19; iter: 0; batch classifier loss: 0.269742; batch adversarial loss: 0.495400\n",
      "epoch 20; iter: 0; batch classifier loss: 0.240099; batch adversarial loss: 0.462670\n",
      "epoch 21; iter: 0; batch classifier loss: 0.274006; batch adversarial loss: 0.524244\n",
      "epoch 22; iter: 0; batch classifier loss: 0.263732; batch adversarial loss: 0.498862\n",
      "epoch 23; iter: 0; batch classifier loss: 0.211810; batch adversarial loss: 0.538452\n",
      "epoch 24; iter: 0; batch classifier loss: 0.261495; batch adversarial loss: 0.489699\n",
      "epoch 25; iter: 0; batch classifier loss: 0.238883; batch adversarial loss: 0.442775\n",
      "epoch 26; iter: 0; batch classifier loss: 0.338160; batch adversarial loss: 0.566368\n",
      "epoch 27; iter: 0; batch classifier loss: 0.294288; batch adversarial loss: 0.498372\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184420; batch adversarial loss: 0.440874\n",
      "epoch 29; iter: 0; batch classifier loss: 0.102273; batch adversarial loss: 0.451179\n",
      "epoch 30; iter: 0; batch classifier loss: 0.092277; batch adversarial loss: 0.513509\n",
      "epoch 31; iter: 0; batch classifier loss: 0.150273; batch adversarial loss: 0.447831\n",
      "epoch 32; iter: 0; batch classifier loss: 0.138787; batch adversarial loss: 0.466956\n",
      "epoch 33; iter: 0; batch classifier loss: 0.105896; batch adversarial loss: 0.405269\n",
      "epoch 34; iter: 0; batch classifier loss: 0.147427; batch adversarial loss: 0.545969\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142418; batch adversarial loss: 0.505650\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109753; batch adversarial loss: 0.427489\n",
      "epoch 37; iter: 0; batch classifier loss: 0.167310; batch adversarial loss: 0.361618\n",
      "epoch 38; iter: 0; batch classifier loss: 0.093827; batch adversarial loss: 0.502707\n",
      "epoch 39; iter: 0; batch classifier loss: 0.108373; batch adversarial loss: 0.413416\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099410; batch adversarial loss: 0.419024\n",
      "epoch 41; iter: 0; batch classifier loss: 0.114724; batch adversarial loss: 0.450224\n",
      "epoch 42; iter: 0; batch classifier loss: 0.142595; batch adversarial loss: 0.388429\n",
      "epoch 43; iter: 0; batch classifier loss: 0.082084; batch adversarial loss: 0.449045\n",
      "epoch 44; iter: 0; batch classifier loss: 0.100814; batch adversarial loss: 0.579556\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091808; batch adversarial loss: 0.470071\n",
      "epoch 46; iter: 0; batch classifier loss: 0.079580; batch adversarial loss: 0.528223\n",
      "epoch 47; iter: 0; batch classifier loss: 0.121350; batch adversarial loss: 0.474014\n",
      "epoch 48; iter: 0; batch classifier loss: 0.064827; batch adversarial loss: 0.451823\n",
      "epoch 49; iter: 0; batch classifier loss: 0.150282; batch adversarial loss: 0.427054\n",
      "epoch 50; iter: 0; batch classifier loss: 0.213387; batch adversarial loss: 0.378169\n",
      "epoch 51; iter: 0; batch classifier loss: 0.071531; batch adversarial loss: 0.450526\n",
      "epoch 52; iter: 0; batch classifier loss: 0.139421; batch adversarial loss: 0.490425\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088913; batch adversarial loss: 0.383052\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096249; batch adversarial loss: 0.474937\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086847; batch adversarial loss: 0.493564\n",
      "epoch 56; iter: 0; batch classifier loss: 0.073726; batch adversarial loss: 0.407400\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107429; batch adversarial loss: 0.430817\n",
      "epoch 58; iter: 0; batch classifier loss: 0.083843; batch adversarial loss: 0.505102\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092816; batch adversarial loss: 0.567297\n",
      "epoch 60; iter: 0; batch classifier loss: 0.113218; batch adversarial loss: 0.482504\n",
      "epoch 61; iter: 0; batch classifier loss: 0.085837; batch adversarial loss: 0.463394\n",
      "epoch 62; iter: 0; batch classifier loss: 0.046788; batch adversarial loss: 0.383338\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091301; batch adversarial loss: 0.482793\n",
      "epoch 64; iter: 0; batch classifier loss: 0.121016; batch adversarial loss: 0.477446\n",
      "epoch 65; iter: 0; batch classifier loss: 0.093060; batch adversarial loss: 0.416305\n",
      "epoch 66; iter: 0; batch classifier loss: 0.069985; batch adversarial loss: 0.481272\n",
      "epoch 67; iter: 0; batch classifier loss: 0.123254; batch adversarial loss: 0.481595\n",
      "epoch 68; iter: 0; batch classifier loss: 0.121332; batch adversarial loss: 0.402070\n",
      "epoch 69; iter: 0; batch classifier loss: 0.092344; batch adversarial loss: 0.451876\n",
      "epoch 70; iter: 0; batch classifier loss: 0.094491; batch adversarial loss: 0.546874\n",
      "epoch 71; iter: 0; batch classifier loss: 0.088062; batch adversarial loss: 0.456659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.136450; batch adversarial loss: 0.434151\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079149; batch adversarial loss: 0.422379\n",
      "epoch 74; iter: 0; batch classifier loss: 0.040616; batch adversarial loss: 0.470508\n",
      "epoch 75; iter: 0; batch classifier loss: 0.130135; batch adversarial loss: 0.505883\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069448; batch adversarial loss: 0.523009\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076356; batch adversarial loss: 0.496351\n",
      "epoch 78; iter: 0; batch classifier loss: 0.063754; batch adversarial loss: 0.443602\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082590; batch adversarial loss: 0.417618\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067824; batch adversarial loss: 0.487919\n",
      "epoch 81; iter: 0; batch classifier loss: 0.054403; batch adversarial loss: 0.356559\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073507; batch adversarial loss: 0.414468\n",
      "epoch 83; iter: 0; batch classifier loss: 0.095521; batch adversarial loss: 0.457790\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080404; batch adversarial loss: 0.490640\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073148; batch adversarial loss: 0.460290\n",
      "epoch 86; iter: 0; batch classifier loss: 0.085620; batch adversarial loss: 0.402370\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083488; batch adversarial loss: 0.409923\n",
      "epoch 88; iter: 0; batch classifier loss: 0.060133; batch adversarial loss: 0.473668\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068460; batch adversarial loss: 0.482168\n",
      "epoch 90; iter: 0; batch classifier loss: 0.102746; batch adversarial loss: 0.470313\n",
      "epoch 91; iter: 0; batch classifier loss: 0.099573; batch adversarial loss: 0.484765\n",
      "epoch 92; iter: 0; batch classifier loss: 0.097277; batch adversarial loss: 0.460299\n",
      "epoch 93; iter: 0; batch classifier loss: 0.068782; batch adversarial loss: 0.384446\n",
      "epoch 94; iter: 0; batch classifier loss: 0.119342; batch adversarial loss: 0.397965\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081439; batch adversarial loss: 0.502726\n",
      "epoch 96; iter: 0; batch classifier loss: 0.169938; batch adversarial loss: 0.501371\n",
      "epoch 97; iter: 0; batch classifier loss: 0.100191; batch adversarial loss: 0.455233\n",
      "epoch 98; iter: 0; batch classifier loss: 0.136844; batch adversarial loss: 0.405120\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054098; batch adversarial loss: 0.499862\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046107; batch adversarial loss: 0.397539\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041073; batch adversarial loss: 0.428695\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047402; batch adversarial loss: 0.509391\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049392; batch adversarial loss: 0.506543\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034338; batch adversarial loss: 0.415160\n",
      "epoch 105; iter: 0; batch classifier loss: 0.109043; batch adversarial loss: 0.523990\n",
      "epoch 106; iter: 0; batch classifier loss: 0.093020; batch adversarial loss: 0.398752\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040625; batch adversarial loss: 0.490286\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045436; batch adversarial loss: 0.429703\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046099; batch adversarial loss: 0.503453\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050295; batch adversarial loss: 0.327642\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048931; batch adversarial loss: 0.433208\n",
      "epoch 112; iter: 0; batch classifier loss: 0.068948; batch adversarial loss: 0.445875\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045204; batch adversarial loss: 0.524080\n",
      "epoch 114; iter: 0; batch classifier loss: 0.066363; batch adversarial loss: 0.499129\n",
      "epoch 115; iter: 0; batch classifier loss: 0.030474; batch adversarial loss: 0.496814\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034509; batch adversarial loss: 0.490180\n",
      "epoch 117; iter: 0; batch classifier loss: 0.065672; batch adversarial loss: 0.516019\n",
      "epoch 118; iter: 0; batch classifier loss: 0.058994; batch adversarial loss: 0.454409\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035185; batch adversarial loss: 0.472001\n",
      "epoch 120; iter: 0; batch classifier loss: 0.063563; batch adversarial loss: 0.483612\n",
      "epoch 121; iter: 0; batch classifier loss: 0.089090; batch adversarial loss: 0.516000\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041921; batch adversarial loss: 0.410832\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039913; batch adversarial loss: 0.489351\n",
      "epoch 124; iter: 0; batch classifier loss: 0.014475; batch adversarial loss: 0.552995\n",
      "epoch 125; iter: 0; batch classifier loss: 0.066465; batch adversarial loss: 0.411265\n",
      "epoch 126; iter: 0; batch classifier loss: 0.060474; batch adversarial loss: 0.591156\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041784; batch adversarial loss: 0.377418\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038565; batch adversarial loss: 0.482221\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021506; batch adversarial loss: 0.439804\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040500; batch adversarial loss: 0.515274\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045636; batch adversarial loss: 0.440079\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028592; batch adversarial loss: 0.515865\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037877; batch adversarial loss: 0.467560\n",
      "epoch 134; iter: 0; batch classifier loss: 0.012686; batch adversarial loss: 0.520148\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044549; batch adversarial loss: 0.420375\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026253; batch adversarial loss: 0.561592\n",
      "epoch 137; iter: 0; batch classifier loss: 0.050774; batch adversarial loss: 0.506253\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048559; batch adversarial loss: 0.416239\n",
      "epoch 139; iter: 0; batch classifier loss: 0.064049; batch adversarial loss: 0.517368\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036113; batch adversarial loss: 0.488224\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040887; batch adversarial loss: 0.469782\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041611; batch adversarial loss: 0.395494\n",
      "epoch 143; iter: 0; batch classifier loss: 0.048334; batch adversarial loss: 0.402353\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030451; batch adversarial loss: 0.476909\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021817; batch adversarial loss: 0.439939\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038835; batch adversarial loss: 0.495546\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015813; batch adversarial loss: 0.431691\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016493; batch adversarial loss: 0.466881\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042175; batch adversarial loss: 0.451414\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039743; batch adversarial loss: 0.440903\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024051; batch adversarial loss: 0.405916\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016727; batch adversarial loss: 0.491771\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023135; batch adversarial loss: 0.399562\n",
      "epoch 154; iter: 0; batch classifier loss: 0.059163; batch adversarial loss: 0.422328\n",
      "epoch 155; iter: 0; batch classifier loss: 0.006127; batch adversarial loss: 0.426626\n",
      "epoch 156; iter: 0; batch classifier loss: 0.084683; batch adversarial loss: 0.445281\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022688; batch adversarial loss: 0.420790\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026298; batch adversarial loss: 0.467451\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019993; batch adversarial loss: 0.467764\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027091; batch adversarial loss: 0.495262\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039102; batch adversarial loss: 0.478550\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018311; batch adversarial loss: 0.424013\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040740; batch adversarial loss: 0.505276\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021137; batch adversarial loss: 0.430677\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033912; batch adversarial loss: 0.478469\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016155; batch adversarial loss: 0.525251\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024685; batch adversarial loss: 0.506562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.047197; batch adversarial loss: 0.499363\n",
      "epoch 169; iter: 0; batch classifier loss: 0.005158; batch adversarial loss: 0.420715\n",
      "epoch 170; iter: 0; batch classifier loss: 0.044708; batch adversarial loss: 0.435520\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017447; batch adversarial loss: 0.467436\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027955; batch adversarial loss: 0.475622\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029170; batch adversarial loss: 0.465185\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019458; batch adversarial loss: 0.476334\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015240; batch adversarial loss: 0.436380\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022814; batch adversarial loss: 0.517067\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016013; batch adversarial loss: 0.499461\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037964; batch adversarial loss: 0.386375\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022898; batch adversarial loss: 0.409720\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029457; batch adversarial loss: 0.474126\n",
      "epoch 181; iter: 0; batch classifier loss: 0.046928; batch adversarial loss: 0.365484\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018307; batch adversarial loss: 0.478330\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013109; batch adversarial loss: 0.563004\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009124; batch adversarial loss: 0.482852\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016669; batch adversarial loss: 0.515756\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024239; batch adversarial loss: 0.455703\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024161; batch adversarial loss: 0.431087\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016871; batch adversarial loss: 0.426903\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027832; batch adversarial loss: 0.494106\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018291; batch adversarial loss: 0.491568\n",
      "epoch 191; iter: 0; batch classifier loss: 0.038270; batch adversarial loss: 0.445075\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019591; batch adversarial loss: 0.468577\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008203; batch adversarial loss: 0.393697\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014770; batch adversarial loss: 0.561028\n",
      "epoch 195; iter: 0; batch classifier loss: 0.041002; batch adversarial loss: 0.442384\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017839; batch adversarial loss: 0.482434\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012565; batch adversarial loss: 0.541832\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022290; batch adversarial loss: 0.483635\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011272; batch adversarial loss: 0.457165\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682238; batch adversarial loss: 0.694728\n",
      "epoch 1; iter: 0; batch classifier loss: 0.536569; batch adversarial loss: 0.654303\n",
      "epoch 2; iter: 0; batch classifier loss: 0.459264; batch adversarial loss: 0.626942\n",
      "epoch 3; iter: 0; batch classifier loss: 0.389306; batch adversarial loss: 0.594484\n",
      "epoch 4; iter: 0; batch classifier loss: 0.399552; batch adversarial loss: 0.601102\n",
      "epoch 5; iter: 0; batch classifier loss: 0.442293; batch adversarial loss: 0.604702\n",
      "epoch 6; iter: 0; batch classifier loss: 0.448080; batch adversarial loss: 0.599398\n",
      "epoch 7; iter: 0; batch classifier loss: 0.389687; batch adversarial loss: 0.586817\n",
      "epoch 8; iter: 0; batch classifier loss: 0.458473; batch adversarial loss: 0.502979\n",
      "epoch 9; iter: 0; batch classifier loss: 0.390939; batch adversarial loss: 0.535113\n",
      "epoch 10; iter: 0; batch classifier loss: 0.281253; batch adversarial loss: 0.613441\n",
      "epoch 11; iter: 0; batch classifier loss: 0.392909; batch adversarial loss: 0.551713\n",
      "epoch 12; iter: 0; batch classifier loss: 0.410426; batch adversarial loss: 0.560452\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373019; batch adversarial loss: 0.554395\n",
      "epoch 14; iter: 0; batch classifier loss: 0.413023; batch adversarial loss: 0.556891\n",
      "epoch 15; iter: 0; batch classifier loss: 0.390160; batch adversarial loss: 0.463005\n",
      "epoch 16; iter: 0; batch classifier loss: 0.305618; batch adversarial loss: 0.529621\n",
      "epoch 17; iter: 0; batch classifier loss: 0.329126; batch adversarial loss: 0.488967\n",
      "epoch 18; iter: 0; batch classifier loss: 0.278989; batch adversarial loss: 0.493939\n",
      "epoch 19; iter: 0; batch classifier loss: 0.262822; batch adversarial loss: 0.501924\n",
      "epoch 20; iter: 0; batch classifier loss: 0.339510; batch adversarial loss: 0.480644\n",
      "epoch 21; iter: 0; batch classifier loss: 0.287410; batch adversarial loss: 0.472908\n",
      "epoch 22; iter: 0; batch classifier loss: 0.335612; batch adversarial loss: 0.441793\n",
      "epoch 23; iter: 0; batch classifier loss: 0.311538; batch adversarial loss: 0.374277\n",
      "epoch 24; iter: 0; batch classifier loss: 0.267900; batch adversarial loss: 0.499989\n",
      "epoch 25; iter: 0; batch classifier loss: 0.291537; batch adversarial loss: 0.431382\n",
      "epoch 26; iter: 0; batch classifier loss: 0.297771; batch adversarial loss: 0.460757\n",
      "epoch 27; iter: 0; batch classifier loss: 0.262270; batch adversarial loss: 0.523237\n",
      "epoch 28; iter: 0; batch classifier loss: 0.265273; batch adversarial loss: 0.501839\n",
      "epoch 29; iter: 0; batch classifier loss: 0.263125; batch adversarial loss: 0.535213\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172503; batch adversarial loss: 0.573263\n",
      "epoch 31; iter: 0; batch classifier loss: 0.276160; batch adversarial loss: 0.490315\n",
      "epoch 32; iter: 0; batch classifier loss: 0.225839; batch adversarial loss: 0.566666\n",
      "epoch 33; iter: 0; batch classifier loss: 0.185435; batch adversarial loss: 0.568033\n",
      "epoch 34; iter: 0; batch classifier loss: 0.265918; batch adversarial loss: 0.494663\n",
      "epoch 35; iter: 0; batch classifier loss: 0.219634; batch adversarial loss: 0.472182\n",
      "epoch 36; iter: 0; batch classifier loss: 0.207387; batch adversarial loss: 0.497219\n",
      "epoch 37; iter: 0; batch classifier loss: 0.220647; batch adversarial loss: 0.504823\n",
      "epoch 38; iter: 0; batch classifier loss: 0.240392; batch adversarial loss: 0.471154\n",
      "epoch 39; iter: 0; batch classifier loss: 0.187279; batch adversarial loss: 0.431191\n",
      "epoch 40; iter: 0; batch classifier loss: 0.253612; batch adversarial loss: 0.379821\n",
      "epoch 41; iter: 0; batch classifier loss: 0.216763; batch adversarial loss: 0.490868\n",
      "epoch 42; iter: 0; batch classifier loss: 0.231402; batch adversarial loss: 0.458975\n",
      "epoch 43; iter: 0; batch classifier loss: 0.231406; batch adversarial loss: 0.461825\n",
      "epoch 44; iter: 0; batch classifier loss: 0.164873; batch adversarial loss: 0.484178\n",
      "epoch 45; iter: 0; batch classifier loss: 0.211895; batch adversarial loss: 0.449503\n",
      "epoch 46; iter: 0; batch classifier loss: 0.255755; batch adversarial loss: 0.471216\n",
      "epoch 47; iter: 0; batch classifier loss: 0.181682; batch adversarial loss: 0.460188\n",
      "epoch 48; iter: 0; batch classifier loss: 0.182478; batch adversarial loss: 0.494846\n",
      "epoch 49; iter: 0; batch classifier loss: 0.132050; batch adversarial loss: 0.402207\n",
      "epoch 50; iter: 0; batch classifier loss: 0.181453; batch adversarial loss: 0.402580\n",
      "epoch 51; iter: 0; batch classifier loss: 0.230893; batch adversarial loss: 0.551935\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161474; batch adversarial loss: 0.436574\n",
      "epoch 53; iter: 0; batch classifier loss: 0.231419; batch adversarial loss: 0.471156\n",
      "epoch 54; iter: 0; batch classifier loss: 0.171232; batch adversarial loss: 0.505701\n",
      "epoch 55; iter: 0; batch classifier loss: 0.169053; batch adversarial loss: 0.424248\n",
      "epoch 56; iter: 0; batch classifier loss: 0.160903; batch adversarial loss: 0.518071\n",
      "epoch 57; iter: 0; batch classifier loss: 0.145176; batch adversarial loss: 0.505683\n",
      "epoch 58; iter: 0; batch classifier loss: 0.115112; batch adversarial loss: 0.376031\n",
      "epoch 59; iter: 0; batch classifier loss: 0.145570; batch adversarial loss: 0.510180\n",
      "epoch 60; iter: 0; batch classifier loss: 0.242268; batch adversarial loss: 0.518540\n",
      "epoch 61; iter: 0; batch classifier loss: 0.106148; batch adversarial loss: 0.540691\n",
      "epoch 62; iter: 0; batch classifier loss: 0.177408; batch adversarial loss: 0.429059\n",
      "epoch 63; iter: 0; batch classifier loss: 0.258228; batch adversarial loss: 0.446477\n",
      "epoch 64; iter: 0; batch classifier loss: 0.170422; batch adversarial loss: 0.552656\n",
      "epoch 65; iter: 0; batch classifier loss: 0.218498; batch adversarial loss: 0.505122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.181382; batch adversarial loss: 0.460372\n",
      "epoch 67; iter: 0; batch classifier loss: 0.180892; batch adversarial loss: 0.413279\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109876; batch adversarial loss: 0.399978\n",
      "epoch 69; iter: 0; batch classifier loss: 0.085503; batch adversarial loss: 0.539127\n",
      "epoch 70; iter: 0; batch classifier loss: 0.058771; batch adversarial loss: 0.467793\n",
      "epoch 71; iter: 0; batch classifier loss: 0.121137; batch adversarial loss: 0.444455\n",
      "epoch 72; iter: 0; batch classifier loss: 0.173612; batch adversarial loss: 0.438926\n",
      "epoch 73; iter: 0; batch classifier loss: 0.199807; batch adversarial loss: 0.447727\n",
      "epoch 74; iter: 0; batch classifier loss: 0.148597; batch adversarial loss: 0.520045\n",
      "epoch 75; iter: 0; batch classifier loss: 0.149365; batch adversarial loss: 0.493815\n",
      "epoch 76; iter: 0; batch classifier loss: 0.166587; batch adversarial loss: 0.446171\n",
      "epoch 77; iter: 0; batch classifier loss: 0.173640; batch adversarial loss: 0.444775\n",
      "epoch 78; iter: 0; batch classifier loss: 0.192201; batch adversarial loss: 0.380597\n",
      "epoch 79; iter: 0; batch classifier loss: 0.162175; batch adversarial loss: 0.492692\n",
      "epoch 80; iter: 0; batch classifier loss: 0.230091; batch adversarial loss: 0.425788\n",
      "epoch 81; iter: 0; batch classifier loss: 0.126180; batch adversarial loss: 0.481979\n",
      "epoch 82; iter: 0; batch classifier loss: 0.155962; batch adversarial loss: 0.527829\n",
      "epoch 83; iter: 0; batch classifier loss: 0.129206; batch adversarial loss: 0.480631\n",
      "epoch 84; iter: 0; batch classifier loss: 0.121174; batch adversarial loss: 0.422204\n",
      "epoch 85; iter: 0; batch classifier loss: 0.173562; batch adversarial loss: 0.505531\n",
      "epoch 86; iter: 0; batch classifier loss: 0.166505; batch adversarial loss: 0.454457\n",
      "epoch 87; iter: 0; batch classifier loss: 0.137650; batch adversarial loss: 0.425297\n",
      "epoch 88; iter: 0; batch classifier loss: 0.091011; batch adversarial loss: 0.444265\n",
      "epoch 89; iter: 0; batch classifier loss: 0.108030; batch adversarial loss: 0.526983\n",
      "epoch 90; iter: 0; batch classifier loss: 0.099562; batch adversarial loss: 0.538140\n",
      "epoch 91; iter: 0; batch classifier loss: 0.130506; batch adversarial loss: 0.414644\n",
      "epoch 92; iter: 0; batch classifier loss: 0.130820; batch adversarial loss: 0.419898\n",
      "epoch 93; iter: 0; batch classifier loss: 0.114390; batch adversarial loss: 0.441230\n",
      "epoch 94; iter: 0; batch classifier loss: 0.090388; batch adversarial loss: 0.512702\n",
      "epoch 95; iter: 0; batch classifier loss: 0.139297; batch adversarial loss: 0.420072\n",
      "epoch 96; iter: 0; batch classifier loss: 0.106930; batch adversarial loss: 0.422460\n",
      "epoch 97; iter: 0; batch classifier loss: 0.085793; batch adversarial loss: 0.366932\n",
      "epoch 98; iter: 0; batch classifier loss: 0.093027; batch adversarial loss: 0.470527\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038225; batch adversarial loss: 0.451636\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037433; batch adversarial loss: 0.457640\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075948; batch adversarial loss: 0.418212\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066751; batch adversarial loss: 0.476812\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071126; batch adversarial loss: 0.428158\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071378; batch adversarial loss: 0.448901\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044066; batch adversarial loss: 0.380065\n",
      "epoch 106; iter: 0; batch classifier loss: 0.027914; batch adversarial loss: 0.495030\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052452; batch adversarial loss: 0.362746\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054130; batch adversarial loss: 0.526958\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064347; batch adversarial loss: 0.457925\n",
      "epoch 110; iter: 0; batch classifier loss: 0.062840; batch adversarial loss: 0.387611\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049534; batch adversarial loss: 0.439707\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048403; batch adversarial loss: 0.460782\n",
      "epoch 113; iter: 0; batch classifier loss: 0.030670; batch adversarial loss: 0.504477\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034376; batch adversarial loss: 0.473253\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046030; batch adversarial loss: 0.511126\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052618; batch adversarial loss: 0.467614\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030277; batch adversarial loss: 0.502066\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040261; batch adversarial loss: 0.502744\n",
      "epoch 119; iter: 0; batch classifier loss: 0.014949; batch adversarial loss: 0.378844\n",
      "epoch 120; iter: 0; batch classifier loss: 0.010816; batch adversarial loss: 0.584244\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024768; batch adversarial loss: 0.383705\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025673; batch adversarial loss: 0.532032\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017004; batch adversarial loss: 0.436391\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026984; batch adversarial loss: 0.582215\n",
      "epoch 125; iter: 0; batch classifier loss: 0.016808; batch adversarial loss: 0.471859\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025422; batch adversarial loss: 0.424282\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022843; batch adversarial loss: 0.506651\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017102; batch adversarial loss: 0.483916\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025103; batch adversarial loss: 0.474428\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027590; batch adversarial loss: 0.408497\n",
      "epoch 131; iter: 0; batch classifier loss: 0.016664; batch adversarial loss: 0.530108\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016404; batch adversarial loss: 0.505293\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013559; batch adversarial loss: 0.466757\n",
      "epoch 134; iter: 0; batch classifier loss: 0.012968; batch adversarial loss: 0.486168\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050364; batch adversarial loss: 0.548295\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023911; batch adversarial loss: 0.420398\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015620; batch adversarial loss: 0.398108\n",
      "epoch 138; iter: 0; batch classifier loss: 0.015924; batch adversarial loss: 0.410565\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021727; batch adversarial loss: 0.476601\n",
      "epoch 140; iter: 0; batch classifier loss: 0.010520; batch adversarial loss: 0.431985\n",
      "epoch 141; iter: 0; batch classifier loss: 0.011269; batch adversarial loss: 0.527876\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050401; batch adversarial loss: 0.566104\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010616; batch adversarial loss: 0.478326\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025210; batch adversarial loss: 0.515806\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016264; batch adversarial loss: 0.468549\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035476; batch adversarial loss: 0.403895\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013133; batch adversarial loss: 0.419956\n",
      "epoch 148; iter: 0; batch classifier loss: 0.010581; batch adversarial loss: 0.432996\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019365; batch adversarial loss: 0.534307\n",
      "epoch 150; iter: 0; batch classifier loss: 0.005665; batch adversarial loss: 0.550838\n",
      "epoch 151; iter: 0; batch classifier loss: 0.047914; batch adversarial loss: 0.537038\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008288; batch adversarial loss: 0.468890\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021866; batch adversarial loss: 0.486383\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018057; batch adversarial loss: 0.392686\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025581; batch adversarial loss: 0.456101\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017563; batch adversarial loss: 0.477656\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006685; batch adversarial loss: 0.468469\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011309; batch adversarial loss: 0.379440\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012651; batch adversarial loss: 0.499171\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025745; batch adversarial loss: 0.440792\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022144; batch adversarial loss: 0.381916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.014866; batch adversarial loss: 0.460557\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040303; batch adversarial loss: 0.508181\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010685; batch adversarial loss: 0.392883\n",
      "epoch 165; iter: 0; batch classifier loss: 0.005935; batch adversarial loss: 0.557042\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007536; batch adversarial loss: 0.509061\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008346; batch adversarial loss: 0.470207\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008010; batch adversarial loss: 0.405102\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017723; batch adversarial loss: 0.517052\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040115; batch adversarial loss: 0.402419\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011813; batch adversarial loss: 0.377230\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023114; batch adversarial loss: 0.433348\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014426; batch adversarial loss: 0.474515\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028456; batch adversarial loss: 0.483893\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007710; batch adversarial loss: 0.465503\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014511; batch adversarial loss: 0.495459\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015478; batch adversarial loss: 0.474512\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018162; batch adversarial loss: 0.435550\n",
      "epoch 179; iter: 0; batch classifier loss: 0.004702; batch adversarial loss: 0.475803\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034004; batch adversarial loss: 0.439760\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029116; batch adversarial loss: 0.377201\n",
      "epoch 182; iter: 0; batch classifier loss: 0.052512; batch adversarial loss: 0.451839\n",
      "epoch 183; iter: 0; batch classifier loss: 0.004275; batch adversarial loss: 0.447837\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008368; batch adversarial loss: 0.349219\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014336; batch adversarial loss: 0.484897\n",
      "epoch 186; iter: 0; batch classifier loss: 0.003708; batch adversarial loss: 0.403158\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007090; batch adversarial loss: 0.407771\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004217; batch adversarial loss: 0.498579\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015255; batch adversarial loss: 0.466242\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006394; batch adversarial loss: 0.525968\n",
      "epoch 191; iter: 0; batch classifier loss: 0.003524; batch adversarial loss: 0.446045\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030515; batch adversarial loss: 0.469217\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007888; batch adversarial loss: 0.450231\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008109; batch adversarial loss: 0.457681\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004502; batch adversarial loss: 0.506920\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007430; batch adversarial loss: 0.453746\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013017; batch adversarial loss: 0.498895\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006042; batch adversarial loss: 0.486503\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009162; batch adversarial loss: 0.449255\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699031; batch adversarial loss: 0.894667\n",
      "epoch 1; iter: 0; batch classifier loss: 0.453519; batch adversarial loss: 0.955512\n",
      "epoch 2; iter: 0; batch classifier loss: 0.676960; batch adversarial loss: 0.896279\n",
      "epoch 3; iter: 0; batch classifier loss: 0.790026; batch adversarial loss: 0.861427\n",
      "epoch 4; iter: 0; batch classifier loss: 0.801737; batch adversarial loss: 0.776486\n",
      "epoch 5; iter: 0; batch classifier loss: 0.793520; batch adversarial loss: 0.710373\n",
      "epoch 6; iter: 0; batch classifier loss: 0.758893; batch adversarial loss: 0.639513\n",
      "epoch 7; iter: 0; batch classifier loss: 0.702474; batch adversarial loss: 0.595484\n",
      "epoch 8; iter: 0; batch classifier loss: 0.321963; batch adversarial loss: 0.551940\n",
      "epoch 9; iter: 0; batch classifier loss: 0.397195; batch adversarial loss: 0.549318\n",
      "epoch 10; iter: 0; batch classifier loss: 0.297471; batch adversarial loss: 0.558685\n",
      "epoch 11; iter: 0; batch classifier loss: 0.376069; batch adversarial loss: 0.518115\n",
      "epoch 12; iter: 0; batch classifier loss: 0.207665; batch adversarial loss: 0.510545\n",
      "epoch 13; iter: 0; batch classifier loss: 0.260848; batch adversarial loss: 0.518514\n",
      "epoch 14; iter: 0; batch classifier loss: 0.203790; batch adversarial loss: 0.485701\n",
      "epoch 15; iter: 0; batch classifier loss: 0.209857; batch adversarial loss: 0.462993\n",
      "epoch 16; iter: 0; batch classifier loss: 0.170922; batch adversarial loss: 0.504427\n",
      "epoch 17; iter: 0; batch classifier loss: 0.224765; batch adversarial loss: 0.481942\n",
      "epoch 18; iter: 0; batch classifier loss: 0.147115; batch adversarial loss: 0.524212\n",
      "epoch 19; iter: 0; batch classifier loss: 0.167542; batch adversarial loss: 0.377927\n",
      "epoch 20; iter: 0; batch classifier loss: 0.163984; batch adversarial loss: 0.481049\n",
      "epoch 21; iter: 0; batch classifier loss: 0.161069; batch adversarial loss: 0.444917\n",
      "epoch 22; iter: 0; batch classifier loss: 0.151912; batch adversarial loss: 0.392985\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168938; batch adversarial loss: 0.447687\n",
      "epoch 24; iter: 0; batch classifier loss: 0.153707; batch adversarial loss: 0.499525\n",
      "epoch 25; iter: 0; batch classifier loss: 0.113675; batch adversarial loss: 0.386205\n",
      "epoch 26; iter: 0; batch classifier loss: 0.164250; batch adversarial loss: 0.447378\n",
      "epoch 27; iter: 0; batch classifier loss: 0.082192; batch adversarial loss: 0.398519\n",
      "epoch 28; iter: 0; batch classifier loss: 0.091562; batch adversarial loss: 0.416075\n",
      "epoch 29; iter: 0; batch classifier loss: 0.104125; batch adversarial loss: 0.514638\n",
      "epoch 30; iter: 0; batch classifier loss: 0.129111; batch adversarial loss: 0.459751\n",
      "epoch 31; iter: 0; batch classifier loss: 0.150699; batch adversarial loss: 0.415215\n",
      "epoch 32; iter: 0; batch classifier loss: 0.133037; batch adversarial loss: 0.512890\n",
      "epoch 33; iter: 0; batch classifier loss: 0.070666; batch adversarial loss: 0.460218\n",
      "epoch 34; iter: 0; batch classifier loss: 0.105696; batch adversarial loss: 0.444688\n",
      "epoch 35; iter: 0; batch classifier loss: 0.099411; batch adversarial loss: 0.468614\n",
      "epoch 36; iter: 0; batch classifier loss: 0.107239; batch adversarial loss: 0.472108\n",
      "epoch 37; iter: 0; batch classifier loss: 0.088017; batch adversarial loss: 0.362559\n",
      "epoch 38; iter: 0; batch classifier loss: 0.109635; batch adversarial loss: 0.473967\n",
      "epoch 39; iter: 0; batch classifier loss: 0.115721; batch adversarial loss: 0.399120\n",
      "epoch 40; iter: 0; batch classifier loss: 0.102397; batch adversarial loss: 0.449198\n",
      "epoch 41; iter: 0; batch classifier loss: 0.099151; batch adversarial loss: 0.421280\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131318; batch adversarial loss: 0.473034\n",
      "epoch 43; iter: 0; batch classifier loss: 0.130920; batch adversarial loss: 0.445940\n",
      "epoch 44; iter: 0; batch classifier loss: 0.130413; batch adversarial loss: 0.535088\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102348; batch adversarial loss: 0.439211\n",
      "epoch 46; iter: 0; batch classifier loss: 0.124276; batch adversarial loss: 0.366630\n",
      "epoch 47; iter: 0; batch classifier loss: 0.060222; batch adversarial loss: 0.491692\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100738; batch adversarial loss: 0.552840\n",
      "epoch 49; iter: 0; batch classifier loss: 0.084197; batch adversarial loss: 0.457851\n",
      "epoch 50; iter: 0; batch classifier loss: 0.090368; batch adversarial loss: 0.448377\n",
      "epoch 51; iter: 0; batch classifier loss: 0.101916; batch adversarial loss: 0.388961\n",
      "epoch 52; iter: 0; batch classifier loss: 0.047529; batch adversarial loss: 0.540607\n",
      "epoch 53; iter: 0; batch classifier loss: 0.065212; batch adversarial loss: 0.510131\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110953; batch adversarial loss: 0.449802\n",
      "epoch 55; iter: 0; batch classifier loss: 0.062321; batch adversarial loss: 0.474322\n",
      "epoch 56; iter: 0; batch classifier loss: 0.052328; batch adversarial loss: 0.456480\n",
      "epoch 57; iter: 0; batch classifier loss: 0.067381; batch adversarial loss: 0.436990\n",
      "epoch 58; iter: 0; batch classifier loss: 0.061794; batch adversarial loss: 0.453832\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074110; batch adversarial loss: 0.430944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.071433; batch adversarial loss: 0.479857\n",
      "epoch 61; iter: 0; batch classifier loss: 0.084764; batch adversarial loss: 0.377590\n",
      "epoch 62; iter: 0; batch classifier loss: 0.073246; batch adversarial loss: 0.386901\n",
      "epoch 63; iter: 0; batch classifier loss: 0.056844; batch adversarial loss: 0.505923\n",
      "epoch 64; iter: 0; batch classifier loss: 0.030069; batch adversarial loss: 0.514188\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075020; batch adversarial loss: 0.397604\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084266; batch adversarial loss: 0.450040\n",
      "epoch 67; iter: 0; batch classifier loss: 0.062611; batch adversarial loss: 0.526697\n",
      "epoch 68; iter: 0; batch classifier loss: 0.040309; batch adversarial loss: 0.534881\n",
      "epoch 69; iter: 0; batch classifier loss: 0.062203; batch adversarial loss: 0.482398\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065377; batch adversarial loss: 0.442467\n",
      "epoch 71; iter: 0; batch classifier loss: 0.068191; batch adversarial loss: 0.446649\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054738; batch adversarial loss: 0.565406\n",
      "epoch 73; iter: 0; batch classifier loss: 0.080616; batch adversarial loss: 0.525631\n",
      "epoch 74; iter: 0; batch classifier loss: 0.047194; batch adversarial loss: 0.488111\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067372; batch adversarial loss: 0.449234\n",
      "epoch 76; iter: 0; batch classifier loss: 0.032179; batch adversarial loss: 0.431693\n",
      "epoch 77; iter: 0; batch classifier loss: 0.039571; batch adversarial loss: 0.476693\n",
      "epoch 78; iter: 0; batch classifier loss: 0.049981; batch adversarial loss: 0.437404\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057767; batch adversarial loss: 0.516208\n",
      "epoch 80; iter: 0; batch classifier loss: 0.094506; batch adversarial loss: 0.391816\n",
      "epoch 81; iter: 0; batch classifier loss: 0.049526; batch adversarial loss: 0.540331\n",
      "epoch 82; iter: 0; batch classifier loss: 0.037801; batch adversarial loss: 0.451468\n",
      "epoch 83; iter: 0; batch classifier loss: 0.027347; batch adversarial loss: 0.496061\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047050; batch adversarial loss: 0.479197\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059902; batch adversarial loss: 0.491969\n",
      "epoch 86; iter: 0; batch classifier loss: 0.021406; batch adversarial loss: 0.417184\n",
      "epoch 87; iter: 0; batch classifier loss: 0.024848; batch adversarial loss: 0.524378\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040673; batch adversarial loss: 0.426226\n",
      "epoch 89; iter: 0; batch classifier loss: 0.031512; batch adversarial loss: 0.402893\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060249; batch adversarial loss: 0.396722\n",
      "epoch 91; iter: 0; batch classifier loss: 0.044754; batch adversarial loss: 0.512310\n",
      "epoch 92; iter: 0; batch classifier loss: 0.080740; batch adversarial loss: 0.435946\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061969; batch adversarial loss: 0.558895\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049488; batch adversarial loss: 0.476393\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046299; batch adversarial loss: 0.421320\n",
      "epoch 96; iter: 0; batch classifier loss: 0.101895; batch adversarial loss: 0.558601\n",
      "epoch 97; iter: 0; batch classifier loss: 0.026452; batch adversarial loss: 0.551524\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036196; batch adversarial loss: 0.455354\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044308; batch adversarial loss: 0.549441\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037631; batch adversarial loss: 0.384830\n",
      "epoch 101; iter: 0; batch classifier loss: 0.035974; batch adversarial loss: 0.467910\n",
      "epoch 102; iter: 0; batch classifier loss: 0.022444; batch adversarial loss: 0.440378\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040844; batch adversarial loss: 0.504512\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027142; batch adversarial loss: 0.419270\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043041; batch adversarial loss: 0.392651\n",
      "epoch 106; iter: 0; batch classifier loss: 0.029596; batch adversarial loss: 0.510491\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033533; batch adversarial loss: 0.462599\n",
      "epoch 108; iter: 0; batch classifier loss: 0.026812; batch adversarial loss: 0.462258\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049616; batch adversarial loss: 0.475109\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060384; batch adversarial loss: 0.508771\n",
      "epoch 111; iter: 0; batch classifier loss: 0.022015; batch adversarial loss: 0.478063\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034290; batch adversarial loss: 0.446651\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059478; batch adversarial loss: 0.525590\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048817; batch adversarial loss: 0.462006\n",
      "epoch 115; iter: 0; batch classifier loss: 0.013625; batch adversarial loss: 0.462952\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033272; batch adversarial loss: 0.517097\n",
      "epoch 117; iter: 0; batch classifier loss: 0.013112; batch adversarial loss: 0.531138\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039303; batch adversarial loss: 0.358563\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050057; batch adversarial loss: 0.460528\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033770; batch adversarial loss: 0.422577\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040069; batch adversarial loss: 0.458721\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021848; batch adversarial loss: 0.476717\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046303; batch adversarial loss: 0.484036\n",
      "epoch 124; iter: 0; batch classifier loss: 0.015815; batch adversarial loss: 0.401420\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035197; batch adversarial loss: 0.505509\n",
      "epoch 126; iter: 0; batch classifier loss: 0.013965; batch adversarial loss: 0.403282\n",
      "epoch 127; iter: 0; batch classifier loss: 0.017627; batch adversarial loss: 0.476801\n",
      "epoch 128; iter: 0; batch classifier loss: 0.006187; batch adversarial loss: 0.509132\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020191; batch adversarial loss: 0.454011\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031697; batch adversarial loss: 0.478459\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031035; batch adversarial loss: 0.429866\n",
      "epoch 132; iter: 0; batch classifier loss: 0.011383; batch adversarial loss: 0.540257\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019612; batch adversarial loss: 0.468713\n",
      "epoch 134; iter: 0; batch classifier loss: 0.012222; batch adversarial loss: 0.474460\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028750; batch adversarial loss: 0.430664\n",
      "epoch 136; iter: 0; batch classifier loss: 0.015194; batch adversarial loss: 0.509550\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041099; batch adversarial loss: 0.461188\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018259; batch adversarial loss: 0.572502\n",
      "epoch 139; iter: 0; batch classifier loss: 0.012183; batch adversarial loss: 0.571278\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036330; batch adversarial loss: 0.361297\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021407; batch adversarial loss: 0.467679\n",
      "epoch 142; iter: 0; batch classifier loss: 0.009026; batch adversarial loss: 0.441458\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025506; batch adversarial loss: 0.419833\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017118; batch adversarial loss: 0.440521\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025922; batch adversarial loss: 0.557558\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026701; batch adversarial loss: 0.420906\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034648; batch adversarial loss: 0.468004\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011626; batch adversarial loss: 0.428182\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017988; batch adversarial loss: 0.537376\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010007; batch adversarial loss: 0.445801\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028150; batch adversarial loss: 0.451227\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019498; batch adversarial loss: 0.533282\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015634; batch adversarial loss: 0.474456\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017072; batch adversarial loss: 0.548869\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009043; batch adversarial loss: 0.535398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.019025; batch adversarial loss: 0.416086\n",
      "epoch 157; iter: 0; batch classifier loss: 0.008682; batch adversarial loss: 0.357815\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033013; batch adversarial loss: 0.437296\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015183; batch adversarial loss: 0.408784\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022884; batch adversarial loss: 0.468687\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022890; batch adversarial loss: 0.421449\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019049; batch adversarial loss: 0.538090\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020861; batch adversarial loss: 0.484354\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012891; batch adversarial loss: 0.496673\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018652; batch adversarial loss: 0.475707\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022197; batch adversarial loss: 0.432321\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022054; batch adversarial loss: 0.528965\n",
      "epoch 168; iter: 0; batch classifier loss: 0.006282; batch adversarial loss: 0.369953\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006318; batch adversarial loss: 0.409798\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029313; batch adversarial loss: 0.432536\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023676; batch adversarial loss: 0.429744\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019081; batch adversarial loss: 0.552848\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023703; batch adversarial loss: 0.510408\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011364; batch adversarial loss: 0.466916\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028116; batch adversarial loss: 0.450458\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018162; batch adversarial loss: 0.385694\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019206; batch adversarial loss: 0.421714\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007729; batch adversarial loss: 0.478131\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011107; batch adversarial loss: 0.450469\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010338; batch adversarial loss: 0.564689\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017896; batch adversarial loss: 0.429803\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008826; batch adversarial loss: 0.518346\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017936; batch adversarial loss: 0.548670\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028301; batch adversarial loss: 0.426848\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018617; batch adversarial loss: 0.454783\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023218; batch adversarial loss: 0.466302\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033817; batch adversarial loss: 0.467974\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016342; batch adversarial loss: 0.441067\n",
      "epoch 189; iter: 0; batch classifier loss: 0.046169; batch adversarial loss: 0.399218\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025389; batch adversarial loss: 0.454471\n",
      "epoch 191; iter: 0; batch classifier loss: 0.002755; batch adversarial loss: 0.532219\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017823; batch adversarial loss: 0.419007\n",
      "epoch 193; iter: 0; batch classifier loss: 0.044532; batch adversarial loss: 0.380900\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006579; batch adversarial loss: 0.469486\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016108; batch adversarial loss: 0.439808\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020083; batch adversarial loss: 0.462913\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019080; batch adversarial loss: 0.364158\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009778; batch adversarial loss: 0.375291\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005974; batch adversarial loss: 0.479627\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672843; batch adversarial loss: 0.718375\n",
      "epoch 1; iter: 0; batch classifier loss: 0.461014; batch adversarial loss: 0.686253\n",
      "epoch 2; iter: 0; batch classifier loss: 0.336221; batch adversarial loss: 0.660338\n",
      "epoch 3; iter: 0; batch classifier loss: 0.419390; batch adversarial loss: 0.616941\n",
      "epoch 4; iter: 0; batch classifier loss: 0.353359; batch adversarial loss: 0.560075\n",
      "epoch 5; iter: 0; batch classifier loss: 0.342789; batch adversarial loss: 0.529707\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331990; batch adversarial loss: 0.516418\n",
      "epoch 7; iter: 0; batch classifier loss: 0.362469; batch adversarial loss: 0.507200\n",
      "epoch 8; iter: 0; batch classifier loss: 0.287356; batch adversarial loss: 0.501734\n",
      "epoch 9; iter: 0; batch classifier loss: 0.265736; batch adversarial loss: 0.476460\n",
      "epoch 10; iter: 0; batch classifier loss: 0.243860; batch adversarial loss: 0.445665\n",
      "epoch 11; iter: 0; batch classifier loss: 0.237560; batch adversarial loss: 0.483599\n",
      "epoch 12; iter: 0; batch classifier loss: 0.198782; batch adversarial loss: 0.483001\n",
      "epoch 13; iter: 0; batch classifier loss: 0.199502; batch adversarial loss: 0.473318\n",
      "epoch 14; iter: 0; batch classifier loss: 0.160041; batch adversarial loss: 0.497763\n",
      "epoch 15; iter: 0; batch classifier loss: 0.174167; batch adversarial loss: 0.475098\n",
      "epoch 16; iter: 0; batch classifier loss: 0.165990; batch adversarial loss: 0.464173\n",
      "epoch 17; iter: 0; batch classifier loss: 0.172584; batch adversarial loss: 0.484073\n",
      "epoch 18; iter: 0; batch classifier loss: 0.151760; batch adversarial loss: 0.427468\n",
      "epoch 19; iter: 0; batch classifier loss: 0.214062; batch adversarial loss: 0.424382\n",
      "epoch 20; iter: 0; batch classifier loss: 0.130918; batch adversarial loss: 0.468725\n",
      "epoch 21; iter: 0; batch classifier loss: 0.138816; batch adversarial loss: 0.427399\n",
      "epoch 22; iter: 0; batch classifier loss: 0.169341; batch adversarial loss: 0.403691\n",
      "epoch 23; iter: 0; batch classifier loss: 0.177978; batch adversarial loss: 0.372810\n",
      "epoch 24; iter: 0; batch classifier loss: 0.142099; batch adversarial loss: 0.403048\n",
      "epoch 25; iter: 0; batch classifier loss: 0.123087; batch adversarial loss: 0.415461\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180226; batch adversarial loss: 0.422968\n",
      "epoch 27; iter: 0; batch classifier loss: 0.121829; batch adversarial loss: 0.400357\n",
      "epoch 28; iter: 0; batch classifier loss: 0.156559; batch adversarial loss: 0.370516\n",
      "epoch 29; iter: 0; batch classifier loss: 0.138622; batch adversarial loss: 0.425866\n",
      "epoch 30; iter: 0; batch classifier loss: 0.119041; batch adversarial loss: 0.387670\n",
      "epoch 31; iter: 0; batch classifier loss: 0.107534; batch adversarial loss: 0.378475\n",
      "epoch 32; iter: 0; batch classifier loss: 0.190149; batch adversarial loss: 0.411399\n",
      "epoch 33; iter: 0; batch classifier loss: 0.136097; batch adversarial loss: 0.458324\n",
      "epoch 34; iter: 0; batch classifier loss: 0.141750; batch adversarial loss: 0.354837\n",
      "epoch 35; iter: 0; batch classifier loss: 0.132455; batch adversarial loss: 0.403586\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141857; batch adversarial loss: 0.429733\n",
      "epoch 37; iter: 0; batch classifier loss: 0.107883; batch adversarial loss: 0.422997\n",
      "epoch 38; iter: 0; batch classifier loss: 0.116773; batch adversarial loss: 0.461831\n",
      "epoch 39; iter: 0; batch classifier loss: 0.135828; batch adversarial loss: 0.381365\n",
      "epoch 40; iter: 0; batch classifier loss: 0.107325; batch adversarial loss: 0.417107\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116736; batch adversarial loss: 0.435945\n",
      "epoch 42; iter: 0; batch classifier loss: 0.078582; batch adversarial loss: 0.490416\n",
      "epoch 43; iter: 0; batch classifier loss: 0.088677; batch adversarial loss: 0.454287\n",
      "epoch 44; iter: 0; batch classifier loss: 0.081887; batch adversarial loss: 0.439329\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099598; batch adversarial loss: 0.465250\n",
      "epoch 46; iter: 0; batch classifier loss: 0.120951; batch adversarial loss: 0.382915\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113059; batch adversarial loss: 0.364589\n",
      "epoch 48; iter: 0; batch classifier loss: 0.089452; batch adversarial loss: 0.483662\n",
      "epoch 49; iter: 0; batch classifier loss: 0.095350; batch adversarial loss: 0.401734\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083410; batch adversarial loss: 0.379856\n",
      "epoch 51; iter: 0; batch classifier loss: 0.053322; batch adversarial loss: 0.425816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.061870; batch adversarial loss: 0.390085\n",
      "epoch 53; iter: 0; batch classifier loss: 0.083405; batch adversarial loss: 0.462949\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090177; batch adversarial loss: 0.375985\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077633; batch adversarial loss: 0.428287\n",
      "epoch 56; iter: 0; batch classifier loss: 0.056060; batch adversarial loss: 0.487170\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061279; batch adversarial loss: 0.368152\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072822; batch adversarial loss: 0.442042\n",
      "epoch 59; iter: 0; batch classifier loss: 0.106750; batch adversarial loss: 0.536789\n",
      "epoch 60; iter: 0; batch classifier loss: 0.069860; batch adversarial loss: 0.533336\n",
      "epoch 61; iter: 0; batch classifier loss: 0.067168; batch adversarial loss: 0.437507\n",
      "epoch 62; iter: 0; batch classifier loss: 0.113089; batch adversarial loss: 0.350202\n",
      "epoch 63; iter: 0; batch classifier loss: 0.066990; batch adversarial loss: 0.456794\n",
      "epoch 64; iter: 0; batch classifier loss: 0.058937; batch adversarial loss: 0.368797\n",
      "epoch 65; iter: 0; batch classifier loss: 0.067057; batch adversarial loss: 0.468608\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060013; batch adversarial loss: 0.357502\n",
      "epoch 67; iter: 0; batch classifier loss: 0.053968; batch adversarial loss: 0.435849\n",
      "epoch 68; iter: 0; batch classifier loss: 0.091424; batch adversarial loss: 0.366073\n",
      "epoch 69; iter: 0; batch classifier loss: 0.049589; batch adversarial loss: 0.373549\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073250; batch adversarial loss: 0.403959\n",
      "epoch 71; iter: 0; batch classifier loss: 0.061930; batch adversarial loss: 0.421759\n",
      "epoch 72; iter: 0; batch classifier loss: 0.056064; batch adversarial loss: 0.393949\n",
      "epoch 73; iter: 0; batch classifier loss: 0.072593; batch adversarial loss: 0.314460\n",
      "epoch 74; iter: 0; batch classifier loss: 0.050503; batch adversarial loss: 0.461350\n",
      "epoch 75; iter: 0; batch classifier loss: 0.046747; batch adversarial loss: 0.448908\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055624; batch adversarial loss: 0.373278\n",
      "epoch 77; iter: 0; batch classifier loss: 0.046640; batch adversarial loss: 0.398660\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062395; batch adversarial loss: 0.398695\n",
      "epoch 79; iter: 0; batch classifier loss: 0.086646; batch adversarial loss: 0.516254\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060447; batch adversarial loss: 0.346566\n",
      "epoch 81; iter: 0; batch classifier loss: 0.048946; batch adversarial loss: 0.407466\n",
      "epoch 82; iter: 0; batch classifier loss: 0.054473; batch adversarial loss: 0.481083\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071753; batch adversarial loss: 0.517021\n",
      "epoch 84; iter: 0; batch classifier loss: 0.032017; batch adversarial loss: 0.408507\n",
      "epoch 85; iter: 0; batch classifier loss: 0.041403; batch adversarial loss: 0.460736\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053325; batch adversarial loss: 0.391705\n",
      "epoch 87; iter: 0; batch classifier loss: 0.041458; batch adversarial loss: 0.351372\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073776; batch adversarial loss: 0.342119\n",
      "epoch 89; iter: 0; batch classifier loss: 0.067901; batch adversarial loss: 0.477346\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061807; batch adversarial loss: 0.346449\n",
      "epoch 91; iter: 0; batch classifier loss: 0.061224; batch adversarial loss: 0.529553\n",
      "epoch 92; iter: 0; batch classifier loss: 0.037860; batch adversarial loss: 0.426831\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056167; batch adversarial loss: 0.302679\n",
      "epoch 94; iter: 0; batch classifier loss: 0.073138; batch adversarial loss: 0.391676\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043477; batch adversarial loss: 0.419454\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068712; batch adversarial loss: 0.388235\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057444; batch adversarial loss: 0.502642\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059807; batch adversarial loss: 0.424494\n",
      "epoch 99; iter: 0; batch classifier loss: 0.072470; batch adversarial loss: 0.438772\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054063; batch adversarial loss: 0.478839\n",
      "epoch 101; iter: 0; batch classifier loss: 0.067139; batch adversarial loss: 0.393311\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049324; batch adversarial loss: 0.431406\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056761; batch adversarial loss: 0.479504\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039389; batch adversarial loss: 0.444154\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034801; batch adversarial loss: 0.396732\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044740; batch adversarial loss: 0.393373\n",
      "epoch 107; iter: 0; batch classifier loss: 0.043912; batch adversarial loss: 0.385706\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032000; batch adversarial loss: 0.487553\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027412; batch adversarial loss: 0.359734\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044546; batch adversarial loss: 0.362112\n",
      "epoch 111; iter: 0; batch classifier loss: 0.019012; batch adversarial loss: 0.464305\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059544; batch adversarial loss: 0.433653\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042770; batch adversarial loss: 0.463896\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057040; batch adversarial loss: 0.429527\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029616; batch adversarial loss: 0.459471\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027753; batch adversarial loss: 0.476532\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047497; batch adversarial loss: 0.482725\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031147; batch adversarial loss: 0.359303\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048017; batch adversarial loss: 0.530211\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037626; batch adversarial loss: 0.492935\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023393; batch adversarial loss: 0.476618\n",
      "epoch 122; iter: 0; batch classifier loss: 0.010327; batch adversarial loss: 0.384196\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029980; batch adversarial loss: 0.443284\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036946; batch adversarial loss: 0.450714\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017183; batch adversarial loss: 0.545335\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017614; batch adversarial loss: 0.435514\n",
      "epoch 127; iter: 0; batch classifier loss: 0.012382; batch adversarial loss: 0.438310\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021651; batch adversarial loss: 0.421657\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027329; batch adversarial loss: 0.475128\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016683; batch adversarial loss: 0.393489\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029125; batch adversarial loss: 0.418983\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022171; batch adversarial loss: 0.374601\n",
      "epoch 133; iter: 0; batch classifier loss: 0.007178; batch adversarial loss: 0.510720\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027419; batch adversarial loss: 0.459710\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013166; batch adversarial loss: 0.443042\n",
      "epoch 136; iter: 0; batch classifier loss: 0.112316; batch adversarial loss: 0.522092\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027644; batch adversarial loss: 0.470094\n",
      "epoch 138; iter: 0; batch classifier loss: 0.051447; batch adversarial loss: 0.486712\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038013; batch adversarial loss: 0.402142\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024649; batch adversarial loss: 0.437138\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043380; batch adversarial loss: 0.431466\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016907; batch adversarial loss: 0.478121\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015433; batch adversarial loss: 0.431881\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048111; batch adversarial loss: 0.481796\n",
      "epoch 145; iter: 0; batch classifier loss: 0.064633; batch adversarial loss: 0.462616\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018303; batch adversarial loss: 0.427161\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037893; batch adversarial loss: 0.414318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.053579; batch adversarial loss: 0.457219\n",
      "epoch 149; iter: 0; batch classifier loss: 0.058724; batch adversarial loss: 0.516165\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028275; batch adversarial loss: 0.418230\n",
      "epoch 151; iter: 0; batch classifier loss: 0.091044; batch adversarial loss: 0.515854\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028490; batch adversarial loss: 0.551002\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035232; batch adversarial loss: 0.437952\n",
      "epoch 154; iter: 0; batch classifier loss: 0.077375; batch adversarial loss: 0.737781\n",
      "epoch 155; iter: 0; batch classifier loss: 0.075616; batch adversarial loss: 0.429512\n",
      "epoch 156; iter: 0; batch classifier loss: 0.063210; batch adversarial loss: 0.495900\n",
      "epoch 157; iter: 0; batch classifier loss: 0.144183; batch adversarial loss: 0.657579\n",
      "epoch 158; iter: 0; batch classifier loss: 0.093175; batch adversarial loss: 0.456603\n",
      "epoch 159; iter: 0; batch classifier loss: 0.154301; batch adversarial loss: 0.768780\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045439; batch adversarial loss: 0.505190\n",
      "epoch 161; iter: 0; batch classifier loss: 0.083949; batch adversarial loss: 0.543745\n",
      "epoch 162; iter: 0; batch classifier loss: 0.172446; batch adversarial loss: 0.643353\n",
      "epoch 163; iter: 0; batch classifier loss: 0.094579; batch adversarial loss: 0.543154\n",
      "epoch 164; iter: 0; batch classifier loss: 0.106119; batch adversarial loss: 0.509675\n",
      "epoch 165; iter: 0; batch classifier loss: 0.153964; batch adversarial loss: 0.620052\n",
      "epoch 166; iter: 0; batch classifier loss: 0.171696; batch adversarial loss: 0.719680\n",
      "epoch 167; iter: 0; batch classifier loss: 0.145296; batch adversarial loss: 0.690874\n",
      "epoch 168; iter: 0; batch classifier loss: 0.088466; batch adversarial loss: 0.617351\n",
      "epoch 169; iter: 0; batch classifier loss: 0.224018; batch adversarial loss: 0.920687\n",
      "epoch 170; iter: 0; batch classifier loss: 0.096351; batch adversarial loss: 0.577808\n",
      "epoch 171; iter: 0; batch classifier loss: 0.160026; batch adversarial loss: 0.589672\n",
      "epoch 172; iter: 0; batch classifier loss: 0.140931; batch adversarial loss: 0.588239\n",
      "epoch 173; iter: 0; batch classifier loss: 0.133170; batch adversarial loss: 0.524085\n",
      "epoch 174; iter: 0; batch classifier loss: 0.106389; batch adversarial loss: 0.507352\n",
      "epoch 175; iter: 0; batch classifier loss: 0.083336; batch adversarial loss: 0.518805\n",
      "epoch 176; iter: 0; batch classifier loss: 0.105948; batch adversarial loss: 0.570763\n",
      "epoch 177; iter: 0; batch classifier loss: 0.194352; batch adversarial loss: 0.640321\n",
      "epoch 178; iter: 0; batch classifier loss: 0.110515; batch adversarial loss: 0.557423\n",
      "epoch 179; iter: 0; batch classifier loss: 0.162500; batch adversarial loss: 0.580523\n",
      "epoch 180; iter: 0; batch classifier loss: 0.111782; batch adversarial loss: 0.614483\n",
      "epoch 181; iter: 0; batch classifier loss: 0.150541; batch adversarial loss: 0.531538\n",
      "epoch 182; iter: 0; batch classifier loss: 0.102752; batch adversarial loss: 0.501733\n",
      "epoch 183; iter: 0; batch classifier loss: 0.169971; batch adversarial loss: 0.610038\n",
      "epoch 184; iter: 0; batch classifier loss: 0.088347; batch adversarial loss: 0.507285\n",
      "epoch 185; iter: 0; batch classifier loss: 0.153414; batch adversarial loss: 0.515278\n",
      "epoch 186; iter: 0; batch classifier loss: 0.118277; batch adversarial loss: 0.545892\n",
      "epoch 187; iter: 0; batch classifier loss: 0.150824; batch adversarial loss: 0.557947\n",
      "epoch 188; iter: 0; batch classifier loss: 0.103902; batch adversarial loss: 0.557150\n",
      "epoch 189; iter: 0; batch classifier loss: 0.120242; batch adversarial loss: 0.460588\n",
      "epoch 190; iter: 0; batch classifier loss: 0.109807; batch adversarial loss: 0.509396\n",
      "epoch 191; iter: 0; batch classifier loss: 0.085940; batch adversarial loss: 0.421509\n",
      "epoch 192; iter: 0; batch classifier loss: 0.094854; batch adversarial loss: 0.422185\n",
      "epoch 193; iter: 0; batch classifier loss: 0.131854; batch adversarial loss: 0.595758\n",
      "epoch 194; iter: 0; batch classifier loss: 0.160236; batch adversarial loss: 0.515971\n",
      "epoch 195; iter: 0; batch classifier loss: 0.090223; batch adversarial loss: 0.478920\n",
      "epoch 196; iter: 0; batch classifier loss: 0.119247; batch adversarial loss: 0.527745\n",
      "epoch 197; iter: 0; batch classifier loss: 0.150872; batch adversarial loss: 0.477037\n",
      "epoch 198; iter: 0; batch classifier loss: 0.140209; batch adversarial loss: 0.474162\n",
      "epoch 199; iter: 0; batch classifier loss: 0.110938; batch adversarial loss: 0.437963\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695783; batch adversarial loss: 0.980055\n",
      "epoch 1; iter: 0; batch classifier loss: 0.699168; batch adversarial loss: 1.056236\n",
      "epoch 2; iter: 0; batch classifier loss: 0.823549; batch adversarial loss: 1.025123\n",
      "epoch 3; iter: 0; batch classifier loss: 0.909481; batch adversarial loss: 0.965149\n",
      "epoch 4; iter: 0; batch classifier loss: 0.869774; batch adversarial loss: 0.911201\n",
      "epoch 5; iter: 0; batch classifier loss: 0.957484; batch adversarial loss: 0.860024\n",
      "epoch 6; iter: 0; batch classifier loss: 0.726333; batch adversarial loss: 0.766706\n",
      "epoch 7; iter: 0; batch classifier loss: 0.800224; batch adversarial loss: 0.698617\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569711; batch adversarial loss: 0.635854\n",
      "epoch 9; iter: 0; batch classifier loss: 0.594649; batch adversarial loss: 0.603682\n",
      "epoch 10; iter: 0; batch classifier loss: 0.434523; batch adversarial loss: 0.576755\n",
      "epoch 11; iter: 0; batch classifier loss: 0.385491; batch adversarial loss: 0.550744\n",
      "epoch 12; iter: 0; batch classifier loss: 0.348206; batch adversarial loss: 0.500857\n",
      "epoch 13; iter: 0; batch classifier loss: 0.330969; batch adversarial loss: 0.527816\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283428; batch adversarial loss: 0.479620\n",
      "epoch 15; iter: 0; batch classifier loss: 0.236550; batch adversarial loss: 0.469542\n",
      "epoch 16; iter: 0; batch classifier loss: 0.288908; batch adversarial loss: 0.521159\n",
      "epoch 17; iter: 0; batch classifier loss: 0.275805; batch adversarial loss: 0.486293\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214695; batch adversarial loss: 0.494320\n",
      "epoch 19; iter: 0; batch classifier loss: 0.238970; batch adversarial loss: 0.424386\n",
      "epoch 20; iter: 0; batch classifier loss: 0.200584; batch adversarial loss: 0.439702\n",
      "epoch 21; iter: 0; batch classifier loss: 0.154934; batch adversarial loss: 0.513099\n",
      "epoch 22; iter: 0; batch classifier loss: 0.185804; batch adversarial loss: 0.535310\n",
      "epoch 23; iter: 0; batch classifier loss: 0.151203; batch adversarial loss: 0.510597\n",
      "epoch 24; iter: 0; batch classifier loss: 0.133176; batch adversarial loss: 0.503289\n",
      "epoch 25; iter: 0; batch classifier loss: 0.144913; batch adversarial loss: 0.527750\n",
      "epoch 26; iter: 0; batch classifier loss: 0.161086; batch adversarial loss: 0.528593\n",
      "epoch 27; iter: 0; batch classifier loss: 0.174934; batch adversarial loss: 0.500592\n",
      "epoch 28; iter: 0; batch classifier loss: 0.182865; batch adversarial loss: 0.496875\n",
      "epoch 29; iter: 0; batch classifier loss: 0.126644; batch adversarial loss: 0.457805\n",
      "epoch 30; iter: 0; batch classifier loss: 0.114701; batch adversarial loss: 0.450302\n",
      "epoch 31; iter: 0; batch classifier loss: 0.164687; batch adversarial loss: 0.458447\n",
      "epoch 32; iter: 0; batch classifier loss: 0.176070; batch adversarial loss: 0.446865\n",
      "epoch 33; iter: 0; batch classifier loss: 0.169297; batch adversarial loss: 0.445536\n",
      "epoch 34; iter: 0; batch classifier loss: 0.194395; batch adversarial loss: 0.468158\n",
      "epoch 35; iter: 0; batch classifier loss: 0.144211; batch adversarial loss: 0.452207\n",
      "epoch 36; iter: 0; batch classifier loss: 0.135093; batch adversarial loss: 0.391484\n",
      "epoch 37; iter: 0; batch classifier loss: 0.168227; batch adversarial loss: 0.519914\n",
      "epoch 38; iter: 0; batch classifier loss: 0.136576; batch adversarial loss: 0.493861\n",
      "epoch 39; iter: 0; batch classifier loss: 0.158911; batch adversarial loss: 0.542993\n",
      "epoch 40; iter: 0; batch classifier loss: 0.168504; batch adversarial loss: 0.449635\n",
      "epoch 41; iter: 0; batch classifier loss: 0.096560; batch adversarial loss: 0.505171\n",
      "epoch 42; iter: 0; batch classifier loss: 0.085500; batch adversarial loss: 0.447752\n",
      "epoch 43; iter: 0; batch classifier loss: 0.141708; batch adversarial loss: 0.449813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.172488; batch adversarial loss: 0.589927\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103647; batch adversarial loss: 0.534155\n",
      "epoch 46; iter: 0; batch classifier loss: 0.158652; batch adversarial loss: 0.512999\n",
      "epoch 47; iter: 0; batch classifier loss: 0.075993; batch adversarial loss: 0.466912\n",
      "epoch 48; iter: 0; batch classifier loss: 0.109166; batch adversarial loss: 0.465679\n",
      "epoch 49; iter: 0; batch classifier loss: 0.109298; batch adversarial loss: 0.445810\n",
      "epoch 50; iter: 0; batch classifier loss: 0.116484; batch adversarial loss: 0.379071\n",
      "epoch 51; iter: 0; batch classifier loss: 0.186938; batch adversarial loss: 0.368461\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096003; batch adversarial loss: 0.447665\n",
      "epoch 53; iter: 0; batch classifier loss: 0.154497; batch adversarial loss: 0.486676\n",
      "epoch 54; iter: 0; batch classifier loss: 0.082931; batch adversarial loss: 0.529241\n",
      "epoch 55; iter: 0; batch classifier loss: 0.094767; batch adversarial loss: 0.390608\n",
      "epoch 56; iter: 0; batch classifier loss: 0.132154; batch adversarial loss: 0.485367\n",
      "epoch 57; iter: 0; batch classifier loss: 0.101058; batch adversarial loss: 0.550296\n",
      "epoch 58; iter: 0; batch classifier loss: 0.118795; batch adversarial loss: 0.350342\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082187; batch adversarial loss: 0.454273\n",
      "epoch 60; iter: 0; batch classifier loss: 0.093635; batch adversarial loss: 0.517114\n",
      "epoch 61; iter: 0; batch classifier loss: 0.138182; batch adversarial loss: 0.450700\n",
      "epoch 62; iter: 0; batch classifier loss: 0.086555; batch adversarial loss: 0.438715\n",
      "epoch 63; iter: 0; batch classifier loss: 0.081072; batch adversarial loss: 0.467630\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078385; batch adversarial loss: 0.437887\n",
      "epoch 65; iter: 0; batch classifier loss: 0.055078; batch adversarial loss: 0.481817\n",
      "epoch 66; iter: 0; batch classifier loss: 0.083434; batch adversarial loss: 0.511095\n",
      "epoch 67; iter: 0; batch classifier loss: 0.093291; batch adversarial loss: 0.442965\n",
      "epoch 68; iter: 0; batch classifier loss: 0.045518; batch adversarial loss: 0.336907\n",
      "epoch 69; iter: 0; batch classifier loss: 0.077333; batch adversarial loss: 0.430803\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110846; batch adversarial loss: 0.484589\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092698; batch adversarial loss: 0.423361\n",
      "epoch 72; iter: 0; batch classifier loss: 0.095868; batch adversarial loss: 0.475148\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055245; batch adversarial loss: 0.464617\n",
      "epoch 74; iter: 0; batch classifier loss: 0.062062; batch adversarial loss: 0.552679\n",
      "epoch 75; iter: 0; batch classifier loss: 0.085933; batch adversarial loss: 0.506014\n",
      "epoch 76; iter: 0; batch classifier loss: 0.057342; batch adversarial loss: 0.490340\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065105; batch adversarial loss: 0.547422\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054170; batch adversarial loss: 0.439564\n",
      "epoch 79; iter: 0; batch classifier loss: 0.119857; batch adversarial loss: 0.485902\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083959; batch adversarial loss: 0.513407\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083379; batch adversarial loss: 0.489952\n",
      "epoch 82; iter: 0; batch classifier loss: 0.064488; batch adversarial loss: 0.404275\n",
      "epoch 83; iter: 0; batch classifier loss: 0.090027; batch adversarial loss: 0.458175\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052540; batch adversarial loss: 0.556570\n",
      "epoch 85; iter: 0; batch classifier loss: 0.057492; batch adversarial loss: 0.414431\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058340; batch adversarial loss: 0.499342\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082749; batch adversarial loss: 0.422406\n",
      "epoch 88; iter: 0; batch classifier loss: 0.114053; batch adversarial loss: 0.472023\n",
      "epoch 89; iter: 0; batch classifier loss: 0.101556; batch adversarial loss: 0.474294\n",
      "epoch 90; iter: 0; batch classifier loss: 0.080045; batch adversarial loss: 0.474165\n",
      "epoch 91; iter: 0; batch classifier loss: 0.105792; batch adversarial loss: 0.502294\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041928; batch adversarial loss: 0.459038\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052988; batch adversarial loss: 0.458123\n",
      "epoch 94; iter: 0; batch classifier loss: 0.133032; batch adversarial loss: 0.393794\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057268; batch adversarial loss: 0.413302\n",
      "epoch 96; iter: 0; batch classifier loss: 0.040757; batch adversarial loss: 0.571965\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075080; batch adversarial loss: 0.441603\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039323; batch adversarial loss: 0.403338\n",
      "epoch 99; iter: 0; batch classifier loss: 0.094290; batch adversarial loss: 0.414361\n",
      "epoch 100; iter: 0; batch classifier loss: 0.077859; batch adversarial loss: 0.356278\n",
      "epoch 101; iter: 0; batch classifier loss: 0.082926; batch adversarial loss: 0.529485\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055696; batch adversarial loss: 0.440682\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066018; batch adversarial loss: 0.446864\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036755; batch adversarial loss: 0.428476\n",
      "epoch 105; iter: 0; batch classifier loss: 0.103536; batch adversarial loss: 0.412415\n",
      "epoch 106; iter: 0; batch classifier loss: 0.100611; batch adversarial loss: 0.514655\n",
      "epoch 107; iter: 0; batch classifier loss: 0.060598; batch adversarial loss: 0.475353\n",
      "epoch 108; iter: 0; batch classifier loss: 0.080117; batch adversarial loss: 0.455132\n",
      "epoch 109; iter: 0; batch classifier loss: 0.098772; batch adversarial loss: 0.438964\n",
      "epoch 110; iter: 0; batch classifier loss: 0.092864; batch adversarial loss: 0.428680\n",
      "epoch 111; iter: 0; batch classifier loss: 0.095483; batch adversarial loss: 0.470303\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047842; batch adversarial loss: 0.470436\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043364; batch adversarial loss: 0.576411\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057829; batch adversarial loss: 0.440359\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035940; batch adversarial loss: 0.459168\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057465; batch adversarial loss: 0.483357\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046180; batch adversarial loss: 0.422209\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045329; batch adversarial loss: 0.506386\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052155; batch adversarial loss: 0.490376\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057484; batch adversarial loss: 0.507855\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037817; batch adversarial loss: 0.413514\n",
      "epoch 122; iter: 0; batch classifier loss: 0.079605; batch adversarial loss: 0.530921\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021128; batch adversarial loss: 0.442555\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046694; batch adversarial loss: 0.467696\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068176; batch adversarial loss: 0.540330\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063115; batch adversarial loss: 0.420507\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043424; batch adversarial loss: 0.483185\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052049; batch adversarial loss: 0.472088\n",
      "epoch 129; iter: 0; batch classifier loss: 0.094230; batch adversarial loss: 0.423908\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022397; batch adversarial loss: 0.397529\n",
      "epoch 131; iter: 0; batch classifier loss: 0.063552; batch adversarial loss: 0.474960\n",
      "epoch 132; iter: 0; batch classifier loss: 0.111959; batch adversarial loss: 0.497830\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049339; batch adversarial loss: 0.422478\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039823; batch adversarial loss: 0.527476\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019207; batch adversarial loss: 0.415715\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038055; batch adversarial loss: 0.391860\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033257; batch adversarial loss: 0.444842\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038073; batch adversarial loss: 0.438473\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013269; batch adversarial loss: 0.351630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.045768; batch adversarial loss: 0.457831\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022400; batch adversarial loss: 0.470670\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034841; batch adversarial loss: 0.466867\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027271; batch adversarial loss: 0.480430\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031228; batch adversarial loss: 0.439029\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038044; batch adversarial loss: 0.481744\n",
      "epoch 146; iter: 0; batch classifier loss: 0.014977; batch adversarial loss: 0.485063\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016884; batch adversarial loss: 0.446152\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034598; batch adversarial loss: 0.487308\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046231; batch adversarial loss: 0.309185\n",
      "epoch 150; iter: 0; batch classifier loss: 0.060150; batch adversarial loss: 0.498536\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028236; batch adversarial loss: 0.397478\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018153; batch adversarial loss: 0.421321\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025498; batch adversarial loss: 0.437415\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024719; batch adversarial loss: 0.497172\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052855; batch adversarial loss: 0.582212\n",
      "epoch 156; iter: 0; batch classifier loss: 0.053892; batch adversarial loss: 0.524180\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027925; batch adversarial loss: 0.541033\n",
      "epoch 158; iter: 0; batch classifier loss: 0.039991; batch adversarial loss: 0.543318\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033298; batch adversarial loss: 0.412353\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021833; batch adversarial loss: 0.490950\n",
      "epoch 161; iter: 0; batch classifier loss: 0.052756; batch adversarial loss: 0.449160\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029994; batch adversarial loss: 0.393985\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011138; batch adversarial loss: 0.434325\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012817; batch adversarial loss: 0.388202\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018615; batch adversarial loss: 0.396329\n",
      "epoch 166; iter: 0; batch classifier loss: 0.065601; batch adversarial loss: 0.599056\n",
      "epoch 167; iter: 0; batch classifier loss: 0.038950; batch adversarial loss: 0.538921\n",
      "epoch 168; iter: 0; batch classifier loss: 0.046947; batch adversarial loss: 0.476906\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026656; batch adversarial loss: 0.562058\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008125; batch adversarial loss: 0.451396\n",
      "epoch 171; iter: 0; batch classifier loss: 0.053271; batch adversarial loss: 0.511203\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007603; batch adversarial loss: 0.424664\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025638; batch adversarial loss: 0.487966\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039875; batch adversarial loss: 0.417593\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028713; batch adversarial loss: 0.386091\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009850; batch adversarial loss: 0.395109\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007010; batch adversarial loss: 0.416265\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026046; batch adversarial loss: 0.485226\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031056; batch adversarial loss: 0.478613\n",
      "epoch 180; iter: 0; batch classifier loss: 0.048579; batch adversarial loss: 0.491102\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016663; batch adversarial loss: 0.431123\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032525; batch adversarial loss: 0.421330\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022040; batch adversarial loss: 0.427721\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020336; batch adversarial loss: 0.446066\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024624; batch adversarial loss: 0.492600\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027787; batch adversarial loss: 0.510098\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016911; batch adversarial loss: 0.502530\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016135; batch adversarial loss: 0.555291\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010716; batch adversarial loss: 0.522388\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025829; batch adversarial loss: 0.419200\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008087; batch adversarial loss: 0.439462\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020481; batch adversarial loss: 0.470569\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027321; batch adversarial loss: 0.465798\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013215; batch adversarial loss: 0.443292\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013306; batch adversarial loss: 0.457393\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014020; batch adversarial loss: 0.452925\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023352; batch adversarial loss: 0.437502\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013472; batch adversarial loss: 0.424021\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007373; batch adversarial loss: 0.468584\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707804; batch adversarial loss: 0.789787\n",
      "epoch 1; iter: 0; batch classifier loss: 0.471503; batch adversarial loss: 0.733678\n",
      "epoch 2; iter: 0; batch classifier loss: 0.331508; batch adversarial loss: 0.705484\n",
      "epoch 3; iter: 0; batch classifier loss: 0.417598; batch adversarial loss: 0.667349\n",
      "epoch 4; iter: 0; batch classifier loss: 0.295231; batch adversarial loss: 0.641937\n",
      "epoch 5; iter: 0; batch classifier loss: 0.375841; batch adversarial loss: 0.617381\n",
      "epoch 6; iter: 0; batch classifier loss: 0.275649; batch adversarial loss: 0.616978\n",
      "epoch 7; iter: 0; batch classifier loss: 0.321197; batch adversarial loss: 0.546707\n",
      "epoch 8; iter: 0; batch classifier loss: 0.379804; batch adversarial loss: 0.523661\n",
      "epoch 9; iter: 0; batch classifier loss: 0.262668; batch adversarial loss: 0.499754\n",
      "epoch 10; iter: 0; batch classifier loss: 0.343174; batch adversarial loss: 0.493703\n",
      "epoch 11; iter: 0; batch classifier loss: 0.286304; batch adversarial loss: 0.477021\n",
      "epoch 12; iter: 0; batch classifier loss: 0.274710; batch adversarial loss: 0.481742\n",
      "epoch 13; iter: 0; batch classifier loss: 0.198419; batch adversarial loss: 0.500543\n",
      "epoch 14; iter: 0; batch classifier loss: 0.230203; batch adversarial loss: 0.479402\n",
      "epoch 15; iter: 0; batch classifier loss: 0.204307; batch adversarial loss: 0.419355\n",
      "epoch 16; iter: 0; batch classifier loss: 0.198649; batch adversarial loss: 0.417091\n",
      "epoch 17; iter: 0; batch classifier loss: 0.200987; batch adversarial loss: 0.428350\n",
      "epoch 18; iter: 0; batch classifier loss: 0.228657; batch adversarial loss: 0.425033\n",
      "epoch 19; iter: 0; batch classifier loss: 0.302068; batch adversarial loss: 0.408425\n",
      "epoch 20; iter: 0; batch classifier loss: 0.256436; batch adversarial loss: 0.439566\n",
      "epoch 21; iter: 0; batch classifier loss: 0.203347; batch adversarial loss: 0.411901\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206993; batch adversarial loss: 0.508230\n",
      "epoch 23; iter: 0; batch classifier loss: 0.205633; batch adversarial loss: 0.432130\n",
      "epoch 24; iter: 0; batch classifier loss: 0.244307; batch adversarial loss: 0.367087\n",
      "epoch 25; iter: 0; batch classifier loss: 0.202131; batch adversarial loss: 0.432044\n",
      "epoch 26; iter: 0; batch classifier loss: 0.195902; batch adversarial loss: 0.423063\n",
      "epoch 27; iter: 0; batch classifier loss: 0.134390; batch adversarial loss: 0.366780\n",
      "epoch 28; iter: 0; batch classifier loss: 0.145226; batch adversarial loss: 0.424209\n",
      "epoch 29; iter: 0; batch classifier loss: 0.198183; batch adversarial loss: 0.457159\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138131; batch adversarial loss: 0.352600\n",
      "epoch 31; iter: 0; batch classifier loss: 0.171236; batch adversarial loss: 0.439107\n",
      "epoch 32; iter: 0; batch classifier loss: 0.198582; batch adversarial loss: 0.380922\n",
      "epoch 33; iter: 0; batch classifier loss: 0.139172; batch adversarial loss: 0.385874\n",
      "epoch 34; iter: 0; batch classifier loss: 0.160620; batch adversarial loss: 0.412398\n",
      "epoch 35; iter: 0; batch classifier loss: 0.165766; batch adversarial loss: 0.432083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.119050; batch adversarial loss: 0.357757\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145900; batch adversarial loss: 0.476916\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099266; batch adversarial loss: 0.396264\n",
      "epoch 39; iter: 0; batch classifier loss: 0.141400; batch adversarial loss: 0.495494\n",
      "epoch 40; iter: 0; batch classifier loss: 0.107332; batch adversarial loss: 0.427802\n",
      "epoch 41; iter: 0; batch classifier loss: 0.165287; batch adversarial loss: 0.421392\n",
      "epoch 42; iter: 0; batch classifier loss: 0.185965; batch adversarial loss: 0.353144\n",
      "epoch 43; iter: 0; batch classifier loss: 0.078769; batch adversarial loss: 0.454808\n",
      "epoch 44; iter: 0; batch classifier loss: 0.102732; batch adversarial loss: 0.428888\n",
      "epoch 45; iter: 0; batch classifier loss: 0.154942; batch adversarial loss: 0.325267\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113924; batch adversarial loss: 0.419977\n",
      "epoch 47; iter: 0; batch classifier loss: 0.127890; batch adversarial loss: 0.613572\n",
      "epoch 48; iter: 0; batch classifier loss: 0.088462; batch adversarial loss: 0.457584\n",
      "epoch 49; iter: 0; batch classifier loss: 0.100708; batch adversarial loss: 0.432205\n",
      "epoch 50; iter: 0; batch classifier loss: 0.092708; batch adversarial loss: 0.380494\n",
      "epoch 51; iter: 0; batch classifier loss: 0.104408; batch adversarial loss: 0.499819\n",
      "epoch 52; iter: 0; batch classifier loss: 0.102162; batch adversarial loss: 0.422519\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084477; batch adversarial loss: 0.442123\n",
      "epoch 54; iter: 0; batch classifier loss: 0.106535; batch adversarial loss: 0.394268\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077461; batch adversarial loss: 0.451545\n",
      "epoch 56; iter: 0; batch classifier loss: 0.123450; batch adversarial loss: 0.454122\n",
      "epoch 57; iter: 0; batch classifier loss: 0.089564; batch adversarial loss: 0.489520\n",
      "epoch 58; iter: 0; batch classifier loss: 0.114187; batch adversarial loss: 0.383572\n",
      "epoch 59; iter: 0; batch classifier loss: 0.112458; batch adversarial loss: 0.451304\n",
      "epoch 60; iter: 0; batch classifier loss: 0.054947; batch adversarial loss: 0.326856\n",
      "epoch 61; iter: 0; batch classifier loss: 0.086264; batch adversarial loss: 0.420913\n",
      "epoch 62; iter: 0; batch classifier loss: 0.117408; batch adversarial loss: 0.467127\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091683; batch adversarial loss: 0.371283\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076910; batch adversarial loss: 0.421875\n",
      "epoch 65; iter: 0; batch classifier loss: 0.112724; batch adversarial loss: 0.399726\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091943; batch adversarial loss: 0.496257\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107904; batch adversarial loss: 0.384580\n",
      "epoch 68; iter: 0; batch classifier loss: 0.055808; batch adversarial loss: 0.349530\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061005; batch adversarial loss: 0.471380\n",
      "epoch 70; iter: 0; batch classifier loss: 0.106125; batch adversarial loss: 0.411828\n",
      "epoch 71; iter: 0; batch classifier loss: 0.111825; batch adversarial loss: 0.418350\n",
      "epoch 72; iter: 0; batch classifier loss: 0.111773; batch adversarial loss: 0.411571\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058634; batch adversarial loss: 0.367386\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063158; batch adversarial loss: 0.512799\n",
      "epoch 75; iter: 0; batch classifier loss: 0.057586; batch adversarial loss: 0.393816\n",
      "epoch 76; iter: 0; batch classifier loss: 0.088675; batch adversarial loss: 0.495169\n",
      "epoch 77; iter: 0; batch classifier loss: 0.085414; batch adversarial loss: 0.536603\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074336; batch adversarial loss: 0.421595\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070378; batch adversarial loss: 0.496103\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067880; batch adversarial loss: 0.415261\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076150; batch adversarial loss: 0.387921\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066859; batch adversarial loss: 0.368126\n",
      "epoch 83; iter: 0; batch classifier loss: 0.101046; batch adversarial loss: 0.516087\n",
      "epoch 84; iter: 0; batch classifier loss: 0.061201; batch adversarial loss: 0.414159\n",
      "epoch 85; iter: 0; batch classifier loss: 0.054974; batch adversarial loss: 0.451839\n",
      "epoch 86; iter: 0; batch classifier loss: 0.097186; batch adversarial loss: 0.502182\n",
      "epoch 87; iter: 0; batch classifier loss: 0.095097; batch adversarial loss: 0.484619\n",
      "epoch 88; iter: 0; batch classifier loss: 0.046391; batch adversarial loss: 0.346549\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074372; batch adversarial loss: 0.421893\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062314; batch adversarial loss: 0.402563\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071404; batch adversarial loss: 0.352313\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066375; batch adversarial loss: 0.339839\n",
      "epoch 93; iter: 0; batch classifier loss: 0.070633; batch adversarial loss: 0.421533\n",
      "epoch 94; iter: 0; batch classifier loss: 0.076361; batch adversarial loss: 0.379336\n",
      "epoch 95; iter: 0; batch classifier loss: 0.078850; batch adversarial loss: 0.440553\n",
      "epoch 96; iter: 0; batch classifier loss: 0.080533; batch adversarial loss: 0.446150\n",
      "epoch 97; iter: 0; batch classifier loss: 0.093293; batch adversarial loss: 0.481493\n",
      "epoch 98; iter: 0; batch classifier loss: 0.060339; batch adversarial loss: 0.493383\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069431; batch adversarial loss: 0.390940\n",
      "epoch 100; iter: 0; batch classifier loss: 0.091288; batch adversarial loss: 0.531695\n",
      "epoch 101; iter: 0; batch classifier loss: 0.090227; batch adversarial loss: 0.388903\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036458; batch adversarial loss: 0.430807\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033953; batch adversarial loss: 0.433668\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066912; batch adversarial loss: 0.413302\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053654; batch adversarial loss: 0.403840\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041610; batch adversarial loss: 0.474244\n",
      "epoch 107; iter: 0; batch classifier loss: 0.043084; batch adversarial loss: 0.460873\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031079; batch adversarial loss: 0.443474\n",
      "epoch 109; iter: 0; batch classifier loss: 0.073364; batch adversarial loss: 0.397198\n",
      "epoch 110; iter: 0; batch classifier loss: 0.080893; batch adversarial loss: 0.475064\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039507; batch adversarial loss: 0.389235\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038298; batch adversarial loss: 0.491654\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042058; batch adversarial loss: 0.535251\n",
      "epoch 114; iter: 0; batch classifier loss: 0.058023; batch adversarial loss: 0.447473\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041709; batch adversarial loss: 0.442745\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046176; batch adversarial loss: 0.515281\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051107; batch adversarial loss: 0.442433\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035673; batch adversarial loss: 0.427617\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031259; batch adversarial loss: 0.449178\n",
      "epoch 120; iter: 0; batch classifier loss: 0.026134; batch adversarial loss: 0.427336\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038943; batch adversarial loss: 0.387968\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051068; batch adversarial loss: 0.456387\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028628; batch adversarial loss: 0.404606\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048256; batch adversarial loss: 0.458230\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023534; batch adversarial loss: 0.393656\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026846; batch adversarial loss: 0.495833\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048418; batch adversarial loss: 0.544156\n",
      "epoch 128; iter: 0; batch classifier loss: 0.010545; batch adversarial loss: 0.652591\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037965; batch adversarial loss: 0.455735\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032978; batch adversarial loss: 0.448060\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024024; batch adversarial loss: 0.420982\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029648; batch adversarial loss: 0.465778\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029720; batch adversarial loss: 0.517962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.016775; batch adversarial loss: 0.433796\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030819; batch adversarial loss: 0.504957\n",
      "epoch 136; iter: 0; batch classifier loss: 0.071851; batch adversarial loss: 0.543231\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033181; batch adversarial loss: 0.419049\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045887; batch adversarial loss: 0.481260\n",
      "epoch 139; iter: 0; batch classifier loss: 0.156241; batch adversarial loss: 0.699689\n",
      "epoch 140; iter: 0; batch classifier loss: 0.089324; batch adversarial loss: 0.478154\n",
      "epoch 141; iter: 0; batch classifier loss: 0.105902; batch adversarial loss: 0.791763\n",
      "epoch 142; iter: 0; batch classifier loss: 0.152970; batch adversarial loss: 0.665893\n",
      "epoch 143; iter: 0; batch classifier loss: 0.070847; batch adversarial loss: 0.574103\n",
      "epoch 144; iter: 0; batch classifier loss: 0.189450; batch adversarial loss: 0.754042\n",
      "epoch 145; iter: 0; batch classifier loss: 0.179298; batch adversarial loss: 0.688955\n",
      "epoch 146; iter: 0; batch classifier loss: 0.172543; batch adversarial loss: 0.683304\n",
      "epoch 147; iter: 0; batch classifier loss: 0.222421; batch adversarial loss: 0.744128\n",
      "epoch 148; iter: 0; batch classifier loss: 0.116003; batch adversarial loss: 0.601597\n",
      "epoch 149; iter: 0; batch classifier loss: 0.185822; batch adversarial loss: 0.657726\n",
      "epoch 150; iter: 0; batch classifier loss: 0.170701; batch adversarial loss: 0.660342\n",
      "epoch 151; iter: 0; batch classifier loss: 0.155880; batch adversarial loss: 0.629700\n",
      "epoch 152; iter: 0; batch classifier loss: 0.152240; batch adversarial loss: 0.686173\n",
      "epoch 153; iter: 0; batch classifier loss: 0.172571; batch adversarial loss: 0.500766\n",
      "epoch 154; iter: 0; batch classifier loss: 0.143729; batch adversarial loss: 0.596477\n",
      "epoch 155; iter: 0; batch classifier loss: 0.146935; batch adversarial loss: 0.662456\n",
      "epoch 156; iter: 0; batch classifier loss: 0.198106; batch adversarial loss: 0.617220\n",
      "epoch 157; iter: 0; batch classifier loss: 0.215819; batch adversarial loss: 0.699758\n",
      "epoch 158; iter: 0; batch classifier loss: 0.094550; batch adversarial loss: 0.532790\n",
      "epoch 159; iter: 0; batch classifier loss: 0.113369; batch adversarial loss: 0.525643\n",
      "epoch 160; iter: 0; batch classifier loss: 0.154795; batch adversarial loss: 0.516950\n",
      "epoch 161; iter: 0; batch classifier loss: 0.159945; batch adversarial loss: 0.621149\n",
      "epoch 162; iter: 0; batch classifier loss: 0.112720; batch adversarial loss: 0.556224\n",
      "epoch 163; iter: 0; batch classifier loss: 0.126411; batch adversarial loss: 0.592661\n",
      "epoch 164; iter: 0; batch classifier loss: 0.174031; batch adversarial loss: 0.561089\n",
      "epoch 165; iter: 0; batch classifier loss: 0.165324; batch adversarial loss: 0.591171\n",
      "epoch 166; iter: 0; batch classifier loss: 0.124462; batch adversarial loss: 0.508104\n",
      "epoch 167; iter: 0; batch classifier loss: 0.122255; batch adversarial loss: 0.495415\n",
      "epoch 168; iter: 0; batch classifier loss: 0.069538; batch adversarial loss: 0.409819\n",
      "epoch 169; iter: 0; batch classifier loss: 0.133007; batch adversarial loss: 0.575220\n",
      "epoch 170; iter: 0; batch classifier loss: 0.187180; batch adversarial loss: 0.641267\n",
      "epoch 171; iter: 0; batch classifier loss: 0.177949; batch adversarial loss: 0.554653\n",
      "epoch 172; iter: 0; batch classifier loss: 0.137179; batch adversarial loss: 0.529420\n",
      "epoch 173; iter: 0; batch classifier loss: 0.162415; batch adversarial loss: 0.611196\n",
      "epoch 174; iter: 0; batch classifier loss: 0.087168; batch adversarial loss: 0.476784\n",
      "epoch 175; iter: 0; batch classifier loss: 0.144211; batch adversarial loss: 0.488873\n",
      "epoch 176; iter: 0; batch classifier loss: 0.113130; batch adversarial loss: 0.445381\n",
      "epoch 177; iter: 0; batch classifier loss: 0.100133; batch adversarial loss: 0.410056\n",
      "epoch 178; iter: 0; batch classifier loss: 0.181267; batch adversarial loss: 0.599911\n",
      "epoch 179; iter: 0; batch classifier loss: 0.164391; batch adversarial loss: 0.532679\n",
      "epoch 180; iter: 0; batch classifier loss: 0.127967; batch adversarial loss: 0.439470\n",
      "epoch 181; iter: 0; batch classifier loss: 0.134312; batch adversarial loss: 0.497534\n",
      "epoch 182; iter: 0; batch classifier loss: 0.094069; batch adversarial loss: 0.492090\n",
      "epoch 183; iter: 0; batch classifier loss: 0.191261; batch adversarial loss: 0.395499\n",
      "epoch 184; iter: 0; batch classifier loss: 0.115629; batch adversarial loss: 0.475743\n",
      "epoch 185; iter: 0; batch classifier loss: 0.135184; batch adversarial loss: 0.482895\n",
      "epoch 186; iter: 0; batch classifier loss: 0.226387; batch adversarial loss: 0.389958\n",
      "epoch 187; iter: 0; batch classifier loss: 0.096409; batch adversarial loss: 0.480173\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032764; batch adversarial loss: 0.432762\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016229; batch adversarial loss: 0.456259\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035035; batch adversarial loss: 0.426382\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030350; batch adversarial loss: 0.410811\n",
      "epoch 192; iter: 0; batch classifier loss: 0.046008; batch adversarial loss: 0.332974\n",
      "epoch 193; iter: 0; batch classifier loss: 0.063394; batch adversarial loss: 0.524540\n",
      "epoch 194; iter: 0; batch classifier loss: 0.049186; batch adversarial loss: 0.519313\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034713; batch adversarial loss: 0.422644\n",
      "epoch 196; iter: 0; batch classifier loss: 0.043952; batch adversarial loss: 0.451808\n",
      "epoch 197; iter: 0; batch classifier loss: 0.075466; batch adversarial loss: 0.368485\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030521; batch adversarial loss: 0.441218\n",
      "epoch 199; iter: 0; batch classifier loss: 0.044439; batch adversarial loss: 0.466659\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698437; batch adversarial loss: 0.872902\n",
      "epoch 1; iter: 0; batch classifier loss: 0.755552; batch adversarial loss: 0.951312\n",
      "epoch 2; iter: 0; batch classifier loss: 0.876202; batch adversarial loss: 0.893941\n",
      "epoch 3; iter: 0; batch classifier loss: 0.897842; batch adversarial loss: 0.849546\n",
      "epoch 4; iter: 0; batch classifier loss: 0.815815; batch adversarial loss: 0.744118\n",
      "epoch 5; iter: 0; batch classifier loss: 0.798220; batch adversarial loss: 0.693425\n",
      "epoch 6; iter: 0; batch classifier loss: 0.627814; batch adversarial loss: 0.679596\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532185; batch adversarial loss: 0.611746\n",
      "epoch 8; iter: 0; batch classifier loss: 0.378700; batch adversarial loss: 0.610382\n",
      "epoch 9; iter: 0; batch classifier loss: 0.369598; batch adversarial loss: 0.561201\n",
      "epoch 10; iter: 0; batch classifier loss: 0.390115; batch adversarial loss: 0.496080\n",
      "epoch 11; iter: 0; batch classifier loss: 0.252021; batch adversarial loss: 0.531648\n",
      "epoch 12; iter: 0; batch classifier loss: 0.269524; batch adversarial loss: 0.487961\n",
      "epoch 13; iter: 0; batch classifier loss: 0.298920; batch adversarial loss: 0.496844\n",
      "epoch 14; iter: 0; batch classifier loss: 0.266739; batch adversarial loss: 0.505655\n",
      "epoch 15; iter: 0; batch classifier loss: 0.257586; batch adversarial loss: 0.519837\n",
      "epoch 16; iter: 0; batch classifier loss: 0.231939; batch adversarial loss: 0.524454\n",
      "epoch 17; iter: 0; batch classifier loss: 0.214231; batch adversarial loss: 0.533808\n",
      "epoch 18; iter: 0; batch classifier loss: 0.310053; batch adversarial loss: 0.564347\n",
      "epoch 19; iter: 0; batch classifier loss: 0.228926; batch adversarial loss: 0.497862\n",
      "epoch 20; iter: 0; batch classifier loss: 0.235095; batch adversarial loss: 0.506032\n",
      "epoch 21; iter: 0; batch classifier loss: 0.239961; batch adversarial loss: 0.460606\n",
      "epoch 22; iter: 0; batch classifier loss: 0.221125; batch adversarial loss: 0.463411\n",
      "epoch 23; iter: 0; batch classifier loss: 0.264760; batch adversarial loss: 0.465809\n",
      "epoch 24; iter: 0; batch classifier loss: 0.150905; batch adversarial loss: 0.499106\n",
      "epoch 25; iter: 0; batch classifier loss: 0.223948; batch adversarial loss: 0.423434\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208521; batch adversarial loss: 0.503811\n",
      "epoch 27; iter: 0; batch classifier loss: 0.145222; batch adversarial loss: 0.453423\n",
      "epoch 28; iter: 0; batch classifier loss: 0.198703; batch adversarial loss: 0.480476\n",
      "epoch 29; iter: 0; batch classifier loss: 0.140865; batch adversarial loss: 0.494180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.144175; batch adversarial loss: 0.481468\n",
      "epoch 31; iter: 0; batch classifier loss: 0.131339; batch adversarial loss: 0.530475\n",
      "epoch 32; iter: 0; batch classifier loss: 0.193152; batch adversarial loss: 0.468642\n",
      "epoch 33; iter: 0; batch classifier loss: 0.223876; batch adversarial loss: 0.452380\n",
      "epoch 34; iter: 0; batch classifier loss: 0.090485; batch adversarial loss: 0.465275\n",
      "epoch 35; iter: 0; batch classifier loss: 0.141815; batch adversarial loss: 0.449112\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140468; batch adversarial loss: 0.463645\n",
      "epoch 37; iter: 0; batch classifier loss: 0.126623; batch adversarial loss: 0.438321\n",
      "epoch 38; iter: 0; batch classifier loss: 0.186421; batch adversarial loss: 0.398409\n",
      "epoch 39; iter: 0; batch classifier loss: 0.117098; batch adversarial loss: 0.392193\n",
      "epoch 40; iter: 0; batch classifier loss: 0.167757; batch adversarial loss: 0.495370\n",
      "epoch 41; iter: 0; batch classifier loss: 0.155051; batch adversarial loss: 0.422297\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146476; batch adversarial loss: 0.523489\n",
      "epoch 43; iter: 0; batch classifier loss: 0.201015; batch adversarial loss: 0.403245\n",
      "epoch 44; iter: 0; batch classifier loss: 0.131895; batch adversarial loss: 0.383713\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124926; batch adversarial loss: 0.484874\n",
      "epoch 46; iter: 0; batch classifier loss: 0.075834; batch adversarial loss: 0.485789\n",
      "epoch 47; iter: 0; batch classifier loss: 0.165833; batch adversarial loss: 0.377600\n",
      "epoch 48; iter: 0; batch classifier loss: 0.145213; batch adversarial loss: 0.414647\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094058; batch adversarial loss: 0.430994\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129465; batch adversarial loss: 0.549749\n",
      "epoch 51; iter: 0; batch classifier loss: 0.129206; batch adversarial loss: 0.460432\n",
      "epoch 52; iter: 0; batch classifier loss: 0.107484; batch adversarial loss: 0.469771\n",
      "epoch 53; iter: 0; batch classifier loss: 0.147420; batch adversarial loss: 0.423919\n",
      "epoch 54; iter: 0; batch classifier loss: 0.131145; batch adversarial loss: 0.462147\n",
      "epoch 55; iter: 0; batch classifier loss: 0.109602; batch adversarial loss: 0.564966\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101986; batch adversarial loss: 0.477002\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112391; batch adversarial loss: 0.443195\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077892; batch adversarial loss: 0.529894\n",
      "epoch 59; iter: 0; batch classifier loss: 0.161367; batch adversarial loss: 0.387073\n",
      "epoch 60; iter: 0; batch classifier loss: 0.091297; batch adversarial loss: 0.456201\n",
      "epoch 61; iter: 0; batch classifier loss: 0.137507; batch adversarial loss: 0.435601\n",
      "epoch 62; iter: 0; batch classifier loss: 0.061487; batch adversarial loss: 0.364473\n",
      "epoch 63; iter: 0; batch classifier loss: 0.160366; batch adversarial loss: 0.459715\n",
      "epoch 64; iter: 0; batch classifier loss: 0.075875; batch adversarial loss: 0.467003\n",
      "epoch 65; iter: 0; batch classifier loss: 0.120629; batch adversarial loss: 0.449412\n",
      "epoch 66; iter: 0; batch classifier loss: 0.110561; batch adversarial loss: 0.468948\n",
      "epoch 67; iter: 0; batch classifier loss: 0.084651; batch adversarial loss: 0.580055\n",
      "epoch 68; iter: 0; batch classifier loss: 0.131324; batch adversarial loss: 0.492817\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102315; batch adversarial loss: 0.414346\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103311; batch adversarial loss: 0.450016\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079812; batch adversarial loss: 0.488888\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100864; batch adversarial loss: 0.523548\n",
      "epoch 73; iter: 0; batch classifier loss: 0.120070; batch adversarial loss: 0.478193\n",
      "epoch 74; iter: 0; batch classifier loss: 0.091748; batch adversarial loss: 0.476033\n",
      "epoch 75; iter: 0; batch classifier loss: 0.094245; batch adversarial loss: 0.537965\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103977; batch adversarial loss: 0.421861\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064695; batch adversarial loss: 0.529932\n",
      "epoch 78; iter: 0; batch classifier loss: 0.115077; batch adversarial loss: 0.485977\n",
      "epoch 79; iter: 0; batch classifier loss: 0.122904; batch adversarial loss: 0.537018\n",
      "epoch 80; iter: 0; batch classifier loss: 0.112275; batch adversarial loss: 0.391964\n",
      "epoch 81; iter: 0; batch classifier loss: 0.094708; batch adversarial loss: 0.439353\n",
      "epoch 82; iter: 0; batch classifier loss: 0.104076; batch adversarial loss: 0.433385\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094391; batch adversarial loss: 0.362384\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079264; batch adversarial loss: 0.425173\n",
      "epoch 85; iter: 0; batch classifier loss: 0.135976; batch adversarial loss: 0.462130\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084306; batch adversarial loss: 0.490411\n",
      "epoch 87; iter: 0; batch classifier loss: 0.100660; batch adversarial loss: 0.501107\n",
      "epoch 88; iter: 0; batch classifier loss: 0.080013; batch adversarial loss: 0.455633\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060381; batch adversarial loss: 0.505977\n",
      "epoch 90; iter: 0; batch classifier loss: 0.084724; batch adversarial loss: 0.533081\n",
      "epoch 91; iter: 0; batch classifier loss: 0.120654; batch adversarial loss: 0.538840\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058689; batch adversarial loss: 0.517674\n",
      "epoch 93; iter: 0; batch classifier loss: 0.086086; batch adversarial loss: 0.434126\n",
      "epoch 94; iter: 0; batch classifier loss: 0.069728; batch adversarial loss: 0.431853\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068423; batch adversarial loss: 0.430862\n",
      "epoch 96; iter: 0; batch classifier loss: 0.093584; batch adversarial loss: 0.448119\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077045; batch adversarial loss: 0.408602\n",
      "epoch 98; iter: 0; batch classifier loss: 0.102259; batch adversarial loss: 0.446670\n",
      "epoch 99; iter: 0; batch classifier loss: 0.096729; batch adversarial loss: 0.412602\n",
      "epoch 100; iter: 0; batch classifier loss: 0.101099; batch adversarial loss: 0.519807\n",
      "epoch 101; iter: 0; batch classifier loss: 0.066420; batch adversarial loss: 0.429695\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055975; batch adversarial loss: 0.426179\n",
      "epoch 103; iter: 0; batch classifier loss: 0.097158; batch adversarial loss: 0.436086\n",
      "epoch 104; iter: 0; batch classifier loss: 0.072956; batch adversarial loss: 0.572833\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059885; batch adversarial loss: 0.396274\n",
      "epoch 106; iter: 0; batch classifier loss: 0.111175; batch adversarial loss: 0.554075\n",
      "epoch 107; iter: 0; batch classifier loss: 0.073573; batch adversarial loss: 0.527344\n",
      "epoch 108; iter: 0; batch classifier loss: 0.112098; batch adversarial loss: 0.462970\n",
      "epoch 109; iter: 0; batch classifier loss: 0.086689; batch adversarial loss: 0.393358\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036409; batch adversarial loss: 0.508072\n",
      "epoch 111; iter: 0; batch classifier loss: 0.083239; batch adversarial loss: 0.457123\n",
      "epoch 112; iter: 0; batch classifier loss: 0.061134; batch adversarial loss: 0.443429\n",
      "epoch 113; iter: 0; batch classifier loss: 0.075799; batch adversarial loss: 0.418189\n",
      "epoch 114; iter: 0; batch classifier loss: 0.092841; batch adversarial loss: 0.463198\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049346; batch adversarial loss: 0.347680\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043318; batch adversarial loss: 0.391087\n",
      "epoch 117; iter: 0; batch classifier loss: 0.111918; batch adversarial loss: 0.411950\n",
      "epoch 118; iter: 0; batch classifier loss: 0.073946; batch adversarial loss: 0.400015\n",
      "epoch 119; iter: 0; batch classifier loss: 0.064368; batch adversarial loss: 0.475923\n",
      "epoch 120; iter: 0; batch classifier loss: 0.117554; batch adversarial loss: 0.408447\n",
      "epoch 121; iter: 0; batch classifier loss: 0.083100; batch adversarial loss: 0.368095\n",
      "epoch 122; iter: 0; batch classifier loss: 0.103720; batch adversarial loss: 0.464469\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043097; batch adversarial loss: 0.438675\n",
      "epoch 124; iter: 0; batch classifier loss: 0.049279; batch adversarial loss: 0.428584\n",
      "epoch 125; iter: 0; batch classifier loss: 0.087472; batch adversarial loss: 0.474452\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063593; batch adversarial loss: 0.433589\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051354; batch adversarial loss: 0.460271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.100274; batch adversarial loss: 0.452621\n",
      "epoch 129; iter: 0; batch classifier loss: 0.072313; batch adversarial loss: 0.465705\n",
      "epoch 130; iter: 0; batch classifier loss: 0.075966; batch adversarial loss: 0.411765\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054588; batch adversarial loss: 0.498218\n",
      "epoch 132; iter: 0; batch classifier loss: 0.111934; batch adversarial loss: 0.450131\n",
      "epoch 133; iter: 0; batch classifier loss: 0.079469; batch adversarial loss: 0.313796\n",
      "epoch 134; iter: 0; batch classifier loss: 0.082441; batch adversarial loss: 0.461495\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050545; batch adversarial loss: 0.396547\n",
      "epoch 136; iter: 0; batch classifier loss: 0.065930; batch adversarial loss: 0.464238\n",
      "epoch 137; iter: 0; batch classifier loss: 0.128719; batch adversarial loss: 0.460505\n",
      "epoch 138; iter: 0; batch classifier loss: 0.061611; batch adversarial loss: 0.489354\n",
      "epoch 139; iter: 0; batch classifier loss: 0.069239; batch adversarial loss: 0.358468\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053565; batch adversarial loss: 0.396975\n",
      "epoch 141; iter: 0; batch classifier loss: 0.086487; batch adversarial loss: 0.439468\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049959; batch adversarial loss: 0.427981\n",
      "epoch 143; iter: 0; batch classifier loss: 0.070116; batch adversarial loss: 0.536697\n",
      "epoch 144; iter: 0; batch classifier loss: 0.103227; batch adversarial loss: 0.494336\n",
      "epoch 145; iter: 0; batch classifier loss: 0.104606; batch adversarial loss: 0.472176\n",
      "epoch 146; iter: 0; batch classifier loss: 0.092755; batch adversarial loss: 0.470032\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037391; batch adversarial loss: 0.428560\n",
      "epoch 148; iter: 0; batch classifier loss: 0.093021; batch adversarial loss: 0.413900\n",
      "epoch 149; iter: 0; batch classifier loss: 0.070987; batch adversarial loss: 0.378675\n",
      "epoch 150; iter: 0; batch classifier loss: 0.092342; batch adversarial loss: 0.405163\n",
      "epoch 151; iter: 0; batch classifier loss: 0.107104; batch adversarial loss: 0.478860\n",
      "epoch 152; iter: 0; batch classifier loss: 0.108620; batch adversarial loss: 0.440516\n",
      "epoch 153; iter: 0; batch classifier loss: 0.079847; batch adversarial loss: 0.525521\n",
      "epoch 154; iter: 0; batch classifier loss: 0.075527; batch adversarial loss: 0.436292\n",
      "epoch 155; iter: 0; batch classifier loss: 0.047449; batch adversarial loss: 0.514627\n",
      "epoch 156; iter: 0; batch classifier loss: 0.106376; batch adversarial loss: 0.422308\n",
      "epoch 157; iter: 0; batch classifier loss: 0.113020; batch adversarial loss: 0.408895\n",
      "epoch 158; iter: 0; batch classifier loss: 0.097695; batch adversarial loss: 0.299270\n",
      "epoch 159; iter: 0; batch classifier loss: 0.142176; batch adversarial loss: 0.384400\n",
      "epoch 160; iter: 0; batch classifier loss: 0.105027; batch adversarial loss: 0.384548\n",
      "epoch 161; iter: 0; batch classifier loss: 0.111733; batch adversarial loss: 0.522189\n",
      "epoch 162; iter: 0; batch classifier loss: 0.093617; batch adversarial loss: 0.464299\n",
      "epoch 163; iter: 0; batch classifier loss: 0.110089; batch adversarial loss: 0.414210\n",
      "epoch 164; iter: 0; batch classifier loss: 0.121451; batch adversarial loss: 0.490644\n",
      "epoch 165; iter: 0; batch classifier loss: 0.145310; batch adversarial loss: 0.408851\n",
      "epoch 166; iter: 0; batch classifier loss: 0.090556; batch adversarial loss: 0.489752\n",
      "epoch 167; iter: 0; batch classifier loss: 0.098816; batch adversarial loss: 0.452755\n",
      "epoch 168; iter: 0; batch classifier loss: 0.159942; batch adversarial loss: 0.377879\n",
      "epoch 169; iter: 0; batch classifier loss: 0.139893; batch adversarial loss: 0.365887\n",
      "epoch 170; iter: 0; batch classifier loss: 0.139870; batch adversarial loss: 0.519779\n",
      "epoch 171; iter: 0; batch classifier loss: 0.114197; batch adversarial loss: 0.494129\n",
      "epoch 172; iter: 0; batch classifier loss: 0.143481; batch adversarial loss: 0.472812\n",
      "epoch 173; iter: 0; batch classifier loss: 0.216884; batch adversarial loss: 0.383388\n",
      "epoch 174; iter: 0; batch classifier loss: 0.248843; batch adversarial loss: 0.387239\n",
      "epoch 175; iter: 0; batch classifier loss: 0.128576; batch adversarial loss: 0.433455\n",
      "epoch 176; iter: 0; batch classifier loss: 0.123017; batch adversarial loss: 0.371787\n",
      "epoch 177; iter: 0; batch classifier loss: 0.221460; batch adversarial loss: 0.347389\n",
      "epoch 178; iter: 0; batch classifier loss: 0.126978; batch adversarial loss: 0.499086\n",
      "epoch 179; iter: 0; batch classifier loss: 0.150696; batch adversarial loss: 0.498001\n",
      "epoch 180; iter: 0; batch classifier loss: 0.155721; batch adversarial loss: 0.425815\n",
      "epoch 181; iter: 0; batch classifier loss: 0.209918; batch adversarial loss: 0.408037\n",
      "epoch 182; iter: 0; batch classifier loss: 0.158767; batch adversarial loss: 0.473351\n",
      "epoch 183; iter: 0; batch classifier loss: 0.134669; batch adversarial loss: 0.543591\n",
      "epoch 184; iter: 0; batch classifier loss: 0.227635; batch adversarial loss: 0.461085\n",
      "epoch 185; iter: 0; batch classifier loss: 0.172335; batch adversarial loss: 0.504542\n",
      "epoch 186; iter: 0; batch classifier loss: 0.170430; batch adversarial loss: 0.471700\n",
      "epoch 187; iter: 0; batch classifier loss: 0.221636; batch adversarial loss: 0.387151\n",
      "epoch 188; iter: 0; batch classifier loss: 0.201241; batch adversarial loss: 0.470448\n",
      "epoch 189; iter: 0; batch classifier loss: 0.160224; batch adversarial loss: 0.567003\n",
      "epoch 190; iter: 0; batch classifier loss: 0.156682; batch adversarial loss: 0.604079\n",
      "epoch 191; iter: 0; batch classifier loss: 0.094868; batch adversarial loss: 0.471140\n",
      "epoch 192; iter: 0; batch classifier loss: 0.148957; batch adversarial loss: 0.484349\n",
      "epoch 193; iter: 0; batch classifier loss: 0.098855; batch adversarial loss: 0.471453\n",
      "epoch 194; iter: 0; batch classifier loss: 0.229133; batch adversarial loss: 0.493819\n",
      "epoch 195; iter: 0; batch classifier loss: 0.139563; batch adversarial loss: 0.595308\n",
      "epoch 196; iter: 0; batch classifier loss: 0.191337; batch adversarial loss: 0.372402\n",
      "epoch 197; iter: 0; batch classifier loss: 0.167540; batch adversarial loss: 0.361611\n",
      "epoch 198; iter: 0; batch classifier loss: 0.200632; batch adversarial loss: 0.422725\n",
      "epoch 199; iter: 0; batch classifier loss: 0.212528; batch adversarial loss: 0.434102\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686303; batch adversarial loss: 0.737882\n",
      "epoch 1; iter: 0; batch classifier loss: 0.438376; batch adversarial loss: 0.697911\n",
      "epoch 2; iter: 0; batch classifier loss: 0.425393; batch adversarial loss: 0.688783\n",
      "epoch 3; iter: 0; batch classifier loss: 0.345438; batch adversarial loss: 0.648676\n",
      "epoch 4; iter: 0; batch classifier loss: 0.324547; batch adversarial loss: 0.624634\n",
      "epoch 5; iter: 0; batch classifier loss: 0.370059; batch adversarial loss: 0.580974\n",
      "epoch 6; iter: 0; batch classifier loss: 0.303968; batch adversarial loss: 0.537856\n",
      "epoch 7; iter: 0; batch classifier loss: 0.283942; batch adversarial loss: 0.511831\n",
      "epoch 8; iter: 0; batch classifier loss: 0.298987; batch adversarial loss: 0.557704\n",
      "epoch 9; iter: 0; batch classifier loss: 0.216506; batch adversarial loss: 0.540394\n",
      "epoch 10; iter: 0; batch classifier loss: 0.234400; batch adversarial loss: 0.515273\n",
      "epoch 11; iter: 0; batch classifier loss: 0.220865; batch adversarial loss: 0.521343\n",
      "epoch 12; iter: 0; batch classifier loss: 0.232870; batch adversarial loss: 0.485777\n",
      "epoch 13; iter: 0; batch classifier loss: 0.238272; batch adversarial loss: 0.469299\n",
      "epoch 14; iter: 0; batch classifier loss: 0.128787; batch adversarial loss: 0.505554\n",
      "epoch 15; iter: 0; batch classifier loss: 0.153311; batch adversarial loss: 0.499163\n",
      "epoch 16; iter: 0; batch classifier loss: 0.217714; batch adversarial loss: 0.428631\n",
      "epoch 17; iter: 0; batch classifier loss: 0.153809; batch adversarial loss: 0.475212\n",
      "epoch 18; iter: 0; batch classifier loss: 0.204264; batch adversarial loss: 0.505292\n",
      "epoch 19; iter: 0; batch classifier loss: 0.176603; batch adversarial loss: 0.457010\n",
      "epoch 20; iter: 0; batch classifier loss: 0.158915; batch adversarial loss: 0.449761\n",
      "epoch 21; iter: 0; batch classifier loss: 0.173650; batch adversarial loss: 0.415021\n",
      "epoch 22; iter: 0; batch classifier loss: 0.192282; batch adversarial loss: 0.525153\n",
      "epoch 23; iter: 0; batch classifier loss: 0.177280; batch adversarial loss: 0.495531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.183951; batch adversarial loss: 0.396835\n",
      "epoch 25; iter: 0; batch classifier loss: 0.155621; batch adversarial loss: 0.472602\n",
      "epoch 26; iter: 0; batch classifier loss: 0.190908; batch adversarial loss: 0.430672\n",
      "epoch 27; iter: 0; batch classifier loss: 0.141736; batch adversarial loss: 0.421631\n",
      "epoch 28; iter: 0; batch classifier loss: 0.131167; batch adversarial loss: 0.510644\n",
      "epoch 29; iter: 0; batch classifier loss: 0.135827; batch adversarial loss: 0.415299\n",
      "epoch 30; iter: 0; batch classifier loss: 0.223529; batch adversarial loss: 0.359442\n",
      "epoch 31; iter: 0; batch classifier loss: 0.116202; batch adversarial loss: 0.379405\n",
      "epoch 32; iter: 0; batch classifier loss: 0.157344; batch adversarial loss: 0.371431\n",
      "epoch 33; iter: 0; batch classifier loss: 0.180856; batch adversarial loss: 0.472929\n",
      "epoch 34; iter: 0; batch classifier loss: 0.132695; batch adversarial loss: 0.417278\n",
      "epoch 35; iter: 0; batch classifier loss: 0.165760; batch adversarial loss: 0.419600\n",
      "epoch 36; iter: 0; batch classifier loss: 0.143512; batch adversarial loss: 0.380474\n",
      "epoch 37; iter: 0; batch classifier loss: 0.087738; batch adversarial loss: 0.428545\n",
      "epoch 38; iter: 0; batch classifier loss: 0.083040; batch adversarial loss: 0.414595\n",
      "epoch 39; iter: 0; batch classifier loss: 0.150640; batch adversarial loss: 0.405671\n",
      "epoch 40; iter: 0; batch classifier loss: 0.121997; batch adversarial loss: 0.515988\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123028; batch adversarial loss: 0.392478\n",
      "epoch 42; iter: 0; batch classifier loss: 0.123622; batch adversarial loss: 0.478390\n",
      "epoch 43; iter: 0; batch classifier loss: 0.119054; batch adversarial loss: 0.450796\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098012; batch adversarial loss: 0.459499\n",
      "epoch 45; iter: 0; batch classifier loss: 0.119342; batch adversarial loss: 0.435496\n",
      "epoch 46; iter: 0; batch classifier loss: 0.149749; batch adversarial loss: 0.490280\n",
      "epoch 47; iter: 0; batch classifier loss: 0.135448; batch adversarial loss: 0.459843\n",
      "epoch 48; iter: 0; batch classifier loss: 0.126219; batch adversarial loss: 0.434414\n",
      "epoch 49; iter: 0; batch classifier loss: 0.090046; batch adversarial loss: 0.391672\n",
      "epoch 50; iter: 0; batch classifier loss: 0.092455; batch adversarial loss: 0.402121\n",
      "epoch 51; iter: 0; batch classifier loss: 0.119891; batch adversarial loss: 0.401277\n",
      "epoch 52; iter: 0; batch classifier loss: 0.083152; batch adversarial loss: 0.478646\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076770; batch adversarial loss: 0.447793\n",
      "epoch 54; iter: 0; batch classifier loss: 0.131532; batch adversarial loss: 0.444342\n",
      "epoch 55; iter: 0; batch classifier loss: 0.112188; batch adversarial loss: 0.428971\n",
      "epoch 56; iter: 0; batch classifier loss: 0.113484; batch adversarial loss: 0.370713\n",
      "epoch 57; iter: 0; batch classifier loss: 0.122577; batch adversarial loss: 0.411937\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064234; batch adversarial loss: 0.419845\n",
      "epoch 59; iter: 0; batch classifier loss: 0.063279; batch adversarial loss: 0.367474\n",
      "epoch 60; iter: 0; batch classifier loss: 0.078198; batch adversarial loss: 0.453218\n",
      "epoch 61; iter: 0; batch classifier loss: 0.084246; batch adversarial loss: 0.420488\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120368; batch adversarial loss: 0.413491\n",
      "epoch 63; iter: 0; batch classifier loss: 0.083956; batch adversarial loss: 0.399551\n",
      "epoch 64; iter: 0; batch classifier loss: 0.089571; batch adversarial loss: 0.402796\n",
      "epoch 65; iter: 0; batch classifier loss: 0.130854; batch adversarial loss: 0.437866\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084844; batch adversarial loss: 0.446765\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082919; batch adversarial loss: 0.390978\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096635; batch adversarial loss: 0.386761\n",
      "epoch 69; iter: 0; batch classifier loss: 0.090838; batch adversarial loss: 0.494237\n",
      "epoch 70; iter: 0; batch classifier loss: 0.075200; batch adversarial loss: 0.402982\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067238; batch adversarial loss: 0.366954\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080265; batch adversarial loss: 0.461615\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090210; batch adversarial loss: 0.487055\n",
      "epoch 74; iter: 0; batch classifier loss: 0.096059; batch adversarial loss: 0.440787\n",
      "epoch 75; iter: 0; batch classifier loss: 0.084875; batch adversarial loss: 0.492258\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069493; batch adversarial loss: 0.452268\n",
      "epoch 77; iter: 0; batch classifier loss: 0.086547; batch adversarial loss: 0.424804\n",
      "epoch 78; iter: 0; batch classifier loss: 0.046799; batch adversarial loss: 0.388909\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060898; batch adversarial loss: 0.483707\n",
      "epoch 80; iter: 0; batch classifier loss: 0.062986; batch adversarial loss: 0.353248\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061937; batch adversarial loss: 0.391243\n",
      "epoch 82; iter: 0; batch classifier loss: 0.096776; batch adversarial loss: 0.472601\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059073; batch adversarial loss: 0.399563\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055181; batch adversarial loss: 0.439155\n",
      "epoch 85; iter: 0; batch classifier loss: 0.035141; batch adversarial loss: 0.511566\n",
      "epoch 86; iter: 0; batch classifier loss: 0.042074; batch adversarial loss: 0.415322\n",
      "epoch 87; iter: 0; batch classifier loss: 0.044475; batch adversarial loss: 0.438594\n",
      "epoch 88; iter: 0; batch classifier loss: 0.039194; batch adversarial loss: 0.507105\n",
      "epoch 89; iter: 0; batch classifier loss: 0.026408; batch adversarial loss: 0.444421\n",
      "epoch 90; iter: 0; batch classifier loss: 0.079313; batch adversarial loss: 0.401056\n",
      "epoch 91; iter: 0; batch classifier loss: 0.025290; batch adversarial loss: 0.507728\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048376; batch adversarial loss: 0.409003\n",
      "epoch 93; iter: 0; batch classifier loss: 0.045672; batch adversarial loss: 0.481030\n",
      "epoch 94; iter: 0; batch classifier loss: 0.032812; batch adversarial loss: 0.470533\n",
      "epoch 95; iter: 0; batch classifier loss: 0.037675; batch adversarial loss: 0.411321\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058779; batch adversarial loss: 0.529082\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039627; batch adversarial loss: 0.472157\n",
      "epoch 98; iter: 0; batch classifier loss: 0.027486; batch adversarial loss: 0.485870\n",
      "epoch 99; iter: 0; batch classifier loss: 0.068421; batch adversarial loss: 0.531358\n",
      "epoch 100; iter: 0; batch classifier loss: 0.040803; batch adversarial loss: 0.502017\n",
      "epoch 101; iter: 0; batch classifier loss: 0.027568; batch adversarial loss: 0.473919\n",
      "epoch 102; iter: 0; batch classifier loss: 0.025887; batch adversarial loss: 0.477091\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038356; batch adversarial loss: 0.481381\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039992; batch adversarial loss: 0.478439\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030032; batch adversarial loss: 0.469386\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071477; batch adversarial loss: 0.424099\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055434; batch adversarial loss: 0.526754\n",
      "epoch 108; iter: 0; batch classifier loss: 0.018179; batch adversarial loss: 0.519526\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060218; batch adversarial loss: 0.632204\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047937; batch adversarial loss: 0.548627\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046281; batch adversarial loss: 0.556338\n",
      "epoch 112; iter: 0; batch classifier loss: 0.116897; batch adversarial loss: 0.596674\n",
      "epoch 113; iter: 0; batch classifier loss: 0.101171; batch adversarial loss: 0.709965\n",
      "epoch 114; iter: 0; batch classifier loss: 0.133250; batch adversarial loss: 0.562614\n",
      "epoch 115; iter: 0; batch classifier loss: 0.137247; batch adversarial loss: 0.634473\n",
      "epoch 116; iter: 0; batch classifier loss: 0.123538; batch adversarial loss: 0.617826\n",
      "epoch 117; iter: 0; batch classifier loss: 0.123824; batch adversarial loss: 0.634701\n",
      "epoch 118; iter: 0; batch classifier loss: 0.190963; batch adversarial loss: 0.720672\n",
      "epoch 119; iter: 0; batch classifier loss: 0.102352; batch adversarial loss: 0.550387\n",
      "epoch 120; iter: 0; batch classifier loss: 0.279764; batch adversarial loss: 0.904039\n",
      "epoch 121; iter: 0; batch classifier loss: 0.155014; batch adversarial loss: 0.587762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.138627; batch adversarial loss: 0.604817\n",
      "epoch 123; iter: 0; batch classifier loss: 0.088244; batch adversarial loss: 0.469445\n",
      "epoch 124; iter: 0; batch classifier loss: 0.170910; batch adversarial loss: 0.680095\n",
      "epoch 125; iter: 0; batch classifier loss: 0.168500; batch adversarial loss: 0.599924\n",
      "epoch 126; iter: 0; batch classifier loss: 0.158489; batch adversarial loss: 0.690516\n",
      "epoch 127; iter: 0; batch classifier loss: 0.210068; batch adversarial loss: 0.641943\n",
      "epoch 128; iter: 0; batch classifier loss: 0.124097; batch adversarial loss: 0.542827\n",
      "epoch 129; iter: 0; batch classifier loss: 0.154336; batch adversarial loss: 0.563856\n",
      "epoch 130; iter: 0; batch classifier loss: 0.186252; batch adversarial loss: 0.543651\n",
      "epoch 131; iter: 0; batch classifier loss: 0.156911; batch adversarial loss: 0.566890\n",
      "epoch 132; iter: 0; batch classifier loss: 0.155458; batch adversarial loss: 0.608497\n",
      "epoch 133; iter: 0; batch classifier loss: 0.172087; batch adversarial loss: 0.592923\n",
      "epoch 134; iter: 0; batch classifier loss: 0.149616; batch adversarial loss: 0.483001\n",
      "epoch 135; iter: 0; batch classifier loss: 0.132069; batch adversarial loss: 0.648080\n",
      "epoch 136; iter: 0; batch classifier loss: 0.164319; batch adversarial loss: 0.523413\n",
      "epoch 137; iter: 0; batch classifier loss: 0.153981; batch adversarial loss: 0.613627\n",
      "epoch 138; iter: 0; batch classifier loss: 0.157910; batch adversarial loss: 0.526768\n",
      "epoch 139; iter: 0; batch classifier loss: 0.165643; batch adversarial loss: 0.559184\n",
      "epoch 140; iter: 0; batch classifier loss: 0.155920; batch adversarial loss: 0.592725\n",
      "epoch 141; iter: 0; batch classifier loss: 0.155834; batch adversarial loss: 0.567345\n",
      "epoch 142; iter: 0; batch classifier loss: 0.192886; batch adversarial loss: 0.543051\n",
      "epoch 143; iter: 0; batch classifier loss: 0.103860; batch adversarial loss: 0.501394\n",
      "epoch 144; iter: 0; batch classifier loss: 0.098481; batch adversarial loss: 0.486751\n",
      "epoch 145; iter: 0; batch classifier loss: 0.103338; batch adversarial loss: 0.508367\n",
      "epoch 146; iter: 0; batch classifier loss: 0.104017; batch adversarial loss: 0.516966\n",
      "epoch 147; iter: 0; batch classifier loss: 0.094272; batch adversarial loss: 0.400124\n",
      "epoch 148; iter: 0; batch classifier loss: 0.075553; batch adversarial loss: 0.453635\n",
      "epoch 149; iter: 0; batch classifier loss: 0.104619; batch adversarial loss: 0.485875\n",
      "epoch 150; iter: 0; batch classifier loss: 0.078929; batch adversarial loss: 0.516848\n",
      "epoch 151; iter: 0; batch classifier loss: 0.066153; batch adversarial loss: 0.425126\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027518; batch adversarial loss: 0.505750\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042534; batch adversarial loss: 0.548940\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041421; batch adversarial loss: 0.455222\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012689; batch adversarial loss: 0.480956\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017889; batch adversarial loss: 0.448149\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020210; batch adversarial loss: 0.501841\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032116; batch adversarial loss: 0.444287\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023190; batch adversarial loss: 0.475606\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028091; batch adversarial loss: 0.458152\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035013; batch adversarial loss: 0.558982\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019561; batch adversarial loss: 0.467181\n",
      "epoch 163; iter: 0; batch classifier loss: 0.077509; batch adversarial loss: 0.475923\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036929; batch adversarial loss: 0.481732\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034061; batch adversarial loss: 0.513506\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031422; batch adversarial loss: 0.502768\n",
      "epoch 167; iter: 0; batch classifier loss: 0.121540; batch adversarial loss: 0.476264\n",
      "epoch 168; iter: 0; batch classifier loss: 0.073426; batch adversarial loss: 0.542542\n",
      "epoch 169; iter: 0; batch classifier loss: 0.072611; batch adversarial loss: 0.597829\n",
      "epoch 170; iter: 0; batch classifier loss: 0.067943; batch adversarial loss: 0.436564\n",
      "epoch 171; iter: 0; batch classifier loss: 0.097961; batch adversarial loss: 0.418554\n",
      "epoch 172; iter: 0; batch classifier loss: 0.091301; batch adversarial loss: 0.479202\n",
      "epoch 173; iter: 0; batch classifier loss: 0.078060; batch adversarial loss: 0.505124\n",
      "epoch 174; iter: 0; batch classifier loss: 0.132439; batch adversarial loss: 0.446254\n",
      "epoch 175; iter: 0; batch classifier loss: 0.057680; batch adversarial loss: 0.466358\n",
      "epoch 176; iter: 0; batch classifier loss: 0.075807; batch adversarial loss: 0.485656\n",
      "epoch 177; iter: 0; batch classifier loss: 0.056505; batch adversarial loss: 0.409166\n",
      "epoch 178; iter: 0; batch classifier loss: 0.050314; batch adversarial loss: 0.424756\n",
      "epoch 179; iter: 0; batch classifier loss: 0.098191; batch adversarial loss: 0.432664\n",
      "epoch 180; iter: 0; batch classifier loss: 0.054695; batch adversarial loss: 0.442006\n",
      "epoch 181; iter: 0; batch classifier loss: 0.101445; batch adversarial loss: 0.513309\n",
      "epoch 182; iter: 0; batch classifier loss: 0.051986; batch adversarial loss: 0.525605\n",
      "epoch 183; iter: 0; batch classifier loss: 0.056791; batch adversarial loss: 0.436143\n",
      "epoch 184; iter: 0; batch classifier loss: 0.048022; batch adversarial loss: 0.484323\n",
      "epoch 185; iter: 0; batch classifier loss: 0.089914; batch adversarial loss: 0.386599\n",
      "epoch 186; iter: 0; batch classifier loss: 0.073428; batch adversarial loss: 0.515092\n",
      "epoch 187; iter: 0; batch classifier loss: 0.089111; batch adversarial loss: 0.426041\n",
      "epoch 188; iter: 0; batch classifier loss: 0.103737; batch adversarial loss: 0.515263\n",
      "epoch 189; iter: 0; batch classifier loss: 0.062733; batch adversarial loss: 0.546251\n",
      "epoch 190; iter: 0; batch classifier loss: 0.102852; batch adversarial loss: 0.456101\n",
      "epoch 191; iter: 0; batch classifier loss: 0.136387; batch adversarial loss: 0.496509\n",
      "epoch 192; iter: 0; batch classifier loss: 0.107973; batch adversarial loss: 0.524855\n",
      "epoch 193; iter: 0; batch classifier loss: 0.117048; batch adversarial loss: 0.572418\n",
      "epoch 194; iter: 0; batch classifier loss: 0.063895; batch adversarial loss: 0.581988\n",
      "epoch 195; iter: 0; batch classifier loss: 0.102017; batch adversarial loss: 0.558496\n",
      "epoch 196; iter: 0; batch classifier loss: 0.090142; batch adversarial loss: 0.524321\n",
      "epoch 197; iter: 0; batch classifier loss: 0.040471; batch adversarial loss: 0.456931\n",
      "epoch 198; iter: 0; batch classifier loss: 0.117011; batch adversarial loss: 0.541813\n",
      "epoch 199; iter: 0; batch classifier loss: 0.088057; batch adversarial loss: 0.455018\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689450; batch adversarial loss: 0.695637\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433121; batch adversarial loss: 0.669267\n",
      "epoch 2; iter: 0; batch classifier loss: 0.439872; batch adversarial loss: 0.635394\n",
      "epoch 3; iter: 0; batch classifier loss: 0.421185; batch adversarial loss: 0.604542\n",
      "epoch 4; iter: 0; batch classifier loss: 0.342803; batch adversarial loss: 0.566627\n",
      "epoch 5; iter: 0; batch classifier loss: 0.407883; batch adversarial loss: 0.603534\n",
      "epoch 6; iter: 0; batch classifier loss: 0.393996; batch adversarial loss: 0.555076\n",
      "epoch 7; iter: 0; batch classifier loss: 0.470105; batch adversarial loss: 0.564582\n",
      "epoch 8; iter: 0; batch classifier loss: 0.487835; batch adversarial loss: 0.545194\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571368; batch adversarial loss: 0.556686\n",
      "epoch 10; iter: 0; batch classifier loss: 0.490719; batch adversarial loss: 0.554451\n",
      "epoch 11; iter: 0; batch classifier loss: 0.366186; batch adversarial loss: 0.557561\n",
      "epoch 12; iter: 0; batch classifier loss: 0.429955; batch adversarial loss: 0.558055\n",
      "epoch 13; iter: 0; batch classifier loss: 0.355956; batch adversarial loss: 0.540716\n",
      "epoch 14; iter: 0; batch classifier loss: 0.299451; batch adversarial loss: 0.563647\n",
      "epoch 15; iter: 0; batch classifier loss: 0.349836; batch adversarial loss: 0.538703\n",
      "epoch 16; iter: 0; batch classifier loss: 0.276996; batch adversarial loss: 0.523014\n",
      "epoch 17; iter: 0; batch classifier loss: 0.326361; batch adversarial loss: 0.494586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.373203; batch adversarial loss: 0.465598\n",
      "epoch 19; iter: 0; batch classifier loss: 0.265504; batch adversarial loss: 0.521488\n",
      "epoch 20; iter: 0; batch classifier loss: 0.208255; batch adversarial loss: 0.565131\n",
      "epoch 21; iter: 0; batch classifier loss: 0.266155; batch adversarial loss: 0.458584\n",
      "epoch 22; iter: 0; batch classifier loss: 0.240605; batch adversarial loss: 0.562695\n",
      "epoch 23; iter: 0; batch classifier loss: 0.191908; batch adversarial loss: 0.423313\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194940; batch adversarial loss: 0.457561\n",
      "epoch 25; iter: 0; batch classifier loss: 0.271353; batch adversarial loss: 0.415755\n",
      "epoch 26; iter: 0; batch classifier loss: 0.304729; batch adversarial loss: 0.440839\n",
      "epoch 27; iter: 0; batch classifier loss: 0.195075; batch adversarial loss: 0.471064\n",
      "epoch 28; iter: 0; batch classifier loss: 0.236089; batch adversarial loss: 0.508990\n",
      "epoch 29; iter: 0; batch classifier loss: 0.212710; batch adversarial loss: 0.425562\n",
      "epoch 30; iter: 0; batch classifier loss: 0.224576; batch adversarial loss: 0.409717\n",
      "epoch 31; iter: 0; batch classifier loss: 0.189398; batch adversarial loss: 0.463318\n",
      "epoch 32; iter: 0; batch classifier loss: 0.236928; batch adversarial loss: 0.421793\n",
      "epoch 33; iter: 0; batch classifier loss: 0.172643; batch adversarial loss: 0.529638\n",
      "epoch 34; iter: 0; batch classifier loss: 0.222698; batch adversarial loss: 0.370844\n",
      "epoch 35; iter: 0; batch classifier loss: 0.211475; batch adversarial loss: 0.448076\n",
      "epoch 36; iter: 0; batch classifier loss: 0.263036; batch adversarial loss: 0.447344\n",
      "epoch 37; iter: 0; batch classifier loss: 0.169463; batch adversarial loss: 0.422942\n",
      "epoch 38; iter: 0; batch classifier loss: 0.138983; batch adversarial loss: 0.535102\n",
      "epoch 39; iter: 0; batch classifier loss: 0.224220; batch adversarial loss: 0.459153\n",
      "epoch 40; iter: 0; batch classifier loss: 0.193049; batch adversarial loss: 0.559153\n",
      "epoch 41; iter: 0; batch classifier loss: 0.178440; batch adversarial loss: 0.511843\n",
      "epoch 42; iter: 0; batch classifier loss: 0.157756; batch adversarial loss: 0.506059\n",
      "epoch 43; iter: 0; batch classifier loss: 0.137897; batch adversarial loss: 0.513157\n",
      "epoch 44; iter: 0; batch classifier loss: 0.248953; batch adversarial loss: 0.499041\n",
      "epoch 45; iter: 0; batch classifier loss: 0.189952; batch adversarial loss: 0.487641\n",
      "epoch 46; iter: 0; batch classifier loss: 0.161344; batch adversarial loss: 0.536979\n",
      "epoch 47; iter: 0; batch classifier loss: 0.141261; batch adversarial loss: 0.579532\n",
      "epoch 48; iter: 0; batch classifier loss: 0.154312; batch adversarial loss: 0.490281\n",
      "epoch 49; iter: 0; batch classifier loss: 0.161720; batch adversarial loss: 0.427036\n",
      "epoch 50; iter: 0; batch classifier loss: 0.235512; batch adversarial loss: 0.460573\n",
      "epoch 51; iter: 0; batch classifier loss: 0.171443; batch adversarial loss: 0.533695\n",
      "epoch 52; iter: 0; batch classifier loss: 0.175274; batch adversarial loss: 0.431741\n",
      "epoch 53; iter: 0; batch classifier loss: 0.163065; batch adversarial loss: 0.469266\n",
      "epoch 54; iter: 0; batch classifier loss: 0.199671; batch adversarial loss: 0.402338\n",
      "epoch 55; iter: 0; batch classifier loss: 0.197233; batch adversarial loss: 0.459914\n",
      "epoch 56; iter: 0; batch classifier loss: 0.133998; batch adversarial loss: 0.507618\n",
      "epoch 57; iter: 0; batch classifier loss: 0.278661; batch adversarial loss: 0.448870\n",
      "epoch 58; iter: 0; batch classifier loss: 0.105705; batch adversarial loss: 0.529324\n",
      "epoch 59; iter: 0; batch classifier loss: 0.171462; batch adversarial loss: 0.425087\n",
      "epoch 60; iter: 0; batch classifier loss: 0.171534; batch adversarial loss: 0.494412\n",
      "epoch 61; iter: 0; batch classifier loss: 0.207693; batch adversarial loss: 0.469245\n",
      "epoch 62; iter: 0; batch classifier loss: 0.185238; batch adversarial loss: 0.413884\n",
      "epoch 63; iter: 0; batch classifier loss: 0.157519; batch adversarial loss: 0.478957\n",
      "epoch 64; iter: 0; batch classifier loss: 0.152500; batch adversarial loss: 0.493542\n",
      "epoch 65; iter: 0; batch classifier loss: 0.220622; batch adversarial loss: 0.530766\n",
      "epoch 66; iter: 0; batch classifier loss: 0.230751; batch adversarial loss: 0.540823\n",
      "epoch 67; iter: 0; batch classifier loss: 0.116695; batch adversarial loss: 0.646682\n",
      "epoch 68; iter: 0; batch classifier loss: 0.297367; batch adversarial loss: 0.471678\n",
      "epoch 69; iter: 0; batch classifier loss: 0.204999; batch adversarial loss: 0.434816\n",
      "epoch 70; iter: 0; batch classifier loss: 0.169925; batch adversarial loss: 0.400458\n",
      "epoch 71; iter: 0; batch classifier loss: 0.181970; batch adversarial loss: 0.435283\n",
      "epoch 72; iter: 0; batch classifier loss: 0.205760; batch adversarial loss: 0.494726\n",
      "epoch 73; iter: 0; batch classifier loss: 0.208636; batch adversarial loss: 0.514975\n",
      "epoch 74; iter: 0; batch classifier loss: 0.192657; batch adversarial loss: 0.447421\n",
      "epoch 75; iter: 0; batch classifier loss: 0.160663; batch adversarial loss: 0.494365\n",
      "epoch 76; iter: 0; batch classifier loss: 0.183625; batch adversarial loss: 0.460158\n",
      "epoch 77; iter: 0; batch classifier loss: 0.120617; batch adversarial loss: 0.587855\n",
      "epoch 78; iter: 0; batch classifier loss: 0.210256; batch adversarial loss: 0.413198\n",
      "epoch 79; iter: 0; batch classifier loss: 0.176112; batch adversarial loss: 0.443701\n",
      "epoch 80; iter: 0; batch classifier loss: 0.150815; batch adversarial loss: 0.530088\n",
      "epoch 81; iter: 0; batch classifier loss: 0.186449; batch adversarial loss: 0.400575\n",
      "epoch 82; iter: 0; batch classifier loss: 0.127389; batch adversarial loss: 0.460105\n",
      "epoch 83; iter: 0; batch classifier loss: 0.135910; batch adversarial loss: 0.514514\n",
      "epoch 84; iter: 0; batch classifier loss: 0.118393; batch adversarial loss: 0.528405\n",
      "epoch 85; iter: 0; batch classifier loss: 0.110995; batch adversarial loss: 0.430250\n",
      "epoch 86; iter: 0; batch classifier loss: 0.114747; batch adversarial loss: 0.485781\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079159; batch adversarial loss: 0.368950\n",
      "epoch 88; iter: 0; batch classifier loss: 0.095894; batch adversarial loss: 0.489587\n",
      "epoch 89; iter: 0; batch classifier loss: 0.130707; batch adversarial loss: 0.357052\n",
      "epoch 90; iter: 0; batch classifier loss: 0.096343; batch adversarial loss: 0.513035\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067735; batch adversarial loss: 0.517694\n",
      "epoch 92; iter: 0; batch classifier loss: 0.045312; batch adversarial loss: 0.490675\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069601; batch adversarial loss: 0.498341\n",
      "epoch 94; iter: 0; batch classifier loss: 0.114071; batch adversarial loss: 0.438292\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042093; batch adversarial loss: 0.451468\n",
      "epoch 96; iter: 0; batch classifier loss: 0.032099; batch adversarial loss: 0.555955\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054237; batch adversarial loss: 0.429659\n",
      "epoch 98; iter: 0; batch classifier loss: 0.073820; batch adversarial loss: 0.437949\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049333; batch adversarial loss: 0.521002\n",
      "epoch 100; iter: 0; batch classifier loss: 0.068864; batch adversarial loss: 0.525709\n",
      "epoch 101; iter: 0; batch classifier loss: 0.030220; batch adversarial loss: 0.560136\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033852; batch adversarial loss: 0.459094\n",
      "epoch 103; iter: 0; batch classifier loss: 0.070928; batch adversarial loss: 0.376564\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060885; batch adversarial loss: 0.401011\n",
      "epoch 105; iter: 0; batch classifier loss: 0.065149; batch adversarial loss: 0.460926\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052803; batch adversarial loss: 0.513237\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038529; batch adversarial loss: 0.437515\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069620; batch adversarial loss: 0.316892\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051239; batch adversarial loss: 0.534089\n",
      "epoch 110; iter: 0; batch classifier loss: 0.024276; batch adversarial loss: 0.566498\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054194; batch adversarial loss: 0.481120\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053172; batch adversarial loss: 0.436684\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041586; batch adversarial loss: 0.402324\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026210; batch adversarial loss: 0.540228\n",
      "epoch 115; iter: 0; batch classifier loss: 0.055284; batch adversarial loss: 0.459224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.048930; batch adversarial loss: 0.468615\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025209; batch adversarial loss: 0.543346\n",
      "epoch 118; iter: 0; batch classifier loss: 0.076169; batch adversarial loss: 0.484592\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055853; batch adversarial loss: 0.518263\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054163; batch adversarial loss: 0.453859\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054194; batch adversarial loss: 0.456875\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041740; batch adversarial loss: 0.484805\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064465; batch adversarial loss: 0.492837\n",
      "epoch 124; iter: 0; batch classifier loss: 0.018584; batch adversarial loss: 0.401267\n",
      "epoch 125; iter: 0; batch classifier loss: 0.014812; batch adversarial loss: 0.457568\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035134; batch adversarial loss: 0.479140\n",
      "epoch 127; iter: 0; batch classifier loss: 0.011820; batch adversarial loss: 0.456686\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051288; batch adversarial loss: 0.409841\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018936; batch adversarial loss: 0.564041\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023554; batch adversarial loss: 0.463900\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034940; batch adversarial loss: 0.414331\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034905; batch adversarial loss: 0.435871\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026844; batch adversarial loss: 0.381989\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020077; batch adversarial loss: 0.457348\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019008; batch adversarial loss: 0.423289\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019630; batch adversarial loss: 0.492633\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031021; batch adversarial loss: 0.523633\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011977; batch adversarial loss: 0.533535\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013308; batch adversarial loss: 0.487404\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048883; batch adversarial loss: 0.447306\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045909; batch adversarial loss: 0.478484\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045013; batch adversarial loss: 0.424438\n",
      "epoch 143; iter: 0; batch classifier loss: 0.008192; batch adversarial loss: 0.529975\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041466; batch adversarial loss: 0.463118\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015749; batch adversarial loss: 0.418156\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030272; batch adversarial loss: 0.414953\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030918; batch adversarial loss: 0.606872\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017658; batch adversarial loss: 0.523457\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014651; batch adversarial loss: 0.509850\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018015; batch adversarial loss: 0.446003\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039708; batch adversarial loss: 0.432130\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021649; batch adversarial loss: 0.448740\n",
      "epoch 153; iter: 0; batch classifier loss: 0.005454; batch adversarial loss: 0.476389\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015511; batch adversarial loss: 0.478353\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046366; batch adversarial loss: 0.423889\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013150; batch adversarial loss: 0.472247\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020247; batch adversarial loss: 0.565857\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028850; batch adversarial loss: 0.490652\n",
      "epoch 159; iter: 0; batch classifier loss: 0.046392; batch adversarial loss: 0.415165\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007903; batch adversarial loss: 0.429623\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015957; batch adversarial loss: 0.453566\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017396; batch adversarial loss: 0.366189\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013856; batch adversarial loss: 0.441543\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011307; batch adversarial loss: 0.449979\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008540; batch adversarial loss: 0.512058\n",
      "epoch 166; iter: 0; batch classifier loss: 0.008547; batch adversarial loss: 0.441491\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022711; batch adversarial loss: 0.497938\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019141; batch adversarial loss: 0.443973\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008734; batch adversarial loss: 0.475367\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023085; batch adversarial loss: 0.389789\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026520; batch adversarial loss: 0.436673\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006739; batch adversarial loss: 0.441568\n",
      "epoch 173; iter: 0; batch classifier loss: 0.004829; batch adversarial loss: 0.386514\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013437; batch adversarial loss: 0.425544\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011731; batch adversarial loss: 0.520428\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008105; batch adversarial loss: 0.454162\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019527; batch adversarial loss: 0.412824\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008594; batch adversarial loss: 0.420842\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016388; batch adversarial loss: 0.451096\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007006; batch adversarial loss: 0.511558\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014966; batch adversarial loss: 0.569224\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030763; batch adversarial loss: 0.479505\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029290; batch adversarial loss: 0.467458\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015421; batch adversarial loss: 0.495839\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009685; batch adversarial loss: 0.520715\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008488; batch adversarial loss: 0.467438\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025073; batch adversarial loss: 0.457834\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027759; batch adversarial loss: 0.406938\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028184; batch adversarial loss: 0.442933\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024874; batch adversarial loss: 0.560284\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033370; batch adversarial loss: 0.523423\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004695; batch adversarial loss: 0.418097\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015503; batch adversarial loss: 0.333609\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004858; batch adversarial loss: 0.460464\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008908; batch adversarial loss: 0.514610\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017560; batch adversarial loss: 0.490453\n",
      "epoch 197; iter: 0; batch classifier loss: 0.003830; batch adversarial loss: 0.413694\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029040; batch adversarial loss: 0.422193\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007287; batch adversarial loss: 0.474226\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692878; batch adversarial loss: 0.731358\n",
      "epoch 1; iter: 0; batch classifier loss: 0.364286; batch adversarial loss: 0.689192\n",
      "epoch 2; iter: 0; batch classifier loss: 0.337434; batch adversarial loss: 0.643145\n",
      "epoch 3; iter: 0; batch classifier loss: 0.389792; batch adversarial loss: 0.620586\n",
      "epoch 4; iter: 0; batch classifier loss: 0.394691; batch adversarial loss: 0.578182\n",
      "epoch 5; iter: 0; batch classifier loss: 0.347158; batch adversarial loss: 0.578122\n",
      "epoch 6; iter: 0; batch classifier loss: 0.304350; batch adversarial loss: 0.573520\n",
      "epoch 7; iter: 0; batch classifier loss: 0.416319; batch adversarial loss: 0.546008\n",
      "epoch 8; iter: 0; batch classifier loss: 0.291750; batch adversarial loss: 0.535604\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363531; batch adversarial loss: 0.475797\n",
      "epoch 10; iter: 0; batch classifier loss: 0.325691; batch adversarial loss: 0.507021\n",
      "epoch 11; iter: 0; batch classifier loss: 0.387397; batch adversarial loss: 0.524405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.437420; batch adversarial loss: 0.503800\n",
      "epoch 13; iter: 0; batch classifier loss: 0.490303; batch adversarial loss: 0.515747\n",
      "epoch 14; iter: 0; batch classifier loss: 0.459420; batch adversarial loss: 0.502615\n",
      "epoch 15; iter: 0; batch classifier loss: 0.332577; batch adversarial loss: 0.493071\n",
      "epoch 16; iter: 0; batch classifier loss: 0.270306; batch adversarial loss: 0.467525\n",
      "epoch 17; iter: 0; batch classifier loss: 0.334163; batch adversarial loss: 0.482530\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269841; batch adversarial loss: 0.410180\n",
      "epoch 19; iter: 0; batch classifier loss: 0.270373; batch adversarial loss: 0.455223\n",
      "epoch 20; iter: 0; batch classifier loss: 0.250453; batch adversarial loss: 0.414706\n",
      "epoch 21; iter: 0; batch classifier loss: 0.309457; batch adversarial loss: 0.441474\n",
      "epoch 22; iter: 0; batch classifier loss: 0.284114; batch adversarial loss: 0.477855\n",
      "epoch 23; iter: 0; batch classifier loss: 0.265247; batch adversarial loss: 0.399938\n",
      "epoch 24; iter: 0; batch classifier loss: 0.253975; batch adversarial loss: 0.459631\n",
      "epoch 25; iter: 0; batch classifier loss: 0.256431; batch adversarial loss: 0.564275\n",
      "epoch 26; iter: 0; batch classifier loss: 0.225320; batch adversarial loss: 0.461713\n",
      "epoch 27; iter: 0; batch classifier loss: 0.150154; batch adversarial loss: 0.505232\n",
      "epoch 28; iter: 0; batch classifier loss: 0.133184; batch adversarial loss: 0.434373\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178768; batch adversarial loss: 0.503511\n",
      "epoch 30; iter: 0; batch classifier loss: 0.184324; batch adversarial loss: 0.449742\n",
      "epoch 31; iter: 0; batch classifier loss: 0.161378; batch adversarial loss: 0.365286\n",
      "epoch 32; iter: 0; batch classifier loss: 0.097809; batch adversarial loss: 0.426516\n",
      "epoch 33; iter: 0; batch classifier loss: 0.114557; batch adversarial loss: 0.507620\n",
      "epoch 34; iter: 0; batch classifier loss: 0.184252; batch adversarial loss: 0.514328\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151464; batch adversarial loss: 0.428077\n",
      "epoch 36; iter: 0; batch classifier loss: 0.122476; batch adversarial loss: 0.560273\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110379; batch adversarial loss: 0.409421\n",
      "epoch 38; iter: 0; batch classifier loss: 0.090304; batch adversarial loss: 0.381485\n",
      "epoch 39; iter: 0; batch classifier loss: 0.093622; batch adversarial loss: 0.473947\n",
      "epoch 40; iter: 0; batch classifier loss: 0.120131; batch adversarial loss: 0.427533\n",
      "epoch 41; iter: 0; batch classifier loss: 0.099916; batch adversarial loss: 0.447831\n",
      "epoch 42; iter: 0; batch classifier loss: 0.132805; batch adversarial loss: 0.445500\n",
      "epoch 43; iter: 0; batch classifier loss: 0.143903; batch adversarial loss: 0.492311\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118581; batch adversarial loss: 0.520515\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086160; batch adversarial loss: 0.498381\n",
      "epoch 46; iter: 0; batch classifier loss: 0.105333; batch adversarial loss: 0.368468\n",
      "epoch 47; iter: 0; batch classifier loss: 0.059236; batch adversarial loss: 0.444657\n",
      "epoch 48; iter: 0; batch classifier loss: 0.103294; batch adversarial loss: 0.498308\n",
      "epoch 49; iter: 0; batch classifier loss: 0.097278; batch adversarial loss: 0.409336\n",
      "epoch 50; iter: 0; batch classifier loss: 0.081393; batch adversarial loss: 0.388357\n",
      "epoch 51; iter: 0; batch classifier loss: 0.057118; batch adversarial loss: 0.453743\n",
      "epoch 52; iter: 0; batch classifier loss: 0.094706; batch adversarial loss: 0.346990\n",
      "epoch 53; iter: 0; batch classifier loss: 0.087892; batch adversarial loss: 0.438624\n",
      "epoch 54; iter: 0; batch classifier loss: 0.071066; batch adversarial loss: 0.483855\n",
      "epoch 55; iter: 0; batch classifier loss: 0.113942; batch adversarial loss: 0.399502\n",
      "epoch 56; iter: 0; batch classifier loss: 0.091610; batch adversarial loss: 0.450545\n",
      "epoch 57; iter: 0; batch classifier loss: 0.108541; batch adversarial loss: 0.534827\n",
      "epoch 58; iter: 0; batch classifier loss: 0.054200; batch adversarial loss: 0.500376\n",
      "epoch 59; iter: 0; batch classifier loss: 0.079287; batch adversarial loss: 0.424357\n",
      "epoch 60; iter: 0; batch classifier loss: 0.077463; batch adversarial loss: 0.395410\n",
      "epoch 61; iter: 0; batch classifier loss: 0.037772; batch adversarial loss: 0.408062\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069663; batch adversarial loss: 0.467112\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100399; batch adversarial loss: 0.376840\n",
      "epoch 64; iter: 0; batch classifier loss: 0.111716; batch adversarial loss: 0.420417\n",
      "epoch 65; iter: 0; batch classifier loss: 0.054921; batch adversarial loss: 0.553270\n",
      "epoch 66; iter: 0; batch classifier loss: 0.080247; batch adversarial loss: 0.396119\n",
      "epoch 67; iter: 0; batch classifier loss: 0.067112; batch adversarial loss: 0.431829\n",
      "epoch 68; iter: 0; batch classifier loss: 0.064500; batch adversarial loss: 0.530054\n",
      "epoch 69; iter: 0; batch classifier loss: 0.130877; batch adversarial loss: 0.380256\n",
      "epoch 70; iter: 0; batch classifier loss: 0.029152; batch adversarial loss: 0.486687\n",
      "epoch 71; iter: 0; batch classifier loss: 0.075387; batch adversarial loss: 0.415370\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054466; batch adversarial loss: 0.493818\n",
      "epoch 73; iter: 0; batch classifier loss: 0.100955; batch adversarial loss: 0.410624\n",
      "epoch 74; iter: 0; batch classifier loss: 0.083377; batch adversarial loss: 0.373237\n",
      "epoch 75; iter: 0; batch classifier loss: 0.082243; batch adversarial loss: 0.480734\n",
      "epoch 76; iter: 0; batch classifier loss: 0.053908; batch adversarial loss: 0.477874\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050835; batch adversarial loss: 0.411377\n",
      "epoch 78; iter: 0; batch classifier loss: 0.078408; batch adversarial loss: 0.427091\n",
      "epoch 79; iter: 0; batch classifier loss: 0.066060; batch adversarial loss: 0.493536\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076685; batch adversarial loss: 0.488878\n",
      "epoch 81; iter: 0; batch classifier loss: 0.040536; batch adversarial loss: 0.379743\n",
      "epoch 82; iter: 0; batch classifier loss: 0.047278; batch adversarial loss: 0.390367\n",
      "epoch 83; iter: 0; batch classifier loss: 0.033298; batch adversarial loss: 0.468397\n",
      "epoch 84; iter: 0; batch classifier loss: 0.041526; batch adversarial loss: 0.320972\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051692; batch adversarial loss: 0.515331\n",
      "epoch 86; iter: 0; batch classifier loss: 0.055209; batch adversarial loss: 0.407056\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059555; batch adversarial loss: 0.376852\n",
      "epoch 88; iter: 0; batch classifier loss: 0.105286; batch adversarial loss: 0.393372\n",
      "epoch 89; iter: 0; batch classifier loss: 0.028791; batch adversarial loss: 0.458235\n",
      "epoch 90; iter: 0; batch classifier loss: 0.095898; batch adversarial loss: 0.543246\n",
      "epoch 91; iter: 0; batch classifier loss: 0.035123; batch adversarial loss: 0.424659\n",
      "epoch 92; iter: 0; batch classifier loss: 0.089792; batch adversarial loss: 0.356926\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064992; batch adversarial loss: 0.490167\n",
      "epoch 94; iter: 0; batch classifier loss: 0.045316; batch adversarial loss: 0.406769\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065347; batch adversarial loss: 0.450445\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045155; batch adversarial loss: 0.522854\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076066; batch adversarial loss: 0.402286\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059901; batch adversarial loss: 0.463468\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054111; batch adversarial loss: 0.533917\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034279; batch adversarial loss: 0.473081\n",
      "epoch 101; iter: 0; batch classifier loss: 0.038811; batch adversarial loss: 0.373657\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060202; batch adversarial loss: 0.462419\n",
      "epoch 103; iter: 0; batch classifier loss: 0.014042; batch adversarial loss: 0.506757\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057064; batch adversarial loss: 0.423261\n",
      "epoch 105; iter: 0; batch classifier loss: 0.024629; batch adversarial loss: 0.493970\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043526; batch adversarial loss: 0.474587\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058423; batch adversarial loss: 0.430152\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024846; batch adversarial loss: 0.396442\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030547; batch adversarial loss: 0.366102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.017854; batch adversarial loss: 0.461384\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036444; batch adversarial loss: 0.442328\n",
      "epoch 112; iter: 0; batch classifier loss: 0.021168; batch adversarial loss: 0.415903\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040339; batch adversarial loss: 0.390842\n",
      "epoch 114; iter: 0; batch classifier loss: 0.023088; batch adversarial loss: 0.536953\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038697; batch adversarial loss: 0.471597\n",
      "epoch 116; iter: 0; batch classifier loss: 0.019308; batch adversarial loss: 0.471792\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047586; batch adversarial loss: 0.446343\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041112; batch adversarial loss: 0.511564\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065915; batch adversarial loss: 0.414931\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039861; batch adversarial loss: 0.425018\n",
      "epoch 121; iter: 0; batch classifier loss: 0.016985; batch adversarial loss: 0.410772\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037403; batch adversarial loss: 0.439534\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037721; batch adversarial loss: 0.534682\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030375; batch adversarial loss: 0.498818\n",
      "epoch 125; iter: 0; batch classifier loss: 0.093259; batch adversarial loss: 0.382500\n",
      "epoch 126; iter: 0; batch classifier loss: 0.041865; batch adversarial loss: 0.390631\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051443; batch adversarial loss: 0.387944\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024442; batch adversarial loss: 0.427929\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022160; batch adversarial loss: 0.429742\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044939; batch adversarial loss: 0.461087\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039592; batch adversarial loss: 0.548503\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020387; batch adversarial loss: 0.433918\n",
      "epoch 133; iter: 0; batch classifier loss: 0.012718; batch adversarial loss: 0.476086\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037685; batch adversarial loss: 0.527143\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038113; batch adversarial loss: 0.542231\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018400; batch adversarial loss: 0.446668\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015083; batch adversarial loss: 0.410384\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023210; batch adversarial loss: 0.431832\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021235; batch adversarial loss: 0.569216\n",
      "epoch 140; iter: 0; batch classifier loss: 0.016975; batch adversarial loss: 0.600591\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045662; batch adversarial loss: 0.564545\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035409; batch adversarial loss: 0.532339\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022484; batch adversarial loss: 0.470204\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016781; batch adversarial loss: 0.432345\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034368; batch adversarial loss: 0.470160\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022881; batch adversarial loss: 0.477944\n",
      "epoch 147; iter: 0; batch classifier loss: 0.049562; batch adversarial loss: 0.453895\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018686; batch adversarial loss: 0.480053\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015131; batch adversarial loss: 0.506375\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013325; batch adversarial loss: 0.443435\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030232; batch adversarial loss: 0.391206\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037810; batch adversarial loss: 0.449741\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013641; batch adversarial loss: 0.406981\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030809; batch adversarial loss: 0.394828\n",
      "epoch 155; iter: 0; batch classifier loss: 0.060903; batch adversarial loss: 0.427333\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012727; batch adversarial loss: 0.470503\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046970; batch adversarial loss: 0.490310\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013287; batch adversarial loss: 0.415915\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013554; batch adversarial loss: 0.447876\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012273; batch adversarial loss: 0.455036\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020206; batch adversarial loss: 0.333420\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017005; batch adversarial loss: 0.417503\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014927; batch adversarial loss: 0.503697\n",
      "epoch 164; iter: 0; batch classifier loss: 0.103638; batch adversarial loss: 0.328144\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031126; batch adversarial loss: 0.457601\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010161; batch adversarial loss: 0.456185\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016048; batch adversarial loss: 0.575431\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019376; batch adversarial loss: 0.565530\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022025; batch adversarial loss: 0.413402\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009029; batch adversarial loss: 0.460696\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022494; batch adversarial loss: 0.427504\n",
      "epoch 172; iter: 0; batch classifier loss: 0.038634; batch adversarial loss: 0.495487\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014914; batch adversarial loss: 0.565586\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026705; batch adversarial loss: 0.505123\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011423; batch adversarial loss: 0.488108\n",
      "epoch 176; iter: 0; batch classifier loss: 0.044801; batch adversarial loss: 0.426302\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015044; batch adversarial loss: 0.497920\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016434; batch adversarial loss: 0.458316\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037231; batch adversarial loss: 0.398143\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023757; batch adversarial loss: 0.440073\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013692; batch adversarial loss: 0.443170\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014627; batch adversarial loss: 0.405801\n",
      "epoch 183; iter: 0; batch classifier loss: 0.080322; batch adversarial loss: 0.443349\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035141; batch adversarial loss: 0.356735\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015560; batch adversarial loss: 0.397502\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008988; batch adversarial loss: 0.590268\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015360; batch adversarial loss: 0.417476\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023199; batch adversarial loss: 0.480688\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017183; batch adversarial loss: 0.361155\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019790; batch adversarial loss: 0.515515\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016949; batch adversarial loss: 0.466221\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010030; batch adversarial loss: 0.475079\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008870; batch adversarial loss: 0.460129\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025337; batch adversarial loss: 0.485091\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012933; batch adversarial loss: 0.474604\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008181; batch adversarial loss: 0.456558\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006673; batch adversarial loss: 0.526790\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006422; batch adversarial loss: 0.446456\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009631; batch adversarial loss: 0.490504\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692273; batch adversarial loss: 0.890379\n",
      "epoch 1; iter: 0; batch classifier loss: 0.344301; batch adversarial loss: 0.884749\n",
      "epoch 2; iter: 0; batch classifier loss: 0.355515; batch adversarial loss: 0.810106\n",
      "epoch 3; iter: 0; batch classifier loss: 0.390705; batch adversarial loss: 0.752252\n",
      "epoch 4; iter: 0; batch classifier loss: 0.279091; batch adversarial loss: 0.722462\n",
      "epoch 5; iter: 0; batch classifier loss: 0.316319; batch adversarial loss: 0.678939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.311366; batch adversarial loss: 0.631900\n",
      "epoch 7; iter: 0; batch classifier loss: 0.292191; batch adversarial loss: 0.616727\n",
      "epoch 8; iter: 0; batch classifier loss: 0.314328; batch adversarial loss: 0.607790\n",
      "epoch 9; iter: 0; batch classifier loss: 0.276042; batch adversarial loss: 0.565578\n",
      "epoch 10; iter: 0; batch classifier loss: 0.232438; batch adversarial loss: 0.544303\n",
      "epoch 11; iter: 0; batch classifier loss: 0.283115; batch adversarial loss: 0.531456\n",
      "epoch 12; iter: 0; batch classifier loss: 0.244078; batch adversarial loss: 0.513753\n",
      "epoch 13; iter: 0; batch classifier loss: 0.266750; batch adversarial loss: 0.499487\n",
      "epoch 14; iter: 0; batch classifier loss: 0.225399; batch adversarial loss: 0.525246\n",
      "epoch 15; iter: 0; batch classifier loss: 0.276174; batch adversarial loss: 0.486825\n",
      "epoch 16; iter: 0; batch classifier loss: 0.252234; batch adversarial loss: 0.423547\n",
      "epoch 17; iter: 0; batch classifier loss: 0.226987; batch adversarial loss: 0.421634\n",
      "epoch 18; iter: 0; batch classifier loss: 0.249109; batch adversarial loss: 0.499685\n",
      "epoch 19; iter: 0; batch classifier loss: 0.155079; batch adversarial loss: 0.476547\n",
      "epoch 20; iter: 0; batch classifier loss: 0.212978; batch adversarial loss: 0.410719\n",
      "epoch 21; iter: 0; batch classifier loss: 0.257045; batch adversarial loss: 0.447331\n",
      "epoch 22; iter: 0; batch classifier loss: 0.205461; batch adversarial loss: 0.433056\n",
      "epoch 23; iter: 0; batch classifier loss: 0.207097; batch adversarial loss: 0.439669\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192123; batch adversarial loss: 0.440752\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177274; batch adversarial loss: 0.460190\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223615; batch adversarial loss: 0.492409\n",
      "epoch 27; iter: 0; batch classifier loss: 0.214948; batch adversarial loss: 0.442422\n",
      "epoch 28; iter: 0; batch classifier loss: 0.129497; batch adversarial loss: 0.409915\n",
      "epoch 29; iter: 0; batch classifier loss: 0.235265; batch adversarial loss: 0.394911\n",
      "epoch 30; iter: 0; batch classifier loss: 0.148918; batch adversarial loss: 0.409203\n",
      "epoch 31; iter: 0; batch classifier loss: 0.119389; batch adversarial loss: 0.410799\n",
      "epoch 32; iter: 0; batch classifier loss: 0.175028; batch adversarial loss: 0.377914\n",
      "epoch 33; iter: 0; batch classifier loss: 0.168352; batch adversarial loss: 0.372450\n",
      "epoch 34; iter: 0; batch classifier loss: 0.183033; batch adversarial loss: 0.371789\n",
      "epoch 35; iter: 0; batch classifier loss: 0.172841; batch adversarial loss: 0.372460\n",
      "epoch 36; iter: 0; batch classifier loss: 0.136437; batch adversarial loss: 0.344735\n",
      "epoch 37; iter: 0; batch classifier loss: 0.222474; batch adversarial loss: 0.466906\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122167; batch adversarial loss: 0.410404\n",
      "epoch 39; iter: 0; batch classifier loss: 0.169389; batch adversarial loss: 0.443765\n",
      "epoch 40; iter: 0; batch classifier loss: 0.109275; batch adversarial loss: 0.361843\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146154; batch adversarial loss: 0.389360\n",
      "epoch 42; iter: 0; batch classifier loss: 0.125598; batch adversarial loss: 0.412768\n",
      "epoch 43; iter: 0; batch classifier loss: 0.137274; batch adversarial loss: 0.333893\n",
      "epoch 44; iter: 0; batch classifier loss: 0.093080; batch adversarial loss: 0.412707\n",
      "epoch 45; iter: 0; batch classifier loss: 0.137489; batch adversarial loss: 0.403127\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104901; batch adversarial loss: 0.430852\n",
      "epoch 47; iter: 0; batch classifier loss: 0.099206; batch adversarial loss: 0.397559\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092874; batch adversarial loss: 0.410469\n",
      "epoch 49; iter: 0; batch classifier loss: 0.093969; batch adversarial loss: 0.428255\n",
      "epoch 50; iter: 0; batch classifier loss: 0.099225; batch adversarial loss: 0.457711\n",
      "epoch 51; iter: 0; batch classifier loss: 0.085145; batch adversarial loss: 0.448446\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112595; batch adversarial loss: 0.476772\n",
      "epoch 53; iter: 0; batch classifier loss: 0.092352; batch adversarial loss: 0.404535\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122876; batch adversarial loss: 0.386429\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098854; batch adversarial loss: 0.472941\n",
      "epoch 56; iter: 0; batch classifier loss: 0.090837; batch adversarial loss: 0.437965\n",
      "epoch 57; iter: 0; batch classifier loss: 0.065041; batch adversarial loss: 0.420135\n",
      "epoch 58; iter: 0; batch classifier loss: 0.085221; batch adversarial loss: 0.346355\n",
      "epoch 59; iter: 0; batch classifier loss: 0.068731; batch adversarial loss: 0.394683\n",
      "epoch 60; iter: 0; batch classifier loss: 0.078555; batch adversarial loss: 0.397546\n",
      "epoch 61; iter: 0; batch classifier loss: 0.085362; batch adversarial loss: 0.353582\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081656; batch adversarial loss: 0.426041\n",
      "epoch 63; iter: 0; batch classifier loss: 0.125926; batch adversarial loss: 0.412205\n",
      "epoch 64; iter: 0; batch classifier loss: 0.130748; batch adversarial loss: 0.506021\n",
      "epoch 65; iter: 0; batch classifier loss: 0.103287; batch adversarial loss: 0.482412\n",
      "epoch 66; iter: 0; batch classifier loss: 0.056677; batch adversarial loss: 0.384631\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100064; batch adversarial loss: 0.439854\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076177; batch adversarial loss: 0.445061\n",
      "epoch 69; iter: 0; batch classifier loss: 0.058732; batch adversarial loss: 0.443286\n",
      "epoch 70; iter: 0; batch classifier loss: 0.083957; batch adversarial loss: 0.466005\n",
      "epoch 71; iter: 0; batch classifier loss: 0.131188; batch adversarial loss: 0.408613\n",
      "epoch 72; iter: 0; batch classifier loss: 0.089074; batch adversarial loss: 0.376681\n",
      "epoch 73; iter: 0; batch classifier loss: 0.071165; batch adversarial loss: 0.457152\n",
      "epoch 74; iter: 0; batch classifier loss: 0.086305; batch adversarial loss: 0.339267\n",
      "epoch 75; iter: 0; batch classifier loss: 0.092358; batch adversarial loss: 0.321792\n",
      "epoch 76; iter: 0; batch classifier loss: 0.111095; batch adversarial loss: 0.439962\n",
      "epoch 77; iter: 0; batch classifier loss: 0.078332; batch adversarial loss: 0.397641\n",
      "epoch 78; iter: 0; batch classifier loss: 0.058921; batch adversarial loss: 0.415938\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074852; batch adversarial loss: 0.415120\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088700; batch adversarial loss: 0.509745\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067894; batch adversarial loss: 0.390113\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052986; batch adversarial loss: 0.430420\n",
      "epoch 83; iter: 0; batch classifier loss: 0.075114; batch adversarial loss: 0.404963\n",
      "epoch 84; iter: 0; batch classifier loss: 0.054457; batch adversarial loss: 0.374980\n",
      "epoch 85; iter: 0; batch classifier loss: 0.086829; batch adversarial loss: 0.495971\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066057; batch adversarial loss: 0.433381\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057888; batch adversarial loss: 0.389536\n",
      "epoch 88; iter: 0; batch classifier loss: 0.074528; batch adversarial loss: 0.393205\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080639; batch adversarial loss: 0.417967\n",
      "epoch 90; iter: 0; batch classifier loss: 0.092651; batch adversarial loss: 0.466103\n",
      "epoch 91; iter: 0; batch classifier loss: 0.078314; batch adversarial loss: 0.396051\n",
      "epoch 92; iter: 0; batch classifier loss: 0.080818; batch adversarial loss: 0.430624\n",
      "epoch 93; iter: 0; batch classifier loss: 0.123008; batch adversarial loss: 0.483085\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067520; batch adversarial loss: 0.418142\n",
      "epoch 95; iter: 0; batch classifier loss: 0.105803; batch adversarial loss: 0.402845\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045262; batch adversarial loss: 0.404431\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057288; batch adversarial loss: 0.318626\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054138; batch adversarial loss: 0.457072\n",
      "epoch 99; iter: 0; batch classifier loss: 0.068668; batch adversarial loss: 0.508017\n",
      "epoch 100; iter: 0; batch classifier loss: 0.087386; batch adversarial loss: 0.422645\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075762; batch adversarial loss: 0.337792\n",
      "epoch 102; iter: 0; batch classifier loss: 0.086044; batch adversarial loss: 0.411775\n",
      "epoch 103; iter: 0; batch classifier loss: 0.085727; batch adversarial loss: 0.476835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.076691; batch adversarial loss: 0.397149\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051087; batch adversarial loss: 0.374644\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058796; batch adversarial loss: 0.481435\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059923; batch adversarial loss: 0.363281\n",
      "epoch 108; iter: 0; batch classifier loss: 0.062472; batch adversarial loss: 0.508889\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049008; batch adversarial loss: 0.294160\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066405; batch adversarial loss: 0.452899\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060716; batch adversarial loss: 0.431074\n",
      "epoch 112; iter: 0; batch classifier loss: 0.087496; batch adversarial loss: 0.486314\n",
      "epoch 113; iter: 0; batch classifier loss: 0.091572; batch adversarial loss: 0.507331\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048278; batch adversarial loss: 0.525088\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040969; batch adversarial loss: 0.444217\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041478; batch adversarial loss: 0.364295\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048764; batch adversarial loss: 0.466446\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057279; batch adversarial loss: 0.462116\n",
      "epoch 119; iter: 0; batch classifier loss: 0.058388; batch adversarial loss: 0.406617\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040826; batch adversarial loss: 0.436895\n",
      "epoch 121; iter: 0; batch classifier loss: 0.076594; batch adversarial loss: 0.548413\n",
      "epoch 122; iter: 0; batch classifier loss: 0.085551; batch adversarial loss: 0.387251\n",
      "epoch 123; iter: 0; batch classifier loss: 0.062724; batch adversarial loss: 0.431518\n",
      "epoch 124; iter: 0; batch classifier loss: 0.099440; batch adversarial loss: 0.413534\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053038; batch adversarial loss: 0.426150\n",
      "epoch 126; iter: 0; batch classifier loss: 0.099103; batch adversarial loss: 0.523165\n",
      "epoch 127; iter: 0; batch classifier loss: 0.086494; batch adversarial loss: 0.445187\n",
      "epoch 128; iter: 0; batch classifier loss: 0.068881; batch adversarial loss: 0.437081\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050963; batch adversarial loss: 0.352672\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057566; batch adversarial loss: 0.293809\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044632; batch adversarial loss: 0.403462\n",
      "epoch 132; iter: 0; batch classifier loss: 0.094958; batch adversarial loss: 0.516785\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048848; batch adversarial loss: 0.331660\n",
      "epoch 134; iter: 0; batch classifier loss: 0.072039; batch adversarial loss: 0.400531\n",
      "epoch 135; iter: 0; batch classifier loss: 0.052190; batch adversarial loss: 0.503203\n",
      "epoch 136; iter: 0; batch classifier loss: 0.052596; batch adversarial loss: 0.440695\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048518; batch adversarial loss: 0.354447\n",
      "epoch 138; iter: 0; batch classifier loss: 0.051599; batch adversarial loss: 0.421396\n",
      "epoch 139; iter: 0; batch classifier loss: 0.074072; batch adversarial loss: 0.488978\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030959; batch adversarial loss: 0.397543\n",
      "epoch 141; iter: 0; batch classifier loss: 0.060627; batch adversarial loss: 0.330215\n",
      "epoch 142; iter: 0; batch classifier loss: 0.080088; batch adversarial loss: 0.376269\n",
      "epoch 143; iter: 0; batch classifier loss: 0.062243; batch adversarial loss: 0.444034\n",
      "epoch 144; iter: 0; batch classifier loss: 0.060832; batch adversarial loss: 0.407618\n",
      "epoch 145; iter: 0; batch classifier loss: 0.057451; batch adversarial loss: 0.447925\n",
      "epoch 146; iter: 0; batch classifier loss: 0.070856; batch adversarial loss: 0.444695\n",
      "epoch 147; iter: 0; batch classifier loss: 0.055339; batch adversarial loss: 0.444590\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038387; batch adversarial loss: 0.472416\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026217; batch adversarial loss: 0.387182\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042577; batch adversarial loss: 0.496581\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042608; batch adversarial loss: 0.401339\n",
      "epoch 152; iter: 0; batch classifier loss: 0.050284; batch adversarial loss: 0.380104\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040640; batch adversarial loss: 0.471926\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035845; batch adversarial loss: 0.471440\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020421; batch adversarial loss: 0.435237\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020723; batch adversarial loss: 0.445683\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037707; batch adversarial loss: 0.388929\n",
      "epoch 158; iter: 0; batch classifier loss: 0.055740; batch adversarial loss: 0.320537\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039251; batch adversarial loss: 0.423096\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022455; batch adversarial loss: 0.407282\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037559; batch adversarial loss: 0.405114\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014661; batch adversarial loss: 0.440690\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024152; batch adversarial loss: 0.420071\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029268; batch adversarial loss: 0.512445\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041886; batch adversarial loss: 0.438656\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035824; batch adversarial loss: 0.399101\n",
      "epoch 167; iter: 0; batch classifier loss: 0.040032; batch adversarial loss: 0.434824\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038867; batch adversarial loss: 0.532764\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025048; batch adversarial loss: 0.440461\n",
      "epoch 170; iter: 0; batch classifier loss: 0.052978; batch adversarial loss: 0.420478\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026908; batch adversarial loss: 0.466630\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017534; batch adversarial loss: 0.392731\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028823; batch adversarial loss: 0.508326\n",
      "epoch 174; iter: 0; batch classifier loss: 0.049515; batch adversarial loss: 0.482735\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033158; batch adversarial loss: 0.479323\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012446; batch adversarial loss: 0.405905\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033063; batch adversarial loss: 0.467008\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015071; batch adversarial loss: 0.486039\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032431; batch adversarial loss: 0.617871\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009388; batch adversarial loss: 0.514718\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032621; batch adversarial loss: 0.392590\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026858; batch adversarial loss: 0.444727\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028411; batch adversarial loss: 0.334106\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014354; batch adversarial loss: 0.368838\n",
      "epoch 185; iter: 0; batch classifier loss: 0.053550; batch adversarial loss: 0.388908\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033477; batch adversarial loss: 0.487209\n",
      "epoch 187; iter: 0; batch classifier loss: 0.046695; batch adversarial loss: 0.402124\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017452; batch adversarial loss: 0.455948\n",
      "epoch 189; iter: 0; batch classifier loss: 0.055539; batch adversarial loss: 0.487012\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027651; batch adversarial loss: 0.446552\n",
      "epoch 191; iter: 0; batch classifier loss: 0.044487; batch adversarial loss: 0.419979\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040331; batch adversarial loss: 0.415816\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006429; batch adversarial loss: 0.447727\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018159; batch adversarial loss: 0.490568\n",
      "epoch 195; iter: 0; batch classifier loss: 0.042029; batch adversarial loss: 0.507477\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026260; batch adversarial loss: 0.448455\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024980; batch adversarial loss: 0.350099\n",
      "epoch 198; iter: 0; batch classifier loss: 0.056864; batch adversarial loss: 0.525228\n",
      "epoch 199; iter: 0; batch classifier loss: 0.049081; batch adversarial loss: 0.546992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.700702; batch adversarial loss: 0.577899\n",
      "epoch 1; iter: 0; batch classifier loss: 0.351734; batch adversarial loss: 0.606581\n",
      "epoch 2; iter: 0; batch classifier loss: 0.343407; batch adversarial loss: 0.609567\n",
      "epoch 3; iter: 0; batch classifier loss: 0.380391; batch adversarial loss: 0.582465\n",
      "epoch 4; iter: 0; batch classifier loss: 0.374220; batch adversarial loss: 0.596782\n",
      "epoch 5; iter: 0; batch classifier loss: 0.445987; batch adversarial loss: 0.577745\n",
      "epoch 6; iter: 0; batch classifier loss: 0.400292; batch adversarial loss: 0.599606\n",
      "epoch 7; iter: 0; batch classifier loss: 0.392018; batch adversarial loss: 0.603674\n",
      "epoch 8; iter: 0; batch classifier loss: 0.613529; batch adversarial loss: 0.532982\n",
      "epoch 9; iter: 0; batch classifier loss: 0.603490; batch adversarial loss: 0.532706\n",
      "epoch 10; iter: 0; batch classifier loss: 0.615665; batch adversarial loss: 0.592132\n",
      "epoch 11; iter: 0; batch classifier loss: 0.454993; batch adversarial loss: 0.597703\n",
      "epoch 12; iter: 0; batch classifier loss: 0.392369; batch adversarial loss: 0.537786\n",
      "epoch 13; iter: 0; batch classifier loss: 0.389792; batch adversarial loss: 0.440262\n",
      "epoch 14; iter: 0; batch classifier loss: 0.319749; batch adversarial loss: 0.497642\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274232; batch adversarial loss: 0.484454\n",
      "epoch 16; iter: 0; batch classifier loss: 0.259197; batch adversarial loss: 0.496734\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221099; batch adversarial loss: 0.461812\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251629; batch adversarial loss: 0.426982\n",
      "epoch 19; iter: 0; batch classifier loss: 0.305200; batch adversarial loss: 0.484754\n",
      "epoch 20; iter: 0; batch classifier loss: 0.213331; batch adversarial loss: 0.420533\n",
      "epoch 21; iter: 0; batch classifier loss: 0.155028; batch adversarial loss: 0.488166\n",
      "epoch 22; iter: 0; batch classifier loss: 0.208272; batch adversarial loss: 0.451667\n",
      "epoch 23; iter: 0; batch classifier loss: 0.228212; batch adversarial loss: 0.498011\n",
      "epoch 24; iter: 0; batch classifier loss: 0.205334; batch adversarial loss: 0.356835\n",
      "epoch 25; iter: 0; batch classifier loss: 0.186434; batch adversarial loss: 0.460566\n",
      "epoch 26; iter: 0; batch classifier loss: 0.198462; batch adversarial loss: 0.514839\n",
      "epoch 27; iter: 0; batch classifier loss: 0.173389; batch adversarial loss: 0.455961\n",
      "epoch 28; iter: 0; batch classifier loss: 0.209571; batch adversarial loss: 0.440882\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170255; batch adversarial loss: 0.446621\n",
      "epoch 30; iter: 0; batch classifier loss: 0.149606; batch adversarial loss: 0.475993\n",
      "epoch 31; iter: 0; batch classifier loss: 0.199704; batch adversarial loss: 0.527855\n",
      "epoch 32; iter: 0; batch classifier loss: 0.204382; batch adversarial loss: 0.476999\n",
      "epoch 33; iter: 0; batch classifier loss: 0.214285; batch adversarial loss: 0.424317\n",
      "epoch 34; iter: 0; batch classifier loss: 0.158958; batch adversarial loss: 0.373419\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140921; batch adversarial loss: 0.468532\n",
      "epoch 36; iter: 0; batch classifier loss: 0.171837; batch adversarial loss: 0.425226\n",
      "epoch 37; iter: 0; batch classifier loss: 0.160712; batch adversarial loss: 0.415034\n",
      "epoch 38; iter: 0; batch classifier loss: 0.161645; batch adversarial loss: 0.449995\n",
      "epoch 39; iter: 0; batch classifier loss: 0.124899; batch adversarial loss: 0.473607\n",
      "epoch 40; iter: 0; batch classifier loss: 0.180752; batch adversarial loss: 0.496144\n",
      "epoch 41; iter: 0; batch classifier loss: 0.136323; batch adversarial loss: 0.426664\n",
      "epoch 42; iter: 0; batch classifier loss: 0.127264; batch adversarial loss: 0.401190\n",
      "epoch 43; iter: 0; batch classifier loss: 0.132729; batch adversarial loss: 0.439886\n",
      "epoch 44; iter: 0; batch classifier loss: 0.137786; batch adversarial loss: 0.513984\n",
      "epoch 45; iter: 0; batch classifier loss: 0.149970; batch adversarial loss: 0.512031\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116270; batch adversarial loss: 0.452915\n",
      "epoch 47; iter: 0; batch classifier loss: 0.149331; batch adversarial loss: 0.496518\n",
      "epoch 48; iter: 0; batch classifier loss: 0.132043; batch adversarial loss: 0.341654\n",
      "epoch 49; iter: 0; batch classifier loss: 0.164203; batch adversarial loss: 0.432620\n",
      "epoch 50; iter: 0; batch classifier loss: 0.132263; batch adversarial loss: 0.445620\n",
      "epoch 51; iter: 0; batch classifier loss: 0.139302; batch adversarial loss: 0.463017\n",
      "epoch 52; iter: 0; batch classifier loss: 0.113948; batch adversarial loss: 0.463823\n",
      "epoch 53; iter: 0; batch classifier loss: 0.123127; batch adversarial loss: 0.533864\n",
      "epoch 54; iter: 0; batch classifier loss: 0.168474; batch adversarial loss: 0.468543\n",
      "epoch 55; iter: 0; batch classifier loss: 0.115674; batch adversarial loss: 0.488248\n",
      "epoch 56; iter: 0; batch classifier loss: 0.185081; batch adversarial loss: 0.471107\n",
      "epoch 57; iter: 0; batch classifier loss: 0.134051; batch adversarial loss: 0.415242\n",
      "epoch 58; iter: 0; batch classifier loss: 0.164984; batch adversarial loss: 0.572623\n",
      "epoch 59; iter: 0; batch classifier loss: 0.107546; batch adversarial loss: 0.388338\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105366; batch adversarial loss: 0.465823\n",
      "epoch 61; iter: 0; batch classifier loss: 0.132855; batch adversarial loss: 0.418824\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104620; batch adversarial loss: 0.490689\n",
      "epoch 63; iter: 0; batch classifier loss: 0.107964; batch adversarial loss: 0.474512\n",
      "epoch 64; iter: 0; batch classifier loss: 0.178286; batch adversarial loss: 0.513425\n",
      "epoch 65; iter: 0; batch classifier loss: 0.133986; batch adversarial loss: 0.527918\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073433; batch adversarial loss: 0.565504\n",
      "epoch 67; iter: 0; batch classifier loss: 0.143424; batch adversarial loss: 0.373250\n",
      "epoch 68; iter: 0; batch classifier loss: 0.103283; batch adversarial loss: 0.457234\n",
      "epoch 69; iter: 0; batch classifier loss: 0.121035; batch adversarial loss: 0.433577\n",
      "epoch 70; iter: 0; batch classifier loss: 0.125173; batch adversarial loss: 0.394306\n",
      "epoch 71; iter: 0; batch classifier loss: 0.186068; batch adversarial loss: 0.509170\n",
      "epoch 72; iter: 0; batch classifier loss: 0.083344; batch adversarial loss: 0.534120\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077726; batch adversarial loss: 0.453491\n",
      "epoch 74; iter: 0; batch classifier loss: 0.111165; batch adversarial loss: 0.426496\n",
      "epoch 75; iter: 0; batch classifier loss: 0.123981; batch adversarial loss: 0.525958\n",
      "epoch 76; iter: 0; batch classifier loss: 0.126130; batch adversarial loss: 0.425440\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090578; batch adversarial loss: 0.442152\n",
      "epoch 78; iter: 0; batch classifier loss: 0.070991; batch adversarial loss: 0.492772\n",
      "epoch 79; iter: 0; batch classifier loss: 0.130931; batch adversarial loss: 0.445636\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088613; batch adversarial loss: 0.449876\n",
      "epoch 81; iter: 0; batch classifier loss: 0.124359; batch adversarial loss: 0.416896\n",
      "epoch 82; iter: 0; batch classifier loss: 0.131007; batch adversarial loss: 0.380996\n",
      "epoch 83; iter: 0; batch classifier loss: 0.117832; batch adversarial loss: 0.418208\n",
      "epoch 84; iter: 0; batch classifier loss: 0.078387; batch adversarial loss: 0.488631\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080365; batch adversarial loss: 0.481923\n",
      "epoch 86; iter: 0; batch classifier loss: 0.094669; batch adversarial loss: 0.502246\n",
      "epoch 87; iter: 0; batch classifier loss: 0.081062; batch adversarial loss: 0.456830\n",
      "epoch 88; iter: 0; batch classifier loss: 0.093932; batch adversarial loss: 0.382605\n",
      "epoch 89; iter: 0; batch classifier loss: 0.126659; batch adversarial loss: 0.424407\n",
      "epoch 90; iter: 0; batch classifier loss: 0.109356; batch adversarial loss: 0.466184\n",
      "epoch 91; iter: 0; batch classifier loss: 0.107051; batch adversarial loss: 0.507734\n",
      "epoch 92; iter: 0; batch classifier loss: 0.120922; batch adversarial loss: 0.375553\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064667; batch adversarial loss: 0.381631\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072348; batch adversarial loss: 0.470745\n",
      "epoch 95; iter: 0; batch classifier loss: 0.085077; batch adversarial loss: 0.477027\n",
      "epoch 96; iter: 0; batch classifier loss: 0.101711; batch adversarial loss: 0.423039\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070260; batch adversarial loss: 0.441342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.063567; batch adversarial loss: 0.447003\n",
      "epoch 99; iter: 0; batch classifier loss: 0.136721; batch adversarial loss: 0.414128\n",
      "epoch 100; iter: 0; batch classifier loss: 0.098804; batch adversarial loss: 0.452267\n",
      "epoch 101; iter: 0; batch classifier loss: 0.119549; batch adversarial loss: 0.482747\n",
      "epoch 102; iter: 0; batch classifier loss: 0.064240; batch adversarial loss: 0.434290\n",
      "epoch 103; iter: 0; batch classifier loss: 0.067384; batch adversarial loss: 0.478009\n",
      "epoch 104; iter: 0; batch classifier loss: 0.087710; batch adversarial loss: 0.413520\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037414; batch adversarial loss: 0.558569\n",
      "epoch 106; iter: 0; batch classifier loss: 0.087888; batch adversarial loss: 0.372584\n",
      "epoch 107; iter: 0; batch classifier loss: 0.078681; batch adversarial loss: 0.438136\n",
      "epoch 108; iter: 0; batch classifier loss: 0.080047; batch adversarial loss: 0.399319\n",
      "epoch 109; iter: 0; batch classifier loss: 0.102636; batch adversarial loss: 0.428561\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066170; batch adversarial loss: 0.432047\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044251; batch adversarial loss: 0.448881\n",
      "epoch 112; iter: 0; batch classifier loss: 0.028373; batch adversarial loss: 0.416712\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045951; batch adversarial loss: 0.426622\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046180; batch adversarial loss: 0.502187\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040060; batch adversarial loss: 0.526654\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041526; batch adversarial loss: 0.429743\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046237; batch adversarial loss: 0.412364\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051729; batch adversarial loss: 0.333512\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030122; batch adversarial loss: 0.524575\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038496; batch adversarial loss: 0.451808\n",
      "epoch 121; iter: 0; batch classifier loss: 0.067615; batch adversarial loss: 0.515859\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032046; batch adversarial loss: 0.458023\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024599; batch adversarial loss: 0.496702\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059547; batch adversarial loss: 0.458113\n",
      "epoch 125; iter: 0; batch classifier loss: 0.074600; batch adversarial loss: 0.513131\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037514; batch adversarial loss: 0.460449\n",
      "epoch 127; iter: 0; batch classifier loss: 0.064755; batch adversarial loss: 0.403704\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042461; batch adversarial loss: 0.417200\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036330; batch adversarial loss: 0.366026\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038041; batch adversarial loss: 0.427171\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026461; batch adversarial loss: 0.410162\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045968; batch adversarial loss: 0.346797\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055941; batch adversarial loss: 0.341044\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025971; batch adversarial loss: 0.464635\n",
      "epoch 135; iter: 0; batch classifier loss: 0.058132; batch adversarial loss: 0.648147\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036288; batch adversarial loss: 0.422907\n",
      "epoch 137; iter: 0; batch classifier loss: 0.078097; batch adversarial loss: 0.422025\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049992; batch adversarial loss: 0.413535\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036451; batch adversarial loss: 0.377280\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046266; batch adversarial loss: 0.435196\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049867; batch adversarial loss: 0.512129\n",
      "epoch 142; iter: 0; batch classifier loss: 0.062662; batch adversarial loss: 0.372760\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028012; batch adversarial loss: 0.486067\n",
      "epoch 144; iter: 0; batch classifier loss: 0.046005; batch adversarial loss: 0.428332\n",
      "epoch 145; iter: 0; batch classifier loss: 0.007057; batch adversarial loss: 0.444087\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010103; batch adversarial loss: 0.461434\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028909; batch adversarial loss: 0.571677\n",
      "epoch 148; iter: 0; batch classifier loss: 0.057432; batch adversarial loss: 0.477668\n",
      "epoch 149; iter: 0; batch classifier loss: 0.049848; batch adversarial loss: 0.596987\n",
      "epoch 150; iter: 0; batch classifier loss: 0.057219; batch adversarial loss: 0.420575\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041716; batch adversarial loss: 0.541639\n",
      "epoch 152; iter: 0; batch classifier loss: 0.055071; batch adversarial loss: 0.502101\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036380; batch adversarial loss: 0.391086\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018192; batch adversarial loss: 0.436341\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021526; batch adversarial loss: 0.443766\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028852; batch adversarial loss: 0.385024\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039815; batch adversarial loss: 0.374230\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009535; batch adversarial loss: 0.368085\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018636; batch adversarial loss: 0.399545\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025260; batch adversarial loss: 0.438504\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018985; batch adversarial loss: 0.457564\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025874; batch adversarial loss: 0.528410\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007598; batch adversarial loss: 0.476661\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026699; batch adversarial loss: 0.373077\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014504; batch adversarial loss: 0.392981\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028827; batch adversarial loss: 0.464724\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019534; batch adversarial loss: 0.497795\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010837; batch adversarial loss: 0.473444\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023887; batch adversarial loss: 0.380873\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021538; batch adversarial loss: 0.440179\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027097; batch adversarial loss: 0.381980\n",
      "epoch 172; iter: 0; batch classifier loss: 0.084303; batch adversarial loss: 0.504772\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027067; batch adversarial loss: 0.553173\n",
      "epoch 174; iter: 0; batch classifier loss: 0.042959; batch adversarial loss: 0.441472\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034650; batch adversarial loss: 0.319998\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031720; batch adversarial loss: 0.425847\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032116; batch adversarial loss: 0.429506\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026098; batch adversarial loss: 0.368219\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032514; batch adversarial loss: 0.434124\n",
      "epoch 180; iter: 0; batch classifier loss: 0.061775; batch adversarial loss: 0.534737\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018879; batch adversarial loss: 0.501381\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007405; batch adversarial loss: 0.424128\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016679; batch adversarial loss: 0.478698\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016994; batch adversarial loss: 0.467683\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017162; batch adversarial loss: 0.381354\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011193; batch adversarial loss: 0.396588\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017166; batch adversarial loss: 0.470958\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020928; batch adversarial loss: 0.399605\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026828; batch adversarial loss: 0.447982\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021685; batch adversarial loss: 0.322380\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033020; batch adversarial loss: 0.379908\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021387; batch adversarial loss: 0.384428\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016281; batch adversarial loss: 0.416619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.031430; batch adversarial loss: 0.420080\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009219; batch adversarial loss: 0.406387\n",
      "epoch 196; iter: 0; batch classifier loss: 0.035367; batch adversarial loss: 0.436020\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011462; batch adversarial loss: 0.459020\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004654; batch adversarial loss: 0.369492\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021161; batch adversarial loss: 0.521775\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709940; batch adversarial loss: 0.692050\n",
      "epoch 1; iter: 0; batch classifier loss: 0.554398; batch adversarial loss: 0.729066\n",
      "epoch 2; iter: 0; batch classifier loss: 0.460774; batch adversarial loss: 0.654677\n",
      "epoch 3; iter: 0; batch classifier loss: 0.367477; batch adversarial loss: 0.652699\n",
      "epoch 4; iter: 0; batch classifier loss: 0.356022; batch adversarial loss: 0.610241\n",
      "epoch 5; iter: 0; batch classifier loss: 0.354844; batch adversarial loss: 0.551033\n",
      "epoch 6; iter: 0; batch classifier loss: 0.301879; batch adversarial loss: 0.535084\n",
      "epoch 7; iter: 0; batch classifier loss: 0.293257; batch adversarial loss: 0.545855\n",
      "epoch 8; iter: 0; batch classifier loss: 0.244916; batch adversarial loss: 0.528956\n",
      "epoch 9; iter: 0; batch classifier loss: 0.255399; batch adversarial loss: 0.504216\n",
      "epoch 10; iter: 0; batch classifier loss: 0.250587; batch adversarial loss: 0.480955\n",
      "epoch 11; iter: 0; batch classifier loss: 0.225694; batch adversarial loss: 0.490673\n",
      "epoch 12; iter: 0; batch classifier loss: 0.233159; batch adversarial loss: 0.497771\n",
      "epoch 13; iter: 0; batch classifier loss: 0.195765; batch adversarial loss: 0.490141\n",
      "epoch 14; iter: 0; batch classifier loss: 0.185266; batch adversarial loss: 0.459653\n",
      "epoch 15; iter: 0; batch classifier loss: 0.163907; batch adversarial loss: 0.482347\n",
      "epoch 16; iter: 0; batch classifier loss: 0.171459; batch adversarial loss: 0.487192\n",
      "epoch 17; iter: 0; batch classifier loss: 0.149301; batch adversarial loss: 0.464454\n",
      "epoch 18; iter: 0; batch classifier loss: 0.153452; batch adversarial loss: 0.425921\n",
      "epoch 19; iter: 0; batch classifier loss: 0.130560; batch adversarial loss: 0.485111\n",
      "epoch 20; iter: 0; batch classifier loss: 0.189675; batch adversarial loss: 0.441766\n",
      "epoch 21; iter: 0; batch classifier loss: 0.134989; batch adversarial loss: 0.414359\n",
      "epoch 22; iter: 0; batch classifier loss: 0.120206; batch adversarial loss: 0.394816\n",
      "epoch 23; iter: 0; batch classifier loss: 0.085488; batch adversarial loss: 0.465697\n",
      "epoch 24; iter: 0; batch classifier loss: 0.120293; batch adversarial loss: 0.518551\n",
      "epoch 25; iter: 0; batch classifier loss: 0.109559; batch adversarial loss: 0.443260\n",
      "epoch 26; iter: 0; batch classifier loss: 0.099170; batch adversarial loss: 0.451976\n",
      "epoch 27; iter: 0; batch classifier loss: 0.129549; batch adversarial loss: 0.560641\n",
      "epoch 28; iter: 0; batch classifier loss: 0.100908; batch adversarial loss: 0.379917\n",
      "epoch 29; iter: 0; batch classifier loss: 0.103041; batch adversarial loss: 0.480052\n",
      "epoch 30; iter: 0; batch classifier loss: 0.088517; batch adversarial loss: 0.501423\n",
      "epoch 31; iter: 0; batch classifier loss: 0.143298; batch adversarial loss: 0.516713\n",
      "epoch 32; iter: 0; batch classifier loss: 0.134471; batch adversarial loss: 0.453906\n",
      "epoch 33; iter: 0; batch classifier loss: 0.125810; batch adversarial loss: 0.526406\n",
      "epoch 34; iter: 0; batch classifier loss: 0.172020; batch adversarial loss: 0.582399\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137479; batch adversarial loss: 0.536760\n",
      "epoch 36; iter: 0; batch classifier loss: 0.190682; batch adversarial loss: 0.544592\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132854; batch adversarial loss: 0.463993\n",
      "epoch 38; iter: 0; batch classifier loss: 0.145079; batch adversarial loss: 0.489335\n",
      "epoch 39; iter: 0; batch classifier loss: 0.127794; batch adversarial loss: 0.497214\n",
      "epoch 40; iter: 0; batch classifier loss: 0.181020; batch adversarial loss: 0.455255\n",
      "epoch 41; iter: 0; batch classifier loss: 0.130842; batch adversarial loss: 0.521980\n",
      "epoch 42; iter: 0; batch classifier loss: 0.158301; batch adversarial loss: 0.468283\n",
      "epoch 43; iter: 0; batch classifier loss: 0.175439; batch adversarial loss: 0.429599\n",
      "epoch 44; iter: 0; batch classifier loss: 0.182112; batch adversarial loss: 0.461062\n",
      "epoch 45; iter: 0; batch classifier loss: 0.232698; batch adversarial loss: 0.546849\n",
      "epoch 46; iter: 0; batch classifier loss: 0.097675; batch adversarial loss: 0.495083\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103841; batch adversarial loss: 0.482012\n",
      "epoch 48; iter: 0; batch classifier loss: 0.062764; batch adversarial loss: 0.519280\n",
      "epoch 49; iter: 0; batch classifier loss: 0.066517; batch adversarial loss: 0.464195\n",
      "epoch 50; iter: 0; batch classifier loss: 0.073041; batch adversarial loss: 0.491609\n",
      "epoch 51; iter: 0; batch classifier loss: 0.057498; batch adversarial loss: 0.519168\n",
      "epoch 52; iter: 0; batch classifier loss: 0.064352; batch adversarial loss: 0.455163\n",
      "epoch 53; iter: 0; batch classifier loss: 0.083592; batch adversarial loss: 0.502702\n",
      "epoch 54; iter: 0; batch classifier loss: 0.078327; batch adversarial loss: 0.394683\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089859; batch adversarial loss: 0.519570\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098176; batch adversarial loss: 0.388685\n",
      "epoch 57; iter: 0; batch classifier loss: 0.058805; batch adversarial loss: 0.402479\n",
      "epoch 58; iter: 0; batch classifier loss: 0.108505; batch adversarial loss: 0.458685\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082042; batch adversarial loss: 0.523194\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070548; batch adversarial loss: 0.428177\n",
      "epoch 61; iter: 0; batch classifier loss: 0.101138; batch adversarial loss: 0.541881\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108064; batch adversarial loss: 0.440075\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099283; batch adversarial loss: 0.395999\n",
      "epoch 64; iter: 0; batch classifier loss: 0.117443; batch adversarial loss: 0.513714\n",
      "epoch 65; iter: 0; batch classifier loss: 0.120081; batch adversarial loss: 0.554907\n",
      "epoch 66; iter: 0; batch classifier loss: 0.104230; batch adversarial loss: 0.422809\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106409; batch adversarial loss: 0.498367\n",
      "epoch 68; iter: 0; batch classifier loss: 0.148656; batch adversarial loss: 0.472749\n",
      "epoch 69; iter: 0; batch classifier loss: 0.062028; batch adversarial loss: 0.552214\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103872; batch adversarial loss: 0.488587\n",
      "epoch 71; iter: 0; batch classifier loss: 0.172602; batch adversarial loss: 0.372822\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087030; batch adversarial loss: 0.527452\n",
      "epoch 73; iter: 0; batch classifier loss: 0.099137; batch adversarial loss: 0.430142\n",
      "epoch 74; iter: 0; batch classifier loss: 0.113737; batch adversarial loss: 0.466611\n",
      "epoch 75; iter: 0; batch classifier loss: 0.209866; batch adversarial loss: 0.460419\n",
      "epoch 76; iter: 0; batch classifier loss: 0.099167; batch adversarial loss: 0.487398\n",
      "epoch 77; iter: 0; batch classifier loss: 0.143504; batch adversarial loss: 0.492382\n",
      "epoch 78; iter: 0; batch classifier loss: 0.128048; batch adversarial loss: 0.512454\n",
      "epoch 79; iter: 0; batch classifier loss: 0.131972; batch adversarial loss: 0.550765\n",
      "epoch 80; iter: 0; batch classifier loss: 0.166989; batch adversarial loss: 0.496876\n",
      "epoch 81; iter: 0; batch classifier loss: 0.205264; batch adversarial loss: 0.448085\n",
      "epoch 82; iter: 0; batch classifier loss: 0.203801; batch adversarial loss: 0.368537\n",
      "epoch 83; iter: 0; batch classifier loss: 0.166549; batch adversarial loss: 0.422538\n",
      "epoch 84; iter: 0; batch classifier loss: 0.118997; batch adversarial loss: 0.562929\n",
      "epoch 85; iter: 0; batch classifier loss: 0.157966; batch adversarial loss: 0.468766\n",
      "epoch 86; iter: 0; batch classifier loss: 0.149937; batch adversarial loss: 0.522578\n",
      "epoch 87; iter: 0; batch classifier loss: 0.136136; batch adversarial loss: 0.435343\n",
      "epoch 88; iter: 0; batch classifier loss: 0.125746; batch adversarial loss: 0.412772\n",
      "epoch 89; iter: 0; batch classifier loss: 0.154562; batch adversarial loss: 0.479453\n",
      "epoch 90; iter: 0; batch classifier loss: 0.099029; batch adversarial loss: 0.433844\n",
      "epoch 91; iter: 0; batch classifier loss: 0.107094; batch adversarial loss: 0.392563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.094583; batch adversarial loss: 0.452198\n",
      "epoch 93; iter: 0; batch classifier loss: 0.123441; batch adversarial loss: 0.434817\n",
      "epoch 94; iter: 0; batch classifier loss: 0.134679; batch adversarial loss: 0.429593\n",
      "epoch 95; iter: 0; batch classifier loss: 0.147631; batch adversarial loss: 0.384746\n",
      "epoch 96; iter: 0; batch classifier loss: 0.145870; batch adversarial loss: 0.416589\n",
      "epoch 97; iter: 0; batch classifier loss: 0.109599; batch adversarial loss: 0.444844\n",
      "epoch 98; iter: 0; batch classifier loss: 0.094199; batch adversarial loss: 0.555737\n",
      "epoch 99; iter: 0; batch classifier loss: 0.139489; batch adversarial loss: 0.434391\n",
      "epoch 100; iter: 0; batch classifier loss: 0.150191; batch adversarial loss: 0.456186\n",
      "epoch 101; iter: 0; batch classifier loss: 0.117211; batch adversarial loss: 0.435268\n",
      "epoch 102; iter: 0; batch classifier loss: 0.131922; batch adversarial loss: 0.412014\n",
      "epoch 103; iter: 0; batch classifier loss: 0.067482; batch adversarial loss: 0.483587\n",
      "epoch 104; iter: 0; batch classifier loss: 0.105607; batch adversarial loss: 0.411157\n",
      "epoch 105; iter: 0; batch classifier loss: 0.107007; batch adversarial loss: 0.493642\n",
      "epoch 106; iter: 0; batch classifier loss: 0.083822; batch adversarial loss: 0.458298\n",
      "epoch 107; iter: 0; batch classifier loss: 0.094221; batch adversarial loss: 0.479299\n",
      "epoch 108; iter: 0; batch classifier loss: 0.116311; batch adversarial loss: 0.462601\n",
      "epoch 109; iter: 0; batch classifier loss: 0.083794; batch adversarial loss: 0.400146\n",
      "epoch 110; iter: 0; batch classifier loss: 0.089501; batch adversarial loss: 0.381744\n",
      "epoch 111; iter: 0; batch classifier loss: 0.079301; batch adversarial loss: 0.478684\n",
      "epoch 112; iter: 0; batch classifier loss: 0.070702; batch adversarial loss: 0.549065\n",
      "epoch 113; iter: 0; batch classifier loss: 0.082706; batch adversarial loss: 0.429261\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059873; batch adversarial loss: 0.397650\n",
      "epoch 115; iter: 0; batch classifier loss: 0.068282; batch adversarial loss: 0.499834\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057853; batch adversarial loss: 0.453065\n",
      "epoch 117; iter: 0; batch classifier loss: 0.068488; batch adversarial loss: 0.498441\n",
      "epoch 118; iter: 0; batch classifier loss: 0.064612; batch adversarial loss: 0.469559\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045648; batch adversarial loss: 0.545289\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044996; batch adversarial loss: 0.516811\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047745; batch adversarial loss: 0.445435\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038852; batch adversarial loss: 0.411103\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048921; batch adversarial loss: 0.440918\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043533; batch adversarial loss: 0.484039\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042073; batch adversarial loss: 0.459768\n",
      "epoch 126; iter: 0; batch classifier loss: 0.059310; batch adversarial loss: 0.482238\n",
      "epoch 127; iter: 0; batch classifier loss: 0.084624; batch adversarial loss: 0.525393\n",
      "epoch 128; iter: 0; batch classifier loss: 0.076500; batch adversarial loss: 0.521640\n",
      "epoch 129; iter: 0; batch classifier loss: 0.044670; batch adversarial loss: 0.462489\n",
      "epoch 130; iter: 0; batch classifier loss: 0.070845; batch adversarial loss: 0.480372\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041418; batch adversarial loss: 0.469418\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021665; batch adversarial loss: 0.451163\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052976; batch adversarial loss: 0.499900\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043863; batch adversarial loss: 0.390759\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041075; batch adversarial loss: 0.496420\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028442; batch adversarial loss: 0.465721\n",
      "epoch 137; iter: 0; batch classifier loss: 0.068712; batch adversarial loss: 0.523769\n",
      "epoch 138; iter: 0; batch classifier loss: 0.060346; batch adversarial loss: 0.516673\n",
      "epoch 139; iter: 0; batch classifier loss: 0.064297; batch adversarial loss: 0.501932\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041479; batch adversarial loss: 0.425149\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026523; batch adversarial loss: 0.458930\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037640; batch adversarial loss: 0.494149\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023372; batch adversarial loss: 0.473639\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040834; batch adversarial loss: 0.556115\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019957; batch adversarial loss: 0.488896\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030460; batch adversarial loss: 0.499020\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031174; batch adversarial loss: 0.414857\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040432; batch adversarial loss: 0.536996\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030873; batch adversarial loss: 0.506362\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030277; batch adversarial loss: 0.476404\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017920; batch adversarial loss: 0.497807\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019450; batch adversarial loss: 0.525415\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017870; batch adversarial loss: 0.464727\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037253; batch adversarial loss: 0.445555\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028620; batch adversarial loss: 0.541399\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021482; batch adversarial loss: 0.394721\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040411; batch adversarial loss: 0.493355\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029813; batch adversarial loss: 0.531336\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023722; batch adversarial loss: 0.452356\n",
      "epoch 160; iter: 0; batch classifier loss: 0.011971; batch adversarial loss: 0.480273\n",
      "epoch 161; iter: 0; batch classifier loss: 0.048788; batch adversarial loss: 0.507988\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015237; batch adversarial loss: 0.556452\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021427; batch adversarial loss: 0.438505\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012982; batch adversarial loss: 0.441376\n",
      "epoch 165; iter: 0; batch classifier loss: 0.043374; batch adversarial loss: 0.512184\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029436; batch adversarial loss: 0.471210\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030683; batch adversarial loss: 0.529828\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027816; batch adversarial loss: 0.451158\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019342; batch adversarial loss: 0.505420\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016271; batch adversarial loss: 0.511162\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011554; batch adversarial loss: 0.464954\n",
      "epoch 172; iter: 0; batch classifier loss: 0.041681; batch adversarial loss: 0.385058\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030141; batch adversarial loss: 0.453126\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008971; batch adversarial loss: 0.409554\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024540; batch adversarial loss: 0.532397\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019545; batch adversarial loss: 0.471013\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038089; batch adversarial loss: 0.431967\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019201; batch adversarial loss: 0.555083\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015867; batch adversarial loss: 0.518963\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008681; batch adversarial loss: 0.495181\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010600; batch adversarial loss: 0.413206\n",
      "epoch 182; iter: 0; batch classifier loss: 0.005830; batch adversarial loss: 0.488391\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015694; batch adversarial loss: 0.441445\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011850; batch adversarial loss: 0.538801\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012451; batch adversarial loss: 0.494519\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021790; batch adversarial loss: 0.526312\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022295; batch adversarial loss: 0.427318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.037400; batch adversarial loss: 0.511672\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009999; batch adversarial loss: 0.463017\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007744; batch adversarial loss: 0.391604\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007416; batch adversarial loss: 0.516803\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033578; batch adversarial loss: 0.424156\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014087; batch adversarial loss: 0.480650\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018680; batch adversarial loss: 0.456891\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015489; batch adversarial loss: 0.397345\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010311; batch adversarial loss: 0.422668\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009636; batch adversarial loss: 0.516068\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017658; batch adversarial loss: 0.436581\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013205; batch adversarial loss: 0.517445\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714106; batch adversarial loss: 0.946616\n",
      "epoch 1; iter: 0; batch classifier loss: 0.618300; batch adversarial loss: 0.965963\n",
      "epoch 2; iter: 0; batch classifier loss: 0.734230; batch adversarial loss: 1.014264\n",
      "epoch 3; iter: 0; batch classifier loss: 0.938460; batch adversarial loss: 0.927332\n",
      "epoch 4; iter: 0; batch classifier loss: 1.091682; batch adversarial loss: 0.850516\n",
      "epoch 5; iter: 0; batch classifier loss: 0.884592; batch adversarial loss: 0.761602\n",
      "epoch 6; iter: 0; batch classifier loss: 0.923094; batch adversarial loss: 0.685505\n",
      "epoch 7; iter: 0; batch classifier loss: 0.966814; batch adversarial loss: 0.646848\n",
      "epoch 8; iter: 0; batch classifier loss: 0.918396; batch adversarial loss: 0.576829\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571839; batch adversarial loss: 0.558534\n",
      "epoch 10; iter: 0; batch classifier loss: 0.341470; batch adversarial loss: 0.532738\n",
      "epoch 11; iter: 0; batch classifier loss: 0.402057; batch adversarial loss: 0.554563\n",
      "epoch 12; iter: 0; batch classifier loss: 0.287586; batch adversarial loss: 0.514331\n",
      "epoch 13; iter: 0; batch classifier loss: 0.370962; batch adversarial loss: 0.528795\n",
      "epoch 14; iter: 0; batch classifier loss: 0.432702; batch adversarial loss: 0.519457\n",
      "epoch 15; iter: 0; batch classifier loss: 0.319100; batch adversarial loss: 0.520800\n",
      "epoch 16; iter: 0; batch classifier loss: 0.313662; batch adversarial loss: 0.513949\n",
      "epoch 17; iter: 0; batch classifier loss: 0.344166; batch adversarial loss: 0.488177\n",
      "epoch 18; iter: 0; batch classifier loss: 0.285989; batch adversarial loss: 0.494280\n",
      "epoch 19; iter: 0; batch classifier loss: 0.319441; batch adversarial loss: 0.528821\n",
      "epoch 20; iter: 0; batch classifier loss: 0.299940; batch adversarial loss: 0.534857\n",
      "epoch 21; iter: 0; batch classifier loss: 0.363346; batch adversarial loss: 0.557847\n",
      "epoch 22; iter: 0; batch classifier loss: 0.355535; batch adversarial loss: 0.569569\n",
      "epoch 23; iter: 0; batch classifier loss: 0.301184; batch adversarial loss: 0.457115\n",
      "epoch 24; iter: 0; batch classifier loss: 0.347799; batch adversarial loss: 0.478332\n",
      "epoch 25; iter: 0; batch classifier loss: 0.311690; batch adversarial loss: 0.491710\n",
      "epoch 26; iter: 0; batch classifier loss: 0.252010; batch adversarial loss: 0.420915\n",
      "epoch 27; iter: 0; batch classifier loss: 0.297233; batch adversarial loss: 0.423529\n",
      "epoch 28; iter: 0; batch classifier loss: 0.272280; batch adversarial loss: 0.454784\n",
      "epoch 29; iter: 0; batch classifier loss: 0.242837; batch adversarial loss: 0.496920\n",
      "epoch 30; iter: 0; batch classifier loss: 0.285515; batch adversarial loss: 0.490323\n",
      "epoch 31; iter: 0; batch classifier loss: 0.256251; batch adversarial loss: 0.468625\n",
      "epoch 32; iter: 0; batch classifier loss: 0.216098; batch adversarial loss: 0.503470\n",
      "epoch 33; iter: 0; batch classifier loss: 0.173873; batch adversarial loss: 0.415513\n",
      "epoch 34; iter: 0; batch classifier loss: 0.230127; batch adversarial loss: 0.504096\n",
      "epoch 35; iter: 0; batch classifier loss: 0.207577; batch adversarial loss: 0.482130\n",
      "epoch 36; iter: 0; batch classifier loss: 0.251832; batch adversarial loss: 0.455709\n",
      "epoch 37; iter: 0; batch classifier loss: 0.296724; batch adversarial loss: 0.521792\n",
      "epoch 38; iter: 0; batch classifier loss: 0.177464; batch adversarial loss: 0.509847\n",
      "epoch 39; iter: 0; batch classifier loss: 0.217688; batch adversarial loss: 0.543838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.210306; batch adversarial loss: 0.524865\n",
      "epoch 41; iter: 0; batch classifier loss: 0.188527; batch adversarial loss: 0.413122\n",
      "epoch 42; iter: 0; batch classifier loss: 0.168329; batch adversarial loss: 0.480937\n",
      "epoch 43; iter: 0; batch classifier loss: 0.210213; batch adversarial loss: 0.379158\n",
      "epoch 44; iter: 0; batch classifier loss: 0.208244; batch adversarial loss: 0.496033\n",
      "epoch 45; iter: 0; batch classifier loss: 0.178617; batch adversarial loss: 0.497822\n",
      "epoch 46; iter: 0; batch classifier loss: 0.140854; batch adversarial loss: 0.533343\n",
      "epoch 47; iter: 0; batch classifier loss: 0.196375; batch adversarial loss: 0.444265\n",
      "epoch 48; iter: 0; batch classifier loss: 0.183771; batch adversarial loss: 0.396576\n",
      "epoch 49; iter: 0; batch classifier loss: 0.209031; batch adversarial loss: 0.462738\n",
      "epoch 50; iter: 0; batch classifier loss: 0.182049; batch adversarial loss: 0.421195\n",
      "epoch 51; iter: 0; batch classifier loss: 0.140015; batch adversarial loss: 0.530848\n",
      "epoch 52; iter: 0; batch classifier loss: 0.196895; batch adversarial loss: 0.527855\n",
      "epoch 53; iter: 0; batch classifier loss: 0.156852; batch adversarial loss: 0.472461\n",
      "epoch 54; iter: 0; batch classifier loss: 0.160605; batch adversarial loss: 0.544044\n",
      "epoch 55; iter: 0; batch classifier loss: 0.171345; batch adversarial loss: 0.415214\n",
      "epoch 56; iter: 0; batch classifier loss: 0.167793; batch adversarial loss: 0.379951\n",
      "epoch 57; iter: 0; batch classifier loss: 0.168627; batch adversarial loss: 0.448247\n",
      "epoch 58; iter: 0; batch classifier loss: 0.119376; batch adversarial loss: 0.496887\n",
      "epoch 59; iter: 0; batch classifier loss: 0.139376; batch adversarial loss: 0.486513\n",
      "epoch 60; iter: 0; batch classifier loss: 0.169975; batch adversarial loss: 0.444710\n",
      "epoch 61; iter: 0; batch classifier loss: 0.132072; batch adversarial loss: 0.408087\n",
      "epoch 62; iter: 0; batch classifier loss: 0.169175; batch adversarial loss: 0.447313\n",
      "epoch 63; iter: 0; batch classifier loss: 0.152108; batch adversarial loss: 0.438087\n",
      "epoch 64; iter: 0; batch classifier loss: 0.140254; batch adversarial loss: 0.444219\n",
      "epoch 65; iter: 0; batch classifier loss: 0.111371; batch adversarial loss: 0.423269\n",
      "epoch 66; iter: 0; batch classifier loss: 0.155979; batch adversarial loss: 0.520384\n",
      "epoch 67; iter: 0; batch classifier loss: 0.146554; batch adversarial loss: 0.434711\n",
      "epoch 68; iter: 0; batch classifier loss: 0.126916; batch adversarial loss: 0.372761\n",
      "epoch 69; iter: 0; batch classifier loss: 0.144421; batch adversarial loss: 0.432204\n",
      "epoch 70; iter: 0; batch classifier loss: 0.125394; batch adversarial loss: 0.421920\n",
      "epoch 71; iter: 0; batch classifier loss: 0.133401; batch adversarial loss: 0.465233\n",
      "epoch 72; iter: 0; batch classifier loss: 0.174075; batch adversarial loss: 0.397112\n",
      "epoch 73; iter: 0; batch classifier loss: 0.097177; batch adversarial loss: 0.424332\n",
      "epoch 74; iter: 0; batch classifier loss: 0.129912; batch adversarial loss: 0.530339\n",
      "epoch 75; iter: 0; batch classifier loss: 0.141154; batch adversarial loss: 0.453767\n",
      "epoch 76; iter: 0; batch classifier loss: 0.095655; batch adversarial loss: 0.458621\n",
      "epoch 77; iter: 0; batch classifier loss: 0.132518; batch adversarial loss: 0.410768\n",
      "epoch 78; iter: 0; batch classifier loss: 0.116079; batch adversarial loss: 0.531119\n",
      "epoch 79; iter: 0; batch classifier loss: 0.127332; batch adversarial loss: 0.625020\n",
      "epoch 80; iter: 0; batch classifier loss: 0.104212; batch adversarial loss: 0.491953\n",
      "epoch 81; iter: 0; batch classifier loss: 0.142645; batch adversarial loss: 0.436030\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083225; batch adversarial loss: 0.473434\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114084; batch adversarial loss: 0.404399\n",
      "epoch 84; iter: 0; batch classifier loss: 0.134873; batch adversarial loss: 0.427926\n",
      "epoch 85; iter: 0; batch classifier loss: 0.179964; batch adversarial loss: 0.418787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.074849; batch adversarial loss: 0.375797\n",
      "epoch 87; iter: 0; batch classifier loss: 0.080405; batch adversarial loss: 0.493532\n",
      "epoch 88; iter: 0; batch classifier loss: 0.119056; batch adversarial loss: 0.520538\n",
      "epoch 89; iter: 0; batch classifier loss: 0.147289; batch adversarial loss: 0.387974\n",
      "epoch 90; iter: 0; batch classifier loss: 0.098551; batch adversarial loss: 0.479061\n",
      "epoch 91; iter: 0; batch classifier loss: 0.118349; batch adversarial loss: 0.516206\n",
      "epoch 92; iter: 0; batch classifier loss: 0.087358; batch adversarial loss: 0.399970\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047664; batch adversarial loss: 0.397818\n",
      "epoch 94; iter: 0; batch classifier loss: 0.089158; batch adversarial loss: 0.436355\n",
      "epoch 95; iter: 0; batch classifier loss: 0.103087; batch adversarial loss: 0.333581\n",
      "epoch 96; iter: 0; batch classifier loss: 0.069980; batch adversarial loss: 0.460335\n",
      "epoch 97; iter: 0; batch classifier loss: 0.101304; batch adversarial loss: 0.401024\n",
      "epoch 98; iter: 0; batch classifier loss: 0.066809; batch adversarial loss: 0.426135\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069961; batch adversarial loss: 0.391318\n",
      "epoch 100; iter: 0; batch classifier loss: 0.063728; batch adversarial loss: 0.410615\n",
      "epoch 101; iter: 0; batch classifier loss: 0.084484; batch adversarial loss: 0.479225\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079589; batch adversarial loss: 0.502239\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042150; batch adversarial loss: 0.573937\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071003; batch adversarial loss: 0.423679\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038310; batch adversarial loss: 0.555379\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054714; batch adversarial loss: 0.432960\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055585; batch adversarial loss: 0.460313\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037794; batch adversarial loss: 0.518076\n",
      "epoch 109; iter: 0; batch classifier loss: 0.082283; batch adversarial loss: 0.424707\n",
      "epoch 110; iter: 0; batch classifier loss: 0.022829; batch adversarial loss: 0.492556\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029705; batch adversarial loss: 0.512124\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057893; batch adversarial loss: 0.417120\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028165; batch adversarial loss: 0.438518\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054227; batch adversarial loss: 0.446989\n",
      "epoch 115; iter: 0; batch classifier loss: 0.020397; batch adversarial loss: 0.463801\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037855; batch adversarial loss: 0.376187\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048315; batch adversarial loss: 0.474937\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049630; batch adversarial loss: 0.434468\n",
      "epoch 119; iter: 0; batch classifier loss: 0.061362; batch adversarial loss: 0.459988\n",
      "epoch 120; iter: 0; batch classifier loss: 0.018939; batch adversarial loss: 0.411412\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047308; batch adversarial loss: 0.505408\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026253; batch adversarial loss: 0.409947\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037073; batch adversarial loss: 0.395276\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025344; batch adversarial loss: 0.361092\n",
      "epoch 125; iter: 0; batch classifier loss: 0.012780; batch adversarial loss: 0.450310\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047739; batch adversarial loss: 0.474820\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032497; batch adversarial loss: 0.443237\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031864; batch adversarial loss: 0.476734\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025030; batch adversarial loss: 0.415254\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042423; batch adversarial loss: 0.446453\n",
      "epoch 131; iter: 0; batch classifier loss: 0.014296; batch adversarial loss: 0.550069\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038392; batch adversarial loss: 0.421673\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029018; batch adversarial loss: 0.481278\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043656; batch adversarial loss: 0.435508\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038977; batch adversarial loss: 0.419890\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016840; batch adversarial loss: 0.380152\n",
      "epoch 137; iter: 0; batch classifier loss: 0.014782; batch adversarial loss: 0.511220\n",
      "epoch 138; iter: 0; batch classifier loss: 0.005533; batch adversarial loss: 0.504386\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010978; batch adversarial loss: 0.558232\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051735; batch adversarial loss: 0.482532\n",
      "epoch 141; iter: 0; batch classifier loss: 0.010709; batch adversarial loss: 0.404128\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031060; batch adversarial loss: 0.558490\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033545; batch adversarial loss: 0.402449\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030615; batch adversarial loss: 0.415102\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035219; batch adversarial loss: 0.476366\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024142; batch adversarial loss: 0.480924\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038806; batch adversarial loss: 0.439049\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013631; batch adversarial loss: 0.453091\n",
      "epoch 149; iter: 0; batch classifier loss: 0.010070; batch adversarial loss: 0.439177\n",
      "epoch 150; iter: 0; batch classifier loss: 0.005977; batch adversarial loss: 0.475719\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036205; batch adversarial loss: 0.418154\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042343; batch adversarial loss: 0.444315\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030280; batch adversarial loss: 0.425880\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017632; batch adversarial loss: 0.483170\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015208; batch adversarial loss: 0.481545\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012922; batch adversarial loss: 0.368978\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014352; batch adversarial loss: 0.410990\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012013; batch adversarial loss: 0.467239\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016705; batch adversarial loss: 0.441098\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016762; batch adversarial loss: 0.427773\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015842; batch adversarial loss: 0.438741\n",
      "epoch 162; iter: 0; batch classifier loss: 0.006784; batch adversarial loss: 0.488375\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026255; batch adversarial loss: 0.393897\n",
      "epoch 164; iter: 0; batch classifier loss: 0.003026; batch adversarial loss: 0.403564\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021567; batch adversarial loss: 0.498208\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010373; batch adversarial loss: 0.441738\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019790; batch adversarial loss: 0.526181\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033132; batch adversarial loss: 0.431531\n",
      "epoch 169; iter: 0; batch classifier loss: 0.045131; batch adversarial loss: 0.536248\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036382; batch adversarial loss: 0.412677\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013448; batch adversarial loss: 0.537199\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029153; batch adversarial loss: 0.460735\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013744; batch adversarial loss: 0.482818\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020507; batch adversarial loss: 0.552187\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012624; batch adversarial loss: 0.479314\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023089; batch adversarial loss: 0.443709\n",
      "epoch 177; iter: 0; batch classifier loss: 0.040224; batch adversarial loss: 0.460729\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008235; batch adversarial loss: 0.516342\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037746; batch adversarial loss: 0.472700\n",
      "epoch 180; iter: 0; batch classifier loss: 0.005987; batch adversarial loss: 0.391624\n",
      "epoch 181; iter: 0; batch classifier loss: 0.054261; batch adversarial loss: 0.510752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.008442; batch adversarial loss: 0.391063\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009254; batch adversarial loss: 0.435748\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009355; batch adversarial loss: 0.503222\n",
      "epoch 185; iter: 0; batch classifier loss: 0.005641; batch adversarial loss: 0.406870\n",
      "epoch 186; iter: 0; batch classifier loss: 0.046473; batch adversarial loss: 0.458247\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017464; batch adversarial loss: 0.505580\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018479; batch adversarial loss: 0.405990\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004990; batch adversarial loss: 0.534332\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005187; batch adversarial loss: 0.474370\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012112; batch adversarial loss: 0.508147\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013210; batch adversarial loss: 0.426490\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007173; batch adversarial loss: 0.406082\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030086; batch adversarial loss: 0.406586\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022083; batch adversarial loss: 0.442828\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030247; batch adversarial loss: 0.362448\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011298; batch adversarial loss: 0.476810\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024449; batch adversarial loss: 0.404196\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014085; batch adversarial loss: 0.457479\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675970; batch adversarial loss: 0.631139\n",
      "epoch 1; iter: 0; batch classifier loss: 0.470391; batch adversarial loss: 0.655839\n",
      "epoch 2; iter: 0; batch classifier loss: 0.411204; batch adversarial loss: 0.656982\n",
      "epoch 3; iter: 0; batch classifier loss: 0.381516; batch adversarial loss: 0.641323\n",
      "epoch 4; iter: 0; batch classifier loss: 0.497440; batch adversarial loss: 0.604440\n",
      "epoch 5; iter: 0; batch classifier loss: 0.511773; batch adversarial loss: 0.583206\n",
      "epoch 6; iter: 0; batch classifier loss: 0.500727; batch adversarial loss: 0.596634\n",
      "epoch 7; iter: 0; batch classifier loss: 0.405072; batch adversarial loss: 0.545971\n",
      "epoch 8; iter: 0; batch classifier loss: 0.437490; batch adversarial loss: 0.521874\n",
      "epoch 9; iter: 0; batch classifier loss: 0.360806; batch adversarial loss: 0.565265\n",
      "epoch 10; iter: 0; batch classifier loss: 0.347266; batch adversarial loss: 0.572148\n",
      "epoch 11; iter: 0; batch classifier loss: 0.384397; batch adversarial loss: 0.490459\n",
      "epoch 12; iter: 0; batch classifier loss: 0.260177; batch adversarial loss: 0.487261\n",
      "epoch 13; iter: 0; batch classifier loss: 0.297982; batch adversarial loss: 0.492803\n",
      "epoch 14; iter: 0; batch classifier loss: 0.285348; batch adversarial loss: 0.484212\n",
      "epoch 15; iter: 0; batch classifier loss: 0.348823; batch adversarial loss: 0.524356\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242296; batch adversarial loss: 0.497511\n",
      "epoch 17; iter: 0; batch classifier loss: 0.273265; batch adversarial loss: 0.485475\n",
      "epoch 18; iter: 0; batch classifier loss: 0.228706; batch adversarial loss: 0.541955\n",
      "epoch 19; iter: 0; batch classifier loss: 0.260469; batch adversarial loss: 0.519317\n",
      "epoch 20; iter: 0; batch classifier loss: 0.224829; batch adversarial loss: 0.467466\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186462; batch adversarial loss: 0.444353\n",
      "epoch 22; iter: 0; batch classifier loss: 0.194952; batch adversarial loss: 0.488109\n",
      "epoch 23; iter: 0; batch classifier loss: 0.182695; batch adversarial loss: 0.404430\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194799; batch adversarial loss: 0.411871\n",
      "epoch 25; iter: 0; batch classifier loss: 0.212422; batch adversarial loss: 0.405904\n",
      "epoch 26; iter: 0; batch classifier loss: 0.190832; batch adversarial loss: 0.493951\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181021; batch adversarial loss: 0.463341\n",
      "epoch 28; iter: 0; batch classifier loss: 0.207037; batch adversarial loss: 0.479756\n",
      "epoch 29; iter: 0; batch classifier loss: 0.184677; batch adversarial loss: 0.492767\n",
      "epoch 30; iter: 0; batch classifier loss: 0.163517; batch adversarial loss: 0.492155\n",
      "epoch 31; iter: 0; batch classifier loss: 0.222165; batch adversarial loss: 0.412923\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165867; batch adversarial loss: 0.374382\n",
      "epoch 33; iter: 0; batch classifier loss: 0.129790; batch adversarial loss: 0.478946\n",
      "epoch 34; iter: 0; batch classifier loss: 0.158218; batch adversarial loss: 0.499500\n",
      "epoch 35; iter: 0; batch classifier loss: 0.182989; batch adversarial loss: 0.446333\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163948; batch adversarial loss: 0.512570\n",
      "epoch 37; iter: 0; batch classifier loss: 0.195750; batch adversarial loss: 0.454494\n",
      "epoch 38; iter: 0; batch classifier loss: 0.151949; batch adversarial loss: 0.516257\n",
      "epoch 39; iter: 0; batch classifier loss: 0.194311; batch adversarial loss: 0.493715\n",
      "epoch 40; iter: 0; batch classifier loss: 0.145279; batch adversarial loss: 0.419457\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111329; batch adversarial loss: 0.507219\n",
      "epoch 42; iter: 0; batch classifier loss: 0.181608; batch adversarial loss: 0.426040\n",
      "epoch 43; iter: 0; batch classifier loss: 0.157839; batch adversarial loss: 0.529425\n",
      "epoch 44; iter: 0; batch classifier loss: 0.197204; batch adversarial loss: 0.466243\n",
      "epoch 45; iter: 0; batch classifier loss: 0.184558; batch adversarial loss: 0.606629\n",
      "epoch 46; iter: 0; batch classifier loss: 0.212236; batch adversarial loss: 0.432302\n",
      "epoch 47; iter: 0; batch classifier loss: 0.214423; batch adversarial loss: 0.479938\n",
      "epoch 48; iter: 0; batch classifier loss: 0.187497; batch adversarial loss: 0.550982\n",
      "epoch 49; iter: 0; batch classifier loss: 0.151545; batch adversarial loss: 0.529224\n",
      "epoch 50; iter: 0; batch classifier loss: 0.194472; batch adversarial loss: 0.423505\n",
      "epoch 51; iter: 0; batch classifier loss: 0.156057; batch adversarial loss: 0.479270\n",
      "epoch 52; iter: 0; batch classifier loss: 0.191041; batch adversarial loss: 0.507660\n",
      "epoch 53; iter: 0; batch classifier loss: 0.185357; batch adversarial loss: 0.389233\n",
      "epoch 54; iter: 0; batch classifier loss: 0.186341; batch adversarial loss: 0.588202\n",
      "epoch 55; iter: 0; batch classifier loss: 0.177699; batch adversarial loss: 0.506151\n",
      "epoch 56; iter: 0; batch classifier loss: 0.239734; batch adversarial loss: 0.518221\n",
      "epoch 57; iter: 0; batch classifier loss: 0.191492; batch adversarial loss: 0.506526\n",
      "epoch 58; iter: 0; batch classifier loss: 0.171866; batch adversarial loss: 0.435213\n",
      "epoch 59; iter: 0; batch classifier loss: 0.246159; batch adversarial loss: 0.388040\n",
      "epoch 60; iter: 0; batch classifier loss: 0.128738; batch adversarial loss: 0.422220\n",
      "epoch 61; iter: 0; batch classifier loss: 0.118869; batch adversarial loss: 0.421028\n",
      "epoch 62; iter: 0; batch classifier loss: 0.119114; batch adversarial loss: 0.514442\n",
      "epoch 63; iter: 0; batch classifier loss: 0.187556; batch adversarial loss: 0.410451\n",
      "epoch 64; iter: 0; batch classifier loss: 0.123972; batch adversarial loss: 0.482471\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107142; batch adversarial loss: 0.457253\n",
      "epoch 66; iter: 0; batch classifier loss: 0.154408; batch adversarial loss: 0.506458\n",
      "epoch 67; iter: 0; batch classifier loss: 0.170051; batch adversarial loss: 0.410222\n",
      "epoch 68; iter: 0; batch classifier loss: 0.198368; batch adversarial loss: 0.461276\n",
      "epoch 69; iter: 0; batch classifier loss: 0.148292; batch adversarial loss: 0.386449\n",
      "epoch 70; iter: 0; batch classifier loss: 0.169259; batch adversarial loss: 0.447365\n",
      "epoch 71; iter: 0; batch classifier loss: 0.189799; batch adversarial loss: 0.470501\n",
      "epoch 72; iter: 0; batch classifier loss: 0.146344; batch adversarial loss: 0.532773\n",
      "epoch 73; iter: 0; batch classifier loss: 0.228786; batch adversarial loss: 0.456944\n",
      "epoch 74; iter: 0; batch classifier loss: 0.125590; batch adversarial loss: 0.431881\n",
      "epoch 75; iter: 0; batch classifier loss: 0.172167; batch adversarial loss: 0.363170\n",
      "epoch 76; iter: 0; batch classifier loss: 0.153277; batch adversarial loss: 0.457345\n",
      "epoch 77; iter: 0; batch classifier loss: 0.118754; batch adversarial loss: 0.470655\n",
      "epoch 78; iter: 0; batch classifier loss: 0.205717; batch adversarial loss: 0.495744\n",
      "epoch 79; iter: 0; batch classifier loss: 0.178272; batch adversarial loss: 0.409725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.135813; batch adversarial loss: 0.472182\n",
      "epoch 81; iter: 0; batch classifier loss: 0.181483; batch adversarial loss: 0.507282\n",
      "epoch 82; iter: 0; batch classifier loss: 0.138098; batch adversarial loss: 0.506896\n",
      "epoch 83; iter: 0; batch classifier loss: 0.112913; batch adversarial loss: 0.435134\n",
      "epoch 84; iter: 0; batch classifier loss: 0.141265; batch adversarial loss: 0.447511\n",
      "epoch 85; iter: 0; batch classifier loss: 0.182103; batch adversarial loss: 0.470957\n",
      "epoch 86; iter: 0; batch classifier loss: 0.157456; batch adversarial loss: 0.446324\n",
      "epoch 87; iter: 0; batch classifier loss: 0.177676; batch adversarial loss: 0.543999\n",
      "epoch 88; iter: 0; batch classifier loss: 0.151329; batch adversarial loss: 0.468546\n",
      "epoch 89; iter: 0; batch classifier loss: 0.172788; batch adversarial loss: 0.467585\n",
      "epoch 90; iter: 0; batch classifier loss: 0.205657; batch adversarial loss: 0.387447\n",
      "epoch 91; iter: 0; batch classifier loss: 0.129827; batch adversarial loss: 0.472232\n",
      "epoch 92; iter: 0; batch classifier loss: 0.169747; batch adversarial loss: 0.447104\n",
      "epoch 93; iter: 0; batch classifier loss: 0.155493; batch adversarial loss: 0.350300\n",
      "epoch 94; iter: 0; batch classifier loss: 0.124494; batch adversarial loss: 0.400066\n",
      "epoch 95; iter: 0; batch classifier loss: 0.178477; batch adversarial loss: 0.408979\n",
      "epoch 96; iter: 0; batch classifier loss: 0.074653; batch adversarial loss: 0.406838\n",
      "epoch 97; iter: 0; batch classifier loss: 0.107186; batch adversarial loss: 0.479696\n",
      "epoch 98; iter: 0; batch classifier loss: 0.130565; batch adversarial loss: 0.530695\n",
      "epoch 99; iter: 0; batch classifier loss: 0.075491; batch adversarial loss: 0.384764\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060862; batch adversarial loss: 0.494250\n",
      "epoch 101; iter: 0; batch classifier loss: 0.082721; batch adversarial loss: 0.400505\n",
      "epoch 102; iter: 0; batch classifier loss: 0.085922; batch adversarial loss: 0.434443\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041851; batch adversarial loss: 0.487961\n",
      "epoch 104; iter: 0; batch classifier loss: 0.075300; batch adversarial loss: 0.474328\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048522; batch adversarial loss: 0.445160\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059225; batch adversarial loss: 0.453914\n",
      "epoch 107; iter: 0; batch classifier loss: 0.068839; batch adversarial loss: 0.563696\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073139; batch adversarial loss: 0.407553\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049600; batch adversarial loss: 0.488265\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056294; batch adversarial loss: 0.491828\n",
      "epoch 111; iter: 0; batch classifier loss: 0.078711; batch adversarial loss: 0.416569\n",
      "epoch 112; iter: 0; batch classifier loss: 0.072864; batch adversarial loss: 0.475950\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043317; batch adversarial loss: 0.535792\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044870; batch adversarial loss: 0.474242\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027650; batch adversarial loss: 0.572438\n",
      "epoch 116; iter: 0; batch classifier loss: 0.084117; batch adversarial loss: 0.447996\n",
      "epoch 117; iter: 0; batch classifier loss: 0.068717; batch adversarial loss: 0.471392\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057331; batch adversarial loss: 0.448332\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045746; batch adversarial loss: 0.439679\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034953; batch adversarial loss: 0.447847\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044981; batch adversarial loss: 0.470275\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032234; batch adversarial loss: 0.376292\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050388; batch adversarial loss: 0.454179\n",
      "epoch 124; iter: 0; batch classifier loss: 0.083515; batch adversarial loss: 0.542638\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023085; batch adversarial loss: 0.482139\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046333; batch adversarial loss: 0.526407\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023992; batch adversarial loss: 0.440200\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038477; batch adversarial loss: 0.364102\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035521; batch adversarial loss: 0.360944\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033654; batch adversarial loss: 0.361449\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037521; batch adversarial loss: 0.495429\n",
      "epoch 132; iter: 0; batch classifier loss: 0.018340; batch adversarial loss: 0.438195\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028703; batch adversarial loss: 0.410990\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031301; batch adversarial loss: 0.481523\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043186; batch adversarial loss: 0.523397\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028515; batch adversarial loss: 0.429320\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025658; batch adversarial loss: 0.451565\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031966; batch adversarial loss: 0.451822\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031089; batch adversarial loss: 0.461990\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013298; batch adversarial loss: 0.482588\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029758; batch adversarial loss: 0.505042\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025850; batch adversarial loss: 0.446185\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034865; batch adversarial loss: 0.429151\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013720; batch adversarial loss: 0.384194\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013460; batch adversarial loss: 0.559642\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038593; batch adversarial loss: 0.381975\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010505; batch adversarial loss: 0.497835\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015930; batch adversarial loss: 0.368049\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020038; batch adversarial loss: 0.542328\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013033; batch adversarial loss: 0.565590\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043906; batch adversarial loss: 0.515030\n",
      "epoch 152; iter: 0; batch classifier loss: 0.012846; batch adversarial loss: 0.348940\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013150; batch adversarial loss: 0.422870\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017316; batch adversarial loss: 0.421845\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016790; batch adversarial loss: 0.517436\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022563; batch adversarial loss: 0.418662\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013287; batch adversarial loss: 0.488199\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007701; batch adversarial loss: 0.512332\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019251; batch adversarial loss: 0.469950\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044782; batch adversarial loss: 0.414942\n",
      "epoch 161; iter: 0; batch classifier loss: 0.003773; batch adversarial loss: 0.552601\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011959; batch adversarial loss: 0.484996\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014001; batch adversarial loss: 0.494788\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032653; batch adversarial loss: 0.470484\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022477; batch adversarial loss: 0.520137\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037807; batch adversarial loss: 0.398038\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008984; batch adversarial loss: 0.479493\n",
      "epoch 168; iter: 0; batch classifier loss: 0.067414; batch adversarial loss: 0.481857\n",
      "epoch 169; iter: 0; batch classifier loss: 0.042732; batch adversarial loss: 0.492126\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024169; batch adversarial loss: 0.516804\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020928; batch adversarial loss: 0.465675\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010685; batch adversarial loss: 0.524351\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020672; batch adversarial loss: 0.411525\n",
      "epoch 174; iter: 0; batch classifier loss: 0.004695; batch adversarial loss: 0.560053\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014113; batch adversarial loss: 0.455189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.016272; batch adversarial loss: 0.476862\n",
      "epoch 177; iter: 0; batch classifier loss: 0.005932; batch adversarial loss: 0.585515\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009706; batch adversarial loss: 0.474511\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008044; batch adversarial loss: 0.426484\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032350; batch adversarial loss: 0.369551\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014235; batch adversarial loss: 0.411624\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012472; batch adversarial loss: 0.424130\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030905; batch adversarial loss: 0.456253\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026073; batch adversarial loss: 0.433290\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006600; batch adversarial loss: 0.379172\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012118; batch adversarial loss: 0.506288\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009397; batch adversarial loss: 0.557810\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016554; batch adversarial loss: 0.571652\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010960; batch adversarial loss: 0.483354\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031129; batch adversarial loss: 0.434504\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008512; batch adversarial loss: 0.442379\n",
      "epoch 192; iter: 0; batch classifier loss: 0.049702; batch adversarial loss: 0.449579\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010390; batch adversarial loss: 0.453135\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019187; batch adversarial loss: 0.404008\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008529; batch adversarial loss: 0.443152\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009041; batch adversarial loss: 0.494528\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004141; batch adversarial loss: 0.428820\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013704; batch adversarial loss: 0.489096\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020604; batch adversarial loss: 0.471840\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684879; batch adversarial loss: 0.637807\n",
      "epoch 1; iter: 0; batch classifier loss: 0.478285; batch adversarial loss: 0.662465\n",
      "epoch 2; iter: 0; batch classifier loss: 0.445459; batch adversarial loss: 0.653821\n",
      "epoch 3; iter: 0; batch classifier loss: 0.461370; batch adversarial loss: 0.620638\n",
      "epoch 4; iter: 0; batch classifier loss: 0.362459; batch adversarial loss: 0.635649\n",
      "epoch 5; iter: 0; batch classifier loss: 0.438287; batch adversarial loss: 0.632541\n",
      "epoch 6; iter: 0; batch classifier loss: 0.453277; batch adversarial loss: 0.573654\n",
      "epoch 7; iter: 0; batch classifier loss: 0.451980; batch adversarial loss: 0.539142\n",
      "epoch 8; iter: 0; batch classifier loss: 0.399342; batch adversarial loss: 0.532967\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416202; batch adversarial loss: 0.526959\n",
      "epoch 10; iter: 0; batch classifier loss: 0.392978; batch adversarial loss: 0.544973\n",
      "epoch 11; iter: 0; batch classifier loss: 0.378091; batch adversarial loss: 0.506685\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285406; batch adversarial loss: 0.522027\n",
      "epoch 13; iter: 0; batch classifier loss: 0.267896; batch adversarial loss: 0.538567\n",
      "epoch 14; iter: 0; batch classifier loss: 0.303775; batch adversarial loss: 0.546846\n",
      "epoch 15; iter: 0; batch classifier loss: 0.412983; batch adversarial loss: 0.558472\n",
      "epoch 16; iter: 0; batch classifier loss: 0.404597; batch adversarial loss: 0.508883\n",
      "epoch 17; iter: 0; batch classifier loss: 0.397064; batch adversarial loss: 0.459939\n",
      "epoch 18; iter: 0; batch classifier loss: 0.322424; batch adversarial loss: 0.442198\n",
      "epoch 19; iter: 0; batch classifier loss: 0.335057; batch adversarial loss: 0.484899\n",
      "epoch 20; iter: 0; batch classifier loss: 0.295518; batch adversarial loss: 0.499836\n",
      "epoch 21; iter: 0; batch classifier loss: 0.233227; batch adversarial loss: 0.432392\n",
      "epoch 22; iter: 0; batch classifier loss: 0.285507; batch adversarial loss: 0.503199\n",
      "epoch 23; iter: 0; batch classifier loss: 0.236870; batch adversarial loss: 0.521143\n",
      "epoch 24; iter: 0; batch classifier loss: 0.239075; batch adversarial loss: 0.466868\n",
      "epoch 25; iter: 0; batch classifier loss: 0.287078; batch adversarial loss: 0.509565\n",
      "epoch 26; iter: 0; batch classifier loss: 0.262237; batch adversarial loss: 0.495860\n",
      "epoch 27; iter: 0; batch classifier loss: 0.287923; batch adversarial loss: 0.525880\n",
      "epoch 28; iter: 0; batch classifier loss: 0.383962; batch adversarial loss: 0.418231\n",
      "epoch 29; iter: 0; batch classifier loss: 0.245790; batch adversarial loss: 0.486840\n",
      "epoch 30; iter: 0; batch classifier loss: 0.280977; batch adversarial loss: 0.507569\n",
      "epoch 31; iter: 0; batch classifier loss: 0.292471; batch adversarial loss: 0.501838\n",
      "epoch 32; iter: 0; batch classifier loss: 0.314605; batch adversarial loss: 0.442777\n",
      "epoch 33; iter: 0; batch classifier loss: 0.254265; batch adversarial loss: 0.435500\n",
      "epoch 34; iter: 0; batch classifier loss: 0.277157; batch adversarial loss: 0.445749\n",
      "epoch 35; iter: 0; batch classifier loss: 0.335815; batch adversarial loss: 0.442925\n",
      "epoch 36; iter: 0; batch classifier loss: 0.328748; batch adversarial loss: 0.472226\n",
      "epoch 37; iter: 0; batch classifier loss: 0.295720; batch adversarial loss: 0.472443\n",
      "epoch 38; iter: 0; batch classifier loss: 0.274856; batch adversarial loss: 0.429529\n",
      "epoch 39; iter: 0; batch classifier loss: 0.238407; batch adversarial loss: 0.472454\n",
      "epoch 40; iter: 0; batch classifier loss: 0.290098; batch adversarial loss: 0.482793\n",
      "epoch 41; iter: 0; batch classifier loss: 0.127147; batch adversarial loss: 0.437785\n",
      "epoch 42; iter: 0; batch classifier loss: 0.139586; batch adversarial loss: 0.513515\n",
      "epoch 43; iter: 0; batch classifier loss: 0.116422; batch adversarial loss: 0.388161\n",
      "epoch 44; iter: 0; batch classifier loss: 0.125490; batch adversarial loss: 0.514868\n",
      "epoch 45; iter: 0; batch classifier loss: 0.325031; batch adversarial loss: 0.438116\n",
      "epoch 46; iter: 0; batch classifier loss: 0.189932; batch adversarial loss: 0.515053\n",
      "epoch 47; iter: 0; batch classifier loss: 0.192256; batch adversarial loss: 0.450302\n",
      "epoch 48; iter: 0; batch classifier loss: 0.199009; batch adversarial loss: 0.436835\n",
      "epoch 49; iter: 0; batch classifier loss: 0.178369; batch adversarial loss: 0.459158\n",
      "epoch 50; iter: 0; batch classifier loss: 0.268811; batch adversarial loss: 0.518351\n",
      "epoch 51; iter: 0; batch classifier loss: 0.213598; batch adversarial loss: 0.483253\n",
      "epoch 52; iter: 0; batch classifier loss: 0.208873; batch adversarial loss: 0.436224\n",
      "epoch 53; iter: 0; batch classifier loss: 0.142135; batch adversarial loss: 0.354069\n",
      "epoch 54; iter: 0; batch classifier loss: 0.240193; batch adversarial loss: 0.471077\n",
      "epoch 55; iter: 0; batch classifier loss: 0.162122; batch adversarial loss: 0.435559\n",
      "epoch 56; iter: 0; batch classifier loss: 0.245641; batch adversarial loss: 0.517636\n",
      "epoch 57; iter: 0; batch classifier loss: 0.216478; batch adversarial loss: 0.494382\n",
      "epoch 58; iter: 0; batch classifier loss: 0.138426; batch adversarial loss: 0.446457\n",
      "epoch 59; iter: 0; batch classifier loss: 0.141712; batch adversarial loss: 0.533587\n",
      "epoch 60; iter: 0; batch classifier loss: 0.221744; batch adversarial loss: 0.483052\n",
      "epoch 61; iter: 0; batch classifier loss: 0.192741; batch adversarial loss: 0.411235\n",
      "epoch 62; iter: 0; batch classifier loss: 0.201766; batch adversarial loss: 0.458915\n",
      "epoch 63; iter: 0; batch classifier loss: 0.196400; batch adversarial loss: 0.543053\n",
      "epoch 64; iter: 0; batch classifier loss: 0.222594; batch adversarial loss: 0.435245\n",
      "epoch 65; iter: 0; batch classifier loss: 0.114627; batch adversarial loss: 0.447723\n",
      "epoch 66; iter: 0; batch classifier loss: 0.108638; batch adversarial loss: 0.374139\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110674; batch adversarial loss: 0.493365\n",
      "epoch 68; iter: 0; batch classifier loss: 0.205752; batch adversarial loss: 0.556261\n",
      "epoch 69; iter: 0; batch classifier loss: 0.217989; batch adversarial loss: 0.450383\n",
      "epoch 70; iter: 0; batch classifier loss: 0.193037; batch adversarial loss: 0.578948\n",
      "epoch 71; iter: 0; batch classifier loss: 0.172218; batch adversarial loss: 0.471216\n",
      "epoch 72; iter: 0; batch classifier loss: 0.196671; batch adversarial loss: 0.530503\n",
      "epoch 73; iter: 0; batch classifier loss: 0.267258; batch adversarial loss: 0.482802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.087475; batch adversarial loss: 0.506254\n",
      "epoch 75; iter: 0; batch classifier loss: 0.072276; batch adversarial loss: 0.460374\n",
      "epoch 76; iter: 0; batch classifier loss: 0.056976; batch adversarial loss: 0.541586\n",
      "epoch 77; iter: 0; batch classifier loss: 0.114361; batch adversarial loss: 0.517929\n",
      "epoch 78; iter: 0; batch classifier loss: 0.206271; batch adversarial loss: 0.509090\n",
      "epoch 79; iter: 0; batch classifier loss: 0.229781; batch adversarial loss: 0.447368\n",
      "epoch 80; iter: 0; batch classifier loss: 0.211323; batch adversarial loss: 0.485253\n",
      "epoch 81; iter: 0; batch classifier loss: 0.262202; batch adversarial loss: 0.551469\n",
      "epoch 82; iter: 0; batch classifier loss: 0.215125; batch adversarial loss: 0.459035\n",
      "epoch 83; iter: 0; batch classifier loss: 0.230879; batch adversarial loss: 0.410887\n",
      "epoch 84; iter: 0; batch classifier loss: 0.216410; batch adversarial loss: 0.389263\n",
      "epoch 85; iter: 0; batch classifier loss: 0.263463; batch adversarial loss: 0.483289\n",
      "epoch 86; iter: 0; batch classifier loss: 0.134111; batch adversarial loss: 0.505427\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057731; batch adversarial loss: 0.430918\n",
      "epoch 88; iter: 0; batch classifier loss: 0.086692; batch adversarial loss: 0.493641\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060422; batch adversarial loss: 0.468058\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055302; batch adversarial loss: 0.480136\n",
      "epoch 91; iter: 0; batch classifier loss: 0.089986; batch adversarial loss: 0.463044\n",
      "epoch 92; iter: 0; batch classifier loss: 0.114664; batch adversarial loss: 0.392153\n",
      "epoch 93; iter: 0; batch classifier loss: 0.135575; batch adversarial loss: 0.334727\n",
      "epoch 94; iter: 0; batch classifier loss: 0.102760; batch adversarial loss: 0.504197\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048941; batch adversarial loss: 0.482313\n",
      "epoch 96; iter: 0; batch classifier loss: 0.125256; batch adversarial loss: 0.509055\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071507; batch adversarial loss: 0.523098\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050032; batch adversarial loss: 0.422132\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074392; batch adversarial loss: 0.524155\n",
      "epoch 100; iter: 0; batch classifier loss: 0.081440; batch adversarial loss: 0.399519\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070451; batch adversarial loss: 0.445880\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058116; batch adversarial loss: 0.452453\n",
      "epoch 103; iter: 0; batch classifier loss: 0.024472; batch adversarial loss: 0.516346\n",
      "epoch 104; iter: 0; batch classifier loss: 0.078045; batch adversarial loss: 0.414055\n",
      "epoch 105; iter: 0; batch classifier loss: 0.077133; batch adversarial loss: 0.386372\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039360; batch adversarial loss: 0.539421\n",
      "epoch 107; iter: 0; batch classifier loss: 0.070176; batch adversarial loss: 0.389817\n",
      "epoch 108; iter: 0; batch classifier loss: 0.103538; batch adversarial loss: 0.405241\n",
      "epoch 109; iter: 0; batch classifier loss: 0.024226; batch adversarial loss: 0.509465\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060583; batch adversarial loss: 0.516653\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061403; batch adversarial loss: 0.496396\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037212; batch adversarial loss: 0.392530\n",
      "epoch 113; iter: 0; batch classifier loss: 0.060867; batch adversarial loss: 0.544555\n",
      "epoch 114; iter: 0; batch classifier loss: 0.073321; batch adversarial loss: 0.396269\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046159; batch adversarial loss: 0.478542\n",
      "epoch 116; iter: 0; batch classifier loss: 0.072380; batch adversarial loss: 0.508355\n",
      "epoch 117; iter: 0; batch classifier loss: 0.063702; batch adversarial loss: 0.530043\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057838; batch adversarial loss: 0.537904\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031287; batch adversarial loss: 0.490316\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055383; batch adversarial loss: 0.459731\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031393; batch adversarial loss: 0.450479\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032500; batch adversarial loss: 0.498057\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034104; batch adversarial loss: 0.441448\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043990; batch adversarial loss: 0.519437\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041457; batch adversarial loss: 0.467382\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050567; batch adversarial loss: 0.530493\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051143; batch adversarial loss: 0.489269\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037403; batch adversarial loss: 0.426938\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048911; batch adversarial loss: 0.537907\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050338; batch adversarial loss: 0.429563\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022026; batch adversarial loss: 0.520166\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037940; batch adversarial loss: 0.528038\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027961; batch adversarial loss: 0.493510\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018825; batch adversarial loss: 0.460260\n",
      "epoch 135; iter: 0; batch classifier loss: 0.007714; batch adversarial loss: 0.479785\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036191; batch adversarial loss: 0.479225\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027788; batch adversarial loss: 0.491217\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034165; batch adversarial loss: 0.529265\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020009; batch adversarial loss: 0.367737\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024809; batch adversarial loss: 0.438195\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020660; batch adversarial loss: 0.490545\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037521; batch adversarial loss: 0.429344\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033890; batch adversarial loss: 0.392669\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028142; batch adversarial loss: 0.491347\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027679; batch adversarial loss: 0.527015\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018625; batch adversarial loss: 0.448525\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016683; batch adversarial loss: 0.494723\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024696; batch adversarial loss: 0.406135\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036524; batch adversarial loss: 0.476105\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035899; batch adversarial loss: 0.442538\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026942; batch adversarial loss: 0.480340\n",
      "epoch 152; iter: 0; batch classifier loss: 0.051261; batch adversarial loss: 0.457399\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015374; batch adversarial loss: 0.430572\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029728; batch adversarial loss: 0.518849\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024953; batch adversarial loss: 0.463902\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050392; batch adversarial loss: 0.439902\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027364; batch adversarial loss: 0.585844\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017232; batch adversarial loss: 0.460459\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019975; batch adversarial loss: 0.447757\n",
      "epoch 160; iter: 0; batch classifier loss: 0.043878; batch adversarial loss: 0.521254\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012177; batch adversarial loss: 0.473261\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019827; batch adversarial loss: 0.375307\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010714; batch adversarial loss: 0.405091\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021468; batch adversarial loss: 0.602603\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035585; batch adversarial loss: 0.512957\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010042; batch adversarial loss: 0.502648\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023824; batch adversarial loss: 0.456841\n",
      "epoch 168; iter: 0; batch classifier loss: 0.052211; batch adversarial loss: 0.468672\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026886; batch adversarial loss: 0.476952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.013785; batch adversarial loss: 0.443357\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019874; batch adversarial loss: 0.484215\n",
      "epoch 172; iter: 0; batch classifier loss: 0.044689; batch adversarial loss: 0.542387\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025551; batch adversarial loss: 0.422514\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024082; batch adversarial loss: 0.440653\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011154; batch adversarial loss: 0.536470\n",
      "epoch 176; iter: 0; batch classifier loss: 0.004312; batch adversarial loss: 0.473916\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029905; batch adversarial loss: 0.456304\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014920; batch adversarial loss: 0.438513\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014252; batch adversarial loss: 0.479717\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023663; batch adversarial loss: 0.406977\n",
      "epoch 181; iter: 0; batch classifier loss: 0.044029; batch adversarial loss: 0.525769\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014036; batch adversarial loss: 0.456569\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025374; batch adversarial loss: 0.360104\n",
      "epoch 184; iter: 0; batch classifier loss: 0.047381; batch adversarial loss: 0.511926\n",
      "epoch 185; iter: 0; batch classifier loss: 0.005462; batch adversarial loss: 0.476441\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012501; batch adversarial loss: 0.480429\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014204; batch adversarial loss: 0.545518\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032476; batch adversarial loss: 0.401446\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031544; batch adversarial loss: 0.457095\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008180; batch adversarial loss: 0.455940\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018528; batch adversarial loss: 0.478166\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030180; batch adversarial loss: 0.484837\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022463; batch adversarial loss: 0.344751\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034125; batch adversarial loss: 0.427085\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023222; batch adversarial loss: 0.423195\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014083; batch adversarial loss: 0.453918\n",
      "epoch 197; iter: 0; batch classifier loss: 0.035914; batch adversarial loss: 0.389734\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014322; batch adversarial loss: 0.387130\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013570; batch adversarial loss: 0.439272\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712654; batch adversarial loss: 0.729420\n",
      "epoch 1; iter: 0; batch classifier loss: 0.530654; batch adversarial loss: 0.661208\n",
      "epoch 2; iter: 0; batch classifier loss: 0.387251; batch adversarial loss: 0.625389\n",
      "epoch 3; iter: 0; batch classifier loss: 0.454410; batch adversarial loss: 0.616826\n",
      "epoch 4; iter: 0; batch classifier loss: 0.374427; batch adversarial loss: 0.603522\n",
      "epoch 5; iter: 0; batch classifier loss: 0.409074; batch adversarial loss: 0.563803\n",
      "epoch 6; iter: 0; batch classifier loss: 0.313060; batch adversarial loss: 0.577401\n",
      "epoch 7; iter: 0; batch classifier loss: 0.320960; batch adversarial loss: 0.538959\n",
      "epoch 8; iter: 0; batch classifier loss: 0.349038; batch adversarial loss: 0.568700\n",
      "epoch 9; iter: 0; batch classifier loss: 0.315782; batch adversarial loss: 0.514533\n",
      "epoch 10; iter: 0; batch classifier loss: 0.290991; batch adversarial loss: 0.561695\n",
      "epoch 11; iter: 0; batch classifier loss: 0.289996; batch adversarial loss: 0.557134\n",
      "epoch 12; iter: 0; batch classifier loss: 0.296269; batch adversarial loss: 0.510454\n",
      "epoch 13; iter: 0; batch classifier loss: 0.357408; batch adversarial loss: 0.498429\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274094; batch adversarial loss: 0.540944\n",
      "epoch 15; iter: 0; batch classifier loss: 0.316907; batch adversarial loss: 0.480231\n",
      "epoch 16; iter: 0; batch classifier loss: 0.204753; batch adversarial loss: 0.541308\n",
      "epoch 17; iter: 0; batch classifier loss: 0.264978; batch adversarial loss: 0.540535\n",
      "epoch 18; iter: 0; batch classifier loss: 0.218374; batch adversarial loss: 0.458676\n",
      "epoch 19; iter: 0; batch classifier loss: 0.207960; batch adversarial loss: 0.409999\n",
      "epoch 20; iter: 0; batch classifier loss: 0.261945; batch adversarial loss: 0.506815\n",
      "epoch 21; iter: 0; batch classifier loss: 0.259516; batch adversarial loss: 0.489010\n",
      "epoch 22; iter: 0; batch classifier loss: 0.232275; batch adversarial loss: 0.500391\n",
      "epoch 23; iter: 0; batch classifier loss: 0.193622; batch adversarial loss: 0.461861\n",
      "epoch 24; iter: 0; batch classifier loss: 0.215815; batch adversarial loss: 0.486171\n",
      "epoch 25; iter: 0; batch classifier loss: 0.150066; batch adversarial loss: 0.524824\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194987; batch adversarial loss: 0.492529\n",
      "epoch 27; iter: 0; batch classifier loss: 0.194297; batch adversarial loss: 0.587102\n",
      "epoch 28; iter: 0; batch classifier loss: 0.162053; batch adversarial loss: 0.488388\n",
      "epoch 29; iter: 0; batch classifier loss: 0.166935; batch adversarial loss: 0.472922\n",
      "epoch 30; iter: 0; batch classifier loss: 0.225473; batch adversarial loss: 0.478901\n",
      "epoch 31; iter: 0; batch classifier loss: 0.155245; batch adversarial loss: 0.527410\n",
      "epoch 32; iter: 0; batch classifier loss: 0.203609; batch adversarial loss: 0.489789\n",
      "epoch 33; iter: 0; batch classifier loss: 0.168824; batch adversarial loss: 0.412603\n",
      "epoch 34; iter: 0; batch classifier loss: 0.211349; batch adversarial loss: 0.428226\n",
      "epoch 35; iter: 0; batch classifier loss: 0.154462; batch adversarial loss: 0.489783\n",
      "epoch 36; iter: 0; batch classifier loss: 0.160490; batch adversarial loss: 0.557783\n",
      "epoch 37; iter: 0; batch classifier loss: 0.243975; batch adversarial loss: 0.422831\n",
      "epoch 38; iter: 0; batch classifier loss: 0.150230; batch adversarial loss: 0.443537\n",
      "epoch 39; iter: 0; batch classifier loss: 0.174280; batch adversarial loss: 0.522667\n",
      "epoch 40; iter: 0; batch classifier loss: 0.152136; batch adversarial loss: 0.476590\n",
      "epoch 41; iter: 0; batch classifier loss: 0.110360; batch adversarial loss: 0.483919\n",
      "epoch 42; iter: 0; batch classifier loss: 0.154656; batch adversarial loss: 0.475229\n",
      "epoch 43; iter: 0; batch classifier loss: 0.231565; batch adversarial loss: 0.413134\n",
      "epoch 44; iter: 0; batch classifier loss: 0.172448; batch adversarial loss: 0.514480\n",
      "epoch 45; iter: 0; batch classifier loss: 0.134347; batch adversarial loss: 0.521947\n",
      "epoch 46; iter: 0; batch classifier loss: 0.156048; batch adversarial loss: 0.446893\n",
      "epoch 47; iter: 0; batch classifier loss: 0.176487; batch adversarial loss: 0.526692\n",
      "epoch 48; iter: 0; batch classifier loss: 0.163646; batch adversarial loss: 0.466188\n",
      "epoch 49; iter: 0; batch classifier loss: 0.212088; batch adversarial loss: 0.402918\n",
      "epoch 50; iter: 0; batch classifier loss: 0.183958; batch adversarial loss: 0.449316\n",
      "epoch 51; iter: 0; batch classifier loss: 0.165923; batch adversarial loss: 0.494460\n",
      "epoch 52; iter: 0; batch classifier loss: 0.143220; batch adversarial loss: 0.499490\n",
      "epoch 53; iter: 0; batch classifier loss: 0.201022; batch adversarial loss: 0.454136\n",
      "epoch 54; iter: 0; batch classifier loss: 0.137861; batch adversarial loss: 0.518721\n",
      "epoch 55; iter: 0; batch classifier loss: 0.148052; batch adversarial loss: 0.435178\n",
      "epoch 56; iter: 0; batch classifier loss: 0.141529; batch adversarial loss: 0.458812\n",
      "epoch 57; iter: 0; batch classifier loss: 0.148096; batch adversarial loss: 0.473482\n",
      "epoch 58; iter: 0; batch classifier loss: 0.130352; batch adversarial loss: 0.506103\n",
      "epoch 59; iter: 0; batch classifier loss: 0.123530; batch adversarial loss: 0.339753\n",
      "epoch 60; iter: 0; batch classifier loss: 0.176170; batch adversarial loss: 0.467420\n",
      "epoch 61; iter: 0; batch classifier loss: 0.197156; batch adversarial loss: 0.460753\n",
      "epoch 62; iter: 0; batch classifier loss: 0.162405; batch adversarial loss: 0.496020\n",
      "epoch 63; iter: 0; batch classifier loss: 0.153653; batch adversarial loss: 0.437332\n",
      "epoch 64; iter: 0; batch classifier loss: 0.161820; batch adversarial loss: 0.381588\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122785; batch adversarial loss: 0.525558\n",
      "epoch 66; iter: 0; batch classifier loss: 0.167516; batch adversarial loss: 0.497304\n",
      "epoch 67; iter: 0; batch classifier loss: 0.116458; batch adversarial loss: 0.411351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.124336; batch adversarial loss: 0.371950\n",
      "epoch 69; iter: 0; batch classifier loss: 0.119599; batch adversarial loss: 0.423562\n",
      "epoch 70; iter: 0; batch classifier loss: 0.117869; batch adversarial loss: 0.517203\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099453; batch adversarial loss: 0.385752\n",
      "epoch 72; iter: 0; batch classifier loss: 0.132414; batch adversarial loss: 0.490146\n",
      "epoch 73; iter: 0; batch classifier loss: 0.118741; batch adversarial loss: 0.571966\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089662; batch adversarial loss: 0.471891\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061966; batch adversarial loss: 0.454418\n",
      "epoch 76; iter: 0; batch classifier loss: 0.143518; batch adversarial loss: 0.401887\n",
      "epoch 77; iter: 0; batch classifier loss: 0.075513; batch adversarial loss: 0.497671\n",
      "epoch 78; iter: 0; batch classifier loss: 0.092455; batch adversarial loss: 0.498120\n",
      "epoch 79; iter: 0; batch classifier loss: 0.113597; batch adversarial loss: 0.460244\n",
      "epoch 80; iter: 0; batch classifier loss: 0.126492; batch adversarial loss: 0.464563\n",
      "epoch 81; iter: 0; batch classifier loss: 0.107986; batch adversarial loss: 0.435301\n",
      "epoch 82; iter: 0; batch classifier loss: 0.103218; batch adversarial loss: 0.381438\n",
      "epoch 83; iter: 0; batch classifier loss: 0.055989; batch adversarial loss: 0.531934\n",
      "epoch 84; iter: 0; batch classifier loss: 0.099367; batch adversarial loss: 0.453137\n",
      "epoch 85; iter: 0; batch classifier loss: 0.081981; batch adversarial loss: 0.451010\n",
      "epoch 86; iter: 0; batch classifier loss: 0.055655; batch adversarial loss: 0.386715\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072353; batch adversarial loss: 0.577942\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088780; batch adversarial loss: 0.510053\n",
      "epoch 89; iter: 0; batch classifier loss: 0.104073; batch adversarial loss: 0.487104\n",
      "epoch 90; iter: 0; batch classifier loss: 0.076958; batch adversarial loss: 0.512100\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050284; batch adversarial loss: 0.520600\n",
      "epoch 92; iter: 0; batch classifier loss: 0.086297; batch adversarial loss: 0.545253\n",
      "epoch 93; iter: 0; batch classifier loss: 0.073610; batch adversarial loss: 0.447195\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062586; batch adversarial loss: 0.487835\n",
      "epoch 95; iter: 0; batch classifier loss: 0.041460; batch adversarial loss: 0.493517\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051355; batch adversarial loss: 0.479493\n",
      "epoch 97; iter: 0; batch classifier loss: 0.025388; batch adversarial loss: 0.417204\n",
      "epoch 98; iter: 0; batch classifier loss: 0.057355; batch adversarial loss: 0.475439\n",
      "epoch 99; iter: 0; batch classifier loss: 0.027712; batch adversarial loss: 0.492906\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048790; batch adversarial loss: 0.358702\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039538; batch adversarial loss: 0.476434\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056640; batch adversarial loss: 0.510980\n",
      "epoch 103; iter: 0; batch classifier loss: 0.027826; batch adversarial loss: 0.478590\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027626; batch adversarial loss: 0.496077\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035994; batch adversarial loss: 0.528107\n",
      "epoch 106; iter: 0; batch classifier loss: 0.021842; batch adversarial loss: 0.577351\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035040; batch adversarial loss: 0.431596\n",
      "epoch 108; iter: 0; batch classifier loss: 0.020391; batch adversarial loss: 0.422756\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064126; batch adversarial loss: 0.483674\n",
      "epoch 110; iter: 0; batch classifier loss: 0.020847; batch adversarial loss: 0.379100\n",
      "epoch 111; iter: 0; batch classifier loss: 0.022418; batch adversarial loss: 0.559181\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024325; batch adversarial loss: 0.393047\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042843; batch adversarial loss: 0.539399\n",
      "epoch 114; iter: 0; batch classifier loss: 0.020146; batch adversarial loss: 0.454892\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035712; batch adversarial loss: 0.497138\n",
      "epoch 116; iter: 0; batch classifier loss: 0.019420; batch adversarial loss: 0.519320\n",
      "epoch 117; iter: 0; batch classifier loss: 0.024554; batch adversarial loss: 0.432062\n",
      "epoch 118; iter: 0; batch classifier loss: 0.015282; batch adversarial loss: 0.470656\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034889; batch adversarial loss: 0.468433\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054675; batch adversarial loss: 0.503564\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027827; batch adversarial loss: 0.437421\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025485; batch adversarial loss: 0.457590\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033616; batch adversarial loss: 0.527338\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042895; batch adversarial loss: 0.455612\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023846; batch adversarial loss: 0.480586\n",
      "epoch 126; iter: 0; batch classifier loss: 0.016321; batch adversarial loss: 0.406975\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043832; batch adversarial loss: 0.457056\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017093; batch adversarial loss: 0.453191\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020896; batch adversarial loss: 0.464761\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042045; batch adversarial loss: 0.504387\n",
      "epoch 131; iter: 0; batch classifier loss: 0.008514; batch adversarial loss: 0.454089\n",
      "epoch 132; iter: 0; batch classifier loss: 0.017517; batch adversarial loss: 0.480870\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035059; batch adversarial loss: 0.453561\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030899; batch adversarial loss: 0.357900\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014352; batch adversarial loss: 0.476079\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026768; batch adversarial loss: 0.554269\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030054; batch adversarial loss: 0.547550\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013730; batch adversarial loss: 0.477841\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017153; batch adversarial loss: 0.454196\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014233; batch adversarial loss: 0.470264\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024716; batch adversarial loss: 0.458575\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045736; batch adversarial loss: 0.418697\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020792; batch adversarial loss: 0.461162\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023125; batch adversarial loss: 0.414247\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016036; batch adversarial loss: 0.483879\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032772; batch adversarial loss: 0.380580\n",
      "epoch 147; iter: 0; batch classifier loss: 0.007895; batch adversarial loss: 0.495960\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024208; batch adversarial loss: 0.529005\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021608; batch adversarial loss: 0.540494\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021871; batch adversarial loss: 0.365880\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015701; batch adversarial loss: 0.450837\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040039; batch adversarial loss: 0.488210\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014927; batch adversarial loss: 0.453760\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019560; batch adversarial loss: 0.468982\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032090; batch adversarial loss: 0.471808\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015579; batch adversarial loss: 0.440297\n",
      "epoch 157; iter: 0; batch classifier loss: 0.045366; batch adversarial loss: 0.493241\n",
      "epoch 158; iter: 0; batch classifier loss: 0.057192; batch adversarial loss: 0.397917\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012325; batch adversarial loss: 0.501607\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008321; batch adversarial loss: 0.565227\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020083; batch adversarial loss: 0.396326\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020470; batch adversarial loss: 0.492285\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033426; batch adversarial loss: 0.446867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.015296; batch adversarial loss: 0.459572\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030448; batch adversarial loss: 0.464799\n",
      "epoch 166; iter: 0; batch classifier loss: 0.048340; batch adversarial loss: 0.541357\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014165; batch adversarial loss: 0.447705\n",
      "epoch 168; iter: 0; batch classifier loss: 0.042658; batch adversarial loss: 0.455741\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018216; batch adversarial loss: 0.515679\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019342; batch adversarial loss: 0.388629\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023439; batch adversarial loss: 0.421410\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009660; batch adversarial loss: 0.486335\n",
      "epoch 173; iter: 0; batch classifier loss: 0.052985; batch adversarial loss: 0.410740\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035834; batch adversarial loss: 0.429376\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021489; batch adversarial loss: 0.429566\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012951; batch adversarial loss: 0.460041\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011450; batch adversarial loss: 0.410847\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037101; batch adversarial loss: 0.440542\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028843; batch adversarial loss: 0.386296\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014476; batch adversarial loss: 0.543241\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020801; batch adversarial loss: 0.471456\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022581; batch adversarial loss: 0.484505\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010645; batch adversarial loss: 0.544069\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012312; batch adversarial loss: 0.437229\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040369; batch adversarial loss: 0.512894\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034575; batch adversarial loss: 0.473890\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026527; batch adversarial loss: 0.392130\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021820; batch adversarial loss: 0.467289\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020547; batch adversarial loss: 0.467714\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021650; batch adversarial loss: 0.500607\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024815; batch adversarial loss: 0.428048\n",
      "epoch 192; iter: 0; batch classifier loss: 0.079931; batch adversarial loss: 0.398920\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018028; batch adversarial loss: 0.372463\n",
      "epoch 194; iter: 0; batch classifier loss: 0.045701; batch adversarial loss: 0.405773\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017305; batch adversarial loss: 0.412687\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032883; batch adversarial loss: 0.442199\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028259; batch adversarial loss: 0.369465\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037516; batch adversarial loss: 0.503737\n",
      "epoch 199; iter: 0; batch classifier loss: 0.040447; batch adversarial loss: 0.452829\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682266; batch adversarial loss: 0.741037\n",
      "epoch 1; iter: 0; batch classifier loss: 0.508171; batch adversarial loss: 0.701308\n",
      "epoch 2; iter: 0; batch classifier loss: 0.422900; batch adversarial loss: 0.683390\n",
      "epoch 3; iter: 0; batch classifier loss: 0.358083; batch adversarial loss: 0.687706\n",
      "epoch 4; iter: 0; batch classifier loss: 0.299040; batch adversarial loss: 0.635033\n",
      "epoch 5; iter: 0; batch classifier loss: 0.329093; batch adversarial loss: 0.584394\n",
      "epoch 6; iter: 0; batch classifier loss: 0.292729; batch adversarial loss: 0.563588\n",
      "epoch 7; iter: 0; batch classifier loss: 0.266837; batch adversarial loss: 0.534960\n",
      "epoch 8; iter: 0; batch classifier loss: 0.230101; batch adversarial loss: 0.535555\n",
      "epoch 9; iter: 0; batch classifier loss: 0.201963; batch adversarial loss: 0.504059\n",
      "epoch 10; iter: 0; batch classifier loss: 0.265314; batch adversarial loss: 0.501947\n",
      "epoch 11; iter: 0; batch classifier loss: 0.220438; batch adversarial loss: 0.458379\n",
      "epoch 12; iter: 0; batch classifier loss: 0.205973; batch adversarial loss: 0.491590\n",
      "epoch 13; iter: 0; batch classifier loss: 0.194268; batch adversarial loss: 0.469381\n",
      "epoch 14; iter: 0; batch classifier loss: 0.202263; batch adversarial loss: 0.384488\n",
      "epoch 15; iter: 0; batch classifier loss: 0.175705; batch adversarial loss: 0.455213\n",
      "epoch 16; iter: 0; batch classifier loss: 0.157554; batch adversarial loss: 0.543578\n",
      "epoch 17; iter: 0; batch classifier loss: 0.167918; batch adversarial loss: 0.529961\n",
      "epoch 18; iter: 0; batch classifier loss: 0.123497; batch adversarial loss: 0.431929\n",
      "epoch 19; iter: 0; batch classifier loss: 0.173007; batch adversarial loss: 0.546652\n",
      "epoch 20; iter: 0; batch classifier loss: 0.187597; batch adversarial loss: 0.342744\n",
      "epoch 21; iter: 0; batch classifier loss: 0.179299; batch adversarial loss: 0.441819\n",
      "epoch 22; iter: 0; batch classifier loss: 0.125356; batch adversarial loss: 0.463463\n",
      "epoch 23; iter: 0; batch classifier loss: 0.204734; batch adversarial loss: 0.419603\n",
      "epoch 24; iter: 0; batch classifier loss: 0.149487; batch adversarial loss: 0.409211\n",
      "epoch 25; iter: 0; batch classifier loss: 0.217809; batch adversarial loss: 0.388443\n",
      "epoch 26; iter: 0; batch classifier loss: 0.134040; batch adversarial loss: 0.441507\n",
      "epoch 27; iter: 0; batch classifier loss: 0.124511; batch adversarial loss: 0.348057\n",
      "epoch 28; iter: 0; batch classifier loss: 0.154996; batch adversarial loss: 0.424743\n",
      "epoch 29; iter: 0; batch classifier loss: 0.123397; batch adversarial loss: 0.369779\n",
      "epoch 30; iter: 0; batch classifier loss: 0.157341; batch adversarial loss: 0.359164\n",
      "epoch 31; iter: 0; batch classifier loss: 0.121872; batch adversarial loss: 0.428494\n",
      "epoch 32; iter: 0; batch classifier loss: 0.123419; batch adversarial loss: 0.343711\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123315; batch adversarial loss: 0.308231\n",
      "epoch 34; iter: 0; batch classifier loss: 0.101357; batch adversarial loss: 0.453738\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161729; batch adversarial loss: 0.419653\n",
      "epoch 36; iter: 0; batch classifier loss: 0.114411; batch adversarial loss: 0.396767\n",
      "epoch 37; iter: 0; batch classifier loss: 0.121333; batch adversarial loss: 0.387057\n",
      "epoch 38; iter: 0; batch classifier loss: 0.089146; batch adversarial loss: 0.418579\n",
      "epoch 39; iter: 0; batch classifier loss: 0.138268; batch adversarial loss: 0.403391\n",
      "epoch 40; iter: 0; batch classifier loss: 0.096393; batch adversarial loss: 0.377268\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135335; batch adversarial loss: 0.490711\n",
      "epoch 42; iter: 0; batch classifier loss: 0.172341; batch adversarial loss: 0.409619\n",
      "epoch 43; iter: 0; batch classifier loss: 0.087709; batch adversarial loss: 0.362176\n",
      "epoch 44; iter: 0; batch classifier loss: 0.082312; batch adversarial loss: 0.316772\n",
      "epoch 45; iter: 0; batch classifier loss: 0.092232; batch adversarial loss: 0.345777\n",
      "epoch 46; iter: 0; batch classifier loss: 0.094627; batch adversarial loss: 0.439303\n",
      "epoch 47; iter: 0; batch classifier loss: 0.117602; batch adversarial loss: 0.442748\n",
      "epoch 48; iter: 0; batch classifier loss: 0.097262; batch adversarial loss: 0.384534\n",
      "epoch 49; iter: 0; batch classifier loss: 0.117025; batch adversarial loss: 0.354944\n",
      "epoch 50; iter: 0; batch classifier loss: 0.088980; batch adversarial loss: 0.426900\n",
      "epoch 51; iter: 0; batch classifier loss: 0.102626; batch adversarial loss: 0.499559\n",
      "epoch 52; iter: 0; batch classifier loss: 0.069885; batch adversarial loss: 0.393305\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096226; batch adversarial loss: 0.409578\n",
      "epoch 54; iter: 0; batch classifier loss: 0.100490; batch adversarial loss: 0.390974\n",
      "epoch 55; iter: 0; batch classifier loss: 0.095919; batch adversarial loss: 0.307427\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081497; batch adversarial loss: 0.323438\n",
      "epoch 57; iter: 0; batch classifier loss: 0.070264; batch adversarial loss: 0.386965\n",
      "epoch 58; iter: 0; batch classifier loss: 0.114824; batch adversarial loss: 0.431617\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081248; batch adversarial loss: 0.386864\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086348; batch adversarial loss: 0.446348\n",
      "epoch 61; iter: 0; batch classifier loss: 0.137347; batch adversarial loss: 0.375482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.058092; batch adversarial loss: 0.422466\n",
      "epoch 63; iter: 0; batch classifier loss: 0.096770; batch adversarial loss: 0.485971\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057841; batch adversarial loss: 0.496316\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070787; batch adversarial loss: 0.459361\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085960; batch adversarial loss: 0.417358\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059208; batch adversarial loss: 0.361510\n",
      "epoch 68; iter: 0; batch classifier loss: 0.097050; batch adversarial loss: 0.459505\n",
      "epoch 69; iter: 0; batch classifier loss: 0.119304; batch adversarial loss: 0.584443\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070345; batch adversarial loss: 0.449343\n",
      "epoch 71; iter: 0; batch classifier loss: 0.085113; batch adversarial loss: 0.432185\n",
      "epoch 72; iter: 0; batch classifier loss: 0.046642; batch adversarial loss: 0.441792\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058294; batch adversarial loss: 0.401663\n",
      "epoch 74; iter: 0; batch classifier loss: 0.065239; batch adversarial loss: 0.488961\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061668; batch adversarial loss: 0.399651\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066148; batch adversarial loss: 0.431480\n",
      "epoch 77; iter: 0; batch classifier loss: 0.051322; batch adversarial loss: 0.332281\n",
      "epoch 78; iter: 0; batch classifier loss: 0.055205; batch adversarial loss: 0.453228\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060956; batch adversarial loss: 0.437787\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075477; batch adversarial loss: 0.501730\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064681; batch adversarial loss: 0.424251\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073997; batch adversarial loss: 0.362347\n",
      "epoch 83; iter: 0; batch classifier loss: 0.076045; batch adversarial loss: 0.471427\n",
      "epoch 84; iter: 0; batch classifier loss: 0.058406; batch adversarial loss: 0.442240\n",
      "epoch 85; iter: 0; batch classifier loss: 0.116781; batch adversarial loss: 0.387380\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064285; batch adversarial loss: 0.389342\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056613; batch adversarial loss: 0.396601\n",
      "epoch 88; iter: 0; batch classifier loss: 0.079523; batch adversarial loss: 0.452425\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068328; batch adversarial loss: 0.367477\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061785; batch adversarial loss: 0.460502\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059196; batch adversarial loss: 0.415597\n",
      "epoch 92; iter: 0; batch classifier loss: 0.037661; batch adversarial loss: 0.330779\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046693; batch adversarial loss: 0.404503\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043873; batch adversarial loss: 0.456718\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057464; batch adversarial loss: 0.403887\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049522; batch adversarial loss: 0.534127\n",
      "epoch 97; iter: 0; batch classifier loss: 0.041396; batch adversarial loss: 0.472373\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050851; batch adversarial loss: 0.402252\n",
      "epoch 99; iter: 0; batch classifier loss: 0.025592; batch adversarial loss: 0.400950\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056362; batch adversarial loss: 0.449582\n",
      "epoch 101; iter: 0; batch classifier loss: 0.033392; batch adversarial loss: 0.508317\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053958; batch adversarial loss: 0.464547\n",
      "epoch 103; iter: 0; batch classifier loss: 0.021593; batch adversarial loss: 0.543588\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027817; batch adversarial loss: 0.483513\n",
      "epoch 105; iter: 0; batch classifier loss: 0.036466; batch adversarial loss: 0.490447\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064222; batch adversarial loss: 0.513238\n",
      "epoch 107; iter: 0; batch classifier loss: 0.023600; batch adversarial loss: 0.510796\n",
      "epoch 108; iter: 0; batch classifier loss: 0.023099; batch adversarial loss: 0.522545\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033103; batch adversarial loss: 0.501807\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028283; batch adversarial loss: 0.492501\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030385; batch adversarial loss: 0.374997\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038025; batch adversarial loss: 0.521434\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037029; batch adversarial loss: 0.494769\n",
      "epoch 114; iter: 0; batch classifier loss: 0.025652; batch adversarial loss: 0.482322\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057066; batch adversarial loss: 0.451950\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029001; batch adversarial loss: 0.529530\n",
      "epoch 117; iter: 0; batch classifier loss: 0.054301; batch adversarial loss: 0.581158\n",
      "epoch 118; iter: 0; batch classifier loss: 0.089412; batch adversarial loss: 0.641353\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038411; batch adversarial loss: 0.482169\n",
      "epoch 120; iter: 0; batch classifier loss: 0.117604; batch adversarial loss: 0.569293\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050266; batch adversarial loss: 0.560882\n",
      "epoch 122; iter: 0; batch classifier loss: 0.145198; batch adversarial loss: 0.549474\n",
      "epoch 123; iter: 0; batch classifier loss: 0.080096; batch adversarial loss: 0.585230\n",
      "epoch 124; iter: 0; batch classifier loss: 0.106840; batch adversarial loss: 0.611216\n",
      "epoch 125; iter: 0; batch classifier loss: 0.146815; batch adversarial loss: 0.668117\n",
      "epoch 126; iter: 0; batch classifier loss: 0.105130; batch adversarial loss: 0.605594\n",
      "epoch 127; iter: 0; batch classifier loss: 0.079937; batch adversarial loss: 0.494751\n",
      "epoch 128; iter: 0; batch classifier loss: 0.158464; batch adversarial loss: 0.588994\n",
      "epoch 129; iter: 0; batch classifier loss: 0.161024; batch adversarial loss: 0.688313\n",
      "epoch 130; iter: 0; batch classifier loss: 0.152293; batch adversarial loss: 0.601576\n",
      "epoch 131; iter: 0; batch classifier loss: 0.128047; batch adversarial loss: 0.599598\n",
      "epoch 132; iter: 0; batch classifier loss: 0.130897; batch adversarial loss: 0.531351\n",
      "epoch 133; iter: 0; batch classifier loss: 0.180994; batch adversarial loss: 0.717857\n",
      "epoch 134; iter: 0; batch classifier loss: 0.217326; batch adversarial loss: 0.736249\n",
      "epoch 135; iter: 0; batch classifier loss: 0.172889; batch adversarial loss: 0.561722\n",
      "epoch 136; iter: 0; batch classifier loss: 0.176536; batch adversarial loss: 0.583894\n",
      "epoch 137; iter: 0; batch classifier loss: 0.241996; batch adversarial loss: 0.748676\n",
      "epoch 138; iter: 0; batch classifier loss: 0.190308; batch adversarial loss: 0.601749\n",
      "epoch 139; iter: 0; batch classifier loss: 0.201602; batch adversarial loss: 0.701905\n",
      "epoch 140; iter: 0; batch classifier loss: 0.197167; batch adversarial loss: 0.611177\n",
      "epoch 141; iter: 0; batch classifier loss: 0.173495; batch adversarial loss: 0.562494\n",
      "epoch 142; iter: 0; batch classifier loss: 0.168093; batch adversarial loss: 0.675010\n",
      "epoch 143; iter: 0; batch classifier loss: 0.186868; batch adversarial loss: 0.604424\n",
      "epoch 144; iter: 0; batch classifier loss: 0.107821; batch adversarial loss: 0.425065\n",
      "epoch 145; iter: 0; batch classifier loss: 0.093974; batch adversarial loss: 0.464102\n",
      "epoch 146; iter: 0; batch classifier loss: 0.174420; batch adversarial loss: 0.665370\n",
      "epoch 147; iter: 0; batch classifier loss: 0.083043; batch adversarial loss: 0.415063\n",
      "epoch 148; iter: 0; batch classifier loss: 0.134328; batch adversarial loss: 0.543852\n",
      "epoch 149; iter: 0; batch classifier loss: 0.142480; batch adversarial loss: 0.497165\n",
      "epoch 150; iter: 0; batch classifier loss: 0.123187; batch adversarial loss: 0.428067\n",
      "epoch 151; iter: 0; batch classifier loss: 0.133597; batch adversarial loss: 0.578200\n",
      "epoch 152; iter: 0; batch classifier loss: 0.183672; batch adversarial loss: 0.556442\n",
      "epoch 153; iter: 0; batch classifier loss: 0.110743; batch adversarial loss: 0.480908\n",
      "epoch 154; iter: 0; batch classifier loss: 0.118282; batch adversarial loss: 0.498917\n",
      "epoch 155; iter: 0; batch classifier loss: 0.122153; batch adversarial loss: 0.463594\n",
      "epoch 156; iter: 0; batch classifier loss: 0.104596; batch adversarial loss: 0.443902\n",
      "epoch 157; iter: 0; batch classifier loss: 0.124193; batch adversarial loss: 0.505373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.110566; batch adversarial loss: 0.523198\n",
      "epoch 159; iter: 0; batch classifier loss: 0.132369; batch adversarial loss: 0.480489\n",
      "epoch 160; iter: 0; batch classifier loss: 0.165640; batch adversarial loss: 0.486027\n",
      "epoch 161; iter: 0; batch classifier loss: 0.166840; batch adversarial loss: 0.522594\n",
      "epoch 162; iter: 0; batch classifier loss: 0.164548; batch adversarial loss: 0.566778\n",
      "epoch 163; iter: 0; batch classifier loss: 0.109622; batch adversarial loss: 0.466160\n",
      "epoch 164; iter: 0; batch classifier loss: 0.172320; batch adversarial loss: 0.461207\n",
      "epoch 165; iter: 0; batch classifier loss: 0.109881; batch adversarial loss: 0.483630\n",
      "epoch 166; iter: 0; batch classifier loss: 0.093904; batch adversarial loss: 0.407629\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041292; batch adversarial loss: 0.491231\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024947; batch adversarial loss: 0.445068\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025318; batch adversarial loss: 0.372053\n",
      "epoch 170; iter: 0; batch classifier loss: 0.045343; batch adversarial loss: 0.461365\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031048; batch adversarial loss: 0.507524\n",
      "epoch 172; iter: 0; batch classifier loss: 0.057160; batch adversarial loss: 0.467438\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040571; batch adversarial loss: 0.398203\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036597; batch adversarial loss: 0.611745\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029195; batch adversarial loss: 0.514376\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045988; batch adversarial loss: 0.460893\n",
      "epoch 177; iter: 0; batch classifier loss: 0.067310; batch adversarial loss: 0.487797\n",
      "epoch 178; iter: 0; batch classifier loss: 0.059018; batch adversarial loss: 0.495071\n",
      "epoch 179; iter: 0; batch classifier loss: 0.074679; batch adversarial loss: 0.444250\n",
      "epoch 180; iter: 0; batch classifier loss: 0.050806; batch adversarial loss: 0.516428\n",
      "epoch 181; iter: 0; batch classifier loss: 0.078463; batch adversarial loss: 0.569120\n",
      "epoch 182; iter: 0; batch classifier loss: 0.126570; batch adversarial loss: 0.430714\n",
      "epoch 183; iter: 0; batch classifier loss: 0.056910; batch adversarial loss: 0.432812\n",
      "epoch 184; iter: 0; batch classifier loss: 0.102611; batch adversarial loss: 0.454404\n",
      "epoch 185; iter: 0; batch classifier loss: 0.070186; batch adversarial loss: 0.458546\n",
      "epoch 186; iter: 0; batch classifier loss: 0.084335; batch adversarial loss: 0.436777\n",
      "epoch 187; iter: 0; batch classifier loss: 0.098405; batch adversarial loss: 0.423755\n",
      "epoch 188; iter: 0; batch classifier loss: 0.083151; batch adversarial loss: 0.472491\n",
      "epoch 189; iter: 0; batch classifier loss: 0.115049; batch adversarial loss: 0.422843\n",
      "epoch 190; iter: 0; batch classifier loss: 0.112990; batch adversarial loss: 0.470706\n",
      "epoch 191; iter: 0; batch classifier loss: 0.115019; batch adversarial loss: 0.523738\n",
      "epoch 192; iter: 0; batch classifier loss: 0.098707; batch adversarial loss: 0.452067\n",
      "epoch 193; iter: 0; batch classifier loss: 0.073644; batch adversarial loss: 0.451544\n",
      "epoch 194; iter: 0; batch classifier loss: 0.067401; batch adversarial loss: 0.428049\n",
      "epoch 195; iter: 0; batch classifier loss: 0.102942; batch adversarial loss: 0.372778\n",
      "epoch 196; iter: 0; batch classifier loss: 0.138403; batch adversarial loss: 0.432324\n",
      "epoch 197; iter: 0; batch classifier loss: 0.078271; batch adversarial loss: 0.501774\n",
      "epoch 198; iter: 0; batch classifier loss: 0.102270; batch adversarial loss: 0.434174\n",
      "epoch 199; iter: 0; batch classifier loss: 0.093354; batch adversarial loss: 0.534733\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677193; batch adversarial loss: 0.654315\n",
      "epoch 1; iter: 0; batch classifier loss: 0.333529; batch adversarial loss: 0.612971\n",
      "epoch 2; iter: 0; batch classifier loss: 0.394121; batch adversarial loss: 0.611850\n",
      "epoch 3; iter: 0; batch classifier loss: 0.382953; batch adversarial loss: 0.545729\n",
      "epoch 4; iter: 0; batch classifier loss: 0.369032; batch adversarial loss: 0.537555\n",
      "epoch 5; iter: 0; batch classifier loss: 0.274088; batch adversarial loss: 0.575459\n",
      "epoch 6; iter: 0; batch classifier loss: 0.347792; batch adversarial loss: 0.571083\n",
      "epoch 7; iter: 0; batch classifier loss: 0.313299; batch adversarial loss: 0.520516\n",
      "epoch 8; iter: 0; batch classifier loss: 0.213119; batch adversarial loss: 0.531875\n",
      "epoch 9; iter: 0; batch classifier loss: 0.283338; batch adversarial loss: 0.495844\n",
      "epoch 10; iter: 0; batch classifier loss: 0.230667; batch adversarial loss: 0.493266\n",
      "epoch 11; iter: 0; batch classifier loss: 0.149755; batch adversarial loss: 0.492330\n",
      "epoch 12; iter: 0; batch classifier loss: 0.197081; batch adversarial loss: 0.558015\n",
      "epoch 13; iter: 0; batch classifier loss: 0.192178; batch adversarial loss: 0.557440\n",
      "epoch 14; iter: 0; batch classifier loss: 0.218882; batch adversarial loss: 0.523685\n",
      "epoch 15; iter: 0; batch classifier loss: 0.221338; batch adversarial loss: 0.459764\n",
      "epoch 16; iter: 0; batch classifier loss: 0.255761; batch adversarial loss: 0.530119\n",
      "epoch 17; iter: 0; batch classifier loss: 0.244832; batch adversarial loss: 0.458179\n",
      "epoch 18; iter: 0; batch classifier loss: 0.204761; batch adversarial loss: 0.523681\n",
      "epoch 19; iter: 0; batch classifier loss: 0.269977; batch adversarial loss: 0.575101\n",
      "epoch 20; iter: 0; batch classifier loss: 0.288372; batch adversarial loss: 0.524334\n",
      "epoch 21; iter: 0; batch classifier loss: 0.321059; batch adversarial loss: 0.560802\n",
      "epoch 22; iter: 0; batch classifier loss: 0.258478; batch adversarial loss: 0.523763\n",
      "epoch 23; iter: 0; batch classifier loss: 0.253430; batch adversarial loss: 0.489345\n",
      "epoch 24; iter: 0; batch classifier loss: 0.383659; batch adversarial loss: 0.571821\n",
      "epoch 25; iter: 0; batch classifier loss: 0.344122; batch adversarial loss: 0.492491\n",
      "epoch 26; iter: 0; batch classifier loss: 0.261503; batch adversarial loss: 0.516945\n",
      "epoch 27; iter: 0; batch classifier loss: 0.121703; batch adversarial loss: 0.497803\n",
      "epoch 28; iter: 0; batch classifier loss: 0.152192; batch adversarial loss: 0.496136\n",
      "epoch 29; iter: 0; batch classifier loss: 0.117134; batch adversarial loss: 0.477017\n",
      "epoch 30; iter: 0; batch classifier loss: 0.176939; batch adversarial loss: 0.475945\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156223; batch adversarial loss: 0.520005\n",
      "epoch 32; iter: 0; batch classifier loss: 0.118847; batch adversarial loss: 0.498866\n",
      "epoch 33; iter: 0; batch classifier loss: 0.120153; batch adversarial loss: 0.496555\n",
      "epoch 34; iter: 0; batch classifier loss: 0.089988; batch adversarial loss: 0.500296\n",
      "epoch 35; iter: 0; batch classifier loss: 0.128093; batch adversarial loss: 0.431672\n",
      "epoch 36; iter: 0; batch classifier loss: 0.074473; batch adversarial loss: 0.507964\n",
      "epoch 37; iter: 0; batch classifier loss: 0.097064; batch adversarial loss: 0.397758\n",
      "epoch 38; iter: 0; batch classifier loss: 0.153202; batch adversarial loss: 0.424803\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126756; batch adversarial loss: 0.430471\n",
      "epoch 40; iter: 0; batch classifier loss: 0.067217; batch adversarial loss: 0.517374\n",
      "epoch 41; iter: 0; batch classifier loss: 0.133302; batch adversarial loss: 0.448022\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088856; batch adversarial loss: 0.473043\n",
      "epoch 43; iter: 0; batch classifier loss: 0.063286; batch adversarial loss: 0.541160\n",
      "epoch 44; iter: 0; batch classifier loss: 0.134777; batch adversarial loss: 0.434163\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099152; batch adversarial loss: 0.513063\n",
      "epoch 46; iter: 0; batch classifier loss: 0.096231; batch adversarial loss: 0.502339\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113269; batch adversarial loss: 0.538101\n",
      "epoch 48; iter: 0; batch classifier loss: 0.112389; batch adversarial loss: 0.447671\n",
      "epoch 49; iter: 0; batch classifier loss: 0.097530; batch adversarial loss: 0.538295\n",
      "epoch 50; iter: 0; batch classifier loss: 0.082011; batch adversarial loss: 0.503980\n",
      "epoch 51; iter: 0; batch classifier loss: 0.076092; batch adversarial loss: 0.423858\n",
      "epoch 52; iter: 0; batch classifier loss: 0.080912; batch adversarial loss: 0.496464\n",
      "epoch 53; iter: 0; batch classifier loss: 0.082377; batch adversarial loss: 0.467245\n",
      "epoch 54; iter: 0; batch classifier loss: 0.098993; batch adversarial loss: 0.374152\n",
      "epoch 55; iter: 0; batch classifier loss: 0.059472; batch adversarial loss: 0.457519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.069901; batch adversarial loss: 0.538085\n",
      "epoch 57; iter: 0; batch classifier loss: 0.059935; batch adversarial loss: 0.469509\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077010; batch adversarial loss: 0.383679\n",
      "epoch 59; iter: 0; batch classifier loss: 0.064505; batch adversarial loss: 0.443429\n",
      "epoch 60; iter: 0; batch classifier loss: 0.127710; batch adversarial loss: 0.437690\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091084; batch adversarial loss: 0.438890\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101101; batch adversarial loss: 0.447963\n",
      "epoch 63; iter: 0; batch classifier loss: 0.109999; batch adversarial loss: 0.478384\n",
      "epoch 64; iter: 0; batch classifier loss: 0.138539; batch adversarial loss: 0.390568\n",
      "epoch 65; iter: 0; batch classifier loss: 0.085416; batch adversarial loss: 0.427895\n",
      "epoch 66; iter: 0; batch classifier loss: 0.079140; batch adversarial loss: 0.493928\n",
      "epoch 67; iter: 0; batch classifier loss: 0.070258; batch adversarial loss: 0.442297\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084731; batch adversarial loss: 0.536047\n",
      "epoch 69; iter: 0; batch classifier loss: 0.110061; batch adversarial loss: 0.436492\n",
      "epoch 70; iter: 0; batch classifier loss: 0.126309; batch adversarial loss: 0.441184\n",
      "epoch 71; iter: 0; batch classifier loss: 0.094665; batch adversarial loss: 0.418558\n",
      "epoch 72; iter: 0; batch classifier loss: 0.073789; batch adversarial loss: 0.575101\n",
      "epoch 73; iter: 0; batch classifier loss: 0.070990; batch adversarial loss: 0.468223\n",
      "epoch 74; iter: 0; batch classifier loss: 0.090494; batch adversarial loss: 0.493084\n",
      "epoch 75; iter: 0; batch classifier loss: 0.078707; batch adversarial loss: 0.477570\n",
      "epoch 76; iter: 0; batch classifier loss: 0.098374; batch adversarial loss: 0.438476\n",
      "epoch 77; iter: 0; batch classifier loss: 0.089896; batch adversarial loss: 0.497603\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073895; batch adversarial loss: 0.495501\n",
      "epoch 79; iter: 0; batch classifier loss: 0.119716; batch adversarial loss: 0.485562\n",
      "epoch 80; iter: 0; batch classifier loss: 0.115685; batch adversarial loss: 0.513538\n",
      "epoch 81; iter: 0; batch classifier loss: 0.090675; batch adversarial loss: 0.457460\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062869; batch adversarial loss: 0.517549\n",
      "epoch 83; iter: 0; batch classifier loss: 0.097884; batch adversarial loss: 0.527852\n",
      "epoch 84; iter: 0; batch classifier loss: 0.091354; batch adversarial loss: 0.473809\n",
      "epoch 85; iter: 0; batch classifier loss: 0.111444; batch adversarial loss: 0.544018\n",
      "epoch 86; iter: 0; batch classifier loss: 0.129086; batch adversarial loss: 0.450686\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083546; batch adversarial loss: 0.440188\n",
      "epoch 88; iter: 0; batch classifier loss: 0.039648; batch adversarial loss: 0.535264\n",
      "epoch 89; iter: 0; batch classifier loss: 0.124112; batch adversarial loss: 0.521720\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061400; batch adversarial loss: 0.594187\n",
      "epoch 91; iter: 0; batch classifier loss: 0.140490; batch adversarial loss: 0.492330\n",
      "epoch 92; iter: 0; batch classifier loss: 0.130645; batch adversarial loss: 0.445747\n",
      "epoch 93; iter: 0; batch classifier loss: 0.088861; batch adversarial loss: 0.363641\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058333; batch adversarial loss: 0.506747\n",
      "epoch 95; iter: 0; batch classifier loss: 0.098092; batch adversarial loss: 0.476755\n",
      "epoch 96; iter: 0; batch classifier loss: 0.124467; batch adversarial loss: 0.446574\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062254; batch adversarial loss: 0.479900\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061568; batch adversarial loss: 0.431372\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055174; batch adversarial loss: 0.582268\n",
      "epoch 100; iter: 0; batch classifier loss: 0.135359; batch adversarial loss: 0.503086\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054162; batch adversarial loss: 0.486790\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052195; batch adversarial loss: 0.487619\n",
      "epoch 103; iter: 0; batch classifier loss: 0.073324; batch adversarial loss: 0.458889\n",
      "epoch 104; iter: 0; batch classifier loss: 0.087420; batch adversarial loss: 0.582991\n",
      "epoch 105; iter: 0; batch classifier loss: 0.068437; batch adversarial loss: 0.529479\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071656; batch adversarial loss: 0.452568\n",
      "epoch 107; iter: 0; batch classifier loss: 0.098492; batch adversarial loss: 0.415874\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045781; batch adversarial loss: 0.498882\n",
      "epoch 109; iter: 0; batch classifier loss: 0.078912; batch adversarial loss: 0.511087\n",
      "epoch 110; iter: 0; batch classifier loss: 0.089799; batch adversarial loss: 0.395192\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059810; batch adversarial loss: 0.470223\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052625; batch adversarial loss: 0.458672\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044548; batch adversarial loss: 0.391410\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057628; batch adversarial loss: 0.474098\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034646; batch adversarial loss: 0.497749\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039007; batch adversarial loss: 0.399517\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045359; batch adversarial loss: 0.464270\n",
      "epoch 118; iter: 0; batch classifier loss: 0.075852; batch adversarial loss: 0.523751\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019348; batch adversarial loss: 0.443067\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036459; batch adversarial loss: 0.525633\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044569; batch adversarial loss: 0.467001\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062447; batch adversarial loss: 0.429330\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023805; batch adversarial loss: 0.451710\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020464; batch adversarial loss: 0.632812\n",
      "epoch 125; iter: 0; batch classifier loss: 0.016458; batch adversarial loss: 0.464320\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050132; batch adversarial loss: 0.366669\n",
      "epoch 127; iter: 0; batch classifier loss: 0.070531; batch adversarial loss: 0.497130\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051054; batch adversarial loss: 0.486580\n",
      "epoch 129; iter: 0; batch classifier loss: 0.054916; batch adversarial loss: 0.539068\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038771; batch adversarial loss: 0.458559\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038030; batch adversarial loss: 0.500281\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040272; batch adversarial loss: 0.466612\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055421; batch adversarial loss: 0.573704\n",
      "epoch 134; iter: 0; batch classifier loss: 0.063339; batch adversarial loss: 0.499685\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040543; batch adversarial loss: 0.426714\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022283; batch adversarial loss: 0.520039\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021862; batch adversarial loss: 0.446955\n",
      "epoch 138; iter: 0; batch classifier loss: 0.008558; batch adversarial loss: 0.401709\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020368; batch adversarial loss: 0.523150\n",
      "epoch 140; iter: 0; batch classifier loss: 0.058270; batch adversarial loss: 0.414306\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036520; batch adversarial loss: 0.402342\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032716; batch adversarial loss: 0.384110\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022079; batch adversarial loss: 0.470149\n",
      "epoch 144; iter: 0; batch classifier loss: 0.035484; batch adversarial loss: 0.463686\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039123; batch adversarial loss: 0.521528\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016892; batch adversarial loss: 0.521914\n",
      "epoch 147; iter: 0; batch classifier loss: 0.060450; batch adversarial loss: 0.467015\n",
      "epoch 148; iter: 0; batch classifier loss: 0.056890; batch adversarial loss: 0.470299\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046377; batch adversarial loss: 0.474380\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033115; batch adversarial loss: 0.298448\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034755; batch adversarial loss: 0.508089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.036796; batch adversarial loss: 0.486873\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037768; batch adversarial loss: 0.443974\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035894; batch adversarial loss: 0.484788\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018554; batch adversarial loss: 0.515536\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021618; batch adversarial loss: 0.452894\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031485; batch adversarial loss: 0.565448\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028698; batch adversarial loss: 0.498432\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020168; batch adversarial loss: 0.506302\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009996; batch adversarial loss: 0.408798\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017596; batch adversarial loss: 0.559347\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029488; batch adversarial loss: 0.459058\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037282; batch adversarial loss: 0.512016\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023264; batch adversarial loss: 0.413909\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016346; batch adversarial loss: 0.458674\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018951; batch adversarial loss: 0.579202\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021106; batch adversarial loss: 0.418743\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023567; batch adversarial loss: 0.494823\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022423; batch adversarial loss: 0.559380\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031483; batch adversarial loss: 0.464940\n",
      "epoch 171; iter: 0; batch classifier loss: 0.055974; batch adversarial loss: 0.478951\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005685; batch adversarial loss: 0.459670\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014729; batch adversarial loss: 0.516058\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011496; batch adversarial loss: 0.431170\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027970; batch adversarial loss: 0.503236\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012360; batch adversarial loss: 0.422347\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027847; batch adversarial loss: 0.422953\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029261; batch adversarial loss: 0.449229\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009062; batch adversarial loss: 0.432716\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021944; batch adversarial loss: 0.360979\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035307; batch adversarial loss: 0.446492\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006471; batch adversarial loss: 0.609512\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024562; batch adversarial loss: 0.399911\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040227; batch adversarial loss: 0.452861\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013005; batch adversarial loss: 0.477457\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010951; batch adversarial loss: 0.510781\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028341; batch adversarial loss: 0.472343\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041717; batch adversarial loss: 0.504892\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022275; batch adversarial loss: 0.398237\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036389; batch adversarial loss: 0.419313\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018615; batch adversarial loss: 0.412011\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011323; batch adversarial loss: 0.497296\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022261; batch adversarial loss: 0.462163\n",
      "epoch 194; iter: 0; batch classifier loss: 0.064936; batch adversarial loss: 0.469918\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009873; batch adversarial loss: 0.530792\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030357; batch adversarial loss: 0.447816\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017775; batch adversarial loss: 0.422830\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017485; batch adversarial loss: 0.418895\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014412; batch adversarial loss: 0.400326\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704259; batch adversarial loss: 0.838311\n",
      "epoch 1; iter: 0; batch classifier loss: 0.344458; batch adversarial loss: 0.791009\n",
      "epoch 2; iter: 0; batch classifier loss: 0.450334; batch adversarial loss: 0.748511\n",
      "epoch 3; iter: 0; batch classifier loss: 0.342333; batch adversarial loss: 0.683957\n",
      "epoch 4; iter: 0; batch classifier loss: 0.354001; batch adversarial loss: 0.691207\n",
      "epoch 5; iter: 0; batch classifier loss: 0.398756; batch adversarial loss: 0.643684\n",
      "epoch 6; iter: 0; batch classifier loss: 0.356436; batch adversarial loss: 0.589903\n",
      "epoch 7; iter: 0; batch classifier loss: 0.344091; batch adversarial loss: 0.586620\n",
      "epoch 8; iter: 0; batch classifier loss: 0.252719; batch adversarial loss: 0.570303\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282891; batch adversarial loss: 0.526681\n",
      "epoch 10; iter: 0; batch classifier loss: 0.271648; batch adversarial loss: 0.583557\n",
      "epoch 11; iter: 0; batch classifier loss: 0.258977; batch adversarial loss: 0.502832\n",
      "epoch 12; iter: 0; batch classifier loss: 0.239366; batch adversarial loss: 0.511803\n",
      "epoch 13; iter: 0; batch classifier loss: 0.303659; batch adversarial loss: 0.454799\n",
      "epoch 14; iter: 0; batch classifier loss: 0.267475; batch adversarial loss: 0.436845\n",
      "epoch 15; iter: 0; batch classifier loss: 0.256737; batch adversarial loss: 0.433141\n",
      "epoch 16; iter: 0; batch classifier loss: 0.223649; batch adversarial loss: 0.447451\n",
      "epoch 17; iter: 0; batch classifier loss: 0.226101; batch adversarial loss: 0.446726\n",
      "epoch 18; iter: 0; batch classifier loss: 0.302367; batch adversarial loss: 0.383285\n",
      "epoch 19; iter: 0; batch classifier loss: 0.252389; batch adversarial loss: 0.349284\n",
      "epoch 20; iter: 0; batch classifier loss: 0.184499; batch adversarial loss: 0.407550\n",
      "epoch 21; iter: 0; batch classifier loss: 0.289840; batch adversarial loss: 0.358493\n",
      "epoch 22; iter: 0; batch classifier loss: 0.296274; batch adversarial loss: 0.430306\n",
      "epoch 23; iter: 0; batch classifier loss: 0.250013; batch adversarial loss: 0.459551\n",
      "epoch 24; iter: 0; batch classifier loss: 0.193603; batch adversarial loss: 0.387104\n",
      "epoch 25; iter: 0; batch classifier loss: 0.232398; batch adversarial loss: 0.388523\n",
      "epoch 26; iter: 0; batch classifier loss: 0.197555; batch adversarial loss: 0.394290\n",
      "epoch 27; iter: 0; batch classifier loss: 0.196180; batch adversarial loss: 0.378467\n",
      "epoch 28; iter: 0; batch classifier loss: 0.147574; batch adversarial loss: 0.455051\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178666; batch adversarial loss: 0.364733\n",
      "epoch 30; iter: 0; batch classifier loss: 0.127208; batch adversarial loss: 0.408229\n",
      "epoch 31; iter: 0; batch classifier loss: 0.169083; batch adversarial loss: 0.350826\n",
      "epoch 32; iter: 0; batch classifier loss: 0.173652; batch adversarial loss: 0.449731\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163309; batch adversarial loss: 0.368887\n",
      "epoch 34; iter: 0; batch classifier loss: 0.145985; batch adversarial loss: 0.383970\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122644; batch adversarial loss: 0.396682\n",
      "epoch 36; iter: 0; batch classifier loss: 0.129202; batch adversarial loss: 0.369491\n",
      "epoch 37; iter: 0; batch classifier loss: 0.138543; batch adversarial loss: 0.461395\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117113; batch adversarial loss: 0.472271\n",
      "epoch 39; iter: 0; batch classifier loss: 0.133111; batch adversarial loss: 0.415105\n",
      "epoch 40; iter: 0; batch classifier loss: 0.112253; batch adversarial loss: 0.396652\n",
      "epoch 41; iter: 0; batch classifier loss: 0.143938; batch adversarial loss: 0.416032\n",
      "epoch 42; iter: 0; batch classifier loss: 0.100984; batch adversarial loss: 0.332844\n",
      "epoch 43; iter: 0; batch classifier loss: 0.085489; batch adversarial loss: 0.362117\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118066; batch adversarial loss: 0.437391\n",
      "epoch 45; iter: 0; batch classifier loss: 0.110899; batch adversarial loss: 0.452383\n",
      "epoch 46; iter: 0; batch classifier loss: 0.075611; batch adversarial loss: 0.404745\n",
      "epoch 47; iter: 0; batch classifier loss: 0.125410; batch adversarial loss: 0.469253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.090379; batch adversarial loss: 0.451094\n",
      "epoch 49; iter: 0; batch classifier loss: 0.102925; batch adversarial loss: 0.468340\n",
      "epoch 50; iter: 0; batch classifier loss: 0.114280; batch adversarial loss: 0.525803\n",
      "epoch 51; iter: 0; batch classifier loss: 0.165344; batch adversarial loss: 0.421187\n",
      "epoch 52; iter: 0; batch classifier loss: 0.179824; batch adversarial loss: 0.489569\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122529; batch adversarial loss: 0.356008\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129895; batch adversarial loss: 0.390648\n",
      "epoch 55; iter: 0; batch classifier loss: 0.111184; batch adversarial loss: 0.452198\n",
      "epoch 56; iter: 0; batch classifier loss: 0.075679; batch adversarial loss: 0.392069\n",
      "epoch 57; iter: 0; batch classifier loss: 0.133827; batch adversarial loss: 0.472373\n",
      "epoch 58; iter: 0; batch classifier loss: 0.063854; batch adversarial loss: 0.423958\n",
      "epoch 59; iter: 0; batch classifier loss: 0.110946; batch adversarial loss: 0.496664\n",
      "epoch 60; iter: 0; batch classifier loss: 0.098403; batch adversarial loss: 0.435773\n",
      "epoch 61; iter: 0; batch classifier loss: 0.079836; batch adversarial loss: 0.417717\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101859; batch adversarial loss: 0.422033\n",
      "epoch 63; iter: 0; batch classifier loss: 0.105685; batch adversarial loss: 0.494267\n",
      "epoch 64; iter: 0; batch classifier loss: 0.108639; batch adversarial loss: 0.511716\n",
      "epoch 65; iter: 0; batch classifier loss: 0.096673; batch adversarial loss: 0.403624\n",
      "epoch 66; iter: 0; batch classifier loss: 0.094714; batch adversarial loss: 0.344899\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080556; batch adversarial loss: 0.334581\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061180; batch adversarial loss: 0.467370\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076631; batch adversarial loss: 0.371494\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070081; batch adversarial loss: 0.491189\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097040; batch adversarial loss: 0.428228\n",
      "epoch 72; iter: 0; batch classifier loss: 0.049133; batch adversarial loss: 0.468393\n",
      "epoch 73; iter: 0; batch classifier loss: 0.121274; batch adversarial loss: 0.403196\n",
      "epoch 74; iter: 0; batch classifier loss: 0.056614; batch adversarial loss: 0.457205\n",
      "epoch 75; iter: 0; batch classifier loss: 0.098249; batch adversarial loss: 0.413913\n",
      "epoch 76; iter: 0; batch classifier loss: 0.054608; batch adversarial loss: 0.366535\n",
      "epoch 77; iter: 0; batch classifier loss: 0.079351; batch adversarial loss: 0.463429\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085305; batch adversarial loss: 0.399344\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057566; batch adversarial loss: 0.335411\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087099; batch adversarial loss: 0.390778\n",
      "epoch 81; iter: 0; batch classifier loss: 0.103569; batch adversarial loss: 0.499359\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053056; batch adversarial loss: 0.509547\n",
      "epoch 83; iter: 0; batch classifier loss: 0.036970; batch adversarial loss: 0.332864\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075692; batch adversarial loss: 0.463505\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073266; batch adversarial loss: 0.297792\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076945; batch adversarial loss: 0.482103\n",
      "epoch 87; iter: 0; batch classifier loss: 0.074459; batch adversarial loss: 0.478730\n",
      "epoch 88; iter: 0; batch classifier loss: 0.087837; batch adversarial loss: 0.397755\n",
      "epoch 89; iter: 0; batch classifier loss: 0.064437; batch adversarial loss: 0.409738\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054601; batch adversarial loss: 0.404227\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059267; batch adversarial loss: 0.364553\n",
      "epoch 92; iter: 0; batch classifier loss: 0.046678; batch adversarial loss: 0.321238\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044237; batch adversarial loss: 0.429236\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072746; batch adversarial loss: 0.463544\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066702; batch adversarial loss: 0.463899\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064863; batch adversarial loss: 0.406846\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066075; batch adversarial loss: 0.414531\n",
      "epoch 98; iter: 0; batch classifier loss: 0.064765; batch adversarial loss: 0.335289\n",
      "epoch 99; iter: 0; batch classifier loss: 0.098602; batch adversarial loss: 0.462900\n",
      "epoch 100; iter: 0; batch classifier loss: 0.069754; batch adversarial loss: 0.373705\n",
      "epoch 101; iter: 0; batch classifier loss: 0.064732; batch adversarial loss: 0.326506\n",
      "epoch 102; iter: 0; batch classifier loss: 0.065217; batch adversarial loss: 0.428949\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050013; batch adversarial loss: 0.427478\n",
      "epoch 104; iter: 0; batch classifier loss: 0.042634; batch adversarial loss: 0.440498\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050194; batch adversarial loss: 0.459274\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059831; batch adversarial loss: 0.461401\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065305; batch adversarial loss: 0.373942\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041547; batch adversarial loss: 0.378446\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051289; batch adversarial loss: 0.472088\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028385; batch adversarial loss: 0.414740\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040757; batch adversarial loss: 0.517257\n",
      "epoch 112; iter: 0; batch classifier loss: 0.050464; batch adversarial loss: 0.423296\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055174; batch adversarial loss: 0.370329\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046411; batch adversarial loss: 0.480339\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054952; batch adversarial loss: 0.441610\n",
      "epoch 116; iter: 0; batch classifier loss: 0.049621; batch adversarial loss: 0.449639\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046501; batch adversarial loss: 0.418049\n",
      "epoch 118; iter: 0; batch classifier loss: 0.066597; batch adversarial loss: 0.395060\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039345; batch adversarial loss: 0.392189\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036211; batch adversarial loss: 0.433926\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023624; batch adversarial loss: 0.495705\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037163; batch adversarial loss: 0.417834\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014291; batch adversarial loss: 0.495191\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031239; batch adversarial loss: 0.488371\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052020; batch adversarial loss: 0.374422\n",
      "epoch 126; iter: 0; batch classifier loss: 0.018217; batch adversarial loss: 0.434724\n",
      "epoch 127; iter: 0; batch classifier loss: 0.011267; batch adversarial loss: 0.522771\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033142; batch adversarial loss: 0.408424\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042195; batch adversarial loss: 0.453420\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022365; batch adversarial loss: 0.459527\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032762; batch adversarial loss: 0.423560\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016072; batch adversarial loss: 0.417055\n",
      "epoch 133; iter: 0; batch classifier loss: 0.069029; batch adversarial loss: 0.340728\n",
      "epoch 134; iter: 0; batch classifier loss: 0.059526; batch adversarial loss: 0.444516\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045886; batch adversarial loss: 0.439060\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016481; batch adversarial loss: 0.508172\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043038; batch adversarial loss: 0.482450\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011284; batch adversarial loss: 0.412385\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037364; batch adversarial loss: 0.515709\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051329; batch adversarial loss: 0.502759\n",
      "epoch 141; iter: 0; batch classifier loss: 0.058956; batch adversarial loss: 0.635927\n",
      "epoch 142; iter: 0; batch classifier loss: 0.110421; batch adversarial loss: 0.577489\n",
      "epoch 143; iter: 0; batch classifier loss: 0.104081; batch adversarial loss: 0.624534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.081682; batch adversarial loss: 0.526776\n",
      "epoch 145; iter: 0; batch classifier loss: 0.105257; batch adversarial loss: 0.630263\n",
      "epoch 146; iter: 0; batch classifier loss: 0.066034; batch adversarial loss: 0.541082\n",
      "epoch 147; iter: 0; batch classifier loss: 0.143871; batch adversarial loss: 0.767696\n",
      "epoch 148; iter: 0; batch classifier loss: 0.090513; batch adversarial loss: 0.497351\n",
      "epoch 149; iter: 0; batch classifier loss: 0.142586; batch adversarial loss: 0.670714\n",
      "epoch 150; iter: 0; batch classifier loss: 0.099492; batch adversarial loss: 0.561920\n",
      "epoch 151; iter: 0; batch classifier loss: 0.109490; batch adversarial loss: 0.524644\n",
      "epoch 152; iter: 0; batch classifier loss: 0.154979; batch adversarial loss: 0.605914\n",
      "epoch 153; iter: 0; batch classifier loss: 0.138455; batch adversarial loss: 0.693243\n",
      "epoch 154; iter: 0; batch classifier loss: 0.161357; batch adversarial loss: 0.685663\n",
      "epoch 155; iter: 0; batch classifier loss: 0.125002; batch adversarial loss: 0.571828\n",
      "epoch 156; iter: 0; batch classifier loss: 0.112727; batch adversarial loss: 0.478777\n",
      "epoch 157; iter: 0; batch classifier loss: 0.147446; batch adversarial loss: 0.556038\n",
      "epoch 158; iter: 0; batch classifier loss: 0.188036; batch adversarial loss: 0.690325\n",
      "epoch 159; iter: 0; batch classifier loss: 0.150281; batch adversarial loss: 0.711989\n",
      "epoch 160; iter: 0; batch classifier loss: 0.150647; batch adversarial loss: 0.617963\n",
      "epoch 161; iter: 0; batch classifier loss: 0.181974; batch adversarial loss: 0.700369\n",
      "epoch 162; iter: 0; batch classifier loss: 0.145899; batch adversarial loss: 0.558837\n",
      "epoch 163; iter: 0; batch classifier loss: 0.161354; batch adversarial loss: 0.594386\n",
      "epoch 164; iter: 0; batch classifier loss: 0.152078; batch adversarial loss: 0.618629\n",
      "epoch 165; iter: 0; batch classifier loss: 0.099410; batch adversarial loss: 0.526660\n",
      "epoch 166; iter: 0; batch classifier loss: 0.121795; batch adversarial loss: 0.527924\n",
      "epoch 167; iter: 0; batch classifier loss: 0.151672; batch adversarial loss: 0.583439\n",
      "epoch 168; iter: 0; batch classifier loss: 0.140930; batch adversarial loss: 0.539532\n",
      "epoch 169; iter: 0; batch classifier loss: 0.155310; batch adversarial loss: 0.571205\n",
      "epoch 170; iter: 0; batch classifier loss: 0.129388; batch adversarial loss: 0.473938\n",
      "epoch 171; iter: 0; batch classifier loss: 0.100438; batch adversarial loss: 0.514828\n",
      "epoch 172; iter: 0; batch classifier loss: 0.103323; batch adversarial loss: 0.486123\n",
      "epoch 173; iter: 0; batch classifier loss: 0.090105; batch adversarial loss: 0.469940\n",
      "epoch 174; iter: 0; batch classifier loss: 0.170899; batch adversarial loss: 0.533814\n",
      "epoch 175; iter: 0; batch classifier loss: 0.139816; batch adversarial loss: 0.613146\n",
      "epoch 176; iter: 0; batch classifier loss: 0.120971; batch adversarial loss: 0.548205\n",
      "epoch 177; iter: 0; batch classifier loss: 0.227716; batch adversarial loss: 0.645325\n",
      "epoch 178; iter: 0; batch classifier loss: 0.094144; batch adversarial loss: 0.525712\n",
      "epoch 179; iter: 0; batch classifier loss: 0.191075; batch adversarial loss: 0.548328\n",
      "epoch 180; iter: 0; batch classifier loss: 0.129267; batch adversarial loss: 0.506606\n",
      "epoch 181; iter: 0; batch classifier loss: 0.174857; batch adversarial loss: 0.575084\n",
      "epoch 182; iter: 0; batch classifier loss: 0.084377; batch adversarial loss: 0.397905\n",
      "epoch 183; iter: 0; batch classifier loss: 0.096725; batch adversarial loss: 0.462589\n",
      "epoch 184; iter: 0; batch classifier loss: 0.172421; batch adversarial loss: 0.614319\n",
      "epoch 185; iter: 0; batch classifier loss: 0.131732; batch adversarial loss: 0.535164\n",
      "epoch 186; iter: 0; batch classifier loss: 0.072780; batch adversarial loss: 0.523301\n",
      "epoch 187; iter: 0; batch classifier loss: 0.177697; batch adversarial loss: 0.459859\n",
      "epoch 188; iter: 0; batch classifier loss: 0.123641; batch adversarial loss: 0.525771\n",
      "epoch 189; iter: 0; batch classifier loss: 0.095106; batch adversarial loss: 0.483740\n",
      "epoch 190; iter: 0; batch classifier loss: 0.112162; batch adversarial loss: 0.517183\n",
      "epoch 191; iter: 0; batch classifier loss: 0.116938; batch adversarial loss: 0.506211\n",
      "epoch 192; iter: 0; batch classifier loss: 0.098989; batch adversarial loss: 0.463719\n",
      "epoch 193; iter: 0; batch classifier loss: 0.091428; batch adversarial loss: 0.435032\n",
      "epoch 194; iter: 0; batch classifier loss: 0.149636; batch adversarial loss: 0.556031\n",
      "epoch 195; iter: 0; batch classifier loss: 0.058265; batch adversarial loss: 0.564221\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031566; batch adversarial loss: 0.371657\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015686; batch adversarial loss: 0.455671\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032343; batch adversarial loss: 0.458499\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032571; batch adversarial loss: 0.493373\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686861; batch adversarial loss: 0.505622\n",
      "epoch 1; iter: 0; batch classifier loss: 0.389795; batch adversarial loss: 0.611599\n",
      "epoch 2; iter: 0; batch classifier loss: 0.388460; batch adversarial loss: 0.573395\n",
      "epoch 3; iter: 0; batch classifier loss: 0.368272; batch adversarial loss: 0.543624\n",
      "epoch 4; iter: 0; batch classifier loss: 0.287934; batch adversarial loss: 0.568817\n",
      "epoch 5; iter: 0; batch classifier loss: 0.298522; batch adversarial loss: 0.569565\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331816; batch adversarial loss: 0.631734\n",
      "epoch 7; iter: 0; batch classifier loss: 0.323129; batch adversarial loss: 0.554172\n",
      "epoch 8; iter: 0; batch classifier loss: 0.293047; batch adversarial loss: 0.558597\n",
      "epoch 9; iter: 0; batch classifier loss: 0.313669; batch adversarial loss: 0.561755\n",
      "epoch 10; iter: 0; batch classifier loss: 0.280518; batch adversarial loss: 0.525336\n",
      "epoch 11; iter: 0; batch classifier loss: 0.316788; batch adversarial loss: 0.545172\n",
      "epoch 12; iter: 0; batch classifier loss: 0.306838; batch adversarial loss: 0.616309\n",
      "epoch 13; iter: 0; batch classifier loss: 0.361932; batch adversarial loss: 0.518567\n",
      "epoch 14; iter: 0; batch classifier loss: 0.322484; batch adversarial loss: 0.515393\n",
      "epoch 15; iter: 0; batch classifier loss: 0.362309; batch adversarial loss: 0.546331\n",
      "epoch 16; iter: 0; batch classifier loss: 0.398549; batch adversarial loss: 0.516870\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485870; batch adversarial loss: 0.516634\n",
      "epoch 18; iter: 0; batch classifier loss: 0.490259; batch adversarial loss: 0.490521\n",
      "epoch 19; iter: 0; batch classifier loss: 0.262267; batch adversarial loss: 0.498097\n",
      "epoch 20; iter: 0; batch classifier loss: 0.245037; batch adversarial loss: 0.509443\n",
      "epoch 21; iter: 0; batch classifier loss: 0.213000; batch adversarial loss: 0.434185\n",
      "epoch 22; iter: 0; batch classifier loss: 0.199586; batch adversarial loss: 0.454371\n",
      "epoch 23; iter: 0; batch classifier loss: 0.177049; batch adversarial loss: 0.514026\n",
      "epoch 24; iter: 0; batch classifier loss: 0.188548; batch adversarial loss: 0.522594\n",
      "epoch 25; iter: 0; batch classifier loss: 0.194965; batch adversarial loss: 0.574088\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194466; batch adversarial loss: 0.449885\n",
      "epoch 27; iter: 0; batch classifier loss: 0.133569; batch adversarial loss: 0.526412\n",
      "epoch 28; iter: 0; batch classifier loss: 0.136635; batch adversarial loss: 0.495092\n",
      "epoch 29; iter: 0; batch classifier loss: 0.141340; batch adversarial loss: 0.577116\n",
      "epoch 30; iter: 0; batch classifier loss: 0.150682; batch adversarial loss: 0.410884\n",
      "epoch 31; iter: 0; batch classifier loss: 0.104749; batch adversarial loss: 0.543877\n",
      "epoch 32; iter: 0; batch classifier loss: 0.143735; batch adversarial loss: 0.496977\n",
      "epoch 33; iter: 0; batch classifier loss: 0.154303; batch adversarial loss: 0.422820\n",
      "epoch 34; iter: 0; batch classifier loss: 0.174419; batch adversarial loss: 0.427456\n",
      "epoch 35; iter: 0; batch classifier loss: 0.102315; batch adversarial loss: 0.424285\n",
      "epoch 36; iter: 0; batch classifier loss: 0.075765; batch adversarial loss: 0.562488\n",
      "epoch 37; iter: 0; batch classifier loss: 0.095120; batch adversarial loss: 0.408887\n",
      "epoch 38; iter: 0; batch classifier loss: 0.076320; batch adversarial loss: 0.499950\n",
      "epoch 39; iter: 0; batch classifier loss: 0.119741; batch adversarial loss: 0.415193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.182685; batch adversarial loss: 0.472793\n",
      "epoch 41; iter: 0; batch classifier loss: 0.099184; batch adversarial loss: 0.466607\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110628; batch adversarial loss: 0.470384\n",
      "epoch 43; iter: 0; batch classifier loss: 0.180099; batch adversarial loss: 0.490819\n",
      "epoch 44; iter: 0; batch classifier loss: 0.159474; batch adversarial loss: 0.384967\n",
      "epoch 45; iter: 0; batch classifier loss: 0.185150; batch adversarial loss: 0.396914\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131843; batch adversarial loss: 0.424933\n",
      "epoch 47; iter: 0; batch classifier loss: 0.135145; batch adversarial loss: 0.413806\n",
      "epoch 48; iter: 0; batch classifier loss: 0.111850; batch adversarial loss: 0.415875\n",
      "epoch 49; iter: 0; batch classifier loss: 0.125872; batch adversarial loss: 0.393568\n",
      "epoch 50; iter: 0; batch classifier loss: 0.146795; batch adversarial loss: 0.454034\n",
      "epoch 51; iter: 0; batch classifier loss: 0.164883; batch adversarial loss: 0.434882\n",
      "epoch 52; iter: 0; batch classifier loss: 0.165661; batch adversarial loss: 0.400963\n",
      "epoch 53; iter: 0; batch classifier loss: 0.127989; batch adversarial loss: 0.414795\n",
      "epoch 54; iter: 0; batch classifier loss: 0.152590; batch adversarial loss: 0.421644\n",
      "epoch 55; iter: 0; batch classifier loss: 0.078029; batch adversarial loss: 0.539060\n",
      "epoch 56; iter: 0; batch classifier loss: 0.138663; batch adversarial loss: 0.442730\n",
      "epoch 57; iter: 0; batch classifier loss: 0.122761; batch adversarial loss: 0.485828\n",
      "epoch 58; iter: 0; batch classifier loss: 0.144695; batch adversarial loss: 0.397712\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092969; batch adversarial loss: 0.473870\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104517; batch adversarial loss: 0.562926\n",
      "epoch 61; iter: 0; batch classifier loss: 0.142306; batch adversarial loss: 0.474405\n",
      "epoch 62; iter: 0; batch classifier loss: 0.142702; batch adversarial loss: 0.432926\n",
      "epoch 63; iter: 0; batch classifier loss: 0.125855; batch adversarial loss: 0.434464\n",
      "epoch 64; iter: 0; batch classifier loss: 0.122407; batch adversarial loss: 0.494691\n",
      "epoch 65; iter: 0; batch classifier loss: 0.156905; batch adversarial loss: 0.371724\n",
      "epoch 66; iter: 0; batch classifier loss: 0.138582; batch adversarial loss: 0.466043\n",
      "epoch 67; iter: 0; batch classifier loss: 0.140778; batch adversarial loss: 0.511940\n",
      "epoch 68; iter: 0; batch classifier loss: 0.107019; batch adversarial loss: 0.435502\n",
      "epoch 69; iter: 0; batch classifier loss: 0.169631; batch adversarial loss: 0.459269\n",
      "epoch 70; iter: 0; batch classifier loss: 0.129420; batch adversarial loss: 0.409841\n",
      "epoch 71; iter: 0; batch classifier loss: 0.168262; batch adversarial loss: 0.469088\n",
      "epoch 72; iter: 0; batch classifier loss: 0.138223; batch adversarial loss: 0.412367\n",
      "epoch 73; iter: 0; batch classifier loss: 0.153695; batch adversarial loss: 0.393420\n",
      "epoch 74; iter: 0; batch classifier loss: 0.113115; batch adversarial loss: 0.447606\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096067; batch adversarial loss: 0.374938\n",
      "epoch 76; iter: 0; batch classifier loss: 0.137060; batch adversarial loss: 0.480802\n",
      "epoch 77; iter: 0; batch classifier loss: 0.123396; batch adversarial loss: 0.542185\n",
      "epoch 78; iter: 0; batch classifier loss: 0.127679; batch adversarial loss: 0.433300\n",
      "epoch 79; iter: 0; batch classifier loss: 0.112642; batch adversarial loss: 0.488760\n",
      "epoch 80; iter: 0; batch classifier loss: 0.148783; batch adversarial loss: 0.411357\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120186; batch adversarial loss: 0.445574\n",
      "epoch 82; iter: 0; batch classifier loss: 0.170258; batch adversarial loss: 0.414861\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094530; batch adversarial loss: 0.470868\n",
      "epoch 84; iter: 0; batch classifier loss: 0.164049; batch adversarial loss: 0.508503\n",
      "epoch 85; iter: 0; batch classifier loss: 0.131428; batch adversarial loss: 0.436489\n",
      "epoch 86; iter: 0; batch classifier loss: 0.144683; batch adversarial loss: 0.527897\n",
      "epoch 87; iter: 0; batch classifier loss: 0.145963; batch adversarial loss: 0.376810\n",
      "epoch 88; iter: 0; batch classifier loss: 0.155436; batch adversarial loss: 0.438317\n",
      "epoch 89; iter: 0; batch classifier loss: 0.239706; batch adversarial loss: 0.385508\n",
      "epoch 90; iter: 0; batch classifier loss: 0.204212; batch adversarial loss: 0.409335\n",
      "epoch 91; iter: 0; batch classifier loss: 0.122953; batch adversarial loss: 0.528348\n",
      "epoch 92; iter: 0; batch classifier loss: 0.136057; batch adversarial loss: 0.521807\n",
      "epoch 93; iter: 0; batch classifier loss: 0.096249; batch adversarial loss: 0.410092\n",
      "epoch 94; iter: 0; batch classifier loss: 0.120995; batch adversarial loss: 0.450840\n",
      "epoch 95; iter: 0; batch classifier loss: 0.132359; batch adversarial loss: 0.398493\n",
      "epoch 96; iter: 0; batch classifier loss: 0.098119; batch adversarial loss: 0.471185\n",
      "epoch 97; iter: 0; batch classifier loss: 0.172659; batch adversarial loss: 0.449148\n",
      "epoch 98; iter: 0; batch classifier loss: 0.178507; batch adversarial loss: 0.421106\n",
      "epoch 99; iter: 0; batch classifier loss: 0.133206; batch adversarial loss: 0.483588\n",
      "epoch 100; iter: 0; batch classifier loss: 0.116517; batch adversarial loss: 0.432362\n",
      "epoch 101; iter: 0; batch classifier loss: 0.165080; batch adversarial loss: 0.487057\n",
      "epoch 102; iter: 0; batch classifier loss: 0.166599; batch adversarial loss: 0.397104\n",
      "epoch 103; iter: 0; batch classifier loss: 0.133895; batch adversarial loss: 0.507281\n",
      "epoch 104; iter: 0; batch classifier loss: 0.099227; batch adversarial loss: 0.457415\n",
      "epoch 105; iter: 0; batch classifier loss: 0.077812; batch adversarial loss: 0.359194\n",
      "epoch 106; iter: 0; batch classifier loss: 0.181638; batch adversarial loss: 0.516124\n",
      "epoch 107; iter: 0; batch classifier loss: 0.119093; batch adversarial loss: 0.468240\n",
      "epoch 108; iter: 0; batch classifier loss: 0.120807; batch adversarial loss: 0.468587\n",
      "epoch 109; iter: 0; batch classifier loss: 0.113159; batch adversarial loss: 0.402803\n",
      "epoch 110; iter: 0; batch classifier loss: 0.142318; batch adversarial loss: 0.451009\n",
      "epoch 111; iter: 0; batch classifier loss: 0.162531; batch adversarial loss: 0.418393\n",
      "epoch 112; iter: 0; batch classifier loss: 0.093209; batch adversarial loss: 0.484701\n",
      "epoch 113; iter: 0; batch classifier loss: 0.136235; batch adversarial loss: 0.531291\n",
      "epoch 114; iter: 0; batch classifier loss: 0.079633; batch adversarial loss: 0.504878\n",
      "epoch 115; iter: 0; batch classifier loss: 0.114879; batch adversarial loss: 0.485704\n",
      "epoch 116; iter: 0; batch classifier loss: 0.113823; batch adversarial loss: 0.422392\n",
      "epoch 117; iter: 0; batch classifier loss: 0.127100; batch adversarial loss: 0.464202\n",
      "epoch 118; iter: 0; batch classifier loss: 0.117789; batch adversarial loss: 0.381448\n",
      "epoch 119; iter: 0; batch classifier loss: 0.119260; batch adversarial loss: 0.439892\n",
      "epoch 120; iter: 0; batch classifier loss: 0.115333; batch adversarial loss: 0.535138\n",
      "epoch 121; iter: 0; batch classifier loss: 0.136765; batch adversarial loss: 0.461435\n",
      "epoch 122; iter: 0; batch classifier loss: 0.086562; batch adversarial loss: 0.495258\n",
      "epoch 123; iter: 0; batch classifier loss: 0.099363; batch adversarial loss: 0.460090\n",
      "epoch 124; iter: 0; batch classifier loss: 0.068017; batch adversarial loss: 0.448685\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053574; batch adversarial loss: 0.337675\n",
      "epoch 126; iter: 0; batch classifier loss: 0.061183; batch adversarial loss: 0.495707\n",
      "epoch 127; iter: 0; batch classifier loss: 0.062155; batch adversarial loss: 0.571540\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063674; batch adversarial loss: 0.506914\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047176; batch adversarial loss: 0.486574\n",
      "epoch 130; iter: 0; batch classifier loss: 0.082547; batch adversarial loss: 0.417035\n",
      "epoch 131; iter: 0; batch classifier loss: 0.076123; batch adversarial loss: 0.527103\n",
      "epoch 132; iter: 0; batch classifier loss: 0.093329; batch adversarial loss: 0.381361\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051469; batch adversarial loss: 0.439363\n",
      "epoch 134; iter: 0; batch classifier loss: 0.056345; batch adversarial loss: 0.507821\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041089; batch adversarial loss: 0.553640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.052980; batch adversarial loss: 0.457010\n",
      "epoch 137; iter: 0; batch classifier loss: 0.060665; batch adversarial loss: 0.403846\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034270; batch adversarial loss: 0.385960\n",
      "epoch 139; iter: 0; batch classifier loss: 0.074490; batch adversarial loss: 0.472608\n",
      "epoch 140; iter: 0; batch classifier loss: 0.062421; batch adversarial loss: 0.477270\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048712; batch adversarial loss: 0.504052\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023254; batch adversarial loss: 0.497647\n",
      "epoch 143; iter: 0; batch classifier loss: 0.058417; batch adversarial loss: 0.520544\n",
      "epoch 144; iter: 0; batch classifier loss: 0.072035; batch adversarial loss: 0.497958\n",
      "epoch 145; iter: 0; batch classifier loss: 0.054929; batch adversarial loss: 0.413817\n",
      "epoch 146; iter: 0; batch classifier loss: 0.066158; batch adversarial loss: 0.457605\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040227; batch adversarial loss: 0.521542\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049962; batch adversarial loss: 0.451338\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056115; batch adversarial loss: 0.486941\n",
      "epoch 150; iter: 0; batch classifier loss: 0.068288; batch adversarial loss: 0.424046\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024138; batch adversarial loss: 0.431553\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028127; batch adversarial loss: 0.502389\n",
      "epoch 153; iter: 0; batch classifier loss: 0.068842; batch adversarial loss: 0.407188\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033891; batch adversarial loss: 0.485273\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009872; batch adversarial loss: 0.513895\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033378; batch adversarial loss: 0.524956\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035729; batch adversarial loss: 0.469391\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027767; batch adversarial loss: 0.502656\n",
      "epoch 159; iter: 0; batch classifier loss: 0.044206; batch adversarial loss: 0.428662\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044999; batch adversarial loss: 0.481678\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027878; batch adversarial loss: 0.442467\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042236; batch adversarial loss: 0.418004\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035911; batch adversarial loss: 0.370471\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021118; batch adversarial loss: 0.424607\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019610; batch adversarial loss: 0.493587\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024147; batch adversarial loss: 0.423708\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024551; batch adversarial loss: 0.493951\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027164; batch adversarial loss: 0.443870\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029344; batch adversarial loss: 0.420434\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024196; batch adversarial loss: 0.466778\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019687; batch adversarial loss: 0.471495\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012451; batch adversarial loss: 0.526496\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033065; batch adversarial loss: 0.380824\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014096; batch adversarial loss: 0.462761\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029271; batch adversarial loss: 0.422955\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022791; batch adversarial loss: 0.488367\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015720; batch adversarial loss: 0.476416\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023339; batch adversarial loss: 0.377245\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020199; batch adversarial loss: 0.384580\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021561; batch adversarial loss: 0.442219\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015387; batch adversarial loss: 0.590547\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010912; batch adversarial loss: 0.438634\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016680; batch adversarial loss: 0.537280\n",
      "epoch 184; iter: 0; batch classifier loss: 0.049295; batch adversarial loss: 0.534017\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040885; batch adversarial loss: 0.490468\n",
      "epoch 186; iter: 0; batch classifier loss: 0.048882; batch adversarial loss: 0.464453\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013477; batch adversarial loss: 0.542593\n",
      "epoch 188; iter: 0; batch classifier loss: 0.052954; batch adversarial loss: 0.443491\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029086; batch adversarial loss: 0.407679\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021348; batch adversarial loss: 0.485050\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016114; batch adversarial loss: 0.367996\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026783; batch adversarial loss: 0.516869\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035168; batch adversarial loss: 0.525066\n",
      "epoch 194; iter: 0; batch classifier loss: 0.044516; batch adversarial loss: 0.351650\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021122; batch adversarial loss: 0.456525\n",
      "epoch 196; iter: 0; batch classifier loss: 0.034256; batch adversarial loss: 0.524028\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020565; batch adversarial loss: 0.421472\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021788; batch adversarial loss: 0.555925\n",
      "epoch 199; iter: 0; batch classifier loss: 0.044509; batch adversarial loss: 0.339652\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685345; batch adversarial loss: 0.852574\n",
      "epoch 1; iter: 0; batch classifier loss: 0.694318; batch adversarial loss: 0.949612\n",
      "epoch 2; iter: 0; batch classifier loss: 0.890858; batch adversarial loss: 0.965841\n",
      "epoch 3; iter: 0; batch classifier loss: 0.803104; batch adversarial loss: 0.850495\n",
      "epoch 4; iter: 0; batch classifier loss: 0.794971; batch adversarial loss: 0.781054\n",
      "epoch 5; iter: 0; batch classifier loss: 0.820628; batch adversarial loss: 0.779608\n",
      "epoch 6; iter: 0; batch classifier loss: 0.701730; batch adversarial loss: 0.662509\n",
      "epoch 7; iter: 0; batch classifier loss: 0.589637; batch adversarial loss: 0.659548\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546000; batch adversarial loss: 0.624355\n",
      "epoch 9; iter: 0; batch classifier loss: 0.440302; batch adversarial loss: 0.588309\n",
      "epoch 10; iter: 0; batch classifier loss: 0.278843; batch adversarial loss: 0.528413\n",
      "epoch 11; iter: 0; batch classifier loss: 0.296901; batch adversarial loss: 0.547212\n",
      "epoch 12; iter: 0; batch classifier loss: 0.297801; batch adversarial loss: 0.487117\n",
      "epoch 13; iter: 0; batch classifier loss: 0.304568; batch adversarial loss: 0.593114\n",
      "epoch 14; iter: 0; batch classifier loss: 0.305086; batch adversarial loss: 0.603435\n",
      "epoch 15; iter: 0; batch classifier loss: 0.217773; batch adversarial loss: 0.478994\n",
      "epoch 16; iter: 0; batch classifier loss: 0.306944; batch adversarial loss: 0.487133\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217365; batch adversarial loss: 0.531960\n",
      "epoch 18; iter: 0; batch classifier loss: 0.242405; batch adversarial loss: 0.531409\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236867; batch adversarial loss: 0.455589\n",
      "epoch 20; iter: 0; batch classifier loss: 0.255568; batch adversarial loss: 0.493595\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202040; batch adversarial loss: 0.474020\n",
      "epoch 22; iter: 0; batch classifier loss: 0.196633; batch adversarial loss: 0.459287\n",
      "epoch 23; iter: 0; batch classifier loss: 0.217785; batch adversarial loss: 0.515371\n",
      "epoch 24; iter: 0; batch classifier loss: 0.216520; batch adversarial loss: 0.497577\n",
      "epoch 25; iter: 0; batch classifier loss: 0.241326; batch adversarial loss: 0.477726\n",
      "epoch 26; iter: 0; batch classifier loss: 0.173142; batch adversarial loss: 0.446028\n",
      "epoch 27; iter: 0; batch classifier loss: 0.144508; batch adversarial loss: 0.620071\n",
      "epoch 28; iter: 0; batch classifier loss: 0.221938; batch adversarial loss: 0.471023\n",
      "epoch 29; iter: 0; batch classifier loss: 0.193122; batch adversarial loss: 0.466302\n",
      "epoch 30; iter: 0; batch classifier loss: 0.165144; batch adversarial loss: 0.541115\n",
      "epoch 31; iter: 0; batch classifier loss: 0.183020; batch adversarial loss: 0.497730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.139050; batch adversarial loss: 0.503822\n",
      "epoch 33; iter: 0; batch classifier loss: 0.146154; batch adversarial loss: 0.446063\n",
      "epoch 34; iter: 0; batch classifier loss: 0.158231; batch adversarial loss: 0.513290\n",
      "epoch 35; iter: 0; batch classifier loss: 0.187314; batch adversarial loss: 0.444468\n",
      "epoch 36; iter: 0; batch classifier loss: 0.154094; batch adversarial loss: 0.480758\n",
      "epoch 37; iter: 0; batch classifier loss: 0.175321; batch adversarial loss: 0.477237\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127313; batch adversarial loss: 0.487022\n",
      "epoch 39; iter: 0; batch classifier loss: 0.156969; batch adversarial loss: 0.531788\n",
      "epoch 40; iter: 0; batch classifier loss: 0.148204; batch adversarial loss: 0.543436\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125900; batch adversarial loss: 0.498059\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131216; batch adversarial loss: 0.480314\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117495; batch adversarial loss: 0.496639\n",
      "epoch 44; iter: 0; batch classifier loss: 0.196810; batch adversarial loss: 0.445569\n",
      "epoch 45; iter: 0; batch classifier loss: 0.073767; batch adversarial loss: 0.557002\n",
      "epoch 46; iter: 0; batch classifier loss: 0.181380; batch adversarial loss: 0.400639\n",
      "epoch 47; iter: 0; batch classifier loss: 0.152687; batch adversarial loss: 0.508371\n",
      "epoch 48; iter: 0; batch classifier loss: 0.126179; batch adversarial loss: 0.454407\n",
      "epoch 49; iter: 0; batch classifier loss: 0.133391; batch adversarial loss: 0.385924\n",
      "epoch 50; iter: 0; batch classifier loss: 0.124657; batch adversarial loss: 0.501647\n",
      "epoch 51; iter: 0; batch classifier loss: 0.152896; batch adversarial loss: 0.423298\n",
      "epoch 52; iter: 0; batch classifier loss: 0.139210; batch adversarial loss: 0.511731\n",
      "epoch 53; iter: 0; batch classifier loss: 0.139842; batch adversarial loss: 0.470095\n",
      "epoch 54; iter: 0; batch classifier loss: 0.135272; batch adversarial loss: 0.489152\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096149; batch adversarial loss: 0.471676\n",
      "epoch 56; iter: 0; batch classifier loss: 0.111964; batch adversarial loss: 0.453232\n",
      "epoch 57; iter: 0; batch classifier loss: 0.136411; batch adversarial loss: 0.466536\n",
      "epoch 58; iter: 0; batch classifier loss: 0.113613; batch adversarial loss: 0.506076\n",
      "epoch 59; iter: 0; batch classifier loss: 0.113581; batch adversarial loss: 0.466863\n",
      "epoch 60; iter: 0; batch classifier loss: 0.111242; batch adversarial loss: 0.398221\n",
      "epoch 61; iter: 0; batch classifier loss: 0.124983; batch adversarial loss: 0.442852\n",
      "epoch 62; iter: 0; batch classifier loss: 0.114907; batch adversarial loss: 0.466909\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091082; batch adversarial loss: 0.427051\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099561; batch adversarial loss: 0.398095\n",
      "epoch 65; iter: 0; batch classifier loss: 0.162819; batch adversarial loss: 0.375134\n",
      "epoch 66; iter: 0; batch classifier loss: 0.157742; batch adversarial loss: 0.421715\n",
      "epoch 67; iter: 0; batch classifier loss: 0.166021; batch adversarial loss: 0.389877\n",
      "epoch 68; iter: 0; batch classifier loss: 0.111986; batch adversarial loss: 0.431358\n",
      "epoch 69; iter: 0; batch classifier loss: 0.132828; batch adversarial loss: 0.419101\n",
      "epoch 70; iter: 0; batch classifier loss: 0.165492; batch adversarial loss: 0.414993\n",
      "epoch 71; iter: 0; batch classifier loss: 0.200164; batch adversarial loss: 0.359050\n",
      "epoch 72; iter: 0; batch classifier loss: 0.067476; batch adversarial loss: 0.364411\n",
      "epoch 73; iter: 0; batch classifier loss: 0.154719; batch adversarial loss: 0.469030\n",
      "epoch 74; iter: 0; batch classifier loss: 0.163694; batch adversarial loss: 0.358697\n",
      "epoch 75; iter: 0; batch classifier loss: 0.165130; batch adversarial loss: 0.458139\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103001; batch adversarial loss: 0.424450\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108215; batch adversarial loss: 0.567975\n",
      "epoch 78; iter: 0; batch classifier loss: 0.086308; batch adversarial loss: 0.575437\n",
      "epoch 79; iter: 0; batch classifier loss: 0.169682; batch adversarial loss: 0.502657\n",
      "epoch 80; iter: 0; batch classifier loss: 0.116285; batch adversarial loss: 0.579557\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096746; batch adversarial loss: 0.556281\n",
      "epoch 82; iter: 0; batch classifier loss: 0.095238; batch adversarial loss: 0.423955\n",
      "epoch 83; iter: 0; batch classifier loss: 0.125770; batch adversarial loss: 0.474075\n",
      "epoch 84; iter: 0; batch classifier loss: 0.112070; batch adversarial loss: 0.478070\n",
      "epoch 85; iter: 0; batch classifier loss: 0.120357; batch adversarial loss: 0.476556\n",
      "epoch 86; iter: 0; batch classifier loss: 0.126314; batch adversarial loss: 0.526611\n",
      "epoch 87; iter: 0; batch classifier loss: 0.152268; batch adversarial loss: 0.373008\n",
      "epoch 88; iter: 0; batch classifier loss: 0.116409; batch adversarial loss: 0.533647\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081009; batch adversarial loss: 0.417849\n",
      "epoch 90; iter: 0; batch classifier loss: 0.120184; batch adversarial loss: 0.474210\n",
      "epoch 91; iter: 0; batch classifier loss: 0.079105; batch adversarial loss: 0.545161\n",
      "epoch 92; iter: 0; batch classifier loss: 0.102396; batch adversarial loss: 0.518114\n",
      "epoch 93; iter: 0; batch classifier loss: 0.112520; batch adversarial loss: 0.554322\n",
      "epoch 94; iter: 0; batch classifier loss: 0.136539; batch adversarial loss: 0.464859\n",
      "epoch 95; iter: 0; batch classifier loss: 0.100239; batch adversarial loss: 0.478047\n",
      "epoch 96; iter: 0; batch classifier loss: 0.111032; batch adversarial loss: 0.435166\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071328; batch adversarial loss: 0.435594\n",
      "epoch 98; iter: 0; batch classifier loss: 0.097707; batch adversarial loss: 0.431930\n",
      "epoch 99; iter: 0; batch classifier loss: 0.118477; batch adversarial loss: 0.406249\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074917; batch adversarial loss: 0.480112\n",
      "epoch 101; iter: 0; batch classifier loss: 0.185591; batch adversarial loss: 0.444431\n",
      "epoch 102; iter: 0; batch classifier loss: 0.134072; batch adversarial loss: 0.399863\n",
      "epoch 103; iter: 0; batch classifier loss: 0.112769; batch adversarial loss: 0.447380\n",
      "epoch 104; iter: 0; batch classifier loss: 0.148987; batch adversarial loss: 0.450133\n",
      "epoch 105; iter: 0; batch classifier loss: 0.074045; batch adversarial loss: 0.448271\n",
      "epoch 106; iter: 0; batch classifier loss: 0.126865; batch adversarial loss: 0.499692\n",
      "epoch 107; iter: 0; batch classifier loss: 0.117826; batch adversarial loss: 0.456156\n",
      "epoch 108; iter: 0; batch classifier loss: 0.114129; batch adversarial loss: 0.467292\n",
      "epoch 109; iter: 0; batch classifier loss: 0.123601; batch adversarial loss: 0.542475\n",
      "epoch 110; iter: 0; batch classifier loss: 0.073688; batch adversarial loss: 0.461660\n",
      "epoch 111; iter: 0; batch classifier loss: 0.135107; batch adversarial loss: 0.468521\n",
      "epoch 112; iter: 0; batch classifier loss: 0.087682; batch adversarial loss: 0.405139\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071397; batch adversarial loss: 0.554170\n",
      "epoch 114; iter: 0; batch classifier loss: 0.094621; batch adversarial loss: 0.402676\n",
      "epoch 115; iter: 0; batch classifier loss: 0.102402; batch adversarial loss: 0.463493\n",
      "epoch 116; iter: 0; batch classifier loss: 0.120926; batch adversarial loss: 0.424007\n",
      "epoch 117; iter: 0; batch classifier loss: 0.118215; batch adversarial loss: 0.432670\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040601; batch adversarial loss: 0.474609\n",
      "epoch 119; iter: 0; batch classifier loss: 0.083609; batch adversarial loss: 0.492687\n",
      "epoch 120; iter: 0; batch classifier loss: 0.127504; batch adversarial loss: 0.404552\n",
      "epoch 121; iter: 0; batch classifier loss: 0.107732; batch adversarial loss: 0.459896\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066912; batch adversarial loss: 0.547575\n",
      "epoch 123; iter: 0; batch classifier loss: 0.119491; batch adversarial loss: 0.489662\n",
      "epoch 124; iter: 0; batch classifier loss: 0.092175; batch adversarial loss: 0.400198\n",
      "epoch 125; iter: 0; batch classifier loss: 0.135482; batch adversarial loss: 0.463634\n",
      "epoch 126; iter: 0; batch classifier loss: 0.096689; batch adversarial loss: 0.447839\n",
      "epoch 127; iter: 0; batch classifier loss: 0.122577; batch adversarial loss: 0.481486\n",
      "epoch 128; iter: 0; batch classifier loss: 0.074877; batch adversarial loss: 0.495383\n",
      "epoch 129; iter: 0; batch classifier loss: 0.112333; batch adversarial loss: 0.531054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.095612; batch adversarial loss: 0.458162\n",
      "epoch 131; iter: 0; batch classifier loss: 0.148123; batch adversarial loss: 0.487770\n",
      "epoch 132; iter: 0; batch classifier loss: 0.108038; batch adversarial loss: 0.447427\n",
      "epoch 133; iter: 0; batch classifier loss: 0.073455; batch adversarial loss: 0.472790\n",
      "epoch 134; iter: 0; batch classifier loss: 0.117151; batch adversarial loss: 0.455512\n",
      "epoch 135; iter: 0; batch classifier loss: 0.118550; batch adversarial loss: 0.482979\n",
      "epoch 136; iter: 0; batch classifier loss: 0.116800; batch adversarial loss: 0.455176\n",
      "epoch 137; iter: 0; batch classifier loss: 0.120108; batch adversarial loss: 0.483599\n",
      "epoch 138; iter: 0; batch classifier loss: 0.107182; batch adversarial loss: 0.420700\n",
      "epoch 139; iter: 0; batch classifier loss: 0.075621; batch adversarial loss: 0.506492\n",
      "epoch 140; iter: 0; batch classifier loss: 0.145973; batch adversarial loss: 0.391971\n",
      "epoch 141; iter: 0; batch classifier loss: 0.186446; batch adversarial loss: 0.417916\n",
      "epoch 142; iter: 0; batch classifier loss: 0.109465; batch adversarial loss: 0.464216\n",
      "epoch 143; iter: 0; batch classifier loss: 0.206060; batch adversarial loss: 0.502679\n",
      "epoch 144; iter: 0; batch classifier loss: 0.186337; batch adversarial loss: 0.571487\n",
      "epoch 145; iter: 0; batch classifier loss: 0.189571; batch adversarial loss: 0.433711\n",
      "epoch 146; iter: 0; batch classifier loss: 0.214531; batch adversarial loss: 0.515405\n",
      "epoch 147; iter: 0; batch classifier loss: 0.148809; batch adversarial loss: 0.437825\n",
      "epoch 148; iter: 0; batch classifier loss: 0.179196; batch adversarial loss: 0.508569\n",
      "epoch 149; iter: 0; batch classifier loss: 0.184510; batch adversarial loss: 0.363216\n",
      "epoch 150; iter: 0; batch classifier loss: 0.214909; batch adversarial loss: 0.473764\n",
      "epoch 151; iter: 0; batch classifier loss: 0.217316; batch adversarial loss: 0.505349\n",
      "epoch 152; iter: 0; batch classifier loss: 0.191181; batch adversarial loss: 0.470898\n",
      "epoch 153; iter: 0; batch classifier loss: 0.146446; batch adversarial loss: 0.471223\n",
      "epoch 154; iter: 0; batch classifier loss: 0.229032; batch adversarial loss: 0.577844\n",
      "epoch 155; iter: 0; batch classifier loss: 0.247975; batch adversarial loss: 0.447103\n",
      "epoch 156; iter: 0; batch classifier loss: 0.107355; batch adversarial loss: 0.506612\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042907; batch adversarial loss: 0.397241\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047593; batch adversarial loss: 0.446282\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049137; batch adversarial loss: 0.394145\n",
      "epoch 160; iter: 0; batch classifier loss: 0.060093; batch adversarial loss: 0.366989\n",
      "epoch 161; iter: 0; batch classifier loss: 0.057978; batch adversarial loss: 0.387291\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033990; batch adversarial loss: 0.413723\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030966; batch adversarial loss: 0.482029\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034536; batch adversarial loss: 0.466268\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041322; batch adversarial loss: 0.414206\n",
      "epoch 166; iter: 0; batch classifier loss: 0.062741; batch adversarial loss: 0.497978\n",
      "epoch 167; iter: 0; batch classifier loss: 0.076414; batch adversarial loss: 0.415037\n",
      "epoch 168; iter: 0; batch classifier loss: 0.062062; batch adversarial loss: 0.362143\n",
      "epoch 169; iter: 0; batch classifier loss: 0.076365; batch adversarial loss: 0.395022\n",
      "epoch 170; iter: 0; batch classifier loss: 0.104826; batch adversarial loss: 0.398966\n",
      "epoch 171; iter: 0; batch classifier loss: 0.054389; batch adversarial loss: 0.536895\n",
      "epoch 172; iter: 0; batch classifier loss: 0.055334; batch adversarial loss: 0.455867\n",
      "epoch 173; iter: 0; batch classifier loss: 0.049519; batch adversarial loss: 0.460482\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041943; batch adversarial loss: 0.377413\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040613; batch adversarial loss: 0.435306\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028081; batch adversarial loss: 0.555928\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030878; batch adversarial loss: 0.421722\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040514; batch adversarial loss: 0.531065\n",
      "epoch 179; iter: 0; batch classifier loss: 0.089612; batch adversarial loss: 0.358299\n",
      "epoch 180; iter: 0; batch classifier loss: 0.046007; batch adversarial loss: 0.386679\n",
      "epoch 181; iter: 0; batch classifier loss: 0.079854; batch adversarial loss: 0.462618\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042502; batch adversarial loss: 0.391974\n",
      "epoch 183; iter: 0; batch classifier loss: 0.045412; batch adversarial loss: 0.506674\n",
      "epoch 184; iter: 0; batch classifier loss: 0.093512; batch adversarial loss: 0.503714\n",
      "epoch 185; iter: 0; batch classifier loss: 0.099145; batch adversarial loss: 0.440868\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031395; batch adversarial loss: 0.442261\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032087; batch adversarial loss: 0.460853\n",
      "epoch 188; iter: 0; batch classifier loss: 0.049992; batch adversarial loss: 0.347886\n",
      "epoch 189; iter: 0; batch classifier loss: 0.056744; batch adversarial loss: 0.369690\n",
      "epoch 190; iter: 0; batch classifier loss: 0.051934; batch adversarial loss: 0.397928\n",
      "epoch 191; iter: 0; batch classifier loss: 0.053687; batch adversarial loss: 0.412149\n",
      "epoch 192; iter: 0; batch classifier loss: 0.064661; batch adversarial loss: 0.409987\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027806; batch adversarial loss: 0.361760\n",
      "epoch 194; iter: 0; batch classifier loss: 0.072509; batch adversarial loss: 0.426084\n",
      "epoch 195; iter: 0; batch classifier loss: 0.074231; batch adversarial loss: 0.385132\n",
      "epoch 196; iter: 0; batch classifier loss: 0.055126; batch adversarial loss: 0.454592\n",
      "epoch 197; iter: 0; batch classifier loss: 0.052812; batch adversarial loss: 0.389979\n",
      "epoch 198; iter: 0; batch classifier loss: 0.052009; batch adversarial loss: 0.403393\n",
      "epoch 199; iter: 0; batch classifier loss: 0.080095; batch adversarial loss: 0.476444\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671175; batch adversarial loss: 0.595022\n",
      "epoch 1; iter: 0; batch classifier loss: 0.460106; batch adversarial loss: 0.615745\n",
      "epoch 2; iter: 0; batch classifier loss: 0.321804; batch adversarial loss: 0.591199\n",
      "epoch 3; iter: 0; batch classifier loss: 0.323324; batch adversarial loss: 0.575493\n",
      "epoch 4; iter: 0; batch classifier loss: 0.264614; batch adversarial loss: 0.582194\n",
      "epoch 5; iter: 0; batch classifier loss: 0.318512; batch adversarial loss: 0.531480\n",
      "epoch 6; iter: 0; batch classifier loss: 0.244132; batch adversarial loss: 0.550294\n",
      "epoch 7; iter: 0; batch classifier loss: 0.305551; batch adversarial loss: 0.539088\n",
      "epoch 8; iter: 0; batch classifier loss: 0.255094; batch adversarial loss: 0.482209\n",
      "epoch 9; iter: 0; batch classifier loss: 0.250551; batch adversarial loss: 0.463442\n",
      "epoch 10; iter: 0; batch classifier loss: 0.246399; batch adversarial loss: 0.523543\n",
      "epoch 11; iter: 0; batch classifier loss: 0.319644; batch adversarial loss: 0.421701\n",
      "epoch 12; iter: 0; batch classifier loss: 0.184022; batch adversarial loss: 0.480051\n",
      "epoch 13; iter: 0; batch classifier loss: 0.211045; batch adversarial loss: 0.420532\n",
      "epoch 14; iter: 0; batch classifier loss: 0.147774; batch adversarial loss: 0.483552\n",
      "epoch 15; iter: 0; batch classifier loss: 0.177119; batch adversarial loss: 0.418001\n",
      "epoch 16; iter: 0; batch classifier loss: 0.221835; batch adversarial loss: 0.463445\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241064; batch adversarial loss: 0.516882\n",
      "epoch 18; iter: 0; batch classifier loss: 0.167193; batch adversarial loss: 0.493966\n",
      "epoch 19; iter: 0; batch classifier loss: 0.221751; batch adversarial loss: 0.515118\n",
      "epoch 20; iter: 0; batch classifier loss: 0.149128; batch adversarial loss: 0.609189\n",
      "epoch 21; iter: 0; batch classifier loss: 0.222609; batch adversarial loss: 0.577846\n",
      "epoch 22; iter: 0; batch classifier loss: 0.182103; batch adversarial loss: 0.497906\n",
      "epoch 23; iter: 0; batch classifier loss: 0.255386; batch adversarial loss: 0.599885\n",
      "epoch 24; iter: 0; batch classifier loss: 0.208373; batch adversarial loss: 0.546135\n",
      "epoch 25; iter: 0; batch classifier loss: 0.224742; batch adversarial loss: 0.551575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.153718; batch adversarial loss: 0.504180\n",
      "epoch 27; iter: 0; batch classifier loss: 0.170378; batch adversarial loss: 0.516296\n",
      "epoch 28; iter: 0; batch classifier loss: 0.232071; batch adversarial loss: 0.447087\n",
      "epoch 29; iter: 0; batch classifier loss: 0.259681; batch adversarial loss: 0.537241\n",
      "epoch 30; iter: 0; batch classifier loss: 0.251982; batch adversarial loss: 0.458897\n",
      "epoch 31; iter: 0; batch classifier loss: 0.303506; batch adversarial loss: 0.550529\n",
      "epoch 32; iter: 0; batch classifier loss: 0.298073; batch adversarial loss: 0.476206\n",
      "epoch 33; iter: 0; batch classifier loss: 0.255342; batch adversarial loss: 0.547795\n",
      "epoch 34; iter: 0; batch classifier loss: 0.152439; batch adversarial loss: 0.365333\n",
      "epoch 35; iter: 0; batch classifier loss: 0.110490; batch adversarial loss: 0.424027\n",
      "epoch 36; iter: 0; batch classifier loss: 0.113482; batch adversarial loss: 0.455145\n",
      "epoch 37; iter: 0; batch classifier loss: 0.149582; batch adversarial loss: 0.411450\n",
      "epoch 38; iter: 0; batch classifier loss: 0.090636; batch adversarial loss: 0.506770\n",
      "epoch 39; iter: 0; batch classifier loss: 0.082785; batch adversarial loss: 0.403625\n",
      "epoch 40; iter: 0; batch classifier loss: 0.079647; batch adversarial loss: 0.543988\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116298; batch adversarial loss: 0.446506\n",
      "epoch 42; iter: 0; batch classifier loss: 0.094929; batch adversarial loss: 0.450738\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089115; batch adversarial loss: 0.383743\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097464; batch adversarial loss: 0.444006\n",
      "epoch 45; iter: 0; batch classifier loss: 0.069472; batch adversarial loss: 0.489873\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086626; batch adversarial loss: 0.434195\n",
      "epoch 47; iter: 0; batch classifier loss: 0.061623; batch adversarial loss: 0.408971\n",
      "epoch 48; iter: 0; batch classifier loss: 0.115037; batch adversarial loss: 0.555009\n",
      "epoch 49; iter: 0; batch classifier loss: 0.102798; batch adversarial loss: 0.459486\n",
      "epoch 50; iter: 0; batch classifier loss: 0.097313; batch adversarial loss: 0.468248\n",
      "epoch 51; iter: 0; batch classifier loss: 0.105897; batch adversarial loss: 0.387352\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100213; batch adversarial loss: 0.469606\n",
      "epoch 53; iter: 0; batch classifier loss: 0.082146; batch adversarial loss: 0.406366\n",
      "epoch 54; iter: 0; batch classifier loss: 0.071943; batch adversarial loss: 0.491619\n",
      "epoch 55; iter: 0; batch classifier loss: 0.093200; batch adversarial loss: 0.405536\n",
      "epoch 56; iter: 0; batch classifier loss: 0.093730; batch adversarial loss: 0.421266\n",
      "epoch 57; iter: 0; batch classifier loss: 0.115772; batch adversarial loss: 0.442011\n",
      "epoch 58; iter: 0; batch classifier loss: 0.085995; batch adversarial loss: 0.517728\n",
      "epoch 59; iter: 0; batch classifier loss: 0.119951; batch adversarial loss: 0.406420\n",
      "epoch 60; iter: 0; batch classifier loss: 0.132774; batch adversarial loss: 0.478630\n",
      "epoch 61; iter: 0; batch classifier loss: 0.097183; batch adversarial loss: 0.425242\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108434; batch adversarial loss: 0.536762\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103146; batch adversarial loss: 0.447576\n",
      "epoch 64; iter: 0; batch classifier loss: 0.108471; batch adversarial loss: 0.572746\n",
      "epoch 65; iter: 0; batch classifier loss: 0.111449; batch adversarial loss: 0.404033\n",
      "epoch 66; iter: 0; batch classifier loss: 0.102715; batch adversarial loss: 0.450279\n",
      "epoch 67; iter: 0; batch classifier loss: 0.077640; batch adversarial loss: 0.438571\n",
      "epoch 68; iter: 0; batch classifier loss: 0.055712; batch adversarial loss: 0.426264\n",
      "epoch 69; iter: 0; batch classifier loss: 0.049264; batch adversarial loss: 0.470298\n",
      "epoch 70; iter: 0; batch classifier loss: 0.121485; batch adversarial loss: 0.511404\n",
      "epoch 71; iter: 0; batch classifier loss: 0.117637; batch adversarial loss: 0.480123\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071551; batch adversarial loss: 0.458026\n",
      "epoch 73; iter: 0; batch classifier loss: 0.060054; batch adversarial loss: 0.446977\n",
      "epoch 74; iter: 0; batch classifier loss: 0.087550; batch adversarial loss: 0.359745\n",
      "epoch 75; iter: 0; batch classifier loss: 0.129325; batch adversarial loss: 0.431380\n",
      "epoch 76; iter: 0; batch classifier loss: 0.172340; batch adversarial loss: 0.405616\n",
      "epoch 77; iter: 0; batch classifier loss: 0.106189; batch adversarial loss: 0.460856\n",
      "epoch 78; iter: 0; batch classifier loss: 0.105740; batch adversarial loss: 0.488861\n",
      "epoch 79; iter: 0; batch classifier loss: 0.155186; batch adversarial loss: 0.426372\n",
      "epoch 80; iter: 0; batch classifier loss: 0.092537; batch adversarial loss: 0.479262\n",
      "epoch 81; iter: 0; batch classifier loss: 0.127718; batch adversarial loss: 0.474049\n",
      "epoch 82; iter: 0; batch classifier loss: 0.084691; batch adversarial loss: 0.482104\n",
      "epoch 83; iter: 0; batch classifier loss: 0.156328; batch adversarial loss: 0.444831\n",
      "epoch 84; iter: 0; batch classifier loss: 0.120416; batch adversarial loss: 0.469923\n",
      "epoch 85; iter: 0; batch classifier loss: 0.133387; batch adversarial loss: 0.479139\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067998; batch adversarial loss: 0.520385\n",
      "epoch 87; iter: 0; batch classifier loss: 0.093263; batch adversarial loss: 0.406529\n",
      "epoch 88; iter: 0; batch classifier loss: 0.096654; batch adversarial loss: 0.481719\n",
      "epoch 89; iter: 0; batch classifier loss: 0.124710; batch adversarial loss: 0.439566\n",
      "epoch 90; iter: 0; batch classifier loss: 0.089301; batch adversarial loss: 0.473788\n",
      "epoch 91; iter: 0; batch classifier loss: 0.130301; batch adversarial loss: 0.463863\n",
      "epoch 92; iter: 0; batch classifier loss: 0.111231; batch adversarial loss: 0.497118\n",
      "epoch 93; iter: 0; batch classifier loss: 0.104195; batch adversarial loss: 0.513291\n",
      "epoch 94; iter: 0; batch classifier loss: 0.107995; batch adversarial loss: 0.511668\n",
      "epoch 95; iter: 0; batch classifier loss: 0.143503; batch adversarial loss: 0.495112\n",
      "epoch 96; iter: 0; batch classifier loss: 0.114499; batch adversarial loss: 0.490628\n",
      "epoch 97; iter: 0; batch classifier loss: 0.157785; batch adversarial loss: 0.483229\n",
      "epoch 98; iter: 0; batch classifier loss: 0.084506; batch adversarial loss: 0.554638\n",
      "epoch 99; iter: 0; batch classifier loss: 0.186828; batch adversarial loss: 0.372017\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055918; batch adversarial loss: 0.443611\n",
      "epoch 101; iter: 0; batch classifier loss: 0.109265; batch adversarial loss: 0.468217\n",
      "epoch 102; iter: 0; batch classifier loss: 0.089373; batch adversarial loss: 0.405690\n",
      "epoch 103; iter: 0; batch classifier loss: 0.159373; batch adversarial loss: 0.389631\n",
      "epoch 104; iter: 0; batch classifier loss: 0.115267; batch adversarial loss: 0.441066\n",
      "epoch 105; iter: 0; batch classifier loss: 0.131741; batch adversarial loss: 0.442862\n",
      "epoch 106; iter: 0; batch classifier loss: 0.119147; batch adversarial loss: 0.474690\n",
      "epoch 107; iter: 0; batch classifier loss: 0.081350; batch adversarial loss: 0.462755\n",
      "epoch 108; iter: 0; batch classifier loss: 0.094339; batch adversarial loss: 0.435068\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067614; batch adversarial loss: 0.490419\n",
      "epoch 110; iter: 0; batch classifier loss: 0.079335; batch adversarial loss: 0.375327\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066163; batch adversarial loss: 0.458223\n",
      "epoch 112; iter: 0; batch classifier loss: 0.118057; batch adversarial loss: 0.410706\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053332; batch adversarial loss: 0.508465\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061218; batch adversarial loss: 0.500799\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057345; batch adversarial loss: 0.390391\n",
      "epoch 116; iter: 0; batch classifier loss: 0.103778; batch adversarial loss: 0.422272\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060382; batch adversarial loss: 0.396564\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031116; batch adversarial loss: 0.419170\n",
      "epoch 119; iter: 0; batch classifier loss: 0.078866; batch adversarial loss: 0.429015\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045556; batch adversarial loss: 0.483143\n",
      "epoch 121; iter: 0; batch classifier loss: 0.061470; batch adversarial loss: 0.519376\n",
      "epoch 122; iter: 0; batch classifier loss: 0.072149; batch adversarial loss: 0.501145\n",
      "epoch 123; iter: 0; batch classifier loss: 0.069042; batch adversarial loss: 0.379135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.036385; batch adversarial loss: 0.502937\n",
      "epoch 125; iter: 0; batch classifier loss: 0.076550; batch adversarial loss: 0.502099\n",
      "epoch 126; iter: 0; batch classifier loss: 0.078084; batch adversarial loss: 0.460715\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046847; batch adversarial loss: 0.386209\n",
      "epoch 128; iter: 0; batch classifier loss: 0.073904; batch adversarial loss: 0.513483\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033511; batch adversarial loss: 0.407726\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057577; batch adversarial loss: 0.351895\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037773; batch adversarial loss: 0.473738\n",
      "epoch 132; iter: 0; batch classifier loss: 0.074433; batch adversarial loss: 0.468889\n",
      "epoch 133; iter: 0; batch classifier loss: 0.094371; batch adversarial loss: 0.463336\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045064; batch adversarial loss: 0.393877\n",
      "epoch 135; iter: 0; batch classifier loss: 0.061147; batch adversarial loss: 0.449547\n",
      "epoch 136; iter: 0; batch classifier loss: 0.058640; batch adversarial loss: 0.424200\n",
      "epoch 137; iter: 0; batch classifier loss: 0.066085; batch adversarial loss: 0.424330\n",
      "epoch 138; iter: 0; batch classifier loss: 0.047549; batch adversarial loss: 0.433127\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040721; batch adversarial loss: 0.458542\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037484; batch adversarial loss: 0.463184\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045017; batch adversarial loss: 0.614827\n",
      "epoch 142; iter: 0; batch classifier loss: 0.059559; batch adversarial loss: 0.495393\n",
      "epoch 143; iter: 0; batch classifier loss: 0.054038; batch adversarial loss: 0.311531\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052525; batch adversarial loss: 0.351661\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048058; batch adversarial loss: 0.414471\n",
      "epoch 146; iter: 0; batch classifier loss: 0.069393; batch adversarial loss: 0.531951\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046788; batch adversarial loss: 0.441348\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025130; batch adversarial loss: 0.433580\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016825; batch adversarial loss: 0.490434\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031787; batch adversarial loss: 0.339761\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039378; batch adversarial loss: 0.425355\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025571; batch adversarial loss: 0.365940\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030050; batch adversarial loss: 0.451499\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025502; batch adversarial loss: 0.434503\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044150; batch adversarial loss: 0.467099\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031249; batch adversarial loss: 0.477703\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025060; batch adversarial loss: 0.424409\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037892; batch adversarial loss: 0.440277\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025718; batch adversarial loss: 0.496422\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024130; batch adversarial loss: 0.372072\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031667; batch adversarial loss: 0.379092\n",
      "epoch 162; iter: 0; batch classifier loss: 0.035353; batch adversarial loss: 0.421007\n",
      "epoch 163; iter: 0; batch classifier loss: 0.050752; batch adversarial loss: 0.414698\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033947; batch adversarial loss: 0.422484\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041302; batch adversarial loss: 0.452708\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031148; batch adversarial loss: 0.443663\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012211; batch adversarial loss: 0.436366\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037020; batch adversarial loss: 0.408867\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033816; batch adversarial loss: 0.406800\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022767; batch adversarial loss: 0.365456\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027460; batch adversarial loss: 0.396700\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016209; batch adversarial loss: 0.541916\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017876; batch adversarial loss: 0.537073\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021078; batch adversarial loss: 0.523630\n",
      "epoch 175; iter: 0; batch classifier loss: 0.044138; batch adversarial loss: 0.519984\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024884; batch adversarial loss: 0.456879\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031420; batch adversarial loss: 0.404975\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034466; batch adversarial loss: 0.328502\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029034; batch adversarial loss: 0.528934\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014823; batch adversarial loss: 0.461362\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039014; batch adversarial loss: 0.519856\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016916; batch adversarial loss: 0.421021\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015229; batch adversarial loss: 0.480187\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020750; batch adversarial loss: 0.491410\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022088; batch adversarial loss: 0.473647\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026713; batch adversarial loss: 0.430862\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032356; batch adversarial loss: 0.628760\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030510; batch adversarial loss: 0.429002\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033945; batch adversarial loss: 0.562895\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024065; batch adversarial loss: 0.458086\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010490; batch adversarial loss: 0.525727\n",
      "epoch 192; iter: 0; batch classifier loss: 0.048181; batch adversarial loss: 0.400666\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023754; batch adversarial loss: 0.545289\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009175; batch adversarial loss: 0.474004\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005854; batch adversarial loss: 0.550554\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022324; batch adversarial loss: 0.492298\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017582; batch adversarial loss: 0.439365\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021543; batch adversarial loss: 0.406539\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026362; batch adversarial loss: 0.459813\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684853; batch adversarial loss: 0.751985\n",
      "epoch 1; iter: 0; batch classifier loss: 0.483673; batch adversarial loss: 0.681593\n",
      "epoch 2; iter: 0; batch classifier loss: 0.395855; batch adversarial loss: 0.629128\n",
      "epoch 3; iter: 0; batch classifier loss: 0.380656; batch adversarial loss: 0.612987\n",
      "epoch 4; iter: 0; batch classifier loss: 0.381788; batch adversarial loss: 0.568142\n",
      "epoch 5; iter: 0; batch classifier loss: 0.301576; batch adversarial loss: 0.613099\n",
      "epoch 6; iter: 0; batch classifier loss: 0.346994; batch adversarial loss: 0.569513\n",
      "epoch 7; iter: 0; batch classifier loss: 0.268657; batch adversarial loss: 0.560105\n",
      "epoch 8; iter: 0; batch classifier loss: 0.295343; batch adversarial loss: 0.546760\n",
      "epoch 9; iter: 0; batch classifier loss: 0.201300; batch adversarial loss: 0.510820\n",
      "epoch 10; iter: 0; batch classifier loss: 0.331141; batch adversarial loss: 0.517923\n",
      "epoch 11; iter: 0; batch classifier loss: 0.337552; batch adversarial loss: 0.545644\n",
      "epoch 12; iter: 0; batch classifier loss: 0.244570; batch adversarial loss: 0.533741\n",
      "epoch 13; iter: 0; batch classifier loss: 0.227441; batch adversarial loss: 0.522462\n",
      "epoch 14; iter: 0; batch classifier loss: 0.298099; batch adversarial loss: 0.488037\n",
      "epoch 15; iter: 0; batch classifier loss: 0.241719; batch adversarial loss: 0.525271\n",
      "epoch 16; iter: 0; batch classifier loss: 0.276096; batch adversarial loss: 0.490133\n",
      "epoch 17; iter: 0; batch classifier loss: 0.240623; batch adversarial loss: 0.527744\n",
      "epoch 18; iter: 0; batch classifier loss: 0.256263; batch adversarial loss: 0.493738\n",
      "epoch 19; iter: 0; batch classifier loss: 0.254507; batch adversarial loss: 0.542051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.233530; batch adversarial loss: 0.521199\n",
      "epoch 21; iter: 0; batch classifier loss: 0.170357; batch adversarial loss: 0.469347\n",
      "epoch 22; iter: 0; batch classifier loss: 0.197950; batch adversarial loss: 0.581307\n",
      "epoch 23; iter: 0; batch classifier loss: 0.233087; batch adversarial loss: 0.521677\n",
      "epoch 24; iter: 0; batch classifier loss: 0.163727; batch adversarial loss: 0.523312\n",
      "epoch 25; iter: 0; batch classifier loss: 0.165343; batch adversarial loss: 0.408967\n",
      "epoch 26; iter: 0; batch classifier loss: 0.244000; batch adversarial loss: 0.514160\n",
      "epoch 27; iter: 0; batch classifier loss: 0.131213; batch adversarial loss: 0.481540\n",
      "epoch 28; iter: 0; batch classifier loss: 0.213337; batch adversarial loss: 0.412251\n",
      "epoch 29; iter: 0; batch classifier loss: 0.155074; batch adversarial loss: 0.517860\n",
      "epoch 30; iter: 0; batch classifier loss: 0.184449; batch adversarial loss: 0.526090\n",
      "epoch 31; iter: 0; batch classifier loss: 0.102384; batch adversarial loss: 0.456759\n",
      "epoch 32; iter: 0; batch classifier loss: 0.143163; batch adversarial loss: 0.423817\n",
      "epoch 33; iter: 0; batch classifier loss: 0.095298; batch adversarial loss: 0.489467\n",
      "epoch 34; iter: 0; batch classifier loss: 0.102920; batch adversarial loss: 0.465103\n",
      "epoch 35; iter: 0; batch classifier loss: 0.158528; batch adversarial loss: 0.367652\n",
      "epoch 36; iter: 0; batch classifier loss: 0.112778; batch adversarial loss: 0.477784\n",
      "epoch 37; iter: 0; batch classifier loss: 0.152290; batch adversarial loss: 0.466393\n",
      "epoch 38; iter: 0; batch classifier loss: 0.116266; batch adversarial loss: 0.491905\n",
      "epoch 39; iter: 0; batch classifier loss: 0.134203; batch adversarial loss: 0.445484\n",
      "epoch 40; iter: 0; batch classifier loss: 0.089867; batch adversarial loss: 0.462181\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125564; batch adversarial loss: 0.397041\n",
      "epoch 42; iter: 0; batch classifier loss: 0.065438; batch adversarial loss: 0.476052\n",
      "epoch 43; iter: 0; batch classifier loss: 0.115855; batch adversarial loss: 0.497036\n",
      "epoch 44; iter: 0; batch classifier loss: 0.142136; batch adversarial loss: 0.459084\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089978; batch adversarial loss: 0.484223\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114542; batch adversarial loss: 0.494600\n",
      "epoch 47; iter: 0; batch classifier loss: 0.122683; batch adversarial loss: 0.403041\n",
      "epoch 48; iter: 0; batch classifier loss: 0.093020; batch adversarial loss: 0.455855\n",
      "epoch 49; iter: 0; batch classifier loss: 0.117900; batch adversarial loss: 0.463380\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094336; batch adversarial loss: 0.517580\n",
      "epoch 51; iter: 0; batch classifier loss: 0.091760; batch adversarial loss: 0.446575\n",
      "epoch 52; iter: 0; batch classifier loss: 0.119420; batch adversarial loss: 0.432596\n",
      "epoch 53; iter: 0; batch classifier loss: 0.086089; batch adversarial loss: 0.463671\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108493; batch adversarial loss: 0.448532\n",
      "epoch 55; iter: 0; batch classifier loss: 0.041836; batch adversarial loss: 0.524933\n",
      "epoch 56; iter: 0; batch classifier loss: 0.070212; batch adversarial loss: 0.525669\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107807; batch adversarial loss: 0.432674\n",
      "epoch 58; iter: 0; batch classifier loss: 0.124292; batch adversarial loss: 0.441981\n",
      "epoch 59; iter: 0; batch classifier loss: 0.095734; batch adversarial loss: 0.428809\n",
      "epoch 60; iter: 0; batch classifier loss: 0.127780; batch adversarial loss: 0.489630\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071395; batch adversarial loss: 0.382267\n",
      "epoch 62; iter: 0; batch classifier loss: 0.117075; batch adversarial loss: 0.519789\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092437; batch adversarial loss: 0.459925\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082657; batch adversarial loss: 0.441227\n",
      "epoch 65; iter: 0; batch classifier loss: 0.064312; batch adversarial loss: 0.544280\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088985; batch adversarial loss: 0.467630\n",
      "epoch 67; iter: 0; batch classifier loss: 0.092752; batch adversarial loss: 0.454239\n",
      "epoch 68; iter: 0; batch classifier loss: 0.090730; batch adversarial loss: 0.448104\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073608; batch adversarial loss: 0.496877\n",
      "epoch 70; iter: 0; batch classifier loss: 0.074462; batch adversarial loss: 0.332408\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063800; batch adversarial loss: 0.484430\n",
      "epoch 72; iter: 0; batch classifier loss: 0.096610; batch adversarial loss: 0.407582\n",
      "epoch 73; iter: 0; batch classifier loss: 0.059705; batch adversarial loss: 0.419097\n",
      "epoch 74; iter: 0; batch classifier loss: 0.103023; batch adversarial loss: 0.457814\n",
      "epoch 75; iter: 0; batch classifier loss: 0.104078; batch adversarial loss: 0.405375\n",
      "epoch 76; iter: 0; batch classifier loss: 0.054084; batch adversarial loss: 0.422135\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074637; batch adversarial loss: 0.414412\n",
      "epoch 78; iter: 0; batch classifier loss: 0.034019; batch adversarial loss: 0.385041\n",
      "epoch 79; iter: 0; batch classifier loss: 0.058854; batch adversarial loss: 0.503242\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043488; batch adversarial loss: 0.531125\n",
      "epoch 81; iter: 0; batch classifier loss: 0.054796; batch adversarial loss: 0.411893\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053266; batch adversarial loss: 0.493896\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079055; batch adversarial loss: 0.449244\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055273; batch adversarial loss: 0.473199\n",
      "epoch 85; iter: 0; batch classifier loss: 0.078164; batch adversarial loss: 0.666684\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067688; batch adversarial loss: 0.417805\n",
      "epoch 87; iter: 0; batch classifier loss: 0.024506; batch adversarial loss: 0.450572\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067160; batch adversarial loss: 0.494187\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058808; batch adversarial loss: 0.406566\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054626; batch adversarial loss: 0.464045\n",
      "epoch 91; iter: 0; batch classifier loss: 0.034889; batch adversarial loss: 0.613325\n",
      "epoch 92; iter: 0; batch classifier loss: 0.033143; batch adversarial loss: 0.436520\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079548; batch adversarial loss: 0.548505\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066665; batch adversarial loss: 0.488473\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057932; batch adversarial loss: 0.418987\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037754; batch adversarial loss: 0.455918\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050424; batch adversarial loss: 0.585281\n",
      "epoch 98; iter: 0; batch classifier loss: 0.040412; batch adversarial loss: 0.521913\n",
      "epoch 99; iter: 0; batch classifier loss: 0.033254; batch adversarial loss: 0.407246\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061214; batch adversarial loss: 0.477271\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044928; batch adversarial loss: 0.486821\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037111; batch adversarial loss: 0.350146\n",
      "epoch 103; iter: 0; batch classifier loss: 0.024358; batch adversarial loss: 0.549376\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037432; batch adversarial loss: 0.554798\n",
      "epoch 105; iter: 0; batch classifier loss: 0.033290; batch adversarial loss: 0.362970\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030404; batch adversarial loss: 0.425581\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050136; batch adversarial loss: 0.468723\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042829; batch adversarial loss: 0.492684\n",
      "epoch 109; iter: 0; batch classifier loss: 0.013473; batch adversarial loss: 0.359587\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035904; batch adversarial loss: 0.405472\n",
      "epoch 111; iter: 0; batch classifier loss: 0.024053; batch adversarial loss: 0.499255\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032635; batch adversarial loss: 0.475368\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039295; batch adversarial loss: 0.451666\n",
      "epoch 114; iter: 0; batch classifier loss: 0.066998; batch adversarial loss: 0.473047\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041195; batch adversarial loss: 0.459548\n",
      "epoch 116; iter: 0; batch classifier loss: 0.010150; batch adversarial loss: 0.508015\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037953; batch adversarial loss: 0.425844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.015431; batch adversarial loss: 0.478951\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019259; batch adversarial loss: 0.486748\n",
      "epoch 120; iter: 0; batch classifier loss: 0.017552; batch adversarial loss: 0.501207\n",
      "epoch 121; iter: 0; batch classifier loss: 0.012215; batch adversarial loss: 0.429838\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048848; batch adversarial loss: 0.446577\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023336; batch adversarial loss: 0.411754\n",
      "epoch 124; iter: 0; batch classifier loss: 0.017636; batch adversarial loss: 0.466705\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031210; batch adversarial loss: 0.499980\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026171; batch adversarial loss: 0.505347\n",
      "epoch 127; iter: 0; batch classifier loss: 0.017399; batch adversarial loss: 0.533362\n",
      "epoch 128; iter: 0; batch classifier loss: 0.020715; batch adversarial loss: 0.476836\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031342; batch adversarial loss: 0.453320\n",
      "epoch 130; iter: 0; batch classifier loss: 0.070247; batch adversarial loss: 0.448048\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046322; batch adversarial loss: 0.464154\n",
      "epoch 132; iter: 0; batch classifier loss: 0.010859; batch adversarial loss: 0.421894\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015563; batch adversarial loss: 0.446730\n",
      "epoch 134; iter: 0; batch classifier loss: 0.011435; batch adversarial loss: 0.449314\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013456; batch adversarial loss: 0.405208\n",
      "epoch 136; iter: 0; batch classifier loss: 0.048531; batch adversarial loss: 0.360817\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023358; batch adversarial loss: 0.452537\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027426; batch adversarial loss: 0.410447\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028047; batch adversarial loss: 0.411787\n",
      "epoch 140; iter: 0; batch classifier loss: 0.015219; batch adversarial loss: 0.460893\n",
      "epoch 141; iter: 0; batch classifier loss: 0.014004; batch adversarial loss: 0.391900\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024613; batch adversarial loss: 0.372379\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011956; batch adversarial loss: 0.482995\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029228; batch adversarial loss: 0.499762\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027391; batch adversarial loss: 0.422026\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017345; batch adversarial loss: 0.521411\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020981; batch adversarial loss: 0.420479\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036086; batch adversarial loss: 0.515280\n",
      "epoch 149; iter: 0; batch classifier loss: 0.069779; batch adversarial loss: 0.372739\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020984; batch adversarial loss: 0.420407\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030977; batch adversarial loss: 0.447449\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015988; batch adversarial loss: 0.378446\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030933; batch adversarial loss: 0.425739\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021002; batch adversarial loss: 0.481295\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031716; batch adversarial loss: 0.375906\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011626; batch adversarial loss: 0.429418\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014744; batch adversarial loss: 0.491729\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021308; batch adversarial loss: 0.398861\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028040; batch adversarial loss: 0.559558\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031237; batch adversarial loss: 0.524855\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019248; batch adversarial loss: 0.465457\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027887; batch adversarial loss: 0.413491\n",
      "epoch 163; iter: 0; batch classifier loss: 0.060472; batch adversarial loss: 0.384810\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026004; batch adversarial loss: 0.436505\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034426; batch adversarial loss: 0.533054\n",
      "epoch 166; iter: 0; batch classifier loss: 0.008446; batch adversarial loss: 0.497319\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013717; batch adversarial loss: 0.473015\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014277; batch adversarial loss: 0.380021\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030387; batch adversarial loss: 0.455283\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018727; batch adversarial loss: 0.545130\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010953; batch adversarial loss: 0.447305\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019401; batch adversarial loss: 0.531737\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026822; batch adversarial loss: 0.420061\n",
      "epoch 174; iter: 0; batch classifier loss: 0.045254; batch adversarial loss: 0.439882\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022508; batch adversarial loss: 0.430423\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012871; batch adversarial loss: 0.603974\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036373; batch adversarial loss: 0.525848\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026179; batch adversarial loss: 0.373344\n",
      "epoch 179; iter: 0; batch classifier loss: 0.005702; batch adversarial loss: 0.539468\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007740; batch adversarial loss: 0.424907\n",
      "epoch 181; iter: 0; batch classifier loss: 0.031572; batch adversarial loss: 0.444619\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007858; batch adversarial loss: 0.451940\n",
      "epoch 183; iter: 0; batch classifier loss: 0.038804; batch adversarial loss: 0.524731\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013777; batch adversarial loss: 0.496190\n",
      "epoch 185; iter: 0; batch classifier loss: 0.053371; batch adversarial loss: 0.374989\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016133; batch adversarial loss: 0.487210\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025213; batch adversarial loss: 0.484752\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017017; batch adversarial loss: 0.384624\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007624; batch adversarial loss: 0.476059\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024642; batch adversarial loss: 0.433440\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014130; batch adversarial loss: 0.418012\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033897; batch adversarial loss: 0.442451\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025621; batch adversarial loss: 0.540971\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014816; batch adversarial loss: 0.427141\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014174; batch adversarial loss: 0.438705\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008092; batch adversarial loss: 0.537814\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023246; batch adversarial loss: 0.490042\n",
      "epoch 198; iter: 0; batch classifier loss: 0.049239; batch adversarial loss: 0.453916\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033811; batch adversarial loss: 0.471675\n",
      "epoch 0; iter: 0; batch classifier loss: 0.628692; batch adversarial loss: 0.762525\n",
      "epoch 1; iter: 0; batch classifier loss: 0.455299; batch adversarial loss: 0.735572\n",
      "epoch 2; iter: 0; batch classifier loss: 0.345142; batch adversarial loss: 0.688756\n",
      "epoch 3; iter: 0; batch classifier loss: 0.352626; batch adversarial loss: 0.639124\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335769; batch adversarial loss: 0.630943\n",
      "epoch 5; iter: 0; batch classifier loss: 0.314543; batch adversarial loss: 0.598814\n",
      "epoch 6; iter: 0; batch classifier loss: 0.284134; batch adversarial loss: 0.584108\n",
      "epoch 7; iter: 0; batch classifier loss: 0.302068; batch adversarial loss: 0.537535\n",
      "epoch 8; iter: 0; batch classifier loss: 0.280670; batch adversarial loss: 0.555670\n",
      "epoch 9; iter: 0; batch classifier loss: 0.255486; batch adversarial loss: 0.509800\n",
      "epoch 10; iter: 0; batch classifier loss: 0.176308; batch adversarial loss: 0.512091\n",
      "epoch 11; iter: 0; batch classifier loss: 0.216922; batch adversarial loss: 0.526044\n",
      "epoch 12; iter: 0; batch classifier loss: 0.231203; batch adversarial loss: 0.506165\n",
      "epoch 13; iter: 0; batch classifier loss: 0.221614; batch adversarial loss: 0.484891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.205151; batch adversarial loss: 0.473159\n",
      "epoch 15; iter: 0; batch classifier loss: 0.278309; batch adversarial loss: 0.476552\n",
      "epoch 16; iter: 0; batch classifier loss: 0.213391; batch adversarial loss: 0.482409\n",
      "epoch 17; iter: 0; batch classifier loss: 0.189148; batch adversarial loss: 0.446905\n",
      "epoch 18; iter: 0; batch classifier loss: 0.162299; batch adversarial loss: 0.503417\n",
      "epoch 19; iter: 0; batch classifier loss: 0.164615; batch adversarial loss: 0.540965\n",
      "epoch 20; iter: 0; batch classifier loss: 0.180741; batch adversarial loss: 0.502697\n",
      "epoch 21; iter: 0; batch classifier loss: 0.211023; batch adversarial loss: 0.462095\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189945; batch adversarial loss: 0.533734\n",
      "epoch 23; iter: 0; batch classifier loss: 0.157907; batch adversarial loss: 0.449992\n",
      "epoch 24; iter: 0; batch classifier loss: 0.160129; batch adversarial loss: 0.462920\n",
      "epoch 25; iter: 0; batch classifier loss: 0.259789; batch adversarial loss: 0.536587\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193503; batch adversarial loss: 0.494281\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152205; batch adversarial loss: 0.467405\n",
      "epoch 28; iter: 0; batch classifier loss: 0.203306; batch adversarial loss: 0.401013\n",
      "epoch 29; iter: 0; batch classifier loss: 0.131847; batch adversarial loss: 0.477308\n",
      "epoch 30; iter: 0; batch classifier loss: 0.117531; batch adversarial loss: 0.499508\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170598; batch adversarial loss: 0.438074\n",
      "epoch 32; iter: 0; batch classifier loss: 0.118653; batch adversarial loss: 0.503586\n",
      "epoch 33; iter: 0; batch classifier loss: 0.111439; batch adversarial loss: 0.552823\n",
      "epoch 34; iter: 0; batch classifier loss: 0.174924; batch adversarial loss: 0.460511\n",
      "epoch 35; iter: 0; batch classifier loss: 0.166192; batch adversarial loss: 0.517639\n",
      "epoch 36; iter: 0; batch classifier loss: 0.172860; batch adversarial loss: 0.471492\n",
      "epoch 37; iter: 0; batch classifier loss: 0.073529; batch adversarial loss: 0.468555\n",
      "epoch 38; iter: 0; batch classifier loss: 0.100976; batch adversarial loss: 0.507205\n",
      "epoch 39; iter: 0; batch classifier loss: 0.110370; batch adversarial loss: 0.454993\n",
      "epoch 40; iter: 0; batch classifier loss: 0.126573; batch adversarial loss: 0.461142\n",
      "epoch 41; iter: 0; batch classifier loss: 0.105434; batch adversarial loss: 0.389354\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146382; batch adversarial loss: 0.526689\n",
      "epoch 43; iter: 0; batch classifier loss: 0.163864; batch adversarial loss: 0.446166\n",
      "epoch 44; iter: 0; batch classifier loss: 0.082373; batch adversarial loss: 0.479377\n",
      "epoch 45; iter: 0; batch classifier loss: 0.136357; batch adversarial loss: 0.608909\n",
      "epoch 46; iter: 0; batch classifier loss: 0.080811; batch adversarial loss: 0.511328\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103581; batch adversarial loss: 0.457261\n",
      "epoch 48; iter: 0; batch classifier loss: 0.105204; batch adversarial loss: 0.566436\n",
      "epoch 49; iter: 0; batch classifier loss: 0.091470; batch adversarial loss: 0.594450\n",
      "epoch 50; iter: 0; batch classifier loss: 0.233162; batch adversarial loss: 0.490355\n",
      "epoch 51; iter: 0; batch classifier loss: 0.131262; batch adversarial loss: 0.357669\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096714; batch adversarial loss: 0.422978\n",
      "epoch 53; iter: 0; batch classifier loss: 0.112970; batch adversarial loss: 0.494780\n",
      "epoch 54; iter: 0; batch classifier loss: 0.131463; batch adversarial loss: 0.455082\n",
      "epoch 55; iter: 0; batch classifier loss: 0.114590; batch adversarial loss: 0.443294\n",
      "epoch 56; iter: 0; batch classifier loss: 0.073972; batch adversarial loss: 0.426982\n",
      "epoch 57; iter: 0; batch classifier loss: 0.130882; batch adversarial loss: 0.533296\n",
      "epoch 58; iter: 0; batch classifier loss: 0.082135; batch adversarial loss: 0.391162\n",
      "epoch 59; iter: 0; batch classifier loss: 0.071378; batch adversarial loss: 0.538584\n",
      "epoch 60; iter: 0; batch classifier loss: 0.083267; batch adversarial loss: 0.389535\n",
      "epoch 61; iter: 0; batch classifier loss: 0.066636; batch adversarial loss: 0.438743\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069532; batch adversarial loss: 0.509522\n",
      "epoch 63; iter: 0; batch classifier loss: 0.067547; batch adversarial loss: 0.402085\n",
      "epoch 64; iter: 0; batch classifier loss: 0.127266; batch adversarial loss: 0.434468\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122330; batch adversarial loss: 0.472543\n",
      "epoch 66; iter: 0; batch classifier loss: 0.113189; batch adversarial loss: 0.418249\n",
      "epoch 67; iter: 0; batch classifier loss: 0.075530; batch adversarial loss: 0.475093\n",
      "epoch 68; iter: 0; batch classifier loss: 0.102129; batch adversarial loss: 0.438940\n",
      "epoch 69; iter: 0; batch classifier loss: 0.068428; batch adversarial loss: 0.319039\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076812; batch adversarial loss: 0.394044\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063517; batch adversarial loss: 0.447238\n",
      "epoch 72; iter: 0; batch classifier loss: 0.095184; batch adversarial loss: 0.463348\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102025; batch adversarial loss: 0.478367\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070140; batch adversarial loss: 0.508918\n",
      "epoch 75; iter: 0; batch classifier loss: 0.045474; batch adversarial loss: 0.402123\n",
      "epoch 76; iter: 0; batch classifier loss: 0.068282; batch adversarial loss: 0.515367\n",
      "epoch 77; iter: 0; batch classifier loss: 0.049659; batch adversarial loss: 0.484987\n",
      "epoch 78; iter: 0; batch classifier loss: 0.052291; batch adversarial loss: 0.417605\n",
      "epoch 79; iter: 0; batch classifier loss: 0.048504; batch adversarial loss: 0.459494\n",
      "epoch 80; iter: 0; batch classifier loss: 0.082487; batch adversarial loss: 0.371577\n",
      "epoch 81; iter: 0; batch classifier loss: 0.056981; batch adversarial loss: 0.419260\n",
      "epoch 82; iter: 0; batch classifier loss: 0.070023; batch adversarial loss: 0.429911\n",
      "epoch 83; iter: 0; batch classifier loss: 0.057731; batch adversarial loss: 0.490963\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069167; batch adversarial loss: 0.353207\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084005; batch adversarial loss: 0.485495\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062038; batch adversarial loss: 0.558805\n",
      "epoch 87; iter: 0; batch classifier loss: 0.033403; batch adversarial loss: 0.446964\n",
      "epoch 88; iter: 0; batch classifier loss: 0.022502; batch adversarial loss: 0.498829\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066277; batch adversarial loss: 0.400050\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051392; batch adversarial loss: 0.442607\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059259; batch adversarial loss: 0.425083\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060534; batch adversarial loss: 0.504652\n",
      "epoch 93; iter: 0; batch classifier loss: 0.033457; batch adversarial loss: 0.456889\n",
      "epoch 94; iter: 0; batch classifier loss: 0.098918; batch adversarial loss: 0.414860\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068921; batch adversarial loss: 0.417074\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044570; batch adversarial loss: 0.621393\n",
      "epoch 97; iter: 0; batch classifier loss: 0.025266; batch adversarial loss: 0.404918\n",
      "epoch 98; iter: 0; batch classifier loss: 0.037362; batch adversarial loss: 0.424967\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052972; batch adversarial loss: 0.424471\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050378; batch adversarial loss: 0.424041\n",
      "epoch 101; iter: 0; batch classifier loss: 0.020739; batch adversarial loss: 0.481821\n",
      "epoch 102; iter: 0; batch classifier loss: 0.019109; batch adversarial loss: 0.367836\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032009; batch adversarial loss: 0.441689\n",
      "epoch 104; iter: 0; batch classifier loss: 0.040495; batch adversarial loss: 0.450037\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029044; batch adversarial loss: 0.418916\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025295; batch adversarial loss: 0.452981\n",
      "epoch 107; iter: 0; batch classifier loss: 0.091801; batch adversarial loss: 0.437146\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036979; batch adversarial loss: 0.500771\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039386; batch adversarial loss: 0.326359\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030062; batch adversarial loss: 0.468200\n",
      "epoch 111; iter: 0; batch classifier loss: 0.023364; batch adversarial loss: 0.467095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.047979; batch adversarial loss: 0.465172\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025069; batch adversarial loss: 0.435228\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048205; batch adversarial loss: 0.400919\n",
      "epoch 115; iter: 0; batch classifier loss: 0.030316; batch adversarial loss: 0.446278\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030214; batch adversarial loss: 0.430079\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020726; batch adversarial loss: 0.448516\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032682; batch adversarial loss: 0.535617\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029909; batch adversarial loss: 0.447654\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046042; batch adversarial loss: 0.507917\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036154; batch adversarial loss: 0.465906\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044606; batch adversarial loss: 0.467594\n",
      "epoch 123; iter: 0; batch classifier loss: 0.018921; batch adversarial loss: 0.387751\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038457; batch adversarial loss: 0.524312\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032249; batch adversarial loss: 0.512504\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028676; batch adversarial loss: 0.449372\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023114; batch adversarial loss: 0.298099\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027804; batch adversarial loss: 0.511449\n",
      "epoch 129; iter: 0; batch classifier loss: 0.063998; batch adversarial loss: 0.384644\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050049; batch adversarial loss: 0.457281\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020800; batch adversarial loss: 0.389638\n",
      "epoch 132; iter: 0; batch classifier loss: 0.017031; batch adversarial loss: 0.435230\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040101; batch adversarial loss: 0.434927\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026470; batch adversarial loss: 0.466201\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036592; batch adversarial loss: 0.427240\n",
      "epoch 136; iter: 0; batch classifier loss: 0.010279; batch adversarial loss: 0.479109\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038438; batch adversarial loss: 0.437785\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027643; batch adversarial loss: 0.407698\n",
      "epoch 139; iter: 0; batch classifier loss: 0.027283; batch adversarial loss: 0.367978\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029697; batch adversarial loss: 0.497855\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017897; batch adversarial loss: 0.552510\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033490; batch adversarial loss: 0.526596\n",
      "epoch 143; iter: 0; batch classifier loss: 0.009203; batch adversarial loss: 0.415367\n",
      "epoch 144; iter: 0; batch classifier loss: 0.010019; batch adversarial loss: 0.442517\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019685; batch adversarial loss: 0.416046\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015236; batch adversarial loss: 0.369047\n",
      "epoch 147; iter: 0; batch classifier loss: 0.012406; batch adversarial loss: 0.396541\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017882; batch adversarial loss: 0.542202\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020540; batch adversarial loss: 0.454553\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019470; batch adversarial loss: 0.408894\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029168; batch adversarial loss: 0.551161\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016976; batch adversarial loss: 0.471499\n",
      "epoch 153; iter: 0; batch classifier loss: 0.049048; batch adversarial loss: 0.526995\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013874; batch adversarial loss: 0.446400\n",
      "epoch 155; iter: 0; batch classifier loss: 0.059482; batch adversarial loss: 0.386089\n",
      "epoch 156; iter: 0; batch classifier loss: 0.007609; batch adversarial loss: 0.518798\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014463; batch adversarial loss: 0.434241\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030608; batch adversarial loss: 0.383126\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030724; batch adversarial loss: 0.524859\n",
      "epoch 160; iter: 0; batch classifier loss: 0.060293; batch adversarial loss: 0.353271\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035837; batch adversarial loss: 0.552937\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025870; batch adversarial loss: 0.431644\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026759; batch adversarial loss: 0.456357\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012712; batch adversarial loss: 0.495431\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038210; batch adversarial loss: 0.568475\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015518; batch adversarial loss: 0.494885\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041821; batch adversarial loss: 0.418602\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020342; batch adversarial loss: 0.489437\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018598; batch adversarial loss: 0.516331\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017919; batch adversarial loss: 0.526948\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047430; batch adversarial loss: 0.457280\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024494; batch adversarial loss: 0.442278\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012913; batch adversarial loss: 0.533176\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033732; batch adversarial loss: 0.425634\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008923; batch adversarial loss: 0.425372\n",
      "epoch 176; iter: 0; batch classifier loss: 0.054573; batch adversarial loss: 0.379502\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018622; batch adversarial loss: 0.475142\n",
      "epoch 178; iter: 0; batch classifier loss: 0.059699; batch adversarial loss: 0.535193\n",
      "epoch 179; iter: 0; batch classifier loss: 0.065169; batch adversarial loss: 0.473549\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021254; batch adversarial loss: 0.386816\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038973; batch adversarial loss: 0.390813\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021250; batch adversarial loss: 0.376700\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029295; batch adversarial loss: 0.417206\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028687; batch adversarial loss: 0.424191\n",
      "epoch 185; iter: 0; batch classifier loss: 0.052314; batch adversarial loss: 0.403472\n",
      "epoch 186; iter: 0; batch classifier loss: 0.004276; batch adversarial loss: 0.411726\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018808; batch adversarial loss: 0.473692\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027646; batch adversarial loss: 0.399741\n",
      "epoch 189; iter: 0; batch classifier loss: 0.043901; batch adversarial loss: 0.441183\n",
      "epoch 190; iter: 0; batch classifier loss: 0.042541; batch adversarial loss: 0.440580\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037925; batch adversarial loss: 0.405037\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028258; batch adversarial loss: 0.468427\n",
      "epoch 193; iter: 0; batch classifier loss: 0.047196; batch adversarial loss: 0.407988\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024948; batch adversarial loss: 0.548647\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013983; batch adversarial loss: 0.432858\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023390; batch adversarial loss: 0.319717\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024905; batch adversarial loss: 0.415012\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030790; batch adversarial loss: 0.416326\n",
      "epoch 199; iter: 0; batch classifier loss: 0.041047; batch adversarial loss: 0.380143\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703066; batch adversarial loss: 0.796230\n",
      "epoch 1; iter: 0; batch classifier loss: 0.585006; batch adversarial loss: 0.726347\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595864; batch adversarial loss: 0.701650\n",
      "epoch 3; iter: 0; batch classifier loss: 0.431616; batch adversarial loss: 0.607557\n",
      "epoch 4; iter: 0; batch classifier loss: 0.336027; batch adversarial loss: 0.590010\n",
      "epoch 5; iter: 0; batch classifier loss: 0.308713; batch adversarial loss: 0.567769\n",
      "epoch 6; iter: 0; batch classifier loss: 0.305609; batch adversarial loss: 0.565970\n",
      "epoch 7; iter: 0; batch classifier loss: 0.263693; batch adversarial loss: 0.525614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.315074; batch adversarial loss: 0.534989\n",
      "epoch 9; iter: 0; batch classifier loss: 0.301296; batch adversarial loss: 0.552403\n",
      "epoch 10; iter: 0; batch classifier loss: 0.229872; batch adversarial loss: 0.527600\n",
      "epoch 11; iter: 0; batch classifier loss: 0.299909; batch adversarial loss: 0.530453\n",
      "epoch 12; iter: 0; batch classifier loss: 0.270382; batch adversarial loss: 0.470098\n",
      "epoch 13; iter: 0; batch classifier loss: 0.275346; batch adversarial loss: 0.483802\n",
      "epoch 14; iter: 0; batch classifier loss: 0.265913; batch adversarial loss: 0.493253\n",
      "epoch 15; iter: 0; batch classifier loss: 0.244122; batch adversarial loss: 0.496438\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222759; batch adversarial loss: 0.504766\n",
      "epoch 17; iter: 0; batch classifier loss: 0.201505; batch adversarial loss: 0.488200\n",
      "epoch 18; iter: 0; batch classifier loss: 0.195477; batch adversarial loss: 0.487682\n",
      "epoch 19; iter: 0; batch classifier loss: 0.168778; batch adversarial loss: 0.505747\n",
      "epoch 20; iter: 0; batch classifier loss: 0.173566; batch adversarial loss: 0.547251\n",
      "epoch 21; iter: 0; batch classifier loss: 0.168168; batch adversarial loss: 0.465438\n",
      "epoch 22; iter: 0; batch classifier loss: 0.180753; batch adversarial loss: 0.454645\n",
      "epoch 23; iter: 0; batch classifier loss: 0.238866; batch adversarial loss: 0.427710\n",
      "epoch 24; iter: 0; batch classifier loss: 0.225624; batch adversarial loss: 0.473578\n",
      "epoch 25; iter: 0; batch classifier loss: 0.200323; batch adversarial loss: 0.409657\n",
      "epoch 26; iter: 0; batch classifier loss: 0.160585; batch adversarial loss: 0.422055\n",
      "epoch 27; iter: 0; batch classifier loss: 0.103877; batch adversarial loss: 0.451516\n",
      "epoch 28; iter: 0; batch classifier loss: 0.107836; batch adversarial loss: 0.424100\n",
      "epoch 29; iter: 0; batch classifier loss: 0.155622; batch adversarial loss: 0.421863\n",
      "epoch 30; iter: 0; batch classifier loss: 0.148433; batch adversarial loss: 0.437823\n",
      "epoch 31; iter: 0; batch classifier loss: 0.148350; batch adversarial loss: 0.468960\n",
      "epoch 32; iter: 0; batch classifier loss: 0.180546; batch adversarial loss: 0.504977\n",
      "epoch 33; iter: 0; batch classifier loss: 0.133389; batch adversarial loss: 0.562122\n",
      "epoch 34; iter: 0; batch classifier loss: 0.191453; batch adversarial loss: 0.429346\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142054; batch adversarial loss: 0.501945\n",
      "epoch 36; iter: 0; batch classifier loss: 0.169708; batch adversarial loss: 0.432330\n",
      "epoch 37; iter: 0; batch classifier loss: 0.122097; batch adversarial loss: 0.479150\n",
      "epoch 38; iter: 0; batch classifier loss: 0.163081; batch adversarial loss: 0.460085\n",
      "epoch 39; iter: 0; batch classifier loss: 0.115162; batch adversarial loss: 0.422947\n",
      "epoch 40; iter: 0; batch classifier loss: 0.113457; batch adversarial loss: 0.549741\n",
      "epoch 41; iter: 0; batch classifier loss: 0.054763; batch adversarial loss: 0.493747\n",
      "epoch 42; iter: 0; batch classifier loss: 0.080329; batch adversarial loss: 0.477121\n",
      "epoch 43; iter: 0; batch classifier loss: 0.115810; batch adversarial loss: 0.570022\n",
      "epoch 44; iter: 0; batch classifier loss: 0.096537; batch adversarial loss: 0.452274\n",
      "epoch 45; iter: 0; batch classifier loss: 0.144869; batch adversarial loss: 0.471095\n",
      "epoch 46; iter: 0; batch classifier loss: 0.205976; batch adversarial loss: 0.460271\n",
      "epoch 47; iter: 0; batch classifier loss: 0.170898; batch adversarial loss: 0.376179\n",
      "epoch 48; iter: 0; batch classifier loss: 0.120262; batch adversarial loss: 0.517332\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098559; batch adversarial loss: 0.526855\n",
      "epoch 50; iter: 0; batch classifier loss: 0.089092; batch adversarial loss: 0.533238\n",
      "epoch 51; iter: 0; batch classifier loss: 0.144937; batch adversarial loss: 0.581375\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111392; batch adversarial loss: 0.464750\n",
      "epoch 53; iter: 0; batch classifier loss: 0.120954; batch adversarial loss: 0.466396\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077597; batch adversarial loss: 0.634725\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079026; batch adversarial loss: 0.547582\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103444; batch adversarial loss: 0.406044\n",
      "epoch 57; iter: 0; batch classifier loss: 0.091143; batch adversarial loss: 0.516421\n",
      "epoch 58; iter: 0; batch classifier loss: 0.096578; batch adversarial loss: 0.449627\n",
      "epoch 59; iter: 0; batch classifier loss: 0.148627; batch adversarial loss: 0.602664\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097982; batch adversarial loss: 0.403050\n",
      "epoch 61; iter: 0; batch classifier loss: 0.102713; batch adversarial loss: 0.475066\n",
      "epoch 62; iter: 0; batch classifier loss: 0.106316; batch adversarial loss: 0.425646\n",
      "epoch 63; iter: 0; batch classifier loss: 0.090072; batch adversarial loss: 0.457662\n",
      "epoch 64; iter: 0; batch classifier loss: 0.097747; batch adversarial loss: 0.529940\n",
      "epoch 65; iter: 0; batch classifier loss: 0.115847; batch adversarial loss: 0.464756\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096810; batch adversarial loss: 0.442339\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094918; batch adversarial loss: 0.436634\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072728; batch adversarial loss: 0.482464\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063594; batch adversarial loss: 0.532307\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065421; batch adversarial loss: 0.453940\n",
      "epoch 71; iter: 0; batch classifier loss: 0.065554; batch adversarial loss: 0.372889\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077892; batch adversarial loss: 0.498388\n",
      "epoch 73; iter: 0; batch classifier loss: 0.096735; batch adversarial loss: 0.508258\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076589; batch adversarial loss: 0.362937\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083943; batch adversarial loss: 0.356819\n",
      "epoch 76; iter: 0; batch classifier loss: 0.106768; batch adversarial loss: 0.367618\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094478; batch adversarial loss: 0.468502\n",
      "epoch 78; iter: 0; batch classifier loss: 0.134576; batch adversarial loss: 0.428058\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085209; batch adversarial loss: 0.379668\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070331; batch adversarial loss: 0.476198\n",
      "epoch 81; iter: 0; batch classifier loss: 0.062902; batch adversarial loss: 0.492960\n",
      "epoch 82; iter: 0; batch classifier loss: 0.077079; batch adversarial loss: 0.440755\n",
      "epoch 83; iter: 0; batch classifier loss: 0.102085; batch adversarial loss: 0.492418\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103312; batch adversarial loss: 0.419991\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090039; batch adversarial loss: 0.475636\n",
      "epoch 86; iter: 0; batch classifier loss: 0.090877; batch adversarial loss: 0.462665\n",
      "epoch 87; iter: 0; batch classifier loss: 0.060789; batch adversarial loss: 0.410303\n",
      "epoch 88; iter: 0; batch classifier loss: 0.110718; batch adversarial loss: 0.457038\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058033; batch adversarial loss: 0.438237\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053908; batch adversarial loss: 0.497076\n",
      "epoch 91; iter: 0; batch classifier loss: 0.131504; batch adversarial loss: 0.513873\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082426; batch adversarial loss: 0.503224\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047478; batch adversarial loss: 0.444374\n",
      "epoch 94; iter: 0; batch classifier loss: 0.035750; batch adversarial loss: 0.412940\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063769; batch adversarial loss: 0.522366\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065135; batch adversarial loss: 0.406993\n",
      "epoch 97; iter: 0; batch classifier loss: 0.093433; batch adversarial loss: 0.431857\n",
      "epoch 98; iter: 0; batch classifier loss: 0.099664; batch adversarial loss: 0.450208\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044618; batch adversarial loss: 0.457654\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047186; batch adversarial loss: 0.487587\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056574; batch adversarial loss: 0.379626\n",
      "epoch 102; iter: 0; batch classifier loss: 0.072609; batch adversarial loss: 0.429697\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033877; batch adversarial loss: 0.554258\n",
      "epoch 104; iter: 0; batch classifier loss: 0.084927; batch adversarial loss: 0.512347\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062525; batch adversarial loss: 0.386304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.049016; batch adversarial loss: 0.438957\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062670; batch adversarial loss: 0.478227\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067138; batch adversarial loss: 0.426425\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045463; batch adversarial loss: 0.502114\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044426; batch adversarial loss: 0.566564\n",
      "epoch 111; iter: 0; batch classifier loss: 0.056333; batch adversarial loss: 0.415517\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041532; batch adversarial loss: 0.428661\n",
      "epoch 113; iter: 0; batch classifier loss: 0.020823; batch adversarial loss: 0.495221\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035042; batch adversarial loss: 0.409001\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029710; batch adversarial loss: 0.425298\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054342; batch adversarial loss: 0.418857\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055042; batch adversarial loss: 0.507225\n",
      "epoch 118; iter: 0; batch classifier loss: 0.067444; batch adversarial loss: 0.406433\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022659; batch adversarial loss: 0.504500\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054893; batch adversarial loss: 0.501153\n",
      "epoch 121; iter: 0; batch classifier loss: 0.075675; batch adversarial loss: 0.456953\n",
      "epoch 122; iter: 0; batch classifier loss: 0.019199; batch adversarial loss: 0.426901\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029490; batch adversarial loss: 0.565889\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023531; batch adversarial loss: 0.447288\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032892; batch adversarial loss: 0.411964\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036436; batch adversarial loss: 0.464031\n",
      "epoch 127; iter: 0; batch classifier loss: 0.038755; batch adversarial loss: 0.415068\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056418; batch adversarial loss: 0.429890\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016774; batch adversarial loss: 0.485460\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026475; batch adversarial loss: 0.435669\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023081; batch adversarial loss: 0.585092\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046281; batch adversarial loss: 0.389030\n",
      "epoch 133; iter: 0; batch classifier loss: 0.012029; batch adversarial loss: 0.478242\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046422; batch adversarial loss: 0.444673\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020805; batch adversarial loss: 0.366385\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036175; batch adversarial loss: 0.420034\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037178; batch adversarial loss: 0.460531\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027962; batch adversarial loss: 0.565707\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021379; batch adversarial loss: 0.411241\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027039; batch adversarial loss: 0.513302\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019611; batch adversarial loss: 0.487478\n",
      "epoch 142; iter: 0; batch classifier loss: 0.046206; batch adversarial loss: 0.440784\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023332; batch adversarial loss: 0.516609\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024455; batch adversarial loss: 0.437040\n",
      "epoch 145; iter: 0; batch classifier loss: 0.058704; batch adversarial loss: 0.395015\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026579; batch adversarial loss: 0.425152\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013358; batch adversarial loss: 0.458986\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042675; batch adversarial loss: 0.598092\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013463; batch adversarial loss: 0.511591\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014792; batch adversarial loss: 0.459948\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011243; batch adversarial loss: 0.460922\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041507; batch adversarial loss: 0.491828\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013950; batch adversarial loss: 0.512057\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020973; batch adversarial loss: 0.508042\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014666; batch adversarial loss: 0.423560\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015360; batch adversarial loss: 0.510588\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024306; batch adversarial loss: 0.446296\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018342; batch adversarial loss: 0.468518\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019828; batch adversarial loss: 0.440625\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024561; batch adversarial loss: 0.445035\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015901; batch adversarial loss: 0.487188\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037501; batch adversarial loss: 0.423671\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021670; batch adversarial loss: 0.444327\n",
      "epoch 164; iter: 0; batch classifier loss: 0.048595; batch adversarial loss: 0.427431\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014134; batch adversarial loss: 0.537356\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009543; batch adversarial loss: 0.477843\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010628; batch adversarial loss: 0.478662\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019164; batch adversarial loss: 0.415465\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011415; batch adversarial loss: 0.451035\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027432; batch adversarial loss: 0.538374\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021162; batch adversarial loss: 0.462913\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007490; batch adversarial loss: 0.359708\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012491; batch adversarial loss: 0.419480\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019121; batch adversarial loss: 0.456487\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010034; batch adversarial loss: 0.468425\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012836; batch adversarial loss: 0.453839\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027316; batch adversarial loss: 0.527337\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009196; batch adversarial loss: 0.481271\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016852; batch adversarial loss: 0.465251\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011214; batch adversarial loss: 0.540241\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014417; batch adversarial loss: 0.363798\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013732; batch adversarial loss: 0.462545\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022971; batch adversarial loss: 0.524541\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013094; batch adversarial loss: 0.423004\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008539; batch adversarial loss: 0.562422\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011246; batch adversarial loss: 0.364382\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012950; batch adversarial loss: 0.395088\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010462; batch adversarial loss: 0.401066\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009115; batch adversarial loss: 0.503479\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026890; batch adversarial loss: 0.421597\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022616; batch adversarial loss: 0.431676\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009110; batch adversarial loss: 0.503528\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021111; batch adversarial loss: 0.503650\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009762; batch adversarial loss: 0.541010\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011931; batch adversarial loss: 0.466556\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014059; batch adversarial loss: 0.430470\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009518; batch adversarial loss: 0.494751\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005593; batch adversarial loss: 0.510324\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011822; batch adversarial loss: 0.424160\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711390; batch adversarial loss: 0.652930\n",
      "epoch 1; iter: 0; batch classifier loss: 0.477326; batch adversarial loss: 0.636429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.464301; batch adversarial loss: 0.570683\n",
      "epoch 3; iter: 0; batch classifier loss: 0.331219; batch adversarial loss: 0.545217\n",
      "epoch 4; iter: 0; batch classifier loss: 0.339023; batch adversarial loss: 0.531721\n",
      "epoch 5; iter: 0; batch classifier loss: 0.381475; batch adversarial loss: 0.527240\n",
      "epoch 6; iter: 0; batch classifier loss: 0.317230; batch adversarial loss: 0.493284\n",
      "epoch 7; iter: 0; batch classifier loss: 0.319756; batch adversarial loss: 0.567599\n",
      "epoch 8; iter: 0; batch classifier loss: 0.321039; batch adversarial loss: 0.555377\n",
      "epoch 9; iter: 0; batch classifier loss: 0.360176; batch adversarial loss: 0.471084\n",
      "epoch 10; iter: 0; batch classifier loss: 0.254044; batch adversarial loss: 0.524508\n",
      "epoch 11; iter: 0; batch classifier loss: 0.315505; batch adversarial loss: 0.481197\n",
      "epoch 12; iter: 0; batch classifier loss: 0.267415; batch adversarial loss: 0.455973\n",
      "epoch 13; iter: 0; batch classifier loss: 0.323832; batch adversarial loss: 0.495510\n",
      "epoch 14; iter: 0; batch classifier loss: 0.252397; batch adversarial loss: 0.454048\n",
      "epoch 15; iter: 0; batch classifier loss: 0.196044; batch adversarial loss: 0.435871\n",
      "epoch 16; iter: 0; batch classifier loss: 0.249175; batch adversarial loss: 0.448860\n",
      "epoch 17; iter: 0; batch classifier loss: 0.236643; batch adversarial loss: 0.457647\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197410; batch adversarial loss: 0.497284\n",
      "epoch 19; iter: 0; batch classifier loss: 0.188326; batch adversarial loss: 0.454347\n",
      "epoch 20; iter: 0; batch classifier loss: 0.175954; batch adversarial loss: 0.475745\n",
      "epoch 21; iter: 0; batch classifier loss: 0.239361; batch adversarial loss: 0.483434\n",
      "epoch 22; iter: 0; batch classifier loss: 0.240600; batch adversarial loss: 0.507814\n",
      "epoch 23; iter: 0; batch classifier loss: 0.162947; batch adversarial loss: 0.518226\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195060; batch adversarial loss: 0.528268\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177725; batch adversarial loss: 0.457254\n",
      "epoch 26; iter: 0; batch classifier loss: 0.216930; batch adversarial loss: 0.481372\n",
      "epoch 27; iter: 0; batch classifier loss: 0.223915; batch adversarial loss: 0.391264\n",
      "epoch 28; iter: 0; batch classifier loss: 0.156844; batch adversarial loss: 0.495451\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182085; batch adversarial loss: 0.471367\n",
      "epoch 30; iter: 0; batch classifier loss: 0.200384; batch adversarial loss: 0.538318\n",
      "epoch 31; iter: 0; batch classifier loss: 0.165443; batch adversarial loss: 0.498150\n",
      "epoch 32; iter: 0; batch classifier loss: 0.164241; batch adversarial loss: 0.499284\n",
      "epoch 33; iter: 0; batch classifier loss: 0.159285; batch adversarial loss: 0.489935\n",
      "epoch 34; iter: 0; batch classifier loss: 0.227015; batch adversarial loss: 0.482998\n",
      "epoch 35; iter: 0; batch classifier loss: 0.147580; batch adversarial loss: 0.489329\n",
      "epoch 36; iter: 0; batch classifier loss: 0.193496; batch adversarial loss: 0.536572\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145896; batch adversarial loss: 0.443006\n",
      "epoch 38; iter: 0; batch classifier loss: 0.185102; batch adversarial loss: 0.437307\n",
      "epoch 39; iter: 0; batch classifier loss: 0.184540; batch adversarial loss: 0.459589\n",
      "epoch 40; iter: 0; batch classifier loss: 0.163473; batch adversarial loss: 0.508095\n",
      "epoch 41; iter: 0; batch classifier loss: 0.199915; batch adversarial loss: 0.461532\n",
      "epoch 42; iter: 0; batch classifier loss: 0.181912; batch adversarial loss: 0.475841\n",
      "epoch 43; iter: 0; batch classifier loss: 0.234793; batch adversarial loss: 0.455228\n",
      "epoch 44; iter: 0; batch classifier loss: 0.278962; batch adversarial loss: 0.446405\n",
      "epoch 45; iter: 0; batch classifier loss: 0.274502; batch adversarial loss: 0.404711\n",
      "epoch 46; iter: 0; batch classifier loss: 0.245738; batch adversarial loss: 0.462790\n",
      "epoch 47; iter: 0; batch classifier loss: 0.256698; batch adversarial loss: 0.372457\n",
      "epoch 48; iter: 0; batch classifier loss: 0.244762; batch adversarial loss: 0.412884\n",
      "epoch 49; iter: 0; batch classifier loss: 0.245499; batch adversarial loss: 0.472867\n",
      "epoch 50; iter: 0; batch classifier loss: 0.251756; batch adversarial loss: 0.466320\n",
      "epoch 51; iter: 0; batch classifier loss: 0.280770; batch adversarial loss: 0.413029\n",
      "epoch 52; iter: 0; batch classifier loss: 0.232892; batch adversarial loss: 0.436072\n",
      "epoch 53; iter: 0; batch classifier loss: 0.302718; batch adversarial loss: 0.494482\n",
      "epoch 54; iter: 0; batch classifier loss: 0.220051; batch adversarial loss: 0.471489\n",
      "epoch 55; iter: 0; batch classifier loss: 0.229269; batch adversarial loss: 0.506743\n",
      "epoch 56; iter: 0; batch classifier loss: 0.178852; batch adversarial loss: 0.385997\n",
      "epoch 57; iter: 0; batch classifier loss: 0.100616; batch adversarial loss: 0.424879\n",
      "epoch 58; iter: 0; batch classifier loss: 0.070893; batch adversarial loss: 0.367093\n",
      "epoch 59; iter: 0; batch classifier loss: 0.089500; batch adversarial loss: 0.456544\n",
      "epoch 60; iter: 0; batch classifier loss: 0.043358; batch adversarial loss: 0.483464\n",
      "epoch 61; iter: 0; batch classifier loss: 0.098851; batch adversarial loss: 0.458612\n",
      "epoch 62; iter: 0; batch classifier loss: 0.063049; batch adversarial loss: 0.491232\n",
      "epoch 63; iter: 0; batch classifier loss: 0.084920; batch adversarial loss: 0.495216\n",
      "epoch 64; iter: 0; batch classifier loss: 0.077364; batch adversarial loss: 0.408933\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088458; batch adversarial loss: 0.428244\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086329; batch adversarial loss: 0.412294\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095689; batch adversarial loss: 0.375896\n",
      "epoch 68; iter: 0; batch classifier loss: 0.087311; batch adversarial loss: 0.427763\n",
      "epoch 69; iter: 0; batch classifier loss: 0.127553; batch adversarial loss: 0.415873\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110064; batch adversarial loss: 0.404748\n",
      "epoch 71; iter: 0; batch classifier loss: 0.059575; batch adversarial loss: 0.509896\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087025; batch adversarial loss: 0.412108\n",
      "epoch 73; iter: 0; batch classifier loss: 0.086709; batch adversarial loss: 0.463677\n",
      "epoch 74; iter: 0; batch classifier loss: 0.114567; batch adversarial loss: 0.410694\n",
      "epoch 75; iter: 0; batch classifier loss: 0.107615; batch adversarial loss: 0.398432\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077798; batch adversarial loss: 0.482913\n",
      "epoch 77; iter: 0; batch classifier loss: 0.089956; batch adversarial loss: 0.506973\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075713; batch adversarial loss: 0.487912\n",
      "epoch 79; iter: 0; batch classifier loss: 0.087517; batch adversarial loss: 0.483332\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070909; batch adversarial loss: 0.384237\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096552; batch adversarial loss: 0.447604\n",
      "epoch 82; iter: 0; batch classifier loss: 0.080714; batch adversarial loss: 0.450780\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063167; batch adversarial loss: 0.522500\n",
      "epoch 84; iter: 0; batch classifier loss: 0.073067; batch adversarial loss: 0.416189\n",
      "epoch 85; iter: 0; batch classifier loss: 0.066011; batch adversarial loss: 0.471169\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072314; batch adversarial loss: 0.499533\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049735; batch adversarial loss: 0.423330\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067036; batch adversarial loss: 0.439131\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060668; batch adversarial loss: 0.354940\n",
      "epoch 90; iter: 0; batch classifier loss: 0.049573; batch adversarial loss: 0.417276\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062398; batch adversarial loss: 0.462522\n",
      "epoch 92; iter: 0; batch classifier loss: 0.088612; batch adversarial loss: 0.442507\n",
      "epoch 93; iter: 0; batch classifier loss: 0.096535; batch adversarial loss: 0.459410\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041978; batch adversarial loss: 0.447277\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044120; batch adversarial loss: 0.320455\n",
      "epoch 96; iter: 0; batch classifier loss: 0.077407; batch adversarial loss: 0.519766\n",
      "epoch 97; iter: 0; batch classifier loss: 0.079767; batch adversarial loss: 0.346081\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056584; batch adversarial loss: 0.405798\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055888; batch adversarial loss: 0.451160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.090936; batch adversarial loss: 0.520433\n",
      "epoch 101; iter: 0; batch classifier loss: 0.078559; batch adversarial loss: 0.478143\n",
      "epoch 102; iter: 0; batch classifier loss: 0.100029; batch adversarial loss: 0.445833\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041158; batch adversarial loss: 0.347740\n",
      "epoch 104; iter: 0; batch classifier loss: 0.068970; batch adversarial loss: 0.433094\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058284; batch adversarial loss: 0.437064\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052919; batch adversarial loss: 0.464522\n",
      "epoch 107; iter: 0; batch classifier loss: 0.076820; batch adversarial loss: 0.404674\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064614; batch adversarial loss: 0.513219\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066332; batch adversarial loss: 0.439277\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058382; batch adversarial loss: 0.436511\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049039; batch adversarial loss: 0.453286\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049746; batch adversarial loss: 0.375623\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056558; batch adversarial loss: 0.356475\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061113; batch adversarial loss: 0.435159\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060812; batch adversarial loss: 0.371216\n",
      "epoch 116; iter: 0; batch classifier loss: 0.129331; batch adversarial loss: 0.498573\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060575; batch adversarial loss: 0.473738\n",
      "epoch 118; iter: 0; batch classifier loss: 0.058768; batch adversarial loss: 0.338012\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059444; batch adversarial loss: 0.414110\n",
      "epoch 120; iter: 0; batch classifier loss: 0.069573; batch adversarial loss: 0.432343\n",
      "epoch 121; iter: 0; batch classifier loss: 0.094567; batch adversarial loss: 0.392478\n",
      "epoch 122; iter: 0; batch classifier loss: 0.085794; batch adversarial loss: 0.511687\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067362; batch adversarial loss: 0.481330\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052467; batch adversarial loss: 0.426333\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052009; batch adversarial loss: 0.395576\n",
      "epoch 126; iter: 0; batch classifier loss: 0.070971; batch adversarial loss: 0.450605\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046546; batch adversarial loss: 0.442856\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056552; batch adversarial loss: 0.388552\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040401; batch adversarial loss: 0.388483\n",
      "epoch 130; iter: 0; batch classifier loss: 0.055441; batch adversarial loss: 0.390883\n",
      "epoch 131; iter: 0; batch classifier loss: 0.062443; batch adversarial loss: 0.393343\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037286; batch adversarial loss: 0.410681\n",
      "epoch 133; iter: 0; batch classifier loss: 0.062259; batch adversarial loss: 0.365112\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045670; batch adversarial loss: 0.389882\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047246; batch adversarial loss: 0.427720\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034679; batch adversarial loss: 0.466229\n",
      "epoch 137; iter: 0; batch classifier loss: 0.065893; batch adversarial loss: 0.426492\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037574; batch adversarial loss: 0.391912\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038254; batch adversarial loss: 0.408783\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048818; batch adversarial loss: 0.493167\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042151; batch adversarial loss: 0.423138\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032089; batch adversarial loss: 0.475891\n",
      "epoch 143; iter: 0; batch classifier loss: 0.054425; batch adversarial loss: 0.473735\n",
      "epoch 144; iter: 0; batch classifier loss: 0.044600; batch adversarial loss: 0.355162\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043469; batch adversarial loss: 0.471658\n",
      "epoch 146; iter: 0; batch classifier loss: 0.059145; batch adversarial loss: 0.473823\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046584; batch adversarial loss: 0.435970\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032259; batch adversarial loss: 0.506779\n",
      "epoch 149; iter: 0; batch classifier loss: 0.057514; batch adversarial loss: 0.455886\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047659; batch adversarial loss: 0.385326\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027409; batch adversarial loss: 0.458788\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031107; batch adversarial loss: 0.418587\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048789; batch adversarial loss: 0.440413\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035500; batch adversarial loss: 0.300858\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030806; batch adversarial loss: 0.402922\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043788; batch adversarial loss: 0.459415\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033289; batch adversarial loss: 0.324996\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036638; batch adversarial loss: 0.520625\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040477; batch adversarial loss: 0.554587\n",
      "epoch 160; iter: 0; batch classifier loss: 0.087575; batch adversarial loss: 0.451800\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028977; batch adversarial loss: 0.400487\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021020; batch adversarial loss: 0.458050\n",
      "epoch 163; iter: 0; batch classifier loss: 0.051986; batch adversarial loss: 0.438370\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036085; batch adversarial loss: 0.481364\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024901; batch adversarial loss: 0.458179\n",
      "epoch 166; iter: 0; batch classifier loss: 0.049057; batch adversarial loss: 0.455718\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023947; batch adversarial loss: 0.425574\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022261; batch adversarial loss: 0.380066\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012515; batch adversarial loss: 0.417286\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018738; batch adversarial loss: 0.395475\n",
      "epoch 171; iter: 0; batch classifier loss: 0.043716; batch adversarial loss: 0.464547\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030523; batch adversarial loss: 0.512820\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036712; batch adversarial loss: 0.431963\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025509; batch adversarial loss: 0.376475\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038000; batch adversarial loss: 0.457407\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009061; batch adversarial loss: 0.450013\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016402; batch adversarial loss: 0.419925\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024813; batch adversarial loss: 0.454660\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025831; batch adversarial loss: 0.487585\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026132; batch adversarial loss: 0.420925\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011793; batch adversarial loss: 0.451024\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017899; batch adversarial loss: 0.499998\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017219; batch adversarial loss: 0.445772\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021634; batch adversarial loss: 0.481545\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042328; batch adversarial loss: 0.489414\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040941; batch adversarial loss: 0.406535\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031872; batch adversarial loss: 0.449411\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022455; batch adversarial loss: 0.438169\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041920; batch adversarial loss: 0.490592\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010346; batch adversarial loss: 0.422248\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016039; batch adversarial loss: 0.419410\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019485; batch adversarial loss: 0.478839\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019602; batch adversarial loss: 0.386952\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020824; batch adversarial loss: 0.378651\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019624; batch adversarial loss: 0.422215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.023189; batch adversarial loss: 0.415475\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014748; batch adversarial loss: 0.447378\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021897; batch adversarial loss: 0.368468\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011141; batch adversarial loss: 0.463565\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4bed3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
