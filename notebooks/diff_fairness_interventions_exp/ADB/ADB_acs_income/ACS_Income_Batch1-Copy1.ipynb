{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c97df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a52df56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:55:54.052462Z",
     "start_time": "2024-01-06T10:55:54.038357Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec7062b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:56:09.679156Z",
     "start_time": "2024-01-06T10:56:09.668186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "216cc947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.457257Z",
     "start_time": "2024-01-06T11:15:26.114625Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ef0ecf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.466361Z",
     "start_time": "2024-01-06T11:15:26.457627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d75aef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.478005Z",
     "start_time": "2024-01-06T11:15:26.467253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/dh3553/projects/fairness-variance\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec946ab3",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b5f14a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.734704Z",
     "start_time": "2024-01-06T11:15:28.036691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import ACSIncomeDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb99cce",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28d649d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.772286Z",
     "start_time": "2024-01-06T11:15:31.735883Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'ADB_acs_income'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION_NAME = 'ADB'\n",
    "FAIR_INTERVENTION_PARAMS_LST = ['debiased_classifier']\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                     FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, 'folk_GA_2018_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c3746",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ee7f255",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.813421Z",
     "start_time": "2024-01-06T11:15:31.771935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairness_variance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d13b6f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.096974Z",
     "start_time": "2024-01-06T11:15:31.811395Z"
    }
   },
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "547935a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.138747Z",
     "start_time": "2024-01-06T11:15:32.097343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  bbba3cc4-760b-4e93-bb97-3a2077202cce\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb40538",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80a53ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:33.528732Z",
     "start_time": "2024-01-06T11:15:33.475702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL</th>\n",
       "      <th>COW</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WKHP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>230</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4110</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4130</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4020</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8300</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SCHL COW MAR  OCCP POBP RELP SEX RAC1P  AGEP  WKHP\n",
       "0   23   7   3   230   36    0   1     1    55  55.0\n",
       "1   16   1   5  4110   13    2   2     1    20  35.0\n",
       "2   16   4   3  4130   51    0   2     1    59  30.0\n",
       "3   18   4   1  4020   13    0   1     2    43  40.0\n",
       "4   14   1   1  8300   20    1   2     2    33  20.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = ACSIncomeDataset(state=['GA'], year=2018, with_nulls=False,\n",
    "                               subsample_size=15_000, subsample_seed=42)\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f50754ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:34.580537Z",
     "start_time": "2024-01-06T11:15:34.538952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a02e10",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42da6d",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fcd622b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:37.135031Z",
     "start_time": "2024-01-06T11:15:37.105079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00ea6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:44.618835Z",
     "start_time": "2024-01-06T11:15:43.745040Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:04:06 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 100,\n",
      " 'experiment_iteration': 'Exp_iter_1',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 100,\n",
      " 'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc38ee9c876469caefd18438ec5bf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:04:06 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=724)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0a941737a8417cb4f7946d88b35431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8c917d6c174359aff6c81106515faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.703511; batch adversarial loss: 0.868435\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433493; batch adversarial loss: 0.870017\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396227; batch adversarial loss: 0.863279\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393296; batch adversarial loss: 0.784595\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335170; batch adversarial loss: 0.729312\n",
      "epoch 5; iter: 0; batch classifier loss: 0.302273; batch adversarial loss: 0.718420\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340553; batch adversarial loss: 0.671042\n",
      "epoch 7; iter: 0; batch classifier loss: 0.317702; batch adversarial loss: 0.662751\n",
      "epoch 8; iter: 0; batch classifier loss: 0.252170; batch adversarial loss: 0.648393\n",
      "epoch 9; iter: 0; batch classifier loss: 0.292380; batch adversarial loss: 0.613334\n",
      "epoch 10; iter: 0; batch classifier loss: 0.278500; batch adversarial loss: 0.582467\n",
      "epoch 11; iter: 0; batch classifier loss: 0.315808; batch adversarial loss: 0.541661\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282857; batch adversarial loss: 0.547508\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245198; batch adversarial loss: 0.570313\n",
      "epoch 14; iter: 0; batch classifier loss: 0.295288; batch adversarial loss: 0.471533\n",
      "epoch 15; iter: 0; batch classifier loss: 0.255773; batch adversarial loss: 0.471669\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227866; batch adversarial loss: 0.459387\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265236; batch adversarial loss: 0.390383\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221451; batch adversarial loss: 0.492176\n",
      "epoch 19; iter: 0; batch classifier loss: 0.235272; batch adversarial loss: 0.424545\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222551; batch adversarial loss: 0.393122\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149757; batch adversarial loss: 0.495092\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181218; batch adversarial loss: 0.386822\n",
      "epoch 23; iter: 0; batch classifier loss: 0.139735; batch adversarial loss: 0.457702\n",
      "epoch 24; iter: 0; batch classifier loss: 0.153798; batch adversarial loss: 0.475582\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132027; batch adversarial loss: 0.444322\n",
      "epoch 26; iter: 0; batch classifier loss: 0.129947; batch adversarial loss: 0.370190\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140482; batch adversarial loss: 0.350910\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166366; batch adversarial loss: 0.481889\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178009; batch adversarial loss: 0.357132\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7429ae00",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b86d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f4afb59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:56.249510Z",
     "start_time": "2024-01-04T20:53:56.233525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:05:08 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 200,\n",
      " 'experiment_iteration': 'Exp_iter_2',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 200,\n",
      " 'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53050642036f46e7aa789d8a1d516948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:05:08 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=730)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 6043,  3745,  5159,  7241,  7820,  3695, 11501, 11432,  1163,\n",
      "             8994,  7972,  2554,  9884,  2008,  6884, 11995,  5200,  4649,\n",
      "            10244, 13775],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 6043,  3745,  5159,  7241,  7820,  3695, 11501, 11432,  1163,\n",
      "             8994,  7972,  2554,  9884,  2008,  6884, 11995,  5200,  4649,\n",
      "            10244, 13775],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c03dba644214641912426e34b6b21a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6378a4e1194bd39a9bd89cd3615ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.690236; batch adversarial loss: 1.067973\n",
      "epoch 1; iter: 0; batch classifier loss: 0.791201; batch adversarial loss: 1.420529\n",
      "epoch 2; iter: 0; batch classifier loss: 0.821795; batch adversarial loss: 1.398339\n",
      "epoch 3; iter: 0; batch classifier loss: 1.111554; batch adversarial loss: 1.326658\n",
      "epoch 4; iter: 0; batch classifier loss: 1.224526; batch adversarial loss: 1.244752\n",
      "epoch 5; iter: 0; batch classifier loss: 1.355242; batch adversarial loss: 1.131309\n",
      "epoch 6; iter: 0; batch classifier loss: 1.159765; batch adversarial loss: 0.998623\n",
      "epoch 7; iter: 0; batch classifier loss: 1.404092; batch adversarial loss: 0.943428\n",
      "epoch 8; iter: 0; batch classifier loss: 1.203331; batch adversarial loss: 0.845512\n",
      "epoch 9; iter: 0; batch classifier loss: 1.261046; batch adversarial loss: 0.777776\n",
      "epoch 10; iter: 0; batch classifier loss: 1.164749; batch adversarial loss: 0.739158\n",
      "epoch 11; iter: 0; batch classifier loss: 1.128721; batch adversarial loss: 0.683382\n",
      "epoch 12; iter: 0; batch classifier loss: 0.997371; batch adversarial loss: 0.641958\n",
      "epoch 13; iter: 0; batch classifier loss: 0.798669; batch adversarial loss: 0.571434\n",
      "epoch 14; iter: 0; batch classifier loss: 0.723547; batch adversarial loss: 0.521763\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500076; batch adversarial loss: 0.555629\n",
      "epoch 16; iter: 0; batch classifier loss: 0.471367; batch adversarial loss: 0.497687\n",
      "epoch 17; iter: 0; batch classifier loss: 0.316145; batch adversarial loss: 0.460031\n",
      "epoch 18; iter: 0; batch classifier loss: 0.248961; batch adversarial loss: 0.463831\n",
      "epoch 19; iter: 0; batch classifier loss: 0.219669; batch adversarial loss: 0.460054\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220772; batch adversarial loss: 0.533350\n",
      "epoch 21; iter: 0; batch classifier loss: 0.272472; batch adversarial loss: 0.529804\n",
      "epoch 22; iter: 0; batch classifier loss: 0.243011; batch adversarial loss: 0.447813\n",
      "epoch 23; iter: 0; batch classifier loss: 0.187279; batch adversarial loss: 0.489428\n",
      "epoch 24; iter: 0; batch classifier loss: 0.221822; batch adversarial loss: 0.489519\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172494; batch adversarial loss: 0.496528\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181822; batch adversarial loss: 0.443080\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154547; batch adversarial loss: 0.440501\n",
      "epoch 28; iter: 0; batch classifier loss: 0.201780; batch adversarial loss: 0.522590\n",
      "epoch 29; iter: 0; batch classifier loss: 0.238893; batch adversarial loss: 0.473624\n",
      "epoch 30; iter: 0; batch classifier loss: 0.220188; batch adversarial loss: 0.427740\n",
      "epoch 31; iter: 0; batch classifier loss: 0.142355; batch adversarial loss: 0.508127\n",
      "epoch 32; iter: 0; batch classifier loss: 0.187854; batch adversarial loss: 0.551089\n",
      "epoch 33; iter: 0; batch classifier loss: 0.139641; batch adversarial loss: 0.519423\n",
      "epoch 34; iter: 0; batch classifier loss: 0.144963; batch adversarial loss: 0.502754\n",
      "epoch 35; iter: 0; batch classifier loss: 0.145282; batch adversarial loss: 0.509695\n",
      "epoch 36; iter: 0; batch classifier loss: 0.149707; batch adversarial loss: 0.568182\n",
      "epoch 37; iter: 0; batch classifier loss: 0.157650; batch adversarial loss: 0.450646\n",
      "epoch 38; iter: 0; batch classifier loss: 0.129052; batch adversarial loss: 0.434401\n",
      "epoch 39; iter: 0; batch classifier loss: 0.127971; batch adversarial loss: 0.552338\n",
      "epoch 40; iter: 0; batch classifier loss: 0.145975; batch adversarial loss: 0.499324\n",
      "epoch 41; iter: 0; batch classifier loss: 0.156214; batch adversarial loss: 0.432354\n",
      "epoch 42; iter: 0; batch classifier loss: 0.126627; batch adversarial loss: 0.378593\n",
      "epoch 43; iter: 0; batch classifier loss: 0.154301; batch adversarial loss: 0.469532\n",
      "epoch 44; iter: 0; batch classifier loss: 0.153901; batch adversarial loss: 0.443613\n",
      "epoch 45; iter: 0; batch classifier loss: 0.115329; batch adversarial loss: 0.579031\n",
      "epoch 46; iter: 0; batch classifier loss: 0.151857; batch adversarial loss: 0.455610\n",
      "epoch 47; iter: 0; batch classifier loss: 0.190429; batch adversarial loss: 0.473039\n",
      "epoch 48; iter: 0; batch classifier loss: 0.122731; batch adversarial loss: 0.447001\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080533; batch adversarial loss: 0.458586\n",
      "epoch 50; iter: 0; batch classifier loss: 0.158861; batch adversarial loss: 0.406111\n",
      "epoch 51; iter: 0; batch classifier loss: 0.076993; batch adversarial loss: 0.528482\n",
      "epoch 52; iter: 0; batch classifier loss: 0.154235; batch adversarial loss: 0.418471\n",
      "epoch 53; iter: 0; batch classifier loss: 0.142243; batch adversarial loss: 0.434891\n",
      "epoch 54; iter: 0; batch classifier loss: 0.209124; batch adversarial loss: 0.377117\n",
      "epoch 55; iter: 0; batch classifier loss: 0.124534; batch adversarial loss: 0.378342\n",
      "epoch 56; iter: 0; batch classifier loss: 0.105865; batch adversarial loss: 0.426303\n",
      "epoch 57; iter: 0; batch classifier loss: 0.092531; batch adversarial loss: 0.515663\n",
      "epoch 58; iter: 0; batch classifier loss: 0.122826; batch adversarial loss: 0.460673\n",
      "epoch 59; iter: 0; batch classifier loss: 0.111956; batch adversarial loss: 0.486850\n",
      "epoch 60; iter: 0; batch classifier loss: 0.099975; batch adversarial loss: 0.516639\n",
      "epoch 61; iter: 0; batch classifier loss: 0.138738; batch adversarial loss: 0.491466\n",
      "epoch 62; iter: 0; batch classifier loss: 0.103743; batch adversarial loss: 0.410764\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095151; batch adversarial loss: 0.484755\n",
      "epoch 64; iter: 0; batch classifier loss: 0.129501; batch adversarial loss: 0.550823\n",
      "epoch 65; iter: 0; batch classifier loss: 0.124363; batch adversarial loss: 0.353933\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073954; batch adversarial loss: 0.509432\n",
      "epoch 67; iter: 0; batch classifier loss: 0.158222; batch adversarial loss: 0.420800\n",
      "epoch 68; iter: 0; batch classifier loss: 0.126172; batch adversarial loss: 0.517487\n",
      "epoch 69; iter: 0; batch classifier loss: 0.109690; batch adversarial loss: 0.375233\n",
      "epoch 70; iter: 0; batch classifier loss: 0.114530; batch adversarial loss: 0.433037\n",
      "epoch 71; iter: 0; batch classifier loss: 0.102960; batch adversarial loss: 0.436388\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080941; batch adversarial loss: 0.553210\n",
      "epoch 73; iter: 0; batch classifier loss: 0.112459; batch adversarial loss: 0.458192\n",
      "epoch 74; iter: 0; batch classifier loss: 0.092548; batch adversarial loss: 0.513199\n",
      "epoch 75; iter: 0; batch classifier loss: 0.146407; batch adversarial loss: 0.475242\n",
      "epoch 76; iter: 0; batch classifier loss: 0.099694; batch adversarial loss: 0.508591\n",
      "epoch 77; iter: 0; batch classifier loss: 0.118720; batch adversarial loss: 0.484515\n",
      "epoch 78; iter: 0; batch classifier loss: 0.197673; batch adversarial loss: 0.361886\n",
      "epoch 79; iter: 0; batch classifier loss: 0.138996; batch adversarial loss: 0.408747\n",
      "epoch 80; iter: 0; batch classifier loss: 0.116866; batch adversarial loss: 0.446630\n",
      "epoch 81; iter: 0; batch classifier loss: 0.107842; batch adversarial loss: 0.395766\n",
      "epoch 82; iter: 0; batch classifier loss: 0.123784; batch adversarial loss: 0.493104\n",
      "epoch 83; iter: 0; batch classifier loss: 0.109941; batch adversarial loss: 0.458873\n",
      "epoch 84; iter: 0; batch classifier loss: 0.112984; batch adversarial loss: 0.436418\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061819; batch adversarial loss: 0.397674\n",
      "epoch 86; iter: 0; batch classifier loss: 0.167042; batch adversarial loss: 0.473956\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076540; batch adversarial loss: 0.446085\n",
      "epoch 88; iter: 0; batch classifier loss: 0.105774; batch adversarial loss: 0.531356\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080102; batch adversarial loss: 0.398442\n",
      "epoch 90; iter: 0; batch classifier loss: 0.110557; batch adversarial loss: 0.492611\n",
      "epoch 91; iter: 0; batch classifier loss: 0.113140; batch adversarial loss: 0.495961\n",
      "epoch 92; iter: 0; batch classifier loss: 0.118697; batch adversarial loss: 0.481128\n",
      "epoch 93; iter: 0; batch classifier loss: 0.092340; batch adversarial loss: 0.555839\n",
      "epoch 94; iter: 0; batch classifier loss: 0.117454; batch adversarial loss: 0.517391\n",
      "epoch 95; iter: 0; batch classifier loss: 0.112988; batch adversarial loss: 0.506333\n",
      "epoch 96; iter: 0; batch classifier loss: 0.094713; batch adversarial loss: 0.433885\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080597; batch adversarial loss: 0.555296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.140486; batch adversarial loss: 0.396836\n",
      "epoch 99; iter: 0; batch classifier loss: 0.165322; batch adversarial loss: 0.447649\n",
      "epoch 100; iter: 0; batch classifier loss: 0.109697; batch adversarial loss: 0.505721\n",
      "epoch 101; iter: 0; batch classifier loss: 0.082346; batch adversarial loss: 0.457358\n",
      "epoch 102; iter: 0; batch classifier loss: 0.157045; batch adversarial loss: 0.471553\n",
      "epoch 103; iter: 0; batch classifier loss: 0.165498; batch adversarial loss: 0.435104\n",
      "epoch 104; iter: 0; batch classifier loss: 0.119078; batch adversarial loss: 0.408569\n",
      "epoch 105; iter: 0; batch classifier loss: 0.178009; batch adversarial loss: 0.421018\n",
      "epoch 106; iter: 0; batch classifier loss: 0.128808; batch adversarial loss: 0.407817\n",
      "epoch 107; iter: 0; batch classifier loss: 0.171626; batch adversarial loss: 0.448806\n",
      "epoch 108; iter: 0; batch classifier loss: 0.159749; batch adversarial loss: 0.517083\n",
      "epoch 109; iter: 0; batch classifier loss: 0.187585; batch adversarial loss: 0.397034\n",
      "epoch 110; iter: 0; batch classifier loss: 0.116221; batch adversarial loss: 0.459539\n",
      "epoch 111; iter: 0; batch classifier loss: 0.082660; batch adversarial loss: 0.492975\n",
      "epoch 112; iter: 0; batch classifier loss: 0.171036; batch adversarial loss: 0.531173\n",
      "epoch 113; iter: 0; batch classifier loss: 0.134250; batch adversarial loss: 0.493827\n",
      "epoch 114; iter: 0; batch classifier loss: 0.096334; batch adversarial loss: 0.482133\n",
      "epoch 115; iter: 0; batch classifier loss: 0.079577; batch adversarial loss: 0.546041\n",
      "epoch 116; iter: 0; batch classifier loss: 0.094626; batch adversarial loss: 0.433533\n",
      "epoch 117; iter: 0; batch classifier loss: 0.132741; batch adversarial loss: 0.421286\n",
      "epoch 118; iter: 0; batch classifier loss: 0.151759; batch adversarial loss: 0.423191\n",
      "epoch 119; iter: 0; batch classifier loss: 0.126406; batch adversarial loss: 0.372127\n",
      "epoch 120; iter: 0; batch classifier loss: 0.095983; batch adversarial loss: 0.471480\n",
      "epoch 121; iter: 0; batch classifier loss: 0.069454; batch adversarial loss: 0.591706\n",
      "epoch 122; iter: 0; batch classifier loss: 0.125335; batch adversarial loss: 0.468391\n",
      "epoch 123; iter: 0; batch classifier loss: 0.114510; batch adversarial loss: 0.518633\n",
      "epoch 124; iter: 0; batch classifier loss: 0.070681; batch adversarial loss: 0.435306\n",
      "epoch 125; iter: 0; batch classifier loss: 0.107386; batch adversarial loss: 0.386853\n",
      "epoch 126; iter: 0; batch classifier loss: 0.121699; batch adversarial loss: 0.469792\n",
      "epoch 127; iter: 0; batch classifier loss: 0.106368; batch adversarial loss: 0.457433\n",
      "epoch 128; iter: 0; batch classifier loss: 0.084987; batch adversarial loss: 0.556082\n",
      "epoch 129; iter: 0; batch classifier loss: 0.122480; batch adversarial loss: 0.447032\n",
      "epoch 130; iter: 0; batch classifier loss: 0.119443; batch adversarial loss: 0.470697\n",
      "epoch 131; iter: 0; batch classifier loss: 0.206506; batch adversarial loss: 0.447129\n",
      "epoch 132; iter: 0; batch classifier loss: 0.133752; batch adversarial loss: 0.471790\n",
      "epoch 133; iter: 0; batch classifier loss: 0.084189; batch adversarial loss: 0.494696\n",
      "epoch 134; iter: 0; batch classifier loss: 0.114897; batch adversarial loss: 0.422602\n",
      "epoch 135; iter: 0; batch classifier loss: 0.086944; batch adversarial loss: 0.386348\n",
      "epoch 136; iter: 0; batch classifier loss: 0.140962; batch adversarial loss: 0.435105\n",
      "epoch 137; iter: 0; batch classifier loss: 0.087921; batch adversarial loss: 0.458464\n",
      "epoch 138; iter: 0; batch classifier loss: 0.122439; batch adversarial loss: 0.397747\n",
      "epoch 139; iter: 0; batch classifier loss: 0.086238; batch adversarial loss: 0.496585\n",
      "epoch 140; iter: 0; batch classifier loss: 0.098993; batch adversarial loss: 0.508177\n",
      "epoch 141; iter: 0; batch classifier loss: 0.155117; batch adversarial loss: 0.385791\n",
      "epoch 142; iter: 0; batch classifier loss: 0.118647; batch adversarial loss: 0.434306\n",
      "epoch 143; iter: 0; batch classifier loss: 0.080501; batch adversarial loss: 0.458864\n",
      "epoch 144; iter: 0; batch classifier loss: 0.152626; batch adversarial loss: 0.469911\n",
      "epoch 145; iter: 0; batch classifier loss: 0.117505; batch adversarial loss: 0.506234\n",
      "epoch 146; iter: 0; batch classifier loss: 0.104097; batch adversarial loss: 0.468774\n",
      "epoch 147; iter: 0; batch classifier loss: 0.113233; batch adversarial loss: 0.434623\n",
      "epoch 148; iter: 0; batch classifier loss: 0.123884; batch adversarial loss: 0.408564\n",
      "epoch 149; iter: 0; batch classifier loss: 0.128700; batch adversarial loss: 0.447237\n",
      "epoch 150; iter: 0; batch classifier loss: 0.101572; batch adversarial loss: 0.446564\n",
      "epoch 151; iter: 0; batch classifier loss: 0.116601; batch adversarial loss: 0.446415\n",
      "epoch 152; iter: 0; batch classifier loss: 0.083991; batch adversarial loss: 0.495330\n",
      "epoch 153; iter: 0; batch classifier loss: 0.152066; batch adversarial loss: 0.459193\n",
      "epoch 154; iter: 0; batch classifier loss: 0.122997; batch adversarial loss: 0.508692\n",
      "epoch 155; iter: 0; batch classifier loss: 0.119204; batch adversarial loss: 0.482558\n",
      "epoch 156; iter: 0; batch classifier loss: 0.119052; batch adversarial loss: 0.398398\n",
      "epoch 157; iter: 0; batch classifier loss: 0.090392; batch adversarial loss: 0.519049\n",
      "epoch 158; iter: 0; batch classifier loss: 0.194085; batch adversarial loss: 0.445440\n",
      "epoch 159; iter: 0; batch classifier loss: 0.108459; batch adversarial loss: 0.432985\n",
      "epoch 160; iter: 0; batch classifier loss: 0.101928; batch adversarial loss: 0.483282\n",
      "epoch 161; iter: 0; batch classifier loss: 0.164930; batch adversarial loss: 0.434022\n",
      "epoch 162; iter: 0; batch classifier loss: 0.129741; batch adversarial loss: 0.494061\n",
      "epoch 163; iter: 0; batch classifier loss: 0.127687; batch adversarial loss: 0.458396\n",
      "epoch 164; iter: 0; batch classifier loss: 0.131093; batch adversarial loss: 0.398397\n",
      "epoch 165; iter: 0; batch classifier loss: 0.163217; batch adversarial loss: 0.445651\n",
      "epoch 166; iter: 0; batch classifier loss: 0.096385; batch adversarial loss: 0.472507\n",
      "epoch 167; iter: 0; batch classifier loss: 0.112828; batch adversarial loss: 0.445880\n",
      "epoch 168; iter: 0; batch classifier loss: 0.058198; batch adversarial loss: 0.580701\n",
      "epoch 169; iter: 0; batch classifier loss: 0.063616; batch adversarial loss: 0.421633\n",
      "epoch 170; iter: 0; batch classifier loss: 0.146654; batch adversarial loss: 0.397240\n",
      "epoch 171; iter: 0; batch classifier loss: 0.091074; batch adversarial loss: 0.520152\n",
      "epoch 172; iter: 0; batch classifier loss: 0.134559; batch adversarial loss: 0.458103\n",
      "epoch 173; iter: 0; batch classifier loss: 0.133972; batch adversarial loss: 0.519200\n",
      "epoch 174; iter: 0; batch classifier loss: 0.136662; batch adversarial loss: 0.434144\n",
      "epoch 175; iter: 0; batch classifier loss: 0.114656; batch adversarial loss: 0.580300\n",
      "epoch 176; iter: 0; batch classifier loss: 0.159544; batch adversarial loss: 0.445736\n",
      "epoch 177; iter: 0; batch classifier loss: 0.173791; batch adversarial loss: 0.472133\n",
      "epoch 178; iter: 0; batch classifier loss: 0.170709; batch adversarial loss: 0.421734\n",
      "epoch 179; iter: 0; batch classifier loss: 0.084422; batch adversarial loss: 0.434179\n",
      "epoch 180; iter: 0; batch classifier loss: 0.141068; batch adversarial loss: 0.433076\n",
      "epoch 181; iter: 0; batch classifier loss: 0.103820; batch adversarial loss: 0.447152\n",
      "epoch 182; iter: 0; batch classifier loss: 0.158550; batch adversarial loss: 0.471787\n",
      "epoch 183; iter: 0; batch classifier loss: 0.144562; batch adversarial loss: 0.542263\n",
      "epoch 184; iter: 0; batch classifier loss: 0.115155; batch adversarial loss: 0.531639\n",
      "epoch 185; iter: 0; batch classifier loss: 0.160291; batch adversarial loss: 0.531614\n",
      "epoch 186; iter: 0; batch classifier loss: 0.212357; batch adversarial loss: 0.458052\n",
      "epoch 187; iter: 0; batch classifier loss: 0.112222; batch adversarial loss: 0.471405\n",
      "epoch 188; iter: 0; batch classifier loss: 0.129340; batch adversarial loss: 0.374184\n",
      "epoch 189; iter: 0; batch classifier loss: 0.125024; batch adversarial loss: 0.422411\n",
      "epoch 190; iter: 0; batch classifier loss: 0.101082; batch adversarial loss: 0.398269\n",
      "epoch 191; iter: 0; batch classifier loss: 0.092629; batch adversarial loss: 0.495215\n",
      "epoch 192; iter: 0; batch classifier loss: 0.153662; batch adversarial loss: 0.385903\n",
      "epoch 193; iter: 0; batch classifier loss: 0.181495; batch adversarial loss: 0.495043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.154007; batch adversarial loss: 0.470980\n",
      "epoch 195; iter: 0; batch classifier loss: 0.175277; batch adversarial loss: 0.495873\n",
      "epoch 196; iter: 0; batch classifier loss: 0.110212; batch adversarial loss: 0.470591\n",
      "epoch 197; iter: 0; batch classifier loss: 0.085414; batch adversarial loss: 0.397910\n",
      "epoch 198; iter: 0; batch classifier loss: 0.132930; batch adversarial loss: 0.531647\n",
      "epoch 199; iter: 0; batch classifier loss: 0.141201; batch adversarial loss: 0.397944\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703994; batch adversarial loss: 0.536354\n",
      "epoch 1; iter: 0; batch classifier loss: 0.484349; batch adversarial loss: 0.595963\n",
      "epoch 2; iter: 0; batch classifier loss: 0.323915; batch adversarial loss: 0.560121\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393404; batch adversarial loss: 0.554019\n",
      "epoch 4; iter: 0; batch classifier loss: 0.443999; batch adversarial loss: 0.551593\n",
      "epoch 5; iter: 0; batch classifier loss: 0.345861; batch adversarial loss: 0.531653\n",
      "epoch 6; iter: 0; batch classifier loss: 0.361757; batch adversarial loss: 0.580012\n",
      "epoch 7; iter: 0; batch classifier loss: 0.369945; batch adversarial loss: 0.601731\n",
      "epoch 8; iter: 0; batch classifier loss: 0.330500; batch adversarial loss: 0.555267\n",
      "epoch 9; iter: 0; batch classifier loss: 0.392985; batch adversarial loss: 0.568902\n",
      "epoch 10; iter: 0; batch classifier loss: 0.427278; batch adversarial loss: 0.541177\n",
      "epoch 11; iter: 0; batch classifier loss: 0.471979; batch adversarial loss: 0.518278\n",
      "epoch 12; iter: 0; batch classifier loss: 0.450029; batch adversarial loss: 0.562830\n",
      "epoch 13; iter: 0; batch classifier loss: 0.595705; batch adversarial loss: 0.496612\n",
      "epoch 14; iter: 0; batch classifier loss: 0.354340; batch adversarial loss: 0.560843\n",
      "epoch 15; iter: 0; batch classifier loss: 0.303072; batch adversarial loss: 0.470246\n",
      "epoch 16; iter: 0; batch classifier loss: 0.435408; batch adversarial loss: 0.554464\n",
      "epoch 17; iter: 0; batch classifier loss: 0.226102; batch adversarial loss: 0.515766\n",
      "epoch 18; iter: 0; batch classifier loss: 0.198418; batch adversarial loss: 0.436105\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247081; batch adversarial loss: 0.419181\n",
      "epoch 20; iter: 0; batch classifier loss: 0.248860; batch adversarial loss: 0.410931\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234426; batch adversarial loss: 0.404568\n",
      "epoch 22; iter: 0; batch classifier loss: 0.236660; batch adversarial loss: 0.503433\n",
      "epoch 23; iter: 0; batch classifier loss: 0.156760; batch adversarial loss: 0.421499\n",
      "epoch 24; iter: 0; batch classifier loss: 0.172945; batch adversarial loss: 0.436189\n",
      "epoch 25; iter: 0; batch classifier loss: 0.187367; batch adversarial loss: 0.386993\n",
      "epoch 26; iter: 0; batch classifier loss: 0.236703; batch adversarial loss: 0.377151\n",
      "epoch 27; iter: 0; batch classifier loss: 0.206473; batch adversarial loss: 0.455108\n",
      "epoch 28; iter: 0; batch classifier loss: 0.232581; batch adversarial loss: 0.447159\n",
      "epoch 29; iter: 0; batch classifier loss: 0.159111; batch adversarial loss: 0.412120\n",
      "epoch 30; iter: 0; batch classifier loss: 0.145861; batch adversarial loss: 0.508829\n",
      "epoch 31; iter: 0; batch classifier loss: 0.111058; batch adversarial loss: 0.474622\n",
      "epoch 32; iter: 0; batch classifier loss: 0.147486; batch adversarial loss: 0.442284\n",
      "epoch 33; iter: 0; batch classifier loss: 0.149530; batch adversarial loss: 0.571188\n",
      "epoch 34; iter: 0; batch classifier loss: 0.158658; batch adversarial loss: 0.517193\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161465; batch adversarial loss: 0.450037\n",
      "epoch 36; iter: 0; batch classifier loss: 0.164902; batch adversarial loss: 0.475569\n",
      "epoch 37; iter: 0; batch classifier loss: 0.162587; batch adversarial loss: 0.526223\n",
      "epoch 38; iter: 0; batch classifier loss: 0.133935; batch adversarial loss: 0.491078\n",
      "epoch 39; iter: 0; batch classifier loss: 0.169920; batch adversarial loss: 0.479123\n",
      "epoch 40; iter: 0; batch classifier loss: 0.132192; batch adversarial loss: 0.544255\n",
      "epoch 41; iter: 0; batch classifier loss: 0.155085; batch adversarial loss: 0.444602\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115083; batch adversarial loss: 0.420031\n",
      "epoch 43; iter: 0; batch classifier loss: 0.175883; batch adversarial loss: 0.383236\n",
      "epoch 44; iter: 0; batch classifier loss: 0.158596; batch adversarial loss: 0.379123\n",
      "epoch 45; iter: 0; batch classifier loss: 0.197597; batch adversarial loss: 0.455101\n",
      "epoch 46; iter: 0; batch classifier loss: 0.130404; batch adversarial loss: 0.433231\n",
      "epoch 47; iter: 0; batch classifier loss: 0.132873; batch adversarial loss: 0.441760\n",
      "epoch 48; iter: 0; batch classifier loss: 0.143485; batch adversarial loss: 0.495548\n",
      "epoch 49; iter: 0; batch classifier loss: 0.148339; batch adversarial loss: 0.486812\n",
      "epoch 50; iter: 0; batch classifier loss: 0.147616; batch adversarial loss: 0.382740\n",
      "epoch 51; iter: 0; batch classifier loss: 0.137802; batch adversarial loss: 0.405766\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089071; batch adversarial loss: 0.533505\n",
      "epoch 53; iter: 0; batch classifier loss: 0.146816; batch adversarial loss: 0.540013\n",
      "epoch 54; iter: 0; batch classifier loss: 0.128435; batch adversarial loss: 0.445864\n",
      "epoch 55; iter: 0; batch classifier loss: 0.154564; batch adversarial loss: 0.511831\n",
      "epoch 56; iter: 0; batch classifier loss: 0.118746; batch adversarial loss: 0.487406\n",
      "epoch 57; iter: 0; batch classifier loss: 0.167505; batch adversarial loss: 0.481326\n",
      "epoch 58; iter: 0; batch classifier loss: 0.169078; batch adversarial loss: 0.460152\n",
      "epoch 59; iter: 0; batch classifier loss: 0.146914; batch adversarial loss: 0.437652\n",
      "epoch 60; iter: 0; batch classifier loss: 0.179521; batch adversarial loss: 0.457409\n",
      "epoch 61; iter: 0; batch classifier loss: 0.186350; batch adversarial loss: 0.398266\n",
      "epoch 62; iter: 0; batch classifier loss: 0.151756; batch adversarial loss: 0.434433\n",
      "epoch 63; iter: 0; batch classifier loss: 0.157934; batch adversarial loss: 0.435715\n",
      "epoch 64; iter: 0; batch classifier loss: 0.146923; batch adversarial loss: 0.478886\n",
      "epoch 65; iter: 0; batch classifier loss: 0.145583; batch adversarial loss: 0.473544\n",
      "epoch 66; iter: 0; batch classifier loss: 0.208788; batch adversarial loss: 0.471689\n",
      "epoch 67; iter: 0; batch classifier loss: 0.137995; batch adversarial loss: 0.459620\n",
      "epoch 68; iter: 0; batch classifier loss: 0.147788; batch adversarial loss: 0.445323\n",
      "epoch 69; iter: 0; batch classifier loss: 0.138253; batch adversarial loss: 0.364791\n",
      "epoch 70; iter: 0; batch classifier loss: 0.094856; batch adversarial loss: 0.469215\n",
      "epoch 71; iter: 0; batch classifier loss: 0.171052; batch adversarial loss: 0.423552\n",
      "epoch 72; iter: 0; batch classifier loss: 0.181694; batch adversarial loss: 0.458640\n",
      "epoch 73; iter: 0; batch classifier loss: 0.125844; batch adversarial loss: 0.435013\n",
      "epoch 74; iter: 0; batch classifier loss: 0.139610; batch adversarial loss: 0.447364\n",
      "epoch 75; iter: 0; batch classifier loss: 0.148237; batch adversarial loss: 0.507752\n",
      "epoch 76; iter: 0; batch classifier loss: 0.128731; batch adversarial loss: 0.507388\n",
      "epoch 77; iter: 0; batch classifier loss: 0.152817; batch adversarial loss: 0.493740\n",
      "epoch 78; iter: 0; batch classifier loss: 0.121009; batch adversarial loss: 0.385911\n",
      "epoch 79; iter: 0; batch classifier loss: 0.127551; batch adversarial loss: 0.373885\n",
      "epoch 80; iter: 0; batch classifier loss: 0.142309; batch adversarial loss: 0.495869\n",
      "epoch 81; iter: 0; batch classifier loss: 0.154467; batch adversarial loss: 0.470942\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063404; batch adversarial loss: 0.508138\n",
      "epoch 83; iter: 0; batch classifier loss: 0.152597; batch adversarial loss: 0.445240\n",
      "epoch 84; iter: 0; batch classifier loss: 0.175981; batch adversarial loss: 0.506285\n",
      "epoch 85; iter: 0; batch classifier loss: 0.216103; batch adversarial loss: 0.422515\n",
      "epoch 86; iter: 0; batch classifier loss: 0.137728; batch adversarial loss: 0.435128\n",
      "epoch 87; iter: 0; batch classifier loss: 0.146886; batch adversarial loss: 0.482587\n",
      "epoch 88; iter: 0; batch classifier loss: 0.155670; batch adversarial loss: 0.349055\n",
      "epoch 89; iter: 0; batch classifier loss: 0.181240; batch adversarial loss: 0.424209\n",
      "epoch 90; iter: 0; batch classifier loss: 0.118861; batch adversarial loss: 0.435971\n",
      "epoch 91; iter: 0; batch classifier loss: 0.088149; batch adversarial loss: 0.519687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.126099; batch adversarial loss: 0.505901\n",
      "epoch 93; iter: 0; batch classifier loss: 0.123871; batch adversarial loss: 0.520206\n",
      "epoch 94; iter: 0; batch classifier loss: 0.121929; batch adversarial loss: 0.505627\n",
      "epoch 95; iter: 0; batch classifier loss: 0.134594; batch adversarial loss: 0.387934\n",
      "epoch 96; iter: 0; batch classifier loss: 0.143731; batch adversarial loss: 0.387207\n",
      "epoch 97; iter: 0; batch classifier loss: 0.115449; batch adversarial loss: 0.482646\n",
      "epoch 98; iter: 0; batch classifier loss: 0.143486; batch adversarial loss: 0.396177\n",
      "epoch 99; iter: 0; batch classifier loss: 0.141110; batch adversarial loss: 0.471512\n",
      "epoch 100; iter: 0; batch classifier loss: 0.168062; batch adversarial loss: 0.508098\n",
      "epoch 101; iter: 0; batch classifier loss: 0.125146; batch adversarial loss: 0.348715\n",
      "epoch 102; iter: 0; batch classifier loss: 0.138158; batch adversarial loss: 0.396072\n",
      "epoch 103; iter: 0; batch classifier loss: 0.143528; batch adversarial loss: 0.458079\n",
      "epoch 104; iter: 0; batch classifier loss: 0.118353; batch adversarial loss: 0.421884\n",
      "epoch 105; iter: 0; batch classifier loss: 0.115109; batch adversarial loss: 0.446149\n",
      "epoch 106; iter: 0; batch classifier loss: 0.124125; batch adversarial loss: 0.471840\n",
      "epoch 107; iter: 0; batch classifier loss: 0.114663; batch adversarial loss: 0.483007\n",
      "epoch 108; iter: 0; batch classifier loss: 0.162917; batch adversarial loss: 0.395662\n",
      "epoch 109; iter: 0; batch classifier loss: 0.135215; batch adversarial loss: 0.471498\n",
      "epoch 110; iter: 0; batch classifier loss: 0.107777; batch adversarial loss: 0.532006\n",
      "epoch 111; iter: 0; batch classifier loss: 0.100344; batch adversarial loss: 0.492984\n",
      "epoch 112; iter: 0; batch classifier loss: 0.105940; batch adversarial loss: 0.444953\n",
      "epoch 113; iter: 0; batch classifier loss: 0.124444; batch adversarial loss: 0.456381\n",
      "epoch 114; iter: 0; batch classifier loss: 0.101150; batch adversarial loss: 0.491722\n",
      "epoch 115; iter: 0; batch classifier loss: 0.076936; batch adversarial loss: 0.423661\n",
      "epoch 116; iter: 0; batch classifier loss: 0.101131; batch adversarial loss: 0.507221\n",
      "epoch 117; iter: 0; batch classifier loss: 0.092989; batch adversarial loss: 0.435399\n",
      "epoch 118; iter: 0; batch classifier loss: 0.126685; batch adversarial loss: 0.519003\n",
      "epoch 119; iter: 0; batch classifier loss: 0.075233; batch adversarial loss: 0.510906\n",
      "epoch 120; iter: 0; batch classifier loss: 0.065906; batch adversarial loss: 0.440569\n",
      "epoch 121; iter: 0; batch classifier loss: 0.084056; batch adversarial loss: 0.498467\n",
      "epoch 122; iter: 0; batch classifier loss: 0.090222; batch adversarial loss: 0.429828\n",
      "epoch 123; iter: 0; batch classifier loss: 0.094543; batch adversarial loss: 0.446545\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050280; batch adversarial loss: 0.431166\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056487; batch adversarial loss: 0.508285\n",
      "epoch 126; iter: 0; batch classifier loss: 0.084946; batch adversarial loss: 0.420399\n",
      "epoch 127; iter: 0; batch classifier loss: 0.069000; batch adversarial loss: 0.487563\n",
      "epoch 128; iter: 0; batch classifier loss: 0.074789; batch adversarial loss: 0.484602\n",
      "epoch 129; iter: 0; batch classifier loss: 0.065702; batch adversarial loss: 0.419292\n",
      "epoch 130; iter: 0; batch classifier loss: 0.065061; batch adversarial loss: 0.484257\n",
      "epoch 131; iter: 0; batch classifier loss: 0.061889; batch adversarial loss: 0.439318\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053699; batch adversarial loss: 0.465642\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036092; batch adversarial loss: 0.426659\n",
      "epoch 134; iter: 0; batch classifier loss: 0.061846; batch adversarial loss: 0.446593\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043516; batch adversarial loss: 0.458641\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056070; batch adversarial loss: 0.529706\n",
      "epoch 137; iter: 0; batch classifier loss: 0.055026; batch adversarial loss: 0.435541\n",
      "epoch 138; iter: 0; batch classifier loss: 0.065617; batch adversarial loss: 0.470293\n",
      "epoch 139; iter: 0; batch classifier loss: 0.052661; batch adversarial loss: 0.423864\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033599; batch adversarial loss: 0.429245\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053554; batch adversarial loss: 0.426887\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030862; batch adversarial loss: 0.393337\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035876; batch adversarial loss: 0.438160\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030832; batch adversarial loss: 0.437829\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024643; batch adversarial loss: 0.558935\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025892; batch adversarial loss: 0.392253\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024463; batch adversarial loss: 0.463615\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029810; batch adversarial loss: 0.498159\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025002; batch adversarial loss: 0.415430\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044520; batch adversarial loss: 0.408396\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030109; batch adversarial loss: 0.548750\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023254; batch adversarial loss: 0.502761\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014050; batch adversarial loss: 0.430578\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011653; batch adversarial loss: 0.435674\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017154; batch adversarial loss: 0.381930\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026671; batch adversarial loss: 0.466366\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029635; batch adversarial loss: 0.528244\n",
      "epoch 158; iter: 0; batch classifier loss: 0.063422; batch adversarial loss: 0.391358\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017202; batch adversarial loss: 0.335468\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034667; batch adversarial loss: 0.490151\n",
      "epoch 161; iter: 0; batch classifier loss: 0.041252; batch adversarial loss: 0.475597\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025211; batch adversarial loss: 0.450516\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017659; batch adversarial loss: 0.421715\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033863; batch adversarial loss: 0.435549\n",
      "epoch 165; iter: 0; batch classifier loss: 0.006968; batch adversarial loss: 0.492390\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038248; batch adversarial loss: 0.476456\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013182; batch adversarial loss: 0.503532\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019341; batch adversarial loss: 0.474014\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024291; batch adversarial loss: 0.406756\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010070; batch adversarial loss: 0.450815\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029088; batch adversarial loss: 0.536453\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023316; batch adversarial loss: 0.400230\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036759; batch adversarial loss: 0.427824\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024301; batch adversarial loss: 0.396579\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024735; batch adversarial loss: 0.508458\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013894; batch adversarial loss: 0.496170\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024264; batch adversarial loss: 0.478657\n",
      "epoch 178; iter: 0; batch classifier loss: 0.048139; batch adversarial loss: 0.436363\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021817; batch adversarial loss: 0.497506\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010927; batch adversarial loss: 0.503231\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033013; batch adversarial loss: 0.438615\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022751; batch adversarial loss: 0.446801\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019292; batch adversarial loss: 0.480184\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011870; batch adversarial loss: 0.430073\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033080; batch adversarial loss: 0.423441\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030656; batch adversarial loss: 0.564520\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016960; batch adversarial loss: 0.365848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.013213; batch adversarial loss: 0.447930\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028988; batch adversarial loss: 0.448408\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024014; batch adversarial loss: 0.422168\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030605; batch adversarial loss: 0.419683\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011871; batch adversarial loss: 0.485417\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024437; batch adversarial loss: 0.570693\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025410; batch adversarial loss: 0.381788\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014704; batch adversarial loss: 0.477993\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015122; batch adversarial loss: 0.403108\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015721; batch adversarial loss: 0.566893\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014523; batch adversarial loss: 0.416491\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033042; batch adversarial loss: 0.448785\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691868; batch adversarial loss: 0.960170\n",
      "epoch 1; iter: 0; batch classifier loss: 0.480212; batch adversarial loss: 1.028584\n",
      "epoch 2; iter: 0; batch classifier loss: 0.556939; batch adversarial loss: 0.971160\n",
      "epoch 3; iter: 0; batch classifier loss: 0.455882; batch adversarial loss: 0.861757\n",
      "epoch 4; iter: 0; batch classifier loss: 0.411443; batch adversarial loss: 0.888795\n",
      "epoch 5; iter: 0; batch classifier loss: 0.295325; batch adversarial loss: 0.755703\n",
      "epoch 6; iter: 0; batch classifier loss: 0.280601; batch adversarial loss: 0.744014\n",
      "epoch 7; iter: 0; batch classifier loss: 0.339234; batch adversarial loss: 0.687271\n",
      "epoch 8; iter: 0; batch classifier loss: 0.320815; batch adversarial loss: 0.650452\n",
      "epoch 9; iter: 0; batch classifier loss: 0.284671; batch adversarial loss: 0.621117\n",
      "epoch 10; iter: 0; batch classifier loss: 0.237307; batch adversarial loss: 0.612065\n",
      "epoch 11; iter: 0; batch classifier loss: 0.279315; batch adversarial loss: 0.552300\n",
      "epoch 12; iter: 0; batch classifier loss: 0.364421; batch adversarial loss: 0.574237\n",
      "epoch 13; iter: 0; batch classifier loss: 0.236888; batch adversarial loss: 0.562215\n",
      "epoch 14; iter: 0; batch classifier loss: 0.244928; batch adversarial loss: 0.538783\n",
      "epoch 15; iter: 0; batch classifier loss: 0.281647; batch adversarial loss: 0.516514\n",
      "epoch 16; iter: 0; batch classifier loss: 0.253320; batch adversarial loss: 0.534948\n",
      "epoch 17; iter: 0; batch classifier loss: 0.231586; batch adversarial loss: 0.536512\n",
      "epoch 18; iter: 0; batch classifier loss: 0.217585; batch adversarial loss: 0.529999\n",
      "epoch 19; iter: 0; batch classifier loss: 0.181750; batch adversarial loss: 0.521227\n",
      "epoch 20; iter: 0; batch classifier loss: 0.162762; batch adversarial loss: 0.524873\n",
      "epoch 21; iter: 0; batch classifier loss: 0.169271; batch adversarial loss: 0.458355\n",
      "epoch 22; iter: 0; batch classifier loss: 0.227804; batch adversarial loss: 0.471092\n",
      "epoch 23; iter: 0; batch classifier loss: 0.205290; batch adversarial loss: 0.473441\n",
      "epoch 24; iter: 0; batch classifier loss: 0.167565; batch adversarial loss: 0.474617\n",
      "epoch 25; iter: 0; batch classifier loss: 0.227366; batch adversarial loss: 0.500206\n",
      "epoch 26; iter: 0; batch classifier loss: 0.205459; batch adversarial loss: 0.414949\n",
      "epoch 27; iter: 0; batch classifier loss: 0.243400; batch adversarial loss: 0.426486\n",
      "epoch 28; iter: 0; batch classifier loss: 0.154059; batch adversarial loss: 0.475767\n",
      "epoch 29; iter: 0; batch classifier loss: 0.139687; batch adversarial loss: 0.426277\n",
      "epoch 30; iter: 0; batch classifier loss: 0.156298; batch adversarial loss: 0.382038\n",
      "epoch 31; iter: 0; batch classifier loss: 0.181613; batch adversarial loss: 0.446798\n",
      "epoch 32; iter: 0; batch classifier loss: 0.139994; batch adversarial loss: 0.500347\n",
      "epoch 33; iter: 0; batch classifier loss: 0.120651; batch adversarial loss: 0.463223\n",
      "epoch 34; iter: 0; batch classifier loss: 0.133501; batch adversarial loss: 0.388677\n",
      "epoch 35; iter: 0; batch classifier loss: 0.136026; batch adversarial loss: 0.509455\n",
      "epoch 36; iter: 0; batch classifier loss: 0.173521; batch adversarial loss: 0.391322\n",
      "epoch 37; iter: 0; batch classifier loss: 0.184558; batch adversarial loss: 0.417475\n",
      "epoch 38; iter: 0; batch classifier loss: 0.111890; batch adversarial loss: 0.411072\n",
      "epoch 39; iter: 0; batch classifier loss: 0.158820; batch adversarial loss: 0.423107\n",
      "epoch 40; iter: 0; batch classifier loss: 0.130806; batch adversarial loss: 0.434471\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111502; batch adversarial loss: 0.414774\n",
      "epoch 42; iter: 0; batch classifier loss: 0.177273; batch adversarial loss: 0.477763\n",
      "epoch 43; iter: 0; batch classifier loss: 0.073161; batch adversarial loss: 0.411358\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085644; batch adversarial loss: 0.378839\n",
      "epoch 45; iter: 0; batch classifier loss: 0.052427; batch adversarial loss: 0.458847\n",
      "epoch 46; iter: 0; batch classifier loss: 0.074692; batch adversarial loss: 0.388438\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113240; batch adversarial loss: 0.461931\n",
      "epoch 48; iter: 0; batch classifier loss: 0.097642; batch adversarial loss: 0.355792\n",
      "epoch 49; iter: 0; batch classifier loss: 0.149503; batch adversarial loss: 0.440463\n",
      "epoch 50; iter: 0; batch classifier loss: 0.095832; batch adversarial loss: 0.452857\n",
      "epoch 51; iter: 0; batch classifier loss: 0.116138; batch adversarial loss: 0.525681\n",
      "epoch 52; iter: 0; batch classifier loss: 0.122562; batch adversarial loss: 0.462485\n",
      "epoch 53; iter: 0; batch classifier loss: 0.055490; batch adversarial loss: 0.446900\n",
      "epoch 54; iter: 0; batch classifier loss: 0.133441; batch adversarial loss: 0.403150\n",
      "epoch 55; iter: 0; batch classifier loss: 0.058691; batch adversarial loss: 0.473483\n",
      "epoch 56; iter: 0; batch classifier loss: 0.122435; batch adversarial loss: 0.375988\n",
      "epoch 57; iter: 0; batch classifier loss: 0.140350; batch adversarial loss: 0.458889\n",
      "epoch 58; iter: 0; batch classifier loss: 0.135502; batch adversarial loss: 0.452923\n",
      "epoch 59; iter: 0; batch classifier loss: 0.112971; batch adversarial loss: 0.420413\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081009; batch adversarial loss: 0.503225\n",
      "epoch 61; iter: 0; batch classifier loss: 0.115740; batch adversarial loss: 0.507711\n",
      "epoch 62; iter: 0; batch classifier loss: 0.068042; batch adversarial loss: 0.359103\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098353; batch adversarial loss: 0.436907\n",
      "epoch 64; iter: 0; batch classifier loss: 0.056510; batch adversarial loss: 0.407414\n",
      "epoch 65; iter: 0; batch classifier loss: 0.112810; batch adversarial loss: 0.471621\n",
      "epoch 66; iter: 0; batch classifier loss: 0.064869; batch adversarial loss: 0.424909\n",
      "epoch 67; iter: 0; batch classifier loss: 0.124509; batch adversarial loss: 0.456568\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054176; batch adversarial loss: 0.395913\n",
      "epoch 69; iter: 0; batch classifier loss: 0.057180; batch adversarial loss: 0.455120\n",
      "epoch 70; iter: 0; batch classifier loss: 0.057364; batch adversarial loss: 0.424239\n",
      "epoch 71; iter: 0; batch classifier loss: 0.095089; batch adversarial loss: 0.426919\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071625; batch adversarial loss: 0.453609\n",
      "epoch 73; iter: 0; batch classifier loss: 0.103660; batch adversarial loss: 0.463068\n",
      "epoch 74; iter: 0; batch classifier loss: 0.109680; batch adversarial loss: 0.422283\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079385; batch adversarial loss: 0.396946\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072468; batch adversarial loss: 0.434356\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065480; batch adversarial loss: 0.395016\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082192; batch adversarial loss: 0.468563\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070800; batch adversarial loss: 0.497557\n",
      "epoch 80; iter: 0; batch classifier loss: 0.102782; batch adversarial loss: 0.481882\n",
      "epoch 81; iter: 0; batch classifier loss: 0.049995; batch adversarial loss: 0.413651\n",
      "epoch 82; iter: 0; batch classifier loss: 0.064279; batch adversarial loss: 0.498344\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073286; batch adversarial loss: 0.511285\n",
      "epoch 84; iter: 0; batch classifier loss: 0.035714; batch adversarial loss: 0.430908\n",
      "epoch 85; iter: 0; batch classifier loss: 0.087172; batch adversarial loss: 0.474542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.069149; batch adversarial loss: 0.401544\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042234; batch adversarial loss: 0.382168\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062865; batch adversarial loss: 0.473968\n",
      "epoch 89; iter: 0; batch classifier loss: 0.045543; batch adversarial loss: 0.463307\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052289; batch adversarial loss: 0.417136\n",
      "epoch 91; iter: 0; batch classifier loss: 0.090998; batch adversarial loss: 0.447027\n",
      "epoch 92; iter: 0; batch classifier loss: 0.039641; batch adversarial loss: 0.386446\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067271; batch adversarial loss: 0.498582\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079344; batch adversarial loss: 0.310805\n",
      "epoch 95; iter: 0; batch classifier loss: 0.067861; batch adversarial loss: 0.418490\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051901; batch adversarial loss: 0.481753\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064082; batch adversarial loss: 0.368560\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052405; batch adversarial loss: 0.409526\n",
      "epoch 99; iter: 0; batch classifier loss: 0.075672; batch adversarial loss: 0.346946\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039552; batch adversarial loss: 0.457191\n",
      "epoch 101; iter: 0; batch classifier loss: 0.052107; batch adversarial loss: 0.432371\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046398; batch adversarial loss: 0.536480\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063428; batch adversarial loss: 0.442969\n",
      "epoch 104; iter: 0; batch classifier loss: 0.074715; batch adversarial loss: 0.487405\n",
      "epoch 105; iter: 0; batch classifier loss: 0.105985; batch adversarial loss: 0.495423\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025554; batch adversarial loss: 0.445845\n",
      "epoch 107; iter: 0; batch classifier loss: 0.078425; batch adversarial loss: 0.348314\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053017; batch adversarial loss: 0.423126\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032049; batch adversarial loss: 0.363974\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061964; batch adversarial loss: 0.372878\n",
      "epoch 111; iter: 0; batch classifier loss: 0.065599; batch adversarial loss: 0.355002\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052757; batch adversarial loss: 0.428703\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055875; batch adversarial loss: 0.527191\n",
      "epoch 114; iter: 0; batch classifier loss: 0.076387; batch adversarial loss: 0.371989\n",
      "epoch 115; iter: 0; batch classifier loss: 0.095514; batch adversarial loss: 0.438136\n",
      "epoch 116; iter: 0; batch classifier loss: 0.061364; batch adversarial loss: 0.446943\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055034; batch adversarial loss: 0.512347\n",
      "epoch 118; iter: 0; batch classifier loss: 0.070778; batch adversarial loss: 0.430142\n",
      "epoch 119; iter: 0; batch classifier loss: 0.063478; batch adversarial loss: 0.447967\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032158; batch adversarial loss: 0.503345\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051157; batch adversarial loss: 0.443315\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040493; batch adversarial loss: 0.378428\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052624; batch adversarial loss: 0.426670\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059751; batch adversarial loss: 0.486334\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058526; batch adversarial loss: 0.450138\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031554; batch adversarial loss: 0.557297\n",
      "epoch 127; iter: 0; batch classifier loss: 0.062069; batch adversarial loss: 0.477864\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054703; batch adversarial loss: 0.487043\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047493; batch adversarial loss: 0.502294\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044728; batch adversarial loss: 0.432970\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036681; batch adversarial loss: 0.373121\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044328; batch adversarial loss: 0.426253\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040933; batch adversarial loss: 0.422363\n",
      "epoch 134; iter: 0; batch classifier loss: 0.071755; batch adversarial loss: 0.516905\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038831; batch adversarial loss: 0.393230\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056910; batch adversarial loss: 0.355867\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029930; batch adversarial loss: 0.403657\n",
      "epoch 138; iter: 0; batch classifier loss: 0.068607; batch adversarial loss: 0.456895\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038786; batch adversarial loss: 0.367318\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033968; batch adversarial loss: 0.384683\n",
      "epoch 141; iter: 0; batch classifier loss: 0.055975; batch adversarial loss: 0.493720\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031969; batch adversarial loss: 0.367260\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051534; batch adversarial loss: 0.386506\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047639; batch adversarial loss: 0.487879\n",
      "epoch 145; iter: 0; batch classifier loss: 0.051137; batch adversarial loss: 0.391440\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035379; batch adversarial loss: 0.496741\n",
      "epoch 147; iter: 0; batch classifier loss: 0.071661; batch adversarial loss: 0.589457\n",
      "epoch 148; iter: 0; batch classifier loss: 0.086257; batch adversarial loss: 0.348545\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046720; batch adversarial loss: 0.368465\n",
      "epoch 150; iter: 0; batch classifier loss: 0.063438; batch adversarial loss: 0.454192\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033972; batch adversarial loss: 0.492630\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040274; batch adversarial loss: 0.426443\n",
      "epoch 153; iter: 0; batch classifier loss: 0.041329; batch adversarial loss: 0.512701\n",
      "epoch 154; iter: 0; batch classifier loss: 0.048964; batch adversarial loss: 0.398621\n",
      "epoch 155; iter: 0; batch classifier loss: 0.055273; batch adversarial loss: 0.482317\n",
      "epoch 156; iter: 0; batch classifier loss: 0.108890; batch adversarial loss: 0.500899\n",
      "epoch 157; iter: 0; batch classifier loss: 0.077481; batch adversarial loss: 0.437752\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037124; batch adversarial loss: 0.395587\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027814; batch adversarial loss: 0.386572\n",
      "epoch 160; iter: 0; batch classifier loss: 0.043917; batch adversarial loss: 0.358719\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037577; batch adversarial loss: 0.511253\n",
      "epoch 162; iter: 0; batch classifier loss: 0.059169; batch adversarial loss: 0.429998\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040729; batch adversarial loss: 0.406721\n",
      "epoch 164; iter: 0; batch classifier loss: 0.046894; batch adversarial loss: 0.395282\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039670; batch adversarial loss: 0.423908\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022111; batch adversarial loss: 0.390968\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025933; batch adversarial loss: 0.496745\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037069; batch adversarial loss: 0.363350\n",
      "epoch 169; iter: 0; batch classifier loss: 0.042119; batch adversarial loss: 0.406123\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024284; batch adversarial loss: 0.464235\n",
      "epoch 171; iter: 0; batch classifier loss: 0.074349; batch adversarial loss: 0.329352\n",
      "epoch 172; iter: 0; batch classifier loss: 0.046581; batch adversarial loss: 0.461929\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037458; batch adversarial loss: 0.429747\n",
      "epoch 174; iter: 0; batch classifier loss: 0.044208; batch adversarial loss: 0.427771\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040755; batch adversarial loss: 0.447836\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040017; batch adversarial loss: 0.447440\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031736; batch adversarial loss: 0.560014\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032871; batch adversarial loss: 0.416703\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024037; batch adversarial loss: 0.454275\n",
      "epoch 180; iter: 0; batch classifier loss: 0.050261; batch adversarial loss: 0.470896\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028073; batch adversarial loss: 0.490585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.023160; batch adversarial loss: 0.416861\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014411; batch adversarial loss: 0.575697\n",
      "epoch 184; iter: 0; batch classifier loss: 0.083411; batch adversarial loss: 0.392909\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028013; batch adversarial loss: 0.385690\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034338; batch adversarial loss: 0.410519\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030541; batch adversarial loss: 0.499372\n",
      "epoch 188; iter: 0; batch classifier loss: 0.038979; batch adversarial loss: 0.455763\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029137; batch adversarial loss: 0.484103\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026339; batch adversarial loss: 0.450572\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031385; batch adversarial loss: 0.387553\n",
      "epoch 192; iter: 0; batch classifier loss: 0.043937; batch adversarial loss: 0.393536\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025954; batch adversarial loss: 0.488049\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023906; batch adversarial loss: 0.472313\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025821; batch adversarial loss: 0.360250\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028322; batch adversarial loss: 0.482361\n",
      "epoch 197; iter: 0; batch classifier loss: 0.038569; batch adversarial loss: 0.466764\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021996; batch adversarial loss: 0.479814\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018032; batch adversarial loss: 0.396790\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712193; batch adversarial loss: 0.630762\n",
      "epoch 1; iter: 0; batch classifier loss: 0.441972; batch adversarial loss: 0.638028\n",
      "epoch 2; iter: 0; batch classifier loss: 0.391336; batch adversarial loss: 0.629838\n",
      "epoch 3; iter: 0; batch classifier loss: 0.305254; batch adversarial loss: 0.628792\n",
      "epoch 4; iter: 0; batch classifier loss: 0.394145; batch adversarial loss: 0.604156\n",
      "epoch 5; iter: 0; batch classifier loss: 0.409840; batch adversarial loss: 0.621274\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578807; batch adversarial loss: 0.605223\n",
      "epoch 7; iter: 0; batch classifier loss: 0.465507; batch adversarial loss: 0.602605\n",
      "epoch 8; iter: 0; batch classifier loss: 0.586455; batch adversarial loss: 0.573965\n",
      "epoch 9; iter: 0; batch classifier loss: 0.454382; batch adversarial loss: 0.503518\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374946; batch adversarial loss: 0.524009\n",
      "epoch 11; iter: 0; batch classifier loss: 0.317067; batch adversarial loss: 0.521513\n",
      "epoch 12; iter: 0; batch classifier loss: 0.368713; batch adversarial loss: 0.493922\n",
      "epoch 13; iter: 0; batch classifier loss: 0.378419; batch adversarial loss: 0.522207\n",
      "epoch 14; iter: 0; batch classifier loss: 0.354474; batch adversarial loss: 0.506833\n",
      "epoch 15; iter: 0; batch classifier loss: 0.359963; batch adversarial loss: 0.505763\n",
      "epoch 16; iter: 0; batch classifier loss: 0.337446; batch adversarial loss: 0.518804\n",
      "epoch 17; iter: 0; batch classifier loss: 0.290130; batch adversarial loss: 0.436753\n",
      "epoch 18; iter: 0; batch classifier loss: 0.332231; batch adversarial loss: 0.544162\n",
      "epoch 19; iter: 0; batch classifier loss: 0.251862; batch adversarial loss: 0.507771\n",
      "epoch 20; iter: 0; batch classifier loss: 0.225380; batch adversarial loss: 0.471702\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234494; batch adversarial loss: 0.508016\n",
      "epoch 22; iter: 0; batch classifier loss: 0.291302; batch adversarial loss: 0.508895\n",
      "epoch 23; iter: 0; batch classifier loss: 0.278648; batch adversarial loss: 0.481280\n",
      "epoch 24; iter: 0; batch classifier loss: 0.251226; batch adversarial loss: 0.452533\n",
      "epoch 25; iter: 0; batch classifier loss: 0.241097; batch adversarial loss: 0.480051\n",
      "epoch 26; iter: 0; batch classifier loss: 0.175424; batch adversarial loss: 0.398896\n",
      "epoch 27; iter: 0; batch classifier loss: 0.240061; batch adversarial loss: 0.477217\n",
      "epoch 28; iter: 0; batch classifier loss: 0.192099; batch adversarial loss: 0.506644\n",
      "epoch 29; iter: 0; batch classifier loss: 0.174531; batch adversarial loss: 0.499057\n",
      "epoch 30; iter: 0; batch classifier loss: 0.177077; batch adversarial loss: 0.485349\n",
      "epoch 31; iter: 0; batch classifier loss: 0.191051; batch adversarial loss: 0.531678\n",
      "epoch 32; iter: 0; batch classifier loss: 0.198230; batch adversarial loss: 0.536520\n",
      "epoch 33; iter: 0; batch classifier loss: 0.206652; batch adversarial loss: 0.540994\n",
      "epoch 34; iter: 0; batch classifier loss: 0.135337; batch adversarial loss: 0.456521\n",
      "epoch 35; iter: 0; batch classifier loss: 0.239320; batch adversarial loss: 0.405727\n",
      "epoch 36; iter: 0; batch classifier loss: 0.176362; batch adversarial loss: 0.513785\n",
      "epoch 37; iter: 0; batch classifier loss: 0.168999; batch adversarial loss: 0.547096\n",
      "epoch 38; iter: 0; batch classifier loss: 0.207485; batch adversarial loss: 0.407708\n",
      "epoch 39; iter: 0; batch classifier loss: 0.193641; batch adversarial loss: 0.491294\n",
      "epoch 40; iter: 0; batch classifier loss: 0.204255; batch adversarial loss: 0.484923\n",
      "epoch 41; iter: 0; batch classifier loss: 0.164058; batch adversarial loss: 0.542259\n",
      "epoch 42; iter: 0; batch classifier loss: 0.209091; batch adversarial loss: 0.416134\n",
      "epoch 43; iter: 0; batch classifier loss: 0.268526; batch adversarial loss: 0.452626\n",
      "epoch 44; iter: 0; batch classifier loss: 0.202342; batch adversarial loss: 0.504317\n",
      "epoch 45; iter: 0; batch classifier loss: 0.182190; batch adversarial loss: 0.389049\n",
      "epoch 46; iter: 0; batch classifier loss: 0.211627; batch adversarial loss: 0.472832\n",
      "epoch 47; iter: 0; batch classifier loss: 0.251320; batch adversarial loss: 0.412911\n",
      "epoch 48; iter: 0; batch classifier loss: 0.179664; batch adversarial loss: 0.438009\n",
      "epoch 49; iter: 0; batch classifier loss: 0.202388; batch adversarial loss: 0.492304\n",
      "epoch 50; iter: 0; batch classifier loss: 0.279839; batch adversarial loss: 0.378307\n",
      "epoch 51; iter: 0; batch classifier loss: 0.190869; batch adversarial loss: 0.481760\n",
      "epoch 52; iter: 0; batch classifier loss: 0.287584; batch adversarial loss: 0.473015\n",
      "epoch 53; iter: 0; batch classifier loss: 0.119916; batch adversarial loss: 0.587953\n",
      "epoch 54; iter: 0; batch classifier loss: 0.183738; batch adversarial loss: 0.410982\n",
      "epoch 55; iter: 0; batch classifier loss: 0.118993; batch adversarial loss: 0.543563\n",
      "epoch 56; iter: 0; batch classifier loss: 0.194837; batch adversarial loss: 0.387295\n",
      "epoch 57; iter: 0; batch classifier loss: 0.142202; batch adversarial loss: 0.472018\n",
      "epoch 58; iter: 0; batch classifier loss: 0.112315; batch adversarial loss: 0.481811\n",
      "epoch 59; iter: 0; batch classifier loss: 0.254314; batch adversarial loss: 0.460156\n",
      "epoch 60; iter: 0; batch classifier loss: 0.195836; batch adversarial loss: 0.457984\n",
      "epoch 61; iter: 0; batch classifier loss: 0.268627; batch adversarial loss: 0.435765\n",
      "epoch 62; iter: 0; batch classifier loss: 0.164723; batch adversarial loss: 0.483959\n",
      "epoch 63; iter: 0; batch classifier loss: 0.189477; batch adversarial loss: 0.400141\n",
      "epoch 64; iter: 0; batch classifier loss: 0.197667; batch adversarial loss: 0.484259\n",
      "epoch 65; iter: 0; batch classifier loss: 0.212498; batch adversarial loss: 0.398929\n",
      "epoch 66; iter: 0; batch classifier loss: 0.149317; batch adversarial loss: 0.436194\n",
      "epoch 67; iter: 0; batch classifier loss: 0.159862; batch adversarial loss: 0.459591\n",
      "epoch 68; iter: 0; batch classifier loss: 0.179586; batch adversarial loss: 0.399213\n",
      "epoch 69; iter: 0; batch classifier loss: 0.155273; batch adversarial loss: 0.494608\n",
      "epoch 70; iter: 0; batch classifier loss: 0.206926; batch adversarial loss: 0.495134\n",
      "epoch 71; iter: 0; batch classifier loss: 0.167653; batch adversarial loss: 0.483011\n",
      "epoch 72; iter: 0; batch classifier loss: 0.044636; batch adversarial loss: 0.457829\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090306; batch adversarial loss: 0.384444\n",
      "epoch 74; iter: 0; batch classifier loss: 0.056296; batch adversarial loss: 0.510507\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077444; batch adversarial loss: 0.390317\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046854; batch adversarial loss: 0.514979\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062569; batch adversarial loss: 0.377825\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071920; batch adversarial loss: 0.528893\n",
      "epoch 79; iter: 0; batch classifier loss: 0.066289; batch adversarial loss: 0.480469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.048082; batch adversarial loss: 0.438874\n",
      "epoch 81; iter: 0; batch classifier loss: 0.032627; batch adversarial loss: 0.367791\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063417; batch adversarial loss: 0.458788\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054775; batch adversarial loss: 0.438679\n",
      "epoch 84; iter: 0; batch classifier loss: 0.074924; batch adversarial loss: 0.462156\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067203; batch adversarial loss: 0.445540\n",
      "epoch 86; iter: 0; batch classifier loss: 0.087413; batch adversarial loss: 0.382555\n",
      "epoch 87; iter: 0; batch classifier loss: 0.052156; batch adversarial loss: 0.463299\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073898; batch adversarial loss: 0.441893\n",
      "epoch 89; iter: 0; batch classifier loss: 0.127012; batch adversarial loss: 0.555054\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053209; batch adversarial loss: 0.367144\n",
      "epoch 91; iter: 0; batch classifier loss: 0.072041; batch adversarial loss: 0.433833\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041212; batch adversarial loss: 0.390424\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064522; batch adversarial loss: 0.475964\n",
      "epoch 94; iter: 0; batch classifier loss: 0.063043; batch adversarial loss: 0.448942\n",
      "epoch 95; iter: 0; batch classifier loss: 0.086902; batch adversarial loss: 0.466614\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063738; batch adversarial loss: 0.452120\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043066; batch adversarial loss: 0.375260\n",
      "epoch 98; iter: 0; batch classifier loss: 0.090630; batch adversarial loss: 0.437887\n",
      "epoch 99; iter: 0; batch classifier loss: 0.098021; batch adversarial loss: 0.534630\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065111; batch adversarial loss: 0.471186\n",
      "epoch 101; iter: 0; batch classifier loss: 0.095252; batch adversarial loss: 0.517951\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055185; batch adversarial loss: 0.344993\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055334; batch adversarial loss: 0.470762\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039464; batch adversarial loss: 0.467434\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062132; batch adversarial loss: 0.413556\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064809; batch adversarial loss: 0.421511\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048734; batch adversarial loss: 0.436879\n",
      "epoch 108; iter: 0; batch classifier loss: 0.099291; batch adversarial loss: 0.432240\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037659; batch adversarial loss: 0.514436\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046082; batch adversarial loss: 0.431623\n",
      "epoch 111; iter: 0; batch classifier loss: 0.074380; batch adversarial loss: 0.486341\n",
      "epoch 112; iter: 0; batch classifier loss: 0.080854; batch adversarial loss: 0.432719\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039373; batch adversarial loss: 0.350302\n",
      "epoch 114; iter: 0; batch classifier loss: 0.066963; batch adversarial loss: 0.459670\n",
      "epoch 115; iter: 0; batch classifier loss: 0.081136; batch adversarial loss: 0.363932\n",
      "epoch 116; iter: 0; batch classifier loss: 0.104481; batch adversarial loss: 0.468206\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043027; batch adversarial loss: 0.471480\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047139; batch adversarial loss: 0.448335\n",
      "epoch 119; iter: 0; batch classifier loss: 0.066167; batch adversarial loss: 0.357275\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049024; batch adversarial loss: 0.462301\n",
      "epoch 121; iter: 0; batch classifier loss: 0.087765; batch adversarial loss: 0.436934\n",
      "epoch 122; iter: 0; batch classifier loss: 0.084014; batch adversarial loss: 0.459809\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057886; batch adversarial loss: 0.400684\n",
      "epoch 124; iter: 0; batch classifier loss: 0.091512; batch adversarial loss: 0.441272\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068355; batch adversarial loss: 0.374816\n",
      "epoch 126; iter: 0; batch classifier loss: 0.069517; batch adversarial loss: 0.417031\n",
      "epoch 127; iter: 0; batch classifier loss: 0.080281; batch adversarial loss: 0.470335\n",
      "epoch 128; iter: 0; batch classifier loss: 0.070011; batch adversarial loss: 0.417066\n",
      "epoch 129; iter: 0; batch classifier loss: 0.083174; batch adversarial loss: 0.426439\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061641; batch adversarial loss: 0.463206\n",
      "epoch 131; iter: 0; batch classifier loss: 0.098046; batch adversarial loss: 0.499092\n",
      "epoch 132; iter: 0; batch classifier loss: 0.073198; batch adversarial loss: 0.494288\n",
      "epoch 133; iter: 0; batch classifier loss: 0.061093; batch adversarial loss: 0.482519\n",
      "epoch 134; iter: 0; batch classifier loss: 0.074551; batch adversarial loss: 0.423387\n",
      "epoch 135; iter: 0; batch classifier loss: 0.048139; batch adversarial loss: 0.474843\n",
      "epoch 136; iter: 0; batch classifier loss: 0.068338; batch adversarial loss: 0.509002\n",
      "epoch 137; iter: 0; batch classifier loss: 0.063934; batch adversarial loss: 0.357806\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040533; batch adversarial loss: 0.468682\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049913; batch adversarial loss: 0.495640\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041929; batch adversarial loss: 0.420807\n",
      "epoch 141; iter: 0; batch classifier loss: 0.055038; batch adversarial loss: 0.468730\n",
      "epoch 142; iter: 0; batch classifier loss: 0.105913; batch adversarial loss: 0.448291\n",
      "epoch 143; iter: 0; batch classifier loss: 0.060826; batch adversarial loss: 0.510352\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047820; batch adversarial loss: 0.436783\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048051; batch adversarial loss: 0.435216\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041404; batch adversarial loss: 0.354770\n",
      "epoch 147; iter: 0; batch classifier loss: 0.054263; batch adversarial loss: 0.464999\n",
      "epoch 148; iter: 0; batch classifier loss: 0.044195; batch adversarial loss: 0.407555\n",
      "epoch 149; iter: 0; batch classifier loss: 0.064102; batch adversarial loss: 0.381164\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047400; batch adversarial loss: 0.451610\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036381; batch adversarial loss: 0.380529\n",
      "epoch 152; iter: 0; batch classifier loss: 0.050365; batch adversarial loss: 0.452495\n",
      "epoch 153; iter: 0; batch classifier loss: 0.057113; batch adversarial loss: 0.424423\n",
      "epoch 154; iter: 0; batch classifier loss: 0.049190; batch adversarial loss: 0.448820\n",
      "epoch 155; iter: 0; batch classifier loss: 0.062118; batch adversarial loss: 0.379107\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041108; batch adversarial loss: 0.387677\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025888; batch adversarial loss: 0.458168\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017683; batch adversarial loss: 0.411820\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030891; batch adversarial loss: 0.440139\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031197; batch adversarial loss: 0.555972\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031577; batch adversarial loss: 0.393770\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016829; batch adversarial loss: 0.525681\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033473; batch adversarial loss: 0.433626\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030894; batch adversarial loss: 0.534059\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029665; batch adversarial loss: 0.418608\n",
      "epoch 166; iter: 0; batch classifier loss: 0.052315; batch adversarial loss: 0.485730\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039326; batch adversarial loss: 0.509550\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025055; batch adversarial loss: 0.401508\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019241; batch adversarial loss: 0.430428\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024183; batch adversarial loss: 0.530171\n",
      "epoch 171; iter: 0; batch classifier loss: 0.035721; batch adversarial loss: 0.554654\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026325; batch adversarial loss: 0.457447\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033000; batch adversarial loss: 0.407600\n",
      "epoch 174; iter: 0; batch classifier loss: 0.034060; batch adversarial loss: 0.483494\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026962; batch adversarial loss: 0.441652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.018688; batch adversarial loss: 0.476117\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023643; batch adversarial loss: 0.489338\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031268; batch adversarial loss: 0.494156\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022763; batch adversarial loss: 0.384590\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030723; batch adversarial loss: 0.429501\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021088; batch adversarial loss: 0.383687\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013793; batch adversarial loss: 0.482168\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014205; batch adversarial loss: 0.479041\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011060; batch adversarial loss: 0.429600\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038376; batch adversarial loss: 0.501283\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020797; batch adversarial loss: 0.512787\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026878; batch adversarial loss: 0.430129\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028471; batch adversarial loss: 0.463235\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007626; batch adversarial loss: 0.506594\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022051; batch adversarial loss: 0.497138\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023678; batch adversarial loss: 0.482566\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010588; batch adversarial loss: 0.415027\n",
      "epoch 193; iter: 0; batch classifier loss: 0.038772; batch adversarial loss: 0.527652\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013963; batch adversarial loss: 0.474898\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030813; batch adversarial loss: 0.381821\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033891; batch adversarial loss: 0.561839\n",
      "epoch 197; iter: 0; batch classifier loss: 0.030156; batch adversarial loss: 0.521206\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027561; batch adversarial loss: 0.491294\n",
      "epoch 199; iter: 0; batch classifier loss: 0.042488; batch adversarial loss: 0.478411\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681925; batch adversarial loss: 0.773011\n",
      "epoch 1; iter: 0; batch classifier loss: 0.538516; batch adversarial loss: 0.704190\n",
      "epoch 2; iter: 0; batch classifier loss: 0.567843; batch adversarial loss: 0.669735\n",
      "epoch 3; iter: 0; batch classifier loss: 0.417516; batch adversarial loss: 0.584472\n",
      "epoch 4; iter: 0; batch classifier loss: 0.393588; batch adversarial loss: 0.589948\n",
      "epoch 5; iter: 0; batch classifier loss: 0.335390; batch adversarial loss: 0.544664\n",
      "epoch 6; iter: 0; batch classifier loss: 0.338034; batch adversarial loss: 0.569134\n",
      "epoch 7; iter: 0; batch classifier loss: 0.359995; batch adversarial loss: 0.524311\n",
      "epoch 8; iter: 0; batch classifier loss: 0.293296; batch adversarial loss: 0.532558\n",
      "epoch 9; iter: 0; batch classifier loss: 0.281200; batch adversarial loss: 0.546794\n",
      "epoch 10; iter: 0; batch classifier loss: 0.300081; batch adversarial loss: 0.569447\n",
      "epoch 11; iter: 0; batch classifier loss: 0.414045; batch adversarial loss: 0.507491\n",
      "epoch 12; iter: 0; batch classifier loss: 0.286987; batch adversarial loss: 0.492111\n",
      "epoch 13; iter: 0; batch classifier loss: 0.310532; batch adversarial loss: 0.508841\n",
      "epoch 14; iter: 0; batch classifier loss: 0.268298; batch adversarial loss: 0.490619\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274834; batch adversarial loss: 0.525791\n",
      "epoch 16; iter: 0; batch classifier loss: 0.282758; batch adversarial loss: 0.448077\n",
      "epoch 17; iter: 0; batch classifier loss: 0.276911; batch adversarial loss: 0.481344\n",
      "epoch 18; iter: 0; batch classifier loss: 0.298252; batch adversarial loss: 0.397884\n",
      "epoch 19; iter: 0; batch classifier loss: 0.364612; batch adversarial loss: 0.413863\n",
      "epoch 20; iter: 0; batch classifier loss: 0.304019; batch adversarial loss: 0.472495\n",
      "epoch 21; iter: 0; batch classifier loss: 0.264828; batch adversarial loss: 0.456385\n",
      "epoch 22; iter: 0; batch classifier loss: 0.250355; batch adversarial loss: 0.475017\n",
      "epoch 23; iter: 0; batch classifier loss: 0.263967; batch adversarial loss: 0.458627\n",
      "epoch 24; iter: 0; batch classifier loss: 0.263736; batch adversarial loss: 0.394499\n",
      "epoch 25; iter: 0; batch classifier loss: 0.297158; batch adversarial loss: 0.439031\n",
      "epoch 26; iter: 0; batch classifier loss: 0.239097; batch adversarial loss: 0.536132\n",
      "epoch 27; iter: 0; batch classifier loss: 0.220466; batch adversarial loss: 0.475443\n",
      "epoch 28; iter: 0; batch classifier loss: 0.248950; batch adversarial loss: 0.496337\n",
      "epoch 29; iter: 0; batch classifier loss: 0.157331; batch adversarial loss: 0.567715\n",
      "epoch 30; iter: 0; batch classifier loss: 0.171337; batch adversarial loss: 0.449694\n",
      "epoch 31; iter: 0; batch classifier loss: 0.279732; batch adversarial loss: 0.505331\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154945; batch adversarial loss: 0.494712\n",
      "epoch 33; iter: 0; batch classifier loss: 0.309354; batch adversarial loss: 0.416706\n",
      "epoch 34; iter: 0; batch classifier loss: 0.201068; batch adversarial loss: 0.409854\n",
      "epoch 35; iter: 0; batch classifier loss: 0.230559; batch adversarial loss: 0.492730\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187551; batch adversarial loss: 0.409017\n",
      "epoch 37; iter: 0; batch classifier loss: 0.159279; batch adversarial loss: 0.549545\n",
      "epoch 38; iter: 0; batch classifier loss: 0.174609; batch adversarial loss: 0.478811\n",
      "epoch 39; iter: 0; batch classifier loss: 0.165855; batch adversarial loss: 0.499598\n",
      "epoch 40; iter: 0; batch classifier loss: 0.184157; batch adversarial loss: 0.461457\n",
      "epoch 41; iter: 0; batch classifier loss: 0.218758; batch adversarial loss: 0.488328\n",
      "epoch 42; iter: 0; batch classifier loss: 0.231627; batch adversarial loss: 0.524184\n",
      "epoch 43; iter: 0; batch classifier loss: 0.165244; batch adversarial loss: 0.592807\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123956; batch adversarial loss: 0.403677\n",
      "epoch 45; iter: 0; batch classifier loss: 0.199442; batch adversarial loss: 0.409241\n",
      "epoch 46; iter: 0; batch classifier loss: 0.135320; batch adversarial loss: 0.501043\n",
      "epoch 47; iter: 0; batch classifier loss: 0.170018; batch adversarial loss: 0.388410\n",
      "epoch 48; iter: 0; batch classifier loss: 0.194229; batch adversarial loss: 0.407853\n",
      "epoch 49; iter: 0; batch classifier loss: 0.196917; batch adversarial loss: 0.475102\n",
      "epoch 50; iter: 0; batch classifier loss: 0.175311; batch adversarial loss: 0.460571\n",
      "epoch 51; iter: 0; batch classifier loss: 0.173869; batch adversarial loss: 0.482236\n",
      "epoch 52; iter: 0; batch classifier loss: 0.180933; batch adversarial loss: 0.393444\n",
      "epoch 53; iter: 0; batch classifier loss: 0.190941; batch adversarial loss: 0.449740\n",
      "epoch 54; iter: 0; batch classifier loss: 0.174335; batch adversarial loss: 0.414986\n",
      "epoch 55; iter: 0; batch classifier loss: 0.157593; batch adversarial loss: 0.422564\n",
      "epoch 56; iter: 0; batch classifier loss: 0.130668; batch adversarial loss: 0.524637\n",
      "epoch 57; iter: 0; batch classifier loss: 0.153982; batch adversarial loss: 0.396256\n",
      "epoch 58; iter: 0; batch classifier loss: 0.147927; batch adversarial loss: 0.499513\n",
      "epoch 59; iter: 0; batch classifier loss: 0.161985; batch adversarial loss: 0.406340\n",
      "epoch 60; iter: 0; batch classifier loss: 0.169472; batch adversarial loss: 0.498059\n",
      "epoch 61; iter: 0; batch classifier loss: 0.107068; batch adversarial loss: 0.444498\n",
      "epoch 62; iter: 0; batch classifier loss: 0.142391; batch adversarial loss: 0.391095\n",
      "epoch 63; iter: 0; batch classifier loss: 0.139189; batch adversarial loss: 0.439386\n",
      "epoch 64; iter: 0; batch classifier loss: 0.113945; batch adversarial loss: 0.433659\n",
      "epoch 65; iter: 0; batch classifier loss: 0.171388; batch adversarial loss: 0.380477\n",
      "epoch 66; iter: 0; batch classifier loss: 0.137161; batch adversarial loss: 0.565704\n",
      "epoch 67; iter: 0; batch classifier loss: 0.147377; batch adversarial loss: 0.432139\n",
      "epoch 68; iter: 0; batch classifier loss: 0.086394; batch adversarial loss: 0.427245\n",
      "epoch 69; iter: 0; batch classifier loss: 0.100253; batch adversarial loss: 0.484925\n",
      "epoch 70; iter: 0; batch classifier loss: 0.116407; batch adversarial loss: 0.454146\n",
      "epoch 71; iter: 0; batch classifier loss: 0.103415; batch adversarial loss: 0.458336\n",
      "epoch 72; iter: 0; batch classifier loss: 0.197909; batch adversarial loss: 0.468039\n",
      "epoch 73; iter: 0; batch classifier loss: 0.114379; batch adversarial loss: 0.411854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.143594; batch adversarial loss: 0.520602\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110866; batch adversarial loss: 0.425452\n",
      "epoch 76; iter: 0; batch classifier loss: 0.112439; batch adversarial loss: 0.469490\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074162; batch adversarial loss: 0.443038\n",
      "epoch 78; iter: 0; batch classifier loss: 0.136518; batch adversarial loss: 0.430308\n",
      "epoch 79; iter: 0; batch classifier loss: 0.135914; batch adversarial loss: 0.412078\n",
      "epoch 80; iter: 0; batch classifier loss: 0.092114; batch adversarial loss: 0.457616\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096885; batch adversarial loss: 0.543292\n",
      "epoch 82; iter: 0; batch classifier loss: 0.193262; batch adversarial loss: 0.451615\n",
      "epoch 83; iter: 0; batch classifier loss: 0.095734; batch adversarial loss: 0.395374\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077248; batch adversarial loss: 0.399124\n",
      "epoch 85; iter: 0; batch classifier loss: 0.115820; batch adversarial loss: 0.484358\n",
      "epoch 86; iter: 0; batch classifier loss: 0.107127; batch adversarial loss: 0.414756\n",
      "epoch 87; iter: 0; batch classifier loss: 0.090841; batch adversarial loss: 0.521901\n",
      "epoch 88; iter: 0; batch classifier loss: 0.071837; batch adversarial loss: 0.466292\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074273; batch adversarial loss: 0.507552\n",
      "epoch 90; iter: 0; batch classifier loss: 0.080143; batch adversarial loss: 0.407410\n",
      "epoch 91; iter: 0; batch classifier loss: 0.089335; batch adversarial loss: 0.413252\n",
      "epoch 92; iter: 0; batch classifier loss: 0.078186; batch adversarial loss: 0.446783\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060328; batch adversarial loss: 0.433741\n",
      "epoch 94; iter: 0; batch classifier loss: 0.078145; batch adversarial loss: 0.575552\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087234; batch adversarial loss: 0.562493\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066864; batch adversarial loss: 0.529588\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071254; batch adversarial loss: 0.386665\n",
      "epoch 98; iter: 0; batch classifier loss: 0.085071; batch adversarial loss: 0.396782\n",
      "epoch 99; iter: 0; batch classifier loss: 0.092184; batch adversarial loss: 0.378003\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059329; batch adversarial loss: 0.484595\n",
      "epoch 101; iter: 0; batch classifier loss: 0.052998; batch adversarial loss: 0.402580\n",
      "epoch 102; iter: 0; batch classifier loss: 0.091000; batch adversarial loss: 0.425698\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046388; batch adversarial loss: 0.429251\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056838; batch adversarial loss: 0.399671\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058204; batch adversarial loss: 0.455676\n",
      "epoch 106; iter: 0; batch classifier loss: 0.081086; batch adversarial loss: 0.423004\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033671; batch adversarial loss: 0.503648\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063658; batch adversarial loss: 0.513831\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037143; batch adversarial loss: 0.391856\n",
      "epoch 110; iter: 0; batch classifier loss: 0.029856; batch adversarial loss: 0.500374\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048120; batch adversarial loss: 0.469052\n",
      "epoch 112; iter: 0; batch classifier loss: 0.093253; batch adversarial loss: 0.475611\n",
      "epoch 113; iter: 0; batch classifier loss: 0.067257; batch adversarial loss: 0.510784\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033686; batch adversarial loss: 0.472567\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039857; batch adversarial loss: 0.432374\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045890; batch adversarial loss: 0.493598\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037756; batch adversarial loss: 0.489038\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036013; batch adversarial loss: 0.455330\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042478; batch adversarial loss: 0.358144\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030432; batch adversarial loss: 0.487731\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047306; batch adversarial loss: 0.402957\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029811; batch adversarial loss: 0.425939\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017100; batch adversarial loss: 0.435163\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040393; batch adversarial loss: 0.414010\n",
      "epoch 125; iter: 0; batch classifier loss: 0.064105; batch adversarial loss: 0.337972\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021348; batch adversarial loss: 0.385904\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045573; batch adversarial loss: 0.460005\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033641; batch adversarial loss: 0.500487\n",
      "epoch 129; iter: 0; batch classifier loss: 0.012863; batch adversarial loss: 0.438176\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039576; batch adversarial loss: 0.365005\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038501; batch adversarial loss: 0.388523\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038999; batch adversarial loss: 0.452368\n",
      "epoch 133; iter: 0; batch classifier loss: 0.016445; batch adversarial loss: 0.497413\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017048; batch adversarial loss: 0.453466\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022129; batch adversarial loss: 0.467892\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023887; batch adversarial loss: 0.365354\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039022; batch adversarial loss: 0.478997\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044371; batch adversarial loss: 0.500244\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026994; batch adversarial loss: 0.419950\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025262; batch adversarial loss: 0.484093\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029633; batch adversarial loss: 0.376621\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023778; batch adversarial loss: 0.459217\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028661; batch adversarial loss: 0.444960\n",
      "epoch 144; iter: 0; batch classifier loss: 0.057416; batch adversarial loss: 0.432152\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042422; batch adversarial loss: 0.431948\n",
      "epoch 146; iter: 0; batch classifier loss: 0.008788; batch adversarial loss: 0.442654\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019878; batch adversarial loss: 0.557389\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037080; batch adversarial loss: 0.407676\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023063; batch adversarial loss: 0.497222\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017434; batch adversarial loss: 0.474679\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024233; batch adversarial loss: 0.403912\n",
      "epoch 152; iter: 0; batch classifier loss: 0.056419; batch adversarial loss: 0.454782\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011386; batch adversarial loss: 0.454473\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034550; batch adversarial loss: 0.495238\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025455; batch adversarial loss: 0.528765\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010158; batch adversarial loss: 0.371825\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019208; batch adversarial loss: 0.420560\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037473; batch adversarial loss: 0.478367\n",
      "epoch 159; iter: 0; batch classifier loss: 0.048369; batch adversarial loss: 0.450808\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009528; batch adversarial loss: 0.419055\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013305; batch adversarial loss: 0.491098\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024019; batch adversarial loss: 0.453388\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018968; batch adversarial loss: 0.396320\n",
      "epoch 164; iter: 0; batch classifier loss: 0.008856; batch adversarial loss: 0.369325\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024738; batch adversarial loss: 0.428319\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032246; batch adversarial loss: 0.541322\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025395; batch adversarial loss: 0.372293\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015590; batch adversarial loss: 0.378371\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025141; batch adversarial loss: 0.401383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.016458; batch adversarial loss: 0.492836\n",
      "epoch 171; iter: 0; batch classifier loss: 0.039838; batch adversarial loss: 0.431525\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012893; batch adversarial loss: 0.449281\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021382; batch adversarial loss: 0.550530\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021567; batch adversarial loss: 0.398339\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018780; batch adversarial loss: 0.488107\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011686; batch adversarial loss: 0.439148\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025753; batch adversarial loss: 0.403101\n",
      "epoch 178; iter: 0; batch classifier loss: 0.060367; batch adversarial loss: 0.426309\n",
      "epoch 179; iter: 0; batch classifier loss: 0.060778; batch adversarial loss: 0.384988\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008591; batch adversarial loss: 0.483088\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006674; batch adversarial loss: 0.384595\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022282; batch adversarial loss: 0.439034\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007363; batch adversarial loss: 0.345406\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020320; batch adversarial loss: 0.427727\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018145; batch adversarial loss: 0.422235\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021395; batch adversarial loss: 0.416566\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011449; batch adversarial loss: 0.415821\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015853; batch adversarial loss: 0.508939\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012650; batch adversarial loss: 0.370974\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015016; batch adversarial loss: 0.527110\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006445; batch adversarial loss: 0.406760\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016543; batch adversarial loss: 0.367006\n",
      "epoch 193; iter: 0; batch classifier loss: 0.057224; batch adversarial loss: 0.407960\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022232; batch adversarial loss: 0.465986\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025205; batch adversarial loss: 0.526934\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017452; batch adversarial loss: 0.537858\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006337; batch adversarial loss: 0.562566\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013828; batch adversarial loss: 0.398559\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026173; batch adversarial loss: 0.428694\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713578; batch adversarial loss: 0.611581\n",
      "epoch 1; iter: 0; batch classifier loss: 0.406177; batch adversarial loss: 0.609942\n",
      "epoch 2; iter: 0; batch classifier loss: 0.370268; batch adversarial loss: 0.587265\n",
      "epoch 3; iter: 0; batch classifier loss: 0.305711; batch adversarial loss: 0.564307\n",
      "epoch 4; iter: 0; batch classifier loss: 0.289070; batch adversarial loss: 0.567180\n",
      "epoch 5; iter: 0; batch classifier loss: 0.350465; batch adversarial loss: 0.547667\n",
      "epoch 6; iter: 0; batch classifier loss: 0.329908; batch adversarial loss: 0.548399\n",
      "epoch 7; iter: 0; batch classifier loss: 0.269860; batch adversarial loss: 0.497632\n",
      "epoch 8; iter: 0; batch classifier loss: 0.310427; batch adversarial loss: 0.557060\n",
      "epoch 9; iter: 0; batch classifier loss: 0.226032; batch adversarial loss: 0.491961\n",
      "epoch 10; iter: 0; batch classifier loss: 0.328268; batch adversarial loss: 0.482627\n",
      "epoch 11; iter: 0; batch classifier loss: 0.225600; batch adversarial loss: 0.460639\n",
      "epoch 12; iter: 0; batch classifier loss: 0.310900; batch adversarial loss: 0.567354\n",
      "epoch 13; iter: 0; batch classifier loss: 0.252937; batch adversarial loss: 0.479692\n",
      "epoch 14; iter: 0; batch classifier loss: 0.303630; batch adversarial loss: 0.566645\n",
      "epoch 15; iter: 0; batch classifier loss: 0.291245; batch adversarial loss: 0.478430\n",
      "epoch 16; iter: 0; batch classifier loss: 0.407007; batch adversarial loss: 0.592530\n",
      "epoch 17; iter: 0; batch classifier loss: 0.392982; batch adversarial loss: 0.554309\n",
      "epoch 18; iter: 0; batch classifier loss: 0.581532; batch adversarial loss: 0.524007\n",
      "epoch 19; iter: 0; batch classifier loss: 0.581382; batch adversarial loss: 0.508187\n",
      "epoch 20; iter: 0; batch classifier loss: 0.560707; batch adversarial loss: 0.467873\n",
      "epoch 21; iter: 0; batch classifier loss: 0.274823; batch adversarial loss: 0.476397\n",
      "epoch 22; iter: 0; batch classifier loss: 0.234418; batch adversarial loss: 0.561262\n",
      "epoch 23; iter: 0; batch classifier loss: 0.217297; batch adversarial loss: 0.488994\n",
      "epoch 24; iter: 0; batch classifier loss: 0.139441; batch adversarial loss: 0.464882\n",
      "epoch 25; iter: 0; batch classifier loss: 0.188328; batch adversarial loss: 0.463213\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189264; batch adversarial loss: 0.496914\n",
      "epoch 27; iter: 0; batch classifier loss: 0.197246; batch adversarial loss: 0.442786\n",
      "epoch 28; iter: 0; batch classifier loss: 0.146099; batch adversarial loss: 0.501313\n",
      "epoch 29; iter: 0; batch classifier loss: 0.133472; batch adversarial loss: 0.418450\n",
      "epoch 30; iter: 0; batch classifier loss: 0.221293; batch adversarial loss: 0.492695\n",
      "epoch 31; iter: 0; batch classifier loss: 0.129708; batch adversarial loss: 0.455941\n",
      "epoch 32; iter: 0; batch classifier loss: 0.190165; batch adversarial loss: 0.441820\n",
      "epoch 33; iter: 0; batch classifier loss: 0.206069; batch adversarial loss: 0.524661\n",
      "epoch 34; iter: 0; batch classifier loss: 0.168241; batch adversarial loss: 0.382711\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153426; batch adversarial loss: 0.388968\n",
      "epoch 36; iter: 0; batch classifier loss: 0.119665; batch adversarial loss: 0.492703\n",
      "epoch 37; iter: 0; batch classifier loss: 0.211705; batch adversarial loss: 0.437844\n",
      "epoch 38; iter: 0; batch classifier loss: 0.219790; batch adversarial loss: 0.430026\n",
      "epoch 39; iter: 0; batch classifier loss: 0.163613; batch adversarial loss: 0.523537\n",
      "epoch 40; iter: 0; batch classifier loss: 0.158134; batch adversarial loss: 0.419573\n",
      "epoch 41; iter: 0; batch classifier loss: 0.157409; batch adversarial loss: 0.444042\n",
      "epoch 42; iter: 0; batch classifier loss: 0.186975; batch adversarial loss: 0.377511\n",
      "epoch 43; iter: 0; batch classifier loss: 0.168400; batch adversarial loss: 0.399429\n",
      "epoch 44; iter: 0; batch classifier loss: 0.183567; batch adversarial loss: 0.488296\n",
      "epoch 45; iter: 0; batch classifier loss: 0.189600; batch adversarial loss: 0.503836\n",
      "epoch 46; iter: 0; batch classifier loss: 0.178626; batch adversarial loss: 0.499671\n",
      "epoch 47; iter: 0; batch classifier loss: 0.191857; batch adversarial loss: 0.468514\n",
      "epoch 48; iter: 0; batch classifier loss: 0.175803; batch adversarial loss: 0.476517\n",
      "epoch 49; iter: 0; batch classifier loss: 0.180429; batch adversarial loss: 0.521202\n",
      "epoch 50; iter: 0; batch classifier loss: 0.149559; batch adversarial loss: 0.505233\n",
      "epoch 51; iter: 0; batch classifier loss: 0.166181; batch adversarial loss: 0.539703\n",
      "epoch 52; iter: 0; batch classifier loss: 0.238100; batch adversarial loss: 0.564792\n",
      "epoch 53; iter: 0; batch classifier loss: 0.179918; batch adversarial loss: 0.489291\n",
      "epoch 54; iter: 0; batch classifier loss: 0.207004; batch adversarial loss: 0.546715\n",
      "epoch 55; iter: 0; batch classifier loss: 0.287283; batch adversarial loss: 0.454007\n",
      "epoch 56; iter: 0; batch classifier loss: 0.185663; batch adversarial loss: 0.424967\n",
      "epoch 57; iter: 0; batch classifier loss: 0.179958; batch adversarial loss: 0.501218\n",
      "epoch 58; iter: 0; batch classifier loss: 0.215807; batch adversarial loss: 0.497601\n",
      "epoch 59; iter: 0; batch classifier loss: 0.218684; batch adversarial loss: 0.402337\n",
      "epoch 60; iter: 0; batch classifier loss: 0.189227; batch adversarial loss: 0.495038\n",
      "epoch 61; iter: 0; batch classifier loss: 0.142935; batch adversarial loss: 0.417777\n",
      "epoch 62; iter: 0; batch classifier loss: 0.209607; batch adversarial loss: 0.398013\n",
      "epoch 63; iter: 0; batch classifier loss: 0.109978; batch adversarial loss: 0.439807\n",
      "epoch 64; iter: 0; batch classifier loss: 0.184995; batch adversarial loss: 0.457522\n",
      "epoch 65; iter: 0; batch classifier loss: 0.248484; batch adversarial loss: 0.361872\n",
      "epoch 66; iter: 0; batch classifier loss: 0.240203; batch adversarial loss: 0.460393\n",
      "epoch 67; iter: 0; batch classifier loss: 0.188766; batch adversarial loss: 0.412030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.117510; batch adversarial loss: 0.509648\n",
      "epoch 69; iter: 0; batch classifier loss: 0.207887; batch adversarial loss: 0.506874\n",
      "epoch 70; iter: 0; batch classifier loss: 0.204837; batch adversarial loss: 0.447461\n",
      "epoch 71; iter: 0; batch classifier loss: 0.181931; batch adversarial loss: 0.447641\n",
      "epoch 72; iter: 0; batch classifier loss: 0.228874; batch adversarial loss: 0.396641\n",
      "epoch 73; iter: 0; batch classifier loss: 0.211052; batch adversarial loss: 0.409618\n",
      "epoch 74; iter: 0; batch classifier loss: 0.249925; batch adversarial loss: 0.372823\n",
      "epoch 75; iter: 0; batch classifier loss: 0.208023; batch adversarial loss: 0.373047\n",
      "epoch 76; iter: 0; batch classifier loss: 0.135147; batch adversarial loss: 0.421208\n",
      "epoch 77; iter: 0; batch classifier loss: 0.096879; batch adversarial loss: 0.431856\n",
      "epoch 78; iter: 0; batch classifier loss: 0.163550; batch adversarial loss: 0.470215\n",
      "epoch 79; iter: 0; batch classifier loss: 0.186400; batch adversarial loss: 0.472798\n",
      "epoch 80; iter: 0; batch classifier loss: 0.181948; batch adversarial loss: 0.470655\n",
      "epoch 81; iter: 0; batch classifier loss: 0.226690; batch adversarial loss: 0.396091\n",
      "epoch 82; iter: 0; batch classifier loss: 0.203474; batch adversarial loss: 0.395983\n",
      "epoch 83; iter: 0; batch classifier loss: 0.158775; batch adversarial loss: 0.458513\n",
      "epoch 84; iter: 0; batch classifier loss: 0.208930; batch adversarial loss: 0.434280\n",
      "epoch 85; iter: 0; batch classifier loss: 0.243542; batch adversarial loss: 0.521702\n",
      "epoch 86; iter: 0; batch classifier loss: 0.280021; batch adversarial loss: 0.483282\n",
      "epoch 87; iter: 0; batch classifier loss: 0.180372; batch adversarial loss: 0.471402\n",
      "epoch 88; iter: 0; batch classifier loss: 0.198283; batch adversarial loss: 0.520363\n",
      "epoch 89; iter: 0; batch classifier loss: 0.128529; batch adversarial loss: 0.420672\n",
      "epoch 90; iter: 0; batch classifier loss: 0.190829; batch adversarial loss: 0.521786\n",
      "epoch 91; iter: 0; batch classifier loss: 0.229861; batch adversarial loss: 0.509521\n",
      "epoch 92; iter: 0; batch classifier loss: 0.197882; batch adversarial loss: 0.409608\n",
      "epoch 93; iter: 0; batch classifier loss: 0.214987; batch adversarial loss: 0.421779\n",
      "epoch 94; iter: 0; batch classifier loss: 0.234425; batch adversarial loss: 0.496118\n",
      "epoch 95; iter: 0; batch classifier loss: 0.228136; batch adversarial loss: 0.446471\n",
      "epoch 96; iter: 0; batch classifier loss: 0.076038; batch adversarial loss: 0.544417\n",
      "epoch 97; iter: 0; batch classifier loss: 0.105019; batch adversarial loss: 0.485800\n",
      "epoch 98; iter: 0; batch classifier loss: 0.089145; batch adversarial loss: 0.524781\n",
      "epoch 99; iter: 0; batch classifier loss: 0.106640; batch adversarial loss: 0.414584\n",
      "epoch 100; iter: 0; batch classifier loss: 0.125940; batch adversarial loss: 0.380259\n",
      "epoch 101; iter: 0; batch classifier loss: 0.127016; batch adversarial loss: 0.453309\n",
      "epoch 102; iter: 0; batch classifier loss: 0.094265; batch adversarial loss: 0.501367\n",
      "epoch 103; iter: 0; batch classifier loss: 0.195780; batch adversarial loss: 0.408286\n",
      "epoch 104; iter: 0; batch classifier loss: 0.146677; batch adversarial loss: 0.569888\n",
      "epoch 105; iter: 0; batch classifier loss: 0.104804; batch adversarial loss: 0.438999\n",
      "epoch 106; iter: 0; batch classifier loss: 0.122177; batch adversarial loss: 0.460870\n",
      "epoch 107; iter: 0; batch classifier loss: 0.083273; batch adversarial loss: 0.415642\n",
      "epoch 108; iter: 0; batch classifier loss: 0.093615; batch adversarial loss: 0.360384\n",
      "epoch 109; iter: 0; batch classifier loss: 0.077683; batch adversarial loss: 0.516182\n",
      "epoch 110; iter: 0; batch classifier loss: 0.123523; batch adversarial loss: 0.362875\n",
      "epoch 111; iter: 0; batch classifier loss: 0.075951; batch adversarial loss: 0.444416\n",
      "epoch 112; iter: 0; batch classifier loss: 0.078655; batch adversarial loss: 0.378175\n",
      "epoch 113; iter: 0; batch classifier loss: 0.091909; batch adversarial loss: 0.446765\n",
      "epoch 114; iter: 0; batch classifier loss: 0.109412; batch adversarial loss: 0.399388\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062533; batch adversarial loss: 0.457391\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062796; batch adversarial loss: 0.500443\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040925; batch adversarial loss: 0.426612\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051981; batch adversarial loss: 0.383416\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065866; batch adversarial loss: 0.525883\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064377; batch adversarial loss: 0.460570\n",
      "epoch 121; iter: 0; batch classifier loss: 0.120351; batch adversarial loss: 0.407354\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026141; batch adversarial loss: 0.461541\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043265; batch adversarial loss: 0.426556\n",
      "epoch 124; iter: 0; batch classifier loss: 0.061242; batch adversarial loss: 0.341067\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048720; batch adversarial loss: 0.421452\n",
      "epoch 126; iter: 0; batch classifier loss: 0.072208; batch adversarial loss: 0.420800\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053347; batch adversarial loss: 0.354406\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054071; batch adversarial loss: 0.471573\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048349; batch adversarial loss: 0.464154\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051278; batch adversarial loss: 0.405089\n",
      "epoch 131; iter: 0; batch classifier loss: 0.068298; batch adversarial loss: 0.483520\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026722; batch adversarial loss: 0.472738\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021288; batch adversarial loss: 0.425623\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027805; batch adversarial loss: 0.456070\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016245; batch adversarial loss: 0.483012\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057166; batch adversarial loss: 0.394283\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039715; batch adversarial loss: 0.485890\n",
      "epoch 138; iter: 0; batch classifier loss: 0.073671; batch adversarial loss: 0.440102\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023353; batch adversarial loss: 0.500702\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030823; batch adversarial loss: 0.443348\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021391; batch adversarial loss: 0.449781\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045301; batch adversarial loss: 0.486740\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021224; batch adversarial loss: 0.489942\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031570; batch adversarial loss: 0.484376\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033936; batch adversarial loss: 0.464633\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027682; batch adversarial loss: 0.434371\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023446; batch adversarial loss: 0.569030\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019903; batch adversarial loss: 0.450925\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019942; batch adversarial loss: 0.472686\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040407; batch adversarial loss: 0.584203\n",
      "epoch 151; iter: 0; batch classifier loss: 0.068098; batch adversarial loss: 0.357510\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010097; batch adversarial loss: 0.475880\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029218; batch adversarial loss: 0.519995\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018048; batch adversarial loss: 0.377175\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030246; batch adversarial loss: 0.388679\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050680; batch adversarial loss: 0.482921\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032889; batch adversarial loss: 0.370834\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036169; batch adversarial loss: 0.471882\n",
      "epoch 159; iter: 0; batch classifier loss: 0.050461; batch adversarial loss: 0.368947\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014561; batch adversarial loss: 0.429496\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012095; batch adversarial loss: 0.392613\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011035; batch adversarial loss: 0.391364\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020038; batch adversarial loss: 0.438082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.016307; batch adversarial loss: 0.413206\n",
      "epoch 165; iter: 0; batch classifier loss: 0.063762; batch adversarial loss: 0.483943\n",
      "epoch 166; iter: 0; batch classifier loss: 0.057244; batch adversarial loss: 0.397820\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026738; batch adversarial loss: 0.465053\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014535; batch adversarial loss: 0.470281\n",
      "epoch 169; iter: 0; batch classifier loss: 0.061133; batch adversarial loss: 0.432078\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023378; batch adversarial loss: 0.387855\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018810; batch adversarial loss: 0.398939\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016214; batch adversarial loss: 0.401742\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017807; batch adversarial loss: 0.466811\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028657; batch adversarial loss: 0.478820\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042331; batch adversarial loss: 0.413876\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023756; batch adversarial loss: 0.488840\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022641; batch adversarial loss: 0.513591\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019174; batch adversarial loss: 0.409264\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030906; batch adversarial loss: 0.473175\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032150; batch adversarial loss: 0.535312\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022384; batch adversarial loss: 0.417414\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014109; batch adversarial loss: 0.406626\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036861; batch adversarial loss: 0.354847\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012020; batch adversarial loss: 0.463216\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013059; batch adversarial loss: 0.421926\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013454; batch adversarial loss: 0.482707\n",
      "epoch 187; iter: 0; batch classifier loss: 0.052731; batch adversarial loss: 0.446037\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012821; batch adversarial loss: 0.531044\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021541; batch adversarial loss: 0.364194\n",
      "epoch 190; iter: 0; batch classifier loss: 0.068875; batch adversarial loss: 0.389882\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014527; batch adversarial loss: 0.451243\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015015; batch adversarial loss: 0.388121\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018267; batch adversarial loss: 0.385803\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031736; batch adversarial loss: 0.531168\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014871; batch adversarial loss: 0.465589\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028833; batch adversarial loss: 0.485232\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015149; batch adversarial loss: 0.445149\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023732; batch adversarial loss: 0.505955\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007129; batch adversarial loss: 0.408022\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714718; batch adversarial loss: 0.701084\n",
      "epoch 1; iter: 0; batch classifier loss: 0.511560; batch adversarial loss: 0.664955\n",
      "epoch 2; iter: 0; batch classifier loss: 0.507088; batch adversarial loss: 0.632031\n",
      "epoch 3; iter: 0; batch classifier loss: 0.406303; batch adversarial loss: 0.632277\n",
      "epoch 4; iter: 0; batch classifier loss: 0.571937; batch adversarial loss: 0.605535\n",
      "epoch 5; iter: 0; batch classifier loss: 0.437812; batch adversarial loss: 0.596551\n",
      "epoch 6; iter: 0; batch classifier loss: 0.518933; batch adversarial loss: 0.580898\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537224; batch adversarial loss: 0.545487\n",
      "epoch 8; iter: 0; batch classifier loss: 0.455597; batch adversarial loss: 0.597687\n",
      "epoch 9; iter: 0; batch classifier loss: 0.438809; batch adversarial loss: 0.539828\n",
      "epoch 10; iter: 0; batch classifier loss: 0.427795; batch adversarial loss: 0.537385\n",
      "epoch 11; iter: 0; batch classifier loss: 0.409222; batch adversarial loss: 0.565158\n",
      "epoch 12; iter: 0; batch classifier loss: 0.301047; batch adversarial loss: 0.590905\n",
      "epoch 13; iter: 0; batch classifier loss: 0.299957; batch adversarial loss: 0.556260\n",
      "epoch 14; iter: 0; batch classifier loss: 0.380376; batch adversarial loss: 0.533823\n",
      "epoch 15; iter: 0; batch classifier loss: 0.368730; batch adversarial loss: 0.485062\n",
      "epoch 16; iter: 0; batch classifier loss: 0.279093; batch adversarial loss: 0.543560\n",
      "epoch 17; iter: 0; batch classifier loss: 0.418138; batch adversarial loss: 0.463805\n",
      "epoch 18; iter: 0; batch classifier loss: 0.301928; batch adversarial loss: 0.526953\n",
      "epoch 19; iter: 0; batch classifier loss: 0.322828; batch adversarial loss: 0.460715\n",
      "epoch 20; iter: 0; batch classifier loss: 0.264614; batch adversarial loss: 0.414501\n",
      "epoch 21; iter: 0; batch classifier loss: 0.252207; batch adversarial loss: 0.492405\n",
      "epoch 22; iter: 0; batch classifier loss: 0.292510; batch adversarial loss: 0.527911\n",
      "epoch 23; iter: 0; batch classifier loss: 0.363810; batch adversarial loss: 0.481647\n",
      "epoch 24; iter: 0; batch classifier loss: 0.252468; batch adversarial loss: 0.488471\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237761; batch adversarial loss: 0.538394\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208945; batch adversarial loss: 0.578678\n",
      "epoch 27; iter: 0; batch classifier loss: 0.336562; batch adversarial loss: 0.513498\n",
      "epoch 28; iter: 0; batch classifier loss: 0.329269; batch adversarial loss: 0.458047\n",
      "epoch 29; iter: 0; batch classifier loss: 0.286772; batch adversarial loss: 0.491821\n",
      "epoch 30; iter: 0; batch classifier loss: 0.258634; batch adversarial loss: 0.396488\n",
      "epoch 31; iter: 0; batch classifier loss: 0.245933; batch adversarial loss: 0.453356\n",
      "epoch 32; iter: 0; batch classifier loss: 0.244112; batch adversarial loss: 0.464585\n",
      "epoch 33; iter: 0; batch classifier loss: 0.298146; batch adversarial loss: 0.458159\n",
      "epoch 34; iter: 0; batch classifier loss: 0.263421; batch adversarial loss: 0.468097\n",
      "epoch 35; iter: 0; batch classifier loss: 0.254119; batch adversarial loss: 0.383341\n",
      "epoch 36; iter: 0; batch classifier loss: 0.217839; batch adversarial loss: 0.506896\n",
      "epoch 37; iter: 0; batch classifier loss: 0.211634; batch adversarial loss: 0.498606\n",
      "epoch 38; iter: 0; batch classifier loss: 0.220701; batch adversarial loss: 0.526316\n",
      "epoch 39; iter: 0; batch classifier loss: 0.297795; batch adversarial loss: 0.404083\n",
      "epoch 40; iter: 0; batch classifier loss: 0.222513; batch adversarial loss: 0.499475\n",
      "epoch 41; iter: 0; batch classifier loss: 0.248190; batch adversarial loss: 0.534751\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235239; batch adversarial loss: 0.390360\n",
      "epoch 43; iter: 0; batch classifier loss: 0.262300; batch adversarial loss: 0.436253\n",
      "epoch 44; iter: 0; batch classifier loss: 0.280070; batch adversarial loss: 0.423259\n",
      "epoch 45; iter: 0; batch classifier loss: 0.261243; batch adversarial loss: 0.435700\n",
      "epoch 46; iter: 0; batch classifier loss: 0.228611; batch adversarial loss: 0.352494\n",
      "epoch 47; iter: 0; batch classifier loss: 0.149862; batch adversarial loss: 0.470768\n",
      "epoch 48; iter: 0; batch classifier loss: 0.121478; batch adversarial loss: 0.495411\n",
      "epoch 49; iter: 0; batch classifier loss: 0.188461; batch adversarial loss: 0.361334\n",
      "epoch 50; iter: 0; batch classifier loss: 0.163391; batch adversarial loss: 0.447394\n",
      "epoch 51; iter: 0; batch classifier loss: 0.144316; batch adversarial loss: 0.459072\n",
      "epoch 52; iter: 0; batch classifier loss: 0.243583; batch adversarial loss: 0.359225\n",
      "epoch 53; iter: 0; batch classifier loss: 0.168949; batch adversarial loss: 0.423088\n",
      "epoch 54; iter: 0; batch classifier loss: 0.220244; batch adversarial loss: 0.348341\n",
      "epoch 55; iter: 0; batch classifier loss: 0.222583; batch adversarial loss: 0.398072\n",
      "epoch 56; iter: 0; batch classifier loss: 0.149320; batch adversarial loss: 0.408908\n",
      "epoch 57; iter: 0; batch classifier loss: 0.178702; batch adversarial loss: 0.397115\n",
      "epoch 58; iter: 0; batch classifier loss: 0.224495; batch adversarial loss: 0.556920\n",
      "epoch 59; iter: 0; batch classifier loss: 0.126909; batch adversarial loss: 0.421287\n",
      "epoch 60; iter: 0; batch classifier loss: 0.132433; batch adversarial loss: 0.496131\n",
      "epoch 61; iter: 0; batch classifier loss: 0.198565; batch adversarial loss: 0.595021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.099931; batch adversarial loss: 0.396363\n",
      "epoch 63; iter: 0; batch classifier loss: 0.142282; batch adversarial loss: 0.446409\n",
      "epoch 64; iter: 0; batch classifier loss: 0.136664; batch adversarial loss: 0.460717\n",
      "epoch 65; iter: 0; batch classifier loss: 0.263684; batch adversarial loss: 0.398789\n",
      "epoch 66; iter: 0; batch classifier loss: 0.115432; batch adversarial loss: 0.472418\n",
      "epoch 67; iter: 0; batch classifier loss: 0.126545; batch adversarial loss: 0.382982\n",
      "epoch 68; iter: 0; batch classifier loss: 0.180006; batch adversarial loss: 0.445607\n",
      "epoch 69; iter: 0; batch classifier loss: 0.223944; batch adversarial loss: 0.460179\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144343; batch adversarial loss: 0.519798\n",
      "epoch 71; iter: 0; batch classifier loss: 0.113691; batch adversarial loss: 0.485138\n",
      "epoch 72; iter: 0; batch classifier loss: 0.198842; batch adversarial loss: 0.373257\n",
      "epoch 73; iter: 0; batch classifier loss: 0.218482; batch adversarial loss: 0.532752\n",
      "epoch 74; iter: 0; batch classifier loss: 0.074024; batch adversarial loss: 0.396206\n",
      "epoch 75; iter: 0; batch classifier loss: 0.089158; batch adversarial loss: 0.493424\n",
      "epoch 76; iter: 0; batch classifier loss: 0.068288; batch adversarial loss: 0.506192\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050168; batch adversarial loss: 0.423140\n",
      "epoch 78; iter: 0; batch classifier loss: 0.067794; batch adversarial loss: 0.475109\n",
      "epoch 79; iter: 0; batch classifier loss: 0.086046; batch adversarial loss: 0.403114\n",
      "epoch 80; iter: 0; batch classifier loss: 0.095377; batch adversarial loss: 0.341282\n",
      "epoch 81; iter: 0; batch classifier loss: 0.119358; batch adversarial loss: 0.523883\n",
      "epoch 82; iter: 0; batch classifier loss: 0.087298; batch adversarial loss: 0.424000\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054934; batch adversarial loss: 0.394092\n",
      "epoch 84; iter: 0; batch classifier loss: 0.092933; batch adversarial loss: 0.528258\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080706; batch adversarial loss: 0.542230\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081443; batch adversarial loss: 0.485948\n",
      "epoch 87; iter: 0; batch classifier loss: 0.032925; batch adversarial loss: 0.446922\n",
      "epoch 88; iter: 0; batch classifier loss: 0.089754; batch adversarial loss: 0.367701\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056154; batch adversarial loss: 0.435377\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045499; batch adversarial loss: 0.468933\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056224; batch adversarial loss: 0.475889\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043618; batch adversarial loss: 0.429245\n",
      "epoch 93; iter: 0; batch classifier loss: 0.029422; batch adversarial loss: 0.449970\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079986; batch adversarial loss: 0.405923\n",
      "epoch 95; iter: 0; batch classifier loss: 0.037834; batch adversarial loss: 0.476136\n",
      "epoch 96; iter: 0; batch classifier loss: 0.040147; batch adversarial loss: 0.433603\n",
      "epoch 97; iter: 0; batch classifier loss: 0.026869; batch adversarial loss: 0.490270\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049115; batch adversarial loss: 0.443434\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044717; batch adversarial loss: 0.403581\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055964; batch adversarial loss: 0.454977\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042984; batch adversarial loss: 0.501134\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039704; batch adversarial loss: 0.325290\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050945; batch adversarial loss: 0.474951\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066374; batch adversarial loss: 0.421229\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056260; batch adversarial loss: 0.358543\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025623; batch adversarial loss: 0.452212\n",
      "epoch 107; iter: 0; batch classifier loss: 0.057978; batch adversarial loss: 0.422865\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028543; batch adversarial loss: 0.419888\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061324; batch adversarial loss: 0.427590\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025296; batch adversarial loss: 0.455054\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029073; batch adversarial loss: 0.444165\n",
      "epoch 112; iter: 0; batch classifier loss: 0.029620; batch adversarial loss: 0.470675\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026258; batch adversarial loss: 0.541742\n",
      "epoch 114; iter: 0; batch classifier loss: 0.031467; batch adversarial loss: 0.461044\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051082; batch adversarial loss: 0.427313\n",
      "epoch 116; iter: 0; batch classifier loss: 0.031220; batch adversarial loss: 0.483008\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029668; batch adversarial loss: 0.425543\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029931; batch adversarial loss: 0.485038\n",
      "epoch 119; iter: 0; batch classifier loss: 0.017951; batch adversarial loss: 0.532911\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035419; batch adversarial loss: 0.410642\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040753; batch adversarial loss: 0.449804\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026466; batch adversarial loss: 0.379897\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029826; batch adversarial loss: 0.396695\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024779; batch adversarial loss: 0.489017\n",
      "epoch 125; iter: 0; batch classifier loss: 0.015288; batch adversarial loss: 0.393169\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057337; batch adversarial loss: 0.464320\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021987; batch adversarial loss: 0.415126\n",
      "epoch 128; iter: 0; batch classifier loss: 0.011706; batch adversarial loss: 0.380168\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045172; batch adversarial loss: 0.482715\n",
      "epoch 130; iter: 0; batch classifier loss: 0.014673; batch adversarial loss: 0.427686\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027019; batch adversarial loss: 0.498815\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015287; batch adversarial loss: 0.513507\n",
      "epoch 133; iter: 0; batch classifier loss: 0.080635; batch adversarial loss: 0.344956\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034279; batch adversarial loss: 0.513075\n",
      "epoch 135; iter: 0; batch classifier loss: 0.008155; batch adversarial loss: 0.446081\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027810; batch adversarial loss: 0.475833\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018137; batch adversarial loss: 0.458559\n",
      "epoch 138; iter: 0; batch classifier loss: 0.008951; batch adversarial loss: 0.468973\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009403; batch adversarial loss: 0.481169\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024419; batch adversarial loss: 0.526048\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017992; batch adversarial loss: 0.524282\n",
      "epoch 142; iter: 0; batch classifier loss: 0.007761; batch adversarial loss: 0.448662\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025495; batch adversarial loss: 0.519929\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049434; batch adversarial loss: 0.481428\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028656; batch adversarial loss: 0.493401\n",
      "epoch 146; iter: 0; batch classifier loss: 0.007767; batch adversarial loss: 0.430252\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026087; batch adversarial loss: 0.474139\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013515; batch adversarial loss: 0.370786\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022266; batch adversarial loss: 0.522476\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039585; batch adversarial loss: 0.445874\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016894; batch adversarial loss: 0.489420\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017752; batch adversarial loss: 0.354090\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028896; batch adversarial loss: 0.342821\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026194; batch adversarial loss: 0.387157\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016072; batch adversarial loss: 0.401404\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014554; batch adversarial loss: 0.494653\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011226; batch adversarial loss: 0.345622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.005637; batch adversarial loss: 0.368457\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021858; batch adversarial loss: 0.442469\n",
      "epoch 160; iter: 0; batch classifier loss: 0.002436; batch adversarial loss: 0.459020\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021412; batch adversarial loss: 0.429831\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037985; batch adversarial loss: 0.500240\n",
      "epoch 163; iter: 0; batch classifier loss: 0.005760; batch adversarial loss: 0.476664\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015684; batch adversarial loss: 0.365552\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015860; batch adversarial loss: 0.459672\n",
      "epoch 166; iter: 0; batch classifier loss: 0.041105; batch adversarial loss: 0.464423\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014317; batch adversarial loss: 0.468802\n",
      "epoch 168; iter: 0; batch classifier loss: 0.003919; batch adversarial loss: 0.363614\n",
      "epoch 169; iter: 0; batch classifier loss: 0.005396; batch adversarial loss: 0.380225\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013871; batch adversarial loss: 0.379393\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005939; batch adversarial loss: 0.454188\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010341; batch adversarial loss: 0.433470\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010977; batch adversarial loss: 0.380780\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023076; batch adversarial loss: 0.371400\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023943; batch adversarial loss: 0.367829\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017146; batch adversarial loss: 0.509133\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008791; batch adversarial loss: 0.425432\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013669; batch adversarial loss: 0.347712\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030725; batch adversarial loss: 0.575339\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014104; batch adversarial loss: 0.419425\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027236; batch adversarial loss: 0.429541\n",
      "epoch 182; iter: 0; batch classifier loss: 0.040047; batch adversarial loss: 0.536210\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018721; batch adversarial loss: 0.381477\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012731; batch adversarial loss: 0.510174\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014142; batch adversarial loss: 0.452617\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007449; batch adversarial loss: 0.391587\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006334; batch adversarial loss: 0.515249\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004070; batch adversarial loss: 0.397701\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013999; batch adversarial loss: 0.560100\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018582; batch adversarial loss: 0.498376\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006075; batch adversarial loss: 0.441495\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010459; batch adversarial loss: 0.464710\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034362; batch adversarial loss: 0.448984\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004540; batch adversarial loss: 0.494379\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014430; batch adversarial loss: 0.374422\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009185; batch adversarial loss: 0.390827\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010133; batch adversarial loss: 0.471116\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011370; batch adversarial loss: 0.376090\n",
      "epoch 199; iter: 0; batch classifier loss: 0.002446; batch adversarial loss: 0.552121\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705818; batch adversarial loss: 0.544818\n",
      "epoch 1; iter: 0; batch classifier loss: 0.450933; batch adversarial loss: 0.598594\n",
      "epoch 2; iter: 0; batch classifier loss: 0.405396; batch adversarial loss: 0.589030\n",
      "epoch 3; iter: 0; batch classifier loss: 0.399745; batch adversarial loss: 0.618533\n",
      "epoch 4; iter: 0; batch classifier loss: 0.325135; batch adversarial loss: 0.576434\n",
      "epoch 5; iter: 0; batch classifier loss: 0.405374; batch adversarial loss: 0.650525\n",
      "epoch 6; iter: 0; batch classifier loss: 0.383162; batch adversarial loss: 0.625232\n",
      "epoch 7; iter: 0; batch classifier loss: 0.377097; batch adversarial loss: 0.584593\n",
      "epoch 8; iter: 0; batch classifier loss: 0.373674; batch adversarial loss: 0.662081\n",
      "epoch 9; iter: 0; batch classifier loss: 0.361381; batch adversarial loss: 0.516570\n",
      "epoch 10; iter: 0; batch classifier loss: 0.494265; batch adversarial loss: 0.532299\n",
      "epoch 11; iter: 0; batch classifier loss: 0.387316; batch adversarial loss: 0.529021\n",
      "epoch 12; iter: 0; batch classifier loss: 0.613805; batch adversarial loss: 0.621575\n",
      "epoch 13; iter: 0; batch classifier loss: 0.566828; batch adversarial loss: 0.516661\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538746; batch adversarial loss: 0.478200\n",
      "epoch 15; iter: 0; batch classifier loss: 0.441874; batch adversarial loss: 0.539967\n",
      "epoch 16; iter: 0; batch classifier loss: 0.304232; batch adversarial loss: 0.516877\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225357; batch adversarial loss: 0.527413\n",
      "epoch 18; iter: 0; batch classifier loss: 0.216605; batch adversarial loss: 0.528974\n",
      "epoch 19; iter: 0; batch classifier loss: 0.194574; batch adversarial loss: 0.456388\n",
      "epoch 20; iter: 0; batch classifier loss: 0.181681; batch adversarial loss: 0.409890\n",
      "epoch 21; iter: 0; batch classifier loss: 0.187611; batch adversarial loss: 0.540960\n",
      "epoch 22; iter: 0; batch classifier loss: 0.243798; batch adversarial loss: 0.499601\n",
      "epoch 23; iter: 0; batch classifier loss: 0.161468; batch adversarial loss: 0.514221\n",
      "epoch 24; iter: 0; batch classifier loss: 0.191869; batch adversarial loss: 0.420234\n",
      "epoch 25; iter: 0; batch classifier loss: 0.270052; batch adversarial loss: 0.503453\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187312; batch adversarial loss: 0.444568\n",
      "epoch 27; iter: 0; batch classifier loss: 0.147110; batch adversarial loss: 0.402276\n",
      "epoch 28; iter: 0; batch classifier loss: 0.147995; batch adversarial loss: 0.421263\n",
      "epoch 29; iter: 0; batch classifier loss: 0.167972; batch adversarial loss: 0.517675\n",
      "epoch 30; iter: 0; batch classifier loss: 0.210441; batch adversarial loss: 0.417542\n",
      "epoch 31; iter: 0; batch classifier loss: 0.184732; batch adversarial loss: 0.444017\n",
      "epoch 32; iter: 0; batch classifier loss: 0.143251; batch adversarial loss: 0.410955\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128311; batch adversarial loss: 0.427001\n",
      "epoch 34; iter: 0; batch classifier loss: 0.188597; batch adversarial loss: 0.402420\n",
      "epoch 35; iter: 0; batch classifier loss: 0.133742; batch adversarial loss: 0.478434\n",
      "epoch 36; iter: 0; batch classifier loss: 0.130012; batch adversarial loss: 0.497016\n",
      "epoch 37; iter: 0; batch classifier loss: 0.193980; batch adversarial loss: 0.415473\n",
      "epoch 38; iter: 0; batch classifier loss: 0.177247; batch adversarial loss: 0.468097\n",
      "epoch 39; iter: 0; batch classifier loss: 0.153240; batch adversarial loss: 0.396907\n",
      "epoch 40; iter: 0; batch classifier loss: 0.157695; batch adversarial loss: 0.563340\n",
      "epoch 41; iter: 0; batch classifier loss: 0.164133; batch adversarial loss: 0.482751\n",
      "epoch 42; iter: 0; batch classifier loss: 0.156906; batch adversarial loss: 0.456418\n",
      "epoch 43; iter: 0; batch classifier loss: 0.142944; batch adversarial loss: 0.436064\n",
      "epoch 44; iter: 0; batch classifier loss: 0.165642; batch adversarial loss: 0.458132\n",
      "epoch 45; iter: 0; batch classifier loss: 0.158968; batch adversarial loss: 0.429192\n",
      "epoch 46; iter: 0; batch classifier loss: 0.223180; batch adversarial loss: 0.436958\n",
      "epoch 47; iter: 0; batch classifier loss: 0.135911; batch adversarial loss: 0.455128\n",
      "epoch 48; iter: 0; batch classifier loss: 0.200590; batch adversarial loss: 0.392242\n",
      "epoch 49; iter: 0; batch classifier loss: 0.201691; batch adversarial loss: 0.438207\n",
      "epoch 50; iter: 0; batch classifier loss: 0.165162; batch adversarial loss: 0.400883\n",
      "epoch 51; iter: 0; batch classifier loss: 0.203568; batch adversarial loss: 0.473711\n",
      "epoch 52; iter: 0; batch classifier loss: 0.197089; batch adversarial loss: 0.471305\n",
      "epoch 53; iter: 0; batch classifier loss: 0.166732; batch adversarial loss: 0.463911\n",
      "epoch 54; iter: 0; batch classifier loss: 0.180078; batch adversarial loss: 0.496875\n",
      "epoch 55; iter: 0; batch classifier loss: 0.237120; batch adversarial loss: 0.482993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.234826; batch adversarial loss: 0.457721\n",
      "epoch 57; iter: 0; batch classifier loss: 0.214699; batch adversarial loss: 0.472704\n",
      "epoch 58; iter: 0; batch classifier loss: 0.257072; batch adversarial loss: 0.507584\n",
      "epoch 59; iter: 0; batch classifier loss: 0.184203; batch adversarial loss: 0.412052\n",
      "epoch 60; iter: 0; batch classifier loss: 0.276939; batch adversarial loss: 0.493261\n",
      "epoch 61; iter: 0; batch classifier loss: 0.167170; batch adversarial loss: 0.458633\n",
      "epoch 62; iter: 0; batch classifier loss: 0.214497; batch adversarial loss: 0.482934\n",
      "epoch 63; iter: 0; batch classifier loss: 0.258505; batch adversarial loss: 0.411170\n",
      "epoch 64; iter: 0; batch classifier loss: 0.319766; batch adversarial loss: 0.446957\n",
      "epoch 65; iter: 0; batch classifier loss: 0.248604; batch adversarial loss: 0.494915\n",
      "epoch 66; iter: 0; batch classifier loss: 0.141238; batch adversarial loss: 0.458580\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091767; batch adversarial loss: 0.434208\n",
      "epoch 68; iter: 0; batch classifier loss: 0.100599; batch adversarial loss: 0.459218\n",
      "epoch 69; iter: 0; batch classifier loss: 0.127953; batch adversarial loss: 0.482726\n",
      "epoch 70; iter: 0; batch classifier loss: 0.158674; batch adversarial loss: 0.471103\n",
      "epoch 71; iter: 0; batch classifier loss: 0.233454; batch adversarial loss: 0.410681\n",
      "epoch 72; iter: 0; batch classifier loss: 0.149478; batch adversarial loss: 0.482091\n",
      "epoch 73; iter: 0; batch classifier loss: 0.176799; batch adversarial loss: 0.447680\n",
      "epoch 74; iter: 0; batch classifier loss: 0.154479; batch adversarial loss: 0.388171\n",
      "epoch 75; iter: 0; batch classifier loss: 0.159017; batch adversarial loss: 0.517182\n",
      "epoch 76; iter: 0; batch classifier loss: 0.217631; batch adversarial loss: 0.519338\n",
      "epoch 77; iter: 0; batch classifier loss: 0.155388; batch adversarial loss: 0.530931\n",
      "epoch 78; iter: 0; batch classifier loss: 0.189893; batch adversarial loss: 0.518758\n",
      "epoch 79; iter: 0; batch classifier loss: 0.124877; batch adversarial loss: 0.495064\n",
      "epoch 80; iter: 0; batch classifier loss: 0.164835; batch adversarial loss: 0.361838\n",
      "epoch 81; iter: 0; batch classifier loss: 0.118711; batch adversarial loss: 0.520748\n",
      "epoch 82; iter: 0; batch classifier loss: 0.204785; batch adversarial loss: 0.471175\n",
      "epoch 83; iter: 0; batch classifier loss: 0.198492; batch adversarial loss: 0.362979\n",
      "epoch 84; iter: 0; batch classifier loss: 0.181129; batch adversarial loss: 0.555184\n",
      "epoch 85; iter: 0; batch classifier loss: 0.099520; batch adversarial loss: 0.411224\n",
      "epoch 86; iter: 0; batch classifier loss: 0.269107; batch adversarial loss: 0.397807\n",
      "epoch 87; iter: 0; batch classifier loss: 0.204695; batch adversarial loss: 0.422554\n",
      "epoch 88; iter: 0; batch classifier loss: 0.185656; batch adversarial loss: 0.483110\n",
      "epoch 89; iter: 0; batch classifier loss: 0.100170; batch adversarial loss: 0.409484\n",
      "epoch 90; iter: 0; batch classifier loss: 0.127213; batch adversarial loss: 0.396989\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074063; batch adversarial loss: 0.456359\n",
      "epoch 92; iter: 0; batch classifier loss: 0.073465; batch adversarial loss: 0.557197\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059517; batch adversarial loss: 0.333412\n",
      "epoch 94; iter: 0; batch classifier loss: 0.090114; batch adversarial loss: 0.451352\n",
      "epoch 95; iter: 0; batch classifier loss: 0.112004; batch adversarial loss: 0.360800\n",
      "epoch 96; iter: 0; batch classifier loss: 0.074531; batch adversarial loss: 0.433246\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077641; batch adversarial loss: 0.398333\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051948; batch adversarial loss: 0.505994\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049764; batch adversarial loss: 0.439900\n",
      "epoch 100; iter: 0; batch classifier loss: 0.124909; batch adversarial loss: 0.466851\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050270; batch adversarial loss: 0.492584\n",
      "epoch 102; iter: 0; batch classifier loss: 0.096009; batch adversarial loss: 0.478443\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058045; batch adversarial loss: 0.511630\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060935; batch adversarial loss: 0.530478\n",
      "epoch 105; iter: 0; batch classifier loss: 0.104907; batch adversarial loss: 0.435034\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068378; batch adversarial loss: 0.503377\n",
      "epoch 107; iter: 0; batch classifier loss: 0.091623; batch adversarial loss: 0.533252\n",
      "epoch 108; iter: 0; batch classifier loss: 0.096608; batch adversarial loss: 0.485594\n",
      "epoch 109; iter: 0; batch classifier loss: 0.075730; batch adversarial loss: 0.370539\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066941; batch adversarial loss: 0.350166\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047933; batch adversarial loss: 0.469534\n",
      "epoch 112; iter: 0; batch classifier loss: 0.080598; batch adversarial loss: 0.540459\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053061; batch adversarial loss: 0.468657\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047246; batch adversarial loss: 0.349598\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049138; batch adversarial loss: 0.429214\n",
      "epoch 116; iter: 0; batch classifier loss: 0.074367; batch adversarial loss: 0.471636\n",
      "epoch 117; iter: 0; batch classifier loss: 0.098729; batch adversarial loss: 0.362306\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059189; batch adversarial loss: 0.472392\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042642; batch adversarial loss: 0.460519\n",
      "epoch 120; iter: 0; batch classifier loss: 0.080168; batch adversarial loss: 0.392449\n",
      "epoch 121; iter: 0; batch classifier loss: 0.059961; batch adversarial loss: 0.402071\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051084; batch adversarial loss: 0.450373\n",
      "epoch 123; iter: 0; batch classifier loss: 0.077778; batch adversarial loss: 0.422733\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059683; batch adversarial loss: 0.538786\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054466; batch adversarial loss: 0.428560\n",
      "epoch 126; iter: 0; batch classifier loss: 0.066136; batch adversarial loss: 0.457247\n",
      "epoch 127; iter: 0; batch classifier loss: 0.056157; batch adversarial loss: 0.412025\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039073; batch adversarial loss: 0.502832\n",
      "epoch 129; iter: 0; batch classifier loss: 0.066904; batch adversarial loss: 0.455023\n",
      "epoch 130; iter: 0; batch classifier loss: 0.079447; batch adversarial loss: 0.454375\n",
      "epoch 131; iter: 0; batch classifier loss: 0.053508; batch adversarial loss: 0.484357\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038871; batch adversarial loss: 0.571495\n",
      "epoch 133; iter: 0; batch classifier loss: 0.057835; batch adversarial loss: 0.497382\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022290; batch adversarial loss: 0.414797\n",
      "epoch 135; iter: 0; batch classifier loss: 0.058579; batch adversarial loss: 0.416100\n",
      "epoch 136; iter: 0; batch classifier loss: 0.069872; batch adversarial loss: 0.517504\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021269; batch adversarial loss: 0.470787\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049684; batch adversarial loss: 0.423134\n",
      "epoch 139; iter: 0; batch classifier loss: 0.055649; batch adversarial loss: 0.538891\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038243; batch adversarial loss: 0.464621\n",
      "epoch 141; iter: 0; batch classifier loss: 0.054988; batch adversarial loss: 0.414118\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028708; batch adversarial loss: 0.437791\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050590; batch adversarial loss: 0.382914\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033191; batch adversarial loss: 0.468312\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032862; batch adversarial loss: 0.487959\n",
      "epoch 146; iter: 0; batch classifier loss: 0.069908; batch adversarial loss: 0.449788\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034145; batch adversarial loss: 0.433819\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031878; batch adversarial loss: 0.451488\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056235; batch adversarial loss: 0.422000\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033324; batch adversarial loss: 0.405009\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040656; batch adversarial loss: 0.393571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.030120; batch adversarial loss: 0.461697\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028954; batch adversarial loss: 0.449563\n",
      "epoch 154; iter: 0; batch classifier loss: 0.064528; batch adversarial loss: 0.415913\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015748; batch adversarial loss: 0.503220\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040806; batch adversarial loss: 0.436729\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011096; batch adversarial loss: 0.550594\n",
      "epoch 158; iter: 0; batch classifier loss: 0.056082; batch adversarial loss: 0.388848\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031696; batch adversarial loss: 0.404535\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031095; batch adversarial loss: 0.434938\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031655; batch adversarial loss: 0.401279\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027554; batch adversarial loss: 0.547209\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040271; batch adversarial loss: 0.504094\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013077; batch adversarial loss: 0.619014\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026970; batch adversarial loss: 0.426570\n",
      "epoch 166; iter: 0; batch classifier loss: 0.054112; batch adversarial loss: 0.512666\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015904; batch adversarial loss: 0.515206\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011599; batch adversarial loss: 0.538174\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032985; batch adversarial loss: 0.505237\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013778; batch adversarial loss: 0.420030\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018943; batch adversarial loss: 0.469613\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025880; batch adversarial loss: 0.447199\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013513; batch adversarial loss: 0.390000\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014325; batch adversarial loss: 0.515066\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017657; batch adversarial loss: 0.448276\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041107; batch adversarial loss: 0.457692\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021649; batch adversarial loss: 0.476350\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017759; batch adversarial loss: 0.532824\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011743; batch adversarial loss: 0.467603\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031459; batch adversarial loss: 0.522338\n",
      "epoch 181; iter: 0; batch classifier loss: 0.080743; batch adversarial loss: 0.375819\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010245; batch adversarial loss: 0.472739\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012872; batch adversarial loss: 0.410952\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014828; batch adversarial loss: 0.451275\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014602; batch adversarial loss: 0.449091\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022240; batch adversarial loss: 0.455142\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010809; batch adversarial loss: 0.462524\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016778; batch adversarial loss: 0.518856\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027404; batch adversarial loss: 0.415722\n",
      "epoch 190; iter: 0; batch classifier loss: 0.003517; batch adversarial loss: 0.623064\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037731; batch adversarial loss: 0.394528\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020494; batch adversarial loss: 0.335246\n",
      "epoch 193; iter: 0; batch classifier loss: 0.049686; batch adversarial loss: 0.428543\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007366; batch adversarial loss: 0.396439\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013806; batch adversarial loss: 0.451293\n",
      "epoch 196; iter: 0; batch classifier loss: 0.036463; batch adversarial loss: 0.380716\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019991; batch adversarial loss: 0.474877\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019393; batch adversarial loss: 0.369781\n",
      "epoch 199; iter: 0; batch classifier loss: 0.043238; batch adversarial loss: 0.549072\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716172; batch adversarial loss: 0.773418\n",
      "epoch 1; iter: 0; batch classifier loss: 0.573749; batch adversarial loss: 0.715954\n",
      "epoch 2; iter: 0; batch classifier loss: 0.466866; batch adversarial loss: 0.629430\n",
      "epoch 3; iter: 0; batch classifier loss: 0.420423; batch adversarial loss: 0.607271\n",
      "epoch 4; iter: 0; batch classifier loss: 0.412734; batch adversarial loss: 0.603114\n",
      "epoch 5; iter: 0; batch classifier loss: 0.375253; batch adversarial loss: 0.592569\n",
      "epoch 6; iter: 0; batch classifier loss: 0.391288; batch adversarial loss: 0.530873\n",
      "epoch 7; iter: 0; batch classifier loss: 0.352613; batch adversarial loss: 0.564941\n",
      "epoch 8; iter: 0; batch classifier loss: 0.360391; batch adversarial loss: 0.565307\n",
      "epoch 9; iter: 0; batch classifier loss: 0.242099; batch adversarial loss: 0.570914\n",
      "epoch 10; iter: 0; batch classifier loss: 0.294873; batch adversarial loss: 0.475885\n",
      "epoch 11; iter: 0; batch classifier loss: 0.381132; batch adversarial loss: 0.500048\n",
      "epoch 12; iter: 0; batch classifier loss: 0.250629; batch adversarial loss: 0.483804\n",
      "epoch 13; iter: 0; batch classifier loss: 0.341914; batch adversarial loss: 0.485070\n",
      "epoch 14; iter: 0; batch classifier loss: 0.259168; batch adversarial loss: 0.477784\n",
      "epoch 15; iter: 0; batch classifier loss: 0.233530; batch adversarial loss: 0.585130\n",
      "epoch 16; iter: 0; batch classifier loss: 0.318434; batch adversarial loss: 0.491732\n",
      "epoch 17; iter: 0; batch classifier loss: 0.320435; batch adversarial loss: 0.492903\n",
      "epoch 18; iter: 0; batch classifier loss: 0.304643; batch adversarial loss: 0.472756\n",
      "epoch 19; iter: 0; batch classifier loss: 0.279777; batch adversarial loss: 0.483011\n",
      "epoch 20; iter: 0; batch classifier loss: 0.356176; batch adversarial loss: 0.541541\n",
      "epoch 21; iter: 0; batch classifier loss: 0.235910; batch adversarial loss: 0.498911\n",
      "epoch 22; iter: 0; batch classifier loss: 0.255769; batch adversarial loss: 0.485754\n",
      "epoch 23; iter: 0; batch classifier loss: 0.255331; batch adversarial loss: 0.505514\n",
      "epoch 24; iter: 0; batch classifier loss: 0.282859; batch adversarial loss: 0.538545\n",
      "epoch 25; iter: 0; batch classifier loss: 0.235470; batch adversarial loss: 0.438342\n",
      "epoch 26; iter: 0; batch classifier loss: 0.215221; batch adversarial loss: 0.485207\n",
      "epoch 27; iter: 0; batch classifier loss: 0.258346; batch adversarial loss: 0.569124\n",
      "epoch 28; iter: 0; batch classifier loss: 0.225700; batch adversarial loss: 0.477938\n",
      "epoch 29; iter: 0; batch classifier loss: 0.239650; batch adversarial loss: 0.421488\n",
      "epoch 30; iter: 0; batch classifier loss: 0.216792; batch adversarial loss: 0.542430\n",
      "epoch 31; iter: 0; batch classifier loss: 0.231271; batch adversarial loss: 0.488469\n",
      "epoch 32; iter: 0; batch classifier loss: 0.257919; batch adversarial loss: 0.358858\n",
      "epoch 33; iter: 0; batch classifier loss: 0.210093; batch adversarial loss: 0.478203\n",
      "epoch 34; iter: 0; batch classifier loss: 0.201795; batch adversarial loss: 0.437563\n",
      "epoch 35; iter: 0; batch classifier loss: 0.239480; batch adversarial loss: 0.458631\n",
      "epoch 36; iter: 0; batch classifier loss: 0.176357; batch adversarial loss: 0.426488\n",
      "epoch 37; iter: 0; batch classifier loss: 0.169056; batch adversarial loss: 0.478373\n",
      "epoch 38; iter: 0; batch classifier loss: 0.118947; batch adversarial loss: 0.487417\n",
      "epoch 39; iter: 0; batch classifier loss: 0.255735; batch adversarial loss: 0.409085\n",
      "epoch 40; iter: 0; batch classifier loss: 0.157976; batch adversarial loss: 0.445970\n",
      "epoch 41; iter: 0; batch classifier loss: 0.174266; batch adversarial loss: 0.482482\n",
      "epoch 42; iter: 0; batch classifier loss: 0.160233; batch adversarial loss: 0.410761\n",
      "epoch 43; iter: 0; batch classifier loss: 0.201717; batch adversarial loss: 0.423034\n",
      "epoch 44; iter: 0; batch classifier loss: 0.150782; batch adversarial loss: 0.496457\n",
      "epoch 45; iter: 0; batch classifier loss: 0.106712; batch adversarial loss: 0.539182\n",
      "epoch 46; iter: 0; batch classifier loss: 0.212764; batch adversarial loss: 0.462480\n",
      "epoch 47; iter: 0; batch classifier loss: 0.150514; batch adversarial loss: 0.419673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.137811; batch adversarial loss: 0.527637\n",
      "epoch 49; iter: 0; batch classifier loss: 0.103569; batch adversarial loss: 0.532033\n",
      "epoch 50; iter: 0; batch classifier loss: 0.100925; batch adversarial loss: 0.496560\n",
      "epoch 51; iter: 0; batch classifier loss: 0.153803; batch adversarial loss: 0.447669\n",
      "epoch 52; iter: 0; batch classifier loss: 0.102580; batch adversarial loss: 0.430272\n",
      "epoch 53; iter: 0; batch classifier loss: 0.128921; batch adversarial loss: 0.474883\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127980; batch adversarial loss: 0.445220\n",
      "epoch 55; iter: 0; batch classifier loss: 0.152136; batch adversarial loss: 0.412217\n",
      "epoch 56; iter: 0; batch classifier loss: 0.100962; batch adversarial loss: 0.415409\n",
      "epoch 57; iter: 0; batch classifier loss: 0.113730; batch adversarial loss: 0.490882\n",
      "epoch 58; iter: 0; batch classifier loss: 0.142181; batch adversarial loss: 0.446629\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105057; batch adversarial loss: 0.538743\n",
      "epoch 60; iter: 0; batch classifier loss: 0.124010; batch adversarial loss: 0.483065\n",
      "epoch 61; iter: 0; batch classifier loss: 0.066121; batch adversarial loss: 0.391974\n",
      "epoch 62; iter: 0; batch classifier loss: 0.128763; batch adversarial loss: 0.407180\n",
      "epoch 63; iter: 0; batch classifier loss: 0.114475; batch adversarial loss: 0.481702\n",
      "epoch 64; iter: 0; batch classifier loss: 0.079494; batch adversarial loss: 0.355413\n",
      "epoch 65; iter: 0; batch classifier loss: 0.112839; batch adversarial loss: 0.527663\n",
      "epoch 66; iter: 0; batch classifier loss: 0.118055; batch adversarial loss: 0.528366\n",
      "epoch 67; iter: 0; batch classifier loss: 0.126684; batch adversarial loss: 0.395285\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079359; batch adversarial loss: 0.518498\n",
      "epoch 69; iter: 0; batch classifier loss: 0.093460; batch adversarial loss: 0.396550\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103855; batch adversarial loss: 0.505598\n",
      "epoch 71; iter: 0; batch classifier loss: 0.136858; batch adversarial loss: 0.489574\n",
      "epoch 72; iter: 0; batch classifier loss: 0.117078; batch adversarial loss: 0.397787\n",
      "epoch 73; iter: 0; batch classifier loss: 0.129113; batch adversarial loss: 0.412695\n",
      "epoch 74; iter: 0; batch classifier loss: 0.110727; batch adversarial loss: 0.454793\n",
      "epoch 75; iter: 0; batch classifier loss: 0.054452; batch adversarial loss: 0.494526\n",
      "epoch 76; iter: 0; batch classifier loss: 0.087231; batch adversarial loss: 0.452844\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076517; batch adversarial loss: 0.400463\n",
      "epoch 78; iter: 0; batch classifier loss: 0.069992; batch adversarial loss: 0.481876\n",
      "epoch 79; iter: 0; batch classifier loss: 0.105335; batch adversarial loss: 0.485413\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053576; batch adversarial loss: 0.456577\n",
      "epoch 81; iter: 0; batch classifier loss: 0.114852; batch adversarial loss: 0.431279\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074607; batch adversarial loss: 0.374892\n",
      "epoch 83; iter: 0; batch classifier loss: 0.101144; batch adversarial loss: 0.396473\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103026; batch adversarial loss: 0.454620\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074940; batch adversarial loss: 0.445480\n",
      "epoch 86; iter: 0; batch classifier loss: 0.080066; batch adversarial loss: 0.485158\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066798; batch adversarial loss: 0.441881\n",
      "epoch 88; iter: 0; batch classifier loss: 0.095616; batch adversarial loss: 0.379224\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069765; batch adversarial loss: 0.466960\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051665; batch adversarial loss: 0.446163\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074064; batch adversarial loss: 0.423972\n",
      "epoch 92; iter: 0; batch classifier loss: 0.109038; batch adversarial loss: 0.456573\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080174; batch adversarial loss: 0.403320\n",
      "epoch 94; iter: 0; batch classifier loss: 0.034317; batch adversarial loss: 0.457776\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047566; batch adversarial loss: 0.519423\n",
      "epoch 96; iter: 0; batch classifier loss: 0.087222; batch adversarial loss: 0.468784\n",
      "epoch 97; iter: 0; batch classifier loss: 0.038070; batch adversarial loss: 0.408019\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042552; batch adversarial loss: 0.431764\n",
      "epoch 99; iter: 0; batch classifier loss: 0.070648; batch adversarial loss: 0.446117\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053135; batch adversarial loss: 0.393258\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075740; batch adversarial loss: 0.468054\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036040; batch adversarial loss: 0.474020\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042211; batch adversarial loss: 0.481306\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037133; batch adversarial loss: 0.626717\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046934; batch adversarial loss: 0.452966\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042578; batch adversarial loss: 0.458223\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028526; batch adversarial loss: 0.351440\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049446; batch adversarial loss: 0.374064\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027805; batch adversarial loss: 0.482861\n",
      "epoch 110; iter: 0; batch classifier loss: 0.089941; batch adversarial loss: 0.338792\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031358; batch adversarial loss: 0.505430\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031181; batch adversarial loss: 0.386576\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048551; batch adversarial loss: 0.423873\n",
      "epoch 114; iter: 0; batch classifier loss: 0.022963; batch adversarial loss: 0.502835\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028145; batch adversarial loss: 0.418880\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032492; batch adversarial loss: 0.424418\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034569; batch adversarial loss: 0.502997\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029013; batch adversarial loss: 0.411231\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027691; batch adversarial loss: 0.436091\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037672; batch adversarial loss: 0.420724\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038366; batch adversarial loss: 0.473137\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029800; batch adversarial loss: 0.430197\n",
      "epoch 123; iter: 0; batch classifier loss: 0.107833; batch adversarial loss: 0.395934\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030261; batch adversarial loss: 0.447560\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037778; batch adversarial loss: 0.427767\n",
      "epoch 126; iter: 0; batch classifier loss: 0.014139; batch adversarial loss: 0.596098\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030157; batch adversarial loss: 0.391988\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029372; batch adversarial loss: 0.415679\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023218; batch adversarial loss: 0.488401\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034559; batch adversarial loss: 0.412181\n",
      "epoch 131; iter: 0; batch classifier loss: 0.069033; batch adversarial loss: 0.440171\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043704; batch adversarial loss: 0.397318\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027203; batch adversarial loss: 0.528127\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042642; batch adversarial loss: 0.411658\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030494; batch adversarial loss: 0.499452\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021493; batch adversarial loss: 0.479726\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045371; batch adversarial loss: 0.409374\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046593; batch adversarial loss: 0.478491\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035937; batch adversarial loss: 0.429538\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029799; batch adversarial loss: 0.461799\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033434; batch adversarial loss: 0.514300\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016129; batch adversarial loss: 0.505323\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043379; batch adversarial loss: 0.493934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.051452; batch adversarial loss: 0.479236\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013416; batch adversarial loss: 0.452852\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029932; batch adversarial loss: 0.510165\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011929; batch adversarial loss: 0.383177\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015488; batch adversarial loss: 0.390017\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024584; batch adversarial loss: 0.413323\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030850; batch adversarial loss: 0.518831\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018636; batch adversarial loss: 0.485633\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010803; batch adversarial loss: 0.363651\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017506; batch adversarial loss: 0.461391\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021414; batch adversarial loss: 0.504881\n",
      "epoch 155; iter: 0; batch classifier loss: 0.050432; batch adversarial loss: 0.462631\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015912; batch adversarial loss: 0.495834\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019790; batch adversarial loss: 0.541561\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017972; batch adversarial loss: 0.445038\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037515; batch adversarial loss: 0.456536\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032266; batch adversarial loss: 0.444853\n",
      "epoch 161; iter: 0; batch classifier loss: 0.064189; batch adversarial loss: 0.471820\n",
      "epoch 162; iter: 0; batch classifier loss: 0.044382; batch adversarial loss: 0.403588\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025856; batch adversarial loss: 0.399577\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038776; batch adversarial loss: 0.452449\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039033; batch adversarial loss: 0.477952\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020527; batch adversarial loss: 0.402597\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029804; batch adversarial loss: 0.525726\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011042; batch adversarial loss: 0.439365\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027377; batch adversarial loss: 0.470558\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016344; batch adversarial loss: 0.493964\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024700; batch adversarial loss: 0.434197\n",
      "epoch 172; iter: 0; batch classifier loss: 0.057827; batch adversarial loss: 0.456421\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014231; batch adversarial loss: 0.440783\n",
      "epoch 174; iter: 0; batch classifier loss: 0.047401; batch adversarial loss: 0.466735\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022821; batch adversarial loss: 0.466562\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021157; batch adversarial loss: 0.489331\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019485; batch adversarial loss: 0.481049\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006046; batch adversarial loss: 0.441595\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035575; batch adversarial loss: 0.435591\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024762; batch adversarial loss: 0.443245\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017683; batch adversarial loss: 0.579630\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023988; batch adversarial loss: 0.490215\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012725; batch adversarial loss: 0.524795\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009881; batch adversarial loss: 0.425156\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023200; batch adversarial loss: 0.522027\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022216; batch adversarial loss: 0.390255\n",
      "epoch 187; iter: 0; batch classifier loss: 0.049114; batch adversarial loss: 0.427303\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005057; batch adversarial loss: 0.533340\n",
      "epoch 189; iter: 0; batch classifier loss: 0.002999; batch adversarial loss: 0.473072\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012118; batch adversarial loss: 0.454017\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023986; batch adversarial loss: 0.462235\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022540; batch adversarial loss: 0.386297\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007941; batch adversarial loss: 0.445410\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005628; batch adversarial loss: 0.468201\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033490; batch adversarial loss: 0.482680\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017246; batch adversarial loss: 0.434253\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005695; batch adversarial loss: 0.417406\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020826; batch adversarial loss: 0.412662\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017320; batch adversarial loss: 0.515970\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677177; batch adversarial loss: 0.614213\n",
      "epoch 1; iter: 0; batch classifier loss: 0.426120; batch adversarial loss: 0.624680\n",
      "epoch 2; iter: 0; batch classifier loss: 0.442016; batch adversarial loss: 0.596770\n",
      "epoch 3; iter: 0; batch classifier loss: 0.397868; batch adversarial loss: 0.569281\n",
      "epoch 4; iter: 0; batch classifier loss: 0.292935; batch adversarial loss: 0.531119\n",
      "epoch 5; iter: 0; batch classifier loss: 0.266133; batch adversarial loss: 0.506458\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315336; batch adversarial loss: 0.533075\n",
      "epoch 7; iter: 0; batch classifier loss: 0.259403; batch adversarial loss: 0.547518\n",
      "epoch 8; iter: 0; batch classifier loss: 0.314418; batch adversarial loss: 0.497595\n",
      "epoch 9; iter: 0; batch classifier loss: 0.354324; batch adversarial loss: 0.472242\n",
      "epoch 10; iter: 0; batch classifier loss: 0.253581; batch adversarial loss: 0.568421\n",
      "epoch 11; iter: 0; batch classifier loss: 0.175607; batch adversarial loss: 0.437901\n",
      "epoch 12; iter: 0; batch classifier loss: 0.195941; batch adversarial loss: 0.601089\n",
      "epoch 13; iter: 0; batch classifier loss: 0.225789; batch adversarial loss: 0.474270\n",
      "epoch 14; iter: 0; batch classifier loss: 0.248141; batch adversarial loss: 0.452783\n",
      "epoch 15; iter: 0; batch classifier loss: 0.186465; batch adversarial loss: 0.479020\n",
      "epoch 16; iter: 0; batch classifier loss: 0.218599; batch adversarial loss: 0.478935\n",
      "epoch 17; iter: 0; batch classifier loss: 0.202631; batch adversarial loss: 0.493711\n",
      "epoch 18; iter: 0; batch classifier loss: 0.208358; batch adversarial loss: 0.512716\n",
      "epoch 19; iter: 0; batch classifier loss: 0.243922; batch adversarial loss: 0.502045\n",
      "epoch 20; iter: 0; batch classifier loss: 0.228504; batch adversarial loss: 0.497129\n",
      "epoch 21; iter: 0; batch classifier loss: 0.345578; batch adversarial loss: 0.542298\n",
      "epoch 22; iter: 0; batch classifier loss: 0.342961; batch adversarial loss: 0.633207\n",
      "epoch 23; iter: 0; batch classifier loss: 0.293078; batch adversarial loss: 0.536566\n",
      "epoch 24; iter: 0; batch classifier loss: 0.334808; batch adversarial loss: 0.549125\n",
      "epoch 25; iter: 0; batch classifier loss: 0.369711; batch adversarial loss: 0.494100\n",
      "epoch 26; iter: 0; batch classifier loss: 0.218450; batch adversarial loss: 0.456849\n",
      "epoch 27; iter: 0; batch classifier loss: 0.160934; batch adversarial loss: 0.516419\n",
      "epoch 28; iter: 0; batch classifier loss: 0.161188; batch adversarial loss: 0.456951\n",
      "epoch 29; iter: 0; batch classifier loss: 0.151509; batch adversarial loss: 0.389574\n",
      "epoch 30; iter: 0; batch classifier loss: 0.170536; batch adversarial loss: 0.404432\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170949; batch adversarial loss: 0.454620\n",
      "epoch 32; iter: 0; batch classifier loss: 0.195431; batch adversarial loss: 0.458374\n",
      "epoch 33; iter: 0; batch classifier loss: 0.127973; batch adversarial loss: 0.445525\n",
      "epoch 34; iter: 0; batch classifier loss: 0.112853; batch adversarial loss: 0.499168\n",
      "epoch 35; iter: 0; batch classifier loss: 0.096685; batch adversarial loss: 0.505027\n",
      "epoch 36; iter: 0; batch classifier loss: 0.119178; batch adversarial loss: 0.534319\n",
      "epoch 37; iter: 0; batch classifier loss: 0.151240; batch adversarial loss: 0.490759\n",
      "epoch 38; iter: 0; batch classifier loss: 0.130972; batch adversarial loss: 0.480633\n",
      "epoch 39; iter: 0; batch classifier loss: 0.079341; batch adversarial loss: 0.415605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.120388; batch adversarial loss: 0.446569\n",
      "epoch 41; iter: 0; batch classifier loss: 0.128040; batch adversarial loss: 0.429723\n",
      "epoch 42; iter: 0; batch classifier loss: 0.101921; batch adversarial loss: 0.361203\n",
      "epoch 43; iter: 0; batch classifier loss: 0.109722; batch adversarial loss: 0.509148\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097327; batch adversarial loss: 0.570258\n",
      "epoch 45; iter: 0; batch classifier loss: 0.157382; batch adversarial loss: 0.419172\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131249; batch adversarial loss: 0.485543\n",
      "epoch 47; iter: 0; batch classifier loss: 0.093800; batch adversarial loss: 0.474119\n",
      "epoch 48; iter: 0; batch classifier loss: 0.142592; batch adversarial loss: 0.457013\n",
      "epoch 49; iter: 0; batch classifier loss: 0.128733; batch adversarial loss: 0.550427\n",
      "epoch 50; iter: 0; batch classifier loss: 0.147772; batch adversarial loss: 0.454426\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098646; batch adversarial loss: 0.439725\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111438; batch adversarial loss: 0.397817\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088260; batch adversarial loss: 0.506101\n",
      "epoch 54; iter: 0; batch classifier loss: 0.138934; batch adversarial loss: 0.384808\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101642; batch adversarial loss: 0.403357\n",
      "epoch 56; iter: 0; batch classifier loss: 0.152678; batch adversarial loss: 0.465954\n",
      "epoch 57; iter: 0; batch classifier loss: 0.100870; batch adversarial loss: 0.484654\n",
      "epoch 58; iter: 0; batch classifier loss: 0.096203; batch adversarial loss: 0.557842\n",
      "epoch 59; iter: 0; batch classifier loss: 0.157244; batch adversarial loss: 0.397385\n",
      "epoch 60; iter: 0; batch classifier loss: 0.128474; batch adversarial loss: 0.507417\n",
      "epoch 61; iter: 0; batch classifier loss: 0.136354; batch adversarial loss: 0.399278\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093949; batch adversarial loss: 0.578383\n",
      "epoch 63; iter: 0; batch classifier loss: 0.153854; batch adversarial loss: 0.448068\n",
      "epoch 64; iter: 0; batch classifier loss: 0.094648; batch adversarial loss: 0.421327\n",
      "epoch 65; iter: 0; batch classifier loss: 0.111997; batch adversarial loss: 0.504060\n",
      "epoch 66; iter: 0; batch classifier loss: 0.180278; batch adversarial loss: 0.520874\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171767; batch adversarial loss: 0.322840\n",
      "epoch 68; iter: 0; batch classifier loss: 0.138382; batch adversarial loss: 0.425558\n",
      "epoch 69; iter: 0; batch classifier loss: 0.160287; batch adversarial loss: 0.411449\n",
      "epoch 70; iter: 0; batch classifier loss: 0.114369; batch adversarial loss: 0.446509\n",
      "epoch 71; iter: 0; batch classifier loss: 0.144718; batch adversarial loss: 0.415884\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070485; batch adversarial loss: 0.495744\n",
      "epoch 73; iter: 0; batch classifier loss: 0.106232; batch adversarial loss: 0.528586\n",
      "epoch 74; iter: 0; batch classifier loss: 0.114837; batch adversarial loss: 0.538677\n",
      "epoch 75; iter: 0; batch classifier loss: 0.092610; batch adversarial loss: 0.508482\n",
      "epoch 76; iter: 0; batch classifier loss: 0.135872; batch adversarial loss: 0.457981\n",
      "epoch 77; iter: 0; batch classifier loss: 0.135524; batch adversarial loss: 0.410449\n",
      "epoch 78; iter: 0; batch classifier loss: 0.137156; batch adversarial loss: 0.513080\n",
      "epoch 79; iter: 0; batch classifier loss: 0.147610; batch adversarial loss: 0.492443\n",
      "epoch 80; iter: 0; batch classifier loss: 0.152868; batch adversarial loss: 0.506772\n",
      "epoch 81; iter: 0; batch classifier loss: 0.176569; batch adversarial loss: 0.458853\n",
      "epoch 82; iter: 0; batch classifier loss: 0.136394; batch adversarial loss: 0.444122\n",
      "epoch 83; iter: 0; batch classifier loss: 0.167742; batch adversarial loss: 0.425704\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077150; batch adversarial loss: 0.490426\n",
      "epoch 85; iter: 0; batch classifier loss: 0.119251; batch adversarial loss: 0.527919\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089926; batch adversarial loss: 0.583813\n",
      "epoch 87; iter: 0; batch classifier loss: 0.103131; batch adversarial loss: 0.438967\n",
      "epoch 88; iter: 0; batch classifier loss: 0.148060; batch adversarial loss: 0.446692\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087412; batch adversarial loss: 0.448093\n",
      "epoch 90; iter: 0; batch classifier loss: 0.117421; batch adversarial loss: 0.468142\n",
      "epoch 91; iter: 0; batch classifier loss: 0.158380; batch adversarial loss: 0.359835\n",
      "epoch 92; iter: 0; batch classifier loss: 0.166844; batch adversarial loss: 0.565907\n",
      "epoch 93; iter: 0; batch classifier loss: 0.109156; batch adversarial loss: 0.458818\n",
      "epoch 94; iter: 0; batch classifier loss: 0.088872; batch adversarial loss: 0.477331\n",
      "epoch 95; iter: 0; batch classifier loss: 0.097457; batch adversarial loss: 0.426653\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075517; batch adversarial loss: 0.458063\n",
      "epoch 97; iter: 0; batch classifier loss: 0.098617; batch adversarial loss: 0.396225\n",
      "epoch 98; iter: 0; batch classifier loss: 0.128303; batch adversarial loss: 0.543968\n",
      "epoch 99; iter: 0; batch classifier loss: 0.147336; batch adversarial loss: 0.491304\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074500; batch adversarial loss: 0.417747\n",
      "epoch 101; iter: 0; batch classifier loss: 0.132562; batch adversarial loss: 0.510110\n",
      "epoch 102; iter: 0; batch classifier loss: 0.077023; batch adversarial loss: 0.524440\n",
      "epoch 103; iter: 0; batch classifier loss: 0.111719; batch adversarial loss: 0.539129\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071470; batch adversarial loss: 0.494667\n",
      "epoch 105; iter: 0; batch classifier loss: 0.100742; batch adversarial loss: 0.437300\n",
      "epoch 106; iter: 0; batch classifier loss: 0.105955; batch adversarial loss: 0.485544\n",
      "epoch 107; iter: 0; batch classifier loss: 0.107916; batch adversarial loss: 0.410575\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049259; batch adversarial loss: 0.484645\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060203; batch adversarial loss: 0.372696\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059824; batch adversarial loss: 0.498409\n",
      "epoch 111; iter: 0; batch classifier loss: 0.072676; batch adversarial loss: 0.428542\n",
      "epoch 112; iter: 0; batch classifier loss: 0.079618; batch adversarial loss: 0.539622\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055044; batch adversarial loss: 0.395669\n",
      "epoch 114; iter: 0; batch classifier loss: 0.095519; batch adversarial loss: 0.520218\n",
      "epoch 115; iter: 0; batch classifier loss: 0.073105; batch adversarial loss: 0.494209\n",
      "epoch 116; iter: 0; batch classifier loss: 0.079677; batch adversarial loss: 0.385253\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041150; batch adversarial loss: 0.498872\n",
      "epoch 118; iter: 0; batch classifier loss: 0.077801; batch adversarial loss: 0.394531\n",
      "epoch 119; iter: 0; batch classifier loss: 0.069584; batch adversarial loss: 0.503956\n",
      "epoch 120; iter: 0; batch classifier loss: 0.063182; batch adversarial loss: 0.460610\n",
      "epoch 121; iter: 0; batch classifier loss: 0.100003; batch adversarial loss: 0.533704\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050972; batch adversarial loss: 0.484271\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064774; batch adversarial loss: 0.449943\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035893; batch adversarial loss: 0.453833\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062640; batch adversarial loss: 0.407490\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044922; batch adversarial loss: 0.516558\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053217; batch adversarial loss: 0.389327\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022915; batch adversarial loss: 0.528430\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027790; batch adversarial loss: 0.431617\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033341; batch adversarial loss: 0.430412\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029993; batch adversarial loss: 0.512961\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030304; batch adversarial loss: 0.474667\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046771; batch adversarial loss: 0.403831\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035261; batch adversarial loss: 0.383595\n",
      "epoch 135; iter: 0; batch classifier loss: 0.072005; batch adversarial loss: 0.560138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.043534; batch adversarial loss: 0.447290\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038786; batch adversarial loss: 0.461642\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014840; batch adversarial loss: 0.452468\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049903; batch adversarial loss: 0.452958\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047599; batch adversarial loss: 0.414323\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038519; batch adversarial loss: 0.447287\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043141; batch adversarial loss: 0.450620\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024960; batch adversarial loss: 0.453933\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032842; batch adversarial loss: 0.420693\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040402; batch adversarial loss: 0.528969\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024549; batch adversarial loss: 0.389133\n",
      "epoch 147; iter: 0; batch classifier loss: 0.045723; batch adversarial loss: 0.486623\n",
      "epoch 148; iter: 0; batch classifier loss: 0.052113; batch adversarial loss: 0.506587\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051636; batch adversarial loss: 0.450363\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044388; batch adversarial loss: 0.470616\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038367; batch adversarial loss: 0.467819\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030405; batch adversarial loss: 0.501067\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027739; batch adversarial loss: 0.476510\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040888; batch adversarial loss: 0.431144\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031140; batch adversarial loss: 0.493151\n",
      "epoch 156; iter: 0; batch classifier loss: 0.054028; batch adversarial loss: 0.554269\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018851; batch adversarial loss: 0.285844\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023063; batch adversarial loss: 0.383794\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034701; batch adversarial loss: 0.449706\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018270; batch adversarial loss: 0.467139\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028227; batch adversarial loss: 0.467241\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019042; batch adversarial loss: 0.467761\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026888; batch adversarial loss: 0.508336\n",
      "epoch 164; iter: 0; batch classifier loss: 0.007171; batch adversarial loss: 0.455370\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015950; batch adversarial loss: 0.497072\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015440; batch adversarial loss: 0.506856\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022222; batch adversarial loss: 0.418815\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037534; batch adversarial loss: 0.402074\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011678; batch adversarial loss: 0.536747\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031419; batch adversarial loss: 0.409521\n",
      "epoch 171; iter: 0; batch classifier loss: 0.041613; batch adversarial loss: 0.485800\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011610; batch adversarial loss: 0.486022\n",
      "epoch 173; iter: 0; batch classifier loss: 0.044586; batch adversarial loss: 0.471363\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012382; batch adversarial loss: 0.442864\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024792; batch adversarial loss: 0.430748\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032351; batch adversarial loss: 0.489746\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006711; batch adversarial loss: 0.466092\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021826; batch adversarial loss: 0.427982\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023210; batch adversarial loss: 0.477929\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024504; batch adversarial loss: 0.489529\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015188; batch adversarial loss: 0.510410\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008771; batch adversarial loss: 0.496524\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008707; batch adversarial loss: 0.520558\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014015; batch adversarial loss: 0.460096\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016124; batch adversarial loss: 0.395548\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021684; batch adversarial loss: 0.430658\n",
      "epoch 187; iter: 0; batch classifier loss: 0.061167; batch adversarial loss: 0.501247\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014034; batch adversarial loss: 0.467744\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014101; batch adversarial loss: 0.482979\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014695; batch adversarial loss: 0.447847\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016032; batch adversarial loss: 0.496361\n",
      "epoch 192; iter: 0; batch classifier loss: 0.052246; batch adversarial loss: 0.475027\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024924; batch adversarial loss: 0.480523\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023584; batch adversarial loss: 0.444045\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015670; batch adversarial loss: 0.316512\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017048; batch adversarial loss: 0.545142\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013596; batch adversarial loss: 0.453764\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012524; batch adversarial loss: 0.501208\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019992; batch adversarial loss: 0.491645\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687239; batch adversarial loss: 0.608759\n",
      "epoch 1; iter: 0; batch classifier loss: 0.435609; batch adversarial loss: 0.610546\n",
      "epoch 2; iter: 0; batch classifier loss: 0.447392; batch adversarial loss: 0.607114\n",
      "epoch 3; iter: 0; batch classifier loss: 0.346930; batch adversarial loss: 0.545613\n",
      "epoch 4; iter: 0; batch classifier loss: 0.283663; batch adversarial loss: 0.548785\n",
      "epoch 5; iter: 0; batch classifier loss: 0.330472; batch adversarial loss: 0.490548\n",
      "epoch 6; iter: 0; batch classifier loss: 0.296853; batch adversarial loss: 0.533600\n",
      "epoch 7; iter: 0; batch classifier loss: 0.208076; batch adversarial loss: 0.470918\n",
      "epoch 8; iter: 0; batch classifier loss: 0.275548; batch adversarial loss: 0.446089\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282807; batch adversarial loss: 0.505737\n",
      "epoch 10; iter: 0; batch classifier loss: 0.235392; batch adversarial loss: 0.470247\n",
      "epoch 11; iter: 0; batch classifier loss: 0.236709; batch adversarial loss: 0.527117\n",
      "epoch 12; iter: 0; batch classifier loss: 0.280907; batch adversarial loss: 0.509040\n",
      "epoch 13; iter: 0; batch classifier loss: 0.228785; batch adversarial loss: 0.544530\n",
      "epoch 14; iter: 0; batch classifier loss: 0.253235; batch adversarial loss: 0.534199\n",
      "epoch 15; iter: 0; batch classifier loss: 0.259811; batch adversarial loss: 0.517313\n",
      "epoch 16; iter: 0; batch classifier loss: 0.276612; batch adversarial loss: 0.493456\n",
      "epoch 17; iter: 0; batch classifier loss: 0.303595; batch adversarial loss: 0.492626\n",
      "epoch 18; iter: 0; batch classifier loss: 0.393602; batch adversarial loss: 0.616221\n",
      "epoch 19; iter: 0; batch classifier loss: 0.191069; batch adversarial loss: 0.455058\n",
      "epoch 20; iter: 0; batch classifier loss: 0.290562; batch adversarial loss: 0.432326\n",
      "epoch 21; iter: 0; batch classifier loss: 0.261595; batch adversarial loss: 0.502417\n",
      "epoch 22; iter: 0; batch classifier loss: 0.257074; batch adversarial loss: 0.475887\n",
      "epoch 23; iter: 0; batch classifier loss: 0.221295; batch adversarial loss: 0.464895\n",
      "epoch 24; iter: 0; batch classifier loss: 0.346152; batch adversarial loss: 0.580380\n",
      "epoch 25; iter: 0; batch classifier loss: 0.433120; batch adversarial loss: 0.519880\n",
      "epoch 26; iter: 0; batch classifier loss: 0.389603; batch adversarial loss: 0.438896\n",
      "epoch 27; iter: 0; batch classifier loss: 0.309092; batch adversarial loss: 0.553907\n",
      "epoch 28; iter: 0; batch classifier loss: 0.189107; batch adversarial loss: 0.510139\n",
      "epoch 29; iter: 0; batch classifier loss: 0.152779; batch adversarial loss: 0.451481\n",
      "epoch 30; iter: 0; batch classifier loss: 0.220244; batch adversarial loss: 0.420748\n",
      "epoch 31; iter: 0; batch classifier loss: 0.164972; batch adversarial loss: 0.399816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.105158; batch adversarial loss: 0.452220\n",
      "epoch 33; iter: 0; batch classifier loss: 0.084424; batch adversarial loss: 0.399083\n",
      "epoch 34; iter: 0; batch classifier loss: 0.146913; batch adversarial loss: 0.432734\n",
      "epoch 35; iter: 0; batch classifier loss: 0.136581; batch adversarial loss: 0.454889\n",
      "epoch 36; iter: 0; batch classifier loss: 0.093026; batch adversarial loss: 0.552938\n",
      "epoch 37; iter: 0; batch classifier loss: 0.129535; batch adversarial loss: 0.480928\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127525; batch adversarial loss: 0.520155\n",
      "epoch 39; iter: 0; batch classifier loss: 0.096870; batch adversarial loss: 0.430010\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091425; batch adversarial loss: 0.445114\n",
      "epoch 41; iter: 0; batch classifier loss: 0.149227; batch adversarial loss: 0.470466\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146186; batch adversarial loss: 0.431036\n",
      "epoch 43; iter: 0; batch classifier loss: 0.123893; batch adversarial loss: 0.391798\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119123; batch adversarial loss: 0.456358\n",
      "epoch 45; iter: 0; batch classifier loss: 0.118368; batch adversarial loss: 0.516006\n",
      "epoch 46; iter: 0; batch classifier loss: 0.097775; batch adversarial loss: 0.479993\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119184; batch adversarial loss: 0.419405\n",
      "epoch 48; iter: 0; batch classifier loss: 0.136240; batch adversarial loss: 0.363314\n",
      "epoch 49; iter: 0; batch classifier loss: 0.150383; batch adversarial loss: 0.407530\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101824; batch adversarial loss: 0.458080\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077585; batch adversarial loss: 0.557123\n",
      "epoch 52; iter: 0; batch classifier loss: 0.133520; batch adversarial loss: 0.488600\n",
      "epoch 53; iter: 0; batch classifier loss: 0.085536; batch adversarial loss: 0.449003\n",
      "epoch 54; iter: 0; batch classifier loss: 0.104964; batch adversarial loss: 0.467824\n",
      "epoch 55; iter: 0; batch classifier loss: 0.138949; batch adversarial loss: 0.439653\n",
      "epoch 56; iter: 0; batch classifier loss: 0.093225; batch adversarial loss: 0.512000\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095028; batch adversarial loss: 0.566133\n",
      "epoch 58; iter: 0; batch classifier loss: 0.076911; batch adversarial loss: 0.429618\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087465; batch adversarial loss: 0.456433\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115476; batch adversarial loss: 0.420289\n",
      "epoch 61; iter: 0; batch classifier loss: 0.119962; batch adversarial loss: 0.418229\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081839; batch adversarial loss: 0.504408\n",
      "epoch 63; iter: 0; batch classifier loss: 0.050757; batch adversarial loss: 0.499906\n",
      "epoch 64; iter: 0; batch classifier loss: 0.102284; batch adversarial loss: 0.443063\n",
      "epoch 65; iter: 0; batch classifier loss: 0.099711; batch adversarial loss: 0.426597\n",
      "epoch 66; iter: 0; batch classifier loss: 0.123452; batch adversarial loss: 0.423978\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096908; batch adversarial loss: 0.450742\n",
      "epoch 68; iter: 0; batch classifier loss: 0.106770; batch adversarial loss: 0.447343\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071852; batch adversarial loss: 0.463996\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095796; batch adversarial loss: 0.509377\n",
      "epoch 71; iter: 0; batch classifier loss: 0.120770; batch adversarial loss: 0.480654\n",
      "epoch 72; iter: 0; batch classifier loss: 0.103415; batch adversarial loss: 0.483739\n",
      "epoch 73; iter: 0; batch classifier loss: 0.141426; batch adversarial loss: 0.396046\n",
      "epoch 74; iter: 0; batch classifier loss: 0.083817; batch adversarial loss: 0.412416\n",
      "epoch 75; iter: 0; batch classifier loss: 0.185767; batch adversarial loss: 0.581037\n",
      "epoch 76; iter: 0; batch classifier loss: 0.111270; batch adversarial loss: 0.558829\n",
      "epoch 77; iter: 0; batch classifier loss: 0.133018; batch adversarial loss: 0.394275\n",
      "epoch 78; iter: 0; batch classifier loss: 0.136352; batch adversarial loss: 0.512414\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074387; batch adversarial loss: 0.511422\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076819; batch adversarial loss: 0.547582\n",
      "epoch 81; iter: 0; batch classifier loss: 0.093886; batch adversarial loss: 0.410522\n",
      "epoch 82; iter: 0; batch classifier loss: 0.106281; batch adversarial loss: 0.399495\n",
      "epoch 83; iter: 0; batch classifier loss: 0.087879; batch adversarial loss: 0.491752\n",
      "epoch 84; iter: 0; batch classifier loss: 0.102601; batch adversarial loss: 0.430880\n",
      "epoch 85; iter: 0; batch classifier loss: 0.139646; batch adversarial loss: 0.413751\n",
      "epoch 86; iter: 0; batch classifier loss: 0.127350; batch adversarial loss: 0.433855\n",
      "epoch 87; iter: 0; batch classifier loss: 0.115866; batch adversarial loss: 0.406777\n",
      "epoch 88; iter: 0; batch classifier loss: 0.085649; batch adversarial loss: 0.434292\n",
      "epoch 89; iter: 0; batch classifier loss: 0.147055; batch adversarial loss: 0.333436\n",
      "epoch 90; iter: 0; batch classifier loss: 0.096865; batch adversarial loss: 0.448837\n",
      "epoch 91; iter: 0; batch classifier loss: 0.095331; batch adversarial loss: 0.405897\n",
      "epoch 92; iter: 0; batch classifier loss: 0.084005; batch adversarial loss: 0.419011\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060024; batch adversarial loss: 0.436064\n",
      "epoch 94; iter: 0; batch classifier loss: 0.084756; batch adversarial loss: 0.435813\n",
      "epoch 95; iter: 0; batch classifier loss: 0.122979; batch adversarial loss: 0.397641\n",
      "epoch 96; iter: 0; batch classifier loss: 0.146740; batch adversarial loss: 0.448356\n",
      "epoch 97; iter: 0; batch classifier loss: 0.116382; batch adversarial loss: 0.381949\n",
      "epoch 98; iter: 0; batch classifier loss: 0.147172; batch adversarial loss: 0.485922\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048752; batch adversarial loss: 0.478655\n",
      "epoch 100; iter: 0; batch classifier loss: 0.108426; batch adversarial loss: 0.431363\n",
      "epoch 101; iter: 0; batch classifier loss: 0.172244; batch adversarial loss: 0.429426\n",
      "epoch 102; iter: 0; batch classifier loss: 0.133735; batch adversarial loss: 0.403512\n",
      "epoch 103; iter: 0; batch classifier loss: 0.070489; batch adversarial loss: 0.406480\n",
      "epoch 104; iter: 0; batch classifier loss: 0.040267; batch adversarial loss: 0.576907\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084998; batch adversarial loss: 0.515006\n",
      "epoch 106; iter: 0; batch classifier loss: 0.123911; batch adversarial loss: 0.500041\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049190; batch adversarial loss: 0.485657\n",
      "epoch 108; iter: 0; batch classifier loss: 0.066155; batch adversarial loss: 0.429938\n",
      "epoch 109; iter: 0; batch classifier loss: 0.105790; batch adversarial loss: 0.479197\n",
      "epoch 110; iter: 0; batch classifier loss: 0.071056; batch adversarial loss: 0.434818\n",
      "epoch 111; iter: 0; batch classifier loss: 0.096508; batch adversarial loss: 0.394239\n",
      "epoch 112; iter: 0; batch classifier loss: 0.084571; batch adversarial loss: 0.452700\n",
      "epoch 113; iter: 0; batch classifier loss: 0.113232; batch adversarial loss: 0.375367\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053719; batch adversarial loss: 0.348428\n",
      "epoch 115; iter: 0; batch classifier loss: 0.110410; batch adversarial loss: 0.489507\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046629; batch adversarial loss: 0.538858\n",
      "epoch 117; iter: 0; batch classifier loss: 0.086434; batch adversarial loss: 0.476700\n",
      "epoch 118; iter: 0; batch classifier loss: 0.084810; batch adversarial loss: 0.452093\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070044; batch adversarial loss: 0.410791\n",
      "epoch 120; iter: 0; batch classifier loss: 0.021282; batch adversarial loss: 0.458315\n",
      "epoch 121; iter: 0; batch classifier loss: 0.107240; batch adversarial loss: 0.472856\n",
      "epoch 122; iter: 0; batch classifier loss: 0.085339; batch adversarial loss: 0.402346\n",
      "epoch 123; iter: 0; batch classifier loss: 0.070054; batch adversarial loss: 0.516611\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054338; batch adversarial loss: 0.435722\n",
      "epoch 125; iter: 0; batch classifier loss: 0.100045; batch adversarial loss: 0.458644\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030148; batch adversarial loss: 0.456498\n",
      "epoch 127; iter: 0; batch classifier loss: 0.146268; batch adversarial loss: 0.437717\n",
      "epoch 128; iter: 0; batch classifier loss: 0.069771; batch adversarial loss: 0.487269\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043723; batch adversarial loss: 0.415015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.049683; batch adversarial loss: 0.470344\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038012; batch adversarial loss: 0.360275\n",
      "epoch 132; iter: 0; batch classifier loss: 0.073304; batch adversarial loss: 0.407672\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060378; batch adversarial loss: 0.529794\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020460; batch adversarial loss: 0.417984\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034994; batch adversarial loss: 0.476602\n",
      "epoch 136; iter: 0; batch classifier loss: 0.065775; batch adversarial loss: 0.442857\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044551; batch adversarial loss: 0.429766\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023635; batch adversarial loss: 0.543645\n",
      "epoch 139; iter: 0; batch classifier loss: 0.057897; batch adversarial loss: 0.500664\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047159; batch adversarial loss: 0.545175\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030538; batch adversarial loss: 0.529644\n",
      "epoch 142; iter: 0; batch classifier loss: 0.062022; batch adversarial loss: 0.320583\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043283; batch adversarial loss: 0.540863\n",
      "epoch 144; iter: 0; batch classifier loss: 0.073087; batch adversarial loss: 0.419023\n",
      "epoch 145; iter: 0; batch classifier loss: 0.114761; batch adversarial loss: 0.458477\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039789; batch adversarial loss: 0.410282\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013800; batch adversarial loss: 0.338994\n",
      "epoch 148; iter: 0; batch classifier loss: 0.060353; batch adversarial loss: 0.446820\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042469; batch adversarial loss: 0.478778\n",
      "epoch 150; iter: 0; batch classifier loss: 0.051751; batch adversarial loss: 0.399762\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040324; batch adversarial loss: 0.445644\n",
      "epoch 152; iter: 0; batch classifier loss: 0.055710; batch adversarial loss: 0.409569\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014914; batch adversarial loss: 0.524930\n",
      "epoch 154; iter: 0; batch classifier loss: 0.073861; batch adversarial loss: 0.473596\n",
      "epoch 155; iter: 0; batch classifier loss: 0.047528; batch adversarial loss: 0.540405\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042936; batch adversarial loss: 0.418656\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025127; batch adversarial loss: 0.477280\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031786; batch adversarial loss: 0.452881\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036836; batch adversarial loss: 0.406858\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034299; batch adversarial loss: 0.474559\n",
      "epoch 161; iter: 0; batch classifier loss: 0.041554; batch adversarial loss: 0.473718\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038682; batch adversarial loss: 0.447545\n",
      "epoch 163; iter: 0; batch classifier loss: 0.051615; batch adversarial loss: 0.505175\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033506; batch adversarial loss: 0.429247\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036268; batch adversarial loss: 0.522884\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026448; batch adversarial loss: 0.488291\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018468; batch adversarial loss: 0.433698\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040603; batch adversarial loss: 0.465496\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021761; batch adversarial loss: 0.448017\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020863; batch adversarial loss: 0.428064\n",
      "epoch 171; iter: 0; batch classifier loss: 0.044168; batch adversarial loss: 0.400423\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030206; batch adversarial loss: 0.364095\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033191; batch adversarial loss: 0.471126\n",
      "epoch 174; iter: 0; batch classifier loss: 0.060768; batch adversarial loss: 0.401624\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039591; batch adversarial loss: 0.514424\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031952; batch adversarial loss: 0.420831\n",
      "epoch 177; iter: 0; batch classifier loss: 0.040835; batch adversarial loss: 0.473525\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035187; batch adversarial loss: 0.383396\n",
      "epoch 179; iter: 0; batch classifier loss: 0.058789; batch adversarial loss: 0.473127\n",
      "epoch 180; iter: 0; batch classifier loss: 0.054851; batch adversarial loss: 0.471904\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022890; batch adversarial loss: 0.525607\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033626; batch adversarial loss: 0.459488\n",
      "epoch 183; iter: 0; batch classifier loss: 0.060449; batch adversarial loss: 0.454542\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022949; batch adversarial loss: 0.372859\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033321; batch adversarial loss: 0.437390\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041073; batch adversarial loss: 0.383612\n",
      "epoch 187; iter: 0; batch classifier loss: 0.065227; batch adversarial loss: 0.440604\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026759; batch adversarial loss: 0.497362\n",
      "epoch 189; iter: 0; batch classifier loss: 0.052538; batch adversarial loss: 0.429737\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026209; batch adversarial loss: 0.374180\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032355; batch adversarial loss: 0.435293\n",
      "epoch 192; iter: 0; batch classifier loss: 0.063063; batch adversarial loss: 0.387255\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013916; batch adversarial loss: 0.404078\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016164; batch adversarial loss: 0.405161\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008134; batch adversarial loss: 0.463087\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019540; batch adversarial loss: 0.539113\n",
      "epoch 197; iter: 0; batch classifier loss: 0.036549; batch adversarial loss: 0.356518\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013074; batch adversarial loss: 0.501093\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023614; batch adversarial loss: 0.467800\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676579; batch adversarial loss: 0.846489\n",
      "epoch 1; iter: 0; batch classifier loss: 0.512807; batch adversarial loss: 0.844731\n",
      "epoch 2; iter: 0; batch classifier loss: 0.530287; batch adversarial loss: 0.801737\n",
      "epoch 3; iter: 0; batch classifier loss: 0.676177; batch adversarial loss: 0.751487\n",
      "epoch 4; iter: 0; batch classifier loss: 0.708843; batch adversarial loss: 0.680326\n",
      "epoch 5; iter: 0; batch classifier loss: 0.668755; batch adversarial loss: 0.644592\n",
      "epoch 6; iter: 0; batch classifier loss: 0.428298; batch adversarial loss: 0.581011\n",
      "epoch 7; iter: 0; batch classifier loss: 0.387976; batch adversarial loss: 0.551343\n",
      "epoch 8; iter: 0; batch classifier loss: 0.316278; batch adversarial loss: 0.558120\n",
      "epoch 9; iter: 0; batch classifier loss: 0.309341; batch adversarial loss: 0.542403\n",
      "epoch 10; iter: 0; batch classifier loss: 0.244908; batch adversarial loss: 0.531013\n",
      "epoch 11; iter: 0; batch classifier loss: 0.265933; batch adversarial loss: 0.517997\n",
      "epoch 12; iter: 0; batch classifier loss: 0.239347; batch adversarial loss: 0.505899\n",
      "epoch 13; iter: 0; batch classifier loss: 0.201826; batch adversarial loss: 0.484117\n",
      "epoch 14; iter: 0; batch classifier loss: 0.234338; batch adversarial loss: 0.496531\n",
      "epoch 15; iter: 0; batch classifier loss: 0.174636; batch adversarial loss: 0.452316\n",
      "epoch 16; iter: 0; batch classifier loss: 0.240567; batch adversarial loss: 0.444757\n",
      "epoch 17; iter: 0; batch classifier loss: 0.218216; batch adversarial loss: 0.458021\n",
      "epoch 18; iter: 0; batch classifier loss: 0.151933; batch adversarial loss: 0.431006\n",
      "epoch 19; iter: 0; batch classifier loss: 0.169494; batch adversarial loss: 0.446948\n",
      "epoch 20; iter: 0; batch classifier loss: 0.172681; batch adversarial loss: 0.511185\n",
      "epoch 21; iter: 0; batch classifier loss: 0.103170; batch adversarial loss: 0.461569\n",
      "epoch 22; iter: 0; batch classifier loss: 0.149704; batch adversarial loss: 0.495671\n",
      "epoch 23; iter: 0; batch classifier loss: 0.156561; batch adversarial loss: 0.498418\n",
      "epoch 24; iter: 0; batch classifier loss: 0.089916; batch adversarial loss: 0.483232\n",
      "epoch 25; iter: 0; batch classifier loss: 0.135483; batch adversarial loss: 0.390367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.076203; batch adversarial loss: 0.496548\n",
      "epoch 27; iter: 0; batch classifier loss: 0.138358; batch adversarial loss: 0.531732\n",
      "epoch 28; iter: 0; batch classifier loss: 0.155015; batch adversarial loss: 0.425300\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180282; batch adversarial loss: 0.412487\n",
      "epoch 30; iter: 0; batch classifier loss: 0.079143; batch adversarial loss: 0.571402\n",
      "epoch 31; iter: 0; batch classifier loss: 0.126685; batch adversarial loss: 0.447335\n",
      "epoch 32; iter: 0; batch classifier loss: 0.093414; batch adversarial loss: 0.463887\n",
      "epoch 33; iter: 0; batch classifier loss: 0.098251; batch adversarial loss: 0.449122\n",
      "epoch 34; iter: 0; batch classifier loss: 0.126993; batch adversarial loss: 0.458922\n",
      "epoch 35; iter: 0; batch classifier loss: 0.110736; batch adversarial loss: 0.419552\n",
      "epoch 36; iter: 0; batch classifier loss: 0.111543; batch adversarial loss: 0.471544\n",
      "epoch 37; iter: 0; batch classifier loss: 0.104733; batch adversarial loss: 0.505263\n",
      "epoch 38; iter: 0; batch classifier loss: 0.064246; batch adversarial loss: 0.457117\n",
      "epoch 39; iter: 0; batch classifier loss: 0.145183; batch adversarial loss: 0.451757\n",
      "epoch 40; iter: 0; batch classifier loss: 0.106181; batch adversarial loss: 0.468769\n",
      "epoch 41; iter: 0; batch classifier loss: 0.136531; batch adversarial loss: 0.442337\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088180; batch adversarial loss: 0.394813\n",
      "epoch 43; iter: 0; batch classifier loss: 0.155095; batch adversarial loss: 0.481714\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123150; batch adversarial loss: 0.407274\n",
      "epoch 45; iter: 0; batch classifier loss: 0.060652; batch adversarial loss: 0.361130\n",
      "epoch 46; iter: 0; batch classifier loss: 0.128348; batch adversarial loss: 0.558569\n",
      "epoch 47; iter: 0; batch classifier loss: 0.083118; batch adversarial loss: 0.514459\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081038; batch adversarial loss: 0.395761\n",
      "epoch 49; iter: 0; batch classifier loss: 0.081447; batch adversarial loss: 0.455111\n",
      "epoch 50; iter: 0; batch classifier loss: 0.053379; batch adversarial loss: 0.442564\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081028; batch adversarial loss: 0.411613\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082823; batch adversarial loss: 0.387699\n",
      "epoch 53; iter: 0; batch classifier loss: 0.075963; batch adversarial loss: 0.418376\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079385; batch adversarial loss: 0.461686\n",
      "epoch 55; iter: 0; batch classifier loss: 0.051640; batch adversarial loss: 0.476752\n",
      "epoch 56; iter: 0; batch classifier loss: 0.078304; batch adversarial loss: 0.412523\n",
      "epoch 57; iter: 0; batch classifier loss: 0.051638; batch adversarial loss: 0.461705\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072640; batch adversarial loss: 0.380385\n",
      "epoch 59; iter: 0; batch classifier loss: 0.060408; batch adversarial loss: 0.367386\n",
      "epoch 60; iter: 0; batch classifier loss: 0.046098; batch adversarial loss: 0.466576\n",
      "epoch 61; iter: 0; batch classifier loss: 0.089866; batch adversarial loss: 0.512833\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087390; batch adversarial loss: 0.557254\n",
      "epoch 63; iter: 0; batch classifier loss: 0.062254; batch adversarial loss: 0.409797\n",
      "epoch 64; iter: 0; batch classifier loss: 0.043434; batch adversarial loss: 0.489828\n",
      "epoch 65; iter: 0; batch classifier loss: 0.050134; batch adversarial loss: 0.460560\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066786; batch adversarial loss: 0.474272\n",
      "epoch 67; iter: 0; batch classifier loss: 0.045897; batch adversarial loss: 0.488901\n",
      "epoch 68; iter: 0; batch classifier loss: 0.024823; batch adversarial loss: 0.485491\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064246; batch adversarial loss: 0.423243\n",
      "epoch 70; iter: 0; batch classifier loss: 0.047898; batch adversarial loss: 0.504008\n",
      "epoch 71; iter: 0; batch classifier loss: 0.034758; batch adversarial loss: 0.437324\n",
      "epoch 72; iter: 0; batch classifier loss: 0.051566; batch adversarial loss: 0.402938\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065868; batch adversarial loss: 0.415616\n",
      "epoch 74; iter: 0; batch classifier loss: 0.059700; batch adversarial loss: 0.502783\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073507; batch adversarial loss: 0.388578\n",
      "epoch 76; iter: 0; batch classifier loss: 0.020753; batch adversarial loss: 0.395217\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108691; batch adversarial loss: 0.408657\n",
      "epoch 78; iter: 0; batch classifier loss: 0.091286; batch adversarial loss: 0.399251\n",
      "epoch 79; iter: 0; batch classifier loss: 0.059532; batch adversarial loss: 0.491965\n",
      "epoch 80; iter: 0; batch classifier loss: 0.041591; batch adversarial loss: 0.445375\n",
      "epoch 81; iter: 0; batch classifier loss: 0.051784; batch adversarial loss: 0.382189\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056523; batch adversarial loss: 0.509801\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068869; batch adversarial loss: 0.359919\n",
      "epoch 84; iter: 0; batch classifier loss: 0.050405; batch adversarial loss: 0.505824\n",
      "epoch 85; iter: 0; batch classifier loss: 0.016386; batch adversarial loss: 0.485718\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052877; batch adversarial loss: 0.485263\n",
      "epoch 87; iter: 0; batch classifier loss: 0.031704; batch adversarial loss: 0.576037\n",
      "epoch 88; iter: 0; batch classifier loss: 0.068825; batch adversarial loss: 0.452426\n",
      "epoch 89; iter: 0; batch classifier loss: 0.043328; batch adversarial loss: 0.391428\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067947; batch adversarial loss: 0.409370\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057004; batch adversarial loss: 0.424586\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071103; batch adversarial loss: 0.522115\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061407; batch adversarial loss: 0.558852\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038518; batch adversarial loss: 0.409942\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040290; batch adversarial loss: 0.465488\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045981; batch adversarial loss: 0.468698\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057468; batch adversarial loss: 0.391427\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053328; batch adversarial loss: 0.539676\n",
      "epoch 99; iter: 0; batch classifier loss: 0.033861; batch adversarial loss: 0.497600\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047770; batch adversarial loss: 0.535907\n",
      "epoch 101; iter: 0; batch classifier loss: 0.015359; batch adversarial loss: 0.387275\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054222; batch adversarial loss: 0.439778\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038779; batch adversarial loss: 0.434045\n",
      "epoch 104; iter: 0; batch classifier loss: 0.068443; batch adversarial loss: 0.544225\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043145; batch adversarial loss: 0.419768\n",
      "epoch 106; iter: 0; batch classifier loss: 0.095646; batch adversarial loss: 0.440488\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047925; batch adversarial loss: 0.421334\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060605; batch adversarial loss: 0.434589\n",
      "epoch 109; iter: 0; batch classifier loss: 0.031535; batch adversarial loss: 0.499234\n",
      "epoch 110; iter: 0; batch classifier loss: 0.019147; batch adversarial loss: 0.477853\n",
      "epoch 111; iter: 0; batch classifier loss: 0.073166; batch adversarial loss: 0.479407\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038834; batch adversarial loss: 0.486725\n",
      "epoch 113; iter: 0; batch classifier loss: 0.015359; batch adversarial loss: 0.447502\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033119; batch adversarial loss: 0.450376\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042023; batch adversarial loss: 0.465479\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028505; batch adversarial loss: 0.474996\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050606; batch adversarial loss: 0.485751\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050014; batch adversarial loss: 0.505801\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042256; batch adversarial loss: 0.415095\n",
      "epoch 120; iter: 0; batch classifier loss: 0.017127; batch adversarial loss: 0.401675\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033879; batch adversarial loss: 0.438758\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024064; batch adversarial loss: 0.530931\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042097; batch adversarial loss: 0.441166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.037603; batch adversarial loss: 0.464973\n",
      "epoch 125; iter: 0; batch classifier loss: 0.069905; batch adversarial loss: 0.361623\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048121; batch adversarial loss: 0.403929\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042917; batch adversarial loss: 0.447632\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023608; batch adversarial loss: 0.410635\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050956; batch adversarial loss: 0.533530\n",
      "epoch 130; iter: 0; batch classifier loss: 0.066581; batch adversarial loss: 0.414511\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040257; batch adversarial loss: 0.452896\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027762; batch adversarial loss: 0.404359\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028841; batch adversarial loss: 0.436483\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030046; batch adversarial loss: 0.447266\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042036; batch adversarial loss: 0.440289\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026290; batch adversarial loss: 0.511036\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054286; batch adversarial loss: 0.425878\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044381; batch adversarial loss: 0.377225\n",
      "epoch 139; iter: 0; batch classifier loss: 0.068777; batch adversarial loss: 0.489922\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041115; batch adversarial loss: 0.419351\n",
      "epoch 141; iter: 0; batch classifier loss: 0.054402; batch adversarial loss: 0.448200\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028285; batch adversarial loss: 0.401603\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040862; batch adversarial loss: 0.471515\n",
      "epoch 144; iter: 0; batch classifier loss: 0.043547; batch adversarial loss: 0.519540\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013022; batch adversarial loss: 0.453272\n",
      "epoch 146; iter: 0; batch classifier loss: 0.043771; batch adversarial loss: 0.508482\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029449; batch adversarial loss: 0.423844\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020452; batch adversarial loss: 0.439755\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044145; batch adversarial loss: 0.421060\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030022; batch adversarial loss: 0.380937\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021204; batch adversarial loss: 0.356302\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014307; batch adversarial loss: 0.365204\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016603; batch adversarial loss: 0.420875\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012698; batch adversarial loss: 0.413954\n",
      "epoch 155; iter: 0; batch classifier loss: 0.062537; batch adversarial loss: 0.462839\n",
      "epoch 156; iter: 0; batch classifier loss: 0.069388; batch adversarial loss: 0.466882\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032801; batch adversarial loss: 0.430566\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033601; batch adversarial loss: 0.509481\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043949; batch adversarial loss: 0.351288\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014344; batch adversarial loss: 0.454774\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022541; batch adversarial loss: 0.410571\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043785; batch adversarial loss: 0.451729\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020189; batch adversarial loss: 0.492944\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012396; batch adversarial loss: 0.470346\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030446; batch adversarial loss: 0.538550\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035857; batch adversarial loss: 0.505848\n",
      "epoch 167; iter: 0; batch classifier loss: 0.058105; batch adversarial loss: 0.395503\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023017; batch adversarial loss: 0.482063\n",
      "epoch 169; iter: 0; batch classifier loss: 0.051587; batch adversarial loss: 0.524303\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025331; batch adversarial loss: 0.357196\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024376; batch adversarial loss: 0.424973\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028033; batch adversarial loss: 0.423359\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006951; batch adversarial loss: 0.464624\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016112; batch adversarial loss: 0.394624\n",
      "epoch 175; iter: 0; batch classifier loss: 0.058400; batch adversarial loss: 0.614069\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032701; batch adversarial loss: 0.509258\n",
      "epoch 177; iter: 0; batch classifier loss: 0.065842; batch adversarial loss: 0.402821\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007218; batch adversarial loss: 0.432900\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007426; batch adversarial loss: 0.500555\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006311; batch adversarial loss: 0.517578\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036088; batch adversarial loss: 0.402992\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016052; batch adversarial loss: 0.442248\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020993; batch adversarial loss: 0.455454\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027941; batch adversarial loss: 0.481675\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037490; batch adversarial loss: 0.453845\n",
      "epoch 186; iter: 0; batch classifier loss: 0.042933; batch adversarial loss: 0.491563\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010467; batch adversarial loss: 0.452711\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033979; batch adversarial loss: 0.395690\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032425; batch adversarial loss: 0.587603\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021887; batch adversarial loss: 0.463244\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015391; batch adversarial loss: 0.488970\n",
      "epoch 192; iter: 0; batch classifier loss: 0.046789; batch adversarial loss: 0.410798\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015436; batch adversarial loss: 0.349103\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027310; batch adversarial loss: 0.390467\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022987; batch adversarial loss: 0.529385\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015420; batch adversarial loss: 0.482180\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008616; batch adversarial loss: 0.489784\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009020; batch adversarial loss: 0.415823\n",
      "epoch 199; iter: 0; batch classifier loss: 0.041083; batch adversarial loss: 0.498550\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710438; batch adversarial loss: 0.674683\n",
      "epoch 1; iter: 0; batch classifier loss: 0.462627; batch adversarial loss: 0.653147\n",
      "epoch 2; iter: 0; batch classifier loss: 0.395964; batch adversarial loss: 0.599456\n",
      "epoch 3; iter: 0; batch classifier loss: 0.359989; batch adversarial loss: 0.591663\n",
      "epoch 4; iter: 0; batch classifier loss: 0.377031; batch adversarial loss: 0.579610\n",
      "epoch 5; iter: 0; batch classifier loss: 0.300011; batch adversarial loss: 0.534042\n",
      "epoch 6; iter: 0; batch classifier loss: 0.368082; batch adversarial loss: 0.579068\n",
      "epoch 7; iter: 0; batch classifier loss: 0.295504; batch adversarial loss: 0.531012\n",
      "epoch 8; iter: 0; batch classifier loss: 0.364776; batch adversarial loss: 0.500549\n",
      "epoch 9; iter: 0; batch classifier loss: 0.207576; batch adversarial loss: 0.557420\n",
      "epoch 10; iter: 0; batch classifier loss: 0.231224; batch adversarial loss: 0.523429\n",
      "epoch 11; iter: 0; batch classifier loss: 0.270295; batch adversarial loss: 0.509619\n",
      "epoch 12; iter: 0; batch classifier loss: 0.304799; batch adversarial loss: 0.517909\n",
      "epoch 13; iter: 0; batch classifier loss: 0.278527; batch adversarial loss: 0.537612\n",
      "epoch 14; iter: 0; batch classifier loss: 0.321730; batch adversarial loss: 0.545410\n",
      "epoch 15; iter: 0; batch classifier loss: 0.320914; batch adversarial loss: 0.474701\n",
      "epoch 16; iter: 0; batch classifier loss: 0.348891; batch adversarial loss: 0.570864\n",
      "epoch 17; iter: 0; batch classifier loss: 0.478074; batch adversarial loss: 0.529727\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542111; batch adversarial loss: 0.453861\n",
      "epoch 19; iter: 0; batch classifier loss: 0.443888; batch adversarial loss: 0.442718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.282090; batch adversarial loss: 0.462883\n",
      "epoch 21; iter: 0; batch classifier loss: 0.283095; batch adversarial loss: 0.593803\n",
      "epoch 22; iter: 0; batch classifier loss: 0.180327; batch adversarial loss: 0.483580\n",
      "epoch 23; iter: 0; batch classifier loss: 0.184130; batch adversarial loss: 0.501098\n",
      "epoch 24; iter: 0; batch classifier loss: 0.197675; batch adversarial loss: 0.534275\n",
      "epoch 25; iter: 0; batch classifier loss: 0.155743; batch adversarial loss: 0.418787\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176874; batch adversarial loss: 0.501507\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151869; batch adversarial loss: 0.455223\n",
      "epoch 28; iter: 0; batch classifier loss: 0.203809; batch adversarial loss: 0.413601\n",
      "epoch 29; iter: 0; batch classifier loss: 0.177026; batch adversarial loss: 0.602064\n",
      "epoch 30; iter: 0; batch classifier loss: 0.139423; batch adversarial loss: 0.551277\n",
      "epoch 31; iter: 0; batch classifier loss: 0.162977; batch adversarial loss: 0.463179\n",
      "epoch 32; iter: 0; batch classifier loss: 0.098640; batch adversarial loss: 0.440345\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145093; batch adversarial loss: 0.386326\n",
      "epoch 34; iter: 0; batch classifier loss: 0.167090; batch adversarial loss: 0.409008\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142286; batch adversarial loss: 0.511057\n",
      "epoch 36; iter: 0; batch classifier loss: 0.135704; batch adversarial loss: 0.552242\n",
      "epoch 37; iter: 0; batch classifier loss: 0.115203; batch adversarial loss: 0.435522\n",
      "epoch 38; iter: 0; batch classifier loss: 0.093286; batch adversarial loss: 0.467567\n",
      "epoch 39; iter: 0; batch classifier loss: 0.117312; batch adversarial loss: 0.489274\n",
      "epoch 40; iter: 0; batch classifier loss: 0.130160; batch adversarial loss: 0.463420\n",
      "epoch 41; iter: 0; batch classifier loss: 0.097610; batch adversarial loss: 0.607467\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105979; batch adversarial loss: 0.506707\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110947; batch adversarial loss: 0.487594\n",
      "epoch 44; iter: 0; batch classifier loss: 0.168383; batch adversarial loss: 0.473427\n",
      "epoch 45; iter: 0; batch classifier loss: 0.093826; batch adversarial loss: 0.510268\n",
      "epoch 46; iter: 0; batch classifier loss: 0.072253; batch adversarial loss: 0.487372\n",
      "epoch 47; iter: 0; batch classifier loss: 0.105359; batch adversarial loss: 0.423464\n",
      "epoch 48; iter: 0; batch classifier loss: 0.126692; batch adversarial loss: 0.492966\n",
      "epoch 49; iter: 0; batch classifier loss: 0.090361; batch adversarial loss: 0.521228\n",
      "epoch 50; iter: 0; batch classifier loss: 0.100198; batch adversarial loss: 0.523230\n",
      "epoch 51; iter: 0; batch classifier loss: 0.051326; batch adversarial loss: 0.559220\n",
      "epoch 52; iter: 0; batch classifier loss: 0.108516; batch adversarial loss: 0.429856\n",
      "epoch 53; iter: 0; batch classifier loss: 0.108254; batch adversarial loss: 0.519113\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114030; batch adversarial loss: 0.460033\n",
      "epoch 55; iter: 0; batch classifier loss: 0.085221; batch adversarial loss: 0.438611\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082819; batch adversarial loss: 0.514431\n",
      "epoch 57; iter: 0; batch classifier loss: 0.172504; batch adversarial loss: 0.534238\n",
      "epoch 58; iter: 0; batch classifier loss: 0.137495; batch adversarial loss: 0.418020\n",
      "epoch 59; iter: 0; batch classifier loss: 0.079746; batch adversarial loss: 0.507574\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087681; batch adversarial loss: 0.445111\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113851; batch adversarial loss: 0.476720\n",
      "epoch 62; iter: 0; batch classifier loss: 0.168082; batch adversarial loss: 0.427712\n",
      "epoch 63; iter: 0; batch classifier loss: 0.114867; batch adversarial loss: 0.399537\n",
      "epoch 64; iter: 0; batch classifier loss: 0.137484; batch adversarial loss: 0.444580\n",
      "epoch 65; iter: 0; batch classifier loss: 0.120897; batch adversarial loss: 0.460086\n",
      "epoch 66; iter: 0; batch classifier loss: 0.149705; batch adversarial loss: 0.394868\n",
      "epoch 67; iter: 0; batch classifier loss: 0.090529; batch adversarial loss: 0.421667\n",
      "epoch 68; iter: 0; batch classifier loss: 0.092282; batch adversarial loss: 0.416162\n",
      "epoch 69; iter: 0; batch classifier loss: 0.104248; batch adversarial loss: 0.517929\n",
      "epoch 70; iter: 0; batch classifier loss: 0.047451; batch adversarial loss: 0.510574\n",
      "epoch 71; iter: 0; batch classifier loss: 0.066181; batch adversarial loss: 0.475678\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065140; batch adversarial loss: 0.460347\n",
      "epoch 73; iter: 0; batch classifier loss: 0.082463; batch adversarial loss: 0.378147\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070555; batch adversarial loss: 0.544441\n",
      "epoch 75; iter: 0; batch classifier loss: 0.106967; batch adversarial loss: 0.457454\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058688; batch adversarial loss: 0.410983\n",
      "epoch 77; iter: 0; batch classifier loss: 0.143255; batch adversarial loss: 0.447400\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090071; batch adversarial loss: 0.387504\n",
      "epoch 79; iter: 0; batch classifier loss: 0.124653; batch adversarial loss: 0.467865\n",
      "epoch 80; iter: 0; batch classifier loss: 0.058488; batch adversarial loss: 0.487583\n",
      "epoch 81; iter: 0; batch classifier loss: 0.099986; batch adversarial loss: 0.476015\n",
      "epoch 82; iter: 0; batch classifier loss: 0.089503; batch adversarial loss: 0.556769\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070121; batch adversarial loss: 0.511287\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085472; batch adversarial loss: 0.366178\n",
      "epoch 85; iter: 0; batch classifier loss: 0.112510; batch adversarial loss: 0.433590\n",
      "epoch 86; iter: 0; batch classifier loss: 0.114579; batch adversarial loss: 0.518884\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079290; batch adversarial loss: 0.465737\n",
      "epoch 88; iter: 0; batch classifier loss: 0.113161; batch adversarial loss: 0.491826\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053618; batch adversarial loss: 0.492840\n",
      "epoch 90; iter: 0; batch classifier loss: 0.036508; batch adversarial loss: 0.432737\n",
      "epoch 91; iter: 0; batch classifier loss: 0.065535; batch adversarial loss: 0.474536\n",
      "epoch 92; iter: 0; batch classifier loss: 0.081178; batch adversarial loss: 0.418178\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046340; batch adversarial loss: 0.483344\n",
      "epoch 94; iter: 0; batch classifier loss: 0.148282; batch adversarial loss: 0.441369\n",
      "epoch 95; iter: 0; batch classifier loss: 0.029815; batch adversarial loss: 0.481277\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056150; batch adversarial loss: 0.496221\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050284; batch adversarial loss: 0.409961\n",
      "epoch 98; iter: 0; batch classifier loss: 0.073994; batch adversarial loss: 0.457025\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067221; batch adversarial loss: 0.427821\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043630; batch adversarial loss: 0.489574\n",
      "epoch 101; iter: 0; batch classifier loss: 0.036070; batch adversarial loss: 0.463138\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049028; batch adversarial loss: 0.419772\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046726; batch adversarial loss: 0.480000\n",
      "epoch 104; iter: 0; batch classifier loss: 0.081902; batch adversarial loss: 0.514575\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052117; batch adversarial loss: 0.521431\n",
      "epoch 106; iter: 0; batch classifier loss: 0.048333; batch adversarial loss: 0.560704\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048318; batch adversarial loss: 0.478422\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032281; batch adversarial loss: 0.475207\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070791; batch adversarial loss: 0.475122\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042695; batch adversarial loss: 0.443192\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053615; batch adversarial loss: 0.441645\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039474; batch adversarial loss: 0.547422\n",
      "epoch 113; iter: 0; batch classifier loss: 0.068518; batch adversarial loss: 0.493833\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046916; batch adversarial loss: 0.514952\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054773; batch adversarial loss: 0.433793\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053216; batch adversarial loss: 0.559972\n",
      "epoch 117; iter: 0; batch classifier loss: 0.066783; batch adversarial loss: 0.353289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.048697; batch adversarial loss: 0.468365\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046402; batch adversarial loss: 0.481260\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032363; batch adversarial loss: 0.547960\n",
      "epoch 121; iter: 0; batch classifier loss: 0.017143; batch adversarial loss: 0.386137\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034028; batch adversarial loss: 0.324273\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026142; batch adversarial loss: 0.500192\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038163; batch adversarial loss: 0.382230\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027138; batch adversarial loss: 0.424740\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029959; batch adversarial loss: 0.425973\n",
      "epoch 127; iter: 0; batch classifier loss: 0.049730; batch adversarial loss: 0.496913\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045990; batch adversarial loss: 0.417925\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038359; batch adversarial loss: 0.398364\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021204; batch adversarial loss: 0.380825\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025789; batch adversarial loss: 0.442573\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014948; batch adversarial loss: 0.502403\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044630; batch adversarial loss: 0.478134\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016954; batch adversarial loss: 0.615840\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042088; batch adversarial loss: 0.546088\n",
      "epoch 136; iter: 0; batch classifier loss: 0.051516; batch adversarial loss: 0.421370\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054055; batch adversarial loss: 0.449267\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020433; batch adversarial loss: 0.379008\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029056; batch adversarial loss: 0.542389\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022186; batch adversarial loss: 0.430761\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020136; batch adversarial loss: 0.454410\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049533; batch adversarial loss: 0.441759\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036454; batch adversarial loss: 0.465772\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025718; batch adversarial loss: 0.468492\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036219; batch adversarial loss: 0.445070\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020038; batch adversarial loss: 0.437342\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032012; batch adversarial loss: 0.499121\n",
      "epoch 148; iter: 0; batch classifier loss: 0.062330; batch adversarial loss: 0.404855\n",
      "epoch 149; iter: 0; batch classifier loss: 0.082216; batch adversarial loss: 0.421325\n",
      "epoch 150; iter: 0; batch classifier loss: 0.055305; batch adversarial loss: 0.478345\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032426; batch adversarial loss: 0.488141\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037534; batch adversarial loss: 0.413320\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026718; batch adversarial loss: 0.471006\n",
      "epoch 154; iter: 0; batch classifier loss: 0.064488; batch adversarial loss: 0.582080\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033099; batch adversarial loss: 0.420897\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040047; batch adversarial loss: 0.493451\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042564; batch adversarial loss: 0.578205\n",
      "epoch 158; iter: 0; batch classifier loss: 0.080747; batch adversarial loss: 0.390789\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018909; batch adversarial loss: 0.455797\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018015; batch adversarial loss: 0.397891\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019439; batch adversarial loss: 0.395336\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020516; batch adversarial loss: 0.514865\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025067; batch adversarial loss: 0.548066\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011458; batch adversarial loss: 0.478886\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033653; batch adversarial loss: 0.411919\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037909; batch adversarial loss: 0.481591\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006375; batch adversarial loss: 0.521956\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030452; batch adversarial loss: 0.440506\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019845; batch adversarial loss: 0.404994\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013329; batch adversarial loss: 0.488118\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030156; batch adversarial loss: 0.479755\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025335; batch adversarial loss: 0.528820\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022061; batch adversarial loss: 0.476248\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023357; batch adversarial loss: 0.433087\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019392; batch adversarial loss: 0.460624\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022648; batch adversarial loss: 0.451038\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029050; batch adversarial loss: 0.563644\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010328; batch adversarial loss: 0.480141\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015522; batch adversarial loss: 0.407985\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009825; batch adversarial loss: 0.537542\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007769; batch adversarial loss: 0.575555\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011377; batch adversarial loss: 0.396236\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008490; batch adversarial loss: 0.424153\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035963; batch adversarial loss: 0.516577\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009711; batch adversarial loss: 0.458561\n",
      "epoch 186; iter: 0; batch classifier loss: 0.048815; batch adversarial loss: 0.474953\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020499; batch adversarial loss: 0.491496\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024821; batch adversarial loss: 0.456313\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031086; batch adversarial loss: 0.454100\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030320; batch adversarial loss: 0.433464\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020580; batch adversarial loss: 0.489356\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006977; batch adversarial loss: 0.546065\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018316; batch adversarial loss: 0.432572\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015174; batch adversarial loss: 0.435525\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009240; batch adversarial loss: 0.384672\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024612; batch adversarial loss: 0.512444\n",
      "epoch 197; iter: 0; batch classifier loss: 0.053415; batch adversarial loss: 0.428297\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015935; batch adversarial loss: 0.463084\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023417; batch adversarial loss: 0.434330\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726289; batch adversarial loss: 0.553198\n",
      "epoch 1; iter: 0; batch classifier loss: 0.512463; batch adversarial loss: 0.575050\n",
      "epoch 2; iter: 0; batch classifier loss: 0.425849; batch adversarial loss: 0.606347\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374759; batch adversarial loss: 0.591330\n",
      "epoch 4; iter: 0; batch classifier loss: 0.453850; batch adversarial loss: 0.567186\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313470; batch adversarial loss: 0.547778\n",
      "epoch 6; iter: 0; batch classifier loss: 0.422358; batch adversarial loss: 0.653366\n",
      "epoch 7; iter: 0; batch classifier loss: 0.384681; batch adversarial loss: 0.552535\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559531; batch adversarial loss: 0.544888\n",
      "epoch 9; iter: 0; batch classifier loss: 0.509113; batch adversarial loss: 0.577978\n",
      "epoch 10; iter: 0; batch classifier loss: 0.462981; batch adversarial loss: 0.514774\n",
      "epoch 11; iter: 0; batch classifier loss: 0.470132; batch adversarial loss: 0.452496\n",
      "epoch 12; iter: 0; batch classifier loss: 0.353221; batch adversarial loss: 0.551360\n",
      "epoch 13; iter: 0; batch classifier loss: 0.295230; batch adversarial loss: 0.511122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.251944; batch adversarial loss: 0.565435\n",
      "epoch 15; iter: 0; batch classifier loss: 0.257191; batch adversarial loss: 0.498655\n",
      "epoch 16; iter: 0; batch classifier loss: 0.206033; batch adversarial loss: 0.516427\n",
      "epoch 17; iter: 0; batch classifier loss: 0.227873; batch adversarial loss: 0.534073\n",
      "epoch 18; iter: 0; batch classifier loss: 0.283559; batch adversarial loss: 0.521525\n",
      "epoch 19; iter: 0; batch classifier loss: 0.174262; batch adversarial loss: 0.501319\n",
      "epoch 20; iter: 0; batch classifier loss: 0.206545; batch adversarial loss: 0.428472\n",
      "epoch 21; iter: 0; batch classifier loss: 0.181463; batch adversarial loss: 0.481898\n",
      "epoch 22; iter: 0; batch classifier loss: 0.221655; batch adversarial loss: 0.435175\n",
      "epoch 23; iter: 0; batch classifier loss: 0.240825; batch adversarial loss: 0.515141\n",
      "epoch 24; iter: 0; batch classifier loss: 0.184323; batch adversarial loss: 0.412436\n",
      "epoch 25; iter: 0; batch classifier loss: 0.207680; batch adversarial loss: 0.479545\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187458; batch adversarial loss: 0.441221\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162082; batch adversarial loss: 0.504769\n",
      "epoch 28; iter: 0; batch classifier loss: 0.155792; batch adversarial loss: 0.490816\n",
      "epoch 29; iter: 0; batch classifier loss: 0.166668; batch adversarial loss: 0.581394\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198550; batch adversarial loss: 0.359173\n",
      "epoch 31; iter: 0; batch classifier loss: 0.200935; batch adversarial loss: 0.494359\n",
      "epoch 32; iter: 0; batch classifier loss: 0.169199; batch adversarial loss: 0.512707\n",
      "epoch 33; iter: 0; batch classifier loss: 0.159670; batch adversarial loss: 0.473254\n",
      "epoch 34; iter: 0; batch classifier loss: 0.178405; batch adversarial loss: 0.413561\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148784; batch adversarial loss: 0.439600\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141870; batch adversarial loss: 0.464860\n",
      "epoch 37; iter: 0; batch classifier loss: 0.174396; batch adversarial loss: 0.538782\n",
      "epoch 38; iter: 0; batch classifier loss: 0.123802; batch adversarial loss: 0.531292\n",
      "epoch 39; iter: 0; batch classifier loss: 0.215203; batch adversarial loss: 0.459296\n",
      "epoch 40; iter: 0; batch classifier loss: 0.171753; batch adversarial loss: 0.420836\n",
      "epoch 41; iter: 0; batch classifier loss: 0.200309; batch adversarial loss: 0.440925\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200131; batch adversarial loss: 0.493061\n",
      "epoch 43; iter: 0; batch classifier loss: 0.158184; batch adversarial loss: 0.576536\n",
      "epoch 44; iter: 0; batch classifier loss: 0.142059; batch adversarial loss: 0.405580\n",
      "epoch 45; iter: 0; batch classifier loss: 0.219699; batch adversarial loss: 0.487373\n",
      "epoch 46; iter: 0; batch classifier loss: 0.164057; batch adversarial loss: 0.425637\n",
      "epoch 47; iter: 0; batch classifier loss: 0.184317; batch adversarial loss: 0.473650\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141201; batch adversarial loss: 0.489928\n",
      "epoch 49; iter: 0; batch classifier loss: 0.151077; batch adversarial loss: 0.496041\n",
      "epoch 50; iter: 0; batch classifier loss: 0.156286; batch adversarial loss: 0.456254\n",
      "epoch 51; iter: 0; batch classifier loss: 0.137784; batch adversarial loss: 0.475634\n",
      "epoch 52; iter: 0; batch classifier loss: 0.171533; batch adversarial loss: 0.481809\n",
      "epoch 53; iter: 0; batch classifier loss: 0.244320; batch adversarial loss: 0.366155\n",
      "epoch 54; iter: 0; batch classifier loss: 0.187558; batch adversarial loss: 0.403764\n",
      "epoch 55; iter: 0; batch classifier loss: 0.145817; batch adversarial loss: 0.535959\n",
      "epoch 56; iter: 0; batch classifier loss: 0.215707; batch adversarial loss: 0.451883\n",
      "epoch 57; iter: 0; batch classifier loss: 0.198383; batch adversarial loss: 0.503628\n",
      "epoch 58; iter: 0; batch classifier loss: 0.217785; batch adversarial loss: 0.437838\n",
      "epoch 59; iter: 0; batch classifier loss: 0.153739; batch adversarial loss: 0.461278\n",
      "epoch 60; iter: 0; batch classifier loss: 0.134878; batch adversarial loss: 0.463180\n",
      "epoch 61; iter: 0; batch classifier loss: 0.221258; batch adversarial loss: 0.351897\n",
      "epoch 62; iter: 0; batch classifier loss: 0.176490; batch adversarial loss: 0.470024\n",
      "epoch 63; iter: 0; batch classifier loss: 0.150712; batch adversarial loss: 0.398731\n",
      "epoch 64; iter: 0; batch classifier loss: 0.147232; batch adversarial loss: 0.505730\n",
      "epoch 65; iter: 0; batch classifier loss: 0.155333; batch adversarial loss: 0.521188\n",
      "epoch 66; iter: 0; batch classifier loss: 0.197155; batch adversarial loss: 0.456757\n",
      "epoch 67; iter: 0; batch classifier loss: 0.192918; batch adversarial loss: 0.495143\n",
      "epoch 68; iter: 0; batch classifier loss: 0.193794; batch adversarial loss: 0.461864\n",
      "epoch 69; iter: 0; batch classifier loss: 0.160910; batch adversarial loss: 0.553187\n",
      "epoch 70; iter: 0; batch classifier loss: 0.165321; batch adversarial loss: 0.471460\n",
      "epoch 71; iter: 0; batch classifier loss: 0.197797; batch adversarial loss: 0.365459\n",
      "epoch 72; iter: 0; batch classifier loss: 0.237027; batch adversarial loss: 0.434470\n",
      "epoch 73; iter: 0; batch classifier loss: 0.237437; batch adversarial loss: 0.411269\n",
      "epoch 74; iter: 0; batch classifier loss: 0.184456; batch adversarial loss: 0.434350\n",
      "epoch 75; iter: 0; batch classifier loss: 0.183775; batch adversarial loss: 0.495605\n",
      "epoch 76; iter: 0; batch classifier loss: 0.169596; batch adversarial loss: 0.483328\n",
      "epoch 77; iter: 0; batch classifier loss: 0.146491; batch adversarial loss: 0.435825\n",
      "epoch 78; iter: 0; batch classifier loss: 0.203136; batch adversarial loss: 0.483483\n",
      "epoch 79; iter: 0; batch classifier loss: 0.164711; batch adversarial loss: 0.398552\n",
      "epoch 80; iter: 0; batch classifier loss: 0.249944; batch adversarial loss: 0.422976\n",
      "epoch 81; iter: 0; batch classifier loss: 0.181568; batch adversarial loss: 0.530662\n",
      "epoch 82; iter: 0; batch classifier loss: 0.167992; batch adversarial loss: 0.422702\n",
      "epoch 83; iter: 0; batch classifier loss: 0.184572; batch adversarial loss: 0.556251\n",
      "epoch 84; iter: 0; batch classifier loss: 0.143391; batch adversarial loss: 0.458384\n",
      "epoch 85; iter: 0; batch classifier loss: 0.232525; batch adversarial loss: 0.412013\n",
      "epoch 86; iter: 0; batch classifier loss: 0.213652; batch adversarial loss: 0.484010\n",
      "epoch 87; iter: 0; batch classifier loss: 0.202177; batch adversarial loss: 0.459608\n",
      "epoch 88; iter: 0; batch classifier loss: 0.240778; batch adversarial loss: 0.410764\n",
      "epoch 89; iter: 0; batch classifier loss: 0.175116; batch adversarial loss: 0.458139\n",
      "epoch 90; iter: 0; batch classifier loss: 0.193430; batch adversarial loss: 0.423204\n",
      "epoch 91; iter: 0; batch classifier loss: 0.188516; batch adversarial loss: 0.494937\n",
      "epoch 92; iter: 0; batch classifier loss: 0.167745; batch adversarial loss: 0.579065\n",
      "epoch 93; iter: 0; batch classifier loss: 0.175349; batch adversarial loss: 0.434966\n",
      "epoch 94; iter: 0; batch classifier loss: 0.209066; batch adversarial loss: 0.374954\n",
      "epoch 95; iter: 0; batch classifier loss: 0.165646; batch adversarial loss: 0.422652\n",
      "epoch 96; iter: 0; batch classifier loss: 0.099301; batch adversarial loss: 0.482137\n",
      "epoch 97; iter: 0; batch classifier loss: 0.173166; batch adversarial loss: 0.481467\n",
      "epoch 98; iter: 0; batch classifier loss: 0.207684; batch adversarial loss: 0.531329\n",
      "epoch 99; iter: 0; batch classifier loss: 0.212371; batch adversarial loss: 0.470861\n",
      "epoch 100; iter: 0; batch classifier loss: 0.144588; batch adversarial loss: 0.396940\n",
      "epoch 101; iter: 0; batch classifier loss: 0.162530; batch adversarial loss: 0.373932\n",
      "epoch 102; iter: 0; batch classifier loss: 0.234235; batch adversarial loss: 0.520573\n",
      "epoch 103; iter: 0; batch classifier loss: 0.163752; batch adversarial loss: 0.470512\n",
      "epoch 104; iter: 0; batch classifier loss: 0.179706; batch adversarial loss: 0.398008\n",
      "epoch 105; iter: 0; batch classifier loss: 0.285314; batch adversarial loss: 0.375423\n",
      "epoch 106; iter: 0; batch classifier loss: 0.202717; batch adversarial loss: 0.459951\n",
      "epoch 107; iter: 0; batch classifier loss: 0.215143; batch adversarial loss: 0.459020\n",
      "epoch 108; iter: 0; batch classifier loss: 0.217595; batch adversarial loss: 0.492482\n",
      "epoch 109; iter: 0; batch classifier loss: 0.181760; batch adversarial loss: 0.493847\n",
      "epoch 110; iter: 0; batch classifier loss: 0.179051; batch adversarial loss: 0.434867\n",
      "epoch 111; iter: 0; batch classifier loss: 0.191072; batch adversarial loss: 0.470132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.267396; batch adversarial loss: 0.421463\n",
      "epoch 113; iter: 0; batch classifier loss: 0.143852; batch adversarial loss: 0.506502\n",
      "epoch 114; iter: 0; batch classifier loss: 0.189088; batch adversarial loss: 0.445913\n",
      "epoch 115; iter: 0; batch classifier loss: 0.123489; batch adversarial loss: 0.627399\n",
      "epoch 116; iter: 0; batch classifier loss: 0.120816; batch adversarial loss: 0.456559\n",
      "epoch 117; iter: 0; batch classifier loss: 0.169089; batch adversarial loss: 0.433982\n",
      "epoch 118; iter: 0; batch classifier loss: 0.168097; batch adversarial loss: 0.371712\n",
      "epoch 119; iter: 0; batch classifier loss: 0.146804; batch adversarial loss: 0.552669\n",
      "epoch 120; iter: 0; batch classifier loss: 0.131414; batch adversarial loss: 0.458486\n",
      "epoch 121; iter: 0; batch classifier loss: 0.173414; batch adversarial loss: 0.350326\n",
      "epoch 122; iter: 0; batch classifier loss: 0.123152; batch adversarial loss: 0.425605\n",
      "epoch 123; iter: 0; batch classifier loss: 0.159983; batch adversarial loss: 0.398761\n",
      "epoch 124; iter: 0; batch classifier loss: 0.089999; batch adversarial loss: 0.418583\n",
      "epoch 125; iter: 0; batch classifier loss: 0.132723; batch adversarial loss: 0.412988\n",
      "epoch 126; iter: 0; batch classifier loss: 0.071192; batch adversarial loss: 0.523207\n",
      "epoch 127; iter: 0; batch classifier loss: 0.093568; batch adversarial loss: 0.503688\n",
      "epoch 128; iter: 0; batch classifier loss: 0.064330; batch adversarial loss: 0.408677\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050602; batch adversarial loss: 0.474030\n",
      "epoch 130; iter: 0; batch classifier loss: 0.090849; batch adversarial loss: 0.479786\n",
      "epoch 131; iter: 0; batch classifier loss: 0.073167; batch adversarial loss: 0.450914\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049345; batch adversarial loss: 0.475389\n",
      "epoch 133; iter: 0; batch classifier loss: 0.072586; batch adversarial loss: 0.475636\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054043; batch adversarial loss: 0.412259\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043937; batch adversarial loss: 0.445937\n",
      "epoch 136; iter: 0; batch classifier loss: 0.053171; batch adversarial loss: 0.543346\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038627; batch adversarial loss: 0.530536\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019648; batch adversarial loss: 0.516253\n",
      "epoch 139; iter: 0; batch classifier loss: 0.078015; batch adversarial loss: 0.467945\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053724; batch adversarial loss: 0.447735\n",
      "epoch 141; iter: 0; batch classifier loss: 0.059295; batch adversarial loss: 0.418563\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029976; batch adversarial loss: 0.479797\n",
      "epoch 143; iter: 0; batch classifier loss: 0.057587; batch adversarial loss: 0.477748\n",
      "epoch 144; iter: 0; batch classifier loss: 0.058671; batch adversarial loss: 0.465303\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026599; batch adversarial loss: 0.401098\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025028; batch adversarial loss: 0.556713\n",
      "epoch 147; iter: 0; batch classifier loss: 0.053003; batch adversarial loss: 0.469755\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041576; batch adversarial loss: 0.489151\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035055; batch adversarial loss: 0.476827\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036112; batch adversarial loss: 0.456571\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015924; batch adversarial loss: 0.490331\n",
      "epoch 152; iter: 0; batch classifier loss: 0.047296; batch adversarial loss: 0.434379\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039667; batch adversarial loss: 0.406668\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024850; batch adversarial loss: 0.407526\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016500; batch adversarial loss: 0.470926\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038829; batch adversarial loss: 0.402322\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029637; batch adversarial loss: 0.409368\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015517; batch adversarial loss: 0.470062\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039347; batch adversarial loss: 0.522477\n",
      "epoch 160; iter: 0; batch classifier loss: 0.048951; batch adversarial loss: 0.386807\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021371; batch adversarial loss: 0.371559\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032538; batch adversarial loss: 0.479297\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028598; batch adversarial loss: 0.467810\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027901; batch adversarial loss: 0.371726\n",
      "epoch 165; iter: 0; batch classifier loss: 0.052828; batch adversarial loss: 0.570482\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019171; batch adversarial loss: 0.449616\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036145; batch adversarial loss: 0.429213\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036616; batch adversarial loss: 0.540028\n",
      "epoch 169; iter: 0; batch classifier loss: 0.042850; batch adversarial loss: 0.451596\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029969; batch adversarial loss: 0.451644\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010922; batch adversarial loss: 0.453508\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011629; batch adversarial loss: 0.594253\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028691; batch adversarial loss: 0.544436\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036758; batch adversarial loss: 0.457490\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006791; batch adversarial loss: 0.508257\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012762; batch adversarial loss: 0.414537\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012927; batch adversarial loss: 0.453482\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012900; batch adversarial loss: 0.542781\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016247; batch adversarial loss: 0.541537\n",
      "epoch 180; iter: 0; batch classifier loss: 0.045320; batch adversarial loss: 0.500959\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027272; batch adversarial loss: 0.373484\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018821; batch adversarial loss: 0.492762\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015878; batch adversarial loss: 0.493407\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012964; batch adversarial loss: 0.511594\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020365; batch adversarial loss: 0.447548\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025167; batch adversarial loss: 0.597638\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029189; batch adversarial loss: 0.445335\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031736; batch adversarial loss: 0.453575\n",
      "epoch 189; iter: 0; batch classifier loss: 0.072073; batch adversarial loss: 0.491979\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012141; batch adversarial loss: 0.412556\n",
      "epoch 191; iter: 0; batch classifier loss: 0.038073; batch adversarial loss: 0.450272\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024789; batch adversarial loss: 0.476879\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026489; batch adversarial loss: 0.369461\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024030; batch adversarial loss: 0.454112\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026216; batch adversarial loss: 0.466328\n",
      "epoch 196; iter: 0; batch classifier loss: 0.036343; batch adversarial loss: 0.456130\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006838; batch adversarial loss: 0.522121\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017486; batch adversarial loss: 0.458608\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019107; batch adversarial loss: 0.360297\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692537; batch adversarial loss: 0.632209\n",
      "epoch 1; iter: 0; batch classifier loss: 0.503309; batch adversarial loss: 0.590376\n",
      "epoch 2; iter: 0; batch classifier loss: 0.378389; batch adversarial loss: 0.603991\n",
      "epoch 3; iter: 0; batch classifier loss: 0.333549; batch adversarial loss: 0.567738\n",
      "epoch 4; iter: 0; batch classifier loss: 0.405368; batch adversarial loss: 0.523432\n",
      "epoch 5; iter: 0; batch classifier loss: 0.265710; batch adversarial loss: 0.655139\n",
      "epoch 6; iter: 0; batch classifier loss: 0.309938; batch adversarial loss: 0.579879\n",
      "epoch 7; iter: 0; batch classifier loss: 0.317515; batch adversarial loss: 0.504859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.342987; batch adversarial loss: 0.626798\n",
      "epoch 9; iter: 0; batch classifier loss: 0.338254; batch adversarial loss: 0.517279\n",
      "epoch 10; iter: 0; batch classifier loss: 0.425749; batch adversarial loss: 0.502245\n",
      "epoch 11; iter: 0; batch classifier loss: 0.318827; batch adversarial loss: 0.547315\n",
      "epoch 12; iter: 0; batch classifier loss: 0.301279; batch adversarial loss: 0.521208\n",
      "epoch 13; iter: 0; batch classifier loss: 0.265097; batch adversarial loss: 0.467389\n",
      "epoch 14; iter: 0; batch classifier loss: 0.261499; batch adversarial loss: 0.471798\n",
      "epoch 15; iter: 0; batch classifier loss: 0.245410; batch adversarial loss: 0.500366\n",
      "epoch 16; iter: 0; batch classifier loss: 0.194468; batch adversarial loss: 0.515037\n",
      "epoch 17; iter: 0; batch classifier loss: 0.245693; batch adversarial loss: 0.641457\n",
      "epoch 18; iter: 0; batch classifier loss: 0.252358; batch adversarial loss: 0.492351\n",
      "epoch 19; iter: 0; batch classifier loss: 0.231258; batch adversarial loss: 0.467627\n",
      "epoch 20; iter: 0; batch classifier loss: 0.276327; batch adversarial loss: 0.484843\n",
      "epoch 21; iter: 0; batch classifier loss: 0.212569; batch adversarial loss: 0.433038\n",
      "epoch 22; iter: 0; batch classifier loss: 0.168202; batch adversarial loss: 0.608674\n",
      "epoch 23; iter: 0; batch classifier loss: 0.192682; batch adversarial loss: 0.442502\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182616; batch adversarial loss: 0.432229\n",
      "epoch 25; iter: 0; batch classifier loss: 0.162749; batch adversarial loss: 0.458343\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243353; batch adversarial loss: 0.433420\n",
      "epoch 27; iter: 0; batch classifier loss: 0.249629; batch adversarial loss: 0.376469\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173326; batch adversarial loss: 0.477883\n",
      "epoch 29; iter: 0; batch classifier loss: 0.272759; batch adversarial loss: 0.411842\n",
      "epoch 30; iter: 0; batch classifier loss: 0.156716; batch adversarial loss: 0.525572\n",
      "epoch 31; iter: 0; batch classifier loss: 0.183924; batch adversarial loss: 0.533090\n",
      "epoch 32; iter: 0; batch classifier loss: 0.191039; batch adversarial loss: 0.422030\n",
      "epoch 33; iter: 0; batch classifier loss: 0.206697; batch adversarial loss: 0.366162\n",
      "epoch 34; iter: 0; batch classifier loss: 0.183186; batch adversarial loss: 0.447629\n",
      "epoch 35; iter: 0; batch classifier loss: 0.169448; batch adversarial loss: 0.369264\n",
      "epoch 36; iter: 0; batch classifier loss: 0.173583; batch adversarial loss: 0.466148\n",
      "epoch 37; iter: 0; batch classifier loss: 0.147942; batch adversarial loss: 0.474075\n",
      "epoch 38; iter: 0; batch classifier loss: 0.182389; batch adversarial loss: 0.456572\n",
      "epoch 39; iter: 0; batch classifier loss: 0.110256; batch adversarial loss: 0.462289\n",
      "epoch 40; iter: 0; batch classifier loss: 0.161117; batch adversarial loss: 0.455993\n",
      "epoch 41; iter: 0; batch classifier loss: 0.234944; batch adversarial loss: 0.380093\n",
      "epoch 42; iter: 0; batch classifier loss: 0.192517; batch adversarial loss: 0.501277\n",
      "epoch 43; iter: 0; batch classifier loss: 0.184652; batch adversarial loss: 0.371516\n",
      "epoch 44; iter: 0; batch classifier loss: 0.160963; batch adversarial loss: 0.404800\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124745; batch adversarial loss: 0.479314\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114592; batch adversarial loss: 0.529125\n",
      "epoch 47; iter: 0; batch classifier loss: 0.116883; batch adversarial loss: 0.555644\n",
      "epoch 48; iter: 0; batch classifier loss: 0.188459; batch adversarial loss: 0.404756\n",
      "epoch 49; iter: 0; batch classifier loss: 0.165303; batch adversarial loss: 0.415708\n",
      "epoch 50; iter: 0; batch classifier loss: 0.151279; batch adversarial loss: 0.420027\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112912; batch adversarial loss: 0.423772\n",
      "epoch 52; iter: 0; batch classifier loss: 0.128819; batch adversarial loss: 0.433913\n",
      "epoch 53; iter: 0; batch classifier loss: 0.179618; batch adversarial loss: 0.470026\n",
      "epoch 54; iter: 0; batch classifier loss: 0.135174; batch adversarial loss: 0.398228\n",
      "epoch 55; iter: 0; batch classifier loss: 0.172420; batch adversarial loss: 0.422362\n",
      "epoch 56; iter: 0; batch classifier loss: 0.222635; batch adversarial loss: 0.495427\n",
      "epoch 57; iter: 0; batch classifier loss: 0.173378; batch adversarial loss: 0.434224\n",
      "epoch 58; iter: 0; batch classifier loss: 0.191983; batch adversarial loss: 0.472273\n",
      "epoch 59; iter: 0; batch classifier loss: 0.182633; batch adversarial loss: 0.484768\n",
      "epoch 60; iter: 0; batch classifier loss: 0.148527; batch adversarial loss: 0.494953\n",
      "epoch 61; iter: 0; batch classifier loss: 0.142907; batch adversarial loss: 0.522167\n",
      "epoch 62; iter: 0; batch classifier loss: 0.176920; batch adversarial loss: 0.470474\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178096; batch adversarial loss: 0.507424\n",
      "epoch 64; iter: 0; batch classifier loss: 0.165851; batch adversarial loss: 0.433987\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118460; batch adversarial loss: 0.486392\n",
      "epoch 66; iter: 0; batch classifier loss: 0.205687; batch adversarial loss: 0.434412\n",
      "epoch 67; iter: 0; batch classifier loss: 0.201102; batch adversarial loss: 0.383740\n",
      "epoch 68; iter: 0; batch classifier loss: 0.140835; batch adversarial loss: 0.544157\n",
      "epoch 69; iter: 0; batch classifier loss: 0.130271; batch adversarial loss: 0.534211\n",
      "epoch 70; iter: 0; batch classifier loss: 0.179689; batch adversarial loss: 0.457220\n",
      "epoch 71; iter: 0; batch classifier loss: 0.125158; batch adversarial loss: 0.584246\n",
      "epoch 72; iter: 0; batch classifier loss: 0.209641; batch adversarial loss: 0.447209\n",
      "epoch 73; iter: 0; batch classifier loss: 0.185963; batch adversarial loss: 0.421450\n",
      "epoch 74; iter: 0; batch classifier loss: 0.141695; batch adversarial loss: 0.421537\n",
      "epoch 75; iter: 0; batch classifier loss: 0.129238; batch adversarial loss: 0.409119\n",
      "epoch 76; iter: 0; batch classifier loss: 0.148640; batch adversarial loss: 0.459264\n",
      "epoch 77; iter: 0; batch classifier loss: 0.145267; batch adversarial loss: 0.445511\n",
      "epoch 78; iter: 0; batch classifier loss: 0.155847; batch adversarial loss: 0.446821\n",
      "epoch 79; iter: 0; batch classifier loss: 0.173408; batch adversarial loss: 0.547124\n",
      "epoch 80; iter: 0; batch classifier loss: 0.182889; batch adversarial loss: 0.458885\n",
      "epoch 81; iter: 0; batch classifier loss: 0.149446; batch adversarial loss: 0.470558\n",
      "epoch 82; iter: 0; batch classifier loss: 0.167175; batch adversarial loss: 0.433064\n",
      "epoch 83; iter: 0; batch classifier loss: 0.191891; batch adversarial loss: 0.421837\n",
      "epoch 84; iter: 0; batch classifier loss: 0.114228; batch adversarial loss: 0.571481\n",
      "epoch 85; iter: 0; batch classifier loss: 0.123236; batch adversarial loss: 0.508470\n",
      "epoch 86; iter: 0; batch classifier loss: 0.139138; batch adversarial loss: 0.432236\n",
      "epoch 87; iter: 0; batch classifier loss: 0.127177; batch adversarial loss: 0.534425\n",
      "epoch 88; iter: 0; batch classifier loss: 0.209348; batch adversarial loss: 0.371042\n",
      "epoch 89; iter: 0; batch classifier loss: 0.175865; batch adversarial loss: 0.459035\n",
      "epoch 90; iter: 0; batch classifier loss: 0.151157; batch adversarial loss: 0.446116\n",
      "epoch 91; iter: 0; batch classifier loss: 0.153592; batch adversarial loss: 0.546908\n",
      "epoch 92; iter: 0; batch classifier loss: 0.156093; batch adversarial loss: 0.509648\n",
      "epoch 93; iter: 0; batch classifier loss: 0.171982; batch adversarial loss: 0.506799\n",
      "epoch 94; iter: 0; batch classifier loss: 0.151896; batch adversarial loss: 0.383206\n",
      "epoch 95; iter: 0; batch classifier loss: 0.147361; batch adversarial loss: 0.385259\n",
      "epoch 96; iter: 0; batch classifier loss: 0.141908; batch adversarial loss: 0.446146\n",
      "epoch 97; iter: 0; batch classifier loss: 0.214741; batch adversarial loss: 0.383564\n",
      "epoch 98; iter: 0; batch classifier loss: 0.150474; batch adversarial loss: 0.495510\n",
      "epoch 99; iter: 0; batch classifier loss: 0.165922; batch adversarial loss: 0.495340\n",
      "epoch 100; iter: 0; batch classifier loss: 0.224836; batch adversarial loss: 0.436066\n",
      "epoch 101; iter: 0; batch classifier loss: 0.168350; batch adversarial loss: 0.396286\n",
      "epoch 102; iter: 0; batch classifier loss: 0.144166; batch adversarial loss: 0.457268\n",
      "epoch 103; iter: 0; batch classifier loss: 0.162378; batch adversarial loss: 0.495324\n",
      "epoch 104; iter: 0; batch classifier loss: 0.093560; batch adversarial loss: 0.429371\n",
      "epoch 105; iter: 0; batch classifier loss: 0.101340; batch adversarial loss: 0.358454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.104073; batch adversarial loss: 0.570307\n",
      "epoch 107; iter: 0; batch classifier loss: 0.091679; batch adversarial loss: 0.456837\n",
      "epoch 108; iter: 0; batch classifier loss: 0.107996; batch adversarial loss: 0.459739\n",
      "epoch 109; iter: 0; batch classifier loss: 0.075674; batch adversarial loss: 0.490717\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052153; batch adversarial loss: 0.470686\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054551; batch adversarial loss: 0.420530\n",
      "epoch 112; iter: 0; batch classifier loss: 0.085143; batch adversarial loss: 0.442708\n",
      "epoch 113; iter: 0; batch classifier loss: 0.082006; batch adversarial loss: 0.348700\n",
      "epoch 114; iter: 0; batch classifier loss: 0.070762; batch adversarial loss: 0.484479\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063632; batch adversarial loss: 0.381154\n",
      "epoch 116; iter: 0; batch classifier loss: 0.065297; batch adversarial loss: 0.426623\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045253; batch adversarial loss: 0.449321\n",
      "epoch 118; iter: 0; batch classifier loss: 0.091923; batch adversarial loss: 0.407510\n",
      "epoch 119; iter: 0; batch classifier loss: 0.061414; batch adversarial loss: 0.429563\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024445; batch adversarial loss: 0.496382\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057925; batch adversarial loss: 0.418407\n",
      "epoch 122; iter: 0; batch classifier loss: 0.064777; batch adversarial loss: 0.550424\n",
      "epoch 123; iter: 0; batch classifier loss: 0.084862; batch adversarial loss: 0.568046\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046220; batch adversarial loss: 0.440330\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047741; batch adversarial loss: 0.402847\n",
      "epoch 126; iter: 0; batch classifier loss: 0.072419; batch adversarial loss: 0.402280\n",
      "epoch 127; iter: 0; batch classifier loss: 0.049005; batch adversarial loss: 0.428036\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033598; batch adversarial loss: 0.430826\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029951; batch adversarial loss: 0.396241\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042880; batch adversarial loss: 0.358293\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045329; batch adversarial loss: 0.459679\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037367; batch adversarial loss: 0.400817\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039658; batch adversarial loss: 0.363228\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050497; batch adversarial loss: 0.447313\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027101; batch adversarial loss: 0.385131\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023497; batch adversarial loss: 0.465779\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031668; batch adversarial loss: 0.562467\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020572; batch adversarial loss: 0.468077\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035586; batch adversarial loss: 0.509966\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038359; batch adversarial loss: 0.493015\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044715; batch adversarial loss: 0.509965\n",
      "epoch 142; iter: 0; batch classifier loss: 0.015367; batch adversarial loss: 0.463237\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026475; batch adversarial loss: 0.390779\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036014; batch adversarial loss: 0.482100\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045578; batch adversarial loss: 0.396152\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051972; batch adversarial loss: 0.464424\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021992; batch adversarial loss: 0.479011\n",
      "epoch 148; iter: 0; batch classifier loss: 0.008788; batch adversarial loss: 0.421331\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034871; batch adversarial loss: 0.474170\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014182; batch adversarial loss: 0.522510\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027905; batch adversarial loss: 0.472267\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038579; batch adversarial loss: 0.396384\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028080; batch adversarial loss: 0.414296\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013765; batch adversarial loss: 0.385172\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018709; batch adversarial loss: 0.476818\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032642; batch adversarial loss: 0.387479\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030970; batch adversarial loss: 0.482196\n",
      "epoch 158; iter: 0; batch classifier loss: 0.058701; batch adversarial loss: 0.423240\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041977; batch adversarial loss: 0.449236\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013940; batch adversarial loss: 0.594244\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014918; batch adversarial loss: 0.425143\n",
      "epoch 162; iter: 0; batch classifier loss: 0.035695; batch adversarial loss: 0.480899\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038209; batch adversarial loss: 0.450633\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021204; batch adversarial loss: 0.490003\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012515; batch adversarial loss: 0.325216\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022315; batch adversarial loss: 0.434082\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022294; batch adversarial loss: 0.446984\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036394; batch adversarial loss: 0.425270\n",
      "epoch 169; iter: 0; batch classifier loss: 0.005383; batch adversarial loss: 0.415034\n",
      "epoch 170; iter: 0; batch classifier loss: 0.048357; batch adversarial loss: 0.457939\n",
      "epoch 171; iter: 0; batch classifier loss: 0.044695; batch adversarial loss: 0.440349\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034478; batch adversarial loss: 0.423669\n",
      "epoch 173; iter: 0; batch classifier loss: 0.050993; batch adversarial loss: 0.449996\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014638; batch adversarial loss: 0.524922\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028926; batch adversarial loss: 0.576132\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023480; batch adversarial loss: 0.401119\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020451; batch adversarial loss: 0.509837\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029353; batch adversarial loss: 0.332981\n",
      "epoch 179; iter: 0; batch classifier loss: 0.005747; batch adversarial loss: 0.550739\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035673; batch adversarial loss: 0.498194\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015820; batch adversarial loss: 0.420956\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018806; batch adversarial loss: 0.435724\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013723; batch adversarial loss: 0.376279\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026355; batch adversarial loss: 0.433656\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032829; batch adversarial loss: 0.466940\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013952; batch adversarial loss: 0.461107\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010337; batch adversarial loss: 0.424901\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012085; batch adversarial loss: 0.444547\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020075; batch adversarial loss: 0.402302\n",
      "epoch 190; iter: 0; batch classifier loss: 0.003363; batch adversarial loss: 0.497567\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018069; batch adversarial loss: 0.426795\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011884; batch adversarial loss: 0.455172\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015722; batch adversarial loss: 0.485713\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024529; batch adversarial loss: 0.439234\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034812; batch adversarial loss: 0.370613\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006143; batch adversarial loss: 0.468732\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022662; batch adversarial loss: 0.440673\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015397; batch adversarial loss: 0.449067\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031010; batch adversarial loss: 0.373578\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675657; batch adversarial loss: 0.806555\n",
      "epoch 1; iter: 0; batch classifier loss: 0.492325; batch adversarial loss: 0.775812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.472360; batch adversarial loss: 0.732869\n",
      "epoch 3; iter: 0; batch classifier loss: 0.416772; batch adversarial loss: 0.685315\n",
      "epoch 4; iter: 0; batch classifier loss: 0.407210; batch adversarial loss: 0.655618\n",
      "epoch 5; iter: 0; batch classifier loss: 0.371102; batch adversarial loss: 0.618113\n",
      "epoch 6; iter: 0; batch classifier loss: 0.302173; batch adversarial loss: 0.592207\n",
      "epoch 7; iter: 0; batch classifier loss: 0.357904; batch adversarial loss: 0.572734\n",
      "epoch 8; iter: 0; batch classifier loss: 0.285631; batch adversarial loss: 0.564199\n",
      "epoch 9; iter: 0; batch classifier loss: 0.258532; batch adversarial loss: 0.479105\n",
      "epoch 10; iter: 0; batch classifier loss: 0.256506; batch adversarial loss: 0.526093\n",
      "epoch 11; iter: 0; batch classifier loss: 0.228044; batch adversarial loss: 0.529821\n",
      "epoch 12; iter: 0; batch classifier loss: 0.247457; batch adversarial loss: 0.468573\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232268; batch adversarial loss: 0.521773\n",
      "epoch 14; iter: 0; batch classifier loss: 0.183266; batch adversarial loss: 0.428865\n",
      "epoch 15; iter: 0; batch classifier loss: 0.185245; batch adversarial loss: 0.457338\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227384; batch adversarial loss: 0.481219\n",
      "epoch 17; iter: 0; batch classifier loss: 0.150395; batch adversarial loss: 0.535190\n",
      "epoch 18; iter: 0; batch classifier loss: 0.226899; batch adversarial loss: 0.447444\n",
      "epoch 19; iter: 0; batch classifier loss: 0.172551; batch adversarial loss: 0.418251\n",
      "epoch 20; iter: 0; batch classifier loss: 0.182619; batch adversarial loss: 0.499100\n",
      "epoch 21; iter: 0; batch classifier loss: 0.150458; batch adversarial loss: 0.418334\n",
      "epoch 22; iter: 0; batch classifier loss: 0.104777; batch adversarial loss: 0.514239\n",
      "epoch 23; iter: 0; batch classifier loss: 0.138240; batch adversarial loss: 0.488379\n",
      "epoch 24; iter: 0; batch classifier loss: 0.111508; batch adversarial loss: 0.429871\n",
      "epoch 25; iter: 0; batch classifier loss: 0.121962; batch adversarial loss: 0.462858\n",
      "epoch 26; iter: 0; batch classifier loss: 0.144566; batch adversarial loss: 0.446773\n",
      "epoch 27; iter: 0; batch classifier loss: 0.094371; batch adversarial loss: 0.469367\n",
      "epoch 28; iter: 0; batch classifier loss: 0.095214; batch adversarial loss: 0.360797\n",
      "epoch 29; iter: 0; batch classifier loss: 0.086886; batch adversarial loss: 0.509855\n",
      "epoch 30; iter: 0; batch classifier loss: 0.127769; batch adversarial loss: 0.507996\n",
      "epoch 31; iter: 0; batch classifier loss: 0.144686; batch adversarial loss: 0.473837\n",
      "epoch 32; iter: 0; batch classifier loss: 0.104687; batch adversarial loss: 0.413748\n",
      "epoch 33; iter: 0; batch classifier loss: 0.107915; batch adversarial loss: 0.490614\n",
      "epoch 34; iter: 0; batch classifier loss: 0.103790; batch adversarial loss: 0.437042\n",
      "epoch 35; iter: 0; batch classifier loss: 0.094295; batch adversarial loss: 0.431767\n",
      "epoch 36; iter: 0; batch classifier loss: 0.130113; batch adversarial loss: 0.512999\n",
      "epoch 37; iter: 0; batch classifier loss: 0.109266; batch adversarial loss: 0.344485\n",
      "epoch 38; iter: 0; batch classifier loss: 0.110618; batch adversarial loss: 0.456394\n",
      "epoch 39; iter: 0; batch classifier loss: 0.141441; batch adversarial loss: 0.444349\n",
      "epoch 40; iter: 0; batch classifier loss: 0.172194; batch adversarial loss: 0.513200\n",
      "epoch 41; iter: 0; batch classifier loss: 0.117128; batch adversarial loss: 0.442662\n",
      "epoch 42; iter: 0; batch classifier loss: 0.100078; batch adversarial loss: 0.512973\n",
      "epoch 43; iter: 0; batch classifier loss: 0.122155; batch adversarial loss: 0.471268\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112655; batch adversarial loss: 0.376157\n",
      "epoch 45; iter: 0; batch classifier loss: 0.118689; batch adversarial loss: 0.394306\n",
      "epoch 46; iter: 0; batch classifier loss: 0.096691; batch adversarial loss: 0.382577\n",
      "epoch 47; iter: 0; batch classifier loss: 0.091942; batch adversarial loss: 0.427538\n",
      "epoch 48; iter: 0; batch classifier loss: 0.083945; batch adversarial loss: 0.348241\n",
      "epoch 49; iter: 0; batch classifier loss: 0.066976; batch adversarial loss: 0.449420\n",
      "epoch 50; iter: 0; batch classifier loss: 0.113573; batch adversarial loss: 0.431107\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077267; batch adversarial loss: 0.332678\n",
      "epoch 52; iter: 0; batch classifier loss: 0.070464; batch adversarial loss: 0.439132\n",
      "epoch 53; iter: 0; batch classifier loss: 0.148774; batch adversarial loss: 0.446343\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080520; batch adversarial loss: 0.426054\n",
      "epoch 55; iter: 0; batch classifier loss: 0.107615; batch adversarial loss: 0.388554\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099701; batch adversarial loss: 0.469411\n",
      "epoch 57; iter: 0; batch classifier loss: 0.054767; batch adversarial loss: 0.369293\n",
      "epoch 58; iter: 0; batch classifier loss: 0.060870; batch adversarial loss: 0.406896\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084778; batch adversarial loss: 0.370846\n",
      "epoch 60; iter: 0; batch classifier loss: 0.075909; batch adversarial loss: 0.379759\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103746; batch adversarial loss: 0.415568\n",
      "epoch 62; iter: 0; batch classifier loss: 0.121560; batch adversarial loss: 0.398598\n",
      "epoch 63; iter: 0; batch classifier loss: 0.107106; batch adversarial loss: 0.447037\n",
      "epoch 64; iter: 0; batch classifier loss: 0.092195; batch adversarial loss: 0.391904\n",
      "epoch 65; iter: 0; batch classifier loss: 0.104002; batch adversarial loss: 0.406780\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092039; batch adversarial loss: 0.444254\n",
      "epoch 67; iter: 0; batch classifier loss: 0.058514; batch adversarial loss: 0.342309\n",
      "epoch 68; iter: 0; batch classifier loss: 0.089709; batch adversarial loss: 0.383996\n",
      "epoch 69; iter: 0; batch classifier loss: 0.092021; batch adversarial loss: 0.397024\n",
      "epoch 70; iter: 0; batch classifier loss: 0.068212; batch adversarial loss: 0.385825\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063963; batch adversarial loss: 0.437452\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077526; batch adversarial loss: 0.411306\n",
      "epoch 73; iter: 0; batch classifier loss: 0.036914; batch adversarial loss: 0.348858\n",
      "epoch 74; iter: 0; batch classifier loss: 0.043524; batch adversarial loss: 0.486881\n",
      "epoch 75; iter: 0; batch classifier loss: 0.045755; batch adversarial loss: 0.448611\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086172; batch adversarial loss: 0.443424\n",
      "epoch 77; iter: 0; batch classifier loss: 0.099037; batch adversarial loss: 0.434288\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073285; batch adversarial loss: 0.421105\n",
      "epoch 79; iter: 0; batch classifier loss: 0.050606; batch adversarial loss: 0.369446\n",
      "epoch 80; iter: 0; batch classifier loss: 0.058486; batch adversarial loss: 0.443878\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064956; batch adversarial loss: 0.401292\n",
      "epoch 82; iter: 0; batch classifier loss: 0.077888; batch adversarial loss: 0.466096\n",
      "epoch 83; iter: 0; batch classifier loss: 0.084978; batch adversarial loss: 0.356587\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070978; batch adversarial loss: 0.405117\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080020; batch adversarial loss: 0.478789\n",
      "epoch 86; iter: 0; batch classifier loss: 0.107908; batch adversarial loss: 0.373755\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073917; batch adversarial loss: 0.345530\n",
      "epoch 88; iter: 0; batch classifier loss: 0.101317; batch adversarial loss: 0.543009\n",
      "epoch 89; iter: 0; batch classifier loss: 0.103508; batch adversarial loss: 0.491049\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059223; batch adversarial loss: 0.494376\n",
      "epoch 91; iter: 0; batch classifier loss: 0.090319; batch adversarial loss: 0.403747\n",
      "epoch 92; iter: 0; batch classifier loss: 0.089069; batch adversarial loss: 0.468824\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064954; batch adversarial loss: 0.378251\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047892; batch adversarial loss: 0.303869\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039006; batch adversarial loss: 0.460915\n",
      "epoch 96; iter: 0; batch classifier loss: 0.074153; batch adversarial loss: 0.452386\n",
      "epoch 97; iter: 0; batch classifier loss: 0.085681; batch adversarial loss: 0.397830\n",
      "epoch 98; iter: 0; batch classifier loss: 0.094992; batch adversarial loss: 0.363817\n",
      "epoch 99; iter: 0; batch classifier loss: 0.103918; batch adversarial loss: 0.486363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.062167; batch adversarial loss: 0.501809\n",
      "epoch 101; iter: 0; batch classifier loss: 0.081628; batch adversarial loss: 0.495643\n",
      "epoch 102; iter: 0; batch classifier loss: 0.093414; batch adversarial loss: 0.327991\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064759; batch adversarial loss: 0.462378\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061477; batch adversarial loss: 0.440807\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084199; batch adversarial loss: 0.456864\n",
      "epoch 106; iter: 0; batch classifier loss: 0.082593; batch adversarial loss: 0.458902\n",
      "epoch 107; iter: 0; batch classifier loss: 0.054505; batch adversarial loss: 0.440572\n",
      "epoch 108; iter: 0; batch classifier loss: 0.068043; batch adversarial loss: 0.426602\n",
      "epoch 109; iter: 0; batch classifier loss: 0.082920; batch adversarial loss: 0.452707\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050781; batch adversarial loss: 0.490719\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062486; batch adversarial loss: 0.382408\n",
      "epoch 112; iter: 0; batch classifier loss: 0.091935; batch adversarial loss: 0.500634\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053844; batch adversarial loss: 0.383246\n",
      "epoch 114; iter: 0; batch classifier loss: 0.087880; batch adversarial loss: 0.436088\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063259; batch adversarial loss: 0.420045\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054059; batch adversarial loss: 0.384007\n",
      "epoch 117; iter: 0; batch classifier loss: 0.074901; batch adversarial loss: 0.426875\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069426; batch adversarial loss: 0.352191\n",
      "epoch 119; iter: 0; batch classifier loss: 0.061833; batch adversarial loss: 0.419759\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051729; batch adversarial loss: 0.383967\n",
      "epoch 121; iter: 0; batch classifier loss: 0.080421; batch adversarial loss: 0.373254\n",
      "epoch 122; iter: 0; batch classifier loss: 0.054686; batch adversarial loss: 0.418592\n",
      "epoch 123; iter: 0; batch classifier loss: 0.056728; batch adversarial loss: 0.437548\n",
      "epoch 124; iter: 0; batch classifier loss: 0.084087; batch adversarial loss: 0.456602\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062434; batch adversarial loss: 0.387646\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049783; batch adversarial loss: 0.486147\n",
      "epoch 127; iter: 0; batch classifier loss: 0.068691; batch adversarial loss: 0.545053\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040903; batch adversarial loss: 0.356880\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034736; batch adversarial loss: 0.536381\n",
      "epoch 130; iter: 0; batch classifier loss: 0.078346; batch adversarial loss: 0.442901\n",
      "epoch 131; iter: 0; batch classifier loss: 0.078436; batch adversarial loss: 0.391580\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046114; batch adversarial loss: 0.389800\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053303; batch adversarial loss: 0.352026\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053674; batch adversarial loss: 0.488359\n",
      "epoch 135; iter: 0; batch classifier loss: 0.091692; batch adversarial loss: 0.314527\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049120; batch adversarial loss: 0.477205\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046382; batch adversarial loss: 0.453882\n",
      "epoch 138; iter: 0; batch classifier loss: 0.042889; batch adversarial loss: 0.459694\n",
      "epoch 139; iter: 0; batch classifier loss: 0.063176; batch adversarial loss: 0.372428\n",
      "epoch 140; iter: 0; batch classifier loss: 0.079805; batch adversarial loss: 0.441290\n",
      "epoch 141; iter: 0; batch classifier loss: 0.064260; batch adversarial loss: 0.413060\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037640; batch adversarial loss: 0.450891\n",
      "epoch 143; iter: 0; batch classifier loss: 0.067908; batch adversarial loss: 0.403749\n",
      "epoch 144; iter: 0; batch classifier loss: 0.070352; batch adversarial loss: 0.443458\n",
      "epoch 145; iter: 0; batch classifier loss: 0.099664; batch adversarial loss: 0.442429\n",
      "epoch 146; iter: 0; batch classifier loss: 0.036644; batch adversarial loss: 0.314923\n",
      "epoch 147; iter: 0; batch classifier loss: 0.066425; batch adversarial loss: 0.392112\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038780; batch adversarial loss: 0.393672\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032848; batch adversarial loss: 0.362615\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028271; batch adversarial loss: 0.403021\n",
      "epoch 151; iter: 0; batch classifier loss: 0.087138; batch adversarial loss: 0.441213\n",
      "epoch 152; iter: 0; batch classifier loss: 0.050579; batch adversarial loss: 0.425921\n",
      "epoch 153; iter: 0; batch classifier loss: 0.052202; batch adversarial loss: 0.461097\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034681; batch adversarial loss: 0.383212\n",
      "epoch 155; iter: 0; batch classifier loss: 0.053912; batch adversarial loss: 0.367931\n",
      "epoch 156; iter: 0; batch classifier loss: 0.068434; batch adversarial loss: 0.504149\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040068; batch adversarial loss: 0.372462\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037476; batch adversarial loss: 0.370555\n",
      "epoch 159; iter: 0; batch classifier loss: 0.067307; batch adversarial loss: 0.444033\n",
      "epoch 160; iter: 0; batch classifier loss: 0.088205; batch adversarial loss: 0.432973\n",
      "epoch 161; iter: 0; batch classifier loss: 0.055767; batch adversarial loss: 0.378293\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029491; batch adversarial loss: 0.419857\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027305; batch adversarial loss: 0.470616\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033483; batch adversarial loss: 0.442432\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039932; batch adversarial loss: 0.467766\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029173; batch adversarial loss: 0.440562\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025588; batch adversarial loss: 0.481424\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030748; batch adversarial loss: 0.473446\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026959; batch adversarial loss: 0.494435\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021765; batch adversarial loss: 0.415775\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034350; batch adversarial loss: 0.492834\n",
      "epoch 172; iter: 0; batch classifier loss: 0.046391; batch adversarial loss: 0.359923\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022402; batch adversarial loss: 0.521041\n",
      "epoch 174; iter: 0; batch classifier loss: 0.060920; batch adversarial loss: 0.463656\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014700; batch adversarial loss: 0.379082\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016131; batch adversarial loss: 0.400304\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030365; batch adversarial loss: 0.560681\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028012; batch adversarial loss: 0.501474\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028863; batch adversarial loss: 0.367911\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033797; batch adversarial loss: 0.398859\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027192; batch adversarial loss: 0.442852\n",
      "epoch 182; iter: 0; batch classifier loss: 0.048172; batch adversarial loss: 0.580313\n",
      "epoch 183; iter: 0; batch classifier loss: 0.054390; batch adversarial loss: 0.500204\n",
      "epoch 184; iter: 0; batch classifier loss: 0.052837; batch adversarial loss: 0.369289\n",
      "epoch 185; iter: 0; batch classifier loss: 0.112586; batch adversarial loss: 0.675812\n",
      "epoch 186; iter: 0; batch classifier loss: 0.136699; batch adversarial loss: 0.805855\n",
      "epoch 187; iter: 0; batch classifier loss: 0.110499; batch adversarial loss: 0.561397\n",
      "epoch 188; iter: 0; batch classifier loss: 0.271752; batch adversarial loss: 0.751515\n",
      "epoch 189; iter: 0; batch classifier loss: 0.111251; batch adversarial loss: 0.642856\n",
      "epoch 190; iter: 0; batch classifier loss: 0.175002; batch adversarial loss: 0.660526\n",
      "epoch 191; iter: 0; batch classifier loss: 0.124804; batch adversarial loss: 0.561922\n",
      "epoch 192; iter: 0; batch classifier loss: 0.190608; batch adversarial loss: 0.819821\n",
      "epoch 193; iter: 0; batch classifier loss: 0.306268; batch adversarial loss: 0.843563\n",
      "epoch 194; iter: 0; batch classifier loss: 0.174326; batch adversarial loss: 0.765745\n",
      "epoch 195; iter: 0; batch classifier loss: 0.205300; batch adversarial loss: 0.742267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.200898; batch adversarial loss: 0.832839\n",
      "epoch 197; iter: 0; batch classifier loss: 0.207111; batch adversarial loss: 0.673808\n",
      "epoch 198; iter: 0; batch classifier loss: 0.158083; batch adversarial loss: 0.606562\n",
      "epoch 199; iter: 0; batch classifier loss: 0.189258; batch adversarial loss: 0.703842\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730964; batch adversarial loss: 0.631121\n",
      "epoch 1; iter: 0; batch classifier loss: 0.485640; batch adversarial loss: 0.622425\n",
      "epoch 2; iter: 0; batch classifier loss: 0.373462; batch adversarial loss: 0.572775\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374384; batch adversarial loss: 0.607236\n",
      "epoch 4; iter: 0; batch classifier loss: 0.404990; batch adversarial loss: 0.548950\n",
      "epoch 5; iter: 0; batch classifier loss: 0.372011; batch adversarial loss: 0.595951\n",
      "epoch 6; iter: 0; batch classifier loss: 0.300756; batch adversarial loss: 0.559778\n",
      "epoch 7; iter: 0; batch classifier loss: 0.409899; batch adversarial loss: 0.532423\n",
      "epoch 8; iter: 0; batch classifier loss: 0.308608; batch adversarial loss: 0.523705\n",
      "epoch 9; iter: 0; batch classifier loss: 0.268529; batch adversarial loss: 0.558535\n",
      "epoch 10; iter: 0; batch classifier loss: 0.257099; batch adversarial loss: 0.515484\n",
      "epoch 11; iter: 0; batch classifier loss: 0.354797; batch adversarial loss: 0.481243\n",
      "epoch 12; iter: 0; batch classifier loss: 0.270060; batch adversarial loss: 0.534960\n",
      "epoch 13; iter: 0; batch classifier loss: 0.268969; batch adversarial loss: 0.520493\n",
      "epoch 14; iter: 0; batch classifier loss: 0.217274; batch adversarial loss: 0.515508\n",
      "epoch 15; iter: 0; batch classifier loss: 0.319052; batch adversarial loss: 0.470880\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242851; batch adversarial loss: 0.485324\n",
      "epoch 17; iter: 0; batch classifier loss: 0.199159; batch adversarial loss: 0.390956\n",
      "epoch 18; iter: 0; batch classifier loss: 0.309638; batch adversarial loss: 0.516510\n",
      "epoch 19; iter: 0; batch classifier loss: 0.252231; batch adversarial loss: 0.480584\n",
      "epoch 20; iter: 0; batch classifier loss: 0.205499; batch adversarial loss: 0.554590\n",
      "epoch 21; iter: 0; batch classifier loss: 0.209818; batch adversarial loss: 0.444832\n",
      "epoch 22; iter: 0; batch classifier loss: 0.248289; batch adversarial loss: 0.435760\n",
      "epoch 23; iter: 0; batch classifier loss: 0.229300; batch adversarial loss: 0.455831\n",
      "epoch 24; iter: 0; batch classifier loss: 0.201632; batch adversarial loss: 0.506499\n",
      "epoch 25; iter: 0; batch classifier loss: 0.173273; batch adversarial loss: 0.459473\n",
      "epoch 26; iter: 0; batch classifier loss: 0.210110; batch adversarial loss: 0.449073\n",
      "epoch 27; iter: 0; batch classifier loss: 0.145581; batch adversarial loss: 0.544817\n",
      "epoch 28; iter: 0; batch classifier loss: 0.176759; batch adversarial loss: 0.546411\n",
      "epoch 29; iter: 0; batch classifier loss: 0.184845; batch adversarial loss: 0.479892\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153967; batch adversarial loss: 0.563093\n",
      "epoch 31; iter: 0; batch classifier loss: 0.202550; batch adversarial loss: 0.564718\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146214; batch adversarial loss: 0.408692\n",
      "epoch 33; iter: 0; batch classifier loss: 0.117299; batch adversarial loss: 0.497301\n",
      "epoch 34; iter: 0; batch classifier loss: 0.177276; batch adversarial loss: 0.439308\n",
      "epoch 35; iter: 0; batch classifier loss: 0.199772; batch adversarial loss: 0.461553\n",
      "epoch 36; iter: 0; batch classifier loss: 0.200355; batch adversarial loss: 0.436642\n",
      "epoch 37; iter: 0; batch classifier loss: 0.247421; batch adversarial loss: 0.367540\n",
      "epoch 38; iter: 0; batch classifier loss: 0.253809; batch adversarial loss: 0.438778\n",
      "epoch 39; iter: 0; batch classifier loss: 0.189080; batch adversarial loss: 0.415695\n",
      "epoch 40; iter: 0; batch classifier loss: 0.149929; batch adversarial loss: 0.491740\n",
      "epoch 41; iter: 0; batch classifier loss: 0.105474; batch adversarial loss: 0.470608\n",
      "epoch 42; iter: 0; batch classifier loss: 0.177001; batch adversarial loss: 0.426329\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150276; batch adversarial loss: 0.417175\n",
      "epoch 44; iter: 0; batch classifier loss: 0.209174; batch adversarial loss: 0.526375\n",
      "epoch 45; iter: 0; batch classifier loss: 0.188058; batch adversarial loss: 0.437268\n",
      "epoch 46; iter: 0; batch classifier loss: 0.175414; batch adversarial loss: 0.488349\n",
      "epoch 47; iter: 0; batch classifier loss: 0.145300; batch adversarial loss: 0.540746\n",
      "epoch 48; iter: 0; batch classifier loss: 0.186773; batch adversarial loss: 0.438349\n",
      "epoch 49; iter: 0; batch classifier loss: 0.182910; batch adversarial loss: 0.488543\n",
      "epoch 50; iter: 0; batch classifier loss: 0.169016; batch adversarial loss: 0.422226\n",
      "epoch 51; iter: 0; batch classifier loss: 0.191379; batch adversarial loss: 0.485221\n",
      "epoch 52; iter: 0; batch classifier loss: 0.212717; batch adversarial loss: 0.573180\n",
      "epoch 53; iter: 0; batch classifier loss: 0.148992; batch adversarial loss: 0.470506\n",
      "epoch 54; iter: 0; batch classifier loss: 0.123045; batch adversarial loss: 0.462331\n",
      "epoch 55; iter: 0; batch classifier loss: 0.175244; batch adversarial loss: 0.458518\n",
      "epoch 56; iter: 0; batch classifier loss: 0.123963; batch adversarial loss: 0.434071\n",
      "epoch 57; iter: 0; batch classifier loss: 0.258542; batch adversarial loss: 0.414880\n",
      "epoch 58; iter: 0; batch classifier loss: 0.158511; batch adversarial loss: 0.538938\n",
      "epoch 59; iter: 0; batch classifier loss: 0.232529; batch adversarial loss: 0.459678\n",
      "epoch 60; iter: 0; batch classifier loss: 0.192450; batch adversarial loss: 0.520974\n",
      "epoch 61; iter: 0; batch classifier loss: 0.131820; batch adversarial loss: 0.447180\n",
      "epoch 62; iter: 0; batch classifier loss: 0.200810; batch adversarial loss: 0.481547\n",
      "epoch 63; iter: 0; batch classifier loss: 0.189876; batch adversarial loss: 0.513098\n",
      "epoch 64; iter: 0; batch classifier loss: 0.221179; batch adversarial loss: 0.423629\n",
      "epoch 65; iter: 0; batch classifier loss: 0.139574; batch adversarial loss: 0.449824\n",
      "epoch 66; iter: 0; batch classifier loss: 0.127740; batch adversarial loss: 0.445586\n",
      "epoch 67; iter: 0; batch classifier loss: 0.218960; batch adversarial loss: 0.421103\n",
      "epoch 68; iter: 0; batch classifier loss: 0.206184; batch adversarial loss: 0.458518\n",
      "epoch 69; iter: 0; batch classifier loss: 0.133443; batch adversarial loss: 0.435570\n",
      "epoch 70; iter: 0; batch classifier loss: 0.191992; batch adversarial loss: 0.471740\n",
      "epoch 71; iter: 0; batch classifier loss: 0.142454; batch adversarial loss: 0.375436\n",
      "epoch 72; iter: 0; batch classifier loss: 0.148567; batch adversarial loss: 0.552300\n",
      "epoch 73; iter: 0; batch classifier loss: 0.191143; batch adversarial loss: 0.468309\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102758; batch adversarial loss: 0.568209\n",
      "epoch 75; iter: 0; batch classifier loss: 0.168436; batch adversarial loss: 0.480656\n",
      "epoch 76; iter: 0; batch classifier loss: 0.131836; batch adversarial loss: 0.457323\n",
      "epoch 77; iter: 0; batch classifier loss: 0.110696; batch adversarial loss: 0.330490\n",
      "epoch 78; iter: 0; batch classifier loss: 0.148128; batch adversarial loss: 0.514021\n",
      "epoch 79; iter: 0; batch classifier loss: 0.123046; batch adversarial loss: 0.501361\n",
      "epoch 80; iter: 0; batch classifier loss: 0.182284; batch adversarial loss: 0.517710\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120614; batch adversarial loss: 0.548967\n",
      "epoch 82; iter: 0; batch classifier loss: 0.138909; batch adversarial loss: 0.491677\n",
      "epoch 83; iter: 0; batch classifier loss: 0.122539; batch adversarial loss: 0.459915\n",
      "epoch 84; iter: 0; batch classifier loss: 0.121280; batch adversarial loss: 0.375044\n",
      "epoch 85; iter: 0; batch classifier loss: 0.103781; batch adversarial loss: 0.483153\n",
      "epoch 86; iter: 0; batch classifier loss: 0.115418; batch adversarial loss: 0.398419\n",
      "epoch 87; iter: 0; batch classifier loss: 0.102942; batch adversarial loss: 0.490205\n",
      "epoch 88; iter: 0; batch classifier loss: 0.142445; batch adversarial loss: 0.462944\n",
      "epoch 89; iter: 0; batch classifier loss: 0.082190; batch adversarial loss: 0.515772\n",
      "epoch 90; iter: 0; batch classifier loss: 0.116964; batch adversarial loss: 0.527263\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073565; batch adversarial loss: 0.393141\n",
      "epoch 92; iter: 0; batch classifier loss: 0.096032; batch adversarial loss: 0.430082\n",
      "epoch 93; iter: 0; batch classifier loss: 0.096776; batch adversarial loss: 0.420538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.110379; batch adversarial loss: 0.451392\n",
      "epoch 95; iter: 0; batch classifier loss: 0.090250; batch adversarial loss: 0.486836\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070715; batch adversarial loss: 0.466532\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057868; batch adversarial loss: 0.400527\n",
      "epoch 98; iter: 0; batch classifier loss: 0.088150; batch adversarial loss: 0.432874\n",
      "epoch 99; iter: 0; batch classifier loss: 0.070643; batch adversarial loss: 0.477165\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038895; batch adversarial loss: 0.453364\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058846; batch adversarial loss: 0.472240\n",
      "epoch 102; iter: 0; batch classifier loss: 0.109349; batch adversarial loss: 0.534742\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066711; batch adversarial loss: 0.432078\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037894; batch adversarial loss: 0.523614\n",
      "epoch 105; iter: 0; batch classifier loss: 0.026711; batch adversarial loss: 0.368978\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041505; batch adversarial loss: 0.424930\n",
      "epoch 107; iter: 0; batch classifier loss: 0.100588; batch adversarial loss: 0.371675\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070190; batch adversarial loss: 0.427329\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045112; batch adversarial loss: 0.544012\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048747; batch adversarial loss: 0.441992\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042441; batch adversarial loss: 0.466861\n",
      "epoch 112; iter: 0; batch classifier loss: 0.029100; batch adversarial loss: 0.478905\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055449; batch adversarial loss: 0.468468\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039114; batch adversarial loss: 0.527316\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046655; batch adversarial loss: 0.435082\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033942; batch adversarial loss: 0.437707\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043709; batch adversarial loss: 0.532532\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033059; batch adversarial loss: 0.444979\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032934; batch adversarial loss: 0.484124\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035918; batch adversarial loss: 0.521627\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049517; batch adversarial loss: 0.441490\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024158; batch adversarial loss: 0.495684\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036253; batch adversarial loss: 0.446439\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040430; batch adversarial loss: 0.420953\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039929; batch adversarial loss: 0.370396\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029695; batch adversarial loss: 0.539676\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044431; batch adversarial loss: 0.514265\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021335; batch adversarial loss: 0.547111\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020195; batch adversarial loss: 0.545374\n",
      "epoch 130; iter: 0; batch classifier loss: 0.058387; batch adversarial loss: 0.451601\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021533; batch adversarial loss: 0.448349\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041559; batch adversarial loss: 0.551953\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020705; batch adversarial loss: 0.379929\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040740; batch adversarial loss: 0.494900\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032117; batch adversarial loss: 0.448560\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025709; batch adversarial loss: 0.413992\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042018; batch adversarial loss: 0.582848\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022242; batch adversarial loss: 0.416640\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029659; batch adversarial loss: 0.470472\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032874; batch adversarial loss: 0.402480\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037476; batch adversarial loss: 0.465824\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044602; batch adversarial loss: 0.474510\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020140; batch adversarial loss: 0.435874\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049961; batch adversarial loss: 0.492285\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029879; batch adversarial loss: 0.421446\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028401; batch adversarial loss: 0.510781\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029290; batch adversarial loss: 0.511153\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015751; batch adversarial loss: 0.507893\n",
      "epoch 149; iter: 0; batch classifier loss: 0.010708; batch adversarial loss: 0.611300\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023964; batch adversarial loss: 0.461799\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019629; batch adversarial loss: 0.373319\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019169; batch adversarial loss: 0.443465\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015009; batch adversarial loss: 0.437975\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034363; batch adversarial loss: 0.394007\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014920; batch adversarial loss: 0.424562\n",
      "epoch 156; iter: 0; batch classifier loss: 0.009765; batch adversarial loss: 0.502552\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015264; batch adversarial loss: 0.407180\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018787; batch adversarial loss: 0.511206\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021822; batch adversarial loss: 0.436749\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023056; batch adversarial loss: 0.421934\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027128; batch adversarial loss: 0.437073\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013037; batch adversarial loss: 0.451422\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011160; batch adversarial loss: 0.457175\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025072; batch adversarial loss: 0.415943\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010950; batch adversarial loss: 0.461228\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029551; batch adversarial loss: 0.447644\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026306; batch adversarial loss: 0.451486\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019785; batch adversarial loss: 0.451961\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016826; batch adversarial loss: 0.444537\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013395; batch adversarial loss: 0.684791\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038043; batch adversarial loss: 0.499077\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035493; batch adversarial loss: 0.542604\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011969; batch adversarial loss: 0.472428\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021509; batch adversarial loss: 0.430091\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015187; batch adversarial loss: 0.513059\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014575; batch adversarial loss: 0.487423\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016520; batch adversarial loss: 0.349664\n",
      "epoch 178; iter: 0; batch classifier loss: 0.077365; batch adversarial loss: 0.496367\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023639; batch adversarial loss: 0.466389\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026332; batch adversarial loss: 0.487927\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024173; batch adversarial loss: 0.475174\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012203; batch adversarial loss: 0.365048\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016365; batch adversarial loss: 0.473090\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006258; batch adversarial loss: 0.475035\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022181; batch adversarial loss: 0.500311\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014996; batch adversarial loss: 0.404833\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007150; batch adversarial loss: 0.530156\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013456; batch adversarial loss: 0.446357\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009128; batch adversarial loss: 0.431082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.020762; batch adversarial loss: 0.379965\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013272; batch adversarial loss: 0.483357\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011745; batch adversarial loss: 0.460096\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025827; batch adversarial loss: 0.509547\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034099; batch adversarial loss: 0.496188\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024381; batch adversarial loss: 0.433721\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020820; batch adversarial loss: 0.497854\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011279; batch adversarial loss: 0.474725\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038511; batch adversarial loss: 0.436810\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018030; batch adversarial loss: 0.513608\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705576; batch adversarial loss: 0.562674\n",
      "epoch 1; iter: 0; batch classifier loss: 0.371818; batch adversarial loss: 0.600289\n",
      "epoch 2; iter: 0; batch classifier loss: 0.451567; batch adversarial loss: 0.603083\n",
      "epoch 3; iter: 0; batch classifier loss: 0.425734; batch adversarial loss: 0.562427\n",
      "epoch 4; iter: 0; batch classifier loss: 0.290538; batch adversarial loss: 0.567329\n",
      "epoch 5; iter: 0; batch classifier loss: 0.334554; batch adversarial loss: 0.553929\n",
      "epoch 6; iter: 0; batch classifier loss: 0.338594; batch adversarial loss: 0.536203\n",
      "epoch 7; iter: 0; batch classifier loss: 0.239633; batch adversarial loss: 0.542016\n",
      "epoch 8; iter: 0; batch classifier loss: 0.304773; batch adversarial loss: 0.535761\n",
      "epoch 9; iter: 0; batch classifier loss: 0.246409; batch adversarial loss: 0.480088\n",
      "epoch 10; iter: 0; batch classifier loss: 0.306562; batch adversarial loss: 0.544369\n",
      "epoch 11; iter: 0; batch classifier loss: 0.312633; batch adversarial loss: 0.532631\n",
      "epoch 12; iter: 0; batch classifier loss: 0.181906; batch adversarial loss: 0.497381\n",
      "epoch 13; iter: 0; batch classifier loss: 0.251737; batch adversarial loss: 0.535659\n",
      "epoch 14; iter: 0; batch classifier loss: 0.251916; batch adversarial loss: 0.547211\n",
      "epoch 15; iter: 0; batch classifier loss: 0.216099; batch adversarial loss: 0.617019\n",
      "epoch 16; iter: 0; batch classifier loss: 0.302988; batch adversarial loss: 0.542075\n",
      "epoch 17; iter: 0; batch classifier loss: 0.304839; batch adversarial loss: 0.463218\n",
      "epoch 18; iter: 0; batch classifier loss: 0.372036; batch adversarial loss: 0.493788\n",
      "epoch 19; iter: 0; batch classifier loss: 0.456973; batch adversarial loss: 0.498279\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475825; batch adversarial loss: 0.561920\n",
      "epoch 21; iter: 0; batch classifier loss: 0.356506; batch adversarial loss: 0.434461\n",
      "epoch 22; iter: 0; batch classifier loss: 0.194207; batch adversarial loss: 0.483352\n",
      "epoch 23; iter: 0; batch classifier loss: 0.167380; batch adversarial loss: 0.484318\n",
      "epoch 24; iter: 0; batch classifier loss: 0.171807; batch adversarial loss: 0.424434\n",
      "epoch 25; iter: 0; batch classifier loss: 0.178662; batch adversarial loss: 0.388319\n",
      "epoch 26; iter: 0; batch classifier loss: 0.163452; batch adversarial loss: 0.436000\n",
      "epoch 27; iter: 0; batch classifier loss: 0.146680; batch adversarial loss: 0.496785\n",
      "epoch 28; iter: 0; batch classifier loss: 0.137127; batch adversarial loss: 0.421549\n",
      "epoch 29; iter: 0; batch classifier loss: 0.130639; batch adversarial loss: 0.363714\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167772; batch adversarial loss: 0.332261\n",
      "epoch 31; iter: 0; batch classifier loss: 0.126481; batch adversarial loss: 0.409768\n",
      "epoch 32; iter: 0; batch classifier loss: 0.139012; batch adversarial loss: 0.506742\n",
      "epoch 33; iter: 0; batch classifier loss: 0.106496; batch adversarial loss: 0.450836\n",
      "epoch 34; iter: 0; batch classifier loss: 0.110115; batch adversarial loss: 0.441224\n",
      "epoch 35; iter: 0; batch classifier loss: 0.090757; batch adversarial loss: 0.464180\n",
      "epoch 36; iter: 0; batch classifier loss: 0.107751; batch adversarial loss: 0.409873\n",
      "epoch 37; iter: 0; batch classifier loss: 0.107189; batch adversarial loss: 0.541805\n",
      "epoch 38; iter: 0; batch classifier loss: 0.137103; batch adversarial loss: 0.489243\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106101; batch adversarial loss: 0.384773\n",
      "epoch 40; iter: 0; batch classifier loss: 0.089084; batch adversarial loss: 0.432265\n",
      "epoch 41; iter: 0; batch classifier loss: 0.117350; batch adversarial loss: 0.463651\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116322; batch adversarial loss: 0.487885\n",
      "epoch 43; iter: 0; batch classifier loss: 0.072295; batch adversarial loss: 0.489001\n",
      "epoch 44; iter: 0; batch classifier loss: 0.068134; batch adversarial loss: 0.534644\n",
      "epoch 45; iter: 0; batch classifier loss: 0.094964; batch adversarial loss: 0.449575\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116118; batch adversarial loss: 0.396408\n",
      "epoch 47; iter: 0; batch classifier loss: 0.078069; batch adversarial loss: 0.467179\n",
      "epoch 48; iter: 0; batch classifier loss: 0.065961; batch adversarial loss: 0.406795\n",
      "epoch 49; iter: 0; batch classifier loss: 0.066762; batch adversarial loss: 0.461656\n",
      "epoch 50; iter: 0; batch classifier loss: 0.126287; batch adversarial loss: 0.465723\n",
      "epoch 51; iter: 0; batch classifier loss: 0.086888; batch adversarial loss: 0.355118\n",
      "epoch 52; iter: 0; batch classifier loss: 0.065245; batch adversarial loss: 0.415009\n",
      "epoch 53; iter: 0; batch classifier loss: 0.099011; batch adversarial loss: 0.445895\n",
      "epoch 54; iter: 0; batch classifier loss: 0.075937; batch adversarial loss: 0.515496\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087610; batch adversarial loss: 0.509154\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067597; batch adversarial loss: 0.387817\n",
      "epoch 57; iter: 0; batch classifier loss: 0.099392; batch adversarial loss: 0.482671\n",
      "epoch 58; iter: 0; batch classifier loss: 0.065005; batch adversarial loss: 0.374023\n",
      "epoch 59; iter: 0; batch classifier loss: 0.124372; batch adversarial loss: 0.424255\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086670; batch adversarial loss: 0.405730\n",
      "epoch 61; iter: 0; batch classifier loss: 0.108938; batch adversarial loss: 0.519408\n",
      "epoch 62; iter: 0; batch classifier loss: 0.053681; batch adversarial loss: 0.421119\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104757; batch adversarial loss: 0.380861\n",
      "epoch 64; iter: 0; batch classifier loss: 0.087964; batch adversarial loss: 0.591179\n",
      "epoch 65; iter: 0; batch classifier loss: 0.104709; batch adversarial loss: 0.501718\n",
      "epoch 66; iter: 0; batch classifier loss: 0.069961; batch adversarial loss: 0.461635\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091381; batch adversarial loss: 0.601747\n",
      "epoch 68; iter: 0; batch classifier loss: 0.131472; batch adversarial loss: 0.516468\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070588; batch adversarial loss: 0.510920\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098362; batch adversarial loss: 0.488893\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063038; batch adversarial loss: 0.455143\n",
      "epoch 72; iter: 0; batch classifier loss: 0.103148; batch adversarial loss: 0.462239\n",
      "epoch 73; iter: 0; batch classifier loss: 0.132645; batch adversarial loss: 0.479584\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076763; batch adversarial loss: 0.429804\n",
      "epoch 75; iter: 0; batch classifier loss: 0.081791; batch adversarial loss: 0.490684\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072832; batch adversarial loss: 0.474189\n",
      "epoch 77; iter: 0; batch classifier loss: 0.109943; batch adversarial loss: 0.549992\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075758; batch adversarial loss: 0.496199\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080297; batch adversarial loss: 0.433556\n",
      "epoch 80; iter: 0; batch classifier loss: 0.125419; batch adversarial loss: 0.434949\n",
      "epoch 81; iter: 0; batch classifier loss: 0.092636; batch adversarial loss: 0.486646\n",
      "epoch 82; iter: 0; batch classifier loss: 0.084083; batch adversarial loss: 0.425507\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067339; batch adversarial loss: 0.492025\n",
      "epoch 84; iter: 0; batch classifier loss: 0.036680; batch adversarial loss: 0.482962\n",
      "epoch 85; iter: 0; batch classifier loss: 0.063566; batch adversarial loss: 0.530338\n",
      "epoch 86; iter: 0; batch classifier loss: 0.034217; batch adversarial loss: 0.438498\n",
      "epoch 87; iter: 0; batch classifier loss: 0.040581; batch adversarial loss: 0.408500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.075344; batch adversarial loss: 0.585939\n",
      "epoch 89; iter: 0; batch classifier loss: 0.070934; batch adversarial loss: 0.378205\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087346; batch adversarial loss: 0.471069\n",
      "epoch 91; iter: 0; batch classifier loss: 0.096218; batch adversarial loss: 0.455667\n",
      "epoch 92; iter: 0; batch classifier loss: 0.056935; batch adversarial loss: 0.474635\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049573; batch adversarial loss: 0.493618\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051052; batch adversarial loss: 0.473703\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055303; batch adversarial loss: 0.381751\n",
      "epoch 96; iter: 0; batch classifier loss: 0.123156; batch adversarial loss: 0.475202\n",
      "epoch 97; iter: 0; batch classifier loss: 0.067637; batch adversarial loss: 0.411840\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063524; batch adversarial loss: 0.451437\n",
      "epoch 99; iter: 0; batch classifier loss: 0.072201; batch adversarial loss: 0.409799\n",
      "epoch 100; iter: 0; batch classifier loss: 0.109610; batch adversarial loss: 0.457379\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049392; batch adversarial loss: 0.480231\n",
      "epoch 102; iter: 0; batch classifier loss: 0.097928; batch adversarial loss: 0.417480\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044091; batch adversarial loss: 0.544060\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037922; batch adversarial loss: 0.486018\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060879; batch adversarial loss: 0.399965\n",
      "epoch 106; iter: 0; batch classifier loss: 0.038561; batch adversarial loss: 0.442996\n",
      "epoch 107; iter: 0; batch classifier loss: 0.084317; batch adversarial loss: 0.510575\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036929; batch adversarial loss: 0.465526\n",
      "epoch 109; iter: 0; batch classifier loss: 0.052811; batch adversarial loss: 0.521598\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035638; batch adversarial loss: 0.485032\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053214; batch adversarial loss: 0.411070\n",
      "epoch 112; iter: 0; batch classifier loss: 0.070790; batch adversarial loss: 0.404968\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054560; batch adversarial loss: 0.522526\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046971; batch adversarial loss: 0.543946\n",
      "epoch 115; iter: 0; batch classifier loss: 0.030046; batch adversarial loss: 0.403731\n",
      "epoch 116; iter: 0; batch classifier loss: 0.049439; batch adversarial loss: 0.409149\n",
      "epoch 117; iter: 0; batch classifier loss: 0.068199; batch adversarial loss: 0.444485\n",
      "epoch 118; iter: 0; batch classifier loss: 0.022537; batch adversarial loss: 0.408996\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048373; batch adversarial loss: 0.497132\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025690; batch adversarial loss: 0.433162\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053091; batch adversarial loss: 0.483125\n",
      "epoch 122; iter: 0; batch classifier loss: 0.056370; batch adversarial loss: 0.438466\n",
      "epoch 123; iter: 0; batch classifier loss: 0.080555; batch adversarial loss: 0.445230\n",
      "epoch 124; iter: 0; batch classifier loss: 0.063966; batch adversarial loss: 0.428809\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027210; batch adversarial loss: 0.435186\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043149; batch adversarial loss: 0.468594\n",
      "epoch 127; iter: 0; batch classifier loss: 0.080803; batch adversarial loss: 0.532596\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061846; batch adversarial loss: 0.482699\n",
      "epoch 129; iter: 0; batch classifier loss: 0.053117; batch adversarial loss: 0.427007\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057661; batch adversarial loss: 0.427438\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035377; batch adversarial loss: 0.398534\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050598; batch adversarial loss: 0.427002\n",
      "epoch 133; iter: 0; batch classifier loss: 0.066270; batch adversarial loss: 0.482223\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062178; batch adversarial loss: 0.382635\n",
      "epoch 135; iter: 0; batch classifier loss: 0.065540; batch adversarial loss: 0.528448\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027293; batch adversarial loss: 0.388607\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031240; batch adversarial loss: 0.446049\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048085; batch adversarial loss: 0.475038\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040828; batch adversarial loss: 0.444775\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033769; batch adversarial loss: 0.511162\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050156; batch adversarial loss: 0.505009\n",
      "epoch 142; iter: 0; batch classifier loss: 0.057327; batch adversarial loss: 0.435142\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040212; batch adversarial loss: 0.500842\n",
      "epoch 144; iter: 0; batch classifier loss: 0.043723; batch adversarial loss: 0.470451\n",
      "epoch 145; iter: 0; batch classifier loss: 0.059044; batch adversarial loss: 0.476539\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033397; batch adversarial loss: 0.440439\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039315; batch adversarial loss: 0.547427\n",
      "epoch 148; iter: 0; batch classifier loss: 0.059628; batch adversarial loss: 0.373977\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034196; batch adversarial loss: 0.455998\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043956; batch adversarial loss: 0.429180\n",
      "epoch 151; iter: 0; batch classifier loss: 0.058247; batch adversarial loss: 0.432417\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027814; batch adversarial loss: 0.450937\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023548; batch adversarial loss: 0.551930\n",
      "epoch 154; iter: 0; batch classifier loss: 0.066998; batch adversarial loss: 0.414631\n",
      "epoch 155; iter: 0; batch classifier loss: 0.056882; batch adversarial loss: 0.449821\n",
      "epoch 156; iter: 0; batch classifier loss: 0.083255; batch adversarial loss: 0.442024\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015382; batch adversarial loss: 0.405656\n",
      "epoch 158; iter: 0; batch classifier loss: 0.039055; batch adversarial loss: 0.491200\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015944; batch adversarial loss: 0.501338\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031066; batch adversarial loss: 0.453363\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031664; batch adversarial loss: 0.383658\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028956; batch adversarial loss: 0.345452\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036703; batch adversarial loss: 0.429032\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024665; batch adversarial loss: 0.452258\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028149; batch adversarial loss: 0.481205\n",
      "epoch 166; iter: 0; batch classifier loss: 0.060611; batch adversarial loss: 0.390770\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039893; batch adversarial loss: 0.530749\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031165; batch adversarial loss: 0.398504\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038647; batch adversarial loss: 0.377476\n",
      "epoch 170; iter: 0; batch classifier loss: 0.005927; batch adversarial loss: 0.402194\n",
      "epoch 171; iter: 0; batch classifier loss: 0.042228; batch adversarial loss: 0.581521\n",
      "epoch 172; iter: 0; batch classifier loss: 0.063117; batch adversarial loss: 0.419667\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020234; batch adversarial loss: 0.434565\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016196; batch adversarial loss: 0.448484\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023267; batch adversarial loss: 0.421884\n",
      "epoch 176; iter: 0; batch classifier loss: 0.051080; batch adversarial loss: 0.420946\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031372; batch adversarial loss: 0.409121\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019967; batch adversarial loss: 0.488635\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025958; batch adversarial loss: 0.501275\n",
      "epoch 180; iter: 0; batch classifier loss: 0.044321; batch adversarial loss: 0.430935\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016628; batch adversarial loss: 0.513410\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006292; batch adversarial loss: 0.494835\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027023; batch adversarial loss: 0.521440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.055085; batch adversarial loss: 0.408774\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018232; batch adversarial loss: 0.426781\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022674; batch adversarial loss: 0.516295\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011376; batch adversarial loss: 0.442779\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032475; batch adversarial loss: 0.458551\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035753; batch adversarial loss: 0.465825\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022128; batch adversarial loss: 0.313787\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014048; batch adversarial loss: 0.477381\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017566; batch adversarial loss: 0.521544\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021226; batch adversarial loss: 0.421348\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020682; batch adversarial loss: 0.446174\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015837; batch adversarial loss: 0.412465\n",
      "epoch 196; iter: 0; batch classifier loss: 0.064415; batch adversarial loss: 0.491620\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008640; batch adversarial loss: 0.541251\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018259; batch adversarial loss: 0.478151\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021713; batch adversarial loss: 0.465618\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687096; batch adversarial loss: 0.666809\n",
      "epoch 1; iter: 0; batch classifier loss: 0.403377; batch adversarial loss: 0.643085\n",
      "epoch 2; iter: 0; batch classifier loss: 0.409066; batch adversarial loss: 0.627798\n",
      "epoch 3; iter: 0; batch classifier loss: 0.373782; batch adversarial loss: 0.584733\n",
      "epoch 4; iter: 0; batch classifier loss: 0.385658; batch adversarial loss: 0.564333\n",
      "epoch 5; iter: 0; batch classifier loss: 0.325121; batch adversarial loss: 0.568235\n",
      "epoch 6; iter: 0; batch classifier loss: 0.292894; batch adversarial loss: 0.513526\n",
      "epoch 7; iter: 0; batch classifier loss: 0.312108; batch adversarial loss: 0.519679\n",
      "epoch 8; iter: 0; batch classifier loss: 0.250251; batch adversarial loss: 0.533909\n",
      "epoch 9; iter: 0; batch classifier loss: 0.219850; batch adversarial loss: 0.528536\n",
      "epoch 10; iter: 0; batch classifier loss: 0.257705; batch adversarial loss: 0.536895\n",
      "epoch 11; iter: 0; batch classifier loss: 0.303186; batch adversarial loss: 0.524364\n",
      "epoch 12; iter: 0; batch classifier loss: 0.430053; batch adversarial loss: 0.524360\n",
      "epoch 13; iter: 0; batch classifier loss: 0.330622; batch adversarial loss: 0.527666\n",
      "epoch 14; iter: 0; batch classifier loss: 0.341248; batch adversarial loss: 0.565852\n",
      "epoch 15; iter: 0; batch classifier loss: 0.358583; batch adversarial loss: 0.574777\n",
      "epoch 16; iter: 0; batch classifier loss: 0.352771; batch adversarial loss: 0.534899\n",
      "epoch 17; iter: 0; batch classifier loss: 0.637930; batch adversarial loss: 0.480122\n",
      "epoch 18; iter: 0; batch classifier loss: 0.619014; batch adversarial loss: 0.483183\n",
      "epoch 19; iter: 0; batch classifier loss: 0.319586; batch adversarial loss: 0.476079\n",
      "epoch 20; iter: 0; batch classifier loss: 0.262205; batch adversarial loss: 0.446237\n",
      "epoch 21; iter: 0; batch classifier loss: 0.173532; batch adversarial loss: 0.471503\n",
      "epoch 22; iter: 0; batch classifier loss: 0.162964; batch adversarial loss: 0.452568\n",
      "epoch 23; iter: 0; batch classifier loss: 0.191997; batch adversarial loss: 0.484102\n",
      "epoch 24; iter: 0; batch classifier loss: 0.177559; batch adversarial loss: 0.495812\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148122; batch adversarial loss: 0.479449\n",
      "epoch 26; iter: 0; batch classifier loss: 0.162057; batch adversarial loss: 0.450711\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175430; batch adversarial loss: 0.512234\n",
      "epoch 28; iter: 0; batch classifier loss: 0.148138; batch adversarial loss: 0.445271\n",
      "epoch 29; iter: 0; batch classifier loss: 0.118995; batch adversarial loss: 0.451729\n",
      "epoch 30; iter: 0; batch classifier loss: 0.103150; batch adversarial loss: 0.522523\n",
      "epoch 31; iter: 0; batch classifier loss: 0.153855; batch adversarial loss: 0.422466\n",
      "epoch 32; iter: 0; batch classifier loss: 0.142836; batch adversarial loss: 0.466621\n",
      "epoch 33; iter: 0; batch classifier loss: 0.207169; batch adversarial loss: 0.432866\n",
      "epoch 34; iter: 0; batch classifier loss: 0.183124; batch adversarial loss: 0.349900\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125869; batch adversarial loss: 0.407588\n",
      "epoch 36; iter: 0; batch classifier loss: 0.183248; batch adversarial loss: 0.518187\n",
      "epoch 37; iter: 0; batch classifier loss: 0.130241; batch adversarial loss: 0.506977\n",
      "epoch 38; iter: 0; batch classifier loss: 0.116314; batch adversarial loss: 0.470513\n",
      "epoch 39; iter: 0; batch classifier loss: 0.190633; batch adversarial loss: 0.578758\n",
      "epoch 40; iter: 0; batch classifier loss: 0.083371; batch adversarial loss: 0.496639\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109676; batch adversarial loss: 0.509509\n",
      "epoch 42; iter: 0; batch classifier loss: 0.133127; batch adversarial loss: 0.460979\n",
      "epoch 43; iter: 0; batch classifier loss: 0.092380; batch adversarial loss: 0.465667\n",
      "epoch 44; iter: 0; batch classifier loss: 0.153045; batch adversarial loss: 0.481291\n",
      "epoch 45; iter: 0; batch classifier loss: 0.094696; batch adversarial loss: 0.423939\n",
      "epoch 46; iter: 0; batch classifier loss: 0.084982; batch adversarial loss: 0.459597\n",
      "epoch 47; iter: 0; batch classifier loss: 0.116580; batch adversarial loss: 0.525136\n",
      "epoch 48; iter: 0; batch classifier loss: 0.146047; batch adversarial loss: 0.403914\n",
      "epoch 49; iter: 0; batch classifier loss: 0.144258; batch adversarial loss: 0.394781\n",
      "epoch 50; iter: 0; batch classifier loss: 0.097236; batch adversarial loss: 0.478171\n",
      "epoch 51; iter: 0; batch classifier loss: 0.057922; batch adversarial loss: 0.480436\n",
      "epoch 52; iter: 0; batch classifier loss: 0.063206; batch adversarial loss: 0.394329\n",
      "epoch 53; iter: 0; batch classifier loss: 0.089635; batch adversarial loss: 0.480645\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116122; batch adversarial loss: 0.352980\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117829; batch adversarial loss: 0.440666\n",
      "epoch 56; iter: 0; batch classifier loss: 0.060223; batch adversarial loss: 0.412493\n",
      "epoch 57; iter: 0; batch classifier loss: 0.088995; batch adversarial loss: 0.514439\n",
      "epoch 58; iter: 0; batch classifier loss: 0.059200; batch adversarial loss: 0.499051\n",
      "epoch 59; iter: 0; batch classifier loss: 0.060262; batch adversarial loss: 0.425191\n",
      "epoch 60; iter: 0; batch classifier loss: 0.123145; batch adversarial loss: 0.377348\n",
      "epoch 61; iter: 0; batch classifier loss: 0.130225; batch adversarial loss: 0.522780\n",
      "epoch 62; iter: 0; batch classifier loss: 0.107164; batch adversarial loss: 0.444466\n",
      "epoch 63; iter: 0; batch classifier loss: 0.061726; batch adversarial loss: 0.428291\n",
      "epoch 64; iter: 0; batch classifier loss: 0.095673; batch adversarial loss: 0.462357\n",
      "epoch 65; iter: 0; batch classifier loss: 0.069545; batch adversarial loss: 0.484336\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093384; batch adversarial loss: 0.508672\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065706; batch adversarial loss: 0.522102\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071889; batch adversarial loss: 0.385609\n",
      "epoch 69; iter: 0; batch classifier loss: 0.128537; batch adversarial loss: 0.486056\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103891; batch adversarial loss: 0.468561\n",
      "epoch 71; iter: 0; batch classifier loss: 0.103094; batch adversarial loss: 0.495637\n",
      "epoch 72; iter: 0; batch classifier loss: 0.102985; batch adversarial loss: 0.393305\n",
      "epoch 73; iter: 0; batch classifier loss: 0.080000; batch adversarial loss: 0.438657\n",
      "epoch 74; iter: 0; batch classifier loss: 0.136652; batch adversarial loss: 0.475475\n",
      "epoch 75; iter: 0; batch classifier loss: 0.101017; batch adversarial loss: 0.551256\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076474; batch adversarial loss: 0.483577\n",
      "epoch 77; iter: 0; batch classifier loss: 0.048497; batch adversarial loss: 0.551298\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062976; batch adversarial loss: 0.392586\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065794; batch adversarial loss: 0.467874\n",
      "epoch 80; iter: 0; batch classifier loss: 0.072836; batch adversarial loss: 0.501823\n",
      "epoch 81; iter: 0; batch classifier loss: 0.063516; batch adversarial loss: 0.480270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.094730; batch adversarial loss: 0.388519\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086146; batch adversarial loss: 0.474934\n",
      "epoch 84; iter: 0; batch classifier loss: 0.078144; batch adversarial loss: 0.354374\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045294; batch adversarial loss: 0.485612\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066120; batch adversarial loss: 0.524787\n",
      "epoch 87; iter: 0; batch classifier loss: 0.033133; batch adversarial loss: 0.481030\n",
      "epoch 88; iter: 0; batch classifier loss: 0.043172; batch adversarial loss: 0.524619\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056674; batch adversarial loss: 0.403173\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050118; batch adversarial loss: 0.450774\n",
      "epoch 91; iter: 0; batch classifier loss: 0.072190; batch adversarial loss: 0.398320\n",
      "epoch 92; iter: 0; batch classifier loss: 0.033742; batch adversarial loss: 0.421661\n",
      "epoch 93; iter: 0; batch classifier loss: 0.084898; batch adversarial loss: 0.465185\n",
      "epoch 94; iter: 0; batch classifier loss: 0.074004; batch adversarial loss: 0.386598\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039868; batch adversarial loss: 0.563273\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051609; batch adversarial loss: 0.430216\n",
      "epoch 97; iter: 0; batch classifier loss: 0.095846; batch adversarial loss: 0.375656\n",
      "epoch 98; iter: 0; batch classifier loss: 0.024430; batch adversarial loss: 0.352364\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064472; batch adversarial loss: 0.412917\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038157; batch adversarial loss: 0.450546\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054345; batch adversarial loss: 0.419440\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052955; batch adversarial loss: 0.531020\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076547; batch adversarial loss: 0.443891\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037242; batch adversarial loss: 0.532914\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046208; batch adversarial loss: 0.523283\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063207; batch adversarial loss: 0.441960\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062156; batch adversarial loss: 0.353487\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040686; batch adversarial loss: 0.501235\n",
      "epoch 109; iter: 0; batch classifier loss: 0.075453; batch adversarial loss: 0.414895\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036207; batch adversarial loss: 0.536481\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058143; batch adversarial loss: 0.471298\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026583; batch adversarial loss: 0.380993\n",
      "epoch 113; iter: 0; batch classifier loss: 0.013404; batch adversarial loss: 0.424817\n",
      "epoch 114; iter: 0; batch classifier loss: 0.071525; batch adversarial loss: 0.399574\n",
      "epoch 115; iter: 0; batch classifier loss: 0.055459; batch adversarial loss: 0.364539\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030826; batch adversarial loss: 0.409989\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035666; batch adversarial loss: 0.481128\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053883; batch adversarial loss: 0.459343\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034140; batch adversarial loss: 0.382583\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032353; batch adversarial loss: 0.472876\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043248; batch adversarial loss: 0.379761\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038268; batch adversarial loss: 0.390111\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041931; batch adversarial loss: 0.405500\n",
      "epoch 124; iter: 0; batch classifier loss: 0.028881; batch adversarial loss: 0.530513\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049142; batch adversarial loss: 0.418117\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043839; batch adversarial loss: 0.449591\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033604; batch adversarial loss: 0.419642\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031963; batch adversarial loss: 0.503414\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027030; batch adversarial loss: 0.420524\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018080; batch adversarial loss: 0.497757\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024254; batch adversarial loss: 0.404334\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022888; batch adversarial loss: 0.451926\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027741; batch adversarial loss: 0.465639\n",
      "epoch 134; iter: 0; batch classifier loss: 0.065591; batch adversarial loss: 0.498956\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028764; batch adversarial loss: 0.460898\n",
      "epoch 136; iter: 0; batch classifier loss: 0.099921; batch adversarial loss: 0.415422\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046865; batch adversarial loss: 0.480397\n",
      "epoch 138; iter: 0; batch classifier loss: 0.070841; batch adversarial loss: 0.460005\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028257; batch adversarial loss: 0.486013\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045054; batch adversarial loss: 0.522901\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018137; batch adversarial loss: 0.494783\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034836; batch adversarial loss: 0.381028\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035203; batch adversarial loss: 0.369248\n",
      "epoch 144; iter: 0; batch classifier loss: 0.057834; batch adversarial loss: 0.394682\n",
      "epoch 145; iter: 0; batch classifier loss: 0.009053; batch adversarial loss: 0.450838\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022537; batch adversarial loss: 0.362250\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010417; batch adversarial loss: 0.449520\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026787; batch adversarial loss: 0.433833\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035499; batch adversarial loss: 0.440546\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031469; batch adversarial loss: 0.470843\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017031; batch adversarial loss: 0.416426\n",
      "epoch 152; iter: 0; batch classifier loss: 0.060557; batch adversarial loss: 0.518476\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028859; batch adversarial loss: 0.457746\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034553; batch adversarial loss: 0.391651\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020478; batch adversarial loss: 0.556342\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037992; batch adversarial loss: 0.448249\n",
      "epoch 157; iter: 0; batch classifier loss: 0.050465; batch adversarial loss: 0.383845\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011703; batch adversarial loss: 0.471847\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022165; batch adversarial loss: 0.533716\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033492; batch adversarial loss: 0.358945\n",
      "epoch 161; iter: 0; batch classifier loss: 0.062471; batch adversarial loss: 0.406748\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043667; batch adversarial loss: 0.425088\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028681; batch adversarial loss: 0.448608\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036788; batch adversarial loss: 0.437322\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031129; batch adversarial loss: 0.421317\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033439; batch adversarial loss: 0.381101\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039735; batch adversarial loss: 0.472897\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019697; batch adversarial loss: 0.465302\n",
      "epoch 169; iter: 0; batch classifier loss: 0.048367; batch adversarial loss: 0.523296\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012293; batch adversarial loss: 0.467026\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017743; batch adversarial loss: 0.398308\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005894; batch adversarial loss: 0.462656\n",
      "epoch 173; iter: 0; batch classifier loss: 0.052699; batch adversarial loss: 0.474351\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033454; batch adversarial loss: 0.415668\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023922; batch adversarial loss: 0.417081\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023739; batch adversarial loss: 0.442307\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021015; batch adversarial loss: 0.468652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.028247; batch adversarial loss: 0.542368\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023713; batch adversarial loss: 0.520217\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041456; batch adversarial loss: 0.325744\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028285; batch adversarial loss: 0.452114\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029864; batch adversarial loss: 0.501748\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015080; batch adversarial loss: 0.653218\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020989; batch adversarial loss: 0.518771\n",
      "epoch 185; iter: 0; batch classifier loss: 0.046156; batch adversarial loss: 0.357202\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031877; batch adversarial loss: 0.537131\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024069; batch adversarial loss: 0.375797\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021501; batch adversarial loss: 0.474732\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032082; batch adversarial loss: 0.547874\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009083; batch adversarial loss: 0.427746\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030857; batch adversarial loss: 0.387621\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022784; batch adversarial loss: 0.441589\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013408; batch adversarial loss: 0.514334\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028623; batch adversarial loss: 0.474794\n",
      "epoch 195; iter: 0; batch classifier loss: 0.061583; batch adversarial loss: 0.413887\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017527; batch adversarial loss: 0.436093\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018616; batch adversarial loss: 0.433373\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025448; batch adversarial loss: 0.483594\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007637; batch adversarial loss: 0.475678\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682178; batch adversarial loss: 0.920984\n",
      "epoch 1; iter: 0; batch classifier loss: 0.813895; batch adversarial loss: 1.163921\n",
      "epoch 2; iter: 0; batch classifier loss: 0.959677; batch adversarial loss: 1.162239\n",
      "epoch 3; iter: 0; batch classifier loss: 0.900511; batch adversarial loss: 0.982078\n",
      "epoch 4; iter: 0; batch classifier loss: 1.016350; batch adversarial loss: 0.979478\n",
      "epoch 5; iter: 0; batch classifier loss: 0.817334; batch adversarial loss: 0.843126\n",
      "epoch 6; iter: 0; batch classifier loss: 0.856320; batch adversarial loss: 0.775116\n",
      "epoch 7; iter: 0; batch classifier loss: 0.719213; batch adversarial loss: 0.731598\n",
      "epoch 8; iter: 0; batch classifier loss: 0.751790; batch adversarial loss: 0.719426\n",
      "epoch 9; iter: 0; batch classifier loss: 0.597701; batch adversarial loss: 0.628019\n",
      "epoch 10; iter: 0; batch classifier loss: 0.563433; batch adversarial loss: 0.583935\n",
      "epoch 11; iter: 0; batch classifier loss: 0.441874; batch adversarial loss: 0.528554\n",
      "epoch 12; iter: 0; batch classifier loss: 0.317520; batch adversarial loss: 0.610445\n",
      "epoch 13; iter: 0; batch classifier loss: 0.258959; batch adversarial loss: 0.527525\n",
      "epoch 14; iter: 0; batch classifier loss: 0.242806; batch adversarial loss: 0.546956\n",
      "epoch 15; iter: 0; batch classifier loss: 0.258931; batch adversarial loss: 0.463707\n",
      "epoch 16; iter: 0; batch classifier loss: 0.283566; batch adversarial loss: 0.474991\n",
      "epoch 17; iter: 0; batch classifier loss: 0.239604; batch adversarial loss: 0.432920\n",
      "epoch 18; iter: 0; batch classifier loss: 0.183556; batch adversarial loss: 0.525010\n",
      "epoch 19; iter: 0; batch classifier loss: 0.317375; batch adversarial loss: 0.469736\n",
      "epoch 20; iter: 0; batch classifier loss: 0.223689; batch adversarial loss: 0.602989\n",
      "epoch 21; iter: 0; batch classifier loss: 0.248605; batch adversarial loss: 0.528351\n",
      "epoch 22; iter: 0; batch classifier loss: 0.223488; batch adversarial loss: 0.441440\n",
      "epoch 23; iter: 0; batch classifier loss: 0.214297; batch adversarial loss: 0.412169\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182411; batch adversarial loss: 0.519134\n",
      "epoch 25; iter: 0; batch classifier loss: 0.161344; batch adversarial loss: 0.475411\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188905; batch adversarial loss: 0.452346\n",
      "epoch 27; iter: 0; batch classifier loss: 0.208318; batch adversarial loss: 0.459191\n",
      "epoch 28; iter: 0; batch classifier loss: 0.226387; batch adversarial loss: 0.476889\n",
      "epoch 29; iter: 0; batch classifier loss: 0.184060; batch adversarial loss: 0.475972\n",
      "epoch 30; iter: 0; batch classifier loss: 0.201692; batch adversarial loss: 0.532659\n",
      "epoch 31; iter: 0; batch classifier loss: 0.147701; batch adversarial loss: 0.455665\n",
      "epoch 32; iter: 0; batch classifier loss: 0.167697; batch adversarial loss: 0.363017\n",
      "epoch 33; iter: 0; batch classifier loss: 0.215721; batch adversarial loss: 0.423360\n",
      "epoch 34; iter: 0; batch classifier loss: 0.138884; batch adversarial loss: 0.448447\n",
      "epoch 35; iter: 0; batch classifier loss: 0.165670; batch adversarial loss: 0.449975\n",
      "epoch 36; iter: 0; batch classifier loss: 0.221867; batch adversarial loss: 0.511769\n",
      "epoch 37; iter: 0; batch classifier loss: 0.167048; batch adversarial loss: 0.399119\n",
      "epoch 38; iter: 0; batch classifier loss: 0.163639; batch adversarial loss: 0.534679\n",
      "epoch 39; iter: 0; batch classifier loss: 0.219807; batch adversarial loss: 0.496623\n",
      "epoch 40; iter: 0; batch classifier loss: 0.108035; batch adversarial loss: 0.401049\n",
      "epoch 41; iter: 0; batch classifier loss: 0.155030; batch adversarial loss: 0.549570\n",
      "epoch 42; iter: 0; batch classifier loss: 0.159215; batch adversarial loss: 0.509948\n",
      "epoch 43; iter: 0; batch classifier loss: 0.100339; batch adversarial loss: 0.405969\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136979; batch adversarial loss: 0.394032\n",
      "epoch 45; iter: 0; batch classifier loss: 0.128893; batch adversarial loss: 0.474412\n",
      "epoch 46; iter: 0; batch classifier loss: 0.128360; batch adversarial loss: 0.459497\n",
      "epoch 47; iter: 0; batch classifier loss: 0.098338; batch adversarial loss: 0.533523\n",
      "epoch 48; iter: 0; batch classifier loss: 0.166685; batch adversarial loss: 0.546270\n",
      "epoch 49; iter: 0; batch classifier loss: 0.161375; batch adversarial loss: 0.489242\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119436; batch adversarial loss: 0.476454\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106821; batch adversarial loss: 0.437729\n",
      "epoch 52; iter: 0; batch classifier loss: 0.119080; batch adversarial loss: 0.514886\n",
      "epoch 53; iter: 0; batch classifier loss: 0.101090; batch adversarial loss: 0.412544\n",
      "epoch 54; iter: 0; batch classifier loss: 0.118423; batch adversarial loss: 0.436141\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072157; batch adversarial loss: 0.435966\n",
      "epoch 56; iter: 0; batch classifier loss: 0.130377; batch adversarial loss: 0.453953\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095148; batch adversarial loss: 0.538011\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101183; batch adversarial loss: 0.477753\n",
      "epoch 59; iter: 0; batch classifier loss: 0.121821; batch adversarial loss: 0.468900\n",
      "epoch 60; iter: 0; batch classifier loss: 0.066160; batch adversarial loss: 0.415122\n",
      "epoch 61; iter: 0; batch classifier loss: 0.069329; batch adversarial loss: 0.511027\n",
      "epoch 62; iter: 0; batch classifier loss: 0.088991; batch adversarial loss: 0.510360\n",
      "epoch 63; iter: 0; batch classifier loss: 0.080262; batch adversarial loss: 0.472789\n",
      "epoch 64; iter: 0; batch classifier loss: 0.077383; batch adversarial loss: 0.506490\n",
      "epoch 65; iter: 0; batch classifier loss: 0.083447; batch adversarial loss: 0.458934\n",
      "epoch 66; iter: 0; batch classifier loss: 0.099072; batch adversarial loss: 0.465589\n",
      "epoch 67; iter: 0; batch classifier loss: 0.097480; batch adversarial loss: 0.537646\n",
      "epoch 68; iter: 0; batch classifier loss: 0.095413; batch adversarial loss: 0.389239\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084769; batch adversarial loss: 0.386913\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079099; batch adversarial loss: 0.423915\n",
      "epoch 71; iter: 0; batch classifier loss: 0.116100; batch adversarial loss: 0.388011\n",
      "epoch 72; iter: 0; batch classifier loss: 0.050829; batch adversarial loss: 0.573822\n",
      "epoch 73; iter: 0; batch classifier loss: 0.117066; batch adversarial loss: 0.480821\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081495; batch adversarial loss: 0.466127\n",
      "epoch 75; iter: 0; batch classifier loss: 0.070531; batch adversarial loss: 0.505860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.114540; batch adversarial loss: 0.457288\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055049; batch adversarial loss: 0.377202\n",
      "epoch 78; iter: 0; batch classifier loss: 0.060129; batch adversarial loss: 0.477563\n",
      "epoch 79; iter: 0; batch classifier loss: 0.111396; batch adversarial loss: 0.429288\n",
      "epoch 80; iter: 0; batch classifier loss: 0.059404; batch adversarial loss: 0.370503\n",
      "epoch 81; iter: 0; batch classifier loss: 0.126114; batch adversarial loss: 0.501823\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083208; batch adversarial loss: 0.453410\n",
      "epoch 83; iter: 0; batch classifier loss: 0.133414; batch adversarial loss: 0.439450\n",
      "epoch 84; iter: 0; batch classifier loss: 0.099375; batch adversarial loss: 0.382200\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064399; batch adversarial loss: 0.538704\n",
      "epoch 86; iter: 0; batch classifier loss: 0.037863; batch adversarial loss: 0.420296\n",
      "epoch 87; iter: 0; batch classifier loss: 0.146789; batch adversarial loss: 0.344256\n",
      "epoch 88; iter: 0; batch classifier loss: 0.028969; batch adversarial loss: 0.595759\n",
      "epoch 89; iter: 0; batch classifier loss: 0.039854; batch adversarial loss: 0.455403\n",
      "epoch 90; iter: 0; batch classifier loss: 0.093596; batch adversarial loss: 0.390286\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067541; batch adversarial loss: 0.405771\n",
      "epoch 92; iter: 0; batch classifier loss: 0.084716; batch adversarial loss: 0.491874\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050965; batch adversarial loss: 0.410784\n",
      "epoch 94; iter: 0; batch classifier loss: 0.092046; batch adversarial loss: 0.401184\n",
      "epoch 95; iter: 0; batch classifier loss: 0.106651; batch adversarial loss: 0.460822\n",
      "epoch 96; iter: 0; batch classifier loss: 0.067785; batch adversarial loss: 0.421899\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073104; batch adversarial loss: 0.399603\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079717; batch adversarial loss: 0.446189\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061530; batch adversarial loss: 0.490182\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067445; batch adversarial loss: 0.585191\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039507; batch adversarial loss: 0.495359\n",
      "epoch 102; iter: 0; batch classifier loss: 0.045730; batch adversarial loss: 0.570176\n",
      "epoch 103; iter: 0; batch classifier loss: 0.077082; batch adversarial loss: 0.471338\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057057; batch adversarial loss: 0.406779\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029655; batch adversarial loss: 0.438251\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053698; batch adversarial loss: 0.481168\n",
      "epoch 107; iter: 0; batch classifier loss: 0.075298; batch adversarial loss: 0.457877\n",
      "epoch 108; iter: 0; batch classifier loss: 0.082858; batch adversarial loss: 0.409841\n",
      "epoch 109; iter: 0; batch classifier loss: 0.105000; batch adversarial loss: 0.550819\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068353; batch adversarial loss: 0.433600\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055112; batch adversarial loss: 0.437191\n",
      "epoch 112; iter: 0; batch classifier loss: 0.050067; batch adversarial loss: 0.408202\n",
      "epoch 113; iter: 0; batch classifier loss: 0.082720; batch adversarial loss: 0.491974\n",
      "epoch 114; iter: 0; batch classifier loss: 0.069949; batch adversarial loss: 0.422124\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041124; batch adversarial loss: 0.491005\n",
      "epoch 116; iter: 0; batch classifier loss: 0.081832; batch adversarial loss: 0.471743\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053559; batch adversarial loss: 0.436653\n",
      "epoch 118; iter: 0; batch classifier loss: 0.065415; batch adversarial loss: 0.517290\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047609; batch adversarial loss: 0.411651\n",
      "epoch 120; iter: 0; batch classifier loss: 0.052859; batch adversarial loss: 0.397392\n",
      "epoch 121; iter: 0; batch classifier loss: 0.096434; batch adversarial loss: 0.458214\n",
      "epoch 122; iter: 0; batch classifier loss: 0.076034; batch adversarial loss: 0.412660\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035807; batch adversarial loss: 0.477337\n",
      "epoch 124; iter: 0; batch classifier loss: 0.084095; batch adversarial loss: 0.391755\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039603; batch adversarial loss: 0.479308\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052254; batch adversarial loss: 0.526098\n",
      "epoch 127; iter: 0; batch classifier loss: 0.065283; batch adversarial loss: 0.386169\n",
      "epoch 128; iter: 0; batch classifier loss: 0.062689; batch adversarial loss: 0.530730\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040221; batch adversarial loss: 0.524189\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059666; batch adversarial loss: 0.469252\n",
      "epoch 131; iter: 0; batch classifier loss: 0.063485; batch adversarial loss: 0.432300\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034983; batch adversarial loss: 0.462530\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039444; batch adversarial loss: 0.477275\n",
      "epoch 134; iter: 0; batch classifier loss: 0.078029; batch adversarial loss: 0.475871\n",
      "epoch 135; iter: 0; batch classifier loss: 0.055727; batch adversarial loss: 0.485378\n",
      "epoch 136; iter: 0; batch classifier loss: 0.058646; batch adversarial loss: 0.526513\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027619; batch adversarial loss: 0.511824\n",
      "epoch 138; iter: 0; batch classifier loss: 0.071362; batch adversarial loss: 0.513968\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032190; batch adversarial loss: 0.457645\n",
      "epoch 140; iter: 0; batch classifier loss: 0.073455; batch adversarial loss: 0.584889\n",
      "epoch 141; iter: 0; batch classifier loss: 0.071203; batch adversarial loss: 0.342979\n",
      "epoch 142; iter: 0; batch classifier loss: 0.066521; batch adversarial loss: 0.411999\n",
      "epoch 143; iter: 0; batch classifier loss: 0.054443; batch adversarial loss: 0.417483\n",
      "epoch 144; iter: 0; batch classifier loss: 0.069121; batch adversarial loss: 0.399741\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023678; batch adversarial loss: 0.442080\n",
      "epoch 146; iter: 0; batch classifier loss: 0.065202; batch adversarial loss: 0.411545\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018866; batch adversarial loss: 0.501126\n",
      "epoch 148; iter: 0; batch classifier loss: 0.069147; batch adversarial loss: 0.467567\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044623; batch adversarial loss: 0.455227\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028199; batch adversarial loss: 0.377129\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030079; batch adversarial loss: 0.460397\n",
      "epoch 152; iter: 0; batch classifier loss: 0.047565; batch adversarial loss: 0.433375\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042462; batch adversarial loss: 0.438198\n",
      "epoch 154; iter: 0; batch classifier loss: 0.060825; batch adversarial loss: 0.433598\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020220; batch adversarial loss: 0.485526\n",
      "epoch 156; iter: 0; batch classifier loss: 0.051225; batch adversarial loss: 0.454960\n",
      "epoch 157; iter: 0; batch classifier loss: 0.045405; batch adversarial loss: 0.433398\n",
      "epoch 158; iter: 0; batch classifier loss: 0.063315; batch adversarial loss: 0.468799\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043248; batch adversarial loss: 0.375783\n",
      "epoch 160; iter: 0; batch classifier loss: 0.083704; batch adversarial loss: 0.389223\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034961; batch adversarial loss: 0.356400\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046729; batch adversarial loss: 0.420462\n",
      "epoch 163; iter: 0; batch classifier loss: 0.051594; batch adversarial loss: 0.458803\n",
      "epoch 164; iter: 0; batch classifier loss: 0.070472; batch adversarial loss: 0.446191\n",
      "epoch 165; iter: 0; batch classifier loss: 0.043465; batch adversarial loss: 0.435334\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024396; batch adversarial loss: 0.436652\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014061; batch adversarial loss: 0.480484\n",
      "epoch 168; iter: 0; batch classifier loss: 0.044603; batch adversarial loss: 0.496738\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028754; batch adversarial loss: 0.445015\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016268; batch adversarial loss: 0.535988\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040303; batch adversarial loss: 0.500467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.063680; batch adversarial loss: 0.478116\n",
      "epoch 173; iter: 0; batch classifier loss: 0.048186; batch adversarial loss: 0.422071\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036112; batch adversarial loss: 0.596762\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029233; batch adversarial loss: 0.444815\n",
      "epoch 176; iter: 0; batch classifier loss: 0.053330; batch adversarial loss: 0.543164\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015065; batch adversarial loss: 0.382459\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039232; batch adversarial loss: 0.392450\n",
      "epoch 179; iter: 0; batch classifier loss: 0.052388; batch adversarial loss: 0.421771\n",
      "epoch 180; iter: 0; batch classifier loss: 0.060289; batch adversarial loss: 0.417850\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030583; batch adversarial loss: 0.491127\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022054; batch adversarial loss: 0.441582\n",
      "epoch 183; iter: 0; batch classifier loss: 0.002891; batch adversarial loss: 0.413854\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032624; batch adversarial loss: 0.421574\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014510; batch adversarial loss: 0.457757\n",
      "epoch 186; iter: 0; batch classifier loss: 0.039783; batch adversarial loss: 0.451298\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036063; batch adversarial loss: 0.501183\n",
      "epoch 188; iter: 0; batch classifier loss: 0.043970; batch adversarial loss: 0.483582\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030294; batch adversarial loss: 0.442867\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030713; batch adversarial loss: 0.383668\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020285; batch adversarial loss: 0.446584\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015245; batch adversarial loss: 0.490238\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005361; batch adversarial loss: 0.415437\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023944; batch adversarial loss: 0.446681\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037419; batch adversarial loss: 0.468302\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010328; batch adversarial loss: 0.465809\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025831; batch adversarial loss: 0.418581\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039001; batch adversarial loss: 0.476923\n",
      "epoch 199; iter: 0; batch classifier loss: 0.047244; batch adversarial loss: 0.438539\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695913; batch adversarial loss: 0.798191\n",
      "epoch 1; iter: 0; batch classifier loss: 0.514500; batch adversarial loss: 0.764516\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586569; batch adversarial loss: 0.735399\n",
      "epoch 3; iter: 0; batch classifier loss: 0.692345; batch adversarial loss: 0.697219\n",
      "epoch 4; iter: 0; batch classifier loss: 0.632388; batch adversarial loss: 0.614841\n",
      "epoch 5; iter: 0; batch classifier loss: 0.438805; batch adversarial loss: 0.595400\n",
      "epoch 6; iter: 0; batch classifier loss: 0.341361; batch adversarial loss: 0.595042\n",
      "epoch 7; iter: 0; batch classifier loss: 0.351793; batch adversarial loss: 0.595238\n",
      "epoch 8; iter: 0; batch classifier loss: 0.430114; batch adversarial loss: 0.512918\n",
      "epoch 9; iter: 0; batch classifier loss: 0.447773; batch adversarial loss: 0.507083\n",
      "epoch 10; iter: 0; batch classifier loss: 0.387656; batch adversarial loss: 0.558645\n",
      "epoch 11; iter: 0; batch classifier loss: 0.471648; batch adversarial loss: 0.502553\n",
      "epoch 12; iter: 0; batch classifier loss: 0.340508; batch adversarial loss: 0.526052\n",
      "epoch 13; iter: 0; batch classifier loss: 0.473085; batch adversarial loss: 0.501987\n",
      "epoch 14; iter: 0; batch classifier loss: 0.338977; batch adversarial loss: 0.536436\n",
      "epoch 15; iter: 0; batch classifier loss: 0.375750; batch adversarial loss: 0.532154\n",
      "epoch 16; iter: 0; batch classifier loss: 0.333450; batch adversarial loss: 0.471934\n",
      "epoch 17; iter: 0; batch classifier loss: 0.315049; batch adversarial loss: 0.514718\n",
      "epoch 18; iter: 0; batch classifier loss: 0.266997; batch adversarial loss: 0.488461\n",
      "epoch 19; iter: 0; batch classifier loss: 0.309926; batch adversarial loss: 0.472053\n",
      "epoch 20; iter: 0; batch classifier loss: 0.331163; batch adversarial loss: 0.485869\n",
      "epoch 21; iter: 0; batch classifier loss: 0.332713; batch adversarial loss: 0.470993\n",
      "epoch 22; iter: 0; batch classifier loss: 0.345957; batch adversarial loss: 0.419830\n",
      "epoch 23; iter: 0; batch classifier loss: 0.280052; batch adversarial loss: 0.450752\n",
      "epoch 24; iter: 0; batch classifier loss: 0.287078; batch adversarial loss: 0.472989\n",
      "epoch 25; iter: 0; batch classifier loss: 0.304993; batch adversarial loss: 0.460187\n",
      "epoch 26; iter: 0; batch classifier loss: 0.324544; batch adversarial loss: 0.518411\n",
      "epoch 27; iter: 0; batch classifier loss: 0.257778; batch adversarial loss: 0.476684\n",
      "epoch 28; iter: 0; batch classifier loss: 0.287045; batch adversarial loss: 0.407378\n",
      "epoch 29; iter: 0; batch classifier loss: 0.329401; batch adversarial loss: 0.482665\n",
      "epoch 30; iter: 0; batch classifier loss: 0.329741; batch adversarial loss: 0.495140\n",
      "epoch 31; iter: 0; batch classifier loss: 0.304863; batch adversarial loss: 0.472747\n",
      "epoch 32; iter: 0; batch classifier loss: 0.309413; batch adversarial loss: 0.438993\n",
      "epoch 33; iter: 0; batch classifier loss: 0.192656; batch adversarial loss: 0.493292\n",
      "epoch 34; iter: 0; batch classifier loss: 0.240346; batch adversarial loss: 0.457020\n",
      "epoch 35; iter: 0; batch classifier loss: 0.257634; batch adversarial loss: 0.539135\n",
      "epoch 36; iter: 0; batch classifier loss: 0.215501; batch adversarial loss: 0.517663\n",
      "epoch 37; iter: 0; batch classifier loss: 0.223683; batch adversarial loss: 0.445714\n",
      "epoch 38; iter: 0; batch classifier loss: 0.295064; batch adversarial loss: 0.453740\n",
      "epoch 39; iter: 0; batch classifier loss: 0.263160; batch adversarial loss: 0.597319\n",
      "epoch 40; iter: 0; batch classifier loss: 0.232836; batch adversarial loss: 0.598989\n",
      "epoch 41; iter: 0; batch classifier loss: 0.297492; batch adversarial loss: 0.496276\n",
      "epoch 42; iter: 0; batch classifier loss: 0.248580; batch adversarial loss: 0.509283\n",
      "epoch 43; iter: 0; batch classifier loss: 0.222190; batch adversarial loss: 0.468789\n",
      "epoch 44; iter: 0; batch classifier loss: 0.249581; batch adversarial loss: 0.439054\n",
      "epoch 45; iter: 0; batch classifier loss: 0.290505; batch adversarial loss: 0.460763\n",
      "epoch 46; iter: 0; batch classifier loss: 0.204401; batch adversarial loss: 0.463596\n",
      "epoch 47; iter: 0; batch classifier loss: 0.198881; batch adversarial loss: 0.481654\n",
      "epoch 48; iter: 0; batch classifier loss: 0.215144; batch adversarial loss: 0.518670\n",
      "epoch 49; iter: 0; batch classifier loss: 0.229858; batch adversarial loss: 0.471951\n",
      "epoch 50; iter: 0; batch classifier loss: 0.204058; batch adversarial loss: 0.473908\n",
      "epoch 51; iter: 0; batch classifier loss: 0.267476; batch adversarial loss: 0.410916\n",
      "epoch 52; iter: 0; batch classifier loss: 0.183054; batch adversarial loss: 0.412918\n",
      "epoch 53; iter: 0; batch classifier loss: 0.232045; batch adversarial loss: 0.423266\n",
      "epoch 54; iter: 0; batch classifier loss: 0.207153; batch adversarial loss: 0.517027\n",
      "epoch 55; iter: 0; batch classifier loss: 0.242314; batch adversarial loss: 0.364039\n",
      "epoch 56; iter: 0; batch classifier loss: 0.257231; batch adversarial loss: 0.448051\n",
      "epoch 57; iter: 0; batch classifier loss: 0.211614; batch adversarial loss: 0.435407\n",
      "epoch 58; iter: 0; batch classifier loss: 0.197658; batch adversarial loss: 0.458458\n",
      "epoch 59; iter: 0; batch classifier loss: 0.272347; batch adversarial loss: 0.412055\n",
      "epoch 60; iter: 0; batch classifier loss: 0.192587; batch adversarial loss: 0.470581\n",
      "epoch 61; iter: 0; batch classifier loss: 0.219652; batch adversarial loss: 0.435351\n",
      "epoch 62; iter: 0; batch classifier loss: 0.223307; batch adversarial loss: 0.411769\n",
      "epoch 63; iter: 0; batch classifier loss: 0.202436; batch adversarial loss: 0.471053\n",
      "epoch 64; iter: 0; batch classifier loss: 0.222708; batch adversarial loss: 0.506570\n",
      "epoch 65; iter: 0; batch classifier loss: 0.228108; batch adversarial loss: 0.423634\n",
      "epoch 66; iter: 0; batch classifier loss: 0.150145; batch adversarial loss: 0.410877\n",
      "epoch 67; iter: 0; batch classifier loss: 0.121560; batch adversarial loss: 0.421643\n",
      "epoch 68; iter: 0; batch classifier loss: 0.152135; batch adversarial loss: 0.444493\n",
      "epoch 69; iter: 0; batch classifier loss: 0.237823; batch adversarial loss: 0.510967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.210455; batch adversarial loss: 0.446990\n",
      "epoch 71; iter: 0; batch classifier loss: 0.135842; batch adversarial loss: 0.423039\n",
      "epoch 72; iter: 0; batch classifier loss: 0.159866; batch adversarial loss: 0.448395\n",
      "epoch 73; iter: 0; batch classifier loss: 0.203285; batch adversarial loss: 0.409803\n",
      "epoch 74; iter: 0; batch classifier loss: 0.212350; batch adversarial loss: 0.471672\n",
      "epoch 75; iter: 0; batch classifier loss: 0.152438; batch adversarial loss: 0.387927\n",
      "epoch 76; iter: 0; batch classifier loss: 0.157365; batch adversarial loss: 0.447009\n",
      "epoch 77; iter: 0; batch classifier loss: 0.107555; batch adversarial loss: 0.542836\n",
      "epoch 78; iter: 0; batch classifier loss: 0.265641; batch adversarial loss: 0.385053\n",
      "epoch 79; iter: 0; batch classifier loss: 0.240949; batch adversarial loss: 0.483837\n",
      "epoch 80; iter: 0; batch classifier loss: 0.212388; batch adversarial loss: 0.410146\n",
      "epoch 81; iter: 0; batch classifier loss: 0.199535; batch adversarial loss: 0.494884\n",
      "epoch 82; iter: 0; batch classifier loss: 0.196248; batch adversarial loss: 0.506707\n",
      "epoch 83; iter: 0; batch classifier loss: 0.205089; batch adversarial loss: 0.470981\n",
      "epoch 84; iter: 0; batch classifier loss: 0.171734; batch adversarial loss: 0.458536\n",
      "epoch 85; iter: 0; batch classifier loss: 0.215869; batch adversarial loss: 0.482496\n",
      "epoch 86; iter: 0; batch classifier loss: 0.156782; batch adversarial loss: 0.495479\n",
      "epoch 87; iter: 0; batch classifier loss: 0.229783; batch adversarial loss: 0.411066\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088899; batch adversarial loss: 0.470518\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052478; batch adversarial loss: 0.404042\n",
      "epoch 90; iter: 0; batch classifier loss: 0.091607; batch adversarial loss: 0.490818\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046065; batch adversarial loss: 0.381827\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041966; batch adversarial loss: 0.541136\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048845; batch adversarial loss: 0.405493\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070878; batch adversarial loss: 0.328391\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048764; batch adversarial loss: 0.417045\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044555; batch adversarial loss: 0.448840\n",
      "epoch 97; iter: 0; batch classifier loss: 0.033708; batch adversarial loss: 0.371256\n",
      "epoch 98; iter: 0; batch classifier loss: 0.060839; batch adversarial loss: 0.508215\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045229; batch adversarial loss: 0.518940\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055152; batch adversarial loss: 0.439458\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070669; batch adversarial loss: 0.407571\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060780; batch adversarial loss: 0.416115\n",
      "epoch 103; iter: 0; batch classifier loss: 0.031344; batch adversarial loss: 0.435291\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031545; batch adversarial loss: 0.461475\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037343; batch adversarial loss: 0.520760\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042423; batch adversarial loss: 0.520345\n",
      "epoch 107; iter: 0; batch classifier loss: 0.030011; batch adversarial loss: 0.468989\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032817; batch adversarial loss: 0.443616\n",
      "epoch 109; iter: 0; batch classifier loss: 0.017544; batch adversarial loss: 0.535633\n",
      "epoch 110; iter: 0; batch classifier loss: 0.018597; batch adversarial loss: 0.401629\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041151; batch adversarial loss: 0.443462\n",
      "epoch 112; iter: 0; batch classifier loss: 0.021262; batch adversarial loss: 0.520515\n",
      "epoch 113; iter: 0; batch classifier loss: 0.015824; batch adversarial loss: 0.480931\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034779; batch adversarial loss: 0.444756\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033052; batch adversarial loss: 0.524085\n",
      "epoch 116; iter: 0; batch classifier loss: 0.023427; batch adversarial loss: 0.497965\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047834; batch adversarial loss: 0.359378\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043916; batch adversarial loss: 0.455890\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033335; batch adversarial loss: 0.538135\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054193; batch adversarial loss: 0.443446\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039351; batch adversarial loss: 0.378210\n",
      "epoch 122; iter: 0; batch classifier loss: 0.011578; batch adversarial loss: 0.446349\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032265; batch adversarial loss: 0.496071\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022038; batch adversarial loss: 0.437308\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018103; batch adversarial loss: 0.483578\n",
      "epoch 126; iter: 0; batch classifier loss: 0.009737; batch adversarial loss: 0.438940\n",
      "epoch 127; iter: 0; batch classifier loss: 0.018776; batch adversarial loss: 0.511557\n",
      "epoch 128; iter: 0; batch classifier loss: 0.020084; batch adversarial loss: 0.502604\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028973; batch adversarial loss: 0.487829\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016194; batch adversarial loss: 0.466677\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027718; batch adversarial loss: 0.464184\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024264; batch adversarial loss: 0.453598\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028557; batch adversarial loss: 0.493204\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021011; batch adversarial loss: 0.427936\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012322; batch adversarial loss: 0.390815\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021175; batch adversarial loss: 0.468838\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012679; batch adversarial loss: 0.431439\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011712; batch adversarial loss: 0.518680\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031497; batch adversarial loss: 0.454681\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025938; batch adversarial loss: 0.494128\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022870; batch adversarial loss: 0.371360\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016972; batch adversarial loss: 0.452119\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021480; batch adversarial loss: 0.458436\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018606; batch adversarial loss: 0.414998\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019746; batch adversarial loss: 0.503734\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030831; batch adversarial loss: 0.559945\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017545; batch adversarial loss: 0.379358\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023896; batch adversarial loss: 0.394867\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021055; batch adversarial loss: 0.402551\n",
      "epoch 150; iter: 0; batch classifier loss: 0.051422; batch adversarial loss: 0.459269\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038646; batch adversarial loss: 0.468673\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025388; batch adversarial loss: 0.460377\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030320; batch adversarial loss: 0.470937\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018099; batch adversarial loss: 0.511586\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019631; batch adversarial loss: 0.541219\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013948; batch adversarial loss: 0.531089\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031049; batch adversarial loss: 0.349849\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017828; batch adversarial loss: 0.544801\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032910; batch adversarial loss: 0.516568\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018860; batch adversarial loss: 0.353838\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022845; batch adversarial loss: 0.543856\n",
      "epoch 162; iter: 0; batch classifier loss: 0.045212; batch adversarial loss: 0.412582\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026301; batch adversarial loss: 0.435079\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035075; batch adversarial loss: 0.439664\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010558; batch adversarial loss: 0.398478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.004232; batch adversarial loss: 0.551212\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006270; batch adversarial loss: 0.514078\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012149; batch adversarial loss: 0.469383\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016003; batch adversarial loss: 0.567904\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008441; batch adversarial loss: 0.385726\n",
      "epoch 171; iter: 0; batch classifier loss: 0.046023; batch adversarial loss: 0.363169\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024196; batch adversarial loss: 0.431131\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026834; batch adversarial loss: 0.457413\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009540; batch adversarial loss: 0.505094\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042679; batch adversarial loss: 0.458567\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018422; batch adversarial loss: 0.505136\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033929; batch adversarial loss: 0.545980\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012069; batch adversarial loss: 0.456116\n",
      "epoch 179; iter: 0; batch classifier loss: 0.049337; batch adversarial loss: 0.430339\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013716; batch adversarial loss: 0.477091\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010088; batch adversarial loss: 0.604312\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007141; batch adversarial loss: 0.486836\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030119; batch adversarial loss: 0.386670\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022604; batch adversarial loss: 0.507312\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010337; batch adversarial loss: 0.392775\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015424; batch adversarial loss: 0.495287\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016693; batch adversarial loss: 0.452240\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012073; batch adversarial loss: 0.451894\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010635; batch adversarial loss: 0.495094\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005323; batch adversarial loss: 0.504741\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015146; batch adversarial loss: 0.468692\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004034; batch adversarial loss: 0.505511\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014229; batch adversarial loss: 0.368780\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008515; batch adversarial loss: 0.439363\n",
      "epoch 195; iter: 0; batch classifier loss: 0.041713; batch adversarial loss: 0.539315\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019798; batch adversarial loss: 0.510622\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008454; batch adversarial loss: 0.421516\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018282; batch adversarial loss: 0.465649\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019637; batch adversarial loss: 0.436727\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672521; batch adversarial loss: 0.656029\n",
      "epoch 1; iter: 0; batch classifier loss: 0.486054; batch adversarial loss: 0.639591\n",
      "epoch 2; iter: 0; batch classifier loss: 0.446671; batch adversarial loss: 0.643645\n",
      "epoch 3; iter: 0; batch classifier loss: 0.405744; batch adversarial loss: 0.631377\n",
      "epoch 4; iter: 0; batch classifier loss: 0.365806; batch adversarial loss: 0.617782\n",
      "epoch 5; iter: 0; batch classifier loss: 0.536977; batch adversarial loss: 0.590623\n",
      "epoch 6; iter: 0; batch classifier loss: 0.439606; batch adversarial loss: 0.532969\n",
      "epoch 7; iter: 0; batch classifier loss: 0.361927; batch adversarial loss: 0.599769\n",
      "epoch 8; iter: 0; batch classifier loss: 0.339622; batch adversarial loss: 0.533201\n",
      "epoch 9; iter: 0; batch classifier loss: 0.328142; batch adversarial loss: 0.567614\n",
      "epoch 10; iter: 0; batch classifier loss: 0.445129; batch adversarial loss: 0.501723\n",
      "epoch 11; iter: 0; batch classifier loss: 0.350942; batch adversarial loss: 0.510852\n",
      "epoch 12; iter: 0; batch classifier loss: 0.368023; batch adversarial loss: 0.487296\n",
      "epoch 13; iter: 0; batch classifier loss: 0.279236; batch adversarial loss: 0.586768\n",
      "epoch 14; iter: 0; batch classifier loss: 0.319026; batch adversarial loss: 0.512237\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274956; batch adversarial loss: 0.469453\n",
      "epoch 16; iter: 0; batch classifier loss: 0.212461; batch adversarial loss: 0.499090\n",
      "epoch 17; iter: 0; batch classifier loss: 0.267237; batch adversarial loss: 0.564425\n",
      "epoch 18; iter: 0; batch classifier loss: 0.330061; batch adversarial loss: 0.480488\n",
      "epoch 19; iter: 0; batch classifier loss: 0.225996; batch adversarial loss: 0.513523\n",
      "epoch 20; iter: 0; batch classifier loss: 0.252249; batch adversarial loss: 0.441237\n",
      "epoch 21; iter: 0; batch classifier loss: 0.212902; batch adversarial loss: 0.553851\n",
      "epoch 22; iter: 0; batch classifier loss: 0.196905; batch adversarial loss: 0.454853\n",
      "epoch 23; iter: 0; batch classifier loss: 0.249907; batch adversarial loss: 0.417615\n",
      "epoch 24; iter: 0; batch classifier loss: 0.193703; batch adversarial loss: 0.471876\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172658; batch adversarial loss: 0.425960\n",
      "epoch 26; iter: 0; batch classifier loss: 0.221271; batch adversarial loss: 0.482332\n",
      "epoch 27; iter: 0; batch classifier loss: 0.158719; batch adversarial loss: 0.493100\n",
      "epoch 28; iter: 0; batch classifier loss: 0.159592; batch adversarial loss: 0.563617\n",
      "epoch 29; iter: 0; batch classifier loss: 0.120612; batch adversarial loss: 0.445483\n",
      "epoch 30; iter: 0; batch classifier loss: 0.165981; batch adversarial loss: 0.473436\n",
      "epoch 31; iter: 0; batch classifier loss: 0.115820; batch adversarial loss: 0.490030\n",
      "epoch 32; iter: 0; batch classifier loss: 0.218262; batch adversarial loss: 0.358584\n",
      "epoch 33; iter: 0; batch classifier loss: 0.141348; batch adversarial loss: 0.539315\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148605; batch adversarial loss: 0.498950\n",
      "epoch 35; iter: 0; batch classifier loss: 0.190629; batch adversarial loss: 0.429746\n",
      "epoch 36; iter: 0; batch classifier loss: 0.211576; batch adversarial loss: 0.379979\n",
      "epoch 37; iter: 0; batch classifier loss: 0.120214; batch adversarial loss: 0.544900\n",
      "epoch 38; iter: 0; batch classifier loss: 0.151394; batch adversarial loss: 0.535051\n",
      "epoch 39; iter: 0; batch classifier loss: 0.182422; batch adversarial loss: 0.507953\n",
      "epoch 40; iter: 0; batch classifier loss: 0.147586; batch adversarial loss: 0.444741\n",
      "epoch 41; iter: 0; batch classifier loss: 0.176120; batch adversarial loss: 0.525511\n",
      "epoch 42; iter: 0; batch classifier loss: 0.128521; batch adversarial loss: 0.483268\n",
      "epoch 43; iter: 0; batch classifier loss: 0.075850; batch adversarial loss: 0.481794\n",
      "epoch 44; iter: 0; batch classifier loss: 0.143167; batch adversarial loss: 0.398075\n",
      "epoch 45; iter: 0; batch classifier loss: 0.157718; batch adversarial loss: 0.523944\n",
      "epoch 46; iter: 0; batch classifier loss: 0.153147; batch adversarial loss: 0.485290\n",
      "epoch 47; iter: 0; batch classifier loss: 0.133878; batch adversarial loss: 0.533975\n",
      "epoch 48; iter: 0; batch classifier loss: 0.134405; batch adversarial loss: 0.498121\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098599; batch adversarial loss: 0.489338\n",
      "epoch 50; iter: 0; batch classifier loss: 0.118544; batch adversarial loss: 0.445366\n",
      "epoch 51; iter: 0; batch classifier loss: 0.158683; batch adversarial loss: 0.520577\n",
      "epoch 52; iter: 0; batch classifier loss: 0.150459; batch adversarial loss: 0.368430\n",
      "epoch 53; iter: 0; batch classifier loss: 0.101969; batch adversarial loss: 0.457255\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116925; batch adversarial loss: 0.366047\n",
      "epoch 55; iter: 0; batch classifier loss: 0.142573; batch adversarial loss: 0.450024\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101078; batch adversarial loss: 0.424983\n",
      "epoch 57; iter: 0; batch classifier loss: 0.149635; batch adversarial loss: 0.403603\n",
      "epoch 58; iter: 0; batch classifier loss: 0.111575; batch adversarial loss: 0.410636\n",
      "epoch 59; iter: 0; batch classifier loss: 0.141066; batch adversarial loss: 0.457726\n",
      "epoch 60; iter: 0; batch classifier loss: 0.150175; batch adversarial loss: 0.448146\n",
      "epoch 61; iter: 0; batch classifier loss: 0.118901; batch adversarial loss: 0.423523\n",
      "epoch 62; iter: 0; batch classifier loss: 0.141485; batch adversarial loss: 0.498778\n",
      "epoch 63; iter: 0; batch classifier loss: 0.163830; batch adversarial loss: 0.502181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.094711; batch adversarial loss: 0.494898\n",
      "epoch 65; iter: 0; batch classifier loss: 0.101893; batch adversarial loss: 0.571386\n",
      "epoch 66; iter: 0; batch classifier loss: 0.111270; batch adversarial loss: 0.424288\n",
      "epoch 67; iter: 0; batch classifier loss: 0.066736; batch adversarial loss: 0.460553\n",
      "epoch 68; iter: 0; batch classifier loss: 0.128703; batch adversarial loss: 0.378342\n",
      "epoch 69; iter: 0; batch classifier loss: 0.146395; batch adversarial loss: 0.419978\n",
      "epoch 70; iter: 0; batch classifier loss: 0.136049; batch adversarial loss: 0.406065\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115839; batch adversarial loss: 0.549787\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082215; batch adversarial loss: 0.489064\n",
      "epoch 73; iter: 0; batch classifier loss: 0.095310; batch adversarial loss: 0.492802\n",
      "epoch 74; iter: 0; batch classifier loss: 0.093066; batch adversarial loss: 0.529832\n",
      "epoch 75; iter: 0; batch classifier loss: 0.087721; batch adversarial loss: 0.416529\n",
      "epoch 76; iter: 0; batch classifier loss: 0.099104; batch adversarial loss: 0.449259\n",
      "epoch 77; iter: 0; batch classifier loss: 0.123409; batch adversarial loss: 0.424486\n",
      "epoch 78; iter: 0; batch classifier loss: 0.137666; batch adversarial loss: 0.495087\n",
      "epoch 79; iter: 0; batch classifier loss: 0.087001; batch adversarial loss: 0.435282\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083661; batch adversarial loss: 0.429732\n",
      "epoch 81; iter: 0; batch classifier loss: 0.034394; batch adversarial loss: 0.493547\n",
      "epoch 82; iter: 0; batch classifier loss: 0.144425; batch adversarial loss: 0.517228\n",
      "epoch 83; iter: 0; batch classifier loss: 0.077019; batch adversarial loss: 0.395511\n",
      "epoch 84; iter: 0; batch classifier loss: 0.092347; batch adversarial loss: 0.443359\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076312; batch adversarial loss: 0.485461\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089057; batch adversarial loss: 0.368557\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062872; batch adversarial loss: 0.460548\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058602; batch adversarial loss: 0.383308\n",
      "epoch 89; iter: 0; batch classifier loss: 0.071335; batch adversarial loss: 0.554633\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050862; batch adversarial loss: 0.439962\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081208; batch adversarial loss: 0.482390\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062832; batch adversarial loss: 0.479911\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053265; batch adversarial loss: 0.507401\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061480; batch adversarial loss: 0.364060\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052167; batch adversarial loss: 0.381425\n",
      "epoch 96; iter: 0; batch classifier loss: 0.088830; batch adversarial loss: 0.491720\n",
      "epoch 97; iter: 0; batch classifier loss: 0.041152; batch adversarial loss: 0.469597\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056963; batch adversarial loss: 0.450033\n",
      "epoch 99; iter: 0; batch classifier loss: 0.077907; batch adversarial loss: 0.491565\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043631; batch adversarial loss: 0.491867\n",
      "epoch 101; iter: 0; batch classifier loss: 0.082979; batch adversarial loss: 0.524762\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057908; batch adversarial loss: 0.455485\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037002; batch adversarial loss: 0.418018\n",
      "epoch 104; iter: 0; batch classifier loss: 0.024032; batch adversarial loss: 0.478269\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049049; batch adversarial loss: 0.385153\n",
      "epoch 106; iter: 0; batch classifier loss: 0.065812; batch adversarial loss: 0.533625\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052592; batch adversarial loss: 0.433911\n",
      "epoch 108; iter: 0; batch classifier loss: 0.025306; batch adversarial loss: 0.393522\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049941; batch adversarial loss: 0.464545\n",
      "epoch 110; iter: 0; batch classifier loss: 0.055349; batch adversarial loss: 0.431368\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044691; batch adversarial loss: 0.430750\n",
      "epoch 112; iter: 0; batch classifier loss: 0.073254; batch adversarial loss: 0.496710\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055639; batch adversarial loss: 0.416087\n",
      "epoch 114; iter: 0; batch classifier loss: 0.022133; batch adversarial loss: 0.480984\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035646; batch adversarial loss: 0.540001\n",
      "epoch 116; iter: 0; batch classifier loss: 0.018597; batch adversarial loss: 0.427562\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034689; batch adversarial loss: 0.420662\n",
      "epoch 118; iter: 0; batch classifier loss: 0.014288; batch adversarial loss: 0.420868\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070185; batch adversarial loss: 0.427652\n",
      "epoch 120; iter: 0; batch classifier loss: 0.078058; batch adversarial loss: 0.306842\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030110; batch adversarial loss: 0.445404\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029169; batch adversarial loss: 0.546842\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032135; batch adversarial loss: 0.454624\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052030; batch adversarial loss: 0.488860\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017195; batch adversarial loss: 0.517173\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027341; batch adversarial loss: 0.390604\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027943; batch adversarial loss: 0.490309\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041540; batch adversarial loss: 0.374043\n",
      "epoch 129; iter: 0; batch classifier loss: 0.012096; batch adversarial loss: 0.535918\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016461; batch adversarial loss: 0.504561\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018825; batch adversarial loss: 0.594151\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015658; batch adversarial loss: 0.479588\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054907; batch adversarial loss: 0.390191\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034454; batch adversarial loss: 0.527759\n",
      "epoch 135; iter: 0; batch classifier loss: 0.071716; batch adversarial loss: 0.507122\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031180; batch adversarial loss: 0.495476\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040539; batch adversarial loss: 0.408730\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016345; batch adversarial loss: 0.472508\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017020; batch adversarial loss: 0.497727\n",
      "epoch 140; iter: 0; batch classifier loss: 0.043662; batch adversarial loss: 0.476502\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028378; batch adversarial loss: 0.454661\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044592; batch adversarial loss: 0.585594\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013945; batch adversarial loss: 0.435640\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019145; batch adversarial loss: 0.385692\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014142; batch adversarial loss: 0.425976\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021146; batch adversarial loss: 0.434366\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020810; batch adversarial loss: 0.429388\n",
      "epoch 148; iter: 0; batch classifier loss: 0.008782; batch adversarial loss: 0.386836\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018108; batch adversarial loss: 0.519006\n",
      "epoch 150; iter: 0; batch classifier loss: 0.057888; batch adversarial loss: 0.426038\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017536; batch adversarial loss: 0.387694\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014467; batch adversarial loss: 0.431082\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031383; batch adversarial loss: 0.496223\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037537; batch adversarial loss: 0.541814\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029525; batch adversarial loss: 0.351241\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029642; batch adversarial loss: 0.407642\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035217; batch adversarial loss: 0.535727\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025284; batch adversarial loss: 0.434160\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045097; batch adversarial loss: 0.442158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.010748; batch adversarial loss: 0.409730\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015354; batch adversarial loss: 0.400260\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027252; batch adversarial loss: 0.377832\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016224; batch adversarial loss: 0.452688\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022402; batch adversarial loss: 0.527336\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033526; batch adversarial loss: 0.404993\n",
      "epoch 166; iter: 0; batch classifier loss: 0.058819; batch adversarial loss: 0.415740\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032589; batch adversarial loss: 0.522317\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017918; batch adversarial loss: 0.436170\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014569; batch adversarial loss: 0.426771\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023829; batch adversarial loss: 0.417215\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034572; batch adversarial loss: 0.462660\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015452; batch adversarial loss: 0.470570\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014365; batch adversarial loss: 0.377916\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017036; batch adversarial loss: 0.368427\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019220; batch adversarial loss: 0.434698\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012861; batch adversarial loss: 0.494086\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021026; batch adversarial loss: 0.374134\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040962; batch adversarial loss: 0.527337\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022292; batch adversarial loss: 0.431286\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007409; batch adversarial loss: 0.437081\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021011; batch adversarial loss: 0.398115\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007526; batch adversarial loss: 0.388514\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029387; batch adversarial loss: 0.437638\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012819; batch adversarial loss: 0.453871\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017215; batch adversarial loss: 0.503938\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017846; batch adversarial loss: 0.400243\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012365; batch adversarial loss: 0.467273\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010539; batch adversarial loss: 0.400162\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017339; batch adversarial loss: 0.472949\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010712; batch adversarial loss: 0.496891\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015440; batch adversarial loss: 0.449763\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022324; batch adversarial loss: 0.346907\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018873; batch adversarial loss: 0.433618\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030691; batch adversarial loss: 0.420108\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008597; batch adversarial loss: 0.417582\n",
      "epoch 196; iter: 0; batch classifier loss: 0.039944; batch adversarial loss: 0.433069\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032723; batch adversarial loss: 0.429134\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009722; batch adversarial loss: 0.403442\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016126; batch adversarial loss: 0.489567\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673949; batch adversarial loss: 0.721704\n",
      "epoch 1; iter: 0; batch classifier loss: 0.414727; batch adversarial loss: 0.697603\n",
      "epoch 2; iter: 0; batch classifier loss: 0.408931; batch adversarial loss: 0.718454\n",
      "epoch 3; iter: 0; batch classifier loss: 0.335976; batch adversarial loss: 0.685577\n",
      "epoch 4; iter: 0; batch classifier loss: 0.308348; batch adversarial loss: 0.656624\n",
      "epoch 5; iter: 0; batch classifier loss: 0.360970; batch adversarial loss: 0.624846\n",
      "epoch 6; iter: 0; batch classifier loss: 0.299096; batch adversarial loss: 0.584726\n",
      "epoch 7; iter: 0; batch classifier loss: 0.350915; batch adversarial loss: 0.553852\n",
      "epoch 8; iter: 0; batch classifier loss: 0.294485; batch adversarial loss: 0.537103\n",
      "epoch 9; iter: 0; batch classifier loss: 0.252649; batch adversarial loss: 0.474961\n",
      "epoch 10; iter: 0; batch classifier loss: 0.234701; batch adversarial loss: 0.459201\n",
      "epoch 11; iter: 0; batch classifier loss: 0.225110; batch adversarial loss: 0.535843\n",
      "epoch 12; iter: 0; batch classifier loss: 0.277926; batch adversarial loss: 0.437696\n",
      "epoch 13; iter: 0; batch classifier loss: 0.183852; batch adversarial loss: 0.472828\n",
      "epoch 14; iter: 0; batch classifier loss: 0.214832; batch adversarial loss: 0.530594\n",
      "epoch 15; iter: 0; batch classifier loss: 0.165280; batch adversarial loss: 0.444157\n",
      "epoch 16; iter: 0; batch classifier loss: 0.165466; batch adversarial loss: 0.488735\n",
      "epoch 17; iter: 0; batch classifier loss: 0.235890; batch adversarial loss: 0.404955\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197712; batch adversarial loss: 0.483970\n",
      "epoch 19; iter: 0; batch classifier loss: 0.210295; batch adversarial loss: 0.496565\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204633; batch adversarial loss: 0.478992\n",
      "epoch 21; iter: 0; batch classifier loss: 0.242826; batch adversarial loss: 0.448725\n",
      "epoch 22; iter: 0; batch classifier loss: 0.192658; batch adversarial loss: 0.453683\n",
      "epoch 23; iter: 0; batch classifier loss: 0.225423; batch adversarial loss: 0.355137\n",
      "epoch 24; iter: 0; batch classifier loss: 0.208633; batch adversarial loss: 0.445389\n",
      "epoch 25; iter: 0; batch classifier loss: 0.182347; batch adversarial loss: 0.416151\n",
      "epoch 26; iter: 0; batch classifier loss: 0.206103; batch adversarial loss: 0.347406\n",
      "epoch 27; iter: 0; batch classifier loss: 0.193361; batch adversarial loss: 0.377460\n",
      "epoch 28; iter: 0; batch classifier loss: 0.141110; batch adversarial loss: 0.437533\n",
      "epoch 29; iter: 0; batch classifier loss: 0.200469; batch adversarial loss: 0.430411\n",
      "epoch 30; iter: 0; batch classifier loss: 0.156567; batch adversarial loss: 0.361347\n",
      "epoch 31; iter: 0; batch classifier loss: 0.149548; batch adversarial loss: 0.468100\n",
      "epoch 32; iter: 0; batch classifier loss: 0.161849; batch adversarial loss: 0.373984\n",
      "epoch 33; iter: 0; batch classifier loss: 0.108091; batch adversarial loss: 0.411611\n",
      "epoch 34; iter: 0; batch classifier loss: 0.126707; batch adversarial loss: 0.421519\n",
      "epoch 35; iter: 0; batch classifier loss: 0.133214; batch adversarial loss: 0.399840\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126408; batch adversarial loss: 0.397948\n",
      "epoch 37; iter: 0; batch classifier loss: 0.116902; batch adversarial loss: 0.428306\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107869; batch adversarial loss: 0.380892\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107732; batch adversarial loss: 0.442410\n",
      "epoch 40; iter: 0; batch classifier loss: 0.082483; batch adversarial loss: 0.382342\n",
      "epoch 41; iter: 0; batch classifier loss: 0.120556; batch adversarial loss: 0.397004\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106870; batch adversarial loss: 0.498638\n",
      "epoch 43; iter: 0; batch classifier loss: 0.114000; batch adversarial loss: 0.423512\n",
      "epoch 44; iter: 0; batch classifier loss: 0.131345; batch adversarial loss: 0.381327\n",
      "epoch 45; iter: 0; batch classifier loss: 0.107895; batch adversarial loss: 0.425283\n",
      "epoch 46; iter: 0; batch classifier loss: 0.087523; batch adversarial loss: 0.385417\n",
      "epoch 47; iter: 0; batch classifier loss: 0.084226; batch adversarial loss: 0.439395\n",
      "epoch 48; iter: 0; batch classifier loss: 0.077605; batch adversarial loss: 0.507586\n",
      "epoch 49; iter: 0; batch classifier loss: 0.100173; batch adversarial loss: 0.390013\n",
      "epoch 50; iter: 0; batch classifier loss: 0.105594; batch adversarial loss: 0.445971\n",
      "epoch 51; iter: 0; batch classifier loss: 0.099588; batch adversarial loss: 0.525793\n",
      "epoch 52; iter: 0; batch classifier loss: 0.079082; batch adversarial loss: 0.462233\n",
      "epoch 53; iter: 0; batch classifier loss: 0.108973; batch adversarial loss: 0.491201\n",
      "epoch 54; iter: 0; batch classifier loss: 0.104413; batch adversarial loss: 0.370148\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087289; batch adversarial loss: 0.424043\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083969; batch adversarial loss: 0.427715\n",
      "epoch 57; iter: 0; batch classifier loss: 0.081549; batch adversarial loss: 0.416418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.060623; batch adversarial loss: 0.424642\n",
      "epoch 59; iter: 0; batch classifier loss: 0.091799; batch adversarial loss: 0.367904\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095007; batch adversarial loss: 0.388103\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080709; batch adversarial loss: 0.359931\n",
      "epoch 62; iter: 0; batch classifier loss: 0.097285; batch adversarial loss: 0.559619\n",
      "epoch 63; iter: 0; batch classifier loss: 0.062236; batch adversarial loss: 0.436540\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101421; batch adversarial loss: 0.454758\n",
      "epoch 65; iter: 0; batch classifier loss: 0.091990; batch adversarial loss: 0.479036\n",
      "epoch 66; iter: 0; batch classifier loss: 0.106089; batch adversarial loss: 0.526778\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080360; batch adversarial loss: 0.389455\n",
      "epoch 68; iter: 0; batch classifier loss: 0.062993; batch adversarial loss: 0.388683\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061968; batch adversarial loss: 0.453769\n",
      "epoch 70; iter: 0; batch classifier loss: 0.052834; batch adversarial loss: 0.395740\n",
      "epoch 71; iter: 0; batch classifier loss: 0.049943; batch adversarial loss: 0.406705\n",
      "epoch 72; iter: 0; batch classifier loss: 0.057561; batch adversarial loss: 0.471243\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074736; batch adversarial loss: 0.456383\n",
      "epoch 74; iter: 0; batch classifier loss: 0.084327; batch adversarial loss: 0.459296\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059579; batch adversarial loss: 0.453534\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063802; batch adversarial loss: 0.538406\n",
      "epoch 77; iter: 0; batch classifier loss: 0.088990; batch adversarial loss: 0.391157\n",
      "epoch 78; iter: 0; batch classifier loss: 0.083327; batch adversarial loss: 0.455799\n",
      "epoch 79; iter: 0; batch classifier loss: 0.048707; batch adversarial loss: 0.390672\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056538; batch adversarial loss: 0.395143\n",
      "epoch 81; iter: 0; batch classifier loss: 0.041794; batch adversarial loss: 0.426873\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066411; batch adversarial loss: 0.457802\n",
      "epoch 83; iter: 0; batch classifier loss: 0.053047; batch adversarial loss: 0.423386\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045121; batch adversarial loss: 0.434072\n",
      "epoch 85; iter: 0; batch classifier loss: 0.041571; batch adversarial loss: 0.410585\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068779; batch adversarial loss: 0.474717\n",
      "epoch 87; iter: 0; batch classifier loss: 0.088821; batch adversarial loss: 0.373457\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075921; batch adversarial loss: 0.459520\n",
      "epoch 89; iter: 0; batch classifier loss: 0.044063; batch adversarial loss: 0.381162\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053730; batch adversarial loss: 0.384259\n",
      "epoch 91; iter: 0; batch classifier loss: 0.023812; batch adversarial loss: 0.441631\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065390; batch adversarial loss: 0.462010\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039086; batch adversarial loss: 0.433938\n",
      "epoch 94; iter: 0; batch classifier loss: 0.028716; batch adversarial loss: 0.453802\n",
      "epoch 95; iter: 0; batch classifier loss: 0.041620; batch adversarial loss: 0.422984\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044207; batch adversarial loss: 0.490592\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060966; batch adversarial loss: 0.440464\n",
      "epoch 98; iter: 0; batch classifier loss: 0.037715; batch adversarial loss: 0.428501\n",
      "epoch 99; iter: 0; batch classifier loss: 0.033292; batch adversarial loss: 0.439722\n",
      "epoch 100; iter: 0; batch classifier loss: 0.030155; batch adversarial loss: 0.408450\n",
      "epoch 101; iter: 0; batch classifier loss: 0.060808; batch adversarial loss: 0.377790\n",
      "epoch 102; iter: 0; batch classifier loss: 0.025769; batch adversarial loss: 0.490730\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033842; batch adversarial loss: 0.510792\n",
      "epoch 104; iter: 0; batch classifier loss: 0.024466; batch adversarial loss: 0.402126\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035102; batch adversarial loss: 0.423436\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035879; batch adversarial loss: 0.502468\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035577; batch adversarial loss: 0.434976\n",
      "epoch 108; iter: 0; batch classifier loss: 0.047158; batch adversarial loss: 0.490498\n",
      "epoch 109; iter: 0; batch classifier loss: 0.020878; batch adversarial loss: 0.428548\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037262; batch adversarial loss: 0.424707\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035574; batch adversarial loss: 0.472360\n",
      "epoch 112; iter: 0; batch classifier loss: 0.022890; batch adversarial loss: 0.425803\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048442; batch adversarial loss: 0.450919\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027177; batch adversarial loss: 0.525496\n",
      "epoch 115; iter: 0; batch classifier loss: 0.030387; batch adversarial loss: 0.394399\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028353; batch adversarial loss: 0.554955\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055754; batch adversarial loss: 0.486241\n",
      "epoch 118; iter: 0; batch classifier loss: 0.071254; batch adversarial loss: 0.606009\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044293; batch adversarial loss: 0.475733\n",
      "epoch 120; iter: 0; batch classifier loss: 0.026082; batch adversarial loss: 0.475920\n",
      "epoch 121; iter: 0; batch classifier loss: 0.074819; batch adversarial loss: 0.493358\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067878; batch adversarial loss: 0.494583\n",
      "epoch 123; iter: 0; batch classifier loss: 0.075291; batch adversarial loss: 0.535044\n",
      "epoch 124; iter: 0; batch classifier loss: 0.060064; batch adversarial loss: 0.493586\n",
      "epoch 125; iter: 0; batch classifier loss: 0.074088; batch adversarial loss: 0.540181\n",
      "epoch 126; iter: 0; batch classifier loss: 0.183008; batch adversarial loss: 0.798666\n",
      "epoch 127; iter: 0; batch classifier loss: 0.147440; batch adversarial loss: 0.655125\n",
      "epoch 128; iter: 0; batch classifier loss: 0.109488; batch adversarial loss: 0.623640\n",
      "epoch 129; iter: 0; batch classifier loss: 0.093393; batch adversarial loss: 0.624020\n",
      "epoch 130; iter: 0; batch classifier loss: 0.126057; batch adversarial loss: 0.698663\n",
      "epoch 131; iter: 0; batch classifier loss: 0.093916; batch adversarial loss: 0.498757\n",
      "epoch 132; iter: 0; batch classifier loss: 0.146951; batch adversarial loss: 0.674073\n",
      "epoch 133; iter: 0; batch classifier loss: 0.109193; batch adversarial loss: 0.515440\n",
      "epoch 134; iter: 0; batch classifier loss: 0.142192; batch adversarial loss: 0.620711\n",
      "epoch 135; iter: 0; batch classifier loss: 0.093516; batch adversarial loss: 0.496154\n",
      "epoch 136; iter: 0; batch classifier loss: 0.130680; batch adversarial loss: 0.668501\n",
      "epoch 137; iter: 0; batch classifier loss: 0.093615; batch adversarial loss: 0.561657\n",
      "epoch 138; iter: 0; batch classifier loss: 0.150311; batch adversarial loss: 0.648950\n",
      "epoch 139; iter: 0; batch classifier loss: 0.115560; batch adversarial loss: 0.564525\n",
      "epoch 140; iter: 0; batch classifier loss: 0.084631; batch adversarial loss: 0.560096\n",
      "epoch 141; iter: 0; batch classifier loss: 0.165098; batch adversarial loss: 0.550156\n",
      "epoch 142; iter: 0; batch classifier loss: 0.121026; batch adversarial loss: 0.592752\n",
      "epoch 143; iter: 0; batch classifier loss: 0.180640; batch adversarial loss: 0.630364\n",
      "epoch 144; iter: 0; batch classifier loss: 0.180862; batch adversarial loss: 0.539862\n",
      "epoch 145; iter: 0; batch classifier loss: 0.094180; batch adversarial loss: 0.552548\n",
      "epoch 146; iter: 0; batch classifier loss: 0.174970; batch adversarial loss: 0.514806\n",
      "epoch 147; iter: 0; batch classifier loss: 0.162923; batch adversarial loss: 0.599299\n",
      "epoch 148; iter: 0; batch classifier loss: 0.141621; batch adversarial loss: 0.543519\n",
      "epoch 149; iter: 0; batch classifier loss: 0.166196; batch adversarial loss: 0.636020\n",
      "epoch 150; iter: 0; batch classifier loss: 0.160211; batch adversarial loss: 0.572737\n",
      "epoch 151; iter: 0; batch classifier loss: 0.116907; batch adversarial loss: 0.509690\n",
      "epoch 152; iter: 0; batch classifier loss: 0.107903; batch adversarial loss: 0.465510\n",
      "epoch 153; iter: 0; batch classifier loss: 0.133064; batch adversarial loss: 0.515975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.106645; batch adversarial loss: 0.455422\n",
      "epoch 155; iter: 0; batch classifier loss: 0.103844; batch adversarial loss: 0.448815\n",
      "epoch 156; iter: 0; batch classifier loss: 0.072536; batch adversarial loss: 0.411337\n",
      "epoch 157; iter: 0; batch classifier loss: 0.100173; batch adversarial loss: 0.500640\n",
      "epoch 158; iter: 0; batch classifier loss: 0.115874; batch adversarial loss: 0.414170\n",
      "epoch 159; iter: 0; batch classifier loss: 0.121240; batch adversarial loss: 0.519487\n",
      "epoch 160; iter: 0; batch classifier loss: 0.109502; batch adversarial loss: 0.518919\n",
      "epoch 161; iter: 0; batch classifier loss: 0.101964; batch adversarial loss: 0.490092\n",
      "epoch 162; iter: 0; batch classifier loss: 0.082012; batch adversarial loss: 0.448700\n",
      "epoch 163; iter: 0; batch classifier loss: 0.147102; batch adversarial loss: 0.521880\n",
      "epoch 164; iter: 0; batch classifier loss: 0.122436; batch adversarial loss: 0.432961\n",
      "epoch 165; iter: 0; batch classifier loss: 0.084614; batch adversarial loss: 0.511582\n",
      "epoch 166; iter: 0; batch classifier loss: 0.108704; batch adversarial loss: 0.461788\n",
      "epoch 167; iter: 0; batch classifier loss: 0.155559; batch adversarial loss: 0.530985\n",
      "epoch 168; iter: 0; batch classifier loss: 0.068391; batch adversarial loss: 0.528514\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038126; batch adversarial loss: 0.348537\n",
      "epoch 170; iter: 0; batch classifier loss: 0.044984; batch adversarial loss: 0.349217\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026352; batch adversarial loss: 0.456907\n",
      "epoch 172; iter: 0; batch classifier loss: 0.052558; batch adversarial loss: 0.420018\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037957; batch adversarial loss: 0.504264\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038795; batch adversarial loss: 0.557948\n",
      "epoch 175; iter: 0; batch classifier loss: 0.052412; batch adversarial loss: 0.491300\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029607; batch adversarial loss: 0.559450\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025607; batch adversarial loss: 0.406989\n",
      "epoch 178; iter: 0; batch classifier loss: 0.058707; batch adversarial loss: 0.444890\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036014; batch adversarial loss: 0.500797\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039396; batch adversarial loss: 0.416565\n",
      "epoch 181; iter: 0; batch classifier loss: 0.070429; batch adversarial loss: 0.499314\n",
      "epoch 182; iter: 0; batch classifier loss: 0.060795; batch adversarial loss: 0.438011\n",
      "epoch 183; iter: 0; batch classifier loss: 0.048761; batch adversarial loss: 0.366971\n",
      "epoch 184; iter: 0; batch classifier loss: 0.054733; batch adversarial loss: 0.420384\n",
      "epoch 185; iter: 0; batch classifier loss: 0.083953; batch adversarial loss: 0.451554\n",
      "epoch 186; iter: 0; batch classifier loss: 0.056777; batch adversarial loss: 0.423570\n",
      "epoch 187; iter: 0; batch classifier loss: 0.108676; batch adversarial loss: 0.438017\n",
      "epoch 188; iter: 0; batch classifier loss: 0.068749; batch adversarial loss: 0.467492\n",
      "epoch 189; iter: 0; batch classifier loss: 0.101767; batch adversarial loss: 0.431196\n",
      "epoch 190; iter: 0; batch classifier loss: 0.071152; batch adversarial loss: 0.471687\n",
      "epoch 191; iter: 0; batch classifier loss: 0.074648; batch adversarial loss: 0.504887\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040545; batch adversarial loss: 0.529032\n",
      "epoch 193; iter: 0; batch classifier loss: 0.096479; batch adversarial loss: 0.471242\n",
      "epoch 194; iter: 0; batch classifier loss: 0.079060; batch adversarial loss: 0.514938\n",
      "epoch 195; iter: 0; batch classifier loss: 0.046289; batch adversarial loss: 0.522879\n",
      "epoch 196; iter: 0; batch classifier loss: 0.047739; batch adversarial loss: 0.444995\n",
      "epoch 197; iter: 0; batch classifier loss: 0.048117; batch adversarial loss: 0.486854\n",
      "epoch 198; iter: 0; batch classifier loss: 0.051481; batch adversarial loss: 0.437855\n",
      "epoch 199; iter: 0; batch classifier loss: 0.077822; batch adversarial loss: 0.411624\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682848; batch adversarial loss: 0.711795\n",
      "epoch 1; iter: 0; batch classifier loss: 0.444025; batch adversarial loss: 0.660118\n",
      "epoch 2; iter: 0; batch classifier loss: 0.392651; batch adversarial loss: 0.652414\n",
      "epoch 3; iter: 0; batch classifier loss: 0.399457; batch adversarial loss: 0.614351\n",
      "epoch 4; iter: 0; batch classifier loss: 0.354484; batch adversarial loss: 0.618203\n",
      "epoch 5; iter: 0; batch classifier loss: 0.414776; batch adversarial loss: 0.585741\n",
      "epoch 6; iter: 0; batch classifier loss: 0.388941; batch adversarial loss: 0.560498\n",
      "epoch 7; iter: 0; batch classifier loss: 0.382553; batch adversarial loss: 0.591775\n",
      "epoch 8; iter: 0; batch classifier loss: 0.421701; batch adversarial loss: 0.560007\n",
      "epoch 9; iter: 0; batch classifier loss: 0.420552; batch adversarial loss: 0.535692\n",
      "epoch 10; iter: 0; batch classifier loss: 0.364721; batch adversarial loss: 0.557719\n",
      "epoch 11; iter: 0; batch classifier loss: 0.423519; batch adversarial loss: 0.567507\n",
      "epoch 12; iter: 0; batch classifier loss: 0.413827; batch adversarial loss: 0.486836\n",
      "epoch 13; iter: 0; batch classifier loss: 0.301577; batch adversarial loss: 0.553682\n",
      "epoch 14; iter: 0; batch classifier loss: 0.378749; batch adversarial loss: 0.449242\n",
      "epoch 15; iter: 0; batch classifier loss: 0.318181; batch adversarial loss: 0.558504\n",
      "epoch 16; iter: 0; batch classifier loss: 0.256557; batch adversarial loss: 0.546202\n",
      "epoch 17; iter: 0; batch classifier loss: 0.295344; batch adversarial loss: 0.555943\n",
      "epoch 18; iter: 0; batch classifier loss: 0.299734; batch adversarial loss: 0.545833\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261830; batch adversarial loss: 0.529381\n",
      "epoch 20; iter: 0; batch classifier loss: 0.347896; batch adversarial loss: 0.506397\n",
      "epoch 21; iter: 0; batch classifier loss: 0.310936; batch adversarial loss: 0.457116\n",
      "epoch 22; iter: 0; batch classifier loss: 0.241263; batch adversarial loss: 0.496773\n",
      "epoch 23; iter: 0; batch classifier loss: 0.359810; batch adversarial loss: 0.408870\n",
      "epoch 24; iter: 0; batch classifier loss: 0.288736; batch adversarial loss: 0.470249\n",
      "epoch 25; iter: 0; batch classifier loss: 0.253578; batch adversarial loss: 0.480459\n",
      "epoch 26; iter: 0; batch classifier loss: 0.272478; batch adversarial loss: 0.427240\n",
      "epoch 27; iter: 0; batch classifier loss: 0.211232; batch adversarial loss: 0.531613\n",
      "epoch 28; iter: 0; batch classifier loss: 0.209805; batch adversarial loss: 0.497701\n",
      "epoch 29; iter: 0; batch classifier loss: 0.280116; batch adversarial loss: 0.499275\n",
      "epoch 30; iter: 0; batch classifier loss: 0.230129; batch adversarial loss: 0.463784\n",
      "epoch 31; iter: 0; batch classifier loss: 0.163145; batch adversarial loss: 0.477090\n",
      "epoch 32; iter: 0; batch classifier loss: 0.190761; batch adversarial loss: 0.407137\n",
      "epoch 33; iter: 0; batch classifier loss: 0.187070; batch adversarial loss: 0.461248\n",
      "epoch 34; iter: 0; batch classifier loss: 0.224166; batch adversarial loss: 0.440021\n",
      "epoch 35; iter: 0; batch classifier loss: 0.168908; batch adversarial loss: 0.486672\n",
      "epoch 36; iter: 0; batch classifier loss: 0.294026; batch adversarial loss: 0.362882\n",
      "epoch 37; iter: 0; batch classifier loss: 0.258013; batch adversarial loss: 0.459255\n",
      "epoch 38; iter: 0; batch classifier loss: 0.204123; batch adversarial loss: 0.483364\n",
      "epoch 39; iter: 0; batch classifier loss: 0.234060; batch adversarial loss: 0.447014\n",
      "epoch 40; iter: 0; batch classifier loss: 0.233529; batch adversarial loss: 0.454253\n",
      "epoch 41; iter: 0; batch classifier loss: 0.231763; batch adversarial loss: 0.530671\n",
      "epoch 42; iter: 0; batch classifier loss: 0.220663; batch adversarial loss: 0.449923\n",
      "epoch 43; iter: 0; batch classifier loss: 0.242223; batch adversarial loss: 0.410907\n",
      "epoch 44; iter: 0; batch classifier loss: 0.189463; batch adversarial loss: 0.470000\n",
      "epoch 45; iter: 0; batch classifier loss: 0.230985; batch adversarial loss: 0.486968\n",
      "epoch 46; iter: 0; batch classifier loss: 0.242979; batch adversarial loss: 0.494028\n",
      "epoch 47; iter: 0; batch classifier loss: 0.247609; batch adversarial loss: 0.518416\n",
      "epoch 48; iter: 0; batch classifier loss: 0.202040; batch adversarial loss: 0.460113\n",
      "epoch 49; iter: 0; batch classifier loss: 0.253525; batch adversarial loss: 0.400460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.190354; batch adversarial loss: 0.377846\n",
      "epoch 51; iter: 0; batch classifier loss: 0.214348; batch adversarial loss: 0.506454\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101534; batch adversarial loss: 0.492411\n",
      "epoch 53; iter: 0; batch classifier loss: 0.107168; batch adversarial loss: 0.443588\n",
      "epoch 54; iter: 0; batch classifier loss: 0.125158; batch adversarial loss: 0.389328\n",
      "epoch 55; iter: 0; batch classifier loss: 0.110602; batch adversarial loss: 0.521950\n",
      "epoch 56; iter: 0; batch classifier loss: 0.073186; batch adversarial loss: 0.494305\n",
      "epoch 57; iter: 0; batch classifier loss: 0.052455; batch adversarial loss: 0.452314\n",
      "epoch 58; iter: 0; batch classifier loss: 0.047334; batch adversarial loss: 0.406623\n",
      "epoch 59; iter: 0; batch classifier loss: 0.043830; batch adversarial loss: 0.473978\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061996; batch adversarial loss: 0.356034\n",
      "epoch 61; iter: 0; batch classifier loss: 0.059551; batch adversarial loss: 0.455126\n",
      "epoch 62; iter: 0; batch classifier loss: 0.066038; batch adversarial loss: 0.550312\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092893; batch adversarial loss: 0.468621\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082297; batch adversarial loss: 0.522565\n",
      "epoch 65; iter: 0; batch classifier loss: 0.084059; batch adversarial loss: 0.480683\n",
      "epoch 66; iter: 0; batch classifier loss: 0.076416; batch adversarial loss: 0.403183\n",
      "epoch 67; iter: 0; batch classifier loss: 0.067918; batch adversarial loss: 0.452205\n",
      "epoch 68; iter: 0; batch classifier loss: 0.102911; batch adversarial loss: 0.435024\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064521; batch adversarial loss: 0.424722\n",
      "epoch 70; iter: 0; batch classifier loss: 0.089199; batch adversarial loss: 0.434112\n",
      "epoch 71; iter: 0; batch classifier loss: 0.075197; batch adversarial loss: 0.493375\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077751; batch adversarial loss: 0.378124\n",
      "epoch 73; iter: 0; batch classifier loss: 0.080005; batch adversarial loss: 0.485873\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102194; batch adversarial loss: 0.365282\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075140; batch adversarial loss: 0.532339\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065136; batch adversarial loss: 0.330599\n",
      "epoch 77; iter: 0; batch classifier loss: 0.105450; batch adversarial loss: 0.440236\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066665; batch adversarial loss: 0.545057\n",
      "epoch 79; iter: 0; batch classifier loss: 0.083840; batch adversarial loss: 0.434747\n",
      "epoch 80; iter: 0; batch classifier loss: 0.069102; batch adversarial loss: 0.374299\n",
      "epoch 81; iter: 0; batch classifier loss: 0.063859; batch adversarial loss: 0.395351\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075403; batch adversarial loss: 0.447357\n",
      "epoch 83; iter: 0; batch classifier loss: 0.090171; batch adversarial loss: 0.427546\n",
      "epoch 84; iter: 0; batch classifier loss: 0.043608; batch adversarial loss: 0.498644\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061380; batch adversarial loss: 0.499598\n",
      "epoch 86; iter: 0; batch classifier loss: 0.044434; batch adversarial loss: 0.548803\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071362; batch adversarial loss: 0.395311\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063625; batch adversarial loss: 0.458391\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069029; batch adversarial loss: 0.423799\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065806; batch adversarial loss: 0.536184\n",
      "epoch 91; iter: 0; batch classifier loss: 0.069489; batch adversarial loss: 0.416966\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069308; batch adversarial loss: 0.451670\n",
      "epoch 93; iter: 0; batch classifier loss: 0.074141; batch adversarial loss: 0.484424\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058894; batch adversarial loss: 0.438982\n",
      "epoch 95; iter: 0; batch classifier loss: 0.067021; batch adversarial loss: 0.528038\n",
      "epoch 96; iter: 0; batch classifier loss: 0.097127; batch adversarial loss: 0.406795\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049224; batch adversarial loss: 0.395516\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049134; batch adversarial loss: 0.412334\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056135; batch adversarial loss: 0.365868\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060620; batch adversarial loss: 0.460452\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054594; batch adversarial loss: 0.392478\n",
      "epoch 102; iter: 0; batch classifier loss: 0.061010; batch adversarial loss: 0.492951\n",
      "epoch 103; iter: 0; batch classifier loss: 0.081831; batch adversarial loss: 0.424269\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069132; batch adversarial loss: 0.435133\n",
      "epoch 105; iter: 0; batch classifier loss: 0.077281; batch adversarial loss: 0.458136\n",
      "epoch 106; iter: 0; batch classifier loss: 0.072251; batch adversarial loss: 0.441885\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050303; batch adversarial loss: 0.496528\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059190; batch adversarial loss: 0.353450\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061643; batch adversarial loss: 0.414642\n",
      "epoch 110; iter: 0; batch classifier loss: 0.087225; batch adversarial loss: 0.450454\n",
      "epoch 111; iter: 0; batch classifier loss: 0.056913; batch adversarial loss: 0.432969\n",
      "epoch 112; iter: 0; batch classifier loss: 0.058160; batch adversarial loss: 0.421933\n",
      "epoch 113; iter: 0; batch classifier loss: 0.074490; batch adversarial loss: 0.420452\n",
      "epoch 114; iter: 0; batch classifier loss: 0.084388; batch adversarial loss: 0.420052\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056037; batch adversarial loss: 0.414724\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062171; batch adversarial loss: 0.465662\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042972; batch adversarial loss: 0.403924\n",
      "epoch 118; iter: 0; batch classifier loss: 0.076376; batch adversarial loss: 0.431272\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060002; batch adversarial loss: 0.367544\n",
      "epoch 120; iter: 0; batch classifier loss: 0.063357; batch adversarial loss: 0.433700\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048462; batch adversarial loss: 0.381677\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041630; batch adversarial loss: 0.397821\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053364; batch adversarial loss: 0.532067\n",
      "epoch 124; iter: 0; batch classifier loss: 0.073215; batch adversarial loss: 0.340196\n",
      "epoch 125; iter: 0; batch classifier loss: 0.078842; batch adversarial loss: 0.417960\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046290; batch adversarial loss: 0.390884\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044414; batch adversarial loss: 0.441761\n",
      "epoch 128; iter: 0; batch classifier loss: 0.060892; batch adversarial loss: 0.418852\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025035; batch adversarial loss: 0.425027\n",
      "epoch 130; iter: 0; batch classifier loss: 0.052088; batch adversarial loss: 0.350283\n",
      "epoch 131; iter: 0; batch classifier loss: 0.059023; batch adversarial loss: 0.345566\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043350; batch adversarial loss: 0.431605\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035018; batch adversarial loss: 0.480359\n",
      "epoch 134; iter: 0; batch classifier loss: 0.081395; batch adversarial loss: 0.405946\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034788; batch adversarial loss: 0.502825\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026261; batch adversarial loss: 0.460680\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042065; batch adversarial loss: 0.502078\n",
      "epoch 138; iter: 0; batch classifier loss: 0.063094; batch adversarial loss: 0.439204\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036683; batch adversarial loss: 0.302472\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033657; batch adversarial loss: 0.398879\n",
      "epoch 141; iter: 0; batch classifier loss: 0.064502; batch adversarial loss: 0.345543\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028913; batch adversarial loss: 0.371537\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025822; batch adversarial loss: 0.546450\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033973; batch adversarial loss: 0.451340\n",
      "epoch 145; iter: 0; batch classifier loss: 0.063620; batch adversarial loss: 0.405616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.016334; batch adversarial loss: 0.439141\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031687; batch adversarial loss: 0.444752\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036609; batch adversarial loss: 0.478124\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034093; batch adversarial loss: 0.488229\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029255; batch adversarial loss: 0.449210\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037262; batch adversarial loss: 0.403897\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023593; batch adversarial loss: 0.439146\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029608; batch adversarial loss: 0.431815\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030907; batch adversarial loss: 0.463094\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023493; batch adversarial loss: 0.378970\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044895; batch adversarial loss: 0.399399\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037856; batch adversarial loss: 0.356443\n",
      "epoch 158; iter: 0; batch classifier loss: 0.041047; batch adversarial loss: 0.431834\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014883; batch adversarial loss: 0.479484\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035222; batch adversarial loss: 0.526442\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018718; batch adversarial loss: 0.586982\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031794; batch adversarial loss: 0.417675\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030596; batch adversarial loss: 0.480559\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021860; batch adversarial loss: 0.533772\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015893; batch adversarial loss: 0.449907\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034805; batch adversarial loss: 0.513163\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021397; batch adversarial loss: 0.411369\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027096; batch adversarial loss: 0.419718\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029381; batch adversarial loss: 0.470403\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015784; batch adversarial loss: 0.427276\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036422; batch adversarial loss: 0.470672\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010783; batch adversarial loss: 0.450446\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011072; batch adversarial loss: 0.382208\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018644; batch adversarial loss: 0.386262\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013215; batch adversarial loss: 0.549023\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012540; batch adversarial loss: 0.405420\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025899; batch adversarial loss: 0.408336\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039223; batch adversarial loss: 0.400261\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018617; batch adversarial loss: 0.499404\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011740; batch adversarial loss: 0.486691\n",
      "epoch 181; iter: 0; batch classifier loss: 0.059084; batch adversarial loss: 0.499120\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006670; batch adversarial loss: 0.504128\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012886; batch adversarial loss: 0.405916\n",
      "epoch 184; iter: 0; batch classifier loss: 0.064582; batch adversarial loss: 0.439739\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018475; batch adversarial loss: 0.476856\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018225; batch adversarial loss: 0.492516\n",
      "epoch 187; iter: 0; batch classifier loss: 0.038038; batch adversarial loss: 0.392688\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021298; batch adversarial loss: 0.413001\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011853; batch adversarial loss: 0.472897\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025484; batch adversarial loss: 0.397069\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007196; batch adversarial loss: 0.353310\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032725; batch adversarial loss: 0.458556\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014710; batch adversarial loss: 0.461018\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016670; batch adversarial loss: 0.561084\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008453; batch adversarial loss: 0.478415\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006191; batch adversarial loss: 0.485164\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039517; batch adversarial loss: 0.381320\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003131; batch adversarial loss: 0.462800\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017959; batch adversarial loss: 0.428713\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687681; batch adversarial loss: 0.762311\n",
      "epoch 1; iter: 0; batch classifier loss: 0.470332; batch adversarial loss: 0.764732\n",
      "epoch 2; iter: 0; batch classifier loss: 0.444382; batch adversarial loss: 0.726698\n",
      "epoch 3; iter: 0; batch classifier loss: 0.340192; batch adversarial loss: 0.679520\n",
      "epoch 4; iter: 0; batch classifier loss: 0.303495; batch adversarial loss: 0.649368\n",
      "epoch 5; iter: 0; batch classifier loss: 0.390471; batch adversarial loss: 0.595833\n",
      "epoch 6; iter: 0; batch classifier loss: 0.316039; batch adversarial loss: 0.586318\n",
      "epoch 7; iter: 0; batch classifier loss: 0.297131; batch adversarial loss: 0.572243\n",
      "epoch 8; iter: 0; batch classifier loss: 0.300671; batch adversarial loss: 0.531315\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273490; batch adversarial loss: 0.524402\n",
      "epoch 10; iter: 0; batch classifier loss: 0.308133; batch adversarial loss: 0.499725\n",
      "epoch 11; iter: 0; batch classifier loss: 0.262100; batch adversarial loss: 0.494967\n",
      "epoch 12; iter: 0; batch classifier loss: 0.260380; batch adversarial loss: 0.487837\n",
      "epoch 13; iter: 0; batch classifier loss: 0.206232; batch adversarial loss: 0.486800\n",
      "epoch 14; iter: 0; batch classifier loss: 0.169640; batch adversarial loss: 0.454823\n",
      "epoch 15; iter: 0; batch classifier loss: 0.220992; batch adversarial loss: 0.436927\n",
      "epoch 16; iter: 0; batch classifier loss: 0.199338; batch adversarial loss: 0.466019\n",
      "epoch 17; iter: 0; batch classifier loss: 0.215606; batch adversarial loss: 0.434768\n",
      "epoch 18; iter: 0; batch classifier loss: 0.141045; batch adversarial loss: 0.432334\n",
      "epoch 19; iter: 0; batch classifier loss: 0.159497; batch adversarial loss: 0.495386\n",
      "epoch 20; iter: 0; batch classifier loss: 0.125228; batch adversarial loss: 0.484099\n",
      "epoch 21; iter: 0; batch classifier loss: 0.174292; batch adversarial loss: 0.457319\n",
      "epoch 22; iter: 0; batch classifier loss: 0.122545; batch adversarial loss: 0.459305\n",
      "epoch 23; iter: 0; batch classifier loss: 0.115344; batch adversarial loss: 0.478626\n",
      "epoch 24; iter: 0; batch classifier loss: 0.090390; batch adversarial loss: 0.480696\n",
      "epoch 25; iter: 0; batch classifier loss: 0.130278; batch adversarial loss: 0.375143\n",
      "epoch 26; iter: 0; batch classifier loss: 0.095879; batch adversarial loss: 0.414562\n",
      "epoch 27; iter: 0; batch classifier loss: 0.136012; batch adversarial loss: 0.445195\n",
      "epoch 28; iter: 0; batch classifier loss: 0.125100; batch adversarial loss: 0.375463\n",
      "epoch 29; iter: 0; batch classifier loss: 0.085226; batch adversarial loss: 0.405972\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138174; batch adversarial loss: 0.425586\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134853; batch adversarial loss: 0.350270\n",
      "epoch 32; iter: 0; batch classifier loss: 0.115263; batch adversarial loss: 0.432167\n",
      "epoch 33; iter: 0; batch classifier loss: 0.153403; batch adversarial loss: 0.384126\n",
      "epoch 34; iter: 0; batch classifier loss: 0.125161; batch adversarial loss: 0.429798\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153838; batch adversarial loss: 0.349390\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126983; batch adversarial loss: 0.424400\n",
      "epoch 37; iter: 0; batch classifier loss: 0.135108; batch adversarial loss: 0.409795\n",
      "epoch 38; iter: 0; batch classifier loss: 0.156630; batch adversarial loss: 0.472899\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113731; batch adversarial loss: 0.399331\n",
      "epoch 40; iter: 0; batch classifier loss: 0.129488; batch adversarial loss: 0.449937\n",
      "epoch 41; iter: 0; batch classifier loss: 0.162887; batch adversarial loss: 0.387847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.095597; batch adversarial loss: 0.465691\n",
      "epoch 43; iter: 0; batch classifier loss: 0.139525; batch adversarial loss: 0.419987\n",
      "epoch 44; iter: 0; batch classifier loss: 0.102683; batch adversarial loss: 0.432048\n",
      "epoch 45; iter: 0; batch classifier loss: 0.071124; batch adversarial loss: 0.414831\n",
      "epoch 46; iter: 0; batch classifier loss: 0.081232; batch adversarial loss: 0.468470\n",
      "epoch 47; iter: 0; batch classifier loss: 0.075338; batch adversarial loss: 0.430177\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099693; batch adversarial loss: 0.421098\n",
      "epoch 49; iter: 0; batch classifier loss: 0.112672; batch adversarial loss: 0.420391\n",
      "epoch 50; iter: 0; batch classifier loss: 0.115916; batch adversarial loss: 0.415086\n",
      "epoch 51; iter: 0; batch classifier loss: 0.126273; batch adversarial loss: 0.444096\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082036; batch adversarial loss: 0.404603\n",
      "epoch 53; iter: 0; batch classifier loss: 0.128020; batch adversarial loss: 0.469665\n",
      "epoch 54; iter: 0; batch classifier loss: 0.094853; batch adversarial loss: 0.388417\n",
      "epoch 55; iter: 0; batch classifier loss: 0.085644; batch adversarial loss: 0.415012\n",
      "epoch 56; iter: 0; batch classifier loss: 0.105983; batch adversarial loss: 0.341636\n",
      "epoch 57; iter: 0; batch classifier loss: 0.066781; batch adversarial loss: 0.371539\n",
      "epoch 58; iter: 0; batch classifier loss: 0.129981; batch adversarial loss: 0.458731\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076739; batch adversarial loss: 0.421803\n",
      "epoch 60; iter: 0; batch classifier loss: 0.077744; batch adversarial loss: 0.444592\n",
      "epoch 61; iter: 0; batch classifier loss: 0.096957; batch adversarial loss: 0.440545\n",
      "epoch 62; iter: 0; batch classifier loss: 0.099659; batch adversarial loss: 0.366890\n",
      "epoch 63; iter: 0; batch classifier loss: 0.087967; batch adversarial loss: 0.385929\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084310; batch adversarial loss: 0.437018\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070010; batch adversarial loss: 0.463367\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078740; batch adversarial loss: 0.371088\n",
      "epoch 67; iter: 0; batch classifier loss: 0.078762; batch adversarial loss: 0.390190\n",
      "epoch 68; iter: 0; batch classifier loss: 0.041958; batch adversarial loss: 0.437151\n",
      "epoch 69; iter: 0; batch classifier loss: 0.058202; batch adversarial loss: 0.502223\n",
      "epoch 70; iter: 0; batch classifier loss: 0.049181; batch adversarial loss: 0.354849\n",
      "epoch 71; iter: 0; batch classifier loss: 0.052716; batch adversarial loss: 0.414864\n",
      "epoch 72; iter: 0; batch classifier loss: 0.039715; batch adversarial loss: 0.410206\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079240; batch adversarial loss: 0.341359\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054683; batch adversarial loss: 0.339380\n",
      "epoch 75; iter: 0; batch classifier loss: 0.074567; batch adversarial loss: 0.465236\n",
      "epoch 76; iter: 0; batch classifier loss: 0.044592; batch adversarial loss: 0.522654\n",
      "epoch 77; iter: 0; batch classifier loss: 0.043913; batch adversarial loss: 0.369109\n",
      "epoch 78; iter: 0; batch classifier loss: 0.039741; batch adversarial loss: 0.399994\n",
      "epoch 79; iter: 0; batch classifier loss: 0.050502; batch adversarial loss: 0.454867\n",
      "epoch 80; iter: 0; batch classifier loss: 0.049833; batch adversarial loss: 0.393423\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076802; batch adversarial loss: 0.394012\n",
      "epoch 82; iter: 0; batch classifier loss: 0.038657; batch adversarial loss: 0.472517\n",
      "epoch 83; iter: 0; batch classifier loss: 0.041137; batch adversarial loss: 0.422732\n",
      "epoch 84; iter: 0; batch classifier loss: 0.031562; batch adversarial loss: 0.464072\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045146; batch adversarial loss: 0.491296\n",
      "epoch 86; iter: 0; batch classifier loss: 0.078080; batch adversarial loss: 0.449286\n",
      "epoch 87; iter: 0; batch classifier loss: 0.026517; batch adversarial loss: 0.479347\n",
      "epoch 88; iter: 0; batch classifier loss: 0.031778; batch adversarial loss: 0.463295\n",
      "epoch 89; iter: 0; batch classifier loss: 0.032128; batch adversarial loss: 0.531886\n",
      "epoch 90; iter: 0; batch classifier loss: 0.090129; batch adversarial loss: 0.403243\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043016; batch adversarial loss: 0.453253\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043651; batch adversarial loss: 0.574116\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055455; batch adversarial loss: 0.466050\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050316; batch adversarial loss: 0.413808\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083271; batch adversarial loss: 0.567630\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056572; batch adversarial loss: 0.606471\n",
      "epoch 97; iter: 0; batch classifier loss: 0.030617; batch adversarial loss: 0.359242\n",
      "epoch 98; iter: 0; batch classifier loss: 0.100358; batch adversarial loss: 0.609789\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040672; batch adversarial loss: 0.543393\n",
      "epoch 100; iter: 0; batch classifier loss: 0.117015; batch adversarial loss: 0.676840\n",
      "epoch 101; iter: 0; batch classifier loss: 0.105178; batch adversarial loss: 0.487213\n",
      "epoch 102; iter: 0; batch classifier loss: 0.115347; batch adversarial loss: 0.564259\n",
      "epoch 103; iter: 0; batch classifier loss: 0.123778; batch adversarial loss: 0.614044\n",
      "epoch 104; iter: 0; batch classifier loss: 0.148267; batch adversarial loss: 0.551243\n",
      "epoch 105; iter: 0; batch classifier loss: 0.163255; batch adversarial loss: 0.630053\n",
      "epoch 106; iter: 0; batch classifier loss: 0.141129; batch adversarial loss: 0.597331\n",
      "epoch 107; iter: 0; batch classifier loss: 0.154491; batch adversarial loss: 0.644418\n",
      "epoch 108; iter: 0; batch classifier loss: 0.242480; batch adversarial loss: 0.789817\n",
      "epoch 109; iter: 0; batch classifier loss: 0.121339; batch adversarial loss: 0.555702\n",
      "epoch 110; iter: 0; batch classifier loss: 0.208934; batch adversarial loss: 0.571495\n",
      "epoch 111; iter: 0; batch classifier loss: 0.165990; batch adversarial loss: 0.624213\n",
      "epoch 112; iter: 0; batch classifier loss: 0.120758; batch adversarial loss: 0.593341\n",
      "epoch 113; iter: 0; batch classifier loss: 0.115707; batch adversarial loss: 0.583716\n",
      "epoch 114; iter: 0; batch classifier loss: 0.129083; batch adversarial loss: 0.530623\n",
      "epoch 115; iter: 0; batch classifier loss: 0.225482; batch adversarial loss: 0.581099\n",
      "epoch 116; iter: 0; batch classifier loss: 0.196948; batch adversarial loss: 0.628462\n",
      "epoch 117; iter: 0; batch classifier loss: 0.171010; batch adversarial loss: 0.506136\n",
      "epoch 118; iter: 0; batch classifier loss: 0.103330; batch adversarial loss: 0.472469\n",
      "epoch 119; iter: 0; batch classifier loss: 0.147014; batch adversarial loss: 0.544402\n",
      "epoch 120; iter: 0; batch classifier loss: 0.197203; batch adversarial loss: 0.614511\n",
      "epoch 121; iter: 0; batch classifier loss: 0.160001; batch adversarial loss: 0.617807\n",
      "epoch 122; iter: 0; batch classifier loss: 0.094378; batch adversarial loss: 0.424163\n",
      "epoch 123; iter: 0; batch classifier loss: 0.168977; batch adversarial loss: 0.570880\n",
      "epoch 124; iter: 0; batch classifier loss: 0.143203; batch adversarial loss: 0.650916\n",
      "epoch 125; iter: 0; batch classifier loss: 0.167540; batch adversarial loss: 0.584410\n",
      "epoch 126; iter: 0; batch classifier loss: 0.160052; batch adversarial loss: 0.595440\n",
      "epoch 127; iter: 0; batch classifier loss: 0.125146; batch adversarial loss: 0.494864\n",
      "epoch 128; iter: 0; batch classifier loss: 0.156117; batch adversarial loss: 0.577702\n",
      "epoch 129; iter: 0; batch classifier loss: 0.122095; batch adversarial loss: 0.607667\n",
      "epoch 130; iter: 0; batch classifier loss: 0.081616; batch adversarial loss: 0.444517\n",
      "epoch 131; iter: 0; batch classifier loss: 0.159337; batch adversarial loss: 0.465960\n",
      "epoch 132; iter: 0; batch classifier loss: 0.107309; batch adversarial loss: 0.497064\n",
      "epoch 133; iter: 0; batch classifier loss: 0.158102; batch adversarial loss: 0.584135\n",
      "epoch 134; iter: 0; batch classifier loss: 0.154678; batch adversarial loss: 0.424848\n",
      "epoch 135; iter: 0; batch classifier loss: 0.085338; batch adversarial loss: 0.464572\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038821; batch adversarial loss: 0.515357\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036890; batch adversarial loss: 0.388032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.053647; batch adversarial loss: 0.396166\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035864; batch adversarial loss: 0.489851\n",
      "epoch 140; iter: 0; batch classifier loss: 0.059210; batch adversarial loss: 0.472603\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045356; batch adversarial loss: 0.423673\n",
      "epoch 142; iter: 0; batch classifier loss: 0.057512; batch adversarial loss: 0.532794\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053025; batch adversarial loss: 0.391226\n",
      "epoch 144; iter: 0; batch classifier loss: 0.085261; batch adversarial loss: 0.421861\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031279; batch adversarial loss: 0.588762\n",
      "epoch 146; iter: 0; batch classifier loss: 0.049340; batch adversarial loss: 0.503005\n",
      "epoch 147; iter: 0; batch classifier loss: 0.105897; batch adversarial loss: 0.445293\n",
      "epoch 148; iter: 0; batch classifier loss: 0.073820; batch adversarial loss: 0.456848\n",
      "epoch 149; iter: 0; batch classifier loss: 0.074929; batch adversarial loss: 0.456600\n",
      "epoch 150; iter: 0; batch classifier loss: 0.122583; batch adversarial loss: 0.575148\n",
      "epoch 151; iter: 0; batch classifier loss: 0.105621; batch adversarial loss: 0.553403\n",
      "epoch 152; iter: 0; batch classifier loss: 0.100679; batch adversarial loss: 0.447269\n",
      "epoch 153; iter: 0; batch classifier loss: 0.085797; batch adversarial loss: 0.494706\n",
      "epoch 154; iter: 0; batch classifier loss: 0.056993; batch adversarial loss: 0.449143\n",
      "epoch 155; iter: 0; batch classifier loss: 0.070216; batch adversarial loss: 0.580362\n",
      "epoch 156; iter: 0; batch classifier loss: 0.097964; batch adversarial loss: 0.468095\n",
      "epoch 157; iter: 0; batch classifier loss: 0.070495; batch adversarial loss: 0.477884\n",
      "epoch 158; iter: 0; batch classifier loss: 0.077379; batch adversarial loss: 0.408356\n",
      "epoch 159; iter: 0; batch classifier loss: 0.139195; batch adversarial loss: 0.405702\n",
      "epoch 160; iter: 0; batch classifier loss: 0.047897; batch adversarial loss: 0.441146\n",
      "epoch 161; iter: 0; batch classifier loss: 0.069939; batch adversarial loss: 0.468856\n",
      "epoch 162; iter: 0; batch classifier loss: 0.075465; batch adversarial loss: 0.509298\n",
      "epoch 163; iter: 0; batch classifier loss: 0.155109; batch adversarial loss: 0.603771\n",
      "epoch 164; iter: 0; batch classifier loss: 0.115323; batch adversarial loss: 0.455488\n",
      "epoch 165; iter: 0; batch classifier loss: 0.140068; batch adversarial loss: 0.439537\n",
      "epoch 166; iter: 0; batch classifier loss: 0.117851; batch adversarial loss: 0.433457\n",
      "epoch 167; iter: 0; batch classifier loss: 0.138232; batch adversarial loss: 0.506435\n",
      "epoch 168; iter: 0; batch classifier loss: 0.160774; batch adversarial loss: 0.432353\n",
      "epoch 169; iter: 0; batch classifier loss: 0.092811; batch adversarial loss: 0.512934\n",
      "epoch 170; iter: 0; batch classifier loss: 0.145961; batch adversarial loss: 0.537362\n",
      "epoch 171; iter: 0; batch classifier loss: 0.117077; batch adversarial loss: 0.494351\n",
      "epoch 172; iter: 0; batch classifier loss: 0.122796; batch adversarial loss: 0.504245\n",
      "epoch 173; iter: 0; batch classifier loss: 0.105333; batch adversarial loss: 0.561319\n",
      "epoch 174; iter: 0; batch classifier loss: 0.122999; batch adversarial loss: 0.487358\n",
      "epoch 175; iter: 0; batch classifier loss: 0.063129; batch adversarial loss: 0.499240\n",
      "epoch 176; iter: 0; batch classifier loss: 0.136740; batch adversarial loss: 0.478445\n",
      "epoch 177; iter: 0; batch classifier loss: 0.109243; batch adversarial loss: 0.402408\n",
      "epoch 178; iter: 0; batch classifier loss: 0.120620; batch adversarial loss: 0.552418\n",
      "epoch 179; iter: 0; batch classifier loss: 0.109770; batch adversarial loss: 0.430782\n",
      "epoch 180; iter: 0; batch classifier loss: 0.126209; batch adversarial loss: 0.545530\n",
      "epoch 181; iter: 0; batch classifier loss: 0.066565; batch adversarial loss: 0.462817\n",
      "epoch 182; iter: 0; batch classifier loss: 0.066010; batch adversarial loss: 0.523880\n",
      "epoch 183; iter: 0; batch classifier loss: 0.067906; batch adversarial loss: 0.403598\n",
      "epoch 184; iter: 0; batch classifier loss: 0.095768; batch adversarial loss: 0.523978\n",
      "epoch 185; iter: 0; batch classifier loss: 0.087133; batch adversarial loss: 0.424498\n",
      "epoch 186; iter: 0; batch classifier loss: 0.093391; batch adversarial loss: 0.516728\n",
      "epoch 187; iter: 0; batch classifier loss: 0.093556; batch adversarial loss: 0.515291\n",
      "epoch 188; iter: 0; batch classifier loss: 0.116549; batch adversarial loss: 0.455545\n",
      "epoch 189; iter: 0; batch classifier loss: 0.087188; batch adversarial loss: 0.531937\n",
      "epoch 190; iter: 0; batch classifier loss: 0.062584; batch adversarial loss: 0.507009\n",
      "epoch 191; iter: 0; batch classifier loss: 0.106047; batch adversarial loss: 0.481095\n",
      "epoch 192; iter: 0; batch classifier loss: 0.084329; batch adversarial loss: 0.409157\n",
      "epoch 193; iter: 0; batch classifier loss: 0.107019; batch adversarial loss: 0.470124\n",
      "epoch 194; iter: 0; batch classifier loss: 0.104107; batch adversarial loss: 0.451319\n",
      "epoch 195; iter: 0; batch classifier loss: 0.051633; batch adversarial loss: 0.438472\n",
      "epoch 196; iter: 0; batch classifier loss: 0.105850; batch adversarial loss: 0.465312\n",
      "epoch 197; iter: 0; batch classifier loss: 0.053146; batch adversarial loss: 0.556605\n",
      "epoch 198; iter: 0; batch classifier loss: 0.072508; batch adversarial loss: 0.458874\n",
      "epoch 199; iter: 0; batch classifier loss: 0.048183; batch adversarial loss: 0.454165\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685871; batch adversarial loss: 0.720715\n",
      "epoch 1; iter: 0; batch classifier loss: 0.496666; batch adversarial loss: 0.650910\n",
      "epoch 2; iter: 0; batch classifier loss: 0.383286; batch adversarial loss: 0.618530\n",
      "epoch 3; iter: 0; batch classifier loss: 0.431769; batch adversarial loss: 0.575227\n",
      "epoch 4; iter: 0; batch classifier loss: 0.283182; batch adversarial loss: 0.569530\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387695; batch adversarial loss: 0.588558\n",
      "epoch 6; iter: 0; batch classifier loss: 0.387162; batch adversarial loss: 0.562120\n",
      "epoch 7; iter: 0; batch classifier loss: 0.269475; batch adversarial loss: 0.536880\n",
      "epoch 8; iter: 0; batch classifier loss: 0.324045; batch adversarial loss: 0.556962\n",
      "epoch 9; iter: 0; batch classifier loss: 0.354892; batch adversarial loss: 0.523079\n",
      "epoch 10; iter: 0; batch classifier loss: 0.240382; batch adversarial loss: 0.559876\n",
      "epoch 11; iter: 0; batch classifier loss: 0.219966; batch adversarial loss: 0.566174\n",
      "epoch 12; iter: 0; batch classifier loss: 0.317567; batch adversarial loss: 0.518359\n",
      "epoch 13; iter: 0; batch classifier loss: 0.284636; batch adversarial loss: 0.496817\n",
      "epoch 14; iter: 0; batch classifier loss: 0.261940; batch adversarial loss: 0.495716\n",
      "epoch 15; iter: 0; batch classifier loss: 0.212593; batch adversarial loss: 0.489570\n",
      "epoch 16; iter: 0; batch classifier loss: 0.323958; batch adversarial loss: 0.470537\n",
      "epoch 17; iter: 0; batch classifier loss: 0.248223; batch adversarial loss: 0.421281\n",
      "epoch 18; iter: 0; batch classifier loss: 0.302489; batch adversarial loss: 0.455259\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237292; batch adversarial loss: 0.506674\n",
      "epoch 20; iter: 0; batch classifier loss: 0.272045; batch adversarial loss: 0.521139\n",
      "epoch 21; iter: 0; batch classifier loss: 0.199364; batch adversarial loss: 0.471143\n",
      "epoch 22; iter: 0; batch classifier loss: 0.221763; batch adversarial loss: 0.449541\n",
      "epoch 23; iter: 0; batch classifier loss: 0.297793; batch adversarial loss: 0.438094\n",
      "epoch 24; iter: 0; batch classifier loss: 0.210717; batch adversarial loss: 0.388436\n",
      "epoch 25; iter: 0; batch classifier loss: 0.156271; batch adversarial loss: 0.516307\n",
      "epoch 26; iter: 0; batch classifier loss: 0.218688; batch adversarial loss: 0.460360\n",
      "epoch 27; iter: 0; batch classifier loss: 0.230973; batch adversarial loss: 0.482847\n",
      "epoch 28; iter: 0; batch classifier loss: 0.251791; batch adversarial loss: 0.391542\n",
      "epoch 29; iter: 0; batch classifier loss: 0.231555; batch adversarial loss: 0.488905\n",
      "epoch 30; iter: 0; batch classifier loss: 0.244738; batch adversarial loss: 0.470010\n",
      "epoch 31; iter: 0; batch classifier loss: 0.235265; batch adversarial loss: 0.436025\n",
      "epoch 32; iter: 0; batch classifier loss: 0.255416; batch adversarial loss: 0.433416\n",
      "epoch 33; iter: 0; batch classifier loss: 0.225035; batch adversarial loss: 0.435350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.242048; batch adversarial loss: 0.370568\n",
      "epoch 35; iter: 0; batch classifier loss: 0.238731; batch adversarial loss: 0.419091\n",
      "epoch 36; iter: 0; batch classifier loss: 0.276133; batch adversarial loss: 0.460102\n",
      "epoch 37; iter: 0; batch classifier loss: 0.296924; batch adversarial loss: 0.458185\n",
      "epoch 38; iter: 0; batch classifier loss: 0.221790; batch adversarial loss: 0.435870\n",
      "epoch 39; iter: 0; batch classifier loss: 0.229385; batch adversarial loss: 0.489534\n",
      "epoch 40; iter: 0; batch classifier loss: 0.226074; batch adversarial loss: 0.463843\n",
      "epoch 41; iter: 0; batch classifier loss: 0.283569; batch adversarial loss: 0.403013\n",
      "epoch 42; iter: 0; batch classifier loss: 0.225496; batch adversarial loss: 0.524314\n",
      "epoch 43; iter: 0; batch classifier loss: 0.211038; batch adversarial loss: 0.466672\n",
      "epoch 44; iter: 0; batch classifier loss: 0.229278; batch adversarial loss: 0.451073\n",
      "epoch 45; iter: 0; batch classifier loss: 0.232374; batch adversarial loss: 0.523954\n",
      "epoch 46; iter: 0; batch classifier loss: 0.247963; batch adversarial loss: 0.467338\n",
      "epoch 47; iter: 0; batch classifier loss: 0.307498; batch adversarial loss: 0.425835\n",
      "epoch 48; iter: 0; batch classifier loss: 0.225528; batch adversarial loss: 0.438989\n",
      "epoch 49; iter: 0; batch classifier loss: 0.227355; batch adversarial loss: 0.425386\n",
      "epoch 50; iter: 0; batch classifier loss: 0.192568; batch adversarial loss: 0.459178\n",
      "epoch 51; iter: 0; batch classifier loss: 0.247223; batch adversarial loss: 0.457554\n",
      "epoch 52; iter: 0; batch classifier loss: 0.251074; batch adversarial loss: 0.519855\n",
      "epoch 53; iter: 0; batch classifier loss: 0.284731; batch adversarial loss: 0.459015\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116051; batch adversarial loss: 0.553792\n",
      "epoch 55; iter: 0; batch classifier loss: 0.070131; batch adversarial loss: 0.453361\n",
      "epoch 56; iter: 0; batch classifier loss: 0.091334; batch adversarial loss: 0.517473\n",
      "epoch 57; iter: 0; batch classifier loss: 0.100540; batch adversarial loss: 0.440445\n",
      "epoch 58; iter: 0; batch classifier loss: 0.115597; batch adversarial loss: 0.536140\n",
      "epoch 59; iter: 0; batch classifier loss: 0.100323; batch adversarial loss: 0.429179\n",
      "epoch 60; iter: 0; batch classifier loss: 0.096131; batch adversarial loss: 0.470274\n",
      "epoch 61; iter: 0; batch classifier loss: 0.101844; batch adversarial loss: 0.504733\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082239; batch adversarial loss: 0.426881\n",
      "epoch 63; iter: 0; batch classifier loss: 0.084014; batch adversarial loss: 0.469712\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098088; batch adversarial loss: 0.423212\n",
      "epoch 65; iter: 0; batch classifier loss: 0.067399; batch adversarial loss: 0.496982\n",
      "epoch 66; iter: 0; batch classifier loss: 0.079066; batch adversarial loss: 0.419623\n",
      "epoch 67; iter: 0; batch classifier loss: 0.077360; batch adversarial loss: 0.456686\n",
      "epoch 68; iter: 0; batch classifier loss: 0.105203; batch adversarial loss: 0.409451\n",
      "epoch 69; iter: 0; batch classifier loss: 0.097904; batch adversarial loss: 0.399709\n",
      "epoch 70; iter: 0; batch classifier loss: 0.122073; batch adversarial loss: 0.562622\n",
      "epoch 71; iter: 0; batch classifier loss: 0.093503; batch adversarial loss: 0.441978\n",
      "epoch 72; iter: 0; batch classifier loss: 0.050826; batch adversarial loss: 0.460102\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079850; batch adversarial loss: 0.445579\n",
      "epoch 74; iter: 0; batch classifier loss: 0.112570; batch adversarial loss: 0.430829\n",
      "epoch 75; iter: 0; batch classifier loss: 0.040027; batch adversarial loss: 0.472245\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065707; batch adversarial loss: 0.383706\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065114; batch adversarial loss: 0.392938\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090889; batch adversarial loss: 0.516251\n",
      "epoch 79; iter: 0; batch classifier loss: 0.096493; batch adversarial loss: 0.385608\n",
      "epoch 80; iter: 0; batch classifier loss: 0.071145; batch adversarial loss: 0.440901\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067381; batch adversarial loss: 0.443107\n",
      "epoch 82; iter: 0; batch classifier loss: 0.116708; batch adversarial loss: 0.473349\n",
      "epoch 83; iter: 0; batch classifier loss: 0.047670; batch adversarial loss: 0.450574\n",
      "epoch 84; iter: 0; batch classifier loss: 0.099659; batch adversarial loss: 0.421556\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080111; batch adversarial loss: 0.496075\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054537; batch adversarial loss: 0.455882\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071323; batch adversarial loss: 0.480586\n",
      "epoch 88; iter: 0; batch classifier loss: 0.072679; batch adversarial loss: 0.388455\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065281; batch adversarial loss: 0.414139\n",
      "epoch 90; iter: 0; batch classifier loss: 0.116716; batch adversarial loss: 0.412003\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048637; batch adversarial loss: 0.499233\n",
      "epoch 92; iter: 0; batch classifier loss: 0.099917; batch adversarial loss: 0.389560\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043166; batch adversarial loss: 0.378531\n",
      "epoch 94; iter: 0; batch classifier loss: 0.045867; batch adversarial loss: 0.429006\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079379; batch adversarial loss: 0.477103\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044495; batch adversarial loss: 0.419372\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056277; batch adversarial loss: 0.434156\n",
      "epoch 98; iter: 0; batch classifier loss: 0.089875; batch adversarial loss: 0.453997\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058700; batch adversarial loss: 0.399906\n",
      "epoch 100; iter: 0; batch classifier loss: 0.078885; batch adversarial loss: 0.558052\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056717; batch adversarial loss: 0.310732\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055920; batch adversarial loss: 0.401949\n",
      "epoch 103; iter: 0; batch classifier loss: 0.105350; batch adversarial loss: 0.432045\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069411; batch adversarial loss: 0.415957\n",
      "epoch 105; iter: 0; batch classifier loss: 0.071633; batch adversarial loss: 0.419677\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051225; batch adversarial loss: 0.428935\n",
      "epoch 107; iter: 0; batch classifier loss: 0.060998; batch adversarial loss: 0.486974\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057773; batch adversarial loss: 0.431618\n",
      "epoch 109; iter: 0; batch classifier loss: 0.105184; batch adversarial loss: 0.430268\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058099; batch adversarial loss: 0.409259\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053095; batch adversarial loss: 0.386795\n",
      "epoch 112; iter: 0; batch classifier loss: 0.089939; batch adversarial loss: 0.517006\n",
      "epoch 113; iter: 0; batch classifier loss: 0.089522; batch adversarial loss: 0.379456\n",
      "epoch 114; iter: 0; batch classifier loss: 0.070721; batch adversarial loss: 0.374787\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057609; batch adversarial loss: 0.466136\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068151; batch adversarial loss: 0.334568\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039436; batch adversarial loss: 0.485490\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050083; batch adversarial loss: 0.411379\n",
      "epoch 119; iter: 0; batch classifier loss: 0.099278; batch adversarial loss: 0.413863\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062691; batch adversarial loss: 0.424310\n",
      "epoch 121; iter: 0; batch classifier loss: 0.073491; batch adversarial loss: 0.425780\n",
      "epoch 122; iter: 0; batch classifier loss: 0.069399; batch adversarial loss: 0.429137\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057074; batch adversarial loss: 0.390312\n",
      "epoch 124; iter: 0; batch classifier loss: 0.058287; batch adversarial loss: 0.530424\n",
      "epoch 125; iter: 0; batch classifier loss: 0.076588; batch adversarial loss: 0.416153\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046762; batch adversarial loss: 0.467334\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036770; batch adversarial loss: 0.470730\n",
      "epoch 128; iter: 0; batch classifier loss: 0.060135; batch adversarial loss: 0.584209\n",
      "epoch 129; iter: 0; batch classifier loss: 0.053114; batch adversarial loss: 0.498520\n",
      "epoch 130; iter: 0; batch classifier loss: 0.068076; batch adversarial loss: 0.449118\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037811; batch adversarial loss: 0.407303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.051210; batch adversarial loss: 0.399918\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039837; batch adversarial loss: 0.439344\n",
      "epoch 134; iter: 0; batch classifier loss: 0.078133; batch adversarial loss: 0.476674\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039890; batch adversarial loss: 0.376341\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029823; batch adversarial loss: 0.436386\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044883; batch adversarial loss: 0.451645\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035805; batch adversarial loss: 0.453735\n",
      "epoch 139; iter: 0; batch classifier loss: 0.064855; batch adversarial loss: 0.430623\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035193; batch adversarial loss: 0.397128\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044867; batch adversarial loss: 0.402280\n",
      "epoch 142; iter: 0; batch classifier loss: 0.047651; batch adversarial loss: 0.364827\n",
      "epoch 143; iter: 0; batch classifier loss: 0.044954; batch adversarial loss: 0.436771\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039662; batch adversarial loss: 0.490184\n",
      "epoch 145; iter: 0; batch classifier loss: 0.050519; batch adversarial loss: 0.487016\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027446; batch adversarial loss: 0.388188\n",
      "epoch 147; iter: 0; batch classifier loss: 0.045002; batch adversarial loss: 0.410355\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034365; batch adversarial loss: 0.361721\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019335; batch adversarial loss: 0.431481\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052433; batch adversarial loss: 0.421472\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031277; batch adversarial loss: 0.430881\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031812; batch adversarial loss: 0.507709\n",
      "epoch 153; iter: 0; batch classifier loss: 0.066224; batch adversarial loss: 0.479155\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024366; batch adversarial loss: 0.346267\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029167; batch adversarial loss: 0.414304\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033432; batch adversarial loss: 0.414210\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022485; batch adversarial loss: 0.452615\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025048; batch adversarial loss: 0.435433\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021381; batch adversarial loss: 0.418039\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027542; batch adversarial loss: 0.407789\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034092; batch adversarial loss: 0.355157\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027411; batch adversarial loss: 0.520632\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037865; batch adversarial loss: 0.447695\n",
      "epoch 164; iter: 0; batch classifier loss: 0.039884; batch adversarial loss: 0.337655\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028693; batch adversarial loss: 0.354295\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017590; batch adversarial loss: 0.375542\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025931; batch adversarial loss: 0.443838\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024069; batch adversarial loss: 0.493399\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025998; batch adversarial loss: 0.406858\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014912; batch adversarial loss: 0.352984\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018090; batch adversarial loss: 0.548152\n",
      "epoch 172; iter: 0; batch classifier loss: 0.043067; batch adversarial loss: 0.455185\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028783; batch adversarial loss: 0.475963\n",
      "epoch 174; iter: 0; batch classifier loss: 0.042007; batch adversarial loss: 0.367276\n",
      "epoch 175; iter: 0; batch classifier loss: 0.057829; batch adversarial loss: 0.407202\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024535; batch adversarial loss: 0.448063\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023804; batch adversarial loss: 0.564529\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029617; batch adversarial loss: 0.420806\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029222; batch adversarial loss: 0.509871\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035365; batch adversarial loss: 0.375522\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021460; batch adversarial loss: 0.503277\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027730; batch adversarial loss: 0.472039\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020992; batch adversarial loss: 0.475020\n",
      "epoch 184; iter: 0; batch classifier loss: 0.039874; batch adversarial loss: 0.390917\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040024; batch adversarial loss: 0.422839\n",
      "epoch 186; iter: 0; batch classifier loss: 0.061625; batch adversarial loss: 0.445139\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034628; batch adversarial loss: 0.353786\n",
      "epoch 188; iter: 0; batch classifier loss: 0.039551; batch adversarial loss: 0.434482\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019217; batch adversarial loss: 0.436607\n",
      "epoch 190; iter: 0; batch classifier loss: 0.057200; batch adversarial loss: 0.525768\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020989; batch adversarial loss: 0.470212\n",
      "epoch 192; iter: 0; batch classifier loss: 0.070815; batch adversarial loss: 0.509230\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024618; batch adversarial loss: 0.608076\n",
      "epoch 194; iter: 0; batch classifier loss: 0.043428; batch adversarial loss: 0.483853\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018253; batch adversarial loss: 0.510302\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021869; batch adversarial loss: 0.516415\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022618; batch adversarial loss: 0.507524\n",
      "epoch 198; iter: 0; batch classifier loss: 0.073934; batch adversarial loss: 0.481998\n",
      "epoch 199; iter: 0; batch classifier loss: 0.041117; batch adversarial loss: 0.470100\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674987; batch adversarial loss: 0.609387\n",
      "epoch 1; iter: 0; batch classifier loss: 0.518183; batch adversarial loss: 0.654453\n",
      "epoch 2; iter: 0; batch classifier loss: 0.508345; batch adversarial loss: 0.546772\n",
      "epoch 3; iter: 0; batch classifier loss: 0.401678; batch adversarial loss: 0.628554\n",
      "epoch 4; iter: 0; batch classifier loss: 0.405497; batch adversarial loss: 0.566737\n",
      "epoch 5; iter: 0; batch classifier loss: 0.370669; batch adversarial loss: 0.564229\n",
      "epoch 6; iter: 0; batch classifier loss: 0.254601; batch adversarial loss: 0.563890\n",
      "epoch 7; iter: 0; batch classifier loss: 0.293820; batch adversarial loss: 0.578785\n",
      "epoch 8; iter: 0; batch classifier loss: 0.247686; batch adversarial loss: 0.554399\n",
      "epoch 9; iter: 0; batch classifier loss: 0.257280; batch adversarial loss: 0.623170\n",
      "epoch 10; iter: 0; batch classifier loss: 0.266559; batch adversarial loss: 0.504040\n",
      "epoch 11; iter: 0; batch classifier loss: 0.284342; batch adversarial loss: 0.606918\n",
      "epoch 12; iter: 0; batch classifier loss: 0.246634; batch adversarial loss: 0.544500\n",
      "epoch 13; iter: 0; batch classifier loss: 0.294823; batch adversarial loss: 0.527417\n",
      "epoch 14; iter: 0; batch classifier loss: 0.196764; batch adversarial loss: 0.451146\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307298; batch adversarial loss: 0.516523\n",
      "epoch 16; iter: 0; batch classifier loss: 0.215298; batch adversarial loss: 0.521622\n",
      "epoch 17; iter: 0; batch classifier loss: 0.174785; batch adversarial loss: 0.383745\n",
      "epoch 18; iter: 0; batch classifier loss: 0.317955; batch adversarial loss: 0.451799\n",
      "epoch 19; iter: 0; batch classifier loss: 0.192194; batch adversarial loss: 0.412098\n",
      "epoch 20; iter: 0; batch classifier loss: 0.191139; batch adversarial loss: 0.501248\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149922; batch adversarial loss: 0.482713\n",
      "epoch 22; iter: 0; batch classifier loss: 0.204886; batch adversarial loss: 0.456960\n",
      "epoch 23; iter: 0; batch classifier loss: 0.190086; batch adversarial loss: 0.475770\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199480; batch adversarial loss: 0.473925\n",
      "epoch 25; iter: 0; batch classifier loss: 0.155498; batch adversarial loss: 0.465611\n",
      "epoch 26; iter: 0; batch classifier loss: 0.171675; batch adversarial loss: 0.416215\n",
      "epoch 27; iter: 0; batch classifier loss: 0.170319; batch adversarial loss: 0.405496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.151506; batch adversarial loss: 0.445841\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182753; batch adversarial loss: 0.493233\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172117; batch adversarial loss: 0.390926\n",
      "epoch 31; iter: 0; batch classifier loss: 0.167201; batch adversarial loss: 0.413749\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172031; batch adversarial loss: 0.540956\n",
      "epoch 33; iter: 0; batch classifier loss: 0.113988; batch adversarial loss: 0.510495\n",
      "epoch 34; iter: 0; batch classifier loss: 0.087867; batch adversarial loss: 0.435738\n",
      "epoch 35; iter: 0; batch classifier loss: 0.136066; batch adversarial loss: 0.495815\n",
      "epoch 36; iter: 0; batch classifier loss: 0.151680; batch adversarial loss: 0.426748\n",
      "epoch 37; iter: 0; batch classifier loss: 0.133904; batch adversarial loss: 0.363824\n",
      "epoch 38; iter: 0; batch classifier loss: 0.120977; batch adversarial loss: 0.379412\n",
      "epoch 39; iter: 0; batch classifier loss: 0.088759; batch adversarial loss: 0.491798\n",
      "epoch 40; iter: 0; batch classifier loss: 0.100913; batch adversarial loss: 0.428968\n",
      "epoch 41; iter: 0; batch classifier loss: 0.136830; batch adversarial loss: 0.491882\n",
      "epoch 42; iter: 0; batch classifier loss: 0.145852; batch adversarial loss: 0.439888\n",
      "epoch 43; iter: 0; batch classifier loss: 0.141123; batch adversarial loss: 0.435994\n",
      "epoch 44; iter: 0; batch classifier loss: 0.132105; batch adversarial loss: 0.465390\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089916; batch adversarial loss: 0.402217\n",
      "epoch 46; iter: 0; batch classifier loss: 0.177457; batch adversarial loss: 0.425865\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106826; batch adversarial loss: 0.407563\n",
      "epoch 48; iter: 0; batch classifier loss: 0.173444; batch adversarial loss: 0.436818\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101401; batch adversarial loss: 0.487158\n",
      "epoch 50; iter: 0; batch classifier loss: 0.133912; batch adversarial loss: 0.469252\n",
      "epoch 51; iter: 0; batch classifier loss: 0.113724; batch adversarial loss: 0.372522\n",
      "epoch 52; iter: 0; batch classifier loss: 0.183200; batch adversarial loss: 0.517475\n",
      "epoch 53; iter: 0; batch classifier loss: 0.131184; batch adversarial loss: 0.487377\n",
      "epoch 54; iter: 0; batch classifier loss: 0.140398; batch adversarial loss: 0.457911\n",
      "epoch 55; iter: 0; batch classifier loss: 0.124760; batch adversarial loss: 0.484223\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095420; batch adversarial loss: 0.477566\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106625; batch adversarial loss: 0.491132\n",
      "epoch 58; iter: 0; batch classifier loss: 0.096247; batch adversarial loss: 0.369222\n",
      "epoch 59; iter: 0; batch classifier loss: 0.104399; batch adversarial loss: 0.472168\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097984; batch adversarial loss: 0.472842\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093942; batch adversarial loss: 0.407753\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108104; batch adversarial loss: 0.421804\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093786; batch adversarial loss: 0.446728\n",
      "epoch 64; iter: 0; batch classifier loss: 0.116133; batch adversarial loss: 0.436291\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075371; batch adversarial loss: 0.483548\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085929; batch adversarial loss: 0.477302\n",
      "epoch 67; iter: 0; batch classifier loss: 0.071952; batch adversarial loss: 0.480069\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084153; batch adversarial loss: 0.480559\n",
      "epoch 69; iter: 0; batch classifier loss: 0.105683; batch adversarial loss: 0.513222\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082073; batch adversarial loss: 0.446084\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073456; batch adversarial loss: 0.522150\n",
      "epoch 72; iter: 0; batch classifier loss: 0.069562; batch adversarial loss: 0.483498\n",
      "epoch 73; iter: 0; batch classifier loss: 0.097043; batch adversarial loss: 0.469899\n",
      "epoch 74; iter: 0; batch classifier loss: 0.080042; batch adversarial loss: 0.539126\n",
      "epoch 75; iter: 0; batch classifier loss: 0.080887; batch adversarial loss: 0.462553\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072989; batch adversarial loss: 0.453700\n",
      "epoch 77; iter: 0; batch classifier loss: 0.113409; batch adversarial loss: 0.473411\n",
      "epoch 78; iter: 0; batch classifier loss: 0.043505; batch adversarial loss: 0.438905\n",
      "epoch 79; iter: 0; batch classifier loss: 0.088573; batch adversarial loss: 0.510520\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070479; batch adversarial loss: 0.439963\n",
      "epoch 81; iter: 0; batch classifier loss: 0.047722; batch adversarial loss: 0.512866\n",
      "epoch 82; iter: 0; batch classifier loss: 0.051829; batch adversarial loss: 0.528622\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066340; batch adversarial loss: 0.446323\n",
      "epoch 84; iter: 0; batch classifier loss: 0.086088; batch adversarial loss: 0.388828\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083266; batch adversarial loss: 0.468754\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063895; batch adversarial loss: 0.413703\n",
      "epoch 87; iter: 0; batch classifier loss: 0.035341; batch adversarial loss: 0.353631\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076282; batch adversarial loss: 0.427920\n",
      "epoch 89; iter: 0; batch classifier loss: 0.049135; batch adversarial loss: 0.425119\n",
      "epoch 90; iter: 0; batch classifier loss: 0.040837; batch adversarial loss: 0.460345\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063280; batch adversarial loss: 0.443300\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044825; batch adversarial loss: 0.396913\n",
      "epoch 93; iter: 0; batch classifier loss: 0.025495; batch adversarial loss: 0.536364\n",
      "epoch 94; iter: 0; batch classifier loss: 0.054158; batch adversarial loss: 0.485855\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047380; batch adversarial loss: 0.451452\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062935; batch adversarial loss: 0.404321\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050430; batch adversarial loss: 0.547961\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054105; batch adversarial loss: 0.437536\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064405; batch adversarial loss: 0.426893\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048933; batch adversarial loss: 0.549726\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043545; batch adversarial loss: 0.435829\n",
      "epoch 102; iter: 0; batch classifier loss: 0.099335; batch adversarial loss: 0.425411\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048272; batch adversarial loss: 0.427271\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073445; batch adversarial loss: 0.460119\n",
      "epoch 105; iter: 0; batch classifier loss: 0.101627; batch adversarial loss: 0.427236\n",
      "epoch 106; iter: 0; batch classifier loss: 0.022794; batch adversarial loss: 0.472808\n",
      "epoch 107; iter: 0; batch classifier loss: 0.096687; batch adversarial loss: 0.505002\n",
      "epoch 108; iter: 0; batch classifier loss: 0.062762; batch adversarial loss: 0.444410\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045155; batch adversarial loss: 0.556765\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044413; batch adversarial loss: 0.373298\n",
      "epoch 111; iter: 0; batch classifier loss: 0.038563; batch adversarial loss: 0.384827\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035037; batch adversarial loss: 0.503972\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045062; batch adversarial loss: 0.499194\n",
      "epoch 114; iter: 0; batch classifier loss: 0.069281; batch adversarial loss: 0.371904\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022713; batch adversarial loss: 0.467494\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042573; batch adversarial loss: 0.471585\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032828; batch adversarial loss: 0.431398\n",
      "epoch 118; iter: 0; batch classifier loss: 0.105120; batch adversarial loss: 0.396594\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059964; batch adversarial loss: 0.474224\n",
      "epoch 120; iter: 0; batch classifier loss: 0.015877; batch adversarial loss: 0.510963\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040422; batch adversarial loss: 0.465125\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038843; batch adversarial loss: 0.605524\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064869; batch adversarial loss: 0.424147\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037777; batch adversarial loss: 0.444093\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034100; batch adversarial loss: 0.387971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.051539; batch adversarial loss: 0.381033\n",
      "epoch 127; iter: 0; batch classifier loss: 0.010310; batch adversarial loss: 0.551629\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042727; batch adversarial loss: 0.452958\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022683; batch adversarial loss: 0.489917\n",
      "epoch 130; iter: 0; batch classifier loss: 0.013676; batch adversarial loss: 0.398616\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051748; batch adversarial loss: 0.475779\n",
      "epoch 132; iter: 0; batch classifier loss: 0.070063; batch adversarial loss: 0.490385\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030078; batch adversarial loss: 0.449511\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029031; batch adversarial loss: 0.407518\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039057; batch adversarial loss: 0.403196\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023570; batch adversarial loss: 0.417589\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045148; batch adversarial loss: 0.544574\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036973; batch adversarial loss: 0.429312\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045340; batch adversarial loss: 0.472965\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029862; batch adversarial loss: 0.433623\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043581; batch adversarial loss: 0.458371\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016945; batch adversarial loss: 0.478928\n",
      "epoch 143; iter: 0; batch classifier loss: 0.086694; batch adversarial loss: 0.580468\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027298; batch adversarial loss: 0.479423\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043006; batch adversarial loss: 0.467784\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033580; batch adversarial loss: 0.427699\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033979; batch adversarial loss: 0.427065\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038647; batch adversarial loss: 0.456103\n",
      "epoch 149; iter: 0; batch classifier loss: 0.041316; batch adversarial loss: 0.521690\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018435; batch adversarial loss: 0.450291\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048259; batch adversarial loss: 0.423133\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023052; batch adversarial loss: 0.414193\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022012; batch adversarial loss: 0.397853\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024024; batch adversarial loss: 0.417395\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019330; batch adversarial loss: 0.466814\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038718; batch adversarial loss: 0.419991\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015918; batch adversarial loss: 0.487601\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019464; batch adversarial loss: 0.467873\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014311; batch adversarial loss: 0.490530\n",
      "epoch 160; iter: 0; batch classifier loss: 0.039885; batch adversarial loss: 0.468225\n",
      "epoch 161; iter: 0; batch classifier loss: 0.050331; batch adversarial loss: 0.501120\n",
      "epoch 162; iter: 0; batch classifier loss: 0.071850; batch adversarial loss: 0.514212\n",
      "epoch 163; iter: 0; batch classifier loss: 0.052133; batch adversarial loss: 0.435429\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035458; batch adversarial loss: 0.462831\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019900; batch adversarial loss: 0.400027\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032990; batch adversarial loss: 0.482289\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014288; batch adversarial loss: 0.376883\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025531; batch adversarial loss: 0.350347\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012792; batch adversarial loss: 0.461495\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028564; batch adversarial loss: 0.466526\n",
      "epoch 171; iter: 0; batch classifier loss: 0.039188; batch adversarial loss: 0.470200\n",
      "epoch 172; iter: 0; batch classifier loss: 0.044810; batch adversarial loss: 0.416346\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025999; batch adversarial loss: 0.393161\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019275; batch adversarial loss: 0.444929\n",
      "epoch 175; iter: 0; batch classifier loss: 0.093798; batch adversarial loss: 0.473034\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016960; batch adversarial loss: 0.461209\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022013; batch adversarial loss: 0.526852\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010043; batch adversarial loss: 0.409835\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012666; batch adversarial loss: 0.401697\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039131; batch adversarial loss: 0.491049\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020556; batch adversarial loss: 0.421977\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030942; batch adversarial loss: 0.377830\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015146; batch adversarial loss: 0.450947\n",
      "epoch 184; iter: 0; batch classifier loss: 0.049970; batch adversarial loss: 0.492673\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022725; batch adversarial loss: 0.512256\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015605; batch adversarial loss: 0.532095\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025073; batch adversarial loss: 0.512495\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018239; batch adversarial loss: 0.480867\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020315; batch adversarial loss: 0.403857\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025578; batch adversarial loss: 0.393355\n",
      "epoch 191; iter: 0; batch classifier loss: 0.048797; batch adversarial loss: 0.525619\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017529; batch adversarial loss: 0.457493\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008386; batch adversarial loss: 0.502159\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019652; batch adversarial loss: 0.478144\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031971; batch adversarial loss: 0.471852\n",
      "epoch 196; iter: 0; batch classifier loss: 0.063956; batch adversarial loss: 0.463564\n",
      "epoch 197; iter: 0; batch classifier loss: 0.050640; batch adversarial loss: 0.480296\n",
      "epoch 198; iter: 0; batch classifier loss: 0.034997; batch adversarial loss: 0.433122\n",
      "epoch 199; iter: 0; batch classifier loss: 0.056059; batch adversarial loss: 0.494641\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710386; batch adversarial loss: 0.519889\n",
      "epoch 1; iter: 0; batch classifier loss: 0.477602; batch adversarial loss: 0.624428\n",
      "epoch 2; iter: 0; batch classifier loss: 0.429509; batch adversarial loss: 0.580900\n",
      "epoch 3; iter: 0; batch classifier loss: 0.387513; batch adversarial loss: 0.525280\n",
      "epoch 4; iter: 0; batch classifier loss: 0.381399; batch adversarial loss: 0.561986\n",
      "epoch 5; iter: 0; batch classifier loss: 0.460149; batch adversarial loss: 0.588588\n",
      "epoch 6; iter: 0; batch classifier loss: 0.388320; batch adversarial loss: 0.577934\n",
      "epoch 7; iter: 0; batch classifier loss: 0.432220; batch adversarial loss: 0.565896\n",
      "epoch 8; iter: 0; batch classifier loss: 0.345196; batch adversarial loss: 0.589335\n",
      "epoch 9; iter: 0; batch classifier loss: 0.394133; batch adversarial loss: 0.573828\n",
      "epoch 10; iter: 0; batch classifier loss: 0.433801; batch adversarial loss: 0.454796\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403484; batch adversarial loss: 0.569775\n",
      "epoch 12; iter: 0; batch classifier loss: 0.436484; batch adversarial loss: 0.467841\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539818; batch adversarial loss: 0.520767\n",
      "epoch 14; iter: 0; batch classifier loss: 0.706191; batch adversarial loss: 0.481222\n",
      "epoch 15; iter: 0; batch classifier loss: 0.406756; batch adversarial loss: 0.570343\n",
      "epoch 16; iter: 0; batch classifier loss: 0.324052; batch adversarial loss: 0.504197\n",
      "epoch 17; iter: 0; batch classifier loss: 0.274279; batch adversarial loss: 0.444684\n",
      "epoch 18; iter: 0; batch classifier loss: 0.220168; batch adversarial loss: 0.481128\n",
      "epoch 19; iter: 0; batch classifier loss: 0.212566; batch adversarial loss: 0.552831\n",
      "epoch 20; iter: 0; batch classifier loss: 0.228860; batch adversarial loss: 0.538682\n",
      "epoch 21; iter: 0; batch classifier loss: 0.194079; batch adversarial loss: 0.425458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.217814; batch adversarial loss: 0.479012\n",
      "epoch 23; iter: 0; batch classifier loss: 0.219428; batch adversarial loss: 0.444959\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195542; batch adversarial loss: 0.429595\n",
      "epoch 25; iter: 0; batch classifier loss: 0.181882; batch adversarial loss: 0.527469\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243439; batch adversarial loss: 0.484767\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159964; batch adversarial loss: 0.502872\n",
      "epoch 28; iter: 0; batch classifier loss: 0.136850; batch adversarial loss: 0.460765\n",
      "epoch 29; iter: 0; batch classifier loss: 0.153692; batch adversarial loss: 0.483640\n",
      "epoch 30; iter: 0; batch classifier loss: 0.175963; batch adversarial loss: 0.473064\n",
      "epoch 31; iter: 0; batch classifier loss: 0.192496; batch adversarial loss: 0.482933\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146802; batch adversarial loss: 0.433982\n",
      "epoch 33; iter: 0; batch classifier loss: 0.136351; batch adversarial loss: 0.432149\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148070; batch adversarial loss: 0.483213\n",
      "epoch 35; iter: 0; batch classifier loss: 0.120475; batch adversarial loss: 0.409599\n",
      "epoch 36; iter: 0; batch classifier loss: 0.139206; batch adversarial loss: 0.533417\n",
      "epoch 37; iter: 0; batch classifier loss: 0.119527; batch adversarial loss: 0.449493\n",
      "epoch 38; iter: 0; batch classifier loss: 0.132033; batch adversarial loss: 0.489986\n",
      "epoch 39; iter: 0; batch classifier loss: 0.134352; batch adversarial loss: 0.522261\n",
      "epoch 40; iter: 0; batch classifier loss: 0.100136; batch adversarial loss: 0.479508\n",
      "epoch 41; iter: 0; batch classifier loss: 0.103293; batch adversarial loss: 0.492557\n",
      "epoch 42; iter: 0; batch classifier loss: 0.109137; batch adversarial loss: 0.474909\n",
      "epoch 43; iter: 0; batch classifier loss: 0.172107; batch adversarial loss: 0.500916\n",
      "epoch 44; iter: 0; batch classifier loss: 0.128358; batch adversarial loss: 0.462153\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099227; batch adversarial loss: 0.396691\n",
      "epoch 46; iter: 0; batch classifier loss: 0.118689; batch adversarial loss: 0.374913\n",
      "epoch 47; iter: 0; batch classifier loss: 0.115864; batch adversarial loss: 0.474894\n",
      "epoch 48; iter: 0; batch classifier loss: 0.135592; batch adversarial loss: 0.444768\n",
      "epoch 49; iter: 0; batch classifier loss: 0.127271; batch adversarial loss: 0.457240\n",
      "epoch 50; iter: 0; batch classifier loss: 0.127474; batch adversarial loss: 0.468236\n",
      "epoch 51; iter: 0; batch classifier loss: 0.079523; batch adversarial loss: 0.465164\n",
      "epoch 52; iter: 0; batch classifier loss: 0.129927; batch adversarial loss: 0.418022\n",
      "epoch 53; iter: 0; batch classifier loss: 0.100788; batch adversarial loss: 0.429694\n",
      "epoch 54; iter: 0; batch classifier loss: 0.157232; batch adversarial loss: 0.441607\n",
      "epoch 55; iter: 0; batch classifier loss: 0.106234; batch adversarial loss: 0.484696\n",
      "epoch 56; iter: 0; batch classifier loss: 0.137919; batch adversarial loss: 0.345575\n",
      "epoch 57; iter: 0; batch classifier loss: 0.099933; batch adversarial loss: 0.467939\n",
      "epoch 58; iter: 0; batch classifier loss: 0.094521; batch adversarial loss: 0.484325\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099726; batch adversarial loss: 0.511074\n",
      "epoch 60; iter: 0; batch classifier loss: 0.092409; batch adversarial loss: 0.391231\n",
      "epoch 61; iter: 0; batch classifier loss: 0.148126; batch adversarial loss: 0.347784\n",
      "epoch 62; iter: 0; batch classifier loss: 0.123935; batch adversarial loss: 0.462602\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124661; batch adversarial loss: 0.446376\n",
      "epoch 64; iter: 0; batch classifier loss: 0.128594; batch adversarial loss: 0.426499\n",
      "epoch 65; iter: 0; batch classifier loss: 0.131865; batch adversarial loss: 0.430723\n",
      "epoch 66; iter: 0; batch classifier loss: 0.117920; batch adversarial loss: 0.479486\n",
      "epoch 67; iter: 0; batch classifier loss: 0.155071; batch adversarial loss: 0.403949\n",
      "epoch 68; iter: 0; batch classifier loss: 0.117420; batch adversarial loss: 0.403833\n",
      "epoch 69; iter: 0; batch classifier loss: 0.101915; batch adversarial loss: 0.447316\n",
      "epoch 70; iter: 0; batch classifier loss: 0.153922; batch adversarial loss: 0.443006\n",
      "epoch 71; iter: 0; batch classifier loss: 0.119360; batch adversarial loss: 0.419650\n",
      "epoch 72; iter: 0; batch classifier loss: 0.135162; batch adversarial loss: 0.341390\n",
      "epoch 73; iter: 0; batch classifier loss: 0.110773; batch adversarial loss: 0.448252\n",
      "epoch 74; iter: 0; batch classifier loss: 0.071440; batch adversarial loss: 0.439415\n",
      "epoch 75; iter: 0; batch classifier loss: 0.135219; batch adversarial loss: 0.420797\n",
      "epoch 76; iter: 0; batch classifier loss: 0.157361; batch adversarial loss: 0.379969\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087793; batch adversarial loss: 0.479700\n",
      "epoch 78; iter: 0; batch classifier loss: 0.112314; batch adversarial loss: 0.486735\n",
      "epoch 79; iter: 0; batch classifier loss: 0.157637; batch adversarial loss: 0.329756\n",
      "epoch 80; iter: 0; batch classifier loss: 0.127096; batch adversarial loss: 0.475650\n",
      "epoch 81; iter: 0; batch classifier loss: 0.095943; batch adversarial loss: 0.420797\n",
      "epoch 82; iter: 0; batch classifier loss: 0.104318; batch adversarial loss: 0.519547\n",
      "epoch 83; iter: 0; batch classifier loss: 0.112839; batch adversarial loss: 0.447498\n",
      "epoch 84; iter: 0; batch classifier loss: 0.116978; batch adversarial loss: 0.495545\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088185; batch adversarial loss: 0.364424\n",
      "epoch 86; iter: 0; batch classifier loss: 0.079815; batch adversarial loss: 0.485629\n",
      "epoch 87; iter: 0; batch classifier loss: 0.091056; batch adversarial loss: 0.433725\n",
      "epoch 88; iter: 0; batch classifier loss: 0.094587; batch adversarial loss: 0.498596\n",
      "epoch 89; iter: 0; batch classifier loss: 0.129831; batch adversarial loss: 0.382972\n",
      "epoch 90; iter: 0; batch classifier loss: 0.160646; batch adversarial loss: 0.398400\n",
      "epoch 91; iter: 0; batch classifier loss: 0.120198; batch adversarial loss: 0.460893\n",
      "epoch 92; iter: 0; batch classifier loss: 0.113305; batch adversarial loss: 0.537105\n",
      "epoch 93; iter: 0; batch classifier loss: 0.095297; batch adversarial loss: 0.526362\n",
      "epoch 94; iter: 0; batch classifier loss: 0.098096; batch adversarial loss: 0.517734\n",
      "epoch 95; iter: 0; batch classifier loss: 0.090130; batch adversarial loss: 0.457952\n",
      "epoch 96; iter: 0; batch classifier loss: 0.124572; batch adversarial loss: 0.405047\n",
      "epoch 97; iter: 0; batch classifier loss: 0.079642; batch adversarial loss: 0.458730\n",
      "epoch 98; iter: 0; batch classifier loss: 0.097332; batch adversarial loss: 0.504188\n",
      "epoch 99; iter: 0; batch classifier loss: 0.102181; batch adversarial loss: 0.415155\n",
      "epoch 100; iter: 0; batch classifier loss: 0.103009; batch adversarial loss: 0.487613\n",
      "epoch 101; iter: 0; batch classifier loss: 0.088974; batch adversarial loss: 0.382953\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053446; batch adversarial loss: 0.479390\n",
      "epoch 103; iter: 0; batch classifier loss: 0.100116; batch adversarial loss: 0.407969\n",
      "epoch 104; iter: 0; batch classifier loss: 0.094679; batch adversarial loss: 0.481686\n",
      "epoch 105; iter: 0; batch classifier loss: 0.089083; batch adversarial loss: 0.446242\n",
      "epoch 106; iter: 0; batch classifier loss: 0.081942; batch adversarial loss: 0.442281\n",
      "epoch 107; iter: 0; batch classifier loss: 0.097706; batch adversarial loss: 0.403673\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054812; batch adversarial loss: 0.489588\n",
      "epoch 109; iter: 0; batch classifier loss: 0.108293; batch adversarial loss: 0.421738\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057324; batch adversarial loss: 0.399825\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050020; batch adversarial loss: 0.556806\n",
      "epoch 112; iter: 0; batch classifier loss: 0.079306; batch adversarial loss: 0.375209\n",
      "epoch 113; iter: 0; batch classifier loss: 0.125534; batch adversarial loss: 0.501566\n",
      "epoch 114; iter: 0; batch classifier loss: 0.114503; batch adversarial loss: 0.351390\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046976; batch adversarial loss: 0.547984\n",
      "epoch 116; iter: 0; batch classifier loss: 0.067250; batch adversarial loss: 0.512389\n",
      "epoch 117; iter: 0; batch classifier loss: 0.074528; batch adversarial loss: 0.369862\n",
      "epoch 118; iter: 0; batch classifier loss: 0.109463; batch adversarial loss: 0.526340\n",
      "epoch 119; iter: 0; batch classifier loss: 0.082593; batch adversarial loss: 0.473061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.065277; batch adversarial loss: 0.445045\n",
      "epoch 121; iter: 0; batch classifier loss: 0.061428; batch adversarial loss: 0.402609\n",
      "epoch 122; iter: 0; batch classifier loss: 0.060639; batch adversarial loss: 0.430402\n",
      "epoch 123; iter: 0; batch classifier loss: 0.081018; batch adversarial loss: 0.341429\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042412; batch adversarial loss: 0.550790\n",
      "epoch 125; iter: 0; batch classifier loss: 0.096964; batch adversarial loss: 0.419265\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021626; batch adversarial loss: 0.600837\n",
      "epoch 127; iter: 0; batch classifier loss: 0.076062; batch adversarial loss: 0.440057\n",
      "epoch 128; iter: 0; batch classifier loss: 0.079385; batch adversarial loss: 0.366631\n",
      "epoch 129; iter: 0; batch classifier loss: 0.060786; batch adversarial loss: 0.531248\n",
      "epoch 130; iter: 0; batch classifier loss: 0.080360; batch adversarial loss: 0.497194\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043351; batch adversarial loss: 0.479549\n",
      "epoch 132; iter: 0; batch classifier loss: 0.056739; batch adversarial loss: 0.416727\n",
      "epoch 133; iter: 0; batch classifier loss: 0.070567; batch adversarial loss: 0.465538\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034613; batch adversarial loss: 0.483981\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030238; batch adversarial loss: 0.449342\n",
      "epoch 136; iter: 0; batch classifier loss: 0.058663; batch adversarial loss: 0.422035\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018378; batch adversarial loss: 0.379125\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028997; batch adversarial loss: 0.434857\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045394; batch adversarial loss: 0.493026\n",
      "epoch 140; iter: 0; batch classifier loss: 0.059709; batch adversarial loss: 0.433618\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033240; batch adversarial loss: 0.489672\n",
      "epoch 142; iter: 0; batch classifier loss: 0.010381; batch adversarial loss: 0.559768\n",
      "epoch 143; iter: 0; batch classifier loss: 0.045414; batch adversarial loss: 0.426370\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041142; batch adversarial loss: 0.449741\n",
      "epoch 145; iter: 0; batch classifier loss: 0.080571; batch adversarial loss: 0.384441\n",
      "epoch 146; iter: 0; batch classifier loss: 0.049896; batch adversarial loss: 0.443495\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037499; batch adversarial loss: 0.481526\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046651; batch adversarial loss: 0.365608\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031001; batch adversarial loss: 0.492181\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039503; batch adversarial loss: 0.548547\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043366; batch adversarial loss: 0.505731\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024271; batch adversarial loss: 0.378710\n",
      "epoch 153; iter: 0; batch classifier loss: 0.046433; batch adversarial loss: 0.431081\n",
      "epoch 154; iter: 0; batch classifier loss: 0.060158; batch adversarial loss: 0.375117\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045659; batch adversarial loss: 0.447705\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025954; batch adversarial loss: 0.529627\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032787; batch adversarial loss: 0.452014\n",
      "epoch 158; iter: 0; batch classifier loss: 0.052384; batch adversarial loss: 0.452709\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034157; batch adversarial loss: 0.452918\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044561; batch adversarial loss: 0.419984\n",
      "epoch 161; iter: 0; batch classifier loss: 0.055849; batch adversarial loss: 0.484973\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021715; batch adversarial loss: 0.504027\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030220; batch adversarial loss: 0.492096\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026974; batch adversarial loss: 0.419011\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032996; batch adversarial loss: 0.452651\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024793; batch adversarial loss: 0.421409\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009820; batch adversarial loss: 0.479981\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012205; batch adversarial loss: 0.498068\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015606; batch adversarial loss: 0.417996\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023827; batch adversarial loss: 0.422712\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022151; batch adversarial loss: 0.423063\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009125; batch adversarial loss: 0.355064\n",
      "epoch 173; iter: 0; batch classifier loss: 0.039491; batch adversarial loss: 0.408120\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041268; batch adversarial loss: 0.508312\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035435; batch adversarial loss: 0.505248\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015047; batch adversarial loss: 0.473438\n",
      "epoch 177; iter: 0; batch classifier loss: 0.040392; batch adversarial loss: 0.522608\n",
      "epoch 178; iter: 0; batch classifier loss: 0.044363; batch adversarial loss: 0.411427\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023621; batch adversarial loss: 0.385610\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030029; batch adversarial loss: 0.435806\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013416; batch adversarial loss: 0.403048\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034039; batch adversarial loss: 0.528894\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033212; batch adversarial loss: 0.483880\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014317; batch adversarial loss: 0.387447\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020308; batch adversarial loss: 0.493180\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013208; batch adversarial loss: 0.483108\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014881; batch adversarial loss: 0.444682\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029507; batch adversarial loss: 0.417272\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029802; batch adversarial loss: 0.435768\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022603; batch adversarial loss: 0.528526\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023887; batch adversarial loss: 0.401237\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012024; batch adversarial loss: 0.449528\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032145; batch adversarial loss: 0.349287\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023187; batch adversarial loss: 0.428919\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013424; batch adversarial loss: 0.448205\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018716; batch adversarial loss: 0.345970\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027744; batch adversarial loss: 0.386613\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006926; batch adversarial loss: 0.396343\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028151; batch adversarial loss: 0.332401\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692714; batch adversarial loss: 0.660768\n",
      "epoch 1; iter: 0; batch classifier loss: 0.451906; batch adversarial loss: 0.635938\n",
      "epoch 2; iter: 0; batch classifier loss: 0.431576; batch adversarial loss: 0.645926\n",
      "epoch 3; iter: 0; batch classifier loss: 0.410349; batch adversarial loss: 0.633887\n",
      "epoch 4; iter: 0; batch classifier loss: 0.446458; batch adversarial loss: 0.636568\n",
      "epoch 5; iter: 0; batch classifier loss: 0.412533; batch adversarial loss: 0.604910\n",
      "epoch 6; iter: 0; batch classifier loss: 0.454873; batch adversarial loss: 0.566786\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495329; batch adversarial loss: 0.581650\n",
      "epoch 8; iter: 0; batch classifier loss: 0.421851; batch adversarial loss: 0.558675\n",
      "epoch 9; iter: 0; batch classifier loss: 0.398484; batch adversarial loss: 0.568480\n",
      "epoch 10; iter: 0; batch classifier loss: 0.384736; batch adversarial loss: 0.536897\n",
      "epoch 11; iter: 0; batch classifier loss: 0.393000; batch adversarial loss: 0.497237\n",
      "epoch 12; iter: 0; batch classifier loss: 0.350363; batch adversarial loss: 0.543576\n",
      "epoch 13; iter: 0; batch classifier loss: 0.381010; batch adversarial loss: 0.480594\n",
      "epoch 14; iter: 0; batch classifier loss: 0.306624; batch adversarial loss: 0.515457\n",
      "epoch 15; iter: 0; batch classifier loss: 0.315616; batch adversarial loss: 0.493919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.306513; batch adversarial loss: 0.484054\n",
      "epoch 17; iter: 0; batch classifier loss: 0.289217; batch adversarial loss: 0.488722\n",
      "epoch 18; iter: 0; batch classifier loss: 0.364920; batch adversarial loss: 0.468133\n",
      "epoch 19; iter: 0; batch classifier loss: 0.321681; batch adversarial loss: 0.472245\n",
      "epoch 20; iter: 0; batch classifier loss: 0.291865; batch adversarial loss: 0.537394\n",
      "epoch 21; iter: 0; batch classifier loss: 0.267988; batch adversarial loss: 0.428874\n",
      "epoch 22; iter: 0; batch classifier loss: 0.270089; batch adversarial loss: 0.526920\n",
      "epoch 23; iter: 0; batch classifier loss: 0.228320; batch adversarial loss: 0.468289\n",
      "epoch 24; iter: 0; batch classifier loss: 0.267591; batch adversarial loss: 0.451353\n",
      "epoch 25; iter: 0; batch classifier loss: 0.211729; batch adversarial loss: 0.466327\n",
      "epoch 26; iter: 0; batch classifier loss: 0.253502; batch adversarial loss: 0.517289\n",
      "epoch 27; iter: 0; batch classifier loss: 0.201535; batch adversarial loss: 0.471713\n",
      "epoch 28; iter: 0; batch classifier loss: 0.274231; batch adversarial loss: 0.435975\n",
      "epoch 29; iter: 0; batch classifier loss: 0.217512; batch adversarial loss: 0.425711\n",
      "epoch 30; iter: 0; batch classifier loss: 0.271540; batch adversarial loss: 0.387684\n",
      "epoch 31; iter: 0; batch classifier loss: 0.239386; batch adversarial loss: 0.442613\n",
      "epoch 32; iter: 0; batch classifier loss: 0.237561; batch adversarial loss: 0.391268\n",
      "epoch 33; iter: 0; batch classifier loss: 0.202472; batch adversarial loss: 0.533077\n",
      "epoch 34; iter: 0; batch classifier loss: 0.245409; batch adversarial loss: 0.477249\n",
      "epoch 35; iter: 0; batch classifier loss: 0.290075; batch adversarial loss: 0.478210\n",
      "epoch 36; iter: 0; batch classifier loss: 0.213063; batch adversarial loss: 0.488507\n",
      "epoch 37; iter: 0; batch classifier loss: 0.207122; batch adversarial loss: 0.514478\n",
      "epoch 38; iter: 0; batch classifier loss: 0.210332; batch adversarial loss: 0.513436\n",
      "epoch 39; iter: 0; batch classifier loss: 0.245774; batch adversarial loss: 0.416492\n",
      "epoch 40; iter: 0; batch classifier loss: 0.194555; batch adversarial loss: 0.435569\n",
      "epoch 41; iter: 0; batch classifier loss: 0.193272; batch adversarial loss: 0.554491\n",
      "epoch 42; iter: 0; batch classifier loss: 0.208103; batch adversarial loss: 0.406565\n",
      "epoch 43; iter: 0; batch classifier loss: 0.218022; batch adversarial loss: 0.471184\n",
      "epoch 44; iter: 0; batch classifier loss: 0.216493; batch adversarial loss: 0.468849\n",
      "epoch 45; iter: 0; batch classifier loss: 0.197469; batch adversarial loss: 0.414584\n",
      "epoch 46; iter: 0; batch classifier loss: 0.169478; batch adversarial loss: 0.460655\n",
      "epoch 47; iter: 0; batch classifier loss: 0.181223; batch adversarial loss: 0.553890\n",
      "epoch 48; iter: 0; batch classifier loss: 0.219444; batch adversarial loss: 0.445400\n",
      "epoch 49; iter: 0; batch classifier loss: 0.244991; batch adversarial loss: 0.412092\n",
      "epoch 50; iter: 0; batch classifier loss: 0.177664; batch adversarial loss: 0.470654\n",
      "epoch 51; iter: 0; batch classifier loss: 0.250980; batch adversarial loss: 0.411742\n",
      "epoch 52; iter: 0; batch classifier loss: 0.136950; batch adversarial loss: 0.564415\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088403; batch adversarial loss: 0.459604\n",
      "epoch 54; iter: 0; batch classifier loss: 0.182988; batch adversarial loss: 0.484043\n",
      "epoch 55; iter: 0; batch classifier loss: 0.237542; batch adversarial loss: 0.494080\n",
      "epoch 56; iter: 0; batch classifier loss: 0.160947; batch adversarial loss: 0.397039\n",
      "epoch 57; iter: 0; batch classifier loss: 0.206155; batch adversarial loss: 0.434167\n",
      "epoch 58; iter: 0; batch classifier loss: 0.224011; batch adversarial loss: 0.494242\n",
      "epoch 59; iter: 0; batch classifier loss: 0.205242; batch adversarial loss: 0.508599\n",
      "epoch 60; iter: 0; batch classifier loss: 0.171061; batch adversarial loss: 0.483491\n",
      "epoch 61; iter: 0; batch classifier loss: 0.129711; batch adversarial loss: 0.471513\n",
      "epoch 62; iter: 0; batch classifier loss: 0.224069; batch adversarial loss: 0.375607\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103507; batch adversarial loss: 0.506901\n",
      "epoch 64; iter: 0; batch classifier loss: 0.149952; batch adversarial loss: 0.398102\n",
      "epoch 65; iter: 0; batch classifier loss: 0.144429; batch adversarial loss: 0.545565\n",
      "epoch 66; iter: 0; batch classifier loss: 0.159741; batch adversarial loss: 0.446473\n",
      "epoch 67; iter: 0; batch classifier loss: 0.158580; batch adversarial loss: 0.472032\n",
      "epoch 68; iter: 0; batch classifier loss: 0.175370; batch adversarial loss: 0.484563\n",
      "epoch 69; iter: 0; batch classifier loss: 0.205328; batch adversarial loss: 0.421644\n",
      "epoch 70; iter: 0; batch classifier loss: 0.180256; batch adversarial loss: 0.386704\n",
      "epoch 71; iter: 0; batch classifier loss: 0.137948; batch adversarial loss: 0.398148\n",
      "epoch 72; iter: 0; batch classifier loss: 0.194680; batch adversarial loss: 0.434541\n",
      "epoch 73; iter: 0; batch classifier loss: 0.200838; batch adversarial loss: 0.458268\n",
      "epoch 74; iter: 0; batch classifier loss: 0.225373; batch adversarial loss: 0.433720\n",
      "epoch 75; iter: 0; batch classifier loss: 0.169312; batch adversarial loss: 0.569207\n",
      "epoch 76; iter: 0; batch classifier loss: 0.162502; batch adversarial loss: 0.495226\n",
      "epoch 77; iter: 0; batch classifier loss: 0.143564; batch adversarial loss: 0.434284\n",
      "epoch 78; iter: 0; batch classifier loss: 0.134551; batch adversarial loss: 0.434485\n",
      "epoch 79; iter: 0; batch classifier loss: 0.108668; batch adversarial loss: 0.447515\n",
      "epoch 80; iter: 0; batch classifier loss: 0.157475; batch adversarial loss: 0.409728\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120601; batch adversarial loss: 0.450003\n",
      "epoch 82; iter: 0; batch classifier loss: 0.212535; batch adversarial loss: 0.461211\n",
      "epoch 83; iter: 0; batch classifier loss: 0.133231; batch adversarial loss: 0.397694\n",
      "epoch 84; iter: 0; batch classifier loss: 0.136721; batch adversarial loss: 0.396569\n",
      "epoch 85; iter: 0; batch classifier loss: 0.173437; batch adversarial loss: 0.412513\n",
      "epoch 86; iter: 0; batch classifier loss: 0.190867; batch adversarial loss: 0.471629\n",
      "epoch 87; iter: 0; batch classifier loss: 0.123764; batch adversarial loss: 0.459954\n",
      "epoch 88; iter: 0; batch classifier loss: 0.201022; batch adversarial loss: 0.519861\n",
      "epoch 89; iter: 0; batch classifier loss: 0.120707; batch adversarial loss: 0.396265\n",
      "epoch 90; iter: 0; batch classifier loss: 0.113120; batch adversarial loss: 0.460329\n",
      "epoch 91; iter: 0; batch classifier loss: 0.139984; batch adversarial loss: 0.357136\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069435; batch adversarial loss: 0.599122\n",
      "epoch 93; iter: 0; batch classifier loss: 0.120498; batch adversarial loss: 0.354596\n",
      "epoch 94; iter: 0; batch classifier loss: 0.080192; batch adversarial loss: 0.444198\n",
      "epoch 95; iter: 0; batch classifier loss: 0.135348; batch adversarial loss: 0.452263\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096319; batch adversarial loss: 0.441621\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080750; batch adversarial loss: 0.491235\n",
      "epoch 98; iter: 0; batch classifier loss: 0.118854; batch adversarial loss: 0.431645\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074128; batch adversarial loss: 0.395923\n",
      "epoch 100; iter: 0; batch classifier loss: 0.100921; batch adversarial loss: 0.480978\n",
      "epoch 101; iter: 0; batch classifier loss: 0.078588; batch adversarial loss: 0.490746\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042019; batch adversarial loss: 0.357937\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071084; batch adversarial loss: 0.394697\n",
      "epoch 104; iter: 0; batch classifier loss: 0.082603; batch adversarial loss: 0.442448\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060028; batch adversarial loss: 0.461526\n",
      "epoch 106; iter: 0; batch classifier loss: 0.073509; batch adversarial loss: 0.409322\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045496; batch adversarial loss: 0.582256\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056540; batch adversarial loss: 0.467930\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043016; batch adversarial loss: 0.433449\n",
      "epoch 110; iter: 0; batch classifier loss: 0.073310; batch adversarial loss: 0.415905\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058654; batch adversarial loss: 0.525104\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046803; batch adversarial loss: 0.440836\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069038; batch adversarial loss: 0.457598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.050862; batch adversarial loss: 0.463264\n",
      "epoch 115; iter: 0; batch classifier loss: 0.061859; batch adversarial loss: 0.513881\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030979; batch adversarial loss: 0.471623\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048354; batch adversarial loss: 0.434786\n",
      "epoch 118; iter: 0; batch classifier loss: 0.018657; batch adversarial loss: 0.506890\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027520; batch adversarial loss: 0.391842\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041643; batch adversarial loss: 0.357599\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045833; batch adversarial loss: 0.440665\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030681; batch adversarial loss: 0.361868\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029780; batch adversarial loss: 0.463155\n",
      "epoch 124; iter: 0; batch classifier loss: 0.062293; batch adversarial loss: 0.384785\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023993; batch adversarial loss: 0.541191\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042679; batch adversarial loss: 0.366534\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034992; batch adversarial loss: 0.434477\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025589; batch adversarial loss: 0.424924\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025885; batch adversarial loss: 0.496149\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031589; batch adversarial loss: 0.432749\n",
      "epoch 131; iter: 0; batch classifier loss: 0.062841; batch adversarial loss: 0.482507\n",
      "epoch 132; iter: 0; batch classifier loss: 0.068676; batch adversarial loss: 0.500374\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031176; batch adversarial loss: 0.419921\n",
      "epoch 134; iter: 0; batch classifier loss: 0.064499; batch adversarial loss: 0.386623\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049723; batch adversarial loss: 0.414493\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034815; batch adversarial loss: 0.463213\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022217; batch adversarial loss: 0.444004\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049254; batch adversarial loss: 0.393679\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013255; batch adversarial loss: 0.480448\n",
      "epoch 140; iter: 0; batch classifier loss: 0.012310; batch adversarial loss: 0.498421\n",
      "epoch 141; iter: 0; batch classifier loss: 0.014145; batch adversarial loss: 0.525094\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021161; batch adversarial loss: 0.444180\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025376; batch adversarial loss: 0.382839\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040299; batch adversarial loss: 0.424792\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013313; batch adversarial loss: 0.409285\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044465; batch adversarial loss: 0.456616\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018193; batch adversarial loss: 0.401698\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012500; batch adversarial loss: 0.434726\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026046; batch adversarial loss: 0.496078\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015690; batch adversarial loss: 0.491428\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017843; batch adversarial loss: 0.423781\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015573; batch adversarial loss: 0.476679\n",
      "epoch 153; iter: 0; batch classifier loss: 0.007854; batch adversarial loss: 0.457727\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019700; batch adversarial loss: 0.421911\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014346; batch adversarial loss: 0.414406\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043186; batch adversarial loss: 0.418916\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009914; batch adversarial loss: 0.420050\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016488; batch adversarial loss: 0.391087\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030322; batch adversarial loss: 0.459861\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020707; batch adversarial loss: 0.521137\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018718; batch adversarial loss: 0.349484\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010820; batch adversarial loss: 0.559780\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023156; batch adversarial loss: 0.477930\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029853; batch adversarial loss: 0.492014\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014168; batch adversarial loss: 0.422538\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023717; batch adversarial loss: 0.464654\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010345; batch adversarial loss: 0.479927\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034374; batch adversarial loss: 0.515410\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023826; batch adversarial loss: 0.496335\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009958; batch adversarial loss: 0.435208\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014150; batch adversarial loss: 0.449220\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017292; batch adversarial loss: 0.368928\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017540; batch adversarial loss: 0.421836\n",
      "epoch 174; iter: 0; batch classifier loss: 0.004578; batch adversarial loss: 0.495341\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017891; batch adversarial loss: 0.409675\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007675; batch adversarial loss: 0.369508\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009102; batch adversarial loss: 0.436211\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011507; batch adversarial loss: 0.465153\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012571; batch adversarial loss: 0.400125\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024221; batch adversarial loss: 0.455417\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017822; batch adversarial loss: 0.436224\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036794; batch adversarial loss: 0.453122\n",
      "epoch 183; iter: 0; batch classifier loss: 0.003765; batch adversarial loss: 0.511440\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035948; batch adversarial loss: 0.465273\n",
      "epoch 185; iter: 0; batch classifier loss: 0.003802; batch adversarial loss: 0.423000\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021953; batch adversarial loss: 0.525548\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018385; batch adversarial loss: 0.439986\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024397; batch adversarial loss: 0.445167\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033826; batch adversarial loss: 0.423853\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014712; batch adversarial loss: 0.451357\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014335; batch adversarial loss: 0.423472\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020422; batch adversarial loss: 0.442872\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007891; batch adversarial loss: 0.412025\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005266; batch adversarial loss: 0.426174\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033142; batch adversarial loss: 0.508007\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006458; batch adversarial loss: 0.378516\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005728; batch adversarial loss: 0.407384\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008391; batch adversarial loss: 0.431712\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011933; batch adversarial loss: 0.516958\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731885; batch adversarial loss: 0.869485\n",
      "epoch 1; iter: 0; batch classifier loss: 0.442919; batch adversarial loss: 0.786107\n",
      "epoch 2; iter: 0; batch classifier loss: 0.323519; batch adversarial loss: 0.775722\n",
      "epoch 3; iter: 0; batch classifier loss: 0.384144; batch adversarial loss: 0.703310\n",
      "epoch 4; iter: 0; batch classifier loss: 0.374876; batch adversarial loss: 0.659515\n",
      "epoch 5; iter: 0; batch classifier loss: 0.398667; batch adversarial loss: 0.654402\n",
      "epoch 6; iter: 0; batch classifier loss: 0.343095; batch adversarial loss: 0.601965\n",
      "epoch 7; iter: 0; batch classifier loss: 0.299029; batch adversarial loss: 0.594175\n",
      "epoch 8; iter: 0; batch classifier loss: 0.311270; batch adversarial loss: 0.558262\n",
      "epoch 9; iter: 0; batch classifier loss: 0.304689; batch adversarial loss: 0.559000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.269001; batch adversarial loss: 0.523451\n",
      "epoch 11; iter: 0; batch classifier loss: 0.231045; batch adversarial loss: 0.540934\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251939; batch adversarial loss: 0.507398\n",
      "epoch 13; iter: 0; batch classifier loss: 0.259563; batch adversarial loss: 0.466746\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297970; batch adversarial loss: 0.431720\n",
      "epoch 15; iter: 0; batch classifier loss: 0.287056; batch adversarial loss: 0.475452\n",
      "epoch 16; iter: 0; batch classifier loss: 0.224033; batch adversarial loss: 0.445519\n",
      "epoch 17; iter: 0; batch classifier loss: 0.197544; batch adversarial loss: 0.428876\n",
      "epoch 18; iter: 0; batch classifier loss: 0.196542; batch adversarial loss: 0.402310\n",
      "epoch 19; iter: 0; batch classifier loss: 0.190423; batch adversarial loss: 0.454241\n",
      "epoch 20; iter: 0; batch classifier loss: 0.211553; batch adversarial loss: 0.434160\n",
      "epoch 21; iter: 0; batch classifier loss: 0.167507; batch adversarial loss: 0.448498\n",
      "epoch 22; iter: 0; batch classifier loss: 0.193423; batch adversarial loss: 0.459172\n",
      "epoch 23; iter: 0; batch classifier loss: 0.162783; batch adversarial loss: 0.426648\n",
      "epoch 24; iter: 0; batch classifier loss: 0.191941; batch adversarial loss: 0.474213\n",
      "epoch 25; iter: 0; batch classifier loss: 0.200435; batch adversarial loss: 0.437679\n",
      "epoch 26; iter: 0; batch classifier loss: 0.200043; batch adversarial loss: 0.373751\n",
      "epoch 27; iter: 0; batch classifier loss: 0.085052; batch adversarial loss: 0.439608\n",
      "epoch 28; iter: 0; batch classifier loss: 0.132793; batch adversarial loss: 0.400164\n",
      "epoch 29; iter: 0; batch classifier loss: 0.111725; batch adversarial loss: 0.429797\n",
      "epoch 30; iter: 0; batch classifier loss: 0.177965; batch adversarial loss: 0.365145\n",
      "epoch 31; iter: 0; batch classifier loss: 0.144337; batch adversarial loss: 0.468860\n",
      "epoch 32; iter: 0; batch classifier loss: 0.110470; batch adversarial loss: 0.438445\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144246; batch adversarial loss: 0.431163\n",
      "epoch 34; iter: 0; batch classifier loss: 0.089680; batch adversarial loss: 0.378721\n",
      "epoch 35; iter: 0; batch classifier loss: 0.173112; batch adversarial loss: 0.402371\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187528; batch adversarial loss: 0.378038\n",
      "epoch 37; iter: 0; batch classifier loss: 0.114267; batch adversarial loss: 0.447894\n",
      "epoch 38; iter: 0; batch classifier loss: 0.163927; batch adversarial loss: 0.421275\n",
      "epoch 39; iter: 0; batch classifier loss: 0.152985; batch adversarial loss: 0.347482\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135160; batch adversarial loss: 0.400089\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123078; batch adversarial loss: 0.342894\n",
      "epoch 42; iter: 0; batch classifier loss: 0.079536; batch adversarial loss: 0.439050\n",
      "epoch 43; iter: 0; batch classifier loss: 0.178724; batch adversarial loss: 0.358450\n",
      "epoch 44; iter: 0; batch classifier loss: 0.090603; batch adversarial loss: 0.425074\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086049; batch adversarial loss: 0.413116\n",
      "epoch 46; iter: 0; batch classifier loss: 0.077939; batch adversarial loss: 0.534306\n",
      "epoch 47; iter: 0; batch classifier loss: 0.122480; batch adversarial loss: 0.409602\n",
      "epoch 48; iter: 0; batch classifier loss: 0.110268; batch adversarial loss: 0.411666\n",
      "epoch 49; iter: 0; batch classifier loss: 0.079807; batch adversarial loss: 0.479216\n",
      "epoch 50; iter: 0; batch classifier loss: 0.097330; batch adversarial loss: 0.381350\n",
      "epoch 51; iter: 0; batch classifier loss: 0.111427; batch adversarial loss: 0.404552\n",
      "epoch 52; iter: 0; batch classifier loss: 0.113355; batch adversarial loss: 0.483898\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094439; batch adversarial loss: 0.401645\n",
      "epoch 54; iter: 0; batch classifier loss: 0.059486; batch adversarial loss: 0.431822\n",
      "epoch 55; iter: 0; batch classifier loss: 0.063438; batch adversarial loss: 0.453049\n",
      "epoch 56; iter: 0; batch classifier loss: 0.106301; batch adversarial loss: 0.389565\n",
      "epoch 57; iter: 0; batch classifier loss: 0.054814; batch adversarial loss: 0.407370\n",
      "epoch 58; iter: 0; batch classifier loss: 0.106267; batch adversarial loss: 0.452957\n",
      "epoch 59; iter: 0; batch classifier loss: 0.144201; batch adversarial loss: 0.459155\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122217; batch adversarial loss: 0.525590\n",
      "epoch 61; iter: 0; batch classifier loss: 0.058733; batch adversarial loss: 0.385481\n",
      "epoch 62; iter: 0; batch classifier loss: 0.119718; batch adversarial loss: 0.406684\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097837; batch adversarial loss: 0.517276\n",
      "epoch 64; iter: 0; batch classifier loss: 0.074157; batch adversarial loss: 0.451103\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092315; batch adversarial loss: 0.444957\n",
      "epoch 66; iter: 0; batch classifier loss: 0.106797; batch adversarial loss: 0.333105\n",
      "epoch 67; iter: 0; batch classifier loss: 0.058223; batch adversarial loss: 0.426416\n",
      "epoch 68; iter: 0; batch classifier loss: 0.085619; batch adversarial loss: 0.384542\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065895; batch adversarial loss: 0.386937\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065056; batch adversarial loss: 0.336927\n",
      "epoch 71; iter: 0; batch classifier loss: 0.065150; batch adversarial loss: 0.404292\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077619; batch adversarial loss: 0.322609\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062847; batch adversarial loss: 0.379191\n",
      "epoch 74; iter: 0; batch classifier loss: 0.111647; batch adversarial loss: 0.406974\n",
      "epoch 75; iter: 0; batch classifier loss: 0.143692; batch adversarial loss: 0.408265\n",
      "epoch 76; iter: 0; batch classifier loss: 0.053034; batch adversarial loss: 0.435932\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084671; batch adversarial loss: 0.365211\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062441; batch adversarial loss: 0.372399\n",
      "epoch 79; iter: 0; batch classifier loss: 0.087978; batch adversarial loss: 0.447294\n",
      "epoch 80; iter: 0; batch classifier loss: 0.051396; batch adversarial loss: 0.448174\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061695; batch adversarial loss: 0.372201\n",
      "epoch 82; iter: 0; batch classifier loss: 0.058863; batch adversarial loss: 0.401520\n",
      "epoch 83; iter: 0; batch classifier loss: 0.058295; batch adversarial loss: 0.434538\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052432; batch adversarial loss: 0.394690\n",
      "epoch 85; iter: 0; batch classifier loss: 0.044855; batch adversarial loss: 0.386209\n",
      "epoch 86; iter: 0; batch classifier loss: 0.098335; batch adversarial loss: 0.479628\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055637; batch adversarial loss: 0.370281\n",
      "epoch 88; iter: 0; batch classifier loss: 0.082812; batch adversarial loss: 0.415312\n",
      "epoch 89; iter: 0; batch classifier loss: 0.062018; batch adversarial loss: 0.336889\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064496; batch adversarial loss: 0.459435\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068402; batch adversarial loss: 0.395493\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064997; batch adversarial loss: 0.434613\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078839; batch adversarial loss: 0.407487\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046570; batch adversarial loss: 0.431332\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063160; batch adversarial loss: 0.420405\n",
      "epoch 96; iter: 0; batch classifier loss: 0.074009; batch adversarial loss: 0.464600\n",
      "epoch 97; iter: 0; batch classifier loss: 0.097651; batch adversarial loss: 0.467659\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054290; batch adversarial loss: 0.434736\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054735; batch adversarial loss: 0.384004\n",
      "epoch 100; iter: 0; batch classifier loss: 0.078391; batch adversarial loss: 0.417341\n",
      "epoch 101; iter: 0; batch classifier loss: 0.091731; batch adversarial loss: 0.386721\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066011; batch adversarial loss: 0.460990\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063499; batch adversarial loss: 0.487837\n",
      "epoch 104; iter: 0; batch classifier loss: 0.032651; batch adversarial loss: 0.439755\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055211; batch adversarial loss: 0.380098\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067875; batch adversarial loss: 0.329584\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066159; batch adversarial loss: 0.449171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.068334; batch adversarial loss: 0.459047\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055692; batch adversarial loss: 0.398085\n",
      "epoch 110; iter: 0; batch classifier loss: 0.077022; batch adversarial loss: 0.363374\n",
      "epoch 111; iter: 0; batch classifier loss: 0.078305; batch adversarial loss: 0.383440\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039580; batch adversarial loss: 0.413211\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038589; batch adversarial loss: 0.424128\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068980; batch adversarial loss: 0.420461\n",
      "epoch 115; iter: 0; batch classifier loss: 0.058487; batch adversarial loss: 0.352145\n",
      "epoch 116; iter: 0; batch classifier loss: 0.087134; batch adversarial loss: 0.444265\n",
      "epoch 117; iter: 0; batch classifier loss: 0.070803; batch adversarial loss: 0.433341\n",
      "epoch 118; iter: 0; batch classifier loss: 0.078385; batch adversarial loss: 0.390518\n",
      "epoch 119; iter: 0; batch classifier loss: 0.086241; batch adversarial loss: 0.435308\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062579; batch adversarial loss: 0.349414\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040720; batch adversarial loss: 0.466021\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045984; batch adversarial loss: 0.362410\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029348; batch adversarial loss: 0.397969\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043337; batch adversarial loss: 0.368498\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061011; batch adversarial loss: 0.530880\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038234; batch adversarial loss: 0.417561\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024994; batch adversarial loss: 0.330811\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035616; batch adversarial loss: 0.384533\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052422; batch adversarial loss: 0.458633\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061540; batch adversarial loss: 0.380515\n",
      "epoch 131; iter: 0; batch classifier loss: 0.075364; batch adversarial loss: 0.554913\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039679; batch adversarial loss: 0.440399\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040590; batch adversarial loss: 0.442551\n",
      "epoch 134; iter: 0; batch classifier loss: 0.072267; batch adversarial loss: 0.404582\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051163; batch adversarial loss: 0.400216\n",
      "epoch 136; iter: 0; batch classifier loss: 0.052659; batch adversarial loss: 0.443738\n",
      "epoch 137; iter: 0; batch classifier loss: 0.074659; batch adversarial loss: 0.444836\n",
      "epoch 138; iter: 0; batch classifier loss: 0.068203; batch adversarial loss: 0.394532\n",
      "epoch 139; iter: 0; batch classifier loss: 0.068985; batch adversarial loss: 0.370681\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036912; batch adversarial loss: 0.400714\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024507; batch adversarial loss: 0.361396\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048835; batch adversarial loss: 0.452936\n",
      "epoch 143; iter: 0; batch classifier loss: 0.055312; batch adversarial loss: 0.377129\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020532; batch adversarial loss: 0.467830\n",
      "epoch 145; iter: 0; batch classifier loss: 0.062425; batch adversarial loss: 0.455744\n",
      "epoch 146; iter: 0; batch classifier loss: 0.053961; batch adversarial loss: 0.442212\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044949; batch adversarial loss: 0.467095\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038818; batch adversarial loss: 0.395126\n",
      "epoch 149; iter: 0; batch classifier loss: 0.077743; batch adversarial loss: 0.465802\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039144; batch adversarial loss: 0.394495\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023083; batch adversarial loss: 0.396671\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039232; batch adversarial loss: 0.421451\n",
      "epoch 153; iter: 0; batch classifier loss: 0.051256; batch adversarial loss: 0.411320\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034499; batch adversarial loss: 0.380445\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041212; batch adversarial loss: 0.338529\n",
      "epoch 156; iter: 0; batch classifier loss: 0.068449; batch adversarial loss: 0.469351\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030748; batch adversarial loss: 0.423874\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031599; batch adversarial loss: 0.473289\n",
      "epoch 159; iter: 0; batch classifier loss: 0.062489; batch adversarial loss: 0.448701\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034841; batch adversarial loss: 0.522729\n",
      "epoch 161; iter: 0; batch classifier loss: 0.046916; batch adversarial loss: 0.428785\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039653; batch adversarial loss: 0.369920\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027248; batch adversarial loss: 0.361685\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031987; batch adversarial loss: 0.451537\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036482; batch adversarial loss: 0.424919\n",
      "epoch 166; iter: 0; batch classifier loss: 0.052983; batch adversarial loss: 0.504870\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023645; batch adversarial loss: 0.408766\n",
      "epoch 168; iter: 0; batch classifier loss: 0.042337; batch adversarial loss: 0.486838\n",
      "epoch 169; iter: 0; batch classifier loss: 0.042897; batch adversarial loss: 0.477497\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030141; batch adversarial loss: 0.451111\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008330; batch adversarial loss: 0.465060\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022846; batch adversarial loss: 0.474078\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030579; batch adversarial loss: 0.346128\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022204; batch adversarial loss: 0.508154\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018908; batch adversarial loss: 0.437362\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019395; batch adversarial loss: 0.433012\n",
      "epoch 177; iter: 0; batch classifier loss: 0.043600; batch adversarial loss: 0.512915\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029436; batch adversarial loss: 0.458819\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026076; batch adversarial loss: 0.431815\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027484; batch adversarial loss: 0.413980\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015639; batch adversarial loss: 0.424322\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041847; batch adversarial loss: 0.538564\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027705; batch adversarial loss: 0.424738\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032272; batch adversarial loss: 0.480889\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018866; batch adversarial loss: 0.473653\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022395; batch adversarial loss: 0.481287\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027251; batch adversarial loss: 0.390682\n",
      "epoch 188; iter: 0; batch classifier loss: 0.036894; batch adversarial loss: 0.448558\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032122; batch adversarial loss: 0.530192\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028149; batch adversarial loss: 0.382787\n",
      "epoch 191; iter: 0; batch classifier loss: 0.057626; batch adversarial loss: 0.538900\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028976; batch adversarial loss: 0.583728\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034756; batch adversarial loss: 0.450311\n",
      "epoch 194; iter: 0; batch classifier loss: 0.040374; batch adversarial loss: 0.463509\n",
      "epoch 195; iter: 0; batch classifier loss: 0.063605; batch adversarial loss: 0.544086\n",
      "epoch 196; iter: 0; batch classifier loss: 0.051973; batch adversarial loss: 0.556958\n",
      "epoch 197; iter: 0; batch classifier loss: 0.085659; batch adversarial loss: 0.560638\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032964; batch adversarial loss: 0.559906\n",
      "epoch 199; iter: 0; batch classifier loss: 0.053865; batch adversarial loss: 0.667604\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701569; batch adversarial loss: 0.855700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.681965; batch adversarial loss: 0.905629\n",
      "epoch 2; iter: 0; batch classifier loss: 0.878276; batch adversarial loss: 0.891825\n",
      "epoch 3; iter: 0; batch classifier loss: 0.926401; batch adversarial loss: 0.841444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.786320; batch adversarial loss: 0.747745\n",
      "epoch 5; iter: 0; batch classifier loss: 0.764090; batch adversarial loss: 0.668368\n",
      "epoch 6; iter: 0; batch classifier loss: 0.560212; batch adversarial loss: 0.607172\n",
      "epoch 7; iter: 0; batch classifier loss: 0.488353; batch adversarial loss: 0.562808\n",
      "epoch 8; iter: 0; batch classifier loss: 0.358198; batch adversarial loss: 0.566752\n",
      "epoch 9; iter: 0; batch classifier loss: 0.346166; batch adversarial loss: 0.529343\n",
      "epoch 10; iter: 0; batch classifier loss: 0.279359; batch adversarial loss: 0.496772\n",
      "epoch 11; iter: 0; batch classifier loss: 0.286086; batch adversarial loss: 0.551521\n",
      "epoch 12; iter: 0; batch classifier loss: 0.269363; batch adversarial loss: 0.507903\n",
      "epoch 13; iter: 0; batch classifier loss: 0.348410; batch adversarial loss: 0.505228\n",
      "epoch 14; iter: 0; batch classifier loss: 0.190899; batch adversarial loss: 0.505037\n",
      "epoch 15; iter: 0; batch classifier loss: 0.253767; batch adversarial loss: 0.467807\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242227; batch adversarial loss: 0.483363\n",
      "epoch 17; iter: 0; batch classifier loss: 0.255339; batch adversarial loss: 0.512916\n",
      "epoch 18; iter: 0; batch classifier loss: 0.248825; batch adversarial loss: 0.428892\n",
      "epoch 19; iter: 0; batch classifier loss: 0.188235; batch adversarial loss: 0.432925\n",
      "epoch 20; iter: 0; batch classifier loss: 0.234180; batch adversarial loss: 0.528128\n",
      "epoch 21; iter: 0; batch classifier loss: 0.201792; batch adversarial loss: 0.517175\n",
      "epoch 22; iter: 0; batch classifier loss: 0.215560; batch adversarial loss: 0.478643\n",
      "epoch 23; iter: 0; batch classifier loss: 0.262768; batch adversarial loss: 0.474432\n",
      "epoch 24; iter: 0; batch classifier loss: 0.172945; batch adversarial loss: 0.500652\n",
      "epoch 25; iter: 0; batch classifier loss: 0.165719; batch adversarial loss: 0.493663\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189441; batch adversarial loss: 0.452229\n",
      "epoch 27; iter: 0; batch classifier loss: 0.161251; batch adversarial loss: 0.456510\n",
      "epoch 28; iter: 0; batch classifier loss: 0.210697; batch adversarial loss: 0.521362\n",
      "epoch 29; iter: 0; batch classifier loss: 0.133380; batch adversarial loss: 0.406506\n",
      "epoch 30; iter: 0; batch classifier loss: 0.140778; batch adversarial loss: 0.455928\n",
      "epoch 31; iter: 0; batch classifier loss: 0.179963; batch adversarial loss: 0.448430\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181048; batch adversarial loss: 0.450171\n",
      "epoch 33; iter: 0; batch classifier loss: 0.162711; batch adversarial loss: 0.576799\n",
      "epoch 34; iter: 0; batch classifier loss: 0.099892; batch adversarial loss: 0.444566\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148773; batch adversarial loss: 0.451874\n",
      "epoch 36; iter: 0; batch classifier loss: 0.160345; batch adversarial loss: 0.516353\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166558; batch adversarial loss: 0.423774\n",
      "epoch 38; iter: 0; batch classifier loss: 0.106269; batch adversarial loss: 0.428860\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113240; batch adversarial loss: 0.438206\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124870; batch adversarial loss: 0.489453\n",
      "epoch 41; iter: 0; batch classifier loss: 0.145731; batch adversarial loss: 0.477596\n",
      "epoch 42; iter: 0; batch classifier loss: 0.133828; batch adversarial loss: 0.461851\n",
      "epoch 43; iter: 0; batch classifier loss: 0.129920; batch adversarial loss: 0.469464\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112946; batch adversarial loss: 0.437531\n",
      "epoch 45; iter: 0; batch classifier loss: 0.126493; batch adversarial loss: 0.476796\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113502; batch adversarial loss: 0.409018\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096222; batch adversarial loss: 0.408636\n",
      "epoch 48; iter: 0; batch classifier loss: 0.096887; batch adversarial loss: 0.456030\n",
      "epoch 49; iter: 0; batch classifier loss: 0.109614; batch adversarial loss: 0.464210\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096062; batch adversarial loss: 0.408236\n",
      "epoch 51; iter: 0; batch classifier loss: 0.084659; batch adversarial loss: 0.457300\n",
      "epoch 52; iter: 0; batch classifier loss: 0.116391; batch adversarial loss: 0.506453\n",
      "epoch 53; iter: 0; batch classifier loss: 0.120073; batch adversarial loss: 0.417029\n",
      "epoch 54; iter: 0; batch classifier loss: 0.039974; batch adversarial loss: 0.456457\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072456; batch adversarial loss: 0.383826\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065842; batch adversarial loss: 0.457601\n",
      "epoch 57; iter: 0; batch classifier loss: 0.104710; batch adversarial loss: 0.414982\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093855; batch adversarial loss: 0.398417\n",
      "epoch 59; iter: 0; batch classifier loss: 0.065509; batch adversarial loss: 0.577182\n",
      "epoch 60; iter: 0; batch classifier loss: 0.063328; batch adversarial loss: 0.488737\n",
      "epoch 61; iter: 0; batch classifier loss: 0.047646; batch adversarial loss: 0.492901\n",
      "epoch 62; iter: 0; batch classifier loss: 0.050799; batch adversarial loss: 0.417583\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085352; batch adversarial loss: 0.467894\n",
      "epoch 64; iter: 0; batch classifier loss: 0.024158; batch adversarial loss: 0.498547\n",
      "epoch 65; iter: 0; batch classifier loss: 0.072939; batch adversarial loss: 0.472860\n",
      "epoch 66; iter: 0; batch classifier loss: 0.112510; batch adversarial loss: 0.494831\n",
      "epoch 67; iter: 0; batch classifier loss: 0.052895; batch adversarial loss: 0.564375\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081231; batch adversarial loss: 0.422474\n",
      "epoch 69; iter: 0; batch classifier loss: 0.074940; batch adversarial loss: 0.490651\n",
      "epoch 70; iter: 0; batch classifier loss: 0.057045; batch adversarial loss: 0.528594\n",
      "epoch 71; iter: 0; batch classifier loss: 0.048781; batch adversarial loss: 0.499406\n",
      "epoch 72; iter: 0; batch classifier loss: 0.060117; batch adversarial loss: 0.344878\n",
      "epoch 73; iter: 0; batch classifier loss: 0.082626; batch adversarial loss: 0.436261\n",
      "epoch 74; iter: 0; batch classifier loss: 0.099204; batch adversarial loss: 0.367525\n",
      "epoch 75; iter: 0; batch classifier loss: 0.047803; batch adversarial loss: 0.458028\n",
      "epoch 76; iter: 0; batch classifier loss: 0.026937; batch adversarial loss: 0.444943\n",
      "epoch 77; iter: 0; batch classifier loss: 0.046770; batch adversarial loss: 0.453422\n",
      "epoch 78; iter: 0; batch classifier loss: 0.070576; batch adversarial loss: 0.490836\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093794; batch adversarial loss: 0.486209\n",
      "epoch 80; iter: 0; batch classifier loss: 0.062353; batch adversarial loss: 0.446876\n",
      "epoch 81; iter: 0; batch classifier loss: 0.058337; batch adversarial loss: 0.405708\n",
      "epoch 82; iter: 0; batch classifier loss: 0.057825; batch adversarial loss: 0.438073\n",
      "epoch 83; iter: 0; batch classifier loss: 0.076237; batch adversarial loss: 0.359885\n",
      "epoch 84; iter: 0; batch classifier loss: 0.107679; batch adversarial loss: 0.407590\n",
      "epoch 85; iter: 0; batch classifier loss: 0.025786; batch adversarial loss: 0.512650\n",
      "epoch 86; iter: 0; batch classifier loss: 0.041082; batch adversarial loss: 0.431656\n",
      "epoch 87; iter: 0; batch classifier loss: 0.044613; batch adversarial loss: 0.604419\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088027; batch adversarial loss: 0.526158\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065804; batch adversarial loss: 0.423878\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045380; batch adversarial loss: 0.454231\n",
      "epoch 91; iter: 0; batch classifier loss: 0.087178; batch adversarial loss: 0.437447\n",
      "epoch 92; iter: 0; batch classifier loss: 0.086265; batch adversarial loss: 0.512604\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050968; batch adversarial loss: 0.541047\n",
      "epoch 94; iter: 0; batch classifier loss: 0.091390; batch adversarial loss: 0.500849\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066064; batch adversarial loss: 0.457977\n",
      "epoch 96; iter: 0; batch classifier loss: 0.093689; batch adversarial loss: 0.483218\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050085; batch adversarial loss: 0.479508\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046745; batch adversarial loss: 0.475278\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038823; batch adversarial loss: 0.431261\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043753; batch adversarial loss: 0.390420\n",
      "epoch 101; iter: 0; batch classifier loss: 0.033264; batch adversarial loss: 0.466889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.031374; batch adversarial loss: 0.360554\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054852; batch adversarial loss: 0.407093\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039977; batch adversarial loss: 0.396619\n",
      "epoch 105; iter: 0; batch classifier loss: 0.018642; batch adversarial loss: 0.397235\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034989; batch adversarial loss: 0.496228\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062240; batch adversarial loss: 0.505394\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053876; batch adversarial loss: 0.401927\n",
      "epoch 109; iter: 0; batch classifier loss: 0.068737; batch adversarial loss: 0.412151\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047880; batch adversarial loss: 0.404341\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057233; batch adversarial loss: 0.449452\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040669; batch adversarial loss: 0.396769\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063232; batch adversarial loss: 0.464360\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062547; batch adversarial loss: 0.460448\n",
      "epoch 115; iter: 0; batch classifier loss: 0.071134; batch adversarial loss: 0.397228\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029746; batch adversarial loss: 0.516269\n",
      "epoch 117; iter: 0; batch classifier loss: 0.013537; batch adversarial loss: 0.393598\n",
      "epoch 118; iter: 0; batch classifier loss: 0.022654; batch adversarial loss: 0.452162\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044044; batch adversarial loss: 0.389732\n",
      "epoch 120; iter: 0; batch classifier loss: 0.018780; batch adversarial loss: 0.468243\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026612; batch adversarial loss: 0.422209\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034554; batch adversarial loss: 0.407531\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014090; batch adversarial loss: 0.498320\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026508; batch adversarial loss: 0.529421\n",
      "epoch 125; iter: 0; batch classifier loss: 0.012225; batch adversarial loss: 0.436842\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027596; batch adversarial loss: 0.438147\n",
      "epoch 127; iter: 0; batch classifier loss: 0.014062; batch adversarial loss: 0.420579\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029410; batch adversarial loss: 0.433744\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016075; batch adversarial loss: 0.420749\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029405; batch adversarial loss: 0.452354\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027040; batch adversarial loss: 0.421427\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026604; batch adversarial loss: 0.399631\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031210; batch adversarial loss: 0.513268\n",
      "epoch 134; iter: 0; batch classifier loss: 0.056157; batch adversarial loss: 0.458685\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027326; batch adversarial loss: 0.449185\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040942; batch adversarial loss: 0.434494\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038850; batch adversarial loss: 0.470469\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019751; batch adversarial loss: 0.445209\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044486; batch adversarial loss: 0.484683\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027623; batch adversarial loss: 0.375753\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026771; batch adversarial loss: 0.494664\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018933; batch adversarial loss: 0.457507\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039220; batch adversarial loss: 0.478994\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018127; batch adversarial loss: 0.390076\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025873; batch adversarial loss: 0.435164\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029797; batch adversarial loss: 0.420387\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027373; batch adversarial loss: 0.366630\n",
      "epoch 148; iter: 0; batch classifier loss: 0.007195; batch adversarial loss: 0.495318\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019513; batch adversarial loss: 0.570119\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031345; batch adversarial loss: 0.457220\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025899; batch adversarial loss: 0.541953\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025278; batch adversarial loss: 0.493347\n",
      "epoch 153; iter: 0; batch classifier loss: 0.046006; batch adversarial loss: 0.439973\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046306; batch adversarial loss: 0.372014\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017892; batch adversarial loss: 0.454282\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025071; batch adversarial loss: 0.414175\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040577; batch adversarial loss: 0.424611\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013061; batch adversarial loss: 0.522756\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025295; batch adversarial loss: 0.460697\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007086; batch adversarial loss: 0.431642\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026449; batch adversarial loss: 0.468020\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034238; batch adversarial loss: 0.476420\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019656; batch adversarial loss: 0.427575\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022490; batch adversarial loss: 0.423315\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015119; batch adversarial loss: 0.426249\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015037; batch adversarial loss: 0.323007\n",
      "epoch 167; iter: 0; batch classifier loss: 0.050770; batch adversarial loss: 0.494575\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033590; batch adversarial loss: 0.382915\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007962; batch adversarial loss: 0.444668\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014097; batch adversarial loss: 0.438970\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018982; batch adversarial loss: 0.497106\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028343; batch adversarial loss: 0.429916\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034922; batch adversarial loss: 0.406964\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027809; batch adversarial loss: 0.458913\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037657; batch adversarial loss: 0.445187\n",
      "epoch 176; iter: 0; batch classifier loss: 0.006840; batch adversarial loss: 0.510001\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022270; batch adversarial loss: 0.447258\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026404; batch adversarial loss: 0.509554\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015295; batch adversarial loss: 0.438297\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012842; batch adversarial loss: 0.349023\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026137; batch adversarial loss: 0.376233\n",
      "epoch 182; iter: 0; batch classifier loss: 0.039838; batch adversarial loss: 0.462410\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021202; batch adversarial loss: 0.486224\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011124; batch adversarial loss: 0.431478\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021749; batch adversarial loss: 0.522118\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014448; batch adversarial loss: 0.420366\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009769; batch adversarial loss: 0.468481\n",
      "epoch 188; iter: 0; batch classifier loss: 0.002827; batch adversarial loss: 0.444294\n",
      "epoch 189; iter: 0; batch classifier loss: 0.050492; batch adversarial loss: 0.392181\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036796; batch adversarial loss: 0.400847\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005553; batch adversarial loss: 0.415340\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022896; batch adversarial loss: 0.485685\n",
      "epoch 193; iter: 0; batch classifier loss: 0.048548; batch adversarial loss: 0.426073\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006835; batch adversarial loss: 0.516588\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028753; batch adversarial loss: 0.417866\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013477; batch adversarial loss: 0.451246\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009197; batch adversarial loss: 0.429202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.011631; batch adversarial loss: 0.364053\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011181; batch adversarial loss: 0.364351\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687032; batch adversarial loss: 0.870303\n",
      "epoch 1; iter: 0; batch classifier loss: 0.566031; batch adversarial loss: 0.947205\n",
      "epoch 2; iter: 0; batch classifier loss: 0.868702; batch adversarial loss: 1.006595\n",
      "epoch 3; iter: 0; batch classifier loss: 0.979446; batch adversarial loss: 0.902589\n",
      "epoch 4; iter: 0; batch classifier loss: 1.067256; batch adversarial loss: 0.815308\n",
      "epoch 5; iter: 0; batch classifier loss: 0.934603; batch adversarial loss: 0.735774\n",
      "epoch 6; iter: 0; batch classifier loss: 0.977811; batch adversarial loss: 0.649601\n",
      "epoch 7; iter: 0; batch classifier loss: 0.730609; batch adversarial loss: 0.620291\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534818; batch adversarial loss: 0.567844\n",
      "epoch 9; iter: 0; batch classifier loss: 0.410084; batch adversarial loss: 0.527758\n",
      "epoch 10; iter: 0; batch classifier loss: 0.363467; batch adversarial loss: 0.553235\n",
      "epoch 11; iter: 0; batch classifier loss: 0.346394; batch adversarial loss: 0.523229\n",
      "epoch 12; iter: 0; batch classifier loss: 0.349475; batch adversarial loss: 0.557854\n",
      "epoch 13; iter: 0; batch classifier loss: 0.292714; batch adversarial loss: 0.528330\n",
      "epoch 14; iter: 0; batch classifier loss: 0.293824; batch adversarial loss: 0.483159\n",
      "epoch 15; iter: 0; batch classifier loss: 0.355167; batch adversarial loss: 0.487857\n",
      "epoch 16; iter: 0; batch classifier loss: 0.301476; batch adversarial loss: 0.480200\n",
      "epoch 17; iter: 0; batch classifier loss: 0.195582; batch adversarial loss: 0.562721\n",
      "epoch 18; iter: 0; batch classifier loss: 0.305816; batch adversarial loss: 0.461080\n",
      "epoch 19; iter: 0; batch classifier loss: 0.306766; batch adversarial loss: 0.431084\n",
      "epoch 20; iter: 0; batch classifier loss: 0.268964; batch adversarial loss: 0.569074\n",
      "epoch 21; iter: 0; batch classifier loss: 0.257398; batch adversarial loss: 0.448436\n",
      "epoch 22; iter: 0; batch classifier loss: 0.270624; batch adversarial loss: 0.451146\n",
      "epoch 23; iter: 0; batch classifier loss: 0.279771; batch adversarial loss: 0.506031\n",
      "epoch 24; iter: 0; batch classifier loss: 0.217418; batch adversarial loss: 0.504869\n",
      "epoch 25; iter: 0; batch classifier loss: 0.298311; batch adversarial loss: 0.474409\n",
      "epoch 26; iter: 0; batch classifier loss: 0.212515; batch adversarial loss: 0.516564\n",
      "epoch 27; iter: 0; batch classifier loss: 0.209437; batch adversarial loss: 0.544442\n",
      "epoch 28; iter: 0; batch classifier loss: 0.227727; batch adversarial loss: 0.473538\n",
      "epoch 29; iter: 0; batch classifier loss: 0.192005; batch adversarial loss: 0.456556\n",
      "epoch 30; iter: 0; batch classifier loss: 0.261066; batch adversarial loss: 0.419338\n",
      "epoch 31; iter: 0; batch classifier loss: 0.193358; batch adversarial loss: 0.504687\n",
      "epoch 32; iter: 0; batch classifier loss: 0.188470; batch adversarial loss: 0.477629\n",
      "epoch 33; iter: 0; batch classifier loss: 0.230833; batch adversarial loss: 0.503204\n",
      "epoch 34; iter: 0; batch classifier loss: 0.231206; batch adversarial loss: 0.461027\n",
      "epoch 35; iter: 0; batch classifier loss: 0.236255; batch adversarial loss: 0.458168\n",
      "epoch 36; iter: 0; batch classifier loss: 0.210388; batch adversarial loss: 0.462795\n",
      "epoch 37; iter: 0; batch classifier loss: 0.228993; batch adversarial loss: 0.448815\n",
      "epoch 38; iter: 0; batch classifier loss: 0.221403; batch adversarial loss: 0.397310\n",
      "epoch 39; iter: 0; batch classifier loss: 0.315090; batch adversarial loss: 0.450207\n",
      "epoch 40; iter: 0; batch classifier loss: 0.206533; batch adversarial loss: 0.387273\n",
      "epoch 41; iter: 0; batch classifier loss: 0.171642; batch adversarial loss: 0.554048\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235874; batch adversarial loss: 0.383988\n",
      "epoch 43; iter: 0; batch classifier loss: 0.185137; batch adversarial loss: 0.493004\n",
      "epoch 44; iter: 0; batch classifier loss: 0.194641; batch adversarial loss: 0.449406\n",
      "epoch 45; iter: 0; batch classifier loss: 0.156370; batch adversarial loss: 0.458536\n",
      "epoch 46; iter: 0; batch classifier loss: 0.180631; batch adversarial loss: 0.476447\n",
      "epoch 47; iter: 0; batch classifier loss: 0.193850; batch adversarial loss: 0.509608\n",
      "epoch 48; iter: 0; batch classifier loss: 0.202553; batch adversarial loss: 0.426202\n",
      "epoch 49; iter: 0; batch classifier loss: 0.111051; batch adversarial loss: 0.537648\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129591; batch adversarial loss: 0.538537\n",
      "epoch 51; iter: 0; batch classifier loss: 0.188640; batch adversarial loss: 0.407761\n",
      "epoch 52; iter: 0; batch classifier loss: 0.154423; batch adversarial loss: 0.459749\n",
      "epoch 53; iter: 0; batch classifier loss: 0.203789; batch adversarial loss: 0.519395\n",
      "epoch 54; iter: 0; batch classifier loss: 0.140397; batch adversarial loss: 0.472352\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089535; batch adversarial loss: 0.485403\n",
      "epoch 56; iter: 0; batch classifier loss: 0.137037; batch adversarial loss: 0.408685\n",
      "epoch 57; iter: 0; batch classifier loss: 0.170200; batch adversarial loss: 0.469692\n",
      "epoch 58; iter: 0; batch classifier loss: 0.163174; batch adversarial loss: 0.405453\n",
      "epoch 59; iter: 0; batch classifier loss: 0.089284; batch adversarial loss: 0.441106\n",
      "epoch 60; iter: 0; batch classifier loss: 0.154067; batch adversarial loss: 0.455099\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080930; batch adversarial loss: 0.504490\n",
      "epoch 62; iter: 0; batch classifier loss: 0.127674; batch adversarial loss: 0.508643\n",
      "epoch 63; iter: 0; batch classifier loss: 0.108292; batch adversarial loss: 0.460945\n",
      "epoch 64; iter: 0; batch classifier loss: 0.135948; batch adversarial loss: 0.383157\n",
      "epoch 65; iter: 0; batch classifier loss: 0.166294; batch adversarial loss: 0.427721\n",
      "epoch 66; iter: 0; batch classifier loss: 0.160502; batch adversarial loss: 0.478479\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171346; batch adversarial loss: 0.537193\n",
      "epoch 68; iter: 0; batch classifier loss: 0.126219; batch adversarial loss: 0.487363\n",
      "epoch 69; iter: 0; batch classifier loss: 0.148998; batch adversarial loss: 0.496478\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144914; batch adversarial loss: 0.451304\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099540; batch adversarial loss: 0.529169\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097788; batch adversarial loss: 0.526068\n",
      "epoch 73; iter: 0; batch classifier loss: 0.126313; batch adversarial loss: 0.485926\n",
      "epoch 74; iter: 0; batch classifier loss: 0.134286; batch adversarial loss: 0.434005\n",
      "epoch 75; iter: 0; batch classifier loss: 0.085043; batch adversarial loss: 0.438836\n",
      "epoch 76; iter: 0; batch classifier loss: 0.095962; batch adversarial loss: 0.558577\n",
      "epoch 77; iter: 0; batch classifier loss: 0.125211; batch adversarial loss: 0.436625\n",
      "epoch 78; iter: 0; batch classifier loss: 0.089532; batch adversarial loss: 0.515688\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082582; batch adversarial loss: 0.419618\n",
      "epoch 80; iter: 0; batch classifier loss: 0.140644; batch adversarial loss: 0.404816\n",
      "epoch 81; iter: 0; batch classifier loss: 0.116495; batch adversarial loss: 0.506908\n",
      "epoch 82; iter: 0; batch classifier loss: 0.092440; batch adversarial loss: 0.509702\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086159; batch adversarial loss: 0.435075\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068772; batch adversarial loss: 0.508587\n",
      "epoch 85; iter: 0; batch classifier loss: 0.082239; batch adversarial loss: 0.374367\n",
      "epoch 86; iter: 0; batch classifier loss: 0.078507; batch adversarial loss: 0.548903\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068341; batch adversarial loss: 0.443626\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076789; batch adversarial loss: 0.481045\n",
      "epoch 89; iter: 0; batch classifier loss: 0.072773; batch adversarial loss: 0.375497\n",
      "epoch 90; iter: 0; batch classifier loss: 0.077276; batch adversarial loss: 0.530953\n",
      "epoch 91; iter: 0; batch classifier loss: 0.096435; batch adversarial loss: 0.389234\n",
      "epoch 92; iter: 0; batch classifier loss: 0.075317; batch adversarial loss: 0.492296\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064076; batch adversarial loss: 0.384482\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051699; batch adversarial loss: 0.477422\n",
      "epoch 95; iter: 0; batch classifier loss: 0.082442; batch adversarial loss: 0.476014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.067708; batch adversarial loss: 0.475755\n",
      "epoch 97; iter: 0; batch classifier loss: 0.084690; batch adversarial loss: 0.407084\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054488; batch adversarial loss: 0.458498\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055597; batch adversarial loss: 0.532192\n",
      "epoch 100; iter: 0; batch classifier loss: 0.023648; batch adversarial loss: 0.413928\n",
      "epoch 101; iter: 0; batch classifier loss: 0.091547; batch adversarial loss: 0.478019\n",
      "epoch 102; iter: 0; batch classifier loss: 0.061821; batch adversarial loss: 0.331113\n",
      "epoch 103; iter: 0; batch classifier loss: 0.098291; batch adversarial loss: 0.449864\n",
      "epoch 104; iter: 0; batch classifier loss: 0.032700; batch adversarial loss: 0.544943\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054356; batch adversarial loss: 0.366544\n",
      "epoch 106; iter: 0; batch classifier loss: 0.065725; batch adversarial loss: 0.479543\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061568; batch adversarial loss: 0.401813\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031358; batch adversarial loss: 0.465206\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040151; batch adversarial loss: 0.489395\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038377; batch adversarial loss: 0.505265\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062595; batch adversarial loss: 0.472289\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043877; batch adversarial loss: 0.427237\n",
      "epoch 113; iter: 0; batch classifier loss: 0.065101; batch adversarial loss: 0.393762\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026242; batch adversarial loss: 0.340712\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021517; batch adversarial loss: 0.532342\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064332; batch adversarial loss: 0.399035\n",
      "epoch 117; iter: 0; batch classifier loss: 0.075841; batch adversarial loss: 0.487257\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047931; batch adversarial loss: 0.433592\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041364; batch adversarial loss: 0.474257\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049208; batch adversarial loss: 0.478236\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025684; batch adversarial loss: 0.418253\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030653; batch adversarial loss: 0.460199\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043037; batch adversarial loss: 0.402293\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035504; batch adversarial loss: 0.559699\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031915; batch adversarial loss: 0.459913\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038070; batch adversarial loss: 0.497951\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030813; batch adversarial loss: 0.529385\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039101; batch adversarial loss: 0.520744\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038229; batch adversarial loss: 0.461302\n",
      "epoch 130; iter: 0; batch classifier loss: 0.012486; batch adversarial loss: 0.513507\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042146; batch adversarial loss: 0.543427\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058508; batch adversarial loss: 0.519750\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018014; batch adversarial loss: 0.515017\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036089; batch adversarial loss: 0.463988\n",
      "epoch 135; iter: 0; batch classifier loss: 0.064854; batch adversarial loss: 0.535452\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017404; batch adversarial loss: 0.452034\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039205; batch adversarial loss: 0.434228\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039982; batch adversarial loss: 0.420509\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029660; batch adversarial loss: 0.541535\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027707; batch adversarial loss: 0.485906\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025889; batch adversarial loss: 0.433749\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018208; batch adversarial loss: 0.495753\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030480; batch adversarial loss: 0.411500\n",
      "epoch 144; iter: 0; batch classifier loss: 0.005787; batch adversarial loss: 0.448795\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015987; batch adversarial loss: 0.425383\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013294; batch adversarial loss: 0.440317\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017154; batch adversarial loss: 0.529819\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035267; batch adversarial loss: 0.416386\n",
      "epoch 149; iter: 0; batch classifier loss: 0.009014; batch adversarial loss: 0.454225\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037372; batch adversarial loss: 0.447273\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018018; batch adversarial loss: 0.443273\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041332; batch adversarial loss: 0.406362\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015895; batch adversarial loss: 0.433693\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021703; batch adversarial loss: 0.509782\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009175; batch adversarial loss: 0.486687\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044806; batch adversarial loss: 0.494570\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022563; batch adversarial loss: 0.548698\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021933; batch adversarial loss: 0.423865\n",
      "epoch 159; iter: 0; batch classifier loss: 0.005811; batch adversarial loss: 0.497337\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014592; batch adversarial loss: 0.448244\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014101; batch adversarial loss: 0.490918\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023248; batch adversarial loss: 0.389236\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037701; batch adversarial loss: 0.590752\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024815; batch adversarial loss: 0.586854\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015683; batch adversarial loss: 0.471171\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038790; batch adversarial loss: 0.359791\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028637; batch adversarial loss: 0.476921\n",
      "epoch 168; iter: 0; batch classifier loss: 0.048864; batch adversarial loss: 0.481533\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016475; batch adversarial loss: 0.403947\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008864; batch adversarial loss: 0.532182\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025304; batch adversarial loss: 0.390910\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015059; batch adversarial loss: 0.583328\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019868; batch adversarial loss: 0.413754\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022748; batch adversarial loss: 0.405735\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022345; batch adversarial loss: 0.556969\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030316; batch adversarial loss: 0.432783\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016536; batch adversarial loss: 0.493479\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021654; batch adversarial loss: 0.437743\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007915; batch adversarial loss: 0.452997\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034549; batch adversarial loss: 0.397408\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036137; batch adversarial loss: 0.435553\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028866; batch adversarial loss: 0.402592\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033389; batch adversarial loss: 0.491199\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015528; batch adversarial loss: 0.449194\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023254; batch adversarial loss: 0.405308\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008704; batch adversarial loss: 0.466301\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007844; batch adversarial loss: 0.461949\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009580; batch adversarial loss: 0.410469\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004860; batch adversarial loss: 0.476531\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021435; batch adversarial loss: 0.420406\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011867; batch adversarial loss: 0.494349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.020371; batch adversarial loss: 0.396475\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009819; batch adversarial loss: 0.506039\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014796; batch adversarial loss: 0.365428\n",
      "epoch 195; iter: 0; batch classifier loss: 0.007435; batch adversarial loss: 0.507835\n",
      "epoch 196; iter: 0; batch classifier loss: 0.002147; batch adversarial loss: 0.461695\n",
      "epoch 197; iter: 0; batch classifier loss: 0.003942; batch adversarial loss: 0.482211\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010912; batch adversarial loss: 0.354426\n",
      "epoch 199; iter: 0; batch classifier loss: 0.065279; batch adversarial loss: 0.450151\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680975; batch adversarial loss: 0.924950\n",
      "epoch 1; iter: 0; batch classifier loss: 0.450186; batch adversarial loss: 1.051390\n",
      "epoch 2; iter: 0; batch classifier loss: 0.388353; batch adversarial loss: 1.002105\n",
      "epoch 3; iter: 0; batch classifier loss: 0.447084; batch adversarial loss: 0.855222\n",
      "epoch 4; iter: 0; batch classifier loss: 0.275137; batch adversarial loss: 0.879827\n",
      "epoch 5; iter: 0; batch classifier loss: 0.308071; batch adversarial loss: 0.792742\n",
      "epoch 6; iter: 0; batch classifier loss: 0.268083; batch adversarial loss: 0.738450\n",
      "epoch 7; iter: 0; batch classifier loss: 0.290373; batch adversarial loss: 0.684860\n",
      "epoch 8; iter: 0; batch classifier loss: 0.309525; batch adversarial loss: 0.707649\n",
      "epoch 9; iter: 0; batch classifier loss: 0.245410; batch adversarial loss: 0.651762\n",
      "epoch 10; iter: 0; batch classifier loss: 0.266469; batch adversarial loss: 0.630704\n",
      "epoch 11; iter: 0; batch classifier loss: 0.241758; batch adversarial loss: 0.620320\n",
      "epoch 12; iter: 0; batch classifier loss: 0.226144; batch adversarial loss: 0.575335\n",
      "epoch 13; iter: 0; batch classifier loss: 0.249419; batch adversarial loss: 0.584409\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263087; batch adversarial loss: 0.561740\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274304; batch adversarial loss: 0.523481\n",
      "epoch 16; iter: 0; batch classifier loss: 0.276273; batch adversarial loss: 0.534881\n",
      "epoch 17; iter: 0; batch classifier loss: 0.211261; batch adversarial loss: 0.520274\n",
      "epoch 18; iter: 0; batch classifier loss: 0.172374; batch adversarial loss: 0.473242\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223281; batch adversarial loss: 0.462131\n",
      "epoch 20; iter: 0; batch classifier loss: 0.178840; batch adversarial loss: 0.449643\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186743; batch adversarial loss: 0.508610\n",
      "epoch 22; iter: 0; batch classifier loss: 0.186921; batch adversarial loss: 0.443740\n",
      "epoch 23; iter: 0; batch classifier loss: 0.189825; batch adversarial loss: 0.483003\n",
      "epoch 24; iter: 0; batch classifier loss: 0.220549; batch adversarial loss: 0.479686\n",
      "epoch 25; iter: 0; batch classifier loss: 0.218052; batch adversarial loss: 0.511631\n",
      "epoch 26; iter: 0; batch classifier loss: 0.212120; batch adversarial loss: 0.486614\n",
      "epoch 27; iter: 0; batch classifier loss: 0.235761; batch adversarial loss: 0.409601\n",
      "epoch 28; iter: 0; batch classifier loss: 0.263203; batch adversarial loss: 0.417029\n",
      "epoch 29; iter: 0; batch classifier loss: 0.288457; batch adversarial loss: 0.452597\n",
      "epoch 30; iter: 0; batch classifier loss: 0.268958; batch adversarial loss: 0.475643\n",
      "epoch 31; iter: 0; batch classifier loss: 0.246922; batch adversarial loss: 0.495605\n",
      "epoch 32; iter: 0; batch classifier loss: 0.305284; batch adversarial loss: 0.410511\n",
      "epoch 33; iter: 0; batch classifier loss: 0.211061; batch adversarial loss: 0.368801\n",
      "epoch 34; iter: 0; batch classifier loss: 0.211869; batch adversarial loss: 0.449062\n",
      "epoch 35; iter: 0; batch classifier loss: 0.214120; batch adversarial loss: 0.427941\n",
      "epoch 36; iter: 0; batch classifier loss: 0.186854; batch adversarial loss: 0.416179\n",
      "epoch 37; iter: 0; batch classifier loss: 0.206440; batch adversarial loss: 0.419059\n",
      "epoch 38; iter: 0; batch classifier loss: 0.218542; batch adversarial loss: 0.440739\n",
      "epoch 39; iter: 0; batch classifier loss: 0.227072; batch adversarial loss: 0.426283\n",
      "epoch 40; iter: 0; batch classifier loss: 0.175235; batch adversarial loss: 0.440575\n",
      "epoch 41; iter: 0; batch classifier loss: 0.161143; batch adversarial loss: 0.424226\n",
      "epoch 42; iter: 0; batch classifier loss: 0.194192; batch adversarial loss: 0.550637\n",
      "epoch 43; iter: 0; batch classifier loss: 0.143344; batch adversarial loss: 0.456325\n",
      "epoch 44; iter: 0; batch classifier loss: 0.145344; batch adversarial loss: 0.357122\n",
      "epoch 45; iter: 0; batch classifier loss: 0.149710; batch adversarial loss: 0.433209\n",
      "epoch 46; iter: 0; batch classifier loss: 0.148646; batch adversarial loss: 0.500914\n",
      "epoch 47; iter: 0; batch classifier loss: 0.171151; batch adversarial loss: 0.370404\n",
      "epoch 48; iter: 0; batch classifier loss: 0.133278; batch adversarial loss: 0.311749\n",
      "epoch 49; iter: 0; batch classifier loss: 0.160779; batch adversarial loss: 0.447550\n",
      "epoch 50; iter: 0; batch classifier loss: 0.145768; batch adversarial loss: 0.466412\n",
      "epoch 51; iter: 0; batch classifier loss: 0.116427; batch adversarial loss: 0.447816\n",
      "epoch 52; iter: 0; batch classifier loss: 0.133906; batch adversarial loss: 0.460994\n",
      "epoch 53; iter: 0; batch classifier loss: 0.125653; batch adversarial loss: 0.431732\n",
      "epoch 54; iter: 0; batch classifier loss: 0.136596; batch adversarial loss: 0.461632\n",
      "epoch 55; iter: 0; batch classifier loss: 0.095638; batch adversarial loss: 0.426064\n",
      "epoch 56; iter: 0; batch classifier loss: 0.131356; batch adversarial loss: 0.433685\n",
      "epoch 57; iter: 0; batch classifier loss: 0.109175; batch adversarial loss: 0.450650\n",
      "epoch 58; iter: 0; batch classifier loss: 0.112528; batch adversarial loss: 0.473554\n",
      "epoch 59; iter: 0; batch classifier loss: 0.139876; batch adversarial loss: 0.337364\n",
      "epoch 60; iter: 0; batch classifier loss: 0.110548; batch adversarial loss: 0.449295\n",
      "epoch 61; iter: 0; batch classifier loss: 0.101672; batch adversarial loss: 0.352137\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089797; batch adversarial loss: 0.476692\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089125; batch adversarial loss: 0.446772\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076704; batch adversarial loss: 0.396787\n",
      "epoch 65; iter: 0; batch classifier loss: 0.099135; batch adversarial loss: 0.384124\n",
      "epoch 66; iter: 0; batch classifier loss: 0.057085; batch adversarial loss: 0.415292\n",
      "epoch 67; iter: 0; batch classifier loss: 0.072624; batch adversarial loss: 0.452745\n",
      "epoch 68; iter: 0; batch classifier loss: 0.105781; batch adversarial loss: 0.389190\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082036; batch adversarial loss: 0.507415\n",
      "epoch 70; iter: 0; batch classifier loss: 0.060137; batch adversarial loss: 0.367194\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063996; batch adversarial loss: 0.377211\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065490; batch adversarial loss: 0.408508\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084141; batch adversarial loss: 0.465539\n",
      "epoch 74; iter: 0; batch classifier loss: 0.088650; batch adversarial loss: 0.416242\n",
      "epoch 75; iter: 0; batch classifier loss: 0.099160; batch adversarial loss: 0.427406\n",
      "epoch 76; iter: 0; batch classifier loss: 0.101353; batch adversarial loss: 0.368432\n",
      "epoch 77; iter: 0; batch classifier loss: 0.115676; batch adversarial loss: 0.409356\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077388; batch adversarial loss: 0.427324\n",
      "epoch 79; iter: 0; batch classifier loss: 0.122240; batch adversarial loss: 0.420648\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068264; batch adversarial loss: 0.484357\n",
      "epoch 81; iter: 0; batch classifier loss: 0.063502; batch adversarial loss: 0.377683\n",
      "epoch 82; iter: 0; batch classifier loss: 0.051663; batch adversarial loss: 0.392775\n",
      "epoch 83; iter: 0; batch classifier loss: 0.051968; batch adversarial loss: 0.464666\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059052; batch adversarial loss: 0.449986\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080880; batch adversarial loss: 0.489807\n",
      "epoch 86; iter: 0; batch classifier loss: 0.096808; batch adversarial loss: 0.411943\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072317; batch adversarial loss: 0.389772\n",
      "epoch 88; iter: 0; batch classifier loss: 0.089707; batch adversarial loss: 0.462490\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063602; batch adversarial loss: 0.509133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.095791; batch adversarial loss: 0.415619\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066592; batch adversarial loss: 0.517802\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068265; batch adversarial loss: 0.411830\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067236; batch adversarial loss: 0.436459\n",
      "epoch 94; iter: 0; batch classifier loss: 0.054276; batch adversarial loss: 0.441575\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087687; batch adversarial loss: 0.499360\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068602; batch adversarial loss: 0.342982\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071912; batch adversarial loss: 0.375443\n",
      "epoch 98; iter: 0; batch classifier loss: 0.097134; batch adversarial loss: 0.392218\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052471; batch adversarial loss: 0.485781\n",
      "epoch 100; iter: 0; batch classifier loss: 0.052541; batch adversarial loss: 0.452098\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050142; batch adversarial loss: 0.440826\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055530; batch adversarial loss: 0.412094\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047707; batch adversarial loss: 0.386449\n",
      "epoch 104; iter: 0; batch classifier loss: 0.077961; batch adversarial loss: 0.479378\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064812; batch adversarial loss: 0.431364\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032722; batch adversarial loss: 0.430080\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045526; batch adversarial loss: 0.358922\n",
      "epoch 108; iter: 0; batch classifier loss: 0.047860; batch adversarial loss: 0.506202\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054275; batch adversarial loss: 0.452929\n",
      "epoch 110; iter: 0; batch classifier loss: 0.075380; batch adversarial loss: 0.470632\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042047; batch adversarial loss: 0.532945\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040097; batch adversarial loss: 0.492039\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040821; batch adversarial loss: 0.416894\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040095; batch adversarial loss: 0.435513\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041738; batch adversarial loss: 0.485666\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056398; batch adversarial loss: 0.479711\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053254; batch adversarial loss: 0.446267\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056824; batch adversarial loss: 0.540560\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030890; batch adversarial loss: 0.437552\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040463; batch adversarial loss: 0.400879\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048939; batch adversarial loss: 0.385838\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041825; batch adversarial loss: 0.420323\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043685; batch adversarial loss: 0.435947\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024609; batch adversarial loss: 0.448459\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025412; batch adversarial loss: 0.389081\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029852; batch adversarial loss: 0.518348\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047419; batch adversarial loss: 0.347742\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026168; batch adversarial loss: 0.453782\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019282; batch adversarial loss: 0.410893\n",
      "epoch 130; iter: 0; batch classifier loss: 0.012171; batch adversarial loss: 0.493883\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040017; batch adversarial loss: 0.551744\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021030; batch adversarial loss: 0.466221\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029180; batch adversarial loss: 0.541811\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031573; batch adversarial loss: 0.416983\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046737; batch adversarial loss: 0.447431\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017340; batch adversarial loss: 0.371899\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026512; batch adversarial loss: 0.412232\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016656; batch adversarial loss: 0.407494\n",
      "epoch 139; iter: 0; batch classifier loss: 0.011034; batch adversarial loss: 0.400516\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018905; batch adversarial loss: 0.423230\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026665; batch adversarial loss: 0.435835\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041942; batch adversarial loss: 0.426155\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025071; batch adversarial loss: 0.485564\n",
      "epoch 144; iter: 0; batch classifier loss: 0.008190; batch adversarial loss: 0.541892\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020077; batch adversarial loss: 0.518882\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026026; batch adversarial loss: 0.357055\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052740; batch adversarial loss: 0.485375\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036159; batch adversarial loss: 0.538260\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022595; batch adversarial loss: 0.493005\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032407; batch adversarial loss: 0.503335\n",
      "epoch 151; iter: 0; batch classifier loss: 0.071478; batch adversarial loss: 0.549497\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043402; batch adversarial loss: 0.463292\n",
      "epoch 153; iter: 0; batch classifier loss: 0.056068; batch adversarial loss: 0.585624\n",
      "epoch 154; iter: 0; batch classifier loss: 0.074595; batch adversarial loss: 0.630280\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042773; batch adversarial loss: 0.409840\n",
      "epoch 156; iter: 0; batch classifier loss: 0.060847; batch adversarial loss: 0.487950\n",
      "epoch 157; iter: 0; batch classifier loss: 0.058586; batch adversarial loss: 0.601524\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022145; batch adversarial loss: 0.462275\n",
      "epoch 159; iter: 0; batch classifier loss: 0.125257; batch adversarial loss: 0.594262\n",
      "epoch 160; iter: 0; batch classifier loss: 0.166974; batch adversarial loss: 0.723263\n",
      "epoch 161; iter: 0; batch classifier loss: 0.140596; batch adversarial loss: 0.666199\n",
      "epoch 162; iter: 0; batch classifier loss: 0.089582; batch adversarial loss: 0.569288\n",
      "epoch 163; iter: 0; batch classifier loss: 0.083803; batch adversarial loss: 0.524965\n",
      "epoch 164; iter: 0; batch classifier loss: 0.082739; batch adversarial loss: 0.576907\n",
      "epoch 165; iter: 0; batch classifier loss: 0.185975; batch adversarial loss: 0.780532\n",
      "epoch 166; iter: 0; batch classifier loss: 0.126916; batch adversarial loss: 0.622310\n",
      "epoch 167; iter: 0; batch classifier loss: 0.088362; batch adversarial loss: 0.429056\n",
      "epoch 168; iter: 0; batch classifier loss: 0.317668; batch adversarial loss: 0.777903\n",
      "epoch 169; iter: 0; batch classifier loss: 0.090149; batch adversarial loss: 0.587920\n",
      "epoch 170; iter: 0; batch classifier loss: 0.146679; batch adversarial loss: 0.612523\n",
      "epoch 171; iter: 0; batch classifier loss: 0.107362; batch adversarial loss: 0.462174\n",
      "epoch 172; iter: 0; batch classifier loss: 0.124769; batch adversarial loss: 0.584553\n",
      "epoch 173; iter: 0; batch classifier loss: 0.093430; batch adversarial loss: 0.480519\n",
      "epoch 174; iter: 0; batch classifier loss: 0.139712; batch adversarial loss: 0.615060\n",
      "epoch 175; iter: 0; batch classifier loss: 0.130599; batch adversarial loss: 0.507937\n",
      "epoch 176; iter: 0; batch classifier loss: 0.091669; batch adversarial loss: 0.515678\n",
      "epoch 177; iter: 0; batch classifier loss: 0.137895; batch adversarial loss: 0.512718\n",
      "epoch 178; iter: 0; batch classifier loss: 0.156937; batch adversarial loss: 0.536977\n",
      "epoch 179; iter: 0; batch classifier loss: 0.177578; batch adversarial loss: 0.653648\n",
      "epoch 180; iter: 0; batch classifier loss: 0.070499; batch adversarial loss: 0.404724\n",
      "epoch 181; iter: 0; batch classifier loss: 0.216436; batch adversarial loss: 0.584458\n",
      "epoch 182; iter: 0; batch classifier loss: 0.145302; batch adversarial loss: 0.509692\n",
      "epoch 183; iter: 0; batch classifier loss: 0.107992; batch adversarial loss: 0.537651\n",
      "epoch 184; iter: 0; batch classifier loss: 0.170914; batch adversarial loss: 0.615345\n",
      "epoch 185; iter: 0; batch classifier loss: 0.097683; batch adversarial loss: 0.436233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.170431; batch adversarial loss: 0.601933\n",
      "epoch 187; iter: 0; batch classifier loss: 0.129291; batch adversarial loss: 0.495319\n",
      "epoch 188; iter: 0; batch classifier loss: 0.105366; batch adversarial loss: 0.532186\n",
      "epoch 189; iter: 0; batch classifier loss: 0.135998; batch adversarial loss: 0.555050\n",
      "epoch 190; iter: 0; batch classifier loss: 0.124971; batch adversarial loss: 0.532258\n",
      "epoch 191; iter: 0; batch classifier loss: 0.052487; batch adversarial loss: 0.399604\n",
      "epoch 192; iter: 0; batch classifier loss: 0.069970; batch adversarial loss: 0.455124\n",
      "epoch 193; iter: 0; batch classifier loss: 0.091682; batch adversarial loss: 0.444041\n",
      "epoch 194; iter: 0; batch classifier loss: 0.114016; batch adversarial loss: 0.541972\n",
      "epoch 195; iter: 0; batch classifier loss: 0.074270; batch adversarial loss: 0.489640\n",
      "epoch 196; iter: 0; batch classifier loss: 0.137132; batch adversarial loss: 0.450151\n",
      "epoch 197; iter: 0; batch classifier loss: 0.071754; batch adversarial loss: 0.424719\n",
      "epoch 198; iter: 0; batch classifier loss: 0.065087; batch adversarial loss: 0.386630\n",
      "epoch 199; iter: 0; batch classifier loss: 0.051126; batch adversarial loss: 0.492271\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699404; batch adversarial loss: 0.835148\n",
      "epoch 1; iter: 0; batch classifier loss: 0.384566; batch adversarial loss: 0.768973\n",
      "epoch 2; iter: 0; batch classifier loss: 0.349813; batch adversarial loss: 0.709289\n",
      "epoch 3; iter: 0; batch classifier loss: 0.422386; batch adversarial loss: 0.682055\n",
      "epoch 4; iter: 0; batch classifier loss: 0.347007; batch adversarial loss: 0.643738\n",
      "epoch 5; iter: 0; batch classifier loss: 0.336759; batch adversarial loss: 0.626732\n",
      "epoch 6; iter: 0; batch classifier loss: 0.329624; batch adversarial loss: 0.600855\n",
      "epoch 7; iter: 0; batch classifier loss: 0.388299; batch adversarial loss: 0.604557\n",
      "epoch 8; iter: 0; batch classifier loss: 0.258647; batch adversarial loss: 0.582928\n",
      "epoch 9; iter: 0; batch classifier loss: 0.255776; batch adversarial loss: 0.507145\n",
      "epoch 10; iter: 0; batch classifier loss: 0.239046; batch adversarial loss: 0.574719\n",
      "epoch 11; iter: 0; batch classifier loss: 0.291088; batch adversarial loss: 0.516891\n",
      "epoch 12; iter: 0; batch classifier loss: 0.306720; batch adversarial loss: 0.468075\n",
      "epoch 13; iter: 0; batch classifier loss: 0.255671; batch adversarial loss: 0.456305\n",
      "epoch 14; iter: 0; batch classifier loss: 0.155174; batch adversarial loss: 0.470778\n",
      "epoch 15; iter: 0; batch classifier loss: 0.219568; batch adversarial loss: 0.494877\n",
      "epoch 16; iter: 0; batch classifier loss: 0.273237; batch adversarial loss: 0.452665\n",
      "epoch 17; iter: 0; batch classifier loss: 0.197597; batch adversarial loss: 0.494955\n",
      "epoch 18; iter: 0; batch classifier loss: 0.232267; batch adversarial loss: 0.524889\n",
      "epoch 19; iter: 0; batch classifier loss: 0.177180; batch adversarial loss: 0.476435\n",
      "epoch 20; iter: 0; batch classifier loss: 0.193238; batch adversarial loss: 0.434702\n",
      "epoch 21; iter: 0; batch classifier loss: 0.208153; batch adversarial loss: 0.435861\n",
      "epoch 22; iter: 0; batch classifier loss: 0.287677; batch adversarial loss: 0.471779\n",
      "epoch 23; iter: 0; batch classifier loss: 0.207256; batch adversarial loss: 0.408817\n",
      "epoch 24; iter: 0; batch classifier loss: 0.185904; batch adversarial loss: 0.435859\n",
      "epoch 25; iter: 0; batch classifier loss: 0.218189; batch adversarial loss: 0.419743\n",
      "epoch 26; iter: 0; batch classifier loss: 0.221142; batch adversarial loss: 0.417141\n",
      "epoch 27; iter: 0; batch classifier loss: 0.272565; batch adversarial loss: 0.486314\n",
      "epoch 28; iter: 0; batch classifier loss: 0.204707; batch adversarial loss: 0.494650\n",
      "epoch 29; iter: 0; batch classifier loss: 0.228549; batch adversarial loss: 0.412026\n",
      "epoch 30; iter: 0; batch classifier loss: 0.249705; batch adversarial loss: 0.424770\n",
      "epoch 31; iter: 0; batch classifier loss: 0.162445; batch adversarial loss: 0.330289\n",
      "epoch 32; iter: 0; batch classifier loss: 0.202996; batch adversarial loss: 0.421611\n",
      "epoch 33; iter: 0; batch classifier loss: 0.156148; batch adversarial loss: 0.361770\n",
      "epoch 34; iter: 0; batch classifier loss: 0.134861; batch adversarial loss: 0.482458\n",
      "epoch 35; iter: 0; batch classifier loss: 0.167958; batch adversarial loss: 0.411924\n",
      "epoch 36; iter: 0; batch classifier loss: 0.101518; batch adversarial loss: 0.498814\n",
      "epoch 37; iter: 0; batch classifier loss: 0.201079; batch adversarial loss: 0.450274\n",
      "epoch 38; iter: 0; batch classifier loss: 0.119967; batch adversarial loss: 0.348437\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129897; batch adversarial loss: 0.417365\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095568; batch adversarial loss: 0.424358\n",
      "epoch 41; iter: 0; batch classifier loss: 0.121537; batch adversarial loss: 0.377600\n",
      "epoch 42; iter: 0; batch classifier loss: 0.145078; batch adversarial loss: 0.449551\n",
      "epoch 43; iter: 0; batch classifier loss: 0.111449; batch adversarial loss: 0.465554\n",
      "epoch 44; iter: 0; batch classifier loss: 0.147867; batch adversarial loss: 0.397692\n",
      "epoch 45; iter: 0; batch classifier loss: 0.109514; batch adversarial loss: 0.454805\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086792; batch adversarial loss: 0.385446\n",
      "epoch 47; iter: 0; batch classifier loss: 0.072401; batch adversarial loss: 0.423462\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129637; batch adversarial loss: 0.443425\n",
      "epoch 49; iter: 0; batch classifier loss: 0.120146; batch adversarial loss: 0.463367\n",
      "epoch 50; iter: 0; batch classifier loss: 0.099111; batch adversarial loss: 0.424849\n",
      "epoch 51; iter: 0; batch classifier loss: 0.102761; batch adversarial loss: 0.359787\n",
      "epoch 52; iter: 0; batch classifier loss: 0.117255; batch adversarial loss: 0.395178\n",
      "epoch 53; iter: 0; batch classifier loss: 0.071666; batch adversarial loss: 0.477089\n",
      "epoch 54; iter: 0; batch classifier loss: 0.071965; batch adversarial loss: 0.391533\n",
      "epoch 55; iter: 0; batch classifier loss: 0.094754; batch adversarial loss: 0.425924\n",
      "epoch 56; iter: 0; batch classifier loss: 0.130481; batch adversarial loss: 0.516003\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107388; batch adversarial loss: 0.556004\n",
      "epoch 58; iter: 0; batch classifier loss: 0.138666; batch adversarial loss: 0.451040\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102407; batch adversarial loss: 0.412192\n",
      "epoch 60; iter: 0; batch classifier loss: 0.096629; batch adversarial loss: 0.412294\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087117; batch adversarial loss: 0.433005\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093626; batch adversarial loss: 0.422852\n",
      "epoch 63; iter: 0; batch classifier loss: 0.105716; batch adversarial loss: 0.434870\n",
      "epoch 64; iter: 0; batch classifier loss: 0.092060; batch adversarial loss: 0.429404\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092858; batch adversarial loss: 0.364577\n",
      "epoch 66; iter: 0; batch classifier loss: 0.131923; batch adversarial loss: 0.436354\n",
      "epoch 67; iter: 0; batch classifier loss: 0.089941; batch adversarial loss: 0.392251\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060895; batch adversarial loss: 0.401653\n",
      "epoch 69; iter: 0; batch classifier loss: 0.045143; batch adversarial loss: 0.395837\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082801; batch adversarial loss: 0.442483\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082808; batch adversarial loss: 0.404970\n",
      "epoch 72; iter: 0; batch classifier loss: 0.069590; batch adversarial loss: 0.336753\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087676; batch adversarial loss: 0.398285\n",
      "epoch 74; iter: 0; batch classifier loss: 0.114556; batch adversarial loss: 0.416672\n",
      "epoch 75; iter: 0; batch classifier loss: 0.057751; batch adversarial loss: 0.344618\n",
      "epoch 76; iter: 0; batch classifier loss: 0.149275; batch adversarial loss: 0.414713\n",
      "epoch 77; iter: 0; batch classifier loss: 0.126270; batch adversarial loss: 0.462940\n",
      "epoch 78; iter: 0; batch classifier loss: 0.089968; batch adversarial loss: 0.477196\n",
      "epoch 79; iter: 0; batch classifier loss: 0.083765; batch adversarial loss: 0.426186\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067943; batch adversarial loss: 0.285572\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084937; batch adversarial loss: 0.416888\n",
      "epoch 82; iter: 0; batch classifier loss: 0.102033; batch adversarial loss: 0.467944\n",
      "epoch 83; iter: 0; batch classifier loss: 0.051167; batch adversarial loss: 0.465006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.048378; batch adversarial loss: 0.417943\n",
      "epoch 85; iter: 0; batch classifier loss: 0.114399; batch adversarial loss: 0.482217\n",
      "epoch 86; iter: 0; batch classifier loss: 0.082174; batch adversarial loss: 0.464372\n",
      "epoch 87; iter: 0; batch classifier loss: 0.090686; batch adversarial loss: 0.407375\n",
      "epoch 88; iter: 0; batch classifier loss: 0.090288; batch adversarial loss: 0.470300\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048453; batch adversarial loss: 0.421459\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064832; batch adversarial loss: 0.477765\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073314; batch adversarial loss: 0.445341\n",
      "epoch 92; iter: 0; batch classifier loss: 0.080074; batch adversarial loss: 0.424637\n",
      "epoch 93; iter: 0; batch classifier loss: 0.070036; batch adversarial loss: 0.385914\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064893; batch adversarial loss: 0.365185\n",
      "epoch 95; iter: 0; batch classifier loss: 0.090703; batch adversarial loss: 0.531965\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046854; batch adversarial loss: 0.438324\n",
      "epoch 97; iter: 0; batch classifier loss: 0.099951; batch adversarial loss: 0.445140\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062892; batch adversarial loss: 0.422289\n",
      "epoch 99; iter: 0; batch classifier loss: 0.072682; batch adversarial loss: 0.383282\n",
      "epoch 100; iter: 0; batch classifier loss: 0.072858; batch adversarial loss: 0.462251\n",
      "epoch 101; iter: 0; batch classifier loss: 0.069419; batch adversarial loss: 0.457791\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047081; batch adversarial loss: 0.422086\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053314; batch adversarial loss: 0.406873\n",
      "epoch 104; iter: 0; batch classifier loss: 0.072209; batch adversarial loss: 0.381847\n",
      "epoch 105; iter: 0; batch classifier loss: 0.090293; batch adversarial loss: 0.446911\n",
      "epoch 106; iter: 0; batch classifier loss: 0.078249; batch adversarial loss: 0.464324\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046954; batch adversarial loss: 0.389470\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065268; batch adversarial loss: 0.435235\n",
      "epoch 109; iter: 0; batch classifier loss: 0.068856; batch adversarial loss: 0.417581\n",
      "epoch 110; iter: 0; batch classifier loss: 0.070479; batch adversarial loss: 0.427841\n",
      "epoch 111; iter: 0; batch classifier loss: 0.072402; batch adversarial loss: 0.364888\n",
      "epoch 112; iter: 0; batch classifier loss: 0.089211; batch adversarial loss: 0.418625\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052616; batch adversarial loss: 0.510295\n",
      "epoch 114; iter: 0; batch classifier loss: 0.092109; batch adversarial loss: 0.434042\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065261; batch adversarial loss: 0.394653\n",
      "epoch 116; iter: 0; batch classifier loss: 0.087654; batch adversarial loss: 0.414772\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050502; batch adversarial loss: 0.368502\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037849; batch adversarial loss: 0.390022\n",
      "epoch 119; iter: 0; batch classifier loss: 0.062505; batch adversarial loss: 0.422892\n",
      "epoch 120; iter: 0; batch classifier loss: 0.067255; batch adversarial loss: 0.514726\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052827; batch adversarial loss: 0.397848\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039605; batch adversarial loss: 0.412923\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050762; batch adversarial loss: 0.419293\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029151; batch adversarial loss: 0.383032\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040147; batch adversarial loss: 0.395326\n",
      "epoch 126; iter: 0; batch classifier loss: 0.076894; batch adversarial loss: 0.479690\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045946; batch adversarial loss: 0.485417\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038263; batch adversarial loss: 0.451685\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026530; batch adversarial loss: 0.440816\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045093; batch adversarial loss: 0.436355\n",
      "epoch 131; iter: 0; batch classifier loss: 0.068306; batch adversarial loss: 0.544906\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015304; batch adversarial loss: 0.516626\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025355; batch adversarial loss: 0.492331\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018777; batch adversarial loss: 0.563718\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021235; batch adversarial loss: 0.526665\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039372; batch adversarial loss: 0.466124\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043278; batch adversarial loss: 0.512645\n",
      "epoch 138; iter: 0; batch classifier loss: 0.043304; batch adversarial loss: 0.474160\n",
      "epoch 139; iter: 0; batch classifier loss: 0.056484; batch adversarial loss: 0.582084\n",
      "epoch 140; iter: 0; batch classifier loss: 0.093498; batch adversarial loss: 0.568637\n",
      "epoch 141; iter: 0; batch classifier loss: 0.091651; batch adversarial loss: 0.542259\n",
      "epoch 142; iter: 0; batch classifier loss: 0.064194; batch adversarial loss: 0.530926\n",
      "epoch 143; iter: 0; batch classifier loss: 0.163576; batch adversarial loss: 0.705457\n",
      "epoch 144; iter: 0; batch classifier loss: 0.163661; batch adversarial loss: 0.699711\n",
      "epoch 145; iter: 0; batch classifier loss: 0.153225; batch adversarial loss: 0.618753\n",
      "epoch 146; iter: 0; batch classifier loss: 0.125085; batch adversarial loss: 0.646412\n",
      "epoch 147; iter: 0; batch classifier loss: 0.060559; batch adversarial loss: 0.496258\n",
      "epoch 148; iter: 0; batch classifier loss: 0.188827; batch adversarial loss: 0.637643\n",
      "epoch 149; iter: 0; batch classifier loss: 0.132628; batch adversarial loss: 0.663441\n",
      "epoch 150; iter: 0; batch classifier loss: 0.251971; batch adversarial loss: 0.815635\n",
      "epoch 151; iter: 0; batch classifier loss: 0.177455; batch adversarial loss: 0.693164\n",
      "epoch 152; iter: 0; batch classifier loss: 0.166515; batch adversarial loss: 0.654369\n",
      "epoch 153; iter: 0; batch classifier loss: 0.127160; batch adversarial loss: 0.483617\n",
      "epoch 154; iter: 0; batch classifier loss: 0.092482; batch adversarial loss: 0.549257\n",
      "epoch 155; iter: 0; batch classifier loss: 0.135459; batch adversarial loss: 0.591767\n",
      "epoch 156; iter: 0; batch classifier loss: 0.166293; batch adversarial loss: 0.587846\n",
      "epoch 157; iter: 0; batch classifier loss: 0.249403; batch adversarial loss: 0.690292\n",
      "epoch 158; iter: 0; batch classifier loss: 0.144601; batch adversarial loss: 0.624795\n",
      "epoch 159; iter: 0; batch classifier loss: 0.172472; batch adversarial loss: 0.594776\n",
      "epoch 160; iter: 0; batch classifier loss: 0.083960; batch adversarial loss: 0.434661\n",
      "epoch 161; iter: 0; batch classifier loss: 0.165817; batch adversarial loss: 0.645959\n",
      "epoch 162; iter: 0; batch classifier loss: 0.173534; batch adversarial loss: 0.634011\n",
      "epoch 163; iter: 0; batch classifier loss: 0.143209; batch adversarial loss: 0.638351\n",
      "epoch 164; iter: 0; batch classifier loss: 0.197017; batch adversarial loss: 0.552125\n",
      "epoch 165; iter: 0; batch classifier loss: 0.175346; batch adversarial loss: 0.673525\n",
      "epoch 166; iter: 0; batch classifier loss: 0.116933; batch adversarial loss: 0.492386\n",
      "epoch 167; iter: 0; batch classifier loss: 0.150444; batch adversarial loss: 0.524374\n",
      "epoch 168; iter: 0; batch classifier loss: 0.080594; batch adversarial loss: 0.358683\n",
      "epoch 169; iter: 0; batch classifier loss: 0.102957; batch adversarial loss: 0.427228\n",
      "epoch 170; iter: 0; batch classifier loss: 0.075478; batch adversarial loss: 0.398141\n",
      "epoch 171; iter: 0; batch classifier loss: 0.240314; batch adversarial loss: 0.598251\n",
      "epoch 172; iter: 0; batch classifier loss: 0.124084; batch adversarial loss: 0.502062\n",
      "epoch 173; iter: 0; batch classifier loss: 0.130220; batch adversarial loss: 0.509928\n",
      "epoch 174; iter: 0; batch classifier loss: 0.155697; batch adversarial loss: 0.621533\n",
      "epoch 175; iter: 0; batch classifier loss: 0.120810; batch adversarial loss: 0.487326\n",
      "epoch 176; iter: 0; batch classifier loss: 0.105067; batch adversarial loss: 0.460993\n",
      "epoch 177; iter: 0; batch classifier loss: 0.110224; batch adversarial loss: 0.415003\n",
      "epoch 178; iter: 0; batch classifier loss: 0.187633; batch adversarial loss: 0.609355\n",
      "epoch 179; iter: 0; batch classifier loss: 0.160924; batch adversarial loss: 0.562424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.119794; batch adversarial loss: 0.495942\n",
      "epoch 181; iter: 0; batch classifier loss: 0.102700; batch adversarial loss: 0.410894\n",
      "epoch 182; iter: 0; batch classifier loss: 0.121144; batch adversarial loss: 0.459300\n",
      "epoch 183; iter: 0; batch classifier loss: 0.083168; batch adversarial loss: 0.419742\n",
      "epoch 184; iter: 0; batch classifier loss: 0.109756; batch adversarial loss: 0.560738\n",
      "epoch 185; iter: 0; batch classifier loss: 0.072496; batch adversarial loss: 0.474014\n",
      "epoch 186; iter: 0; batch classifier loss: 0.087045; batch adversarial loss: 0.472574\n",
      "epoch 187; iter: 0; batch classifier loss: 0.090566; batch adversarial loss: 0.530097\n",
      "epoch 188; iter: 0; batch classifier loss: 0.053967; batch adversarial loss: 0.445960\n",
      "epoch 189; iter: 0; batch classifier loss: 0.055779; batch adversarial loss: 0.564861\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023971; batch adversarial loss: 0.469987\n",
      "epoch 191; iter: 0; batch classifier loss: 0.057070; batch adversarial loss: 0.445633\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021972; batch adversarial loss: 0.371163\n",
      "epoch 193; iter: 0; batch classifier loss: 0.052216; batch adversarial loss: 0.490014\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024109; batch adversarial loss: 0.443139\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037989; batch adversarial loss: 0.453474\n",
      "epoch 196; iter: 0; batch classifier loss: 0.071049; batch adversarial loss: 0.515027\n",
      "epoch 197; iter: 0; batch classifier loss: 0.036476; batch adversarial loss: 0.433268\n",
      "epoch 198; iter: 0; batch classifier loss: 0.049900; batch adversarial loss: 0.442967\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021038; batch adversarial loss: 0.475581\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684699; batch adversarial loss: 0.611669\n",
      "epoch 1; iter: 0; batch classifier loss: 0.398618; batch adversarial loss: 0.628310\n",
      "epoch 2; iter: 0; batch classifier loss: 0.421418; batch adversarial loss: 0.597759\n",
      "epoch 3; iter: 0; batch classifier loss: 0.442893; batch adversarial loss: 0.562318\n",
      "epoch 4; iter: 0; batch classifier loss: 0.449568; batch adversarial loss: 0.600486\n",
      "epoch 5; iter: 0; batch classifier loss: 0.397683; batch adversarial loss: 0.612535\n",
      "epoch 6; iter: 0; batch classifier loss: 0.378298; batch adversarial loss: 0.618410\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485513; batch adversarial loss: 0.550691\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568894; batch adversarial loss: 0.562671\n",
      "epoch 9; iter: 0; batch classifier loss: 0.417207; batch adversarial loss: 0.560202\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578852; batch adversarial loss: 0.526027\n",
      "epoch 11; iter: 0; batch classifier loss: 0.473015; batch adversarial loss: 0.503937\n",
      "epoch 12; iter: 0; batch classifier loss: 0.380014; batch adversarial loss: 0.492997\n",
      "epoch 13; iter: 0; batch classifier loss: 0.337341; batch adversarial loss: 0.510897\n",
      "epoch 14; iter: 0; batch classifier loss: 0.269080; batch adversarial loss: 0.461517\n",
      "epoch 15; iter: 0; batch classifier loss: 0.286509; batch adversarial loss: 0.491659\n",
      "epoch 16; iter: 0; batch classifier loss: 0.317609; batch adversarial loss: 0.478800\n",
      "epoch 17; iter: 0; batch classifier loss: 0.250611; batch adversarial loss: 0.459882\n",
      "epoch 18; iter: 0; batch classifier loss: 0.285374; batch adversarial loss: 0.505726\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277339; batch adversarial loss: 0.465948\n",
      "epoch 20; iter: 0; batch classifier loss: 0.299045; batch adversarial loss: 0.437648\n",
      "epoch 21; iter: 0; batch classifier loss: 0.245035; batch adversarial loss: 0.454172\n",
      "epoch 22; iter: 0; batch classifier loss: 0.225392; batch adversarial loss: 0.491749\n",
      "epoch 23; iter: 0; batch classifier loss: 0.238905; batch adversarial loss: 0.410944\n",
      "epoch 24; iter: 0; batch classifier loss: 0.248372; batch adversarial loss: 0.480445\n",
      "epoch 25; iter: 0; batch classifier loss: 0.252850; batch adversarial loss: 0.415397\n",
      "epoch 26; iter: 0; batch classifier loss: 0.251296; batch adversarial loss: 0.415178\n",
      "epoch 27; iter: 0; batch classifier loss: 0.227205; batch adversarial loss: 0.495819\n",
      "epoch 28; iter: 0; batch classifier loss: 0.201981; batch adversarial loss: 0.477446\n",
      "epoch 29; iter: 0; batch classifier loss: 0.237251; batch adversarial loss: 0.433163\n",
      "epoch 30; iter: 0; batch classifier loss: 0.203010; batch adversarial loss: 0.368079\n",
      "epoch 31; iter: 0; batch classifier loss: 0.203825; batch adversarial loss: 0.561628\n",
      "epoch 32; iter: 0; batch classifier loss: 0.222101; batch adversarial loss: 0.381222\n",
      "epoch 33; iter: 0; batch classifier loss: 0.227796; batch adversarial loss: 0.366595\n",
      "epoch 34; iter: 0; batch classifier loss: 0.178526; batch adversarial loss: 0.433420\n",
      "epoch 35; iter: 0; batch classifier loss: 0.202280; batch adversarial loss: 0.502096\n",
      "epoch 36; iter: 0; batch classifier loss: 0.220048; batch adversarial loss: 0.318140\n",
      "epoch 37; iter: 0; batch classifier loss: 0.209325; batch adversarial loss: 0.543725\n",
      "epoch 38; iter: 0; batch classifier loss: 0.178630; batch adversarial loss: 0.470169\n",
      "epoch 39; iter: 0; batch classifier loss: 0.210827; batch adversarial loss: 0.458469\n",
      "epoch 40; iter: 0; batch classifier loss: 0.184207; batch adversarial loss: 0.438998\n",
      "epoch 41; iter: 0; batch classifier loss: 0.244720; batch adversarial loss: 0.410053\n",
      "epoch 42; iter: 0; batch classifier loss: 0.190496; batch adversarial loss: 0.367740\n",
      "epoch 43; iter: 0; batch classifier loss: 0.163042; batch adversarial loss: 0.411334\n",
      "epoch 44; iter: 0; batch classifier loss: 0.225558; batch adversarial loss: 0.410214\n",
      "epoch 45; iter: 0; batch classifier loss: 0.203933; batch adversarial loss: 0.414874\n",
      "epoch 46; iter: 0; batch classifier loss: 0.193824; batch adversarial loss: 0.389001\n",
      "epoch 47; iter: 0; batch classifier loss: 0.171818; batch adversarial loss: 0.425092\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141079; batch adversarial loss: 0.444875\n",
      "epoch 49; iter: 0; batch classifier loss: 0.261804; batch adversarial loss: 0.413882\n",
      "epoch 50; iter: 0; batch classifier loss: 0.241935; batch adversarial loss: 0.390138\n",
      "epoch 51; iter: 0; batch classifier loss: 0.204584; batch adversarial loss: 0.475676\n",
      "epoch 52; iter: 0; batch classifier loss: 0.221632; batch adversarial loss: 0.383023\n",
      "epoch 53; iter: 0; batch classifier loss: 0.211583; batch adversarial loss: 0.447471\n",
      "epoch 54; iter: 0; batch classifier loss: 0.142758; batch adversarial loss: 0.481690\n",
      "epoch 55; iter: 0; batch classifier loss: 0.188840; batch adversarial loss: 0.470548\n",
      "epoch 56; iter: 0; batch classifier loss: 0.171938; batch adversarial loss: 0.446933\n",
      "epoch 57; iter: 0; batch classifier loss: 0.150968; batch adversarial loss: 0.434581\n",
      "epoch 58; iter: 0; batch classifier loss: 0.265471; batch adversarial loss: 0.483821\n",
      "epoch 59; iter: 0; batch classifier loss: 0.186277; batch adversarial loss: 0.483779\n",
      "epoch 60; iter: 0; batch classifier loss: 0.106117; batch adversarial loss: 0.458681\n",
      "epoch 61; iter: 0; batch classifier loss: 0.183802; batch adversarial loss: 0.409059\n",
      "epoch 62; iter: 0; batch classifier loss: 0.186510; batch adversarial loss: 0.409783\n",
      "epoch 63; iter: 0; batch classifier loss: 0.136569; batch adversarial loss: 0.510031\n",
      "epoch 64; iter: 0; batch classifier loss: 0.294610; batch adversarial loss: 0.345495\n",
      "epoch 65; iter: 0; batch classifier loss: 0.134860; batch adversarial loss: 0.446460\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093706; batch adversarial loss: 0.432797\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095728; batch adversarial loss: 0.431176\n",
      "epoch 68; iter: 0; batch classifier loss: 0.065294; batch adversarial loss: 0.482870\n",
      "epoch 69; iter: 0; batch classifier loss: 0.091050; batch adversarial loss: 0.420932\n",
      "epoch 70; iter: 0; batch classifier loss: 0.116467; batch adversarial loss: 0.442195\n",
      "epoch 71; iter: 0; batch classifier loss: 0.141836; batch adversarial loss: 0.467411\n",
      "epoch 72; iter: 0; batch classifier loss: 0.104001; batch adversarial loss: 0.537588\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068852; batch adversarial loss: 0.526452\n",
      "epoch 74; iter: 0; batch classifier loss: 0.110643; batch adversarial loss: 0.406505\n",
      "epoch 75; iter: 0; batch classifier loss: 0.157264; batch adversarial loss: 0.442778\n",
      "epoch 76; iter: 0; batch classifier loss: 0.111634; batch adversarial loss: 0.448964\n",
      "epoch 77; iter: 0; batch classifier loss: 0.114557; batch adversarial loss: 0.534220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.117287; batch adversarial loss: 0.394728\n",
      "epoch 79; iter: 0; batch classifier loss: 0.114925; batch adversarial loss: 0.532043\n",
      "epoch 80; iter: 0; batch classifier loss: 0.119301; batch adversarial loss: 0.518568\n",
      "epoch 81; iter: 0; batch classifier loss: 0.107614; batch adversarial loss: 0.531749\n",
      "epoch 82; iter: 0; batch classifier loss: 0.159978; batch adversarial loss: 0.499441\n",
      "epoch 83; iter: 0; batch classifier loss: 0.111907; batch adversarial loss: 0.493826\n",
      "epoch 84; iter: 0; batch classifier loss: 0.114141; batch adversarial loss: 0.316352\n",
      "epoch 85; iter: 0; batch classifier loss: 0.148871; batch adversarial loss: 0.481307\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081233; batch adversarial loss: 0.460796\n",
      "epoch 87; iter: 0; batch classifier loss: 0.094782; batch adversarial loss: 0.417750\n",
      "epoch 88; iter: 0; batch classifier loss: 0.096816; batch adversarial loss: 0.572183\n",
      "epoch 89; iter: 0; batch classifier loss: 0.175782; batch adversarial loss: 0.448531\n",
      "epoch 90; iter: 0; batch classifier loss: 0.127492; batch adversarial loss: 0.519847\n",
      "epoch 91; iter: 0; batch classifier loss: 0.085312; batch adversarial loss: 0.415809\n",
      "epoch 92; iter: 0; batch classifier loss: 0.110818; batch adversarial loss: 0.366553\n",
      "epoch 93; iter: 0; batch classifier loss: 0.138898; batch adversarial loss: 0.362109\n",
      "epoch 94; iter: 0; batch classifier loss: 0.102355; batch adversarial loss: 0.466342\n",
      "epoch 95; iter: 0; batch classifier loss: 0.093882; batch adversarial loss: 0.484365\n",
      "epoch 96; iter: 0; batch classifier loss: 0.111580; batch adversarial loss: 0.443970\n",
      "epoch 97; iter: 0; batch classifier loss: 0.089335; batch adversarial loss: 0.456001\n",
      "epoch 98; iter: 0; batch classifier loss: 0.141382; batch adversarial loss: 0.450700\n",
      "epoch 99; iter: 0; batch classifier loss: 0.138241; batch adversarial loss: 0.521484\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065711; batch adversarial loss: 0.404004\n",
      "epoch 101; iter: 0; batch classifier loss: 0.066041; batch adversarial loss: 0.477416\n",
      "epoch 102; iter: 0; batch classifier loss: 0.114269; batch adversarial loss: 0.410840\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060204; batch adversarial loss: 0.394073\n",
      "epoch 104; iter: 0; batch classifier loss: 0.110970; batch adversarial loss: 0.439974\n",
      "epoch 105; iter: 0; batch classifier loss: 0.156934; batch adversarial loss: 0.375080\n",
      "epoch 106; iter: 0; batch classifier loss: 0.126482; batch adversarial loss: 0.345874\n",
      "epoch 107; iter: 0; batch classifier loss: 0.083852; batch adversarial loss: 0.420701\n",
      "epoch 108; iter: 0; batch classifier loss: 0.072948; batch adversarial loss: 0.486862\n",
      "epoch 109; iter: 0; batch classifier loss: 0.082114; batch adversarial loss: 0.428714\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042518; batch adversarial loss: 0.489167\n",
      "epoch 111; iter: 0; batch classifier loss: 0.068103; batch adversarial loss: 0.438239\n",
      "epoch 112; iter: 0; batch classifier loss: 0.078107; batch adversarial loss: 0.436788\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058033; batch adversarial loss: 0.474513\n",
      "epoch 114; iter: 0; batch classifier loss: 0.069588; batch adversarial loss: 0.443110\n",
      "epoch 115; iter: 0; batch classifier loss: 0.085785; batch adversarial loss: 0.401571\n",
      "epoch 116; iter: 0; batch classifier loss: 0.072875; batch adversarial loss: 0.431203\n",
      "epoch 117; iter: 0; batch classifier loss: 0.082233; batch adversarial loss: 0.411660\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045191; batch adversarial loss: 0.471776\n",
      "epoch 119; iter: 0; batch classifier loss: 0.085881; batch adversarial loss: 0.457314\n",
      "epoch 120; iter: 0; batch classifier loss: 0.082959; batch adversarial loss: 0.446369\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038551; batch adversarial loss: 0.431297\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062122; batch adversarial loss: 0.401640\n",
      "epoch 123; iter: 0; batch classifier loss: 0.080484; batch adversarial loss: 0.475734\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067654; batch adversarial loss: 0.359422\n",
      "epoch 125; iter: 0; batch classifier loss: 0.089158; batch adversarial loss: 0.438785\n",
      "epoch 126; iter: 0; batch classifier loss: 0.074057; batch adversarial loss: 0.469907\n",
      "epoch 127; iter: 0; batch classifier loss: 0.070017; batch adversarial loss: 0.494024\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024193; batch adversarial loss: 0.534438\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032668; batch adversarial loss: 0.401902\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029426; batch adversarial loss: 0.582165\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051375; batch adversarial loss: 0.375681\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034604; batch adversarial loss: 0.405246\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014352; batch adversarial loss: 0.441839\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034310; batch adversarial loss: 0.494733\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057989; batch adversarial loss: 0.379071\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035211; batch adversarial loss: 0.469153\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035629; batch adversarial loss: 0.359811\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027773; batch adversarial loss: 0.497637\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020943; batch adversarial loss: 0.396887\n",
      "epoch 140; iter: 0; batch classifier loss: 0.128726; batch adversarial loss: 0.352945\n",
      "epoch 141; iter: 0; batch classifier loss: 0.073854; batch adversarial loss: 0.477963\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027086; batch adversarial loss: 0.368723\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024509; batch adversarial loss: 0.429565\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039570; batch adversarial loss: 0.420379\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035122; batch adversarial loss: 0.388740\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023937; batch adversarial loss: 0.530936\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042423; batch adversarial loss: 0.404657\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042712; batch adversarial loss: 0.398223\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017270; batch adversarial loss: 0.441218\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041610; batch adversarial loss: 0.379576\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038249; batch adversarial loss: 0.454464\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028929; batch adversarial loss: 0.522409\n",
      "epoch 153; iter: 0; batch classifier loss: 0.047429; batch adversarial loss: 0.444970\n",
      "epoch 154; iter: 0; batch classifier loss: 0.056416; batch adversarial loss: 0.367873\n",
      "epoch 155; iter: 0; batch classifier loss: 0.043496; batch adversarial loss: 0.430482\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025897; batch adversarial loss: 0.601251\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046036; batch adversarial loss: 0.419215\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034966; batch adversarial loss: 0.486496\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015216; batch adversarial loss: 0.447675\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025535; batch adversarial loss: 0.465166\n",
      "epoch 161; iter: 0; batch classifier loss: 0.071551; batch adversarial loss: 0.399805\n",
      "epoch 162; iter: 0; batch classifier loss: 0.035374; batch adversarial loss: 0.544086\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027366; batch adversarial loss: 0.448632\n",
      "epoch 164; iter: 0; batch classifier loss: 0.045468; batch adversarial loss: 0.550331\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016090; batch adversarial loss: 0.411974\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022422; batch adversarial loss: 0.447169\n",
      "epoch 167; iter: 0; batch classifier loss: 0.045973; batch adversarial loss: 0.460989\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013820; batch adversarial loss: 0.521178\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029569; batch adversarial loss: 0.430911\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033425; batch adversarial loss: 0.407464\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038776; batch adversarial loss: 0.464032\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024856; batch adversarial loss: 0.428622\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042174; batch adversarial loss: 0.432436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.012286; batch adversarial loss: 0.429879\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026379; batch adversarial loss: 0.431853\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017928; batch adversarial loss: 0.396756\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046589; batch adversarial loss: 0.436777\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028100; batch adversarial loss: 0.389478\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033879; batch adversarial loss: 0.352567\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035542; batch adversarial loss: 0.414068\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030546; batch adversarial loss: 0.414230\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012262; batch adversarial loss: 0.447201\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025037; batch adversarial loss: 0.448597\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007276; batch adversarial loss: 0.497024\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014539; batch adversarial loss: 0.435247\n",
      "epoch 186; iter: 0; batch classifier loss: 0.043290; batch adversarial loss: 0.468738\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033786; batch adversarial loss: 0.433165\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011197; batch adversarial loss: 0.370945\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023685; batch adversarial loss: 0.498100\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034731; batch adversarial loss: 0.426418\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031293; batch adversarial loss: 0.537356\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009468; batch adversarial loss: 0.402647\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021034; batch adversarial loss: 0.478272\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009249; batch adversarial loss: 0.500017\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022120; batch adversarial loss: 0.352166\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012072; batch adversarial loss: 0.419811\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022262; batch adversarial loss: 0.535497\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023440; batch adversarial loss: 0.418074\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025608; batch adversarial loss: 0.468039\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697199; batch adversarial loss: 0.691961\n",
      "epoch 1; iter: 0; batch classifier loss: 0.603477; batch adversarial loss: 0.660105\n",
      "epoch 2; iter: 0; batch classifier loss: 0.442422; batch adversarial loss: 0.644980\n",
      "epoch 3; iter: 0; batch classifier loss: 0.442114; batch adversarial loss: 0.629998\n",
      "epoch 4; iter: 0; batch classifier loss: 0.442410; batch adversarial loss: 0.598478\n",
      "epoch 5; iter: 0; batch classifier loss: 0.464467; batch adversarial loss: 0.603966\n",
      "epoch 6; iter: 0; batch classifier loss: 0.445707; batch adversarial loss: 0.605778\n",
      "epoch 7; iter: 0; batch classifier loss: 0.435675; batch adversarial loss: 0.573343\n",
      "epoch 8; iter: 0; batch classifier loss: 0.430381; batch adversarial loss: 0.561822\n",
      "epoch 9; iter: 0; batch classifier loss: 0.511797; batch adversarial loss: 0.546373\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484055; batch adversarial loss: 0.530850\n",
      "epoch 11; iter: 0; batch classifier loss: 0.369692; batch adversarial loss: 0.529776\n",
      "epoch 12; iter: 0; batch classifier loss: 0.360271; batch adversarial loss: 0.555665\n",
      "epoch 13; iter: 0; batch classifier loss: 0.347384; batch adversarial loss: 0.507659\n",
      "epoch 14; iter: 0; batch classifier loss: 0.322553; batch adversarial loss: 0.466745\n",
      "epoch 15; iter: 0; batch classifier loss: 0.345272; batch adversarial loss: 0.527017\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296240; batch adversarial loss: 0.488160\n",
      "epoch 17; iter: 0; batch classifier loss: 0.297077; batch adversarial loss: 0.488839\n",
      "epoch 18; iter: 0; batch classifier loss: 0.303397; batch adversarial loss: 0.502065\n",
      "epoch 19; iter: 0; batch classifier loss: 0.248115; batch adversarial loss: 0.486664\n",
      "epoch 20; iter: 0; batch classifier loss: 0.244000; batch adversarial loss: 0.523801\n",
      "epoch 21; iter: 0; batch classifier loss: 0.249471; batch adversarial loss: 0.537666\n",
      "epoch 22; iter: 0; batch classifier loss: 0.201979; batch adversarial loss: 0.458865\n",
      "epoch 23; iter: 0; batch classifier loss: 0.276770; batch adversarial loss: 0.475696\n",
      "epoch 24; iter: 0; batch classifier loss: 0.266606; batch adversarial loss: 0.464607\n",
      "epoch 25; iter: 0; batch classifier loss: 0.311458; batch adversarial loss: 0.417686\n",
      "epoch 26; iter: 0; batch classifier loss: 0.318317; batch adversarial loss: 0.464299\n",
      "epoch 27; iter: 0; batch classifier loss: 0.240160; batch adversarial loss: 0.489146\n",
      "epoch 28; iter: 0; batch classifier loss: 0.287936; batch adversarial loss: 0.466226\n",
      "epoch 29; iter: 0; batch classifier loss: 0.285857; batch adversarial loss: 0.487672\n",
      "epoch 30; iter: 0; batch classifier loss: 0.231159; batch adversarial loss: 0.444174\n",
      "epoch 31; iter: 0; batch classifier loss: 0.242081; batch adversarial loss: 0.479113\n",
      "epoch 32; iter: 0; batch classifier loss: 0.229648; batch adversarial loss: 0.440039\n",
      "epoch 33; iter: 0; batch classifier loss: 0.165998; batch adversarial loss: 0.485721\n",
      "epoch 34; iter: 0; batch classifier loss: 0.262028; batch adversarial loss: 0.443010\n",
      "epoch 35; iter: 0; batch classifier loss: 0.188863; batch adversarial loss: 0.540770\n",
      "epoch 36; iter: 0; batch classifier loss: 0.224605; batch adversarial loss: 0.456334\n",
      "epoch 37; iter: 0; batch classifier loss: 0.238543; batch adversarial loss: 0.472133\n",
      "epoch 38; iter: 0; batch classifier loss: 0.271150; batch adversarial loss: 0.478780\n",
      "epoch 39; iter: 0; batch classifier loss: 0.229917; batch adversarial loss: 0.529734\n",
      "epoch 40; iter: 0; batch classifier loss: 0.236689; batch adversarial loss: 0.494034\n",
      "epoch 41; iter: 0; batch classifier loss: 0.241009; batch adversarial loss: 0.379565\n",
      "epoch 42; iter: 0; batch classifier loss: 0.246630; batch adversarial loss: 0.449643\n",
      "epoch 43; iter: 0; batch classifier loss: 0.241686; batch adversarial loss: 0.506626\n",
      "epoch 44; iter: 0; batch classifier loss: 0.232196; batch adversarial loss: 0.469538\n",
      "epoch 45; iter: 0; batch classifier loss: 0.266703; batch adversarial loss: 0.472365\n",
      "epoch 46; iter: 0; batch classifier loss: 0.275808; batch adversarial loss: 0.471226\n",
      "epoch 47; iter: 0; batch classifier loss: 0.187503; batch adversarial loss: 0.424703\n",
      "epoch 48; iter: 0; batch classifier loss: 0.220576; batch adversarial loss: 0.539969\n",
      "epoch 49; iter: 0; batch classifier loss: 0.123807; batch adversarial loss: 0.539556\n",
      "epoch 50; iter: 0; batch classifier loss: 0.132634; batch adversarial loss: 0.468389\n",
      "epoch 51; iter: 0; batch classifier loss: 0.072021; batch adversarial loss: 0.415601\n",
      "epoch 52; iter: 0; batch classifier loss: 0.084535; batch adversarial loss: 0.390372\n",
      "epoch 53; iter: 0; batch classifier loss: 0.056483; batch adversarial loss: 0.518943\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102792; batch adversarial loss: 0.475092\n",
      "epoch 55; iter: 0; batch classifier loss: 0.108602; batch adversarial loss: 0.407505\n",
      "epoch 56; iter: 0; batch classifier loss: 0.059076; batch adversarial loss: 0.467947\n",
      "epoch 57; iter: 0; batch classifier loss: 0.085489; batch adversarial loss: 0.425985\n",
      "epoch 58; iter: 0; batch classifier loss: 0.082395; batch adversarial loss: 0.474705\n",
      "epoch 59; iter: 0; batch classifier loss: 0.078645; batch adversarial loss: 0.477501\n",
      "epoch 60; iter: 0; batch classifier loss: 0.078135; batch adversarial loss: 0.578418\n",
      "epoch 61; iter: 0; batch classifier loss: 0.096500; batch adversarial loss: 0.457176\n",
      "epoch 62; iter: 0; batch classifier loss: 0.073761; batch adversarial loss: 0.424574\n",
      "epoch 63; iter: 0; batch classifier loss: 0.084597; batch adversarial loss: 0.453465\n",
      "epoch 64; iter: 0; batch classifier loss: 0.104985; batch adversarial loss: 0.404114\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088465; batch adversarial loss: 0.508285\n",
      "epoch 66; iter: 0; batch classifier loss: 0.105872; batch adversarial loss: 0.447388\n",
      "epoch 67; iter: 0; batch classifier loss: 0.053254; batch adversarial loss: 0.372725\n",
      "epoch 68; iter: 0; batch classifier loss: 0.088882; batch adversarial loss: 0.365710\n",
      "epoch 69; iter: 0; batch classifier loss: 0.079415; batch adversarial loss: 0.428585\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091577; batch adversarial loss: 0.434142\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097906; batch adversarial loss: 0.381318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.048645; batch adversarial loss: 0.409027\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075966; batch adversarial loss: 0.408995\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066341; batch adversarial loss: 0.432311\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066180; batch adversarial loss: 0.469525\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058912; batch adversarial loss: 0.443782\n",
      "epoch 77; iter: 0; batch classifier loss: 0.130968; batch adversarial loss: 0.461726\n",
      "epoch 78; iter: 0; batch classifier loss: 0.086063; batch adversarial loss: 0.372102\n",
      "epoch 79; iter: 0; batch classifier loss: 0.092876; batch adversarial loss: 0.408476\n",
      "epoch 80; iter: 0; batch classifier loss: 0.055305; batch adversarial loss: 0.490367\n",
      "epoch 81; iter: 0; batch classifier loss: 0.054774; batch adversarial loss: 0.477397\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071912; batch adversarial loss: 0.461801\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064097; batch adversarial loss: 0.541453\n",
      "epoch 84; iter: 0; batch classifier loss: 0.084661; batch adversarial loss: 0.419939\n",
      "epoch 85; iter: 0; batch classifier loss: 0.072375; batch adversarial loss: 0.422353\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074062; batch adversarial loss: 0.460656\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054550; batch adversarial loss: 0.477414\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069096; batch adversarial loss: 0.483654\n",
      "epoch 89; iter: 0; batch classifier loss: 0.076962; batch adversarial loss: 0.460842\n",
      "epoch 90; iter: 0; batch classifier loss: 0.032206; batch adversarial loss: 0.395426\n",
      "epoch 91; iter: 0; batch classifier loss: 0.047732; batch adversarial loss: 0.414805\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051194; batch adversarial loss: 0.490438\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072461; batch adversarial loss: 0.442757\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043936; batch adversarial loss: 0.490510\n",
      "epoch 95; iter: 0; batch classifier loss: 0.086743; batch adversarial loss: 0.432308\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082719; batch adversarial loss: 0.437063\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063483; batch adversarial loss: 0.452432\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059137; batch adversarial loss: 0.381272\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061178; batch adversarial loss: 0.464425\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037977; batch adversarial loss: 0.542655\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043486; batch adversarial loss: 0.400183\n",
      "epoch 102; iter: 0; batch classifier loss: 0.075899; batch adversarial loss: 0.494991\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057318; batch adversarial loss: 0.521395\n",
      "epoch 104; iter: 0; batch classifier loss: 0.084047; batch adversarial loss: 0.440976\n",
      "epoch 105; iter: 0; batch classifier loss: 0.081310; batch adversarial loss: 0.364078\n",
      "epoch 106; iter: 0; batch classifier loss: 0.072080; batch adversarial loss: 0.338783\n",
      "epoch 107; iter: 0; batch classifier loss: 0.076972; batch adversarial loss: 0.389280\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046141; batch adversarial loss: 0.421140\n",
      "epoch 109; iter: 0; batch classifier loss: 0.063828; batch adversarial loss: 0.426532\n",
      "epoch 110; iter: 0; batch classifier loss: 0.055570; batch adversarial loss: 0.481715\n",
      "epoch 111; iter: 0; batch classifier loss: 0.081783; batch adversarial loss: 0.382070\n",
      "epoch 112; iter: 0; batch classifier loss: 0.094728; batch adversarial loss: 0.502777\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059101; batch adversarial loss: 0.340573\n",
      "epoch 114; iter: 0; batch classifier loss: 0.065807; batch adversarial loss: 0.409764\n",
      "epoch 115; iter: 0; batch classifier loss: 0.066418; batch adversarial loss: 0.474026\n",
      "epoch 116; iter: 0; batch classifier loss: 0.080244; batch adversarial loss: 0.373230\n",
      "epoch 117; iter: 0; batch classifier loss: 0.084468; batch adversarial loss: 0.474988\n",
      "epoch 118; iter: 0; batch classifier loss: 0.062082; batch adversarial loss: 0.353031\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045051; batch adversarial loss: 0.454173\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038218; batch adversarial loss: 0.382614\n",
      "epoch 121; iter: 0; batch classifier loss: 0.078541; batch adversarial loss: 0.419715\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033767; batch adversarial loss: 0.477931\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051006; batch adversarial loss: 0.488119\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048460; batch adversarial loss: 0.388273\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062293; batch adversarial loss: 0.360135\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026585; batch adversarial loss: 0.373523\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043139; batch adversarial loss: 0.388500\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051349; batch adversarial loss: 0.475171\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043635; batch adversarial loss: 0.432789\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031155; batch adversarial loss: 0.339578\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044839; batch adversarial loss: 0.455661\n",
      "epoch 132; iter: 0; batch classifier loss: 0.073659; batch adversarial loss: 0.329966\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032597; batch adversarial loss: 0.512128\n",
      "epoch 134; iter: 0; batch classifier loss: 0.080929; batch adversarial loss: 0.383304\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037901; batch adversarial loss: 0.445081\n",
      "epoch 136; iter: 0; batch classifier loss: 0.048254; batch adversarial loss: 0.495605\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032557; batch adversarial loss: 0.432571\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027371; batch adversarial loss: 0.486177\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031109; batch adversarial loss: 0.472879\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050801; batch adversarial loss: 0.432539\n",
      "epoch 141; iter: 0; batch classifier loss: 0.058679; batch adversarial loss: 0.502798\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034301; batch adversarial loss: 0.399719\n",
      "epoch 143; iter: 0; batch classifier loss: 0.045497; batch adversarial loss: 0.461312\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023758; batch adversarial loss: 0.372508\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023349; batch adversarial loss: 0.464329\n",
      "epoch 146; iter: 0; batch classifier loss: 0.058391; batch adversarial loss: 0.415425\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031602; batch adversarial loss: 0.459498\n",
      "epoch 148; iter: 0; batch classifier loss: 0.059166; batch adversarial loss: 0.324548\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033950; batch adversarial loss: 0.458906\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026698; batch adversarial loss: 0.371040\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030997; batch adversarial loss: 0.512643\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034714; batch adversarial loss: 0.414632\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020912; batch adversarial loss: 0.453246\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023840; batch adversarial loss: 0.464773\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025421; batch adversarial loss: 0.501176\n",
      "epoch 156; iter: 0; batch classifier loss: 0.049551; batch adversarial loss: 0.388405\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041550; batch adversarial loss: 0.372179\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022282; batch adversarial loss: 0.479115\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016941; batch adversarial loss: 0.474760\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036295; batch adversarial loss: 0.467563\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021275; batch adversarial loss: 0.402169\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039728; batch adversarial loss: 0.396347\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018743; batch adversarial loss: 0.442882\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023140; batch adversarial loss: 0.432160\n",
      "epoch 165; iter: 0; batch classifier loss: 0.052918; batch adversarial loss: 0.461753\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016249; batch adversarial loss: 0.522764\n",
      "epoch 167; iter: 0; batch classifier loss: 0.045275; batch adversarial loss: 0.457131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.026583; batch adversarial loss: 0.407404\n",
      "epoch 169; iter: 0; batch classifier loss: 0.041124; batch adversarial loss: 0.495564\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030537; batch adversarial loss: 0.397679\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025039; batch adversarial loss: 0.532650\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022245; batch adversarial loss: 0.473181\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025673; batch adversarial loss: 0.467298\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033732; batch adversarial loss: 0.467922\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013599; batch adversarial loss: 0.507587\n",
      "epoch 176; iter: 0; batch classifier loss: 0.053013; batch adversarial loss: 0.465997\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027334; batch adversarial loss: 0.461107\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013514; batch adversarial loss: 0.357010\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020577; batch adversarial loss: 0.361970\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020530; batch adversarial loss: 0.462411\n",
      "epoch 181; iter: 0; batch classifier loss: 0.053490; batch adversarial loss: 0.469515\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018530; batch adversarial loss: 0.452921\n",
      "epoch 183; iter: 0; batch classifier loss: 0.035645; batch adversarial loss: 0.460859\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019221; batch adversarial loss: 0.421385\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019723; batch adversarial loss: 0.465866\n",
      "epoch 186; iter: 0; batch classifier loss: 0.071931; batch adversarial loss: 0.684490\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016506; batch adversarial loss: 0.458781\n",
      "epoch 188; iter: 0; batch classifier loss: 0.037384; batch adversarial loss: 0.499824\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028816; batch adversarial loss: 0.549308\n",
      "epoch 190; iter: 0; batch classifier loss: 0.088662; batch adversarial loss: 0.547083\n",
      "epoch 191; iter: 0; batch classifier loss: 0.068008; batch adversarial loss: 0.600713\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036497; batch adversarial loss: 0.459451\n",
      "epoch 193; iter: 0; batch classifier loss: 0.074938; batch adversarial loss: 0.531771\n",
      "epoch 194; iter: 0; batch classifier loss: 0.100013; batch adversarial loss: 0.684116\n",
      "epoch 195; iter: 0; batch classifier loss: 0.078359; batch adversarial loss: 0.495582\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029836; batch adversarial loss: 0.412866\n",
      "epoch 197; iter: 0; batch classifier loss: 0.058223; batch adversarial loss: 0.543092\n",
      "epoch 198; iter: 0; batch classifier loss: 0.054872; batch adversarial loss: 0.498764\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014146; batch adversarial loss: 0.516638\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712317; batch adversarial loss: 0.851159\n",
      "epoch 1; iter: 0; batch classifier loss: 0.668123; batch adversarial loss: 0.824073\n",
      "epoch 2; iter: 0; batch classifier loss: 0.799521; batch adversarial loss: 0.811068\n",
      "epoch 3; iter: 0; batch classifier loss: 0.818265; batch adversarial loss: 0.742350\n",
      "epoch 4; iter: 0; batch classifier loss: 0.671808; batch adversarial loss: 0.679422\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495460; batch adversarial loss: 0.635842\n",
      "epoch 6; iter: 0; batch classifier loss: 0.414472; batch adversarial loss: 0.607131\n",
      "epoch 7; iter: 0; batch classifier loss: 0.328113; batch adversarial loss: 0.559226\n",
      "epoch 8; iter: 0; batch classifier loss: 0.261110; batch adversarial loss: 0.556273\n",
      "epoch 9; iter: 0; batch classifier loss: 0.315272; batch adversarial loss: 0.543892\n",
      "epoch 10; iter: 0; batch classifier loss: 0.319294; batch adversarial loss: 0.570284\n",
      "epoch 11; iter: 0; batch classifier loss: 0.309463; batch adversarial loss: 0.610936\n",
      "epoch 12; iter: 0; batch classifier loss: 0.306945; batch adversarial loss: 0.486186\n",
      "epoch 13; iter: 0; batch classifier loss: 0.274536; batch adversarial loss: 0.522727\n",
      "epoch 14; iter: 0; batch classifier loss: 0.285755; batch adversarial loss: 0.491578\n",
      "epoch 15; iter: 0; batch classifier loss: 0.267999; batch adversarial loss: 0.504641\n",
      "epoch 16; iter: 0; batch classifier loss: 0.257565; batch adversarial loss: 0.545695\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241187; batch adversarial loss: 0.481550\n",
      "epoch 18; iter: 0; batch classifier loss: 0.228507; batch adversarial loss: 0.515600\n",
      "epoch 19; iter: 0; batch classifier loss: 0.227427; batch adversarial loss: 0.623947\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204892; batch adversarial loss: 0.514779\n",
      "epoch 21; iter: 0; batch classifier loss: 0.251854; batch adversarial loss: 0.498209\n",
      "epoch 22; iter: 0; batch classifier loss: 0.218907; batch adversarial loss: 0.492311\n",
      "epoch 23; iter: 0; batch classifier loss: 0.256335; batch adversarial loss: 0.477133\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246976; batch adversarial loss: 0.481616\n",
      "epoch 25; iter: 0; batch classifier loss: 0.199219; batch adversarial loss: 0.512712\n",
      "epoch 26; iter: 0; batch classifier loss: 0.201541; batch adversarial loss: 0.484665\n",
      "epoch 27; iter: 0; batch classifier loss: 0.191439; batch adversarial loss: 0.456673\n",
      "epoch 28; iter: 0; batch classifier loss: 0.162402; batch adversarial loss: 0.397643\n",
      "epoch 29; iter: 0; batch classifier loss: 0.165522; batch adversarial loss: 0.508466\n",
      "epoch 30; iter: 0; batch classifier loss: 0.259748; batch adversarial loss: 0.424800\n",
      "epoch 31; iter: 0; batch classifier loss: 0.168838; batch adversarial loss: 0.436493\n",
      "epoch 32; iter: 0; batch classifier loss: 0.201461; batch adversarial loss: 0.464948\n",
      "epoch 33; iter: 0; batch classifier loss: 0.139419; batch adversarial loss: 0.501283\n",
      "epoch 34; iter: 0; batch classifier loss: 0.168000; batch adversarial loss: 0.464909\n",
      "epoch 35; iter: 0; batch classifier loss: 0.157462; batch adversarial loss: 0.595099\n",
      "epoch 36; iter: 0; batch classifier loss: 0.122481; batch adversarial loss: 0.458769\n",
      "epoch 37; iter: 0; batch classifier loss: 0.150979; batch adversarial loss: 0.397553\n",
      "epoch 38; iter: 0; batch classifier loss: 0.153122; batch adversarial loss: 0.467929\n",
      "epoch 39; iter: 0; batch classifier loss: 0.072318; batch adversarial loss: 0.597997\n",
      "epoch 40; iter: 0; batch classifier loss: 0.182389; batch adversarial loss: 0.460442\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142119; batch adversarial loss: 0.491336\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116563; batch adversarial loss: 0.491681\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104640; batch adversarial loss: 0.509738\n",
      "epoch 44; iter: 0; batch classifier loss: 0.153805; batch adversarial loss: 0.471427\n",
      "epoch 45; iter: 0; batch classifier loss: 0.173310; batch adversarial loss: 0.415990\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114179; batch adversarial loss: 0.464032\n",
      "epoch 47; iter: 0; batch classifier loss: 0.159601; batch adversarial loss: 0.502053\n",
      "epoch 48; iter: 0; batch classifier loss: 0.164703; batch adversarial loss: 0.450334\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114807; batch adversarial loss: 0.531301\n",
      "epoch 50; iter: 0; batch classifier loss: 0.107301; batch adversarial loss: 0.467753\n",
      "epoch 51; iter: 0; batch classifier loss: 0.150230; batch adversarial loss: 0.491518\n",
      "epoch 52; iter: 0; batch classifier loss: 0.106030; batch adversarial loss: 0.499002\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076171; batch adversarial loss: 0.524736\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129096; batch adversarial loss: 0.456277\n",
      "epoch 55; iter: 0; batch classifier loss: 0.111126; batch adversarial loss: 0.443723\n",
      "epoch 56; iter: 0; batch classifier loss: 0.105629; batch adversarial loss: 0.428944\n",
      "epoch 57; iter: 0; batch classifier loss: 0.097896; batch adversarial loss: 0.477935\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101662; batch adversarial loss: 0.425927\n",
      "epoch 59; iter: 0; batch classifier loss: 0.116933; batch adversarial loss: 0.442365\n",
      "epoch 60; iter: 0; batch classifier loss: 0.090207; batch adversarial loss: 0.451156\n",
      "epoch 61; iter: 0; batch classifier loss: 0.092450; batch adversarial loss: 0.478977\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093124; batch adversarial loss: 0.421577\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095509; batch adversarial loss: 0.355112\n",
      "epoch 64; iter: 0; batch classifier loss: 0.105197; batch adversarial loss: 0.426789\n",
      "epoch 65; iter: 0; batch classifier loss: 0.108700; batch adversarial loss: 0.544517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.119873; batch adversarial loss: 0.431533\n",
      "epoch 67; iter: 0; batch classifier loss: 0.099208; batch adversarial loss: 0.481017\n",
      "epoch 68; iter: 0; batch classifier loss: 0.085683; batch adversarial loss: 0.526447\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084099; batch adversarial loss: 0.510660\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078690; batch adversarial loss: 0.485857\n",
      "epoch 71; iter: 0; batch classifier loss: 0.095139; batch adversarial loss: 0.507543\n",
      "epoch 72; iter: 0; batch classifier loss: 0.056908; batch adversarial loss: 0.474796\n",
      "epoch 73; iter: 0; batch classifier loss: 0.080791; batch adversarial loss: 0.553633\n",
      "epoch 74; iter: 0; batch classifier loss: 0.120936; batch adversarial loss: 0.555242\n",
      "epoch 75; iter: 0; batch classifier loss: 0.089183; batch adversarial loss: 0.556324\n",
      "epoch 76; iter: 0; batch classifier loss: 0.084388; batch adversarial loss: 0.384126\n",
      "epoch 77; iter: 0; batch classifier loss: 0.097294; batch adversarial loss: 0.423424\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064322; batch adversarial loss: 0.510123\n",
      "epoch 79; iter: 0; batch classifier loss: 0.131231; batch adversarial loss: 0.360181\n",
      "epoch 80; iter: 0; batch classifier loss: 0.099013; batch adversarial loss: 0.519772\n",
      "epoch 81; iter: 0; batch classifier loss: 0.103858; batch adversarial loss: 0.428569\n",
      "epoch 82; iter: 0; batch classifier loss: 0.114539; batch adversarial loss: 0.490932\n",
      "epoch 83; iter: 0; batch classifier loss: 0.110985; batch adversarial loss: 0.478384\n",
      "epoch 84; iter: 0; batch classifier loss: 0.084021; batch adversarial loss: 0.425917\n",
      "epoch 85; iter: 0; batch classifier loss: 0.091609; batch adversarial loss: 0.495746\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058225; batch adversarial loss: 0.452650\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068604; batch adversarial loss: 0.519709\n",
      "epoch 88; iter: 0; batch classifier loss: 0.066629; batch adversarial loss: 0.483291\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059956; batch adversarial loss: 0.516877\n",
      "epoch 90; iter: 0; batch classifier loss: 0.078630; batch adversarial loss: 0.499621\n",
      "epoch 91; iter: 0; batch classifier loss: 0.092939; batch adversarial loss: 0.399538\n",
      "epoch 92; iter: 0; batch classifier loss: 0.056840; batch adversarial loss: 0.405891\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043857; batch adversarial loss: 0.485125\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083589; batch adversarial loss: 0.405177\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053590; batch adversarial loss: 0.374899\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044888; batch adversarial loss: 0.424686\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071346; batch adversarial loss: 0.497169\n",
      "epoch 98; iter: 0; batch classifier loss: 0.084792; batch adversarial loss: 0.374615\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078242; batch adversarial loss: 0.478931\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074014; batch adversarial loss: 0.426180\n",
      "epoch 101; iter: 0; batch classifier loss: 0.031367; batch adversarial loss: 0.491567\n",
      "epoch 102; iter: 0; batch classifier loss: 0.074167; batch adversarial loss: 0.457351\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044898; batch adversarial loss: 0.450268\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038566; batch adversarial loss: 0.541708\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058107; batch adversarial loss: 0.477329\n",
      "epoch 106; iter: 0; batch classifier loss: 0.100696; batch adversarial loss: 0.460284\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062015; batch adversarial loss: 0.435509\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036814; batch adversarial loss: 0.417331\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026516; batch adversarial loss: 0.489311\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068137; batch adversarial loss: 0.433378\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029749; batch adversarial loss: 0.488668\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027100; batch adversarial loss: 0.411033\n",
      "epoch 113; iter: 0; batch classifier loss: 0.036731; batch adversarial loss: 0.542219\n",
      "epoch 114; iter: 0; batch classifier loss: 0.031510; batch adversarial loss: 0.517966\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049689; batch adversarial loss: 0.506927\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033555; batch adversarial loss: 0.449689\n",
      "epoch 117; iter: 0; batch classifier loss: 0.019646; batch adversarial loss: 0.513073\n",
      "epoch 118; iter: 0; batch classifier loss: 0.034435; batch adversarial loss: 0.422521\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049631; batch adversarial loss: 0.532930\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034215; batch adversarial loss: 0.496426\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041710; batch adversarial loss: 0.539027\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026856; batch adversarial loss: 0.463443\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021928; batch adversarial loss: 0.490378\n",
      "epoch 124; iter: 0; batch classifier loss: 0.064418; batch adversarial loss: 0.406131\n",
      "epoch 125; iter: 0; batch classifier loss: 0.009641; batch adversarial loss: 0.528645\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035621; batch adversarial loss: 0.468906\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040022; batch adversarial loss: 0.485221\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019909; batch adversarial loss: 0.429463\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033023; batch adversarial loss: 0.451032\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017505; batch adversarial loss: 0.439515\n",
      "epoch 131; iter: 0; batch classifier loss: 0.014835; batch adversarial loss: 0.568748\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014165; batch adversarial loss: 0.546795\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034941; batch adversarial loss: 0.466652\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031295; batch adversarial loss: 0.467174\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023586; batch adversarial loss: 0.459201\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024232; batch adversarial loss: 0.455905\n",
      "epoch 137; iter: 0; batch classifier loss: 0.011708; batch adversarial loss: 0.478336\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028574; batch adversarial loss: 0.553866\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024482; batch adversarial loss: 0.403810\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020213; batch adversarial loss: 0.480002\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028292; batch adversarial loss: 0.462796\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035797; batch adversarial loss: 0.541914\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031643; batch adversarial loss: 0.539021\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013855; batch adversarial loss: 0.494612\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044737; batch adversarial loss: 0.475637\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028030; batch adversarial loss: 0.486434\n",
      "epoch 147; iter: 0; batch classifier loss: 0.007898; batch adversarial loss: 0.430916\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017420; batch adversarial loss: 0.503767\n",
      "epoch 149; iter: 0; batch classifier loss: 0.008915; batch adversarial loss: 0.474145\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022324; batch adversarial loss: 0.473656\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008290; batch adversarial loss: 0.433379\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017167; batch adversarial loss: 0.480112\n",
      "epoch 153; iter: 0; batch classifier loss: 0.006074; batch adversarial loss: 0.388994\n",
      "epoch 154; iter: 0; batch classifier loss: 0.042277; batch adversarial loss: 0.443391\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019760; batch adversarial loss: 0.347149\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023851; batch adversarial loss: 0.413203\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016002; batch adversarial loss: 0.592437\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013184; batch adversarial loss: 0.430232\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027413; batch adversarial loss: 0.369720\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010398; batch adversarial loss: 0.427017\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028565; batch adversarial loss: 0.401369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.018098; batch adversarial loss: 0.533813\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032635; batch adversarial loss: 0.449374\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021110; batch adversarial loss: 0.483035\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024690; batch adversarial loss: 0.453418\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029618; batch adversarial loss: 0.458407\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032886; batch adversarial loss: 0.447738\n",
      "epoch 168; iter: 0; batch classifier loss: 0.006436; batch adversarial loss: 0.517643\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026987; batch adversarial loss: 0.476236\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012167; batch adversarial loss: 0.371940\n",
      "epoch 171; iter: 0; batch classifier loss: 0.043943; batch adversarial loss: 0.404823\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020207; batch adversarial loss: 0.508226\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015574; batch adversarial loss: 0.405182\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021668; batch adversarial loss: 0.467784\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034180; batch adversarial loss: 0.538257\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037938; batch adversarial loss: 0.515444\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013908; batch adversarial loss: 0.483152\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018051; batch adversarial loss: 0.493982\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019282; batch adversarial loss: 0.478595\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017091; batch adversarial loss: 0.509196\n",
      "epoch 181; iter: 0; batch classifier loss: 0.005962; batch adversarial loss: 0.435345\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038493; batch adversarial loss: 0.550038\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025044; batch adversarial loss: 0.509029\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008955; batch adversarial loss: 0.516059\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011285; batch adversarial loss: 0.399174\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034138; batch adversarial loss: 0.419081\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006603; batch adversarial loss: 0.509905\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005510; batch adversarial loss: 0.491118\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013611; batch adversarial loss: 0.499133\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005139; batch adversarial loss: 0.484233\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022210; batch adversarial loss: 0.456504\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010032; batch adversarial loss: 0.548780\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015671; batch adversarial loss: 0.445430\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004721; batch adversarial loss: 0.452544\n",
      "epoch 195; iter: 0; batch classifier loss: 0.003545; batch adversarial loss: 0.491341\n",
      "epoch 196; iter: 0; batch classifier loss: 0.039633; batch adversarial loss: 0.567211\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004303; batch adversarial loss: 0.478159\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038878; batch adversarial loss: 0.481834\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013409; batch adversarial loss: 0.484268\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696808; batch adversarial loss: 0.547088\n",
      "epoch 1; iter: 0; batch classifier loss: 0.533568; batch adversarial loss: 0.609630\n",
      "epoch 2; iter: 0; batch classifier loss: 0.427940; batch adversarial loss: 0.626012\n",
      "epoch 3; iter: 0; batch classifier loss: 0.436837; batch adversarial loss: 0.574037\n",
      "epoch 4; iter: 0; batch classifier loss: 0.409557; batch adversarial loss: 0.587726\n",
      "epoch 5; iter: 0; batch classifier loss: 0.467293; batch adversarial loss: 0.578610\n",
      "epoch 6; iter: 0; batch classifier loss: 0.480306; batch adversarial loss: 0.622172\n",
      "epoch 7; iter: 0; batch classifier loss: 0.679512; batch adversarial loss: 0.598009\n",
      "epoch 8; iter: 0; batch classifier loss: 0.669576; batch adversarial loss: 0.538634\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527520; batch adversarial loss: 0.576752\n",
      "epoch 10; iter: 0; batch classifier loss: 0.460429; batch adversarial loss: 0.581101\n",
      "epoch 11; iter: 0; batch classifier loss: 0.420671; batch adversarial loss: 0.525972\n",
      "epoch 12; iter: 0; batch classifier loss: 0.417051; batch adversarial loss: 0.532000\n",
      "epoch 13; iter: 0; batch classifier loss: 0.291382; batch adversarial loss: 0.520561\n",
      "epoch 14; iter: 0; batch classifier loss: 0.307086; batch adversarial loss: 0.470720\n",
      "epoch 15; iter: 0; batch classifier loss: 0.313280; batch adversarial loss: 0.517916\n",
      "epoch 16; iter: 0; batch classifier loss: 0.258891; batch adversarial loss: 0.425042\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262432; batch adversarial loss: 0.530686\n",
      "epoch 18; iter: 0; batch classifier loss: 0.245684; batch adversarial loss: 0.587558\n",
      "epoch 19; iter: 0; batch classifier loss: 0.185603; batch adversarial loss: 0.513494\n",
      "epoch 20; iter: 0; batch classifier loss: 0.237406; batch adversarial loss: 0.437852\n",
      "epoch 21; iter: 0; batch classifier loss: 0.218189; batch adversarial loss: 0.526273\n",
      "epoch 22; iter: 0; batch classifier loss: 0.208696; batch adversarial loss: 0.442261\n",
      "epoch 23; iter: 0; batch classifier loss: 0.163554; batch adversarial loss: 0.530794\n",
      "epoch 24; iter: 0; batch classifier loss: 0.163283; batch adversarial loss: 0.556735\n",
      "epoch 25; iter: 0; batch classifier loss: 0.212395; batch adversarial loss: 0.485933\n",
      "epoch 26; iter: 0; batch classifier loss: 0.200211; batch adversarial loss: 0.453148\n",
      "epoch 27; iter: 0; batch classifier loss: 0.148731; batch adversarial loss: 0.450510\n",
      "epoch 28; iter: 0; batch classifier loss: 0.178792; batch adversarial loss: 0.475509\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178530; batch adversarial loss: 0.444900\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152438; batch adversarial loss: 0.395980\n",
      "epoch 31; iter: 0; batch classifier loss: 0.198163; batch adversarial loss: 0.433835\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126081; batch adversarial loss: 0.503333\n",
      "epoch 33; iter: 0; batch classifier loss: 0.168404; batch adversarial loss: 0.420423\n",
      "epoch 34; iter: 0; batch classifier loss: 0.190472; batch adversarial loss: 0.499596\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148981; batch adversarial loss: 0.403038\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141651; batch adversarial loss: 0.505984\n",
      "epoch 37; iter: 0; batch classifier loss: 0.155809; batch adversarial loss: 0.390095\n",
      "epoch 38; iter: 0; batch classifier loss: 0.109624; batch adversarial loss: 0.506307\n",
      "epoch 39; iter: 0; batch classifier loss: 0.150428; batch adversarial loss: 0.464963\n",
      "epoch 40; iter: 0; batch classifier loss: 0.171708; batch adversarial loss: 0.440737\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123487; batch adversarial loss: 0.531295\n",
      "epoch 42; iter: 0; batch classifier loss: 0.147486; batch adversarial loss: 0.489738\n",
      "epoch 43; iter: 0; batch classifier loss: 0.119052; batch adversarial loss: 0.424066\n",
      "epoch 44; iter: 0; batch classifier loss: 0.157580; batch adversarial loss: 0.468241\n",
      "epoch 45; iter: 0; batch classifier loss: 0.112063; batch adversarial loss: 0.476661\n",
      "epoch 46; iter: 0; batch classifier loss: 0.140321; batch adversarial loss: 0.479751\n",
      "epoch 47; iter: 0; batch classifier loss: 0.131490; batch adversarial loss: 0.504214\n",
      "epoch 48; iter: 0; batch classifier loss: 0.122099; batch adversarial loss: 0.423707\n",
      "epoch 49; iter: 0; batch classifier loss: 0.146009; batch adversarial loss: 0.443605\n",
      "epoch 50; iter: 0; batch classifier loss: 0.152546; batch adversarial loss: 0.423077\n",
      "epoch 51; iter: 0; batch classifier loss: 0.120609; batch adversarial loss: 0.435893\n",
      "epoch 52; iter: 0; batch classifier loss: 0.155448; batch adversarial loss: 0.440197\n",
      "epoch 53; iter: 0; batch classifier loss: 0.178745; batch adversarial loss: 0.412943\n",
      "epoch 54; iter: 0; batch classifier loss: 0.140388; batch adversarial loss: 0.528001\n",
      "epoch 55; iter: 0; batch classifier loss: 0.128982; batch adversarial loss: 0.406178\n",
      "epoch 56; iter: 0; batch classifier loss: 0.197952; batch adversarial loss: 0.354822\n",
      "epoch 57; iter: 0; batch classifier loss: 0.151652; batch adversarial loss: 0.495795\n",
      "epoch 58; iter: 0; batch classifier loss: 0.197931; batch adversarial loss: 0.369010\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102578; batch adversarial loss: 0.487890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.166007; batch adversarial loss: 0.477050\n",
      "epoch 61; iter: 0; batch classifier loss: 0.145961; batch adversarial loss: 0.447503\n",
      "epoch 62; iter: 0; batch classifier loss: 0.184663; batch adversarial loss: 0.434405\n",
      "epoch 63; iter: 0; batch classifier loss: 0.111778; batch adversarial loss: 0.430512\n",
      "epoch 64; iter: 0; batch classifier loss: 0.155226; batch adversarial loss: 0.502523\n",
      "epoch 65; iter: 0; batch classifier loss: 0.106606; batch adversarial loss: 0.469408\n",
      "epoch 66; iter: 0; batch classifier loss: 0.157523; batch adversarial loss: 0.423953\n",
      "epoch 67; iter: 0; batch classifier loss: 0.215581; batch adversarial loss: 0.471805\n",
      "epoch 68; iter: 0; batch classifier loss: 0.207058; batch adversarial loss: 0.417937\n",
      "epoch 69; iter: 0; batch classifier loss: 0.149464; batch adversarial loss: 0.451192\n",
      "epoch 70; iter: 0; batch classifier loss: 0.193480; batch adversarial loss: 0.475702\n",
      "epoch 71; iter: 0; batch classifier loss: 0.138573; batch adversarial loss: 0.443955\n",
      "epoch 72; iter: 0; batch classifier loss: 0.188150; batch adversarial loss: 0.506437\n",
      "epoch 73; iter: 0; batch classifier loss: 0.107748; batch adversarial loss: 0.499880\n",
      "epoch 74; iter: 0; batch classifier loss: 0.162876; batch adversarial loss: 0.402934\n",
      "epoch 75; iter: 0; batch classifier loss: 0.193478; batch adversarial loss: 0.370385\n",
      "epoch 76; iter: 0; batch classifier loss: 0.177424; batch adversarial loss: 0.408801\n",
      "epoch 77; iter: 0; batch classifier loss: 0.184250; batch adversarial loss: 0.495348\n",
      "epoch 78; iter: 0; batch classifier loss: 0.183444; batch adversarial loss: 0.447391\n",
      "epoch 79; iter: 0; batch classifier loss: 0.138977; batch adversarial loss: 0.434938\n",
      "epoch 80; iter: 0; batch classifier loss: 0.107129; batch adversarial loss: 0.352280\n",
      "epoch 81; iter: 0; batch classifier loss: 0.125592; batch adversarial loss: 0.410448\n",
      "epoch 82; iter: 0; batch classifier loss: 0.152214; batch adversarial loss: 0.393291\n",
      "epoch 83; iter: 0; batch classifier loss: 0.208627; batch adversarial loss: 0.446077\n",
      "epoch 84; iter: 0; batch classifier loss: 0.114478; batch adversarial loss: 0.421922\n",
      "epoch 85; iter: 0; batch classifier loss: 0.154239; batch adversarial loss: 0.426481\n",
      "epoch 86; iter: 0; batch classifier loss: 0.155439; batch adversarial loss: 0.573482\n",
      "epoch 87; iter: 0; batch classifier loss: 0.136753; batch adversarial loss: 0.481995\n",
      "epoch 88; iter: 0; batch classifier loss: 0.214167; batch adversarial loss: 0.372155\n",
      "epoch 89; iter: 0; batch classifier loss: 0.120282; batch adversarial loss: 0.367506\n",
      "epoch 90; iter: 0; batch classifier loss: 0.131455; batch adversarial loss: 0.432712\n",
      "epoch 91; iter: 0; batch classifier loss: 0.107312; batch adversarial loss: 0.406948\n",
      "epoch 92; iter: 0; batch classifier loss: 0.165716; batch adversarial loss: 0.507327\n",
      "epoch 93; iter: 0; batch classifier loss: 0.150949; batch adversarial loss: 0.458700\n",
      "epoch 94; iter: 0; batch classifier loss: 0.201507; batch adversarial loss: 0.481650\n",
      "epoch 95; iter: 0; batch classifier loss: 0.183567; batch adversarial loss: 0.417398\n",
      "epoch 96; iter: 0; batch classifier loss: 0.122276; batch adversarial loss: 0.479913\n",
      "epoch 97; iter: 0; batch classifier loss: 0.172712; batch adversarial loss: 0.436988\n",
      "epoch 98; iter: 0; batch classifier loss: 0.177357; batch adversarial loss: 0.437813\n",
      "epoch 99; iter: 0; batch classifier loss: 0.228307; batch adversarial loss: 0.333432\n",
      "epoch 100; iter: 0; batch classifier loss: 0.153278; batch adversarial loss: 0.487864\n",
      "epoch 101; iter: 0; batch classifier loss: 0.194467; batch adversarial loss: 0.345287\n",
      "epoch 102; iter: 0; batch classifier loss: 0.097509; batch adversarial loss: 0.381767\n",
      "epoch 103; iter: 0; batch classifier loss: 0.165790; batch adversarial loss: 0.431444\n",
      "epoch 104; iter: 0; batch classifier loss: 0.151212; batch adversarial loss: 0.380890\n",
      "epoch 105; iter: 0; batch classifier loss: 0.171913; batch adversarial loss: 0.475026\n",
      "epoch 106; iter: 0; batch classifier loss: 0.160794; batch adversarial loss: 0.361334\n",
      "epoch 107; iter: 0; batch classifier loss: 0.228623; batch adversarial loss: 0.488831\n",
      "epoch 108; iter: 0; batch classifier loss: 0.161424; batch adversarial loss: 0.408998\n",
      "epoch 109; iter: 0; batch classifier loss: 0.164113; batch adversarial loss: 0.506852\n",
      "epoch 110; iter: 0; batch classifier loss: 0.119616; batch adversarial loss: 0.472333\n",
      "epoch 111; iter: 0; batch classifier loss: 0.146373; batch adversarial loss: 0.495003\n",
      "epoch 112; iter: 0; batch classifier loss: 0.166245; batch adversarial loss: 0.470799\n",
      "epoch 113; iter: 0; batch classifier loss: 0.112089; batch adversarial loss: 0.482755\n",
      "epoch 114; iter: 0; batch classifier loss: 0.148772; batch adversarial loss: 0.527691\n",
      "epoch 115; iter: 0; batch classifier loss: 0.137378; batch adversarial loss: 0.473500\n",
      "epoch 116; iter: 0; batch classifier loss: 0.123956; batch adversarial loss: 0.485662\n",
      "epoch 117; iter: 0; batch classifier loss: 0.113735; batch adversarial loss: 0.445497\n",
      "epoch 118; iter: 0; batch classifier loss: 0.108215; batch adversarial loss: 0.493728\n",
      "epoch 119; iter: 0; batch classifier loss: 0.167946; batch adversarial loss: 0.409923\n",
      "epoch 120; iter: 0; batch classifier loss: 0.176609; batch adversarial loss: 0.465612\n",
      "epoch 121; iter: 0; batch classifier loss: 0.143669; batch adversarial loss: 0.367367\n",
      "epoch 122; iter: 0; batch classifier loss: 0.122423; batch adversarial loss: 0.446380\n",
      "epoch 123; iter: 0; batch classifier loss: 0.119651; batch adversarial loss: 0.469933\n",
      "epoch 124; iter: 0; batch classifier loss: 0.120923; batch adversarial loss: 0.479607\n",
      "epoch 125; iter: 0; batch classifier loss: 0.071912; batch adversarial loss: 0.400339\n",
      "epoch 126; iter: 0; batch classifier loss: 0.132967; batch adversarial loss: 0.492293\n",
      "epoch 127; iter: 0; batch classifier loss: 0.111035; batch adversarial loss: 0.436353\n",
      "epoch 128; iter: 0; batch classifier loss: 0.084291; batch adversarial loss: 0.445659\n",
      "epoch 129; iter: 0; batch classifier loss: 0.089781; batch adversarial loss: 0.448613\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041742; batch adversarial loss: 0.495906\n",
      "epoch 131; iter: 0; batch classifier loss: 0.071960; batch adversarial loss: 0.520899\n",
      "epoch 132; iter: 0; batch classifier loss: 0.085650; batch adversarial loss: 0.416132\n",
      "epoch 133; iter: 0; batch classifier loss: 0.071746; batch adversarial loss: 0.441419\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050907; batch adversarial loss: 0.465887\n",
      "epoch 135; iter: 0; batch classifier loss: 0.072249; batch adversarial loss: 0.440307\n",
      "epoch 136; iter: 0; batch classifier loss: 0.088371; batch adversarial loss: 0.401860\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035966; batch adversarial loss: 0.384981\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041369; batch adversarial loss: 0.510363\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045145; batch adversarial loss: 0.544693\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044676; batch adversarial loss: 0.497189\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033841; batch adversarial loss: 0.447970\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037487; batch adversarial loss: 0.484278\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028752; batch adversarial loss: 0.586432\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028793; batch adversarial loss: 0.453592\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034747; batch adversarial loss: 0.447061\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029075; batch adversarial loss: 0.473367\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037429; batch adversarial loss: 0.458062\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024844; batch adversarial loss: 0.436524\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032802; batch adversarial loss: 0.472366\n",
      "epoch 150; iter: 0; batch classifier loss: 0.051594; batch adversarial loss: 0.424112\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029242; batch adversarial loss: 0.556113\n",
      "epoch 152; iter: 0; batch classifier loss: 0.054829; batch adversarial loss: 0.451791\n",
      "epoch 153; iter: 0; batch classifier loss: 0.046637; batch adversarial loss: 0.375863\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027415; batch adversarial loss: 0.480633\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028869; batch adversarial loss: 0.414169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.036256; batch adversarial loss: 0.478038\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040947; batch adversarial loss: 0.549735\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024274; batch adversarial loss: 0.327772\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028525; batch adversarial loss: 0.468288\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029716; batch adversarial loss: 0.505993\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015663; batch adversarial loss: 0.476632\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018997; batch adversarial loss: 0.385410\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012412; batch adversarial loss: 0.368624\n",
      "epoch 164; iter: 0; batch classifier loss: 0.008897; batch adversarial loss: 0.417515\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009885; batch adversarial loss: 0.529359\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018579; batch adversarial loss: 0.440908\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020163; batch adversarial loss: 0.553557\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014479; batch adversarial loss: 0.419059\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012227; batch adversarial loss: 0.503790\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017376; batch adversarial loss: 0.427483\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028985; batch adversarial loss: 0.396038\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017834; batch adversarial loss: 0.367619\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020028; batch adversarial loss: 0.401987\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020165; batch adversarial loss: 0.469570\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034477; batch adversarial loss: 0.433830\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026466; batch adversarial loss: 0.379297\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009041; batch adversarial loss: 0.420362\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014285; batch adversarial loss: 0.447114\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018872; batch adversarial loss: 0.481588\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017075; batch adversarial loss: 0.515144\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021721; batch adversarial loss: 0.502693\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027926; batch adversarial loss: 0.586672\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036258; batch adversarial loss: 0.449912\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006989; batch adversarial loss: 0.421719\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010806; batch adversarial loss: 0.388155\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025418; batch adversarial loss: 0.501817\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031985; batch adversarial loss: 0.475487\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017259; batch adversarial loss: 0.528128\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009695; batch adversarial loss: 0.349646\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017380; batch adversarial loss: 0.466073\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029064; batch adversarial loss: 0.396507\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012342; batch adversarial loss: 0.489671\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015150; batch adversarial loss: 0.404485\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012284; batch adversarial loss: 0.370139\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011842; batch adversarial loss: 0.445987\n",
      "epoch 196; iter: 0; batch classifier loss: 0.034282; batch adversarial loss: 0.484209\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012101; batch adversarial loss: 0.445785\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014792; batch adversarial loss: 0.426905\n",
      "epoch 199; iter: 0; batch classifier loss: 0.044649; batch adversarial loss: 0.449441\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695850; batch adversarial loss: 0.736682\n",
      "epoch 1; iter: 0; batch classifier loss: 0.463033; batch adversarial loss: 0.694241\n",
      "epoch 2; iter: 0; batch classifier loss: 0.416445; batch adversarial loss: 0.662572\n",
      "epoch 3; iter: 0; batch classifier loss: 0.373264; batch adversarial loss: 0.634915\n",
      "epoch 4; iter: 0; batch classifier loss: 0.414701; batch adversarial loss: 0.615812\n",
      "epoch 5; iter: 0; batch classifier loss: 0.317396; batch adversarial loss: 0.554874\n",
      "epoch 6; iter: 0; batch classifier loss: 0.401230; batch adversarial loss: 0.533446\n",
      "epoch 7; iter: 0; batch classifier loss: 0.252019; batch adversarial loss: 0.541300\n",
      "epoch 8; iter: 0; batch classifier loss: 0.316094; batch adversarial loss: 0.456663\n",
      "epoch 9; iter: 0; batch classifier loss: 0.316094; batch adversarial loss: 0.465649\n",
      "epoch 10; iter: 0; batch classifier loss: 0.224750; batch adversarial loss: 0.476814\n",
      "epoch 11; iter: 0; batch classifier loss: 0.213183; batch adversarial loss: 0.464536\n",
      "epoch 12; iter: 0; batch classifier loss: 0.191524; batch adversarial loss: 0.448201\n",
      "epoch 13; iter: 0; batch classifier loss: 0.181244; batch adversarial loss: 0.534530\n",
      "epoch 14; iter: 0; batch classifier loss: 0.207966; batch adversarial loss: 0.441086\n",
      "epoch 15; iter: 0; batch classifier loss: 0.202474; batch adversarial loss: 0.447376\n",
      "epoch 16; iter: 0; batch classifier loss: 0.179841; batch adversarial loss: 0.446864\n",
      "epoch 17; iter: 0; batch classifier loss: 0.150074; batch adversarial loss: 0.473754\n",
      "epoch 18; iter: 0; batch classifier loss: 0.288217; batch adversarial loss: 0.459960\n",
      "epoch 19; iter: 0; batch classifier loss: 0.111128; batch adversarial loss: 0.483962\n",
      "epoch 20; iter: 0; batch classifier loss: 0.135811; batch adversarial loss: 0.405406\n",
      "epoch 21; iter: 0; batch classifier loss: 0.155231; batch adversarial loss: 0.429511\n",
      "epoch 22; iter: 0; batch classifier loss: 0.134658; batch adversarial loss: 0.500640\n",
      "epoch 23; iter: 0; batch classifier loss: 0.115342; batch adversarial loss: 0.521610\n",
      "epoch 24; iter: 0; batch classifier loss: 0.132276; batch adversarial loss: 0.499156\n",
      "epoch 25; iter: 0; batch classifier loss: 0.108244; batch adversarial loss: 0.468596\n",
      "epoch 26; iter: 0; batch classifier loss: 0.170610; batch adversarial loss: 0.520580\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154174; batch adversarial loss: 0.459896\n",
      "epoch 28; iter: 0; batch classifier loss: 0.149376; batch adversarial loss: 0.506611\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209525; batch adversarial loss: 0.524645\n",
      "epoch 30; iter: 0; batch classifier loss: 0.199119; batch adversarial loss: 0.435568\n",
      "epoch 31; iter: 0; batch classifier loss: 0.189168; batch adversarial loss: 0.459640\n",
      "epoch 32; iter: 0; batch classifier loss: 0.221749; batch adversarial loss: 0.571355\n",
      "epoch 33; iter: 0; batch classifier loss: 0.261527; batch adversarial loss: 0.508840\n",
      "epoch 34; iter: 0; batch classifier loss: 0.177399; batch adversarial loss: 0.493197\n",
      "epoch 35; iter: 0; batch classifier loss: 0.191568; batch adversarial loss: 0.411931\n",
      "epoch 36; iter: 0; batch classifier loss: 0.095112; batch adversarial loss: 0.413576\n",
      "epoch 37; iter: 0; batch classifier loss: 0.087074; batch adversarial loss: 0.400092\n",
      "epoch 38; iter: 0; batch classifier loss: 0.080900; batch adversarial loss: 0.456896\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106368; batch adversarial loss: 0.434268\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124571; batch adversarial loss: 0.584755\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098354; batch adversarial loss: 0.563669\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105169; batch adversarial loss: 0.479832\n",
      "epoch 43; iter: 0; batch classifier loss: 0.061455; batch adversarial loss: 0.391820\n",
      "epoch 44; iter: 0; batch classifier loss: 0.082053; batch adversarial loss: 0.389941\n",
      "epoch 45; iter: 0; batch classifier loss: 0.088060; batch adversarial loss: 0.438845\n",
      "epoch 46; iter: 0; batch classifier loss: 0.099926; batch adversarial loss: 0.488098\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113335; batch adversarial loss: 0.538940\n",
      "epoch 48; iter: 0; batch classifier loss: 0.063791; batch adversarial loss: 0.435838\n",
      "epoch 49; iter: 0; batch classifier loss: 0.081532; batch adversarial loss: 0.450417\n",
      "epoch 50; iter: 0; batch classifier loss: 0.061445; batch adversarial loss: 0.400465\n",
      "epoch 51; iter: 0; batch classifier loss: 0.059891; batch adversarial loss: 0.404388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.091138; batch adversarial loss: 0.449833\n",
      "epoch 53; iter: 0; batch classifier loss: 0.151672; batch adversarial loss: 0.451840\n",
      "epoch 54; iter: 0; batch classifier loss: 0.123247; batch adversarial loss: 0.346834\n",
      "epoch 55; iter: 0; batch classifier loss: 0.131896; batch adversarial loss: 0.438014\n",
      "epoch 56; iter: 0; batch classifier loss: 0.086434; batch adversarial loss: 0.512117\n",
      "epoch 57; iter: 0; batch classifier loss: 0.061674; batch adversarial loss: 0.472188\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091827; batch adversarial loss: 0.527208\n",
      "epoch 59; iter: 0; batch classifier loss: 0.063195; batch adversarial loss: 0.555600\n",
      "epoch 60; iter: 0; batch classifier loss: 0.047966; batch adversarial loss: 0.366497\n",
      "epoch 61; iter: 0; batch classifier loss: 0.077881; batch adversarial loss: 0.397567\n",
      "epoch 62; iter: 0; batch classifier loss: 0.063291; batch adversarial loss: 0.539846\n",
      "epoch 63; iter: 0; batch classifier loss: 0.087182; batch adversarial loss: 0.413580\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072609; batch adversarial loss: 0.450417\n",
      "epoch 65; iter: 0; batch classifier loss: 0.044563; batch adversarial loss: 0.450397\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072064; batch adversarial loss: 0.601070\n",
      "epoch 67; iter: 0; batch classifier loss: 0.092746; batch adversarial loss: 0.546885\n",
      "epoch 68; iter: 0; batch classifier loss: 0.068120; batch adversarial loss: 0.526500\n",
      "epoch 69; iter: 0; batch classifier loss: 0.080901; batch adversarial loss: 0.378798\n",
      "epoch 70; iter: 0; batch classifier loss: 0.049387; batch adversarial loss: 0.414044\n",
      "epoch 71; iter: 0; batch classifier loss: 0.047469; batch adversarial loss: 0.383931\n",
      "epoch 72; iter: 0; batch classifier loss: 0.025561; batch adversarial loss: 0.442243\n",
      "epoch 73; iter: 0; batch classifier loss: 0.064543; batch adversarial loss: 0.394068\n",
      "epoch 74; iter: 0; batch classifier loss: 0.112925; batch adversarial loss: 0.468158\n",
      "epoch 75; iter: 0; batch classifier loss: 0.044274; batch adversarial loss: 0.491122\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073131; batch adversarial loss: 0.403779\n",
      "epoch 77; iter: 0; batch classifier loss: 0.085102; batch adversarial loss: 0.398888\n",
      "epoch 78; iter: 0; batch classifier loss: 0.049788; batch adversarial loss: 0.380410\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063558; batch adversarial loss: 0.373538\n",
      "epoch 80; iter: 0; batch classifier loss: 0.046498; batch adversarial loss: 0.445516\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057708; batch adversarial loss: 0.462424\n",
      "epoch 82; iter: 0; batch classifier loss: 0.031326; batch adversarial loss: 0.401847\n",
      "epoch 83; iter: 0; batch classifier loss: 0.110494; batch adversarial loss: 0.406524\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075822; batch adversarial loss: 0.375216\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067044; batch adversarial loss: 0.555627\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046382; batch adversarial loss: 0.438053\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046151; batch adversarial loss: 0.409696\n",
      "epoch 88; iter: 0; batch classifier loss: 0.100826; batch adversarial loss: 0.411893\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073173; batch adversarial loss: 0.523629\n",
      "epoch 90; iter: 0; batch classifier loss: 0.034702; batch adversarial loss: 0.468267\n",
      "epoch 91; iter: 0; batch classifier loss: 0.026834; batch adversarial loss: 0.504251\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050422; batch adversarial loss: 0.408197\n",
      "epoch 93; iter: 0; batch classifier loss: 0.028623; batch adversarial loss: 0.424003\n",
      "epoch 94; iter: 0; batch classifier loss: 0.032057; batch adversarial loss: 0.457412\n",
      "epoch 95; iter: 0; batch classifier loss: 0.075215; batch adversarial loss: 0.494030\n",
      "epoch 96; iter: 0; batch classifier loss: 0.031483; batch adversarial loss: 0.491653\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046544; batch adversarial loss: 0.463481\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036506; batch adversarial loss: 0.500208\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037499; batch adversarial loss: 0.433891\n",
      "epoch 100; iter: 0; batch classifier loss: 0.031693; batch adversarial loss: 0.396197\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065867; batch adversarial loss: 0.396587\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054659; batch adversarial loss: 0.376749\n",
      "epoch 103; iter: 0; batch classifier loss: 0.069807; batch adversarial loss: 0.477619\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039548; batch adversarial loss: 0.460440\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045202; batch adversarial loss: 0.414173\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060478; batch adversarial loss: 0.408789\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045064; batch adversarial loss: 0.433841\n",
      "epoch 108; iter: 0; batch classifier loss: 0.014670; batch adversarial loss: 0.458778\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051072; batch adversarial loss: 0.456406\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046665; batch adversarial loss: 0.504402\n",
      "epoch 111; iter: 0; batch classifier loss: 0.026207; batch adversarial loss: 0.465523\n",
      "epoch 112; iter: 0; batch classifier loss: 0.068250; batch adversarial loss: 0.410103\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058941; batch adversarial loss: 0.413977\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062701; batch adversarial loss: 0.402560\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029296; batch adversarial loss: 0.516837\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037688; batch adversarial loss: 0.457384\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045247; batch adversarial loss: 0.490298\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026917; batch adversarial loss: 0.417876\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030478; batch adversarial loss: 0.458061\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039457; batch adversarial loss: 0.493348\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029344; batch adversarial loss: 0.391600\n",
      "epoch 122; iter: 0; batch classifier loss: 0.027943; batch adversarial loss: 0.498915\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025395; batch adversarial loss: 0.439609\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030021; batch adversarial loss: 0.451481\n",
      "epoch 125; iter: 0; batch classifier loss: 0.093862; batch adversarial loss: 0.598905\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031317; batch adversarial loss: 0.455711\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030930; batch adversarial loss: 0.467643\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042629; batch adversarial loss: 0.508970\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040260; batch adversarial loss: 0.423757\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034992; batch adversarial loss: 0.444400\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030196; batch adversarial loss: 0.454392\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041541; batch adversarial loss: 0.377550\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030936; batch adversarial loss: 0.499439\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048915; batch adversarial loss: 0.432249\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046507; batch adversarial loss: 0.415312\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041848; batch adversarial loss: 0.394636\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023446; batch adversarial loss: 0.491067\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031855; batch adversarial loss: 0.478083\n",
      "epoch 139; iter: 0; batch classifier loss: 0.008811; batch adversarial loss: 0.465588\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053053; batch adversarial loss: 0.447652\n",
      "epoch 141; iter: 0; batch classifier loss: 0.011418; batch adversarial loss: 0.462697\n",
      "epoch 142; iter: 0; batch classifier loss: 0.015694; batch adversarial loss: 0.500061\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042117; batch adversarial loss: 0.382056\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012160; batch adversarial loss: 0.478384\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036942; batch adversarial loss: 0.448841\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019998; batch adversarial loss: 0.444034\n",
      "epoch 147; iter: 0; batch classifier loss: 0.055909; batch adversarial loss: 0.388302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.004653; batch adversarial loss: 0.438740\n",
      "epoch 149; iter: 0; batch classifier loss: 0.009347; batch adversarial loss: 0.477317\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041188; batch adversarial loss: 0.428070\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009913; batch adversarial loss: 0.402628\n",
      "epoch 152; iter: 0; batch classifier loss: 0.049275; batch adversarial loss: 0.376110\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026521; batch adversarial loss: 0.485342\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033425; batch adversarial loss: 0.405490\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018225; batch adversarial loss: 0.494916\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050927; batch adversarial loss: 0.487966\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036555; batch adversarial loss: 0.497669\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030315; batch adversarial loss: 0.451415\n",
      "epoch 159; iter: 0; batch classifier loss: 0.054104; batch adversarial loss: 0.473031\n",
      "epoch 160; iter: 0; batch classifier loss: 0.039641; batch adversarial loss: 0.441156\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016536; batch adversarial loss: 0.459790\n",
      "epoch 162; iter: 0; batch classifier loss: 0.054402; batch adversarial loss: 0.439180\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009155; batch adversarial loss: 0.500362\n",
      "epoch 164; iter: 0; batch classifier loss: 0.046261; batch adversarial loss: 0.287453\n",
      "epoch 165; iter: 0; batch classifier loss: 0.074713; batch adversarial loss: 0.443532\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038864; batch adversarial loss: 0.412915\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010454; batch adversarial loss: 0.374617\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023337; batch adversarial loss: 0.523797\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006888; batch adversarial loss: 0.462609\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025875; batch adversarial loss: 0.516526\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016841; batch adversarial loss: 0.443841\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007391; batch adversarial loss: 0.421262\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029180; batch adversarial loss: 0.439074\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014050; batch adversarial loss: 0.500707\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035280; batch adversarial loss: 0.361377\n",
      "epoch 176; iter: 0; batch classifier loss: 0.054312; batch adversarial loss: 0.388507\n",
      "epoch 177; iter: 0; batch classifier loss: 0.068911; batch adversarial loss: 0.408238\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008259; batch adversarial loss: 0.447637\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019006; batch adversarial loss: 0.505089\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021344; batch adversarial loss: 0.426366\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013145; batch adversarial loss: 0.468838\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025302; batch adversarial loss: 0.454516\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029659; batch adversarial loss: 0.436497\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016973; batch adversarial loss: 0.448076\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009210; batch adversarial loss: 0.399268\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041463; batch adversarial loss: 0.471891\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032691; batch adversarial loss: 0.421867\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020750; batch adversarial loss: 0.453248\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010935; batch adversarial loss: 0.452453\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050225; batch adversarial loss: 0.540171\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020569; batch adversarial loss: 0.410965\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012100; batch adversarial loss: 0.467486\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019912; batch adversarial loss: 0.437818\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018620; batch adversarial loss: 0.403911\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026804; batch adversarial loss: 0.505533\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010703; batch adversarial loss: 0.428776\n",
      "epoch 197; iter: 0; batch classifier loss: 0.049823; batch adversarial loss: 0.448572\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012924; batch adversarial loss: 0.354452\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014942; batch adversarial loss: 0.511029\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698782; batch adversarial loss: 0.563356\n",
      "epoch 1; iter: 0; batch classifier loss: 0.471423; batch adversarial loss: 0.608835\n",
      "epoch 2; iter: 0; batch classifier loss: 0.443491; batch adversarial loss: 0.585975\n",
      "epoch 3; iter: 0; batch classifier loss: 0.368501; batch adversarial loss: 0.639879\n",
      "epoch 4; iter: 0; batch classifier loss: 0.408325; batch adversarial loss: 0.593922\n",
      "epoch 5; iter: 0; batch classifier loss: 0.447583; batch adversarial loss: 0.575770\n",
      "epoch 6; iter: 0; batch classifier loss: 0.427040; batch adversarial loss: 0.600335\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533716; batch adversarial loss: 0.570931\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535558; batch adversarial loss: 0.577173\n",
      "epoch 9; iter: 0; batch classifier loss: 0.317969; batch adversarial loss: 0.592389\n",
      "epoch 10; iter: 0; batch classifier loss: 0.388853; batch adversarial loss: 0.600042\n",
      "epoch 11; iter: 0; batch classifier loss: 0.341741; batch adversarial loss: 0.500857\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282105; batch adversarial loss: 0.511889\n",
      "epoch 13; iter: 0; batch classifier loss: 0.370479; batch adversarial loss: 0.543233\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274329; batch adversarial loss: 0.454452\n",
      "epoch 15; iter: 0; batch classifier loss: 0.250840; batch adversarial loss: 0.432422\n",
      "epoch 16; iter: 0; batch classifier loss: 0.251563; batch adversarial loss: 0.584550\n",
      "epoch 17; iter: 0; batch classifier loss: 0.237347; batch adversarial loss: 0.521563\n",
      "epoch 18; iter: 0; batch classifier loss: 0.175489; batch adversarial loss: 0.479236\n",
      "epoch 19; iter: 0; batch classifier loss: 0.215014; batch adversarial loss: 0.457238\n",
      "epoch 20; iter: 0; batch classifier loss: 0.226298; batch adversarial loss: 0.507501\n",
      "epoch 21; iter: 0; batch classifier loss: 0.218234; batch adversarial loss: 0.451317\n",
      "epoch 22; iter: 0; batch classifier loss: 0.210031; batch adversarial loss: 0.473818\n",
      "epoch 23; iter: 0; batch classifier loss: 0.196155; batch adversarial loss: 0.373846\n",
      "epoch 24; iter: 0; batch classifier loss: 0.114282; batch adversarial loss: 0.481875\n",
      "epoch 25; iter: 0; batch classifier loss: 0.224727; batch adversarial loss: 0.463430\n",
      "epoch 26; iter: 0; batch classifier loss: 0.207798; batch adversarial loss: 0.415710\n",
      "epoch 27; iter: 0; batch classifier loss: 0.173315; batch adversarial loss: 0.438384\n",
      "epoch 28; iter: 0; batch classifier loss: 0.134124; batch adversarial loss: 0.544998\n",
      "epoch 29; iter: 0; batch classifier loss: 0.150797; batch adversarial loss: 0.513478\n",
      "epoch 30; iter: 0; batch classifier loss: 0.170477; batch adversarial loss: 0.427115\n",
      "epoch 31; iter: 0; batch classifier loss: 0.182884; batch adversarial loss: 0.412556\n",
      "epoch 32; iter: 0; batch classifier loss: 0.216431; batch adversarial loss: 0.507580\n",
      "epoch 33; iter: 0; batch classifier loss: 0.156975; batch adversarial loss: 0.453272\n",
      "epoch 34; iter: 0; batch classifier loss: 0.172002; batch adversarial loss: 0.483173\n",
      "epoch 35; iter: 0; batch classifier loss: 0.110073; batch adversarial loss: 0.601151\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141783; batch adversarial loss: 0.439248\n",
      "epoch 37; iter: 0; batch classifier loss: 0.141651; batch adversarial loss: 0.399929\n",
      "epoch 38; iter: 0; batch classifier loss: 0.169699; batch adversarial loss: 0.504244\n",
      "epoch 39; iter: 0; batch classifier loss: 0.155041; batch adversarial loss: 0.497596\n",
      "epoch 40; iter: 0; batch classifier loss: 0.143430; batch adversarial loss: 0.378503\n",
      "epoch 41; iter: 0; batch classifier loss: 0.149950; batch adversarial loss: 0.399059\n",
      "epoch 42; iter: 0; batch classifier loss: 0.134556; batch adversarial loss: 0.451515\n",
      "epoch 43; iter: 0; batch classifier loss: 0.188553; batch adversarial loss: 0.583105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.146361; batch adversarial loss: 0.493170\n",
      "epoch 45; iter: 0; batch classifier loss: 0.136415; batch adversarial loss: 0.446072\n",
      "epoch 46; iter: 0; batch classifier loss: 0.179835; batch adversarial loss: 0.437906\n",
      "epoch 47; iter: 0; batch classifier loss: 0.153754; batch adversarial loss: 0.477407\n",
      "epoch 48; iter: 0; batch classifier loss: 0.173012; batch adversarial loss: 0.442818\n",
      "epoch 49; iter: 0; batch classifier loss: 0.161515; batch adversarial loss: 0.489125\n",
      "epoch 50; iter: 0; batch classifier loss: 0.152198; batch adversarial loss: 0.449212\n",
      "epoch 51; iter: 0; batch classifier loss: 0.110186; batch adversarial loss: 0.474587\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112273; batch adversarial loss: 0.472870\n",
      "epoch 53; iter: 0; batch classifier loss: 0.180494; batch adversarial loss: 0.558920\n",
      "epoch 54; iter: 0; batch classifier loss: 0.144581; batch adversarial loss: 0.477805\n",
      "epoch 55; iter: 0; batch classifier loss: 0.166409; batch adversarial loss: 0.445145\n",
      "epoch 56; iter: 0; batch classifier loss: 0.192241; batch adversarial loss: 0.447997\n",
      "epoch 57; iter: 0; batch classifier loss: 0.148730; batch adversarial loss: 0.510450\n",
      "epoch 58; iter: 0; batch classifier loss: 0.197567; batch adversarial loss: 0.436139\n",
      "epoch 59; iter: 0; batch classifier loss: 0.183853; batch adversarial loss: 0.495850\n",
      "epoch 60; iter: 0; batch classifier loss: 0.157897; batch adversarial loss: 0.413675\n",
      "epoch 61; iter: 0; batch classifier loss: 0.177945; batch adversarial loss: 0.390198\n",
      "epoch 62; iter: 0; batch classifier loss: 0.186678; batch adversarial loss: 0.421048\n",
      "epoch 63; iter: 0; batch classifier loss: 0.189449; batch adversarial loss: 0.459406\n",
      "epoch 64; iter: 0; batch classifier loss: 0.190923; batch adversarial loss: 0.466138\n",
      "epoch 65; iter: 0; batch classifier loss: 0.230262; batch adversarial loss: 0.450934\n",
      "epoch 66; iter: 0; batch classifier loss: 0.135475; batch adversarial loss: 0.470691\n",
      "epoch 67; iter: 0; batch classifier loss: 0.144633; batch adversarial loss: 0.467294\n",
      "epoch 68; iter: 0; batch classifier loss: 0.169565; batch adversarial loss: 0.491965\n",
      "epoch 69; iter: 0; batch classifier loss: 0.202024; batch adversarial loss: 0.494622\n",
      "epoch 70; iter: 0; batch classifier loss: 0.160302; batch adversarial loss: 0.424036\n",
      "epoch 71; iter: 0; batch classifier loss: 0.250471; batch adversarial loss: 0.578352\n",
      "epoch 72; iter: 0; batch classifier loss: 0.184344; batch adversarial loss: 0.456815\n",
      "epoch 73; iter: 0; batch classifier loss: 0.154576; batch adversarial loss: 0.494666\n",
      "epoch 74; iter: 0; batch classifier loss: 0.109856; batch adversarial loss: 0.371809\n",
      "epoch 75; iter: 0; batch classifier loss: 0.133839; batch adversarial loss: 0.457650\n",
      "epoch 76; iter: 0; batch classifier loss: 0.172138; batch adversarial loss: 0.558499\n",
      "epoch 77; iter: 0; batch classifier loss: 0.183109; batch adversarial loss: 0.361023\n",
      "epoch 78; iter: 0; batch classifier loss: 0.181540; batch adversarial loss: 0.481708\n",
      "epoch 79; iter: 0; batch classifier loss: 0.165777; batch adversarial loss: 0.517388\n",
      "epoch 80; iter: 0; batch classifier loss: 0.094233; batch adversarial loss: 0.457769\n",
      "epoch 81; iter: 0; batch classifier loss: 0.202874; batch adversarial loss: 0.457094\n",
      "epoch 82; iter: 0; batch classifier loss: 0.178736; batch adversarial loss: 0.459513\n",
      "epoch 83; iter: 0; batch classifier loss: 0.143524; batch adversarial loss: 0.447838\n",
      "epoch 84; iter: 0; batch classifier loss: 0.109963; batch adversarial loss: 0.494353\n",
      "epoch 85; iter: 0; batch classifier loss: 0.134147; batch adversarial loss: 0.445950\n",
      "epoch 86; iter: 0; batch classifier loss: 0.115782; batch adversarial loss: 0.435660\n",
      "epoch 87; iter: 0; batch classifier loss: 0.147089; batch adversarial loss: 0.444868\n",
      "epoch 88; iter: 0; batch classifier loss: 0.129172; batch adversarial loss: 0.517869\n",
      "epoch 89; iter: 0; batch classifier loss: 0.172246; batch adversarial loss: 0.468537\n",
      "epoch 90; iter: 0; batch classifier loss: 0.174549; batch adversarial loss: 0.420826\n",
      "epoch 91; iter: 0; batch classifier loss: 0.154029; batch adversarial loss: 0.418585\n",
      "epoch 92; iter: 0; batch classifier loss: 0.170153; batch adversarial loss: 0.470241\n",
      "epoch 93; iter: 0; batch classifier loss: 0.141340; batch adversarial loss: 0.482362\n",
      "epoch 94; iter: 0; batch classifier loss: 0.163672; batch adversarial loss: 0.600628\n",
      "epoch 95; iter: 0; batch classifier loss: 0.119397; batch adversarial loss: 0.529398\n",
      "epoch 96; iter: 0; batch classifier loss: 0.122622; batch adversarial loss: 0.420269\n",
      "epoch 97; iter: 0; batch classifier loss: 0.118487; batch adversarial loss: 0.401754\n",
      "epoch 98; iter: 0; batch classifier loss: 0.120889; batch adversarial loss: 0.460376\n",
      "epoch 99; iter: 0; batch classifier loss: 0.114013; batch adversarial loss: 0.456432\n",
      "epoch 100; iter: 0; batch classifier loss: 0.125516; batch adversarial loss: 0.520793\n",
      "epoch 101; iter: 0; batch classifier loss: 0.138002; batch adversarial loss: 0.503227\n",
      "epoch 102; iter: 0; batch classifier loss: 0.115287; batch adversarial loss: 0.394263\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078429; batch adversarial loss: 0.486501\n",
      "epoch 104; iter: 0; batch classifier loss: 0.148213; batch adversarial loss: 0.370460\n",
      "epoch 105; iter: 0; batch classifier loss: 0.143911; batch adversarial loss: 0.391370\n",
      "epoch 106; iter: 0; batch classifier loss: 0.103563; batch adversarial loss: 0.388855\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059061; batch adversarial loss: 0.574423\n",
      "epoch 108; iter: 0; batch classifier loss: 0.094410; batch adversarial loss: 0.496908\n",
      "epoch 109; iter: 0; batch classifier loss: 0.091279; batch adversarial loss: 0.532536\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067017; batch adversarial loss: 0.446325\n",
      "epoch 111; iter: 0; batch classifier loss: 0.082945; batch adversarial loss: 0.423723\n",
      "epoch 112; iter: 0; batch classifier loss: 0.114691; batch adversarial loss: 0.449287\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069485; batch adversarial loss: 0.422900\n",
      "epoch 114; iter: 0; batch classifier loss: 0.073246; batch adversarial loss: 0.412487\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052558; batch adversarial loss: 0.443655\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045600; batch adversarial loss: 0.426391\n",
      "epoch 117; iter: 0; batch classifier loss: 0.079737; batch adversarial loss: 0.541431\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056346; batch adversarial loss: 0.482743\n",
      "epoch 119; iter: 0; batch classifier loss: 0.067946; batch adversarial loss: 0.590342\n",
      "epoch 120; iter: 0; batch classifier loss: 0.076289; batch adversarial loss: 0.419625\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039604; batch adversarial loss: 0.464677\n",
      "epoch 122; iter: 0; batch classifier loss: 0.103980; batch adversarial loss: 0.479311\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037267; batch adversarial loss: 0.460028\n",
      "epoch 124; iter: 0; batch classifier loss: 0.088557; batch adversarial loss: 0.514057\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048115; batch adversarial loss: 0.530334\n",
      "epoch 126; iter: 0; batch classifier loss: 0.064039; batch adversarial loss: 0.486012\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043159; batch adversarial loss: 0.461138\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045517; batch adversarial loss: 0.463841\n",
      "epoch 129; iter: 0; batch classifier loss: 0.058163; batch adversarial loss: 0.447230\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033194; batch adversarial loss: 0.423217\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031970; batch adversarial loss: 0.484794\n",
      "epoch 132; iter: 0; batch classifier loss: 0.062299; batch adversarial loss: 0.416480\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024509; batch adversarial loss: 0.437499\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037180; batch adversarial loss: 0.475295\n",
      "epoch 135; iter: 0; batch classifier loss: 0.077174; batch adversarial loss: 0.465946\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044730; batch adversarial loss: 0.379536\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041009; batch adversarial loss: 0.453956\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026026; batch adversarial loss: 0.483249\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050723; batch adversarial loss: 0.479124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.035155; batch adversarial loss: 0.487635\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030474; batch adversarial loss: 0.414831\n",
      "epoch 142; iter: 0; batch classifier loss: 0.046163; batch adversarial loss: 0.399006\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037321; batch adversarial loss: 0.499014\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041832; batch adversarial loss: 0.396627\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032787; batch adversarial loss: 0.461363\n",
      "epoch 146; iter: 0; batch classifier loss: 0.070986; batch adversarial loss: 0.478859\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038064; batch adversarial loss: 0.533939\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031878; batch adversarial loss: 0.504953\n",
      "epoch 149; iter: 0; batch classifier loss: 0.054877; batch adversarial loss: 0.511885\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025436; batch adversarial loss: 0.531155\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030471; batch adversarial loss: 0.356784\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018022; batch adversarial loss: 0.469806\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048570; batch adversarial loss: 0.452823\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017390; batch adversarial loss: 0.431935\n",
      "epoch 155; iter: 0; batch classifier loss: 0.071083; batch adversarial loss: 0.465832\n",
      "epoch 156; iter: 0; batch classifier loss: 0.054869; batch adversarial loss: 0.425351\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031791; batch adversarial loss: 0.535385\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037630; batch adversarial loss: 0.524030\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021602; batch adversarial loss: 0.466178\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017667; batch adversarial loss: 0.441631\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030271; batch adversarial loss: 0.522584\n",
      "epoch 162; iter: 0; batch classifier loss: 0.107388; batch adversarial loss: 0.488434\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029364; batch adversarial loss: 0.411481\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031349; batch adversarial loss: 0.445512\n",
      "epoch 165; iter: 0; batch classifier loss: 0.045502; batch adversarial loss: 0.462917\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034418; batch adversarial loss: 0.444958\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029603; batch adversarial loss: 0.516757\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030770; batch adversarial loss: 0.392744\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030571; batch adversarial loss: 0.444864\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016331; batch adversarial loss: 0.468709\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017889; batch adversarial loss: 0.468699\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036148; batch adversarial loss: 0.454753\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010683; batch adversarial loss: 0.462077\n",
      "epoch 174; iter: 0; batch classifier loss: 0.053949; batch adversarial loss: 0.516896\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012793; batch adversarial loss: 0.527147\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028761; batch adversarial loss: 0.569986\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017789; batch adversarial loss: 0.375210\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037169; batch adversarial loss: 0.444451\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036252; batch adversarial loss: 0.395082\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032280; batch adversarial loss: 0.482214\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012814; batch adversarial loss: 0.401324\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029762; batch adversarial loss: 0.493152\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042756; batch adversarial loss: 0.433081\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017915; batch adversarial loss: 0.445108\n",
      "epoch 185; iter: 0; batch classifier loss: 0.041818; batch adversarial loss: 0.398776\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024809; batch adversarial loss: 0.433745\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020577; batch adversarial loss: 0.370526\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025206; batch adversarial loss: 0.567296\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011080; batch adversarial loss: 0.423075\n",
      "epoch 190; iter: 0; batch classifier loss: 0.068502; batch adversarial loss: 0.426010\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031137; batch adversarial loss: 0.429791\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029002; batch adversarial loss: 0.447384\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021165; batch adversarial loss: 0.447005\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021599; batch adversarial loss: 0.355895\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024198; batch adversarial loss: 0.484822\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012940; batch adversarial loss: 0.408309\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005144; batch adversarial loss: 0.491584\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022205; batch adversarial loss: 0.430485\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012660; batch adversarial loss: 0.382529\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682492; batch adversarial loss: 0.788202\n",
      "epoch 1; iter: 0; batch classifier loss: 0.522955; batch adversarial loss: 0.730986\n",
      "epoch 2; iter: 0; batch classifier loss: 0.557249; batch adversarial loss: 0.672979\n",
      "epoch 3; iter: 0; batch classifier loss: 0.503409; batch adversarial loss: 0.635058\n",
      "epoch 4; iter: 0; batch classifier loss: 0.373070; batch adversarial loss: 0.610688\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313383; batch adversarial loss: 0.561353\n",
      "epoch 6; iter: 0; batch classifier loss: 0.273619; batch adversarial loss: 0.567254\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300901; batch adversarial loss: 0.507771\n",
      "epoch 8; iter: 0; batch classifier loss: 0.293176; batch adversarial loss: 0.523753\n",
      "epoch 9; iter: 0; batch classifier loss: 0.306915; batch adversarial loss: 0.498203\n",
      "epoch 10; iter: 0; batch classifier loss: 0.254800; batch adversarial loss: 0.554608\n",
      "epoch 11; iter: 0; batch classifier loss: 0.320678; batch adversarial loss: 0.537672\n",
      "epoch 12; iter: 0; batch classifier loss: 0.250719; batch adversarial loss: 0.577647\n",
      "epoch 13; iter: 0; batch classifier loss: 0.256638; batch adversarial loss: 0.515194\n",
      "epoch 14; iter: 0; batch classifier loss: 0.318912; batch adversarial loss: 0.502450\n",
      "epoch 15; iter: 0; batch classifier loss: 0.285046; batch adversarial loss: 0.478353\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222496; batch adversarial loss: 0.430000\n",
      "epoch 17; iter: 0; batch classifier loss: 0.178419; batch adversarial loss: 0.510699\n",
      "epoch 18; iter: 0; batch classifier loss: 0.240116; batch adversarial loss: 0.501737\n",
      "epoch 19; iter: 0; batch classifier loss: 0.262566; batch adversarial loss: 0.475751\n",
      "epoch 20; iter: 0; batch classifier loss: 0.174231; batch adversarial loss: 0.528338\n",
      "epoch 21; iter: 0; batch classifier loss: 0.194821; batch adversarial loss: 0.474268\n",
      "epoch 22; iter: 0; batch classifier loss: 0.156525; batch adversarial loss: 0.543949\n",
      "epoch 23; iter: 0; batch classifier loss: 0.170281; batch adversarial loss: 0.466742\n",
      "epoch 24; iter: 0; batch classifier loss: 0.188253; batch adversarial loss: 0.426397\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174307; batch adversarial loss: 0.439108\n",
      "epoch 26; iter: 0; batch classifier loss: 0.236499; batch adversarial loss: 0.426365\n",
      "epoch 27; iter: 0; batch classifier loss: 0.165674; batch adversarial loss: 0.413768\n",
      "epoch 28; iter: 0; batch classifier loss: 0.183232; batch adversarial loss: 0.466978\n",
      "epoch 29; iter: 0; batch classifier loss: 0.162018; batch adversarial loss: 0.518544\n",
      "epoch 30; iter: 0; batch classifier loss: 0.186159; batch adversarial loss: 0.431737\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156682; batch adversarial loss: 0.535944\n",
      "epoch 32; iter: 0; batch classifier loss: 0.135163; batch adversarial loss: 0.441777\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188683; batch adversarial loss: 0.463387\n",
      "epoch 34; iter: 0; batch classifier loss: 0.138704; batch adversarial loss: 0.445813\n",
      "epoch 35; iter: 0; batch classifier loss: 0.070040; batch adversarial loss: 0.519642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.114095; batch adversarial loss: 0.441832\n",
      "epoch 37; iter: 0; batch classifier loss: 0.159329; batch adversarial loss: 0.392491\n",
      "epoch 38; iter: 0; batch classifier loss: 0.175569; batch adversarial loss: 0.435138\n",
      "epoch 39; iter: 0; batch classifier loss: 0.095156; batch adversarial loss: 0.436386\n",
      "epoch 40; iter: 0; batch classifier loss: 0.185023; batch adversarial loss: 0.606328\n",
      "epoch 41; iter: 0; batch classifier loss: 0.127108; batch adversarial loss: 0.446794\n",
      "epoch 42; iter: 0; batch classifier loss: 0.151179; batch adversarial loss: 0.496483\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150187; batch adversarial loss: 0.435043\n",
      "epoch 44; iter: 0; batch classifier loss: 0.139291; batch adversarial loss: 0.496713\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086159; batch adversarial loss: 0.466852\n",
      "epoch 46; iter: 0; batch classifier loss: 0.098529; batch adversarial loss: 0.506503\n",
      "epoch 47; iter: 0; batch classifier loss: 0.134386; batch adversarial loss: 0.355193\n",
      "epoch 48; iter: 0; batch classifier loss: 0.088763; batch adversarial loss: 0.464826\n",
      "epoch 49; iter: 0; batch classifier loss: 0.110470; batch adversarial loss: 0.519278\n",
      "epoch 50; iter: 0; batch classifier loss: 0.105199; batch adversarial loss: 0.474937\n",
      "epoch 51; iter: 0; batch classifier loss: 0.130018; batch adversarial loss: 0.482139\n",
      "epoch 52; iter: 0; batch classifier loss: 0.113319; batch adversarial loss: 0.391681\n",
      "epoch 53; iter: 0; batch classifier loss: 0.120195; batch adversarial loss: 0.532834\n",
      "epoch 54; iter: 0; batch classifier loss: 0.118016; batch adversarial loss: 0.429625\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087749; batch adversarial loss: 0.523639\n",
      "epoch 56; iter: 0; batch classifier loss: 0.137891; batch adversarial loss: 0.468976\n",
      "epoch 57; iter: 0; batch classifier loss: 0.103804; batch adversarial loss: 0.461810\n",
      "epoch 58; iter: 0; batch classifier loss: 0.089372; batch adversarial loss: 0.466040\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087409; batch adversarial loss: 0.537810\n",
      "epoch 60; iter: 0; batch classifier loss: 0.124216; batch adversarial loss: 0.437024\n",
      "epoch 61; iter: 0; batch classifier loss: 0.160499; batch adversarial loss: 0.517634\n",
      "epoch 62; iter: 0; batch classifier loss: 0.096545; batch adversarial loss: 0.495134\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078165; batch adversarial loss: 0.661493\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083893; batch adversarial loss: 0.494901\n",
      "epoch 65; iter: 0; batch classifier loss: 0.098663; batch adversarial loss: 0.456723\n",
      "epoch 66; iter: 0; batch classifier loss: 0.123009; batch adversarial loss: 0.432298\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107748; batch adversarial loss: 0.481663\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076198; batch adversarial loss: 0.382888\n",
      "epoch 69; iter: 0; batch classifier loss: 0.090162; batch adversarial loss: 0.406561\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070068; batch adversarial loss: 0.473013\n",
      "epoch 71; iter: 0; batch classifier loss: 0.134621; batch adversarial loss: 0.420179\n",
      "epoch 72; iter: 0; batch classifier loss: 0.058957; batch adversarial loss: 0.487189\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055433; batch adversarial loss: 0.551018\n",
      "epoch 74; iter: 0; batch classifier loss: 0.077330; batch adversarial loss: 0.403130\n",
      "epoch 75; iter: 0; batch classifier loss: 0.088183; batch adversarial loss: 0.352646\n",
      "epoch 76; iter: 0; batch classifier loss: 0.043916; batch adversarial loss: 0.493334\n",
      "epoch 77; iter: 0; batch classifier loss: 0.077515; batch adversarial loss: 0.427704\n",
      "epoch 78; iter: 0; batch classifier loss: 0.092937; batch adversarial loss: 0.474887\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067620; batch adversarial loss: 0.564213\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075533; batch adversarial loss: 0.429040\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067451; batch adversarial loss: 0.523610\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073664; batch adversarial loss: 0.445037\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074419; batch adversarial loss: 0.490856\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082970; batch adversarial loss: 0.495090\n",
      "epoch 85; iter: 0; batch classifier loss: 0.049618; batch adversarial loss: 0.390242\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061829; batch adversarial loss: 0.493575\n",
      "epoch 87; iter: 0; batch classifier loss: 0.052938; batch adversarial loss: 0.429638\n",
      "epoch 88; iter: 0; batch classifier loss: 0.090376; batch adversarial loss: 0.418393\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081955; batch adversarial loss: 0.456500\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050308; batch adversarial loss: 0.435142\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052586; batch adversarial loss: 0.397258\n",
      "epoch 92; iter: 0; batch classifier loss: 0.037123; batch adversarial loss: 0.468033\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056183; batch adversarial loss: 0.510259\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062824; batch adversarial loss: 0.473302\n",
      "epoch 95; iter: 0; batch classifier loss: 0.033845; batch adversarial loss: 0.447311\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035509; batch adversarial loss: 0.456604\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037095; batch adversarial loss: 0.408645\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039651; batch adversarial loss: 0.515990\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042536; batch adversarial loss: 0.420461\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045360; batch adversarial loss: 0.491006\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049169; batch adversarial loss: 0.548773\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051499; batch adversarial loss: 0.510381\n",
      "epoch 103; iter: 0; batch classifier loss: 0.027485; batch adversarial loss: 0.459118\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034323; batch adversarial loss: 0.443374\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051379; batch adversarial loss: 0.456135\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052778; batch adversarial loss: 0.430706\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025966; batch adversarial loss: 0.459237\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036550; batch adversarial loss: 0.550151\n",
      "epoch 109; iter: 0; batch classifier loss: 0.011749; batch adversarial loss: 0.401886\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036549; batch adversarial loss: 0.457009\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055810; batch adversarial loss: 0.518605\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053027; batch adversarial loss: 0.494471\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038426; batch adversarial loss: 0.495501\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032018; batch adversarial loss: 0.522742\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049115; batch adversarial loss: 0.571008\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034336; batch adversarial loss: 0.467320\n",
      "epoch 117; iter: 0; batch classifier loss: 0.005816; batch adversarial loss: 0.539887\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035081; batch adversarial loss: 0.489806\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023641; batch adversarial loss: 0.463102\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051772; batch adversarial loss: 0.454538\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036440; batch adversarial loss: 0.439403\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036708; batch adversarial loss: 0.455240\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019502; batch adversarial loss: 0.469737\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035900; batch adversarial loss: 0.560173\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047121; batch adversarial loss: 0.461759\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024623; batch adversarial loss: 0.496616\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027681; batch adversarial loss: 0.512634\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054073; batch adversarial loss: 0.505093\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028778; batch adversarial loss: 0.465271\n",
      "epoch 130; iter: 0; batch classifier loss: 0.013802; batch adversarial loss: 0.395850\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025152; batch adversarial loss: 0.453813\n",
      "epoch 132; iter: 0; batch classifier loss: 0.013776; batch adversarial loss: 0.419472\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029483; batch adversarial loss: 0.463094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.024538; batch adversarial loss: 0.429421\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027324; batch adversarial loss: 0.476767\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039072; batch adversarial loss: 0.497505\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052312; batch adversarial loss: 0.441899\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053969; batch adversarial loss: 0.379719\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014630; batch adversarial loss: 0.572451\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017806; batch adversarial loss: 0.498307\n",
      "epoch 141; iter: 0; batch classifier loss: 0.067229; batch adversarial loss: 0.475439\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017863; batch adversarial loss: 0.472295\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035436; batch adversarial loss: 0.504051\n",
      "epoch 144; iter: 0; batch classifier loss: 0.003808; batch adversarial loss: 0.517881\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031932; batch adversarial loss: 0.419702\n",
      "epoch 146; iter: 0; batch classifier loss: 0.014414; batch adversarial loss: 0.471565\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015552; batch adversarial loss: 0.500267\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030277; batch adversarial loss: 0.532621\n",
      "epoch 149; iter: 0; batch classifier loss: 0.007543; batch adversarial loss: 0.538244\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036546; batch adversarial loss: 0.472046\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032621; batch adversarial loss: 0.419951\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016385; batch adversarial loss: 0.505105\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023245; batch adversarial loss: 0.418245\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018378; batch adversarial loss: 0.397896\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019387; batch adversarial loss: 0.481563\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010681; batch adversarial loss: 0.466910\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034746; batch adversarial loss: 0.483682\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014869; batch adversarial loss: 0.469651\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020001; batch adversarial loss: 0.414533\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012699; batch adversarial loss: 0.410738\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039001; batch adversarial loss: 0.455893\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010509; batch adversarial loss: 0.428685\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025467; batch adversarial loss: 0.458307\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028970; batch adversarial loss: 0.479849\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022855; batch adversarial loss: 0.454561\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017876; batch adversarial loss: 0.381010\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019228; batch adversarial loss: 0.515047\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031562; batch adversarial loss: 0.478679\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026785; batch adversarial loss: 0.599863\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024482; batch adversarial loss: 0.444247\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012350; batch adversarial loss: 0.570540\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016956; batch adversarial loss: 0.431195\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008786; batch adversarial loss: 0.502923\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012739; batch adversarial loss: 0.473432\n",
      "epoch 175; iter: 0; batch classifier loss: 0.055538; batch adversarial loss: 0.424514\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019346; batch adversarial loss: 0.460831\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011848; batch adversarial loss: 0.443578\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006973; batch adversarial loss: 0.519820\n",
      "epoch 179; iter: 0; batch classifier loss: 0.049577; batch adversarial loss: 0.413454\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019538; batch adversarial loss: 0.314254\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011963; batch adversarial loss: 0.555716\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017411; batch adversarial loss: 0.422246\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011748; batch adversarial loss: 0.475361\n",
      "epoch 184; iter: 0; batch classifier loss: 0.041534; batch adversarial loss: 0.587912\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020193; batch adversarial loss: 0.543027\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007646; batch adversarial loss: 0.411560\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024909; batch adversarial loss: 0.500037\n",
      "epoch 188; iter: 0; batch classifier loss: 0.037504; batch adversarial loss: 0.445714\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021455; batch adversarial loss: 0.438558\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036727; batch adversarial loss: 0.427765\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026318; batch adversarial loss: 0.412046\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037746; batch adversarial loss: 0.505388\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022528; batch adversarial loss: 0.457271\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027213; batch adversarial loss: 0.495168\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010594; batch adversarial loss: 0.413735\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008492; batch adversarial loss: 0.436549\n",
      "epoch 197; iter: 0; batch classifier loss: 0.002487; batch adversarial loss: 0.472781\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004691; batch adversarial loss: 0.466158\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021002; batch adversarial loss: 0.406581\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676303; batch adversarial loss: 0.675223\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433575; batch adversarial loss: 0.606642\n",
      "epoch 2; iter: 0; batch classifier loss: 0.358588; batch adversarial loss: 0.609402\n",
      "epoch 3; iter: 0; batch classifier loss: 0.317907; batch adversarial loss: 0.559150\n",
      "epoch 4; iter: 0; batch classifier loss: 0.387041; batch adversarial loss: 0.553463\n",
      "epoch 5; iter: 0; batch classifier loss: 0.374503; batch adversarial loss: 0.544642\n",
      "epoch 6; iter: 0; batch classifier loss: 0.359357; batch adversarial loss: 0.553560\n",
      "epoch 7; iter: 0; batch classifier loss: 0.289537; batch adversarial loss: 0.527813\n",
      "epoch 8; iter: 0; batch classifier loss: 0.266555; batch adversarial loss: 0.525687\n",
      "epoch 9; iter: 0; batch classifier loss: 0.308495; batch adversarial loss: 0.501377\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264941; batch adversarial loss: 0.477683\n",
      "epoch 11; iter: 0; batch classifier loss: 0.251904; batch adversarial loss: 0.510072\n",
      "epoch 12; iter: 0; batch classifier loss: 0.262860; batch adversarial loss: 0.519454\n",
      "epoch 13; iter: 0; batch classifier loss: 0.228603; batch adversarial loss: 0.489645\n",
      "epoch 14; iter: 0; batch classifier loss: 0.206857; batch adversarial loss: 0.527214\n",
      "epoch 15; iter: 0; batch classifier loss: 0.154587; batch adversarial loss: 0.475120\n",
      "epoch 16; iter: 0; batch classifier loss: 0.197603; batch adversarial loss: 0.417751\n",
      "epoch 17; iter: 0; batch classifier loss: 0.199487; batch adversarial loss: 0.497251\n",
      "epoch 18; iter: 0; batch classifier loss: 0.147661; batch adversarial loss: 0.465515\n",
      "epoch 19; iter: 0; batch classifier loss: 0.198054; batch adversarial loss: 0.445762\n",
      "epoch 20; iter: 0; batch classifier loss: 0.129061; batch adversarial loss: 0.386830\n",
      "epoch 21; iter: 0; batch classifier loss: 0.164573; batch adversarial loss: 0.406294\n",
      "epoch 22; iter: 0; batch classifier loss: 0.137694; batch adversarial loss: 0.509079\n",
      "epoch 23; iter: 0; batch classifier loss: 0.138214; batch adversarial loss: 0.527263\n",
      "epoch 24; iter: 0; batch classifier loss: 0.128118; batch adversarial loss: 0.449185\n",
      "epoch 25; iter: 0; batch classifier loss: 0.167479; batch adversarial loss: 0.459567\n",
      "epoch 26; iter: 0; batch classifier loss: 0.110853; batch adversarial loss: 0.534585\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154962; batch adversarial loss: 0.480286\n",
      "epoch 28; iter: 0; batch classifier loss: 0.073219; batch adversarial loss: 0.478168\n",
      "epoch 29; iter: 0; batch classifier loss: 0.151502; batch adversarial loss: 0.516782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.130371; batch adversarial loss: 0.417751\n",
      "epoch 31; iter: 0; batch classifier loss: 0.142629; batch adversarial loss: 0.431576\n",
      "epoch 32; iter: 0; batch classifier loss: 0.103435; batch adversarial loss: 0.349854\n",
      "epoch 33; iter: 0; batch classifier loss: 0.079248; batch adversarial loss: 0.564849\n",
      "epoch 34; iter: 0; batch classifier loss: 0.093242; batch adversarial loss: 0.430048\n",
      "epoch 35; iter: 0; batch classifier loss: 0.117263; batch adversarial loss: 0.465602\n",
      "epoch 36; iter: 0; batch classifier loss: 0.114561; batch adversarial loss: 0.640110\n",
      "epoch 37; iter: 0; batch classifier loss: 0.080324; batch adversarial loss: 0.487135\n",
      "epoch 38; iter: 0; batch classifier loss: 0.095141; batch adversarial loss: 0.474758\n",
      "epoch 39; iter: 0; batch classifier loss: 0.093164; batch adversarial loss: 0.442970\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103200; batch adversarial loss: 0.437978\n",
      "epoch 41; iter: 0; batch classifier loss: 0.068639; batch adversarial loss: 0.472679\n",
      "epoch 42; iter: 0; batch classifier loss: 0.094441; batch adversarial loss: 0.441250\n",
      "epoch 43; iter: 0; batch classifier loss: 0.120719; batch adversarial loss: 0.449389\n",
      "epoch 44; iter: 0; batch classifier loss: 0.071174; batch adversarial loss: 0.480435\n",
      "epoch 45; iter: 0; batch classifier loss: 0.085620; batch adversarial loss: 0.481101\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117104; batch adversarial loss: 0.464632\n",
      "epoch 47; iter: 0; batch classifier loss: 0.064077; batch adversarial loss: 0.432182\n",
      "epoch 48; iter: 0; batch classifier loss: 0.063710; batch adversarial loss: 0.476871\n",
      "epoch 49; iter: 0; batch classifier loss: 0.066045; batch adversarial loss: 0.507111\n",
      "epoch 50; iter: 0; batch classifier loss: 0.064655; batch adversarial loss: 0.514068\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083416; batch adversarial loss: 0.435856\n",
      "epoch 52; iter: 0; batch classifier loss: 0.085970; batch adversarial loss: 0.447801\n",
      "epoch 53; iter: 0; batch classifier loss: 0.064550; batch adversarial loss: 0.457576\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099664; batch adversarial loss: 0.332369\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086893; batch adversarial loss: 0.415235\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083293; batch adversarial loss: 0.496190\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073509; batch adversarial loss: 0.523192\n",
      "epoch 58; iter: 0; batch classifier loss: 0.113960; batch adversarial loss: 0.532551\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067016; batch adversarial loss: 0.494741\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097340; batch adversarial loss: 0.519736\n",
      "epoch 61; iter: 0; batch classifier loss: 0.112793; batch adversarial loss: 0.455032\n",
      "epoch 62; iter: 0; batch classifier loss: 0.118994; batch adversarial loss: 0.481006\n",
      "epoch 63; iter: 0; batch classifier loss: 0.071383; batch adversarial loss: 0.411942\n",
      "epoch 64; iter: 0; batch classifier loss: 0.110082; batch adversarial loss: 0.342678\n",
      "epoch 65; iter: 0; batch classifier loss: 0.053012; batch adversarial loss: 0.361461\n",
      "epoch 66; iter: 0; batch classifier loss: 0.098018; batch adversarial loss: 0.468053\n",
      "epoch 67; iter: 0; batch classifier loss: 0.103099; batch adversarial loss: 0.485234\n",
      "epoch 68; iter: 0; batch classifier loss: 0.075617; batch adversarial loss: 0.348070\n",
      "epoch 69; iter: 0; batch classifier loss: 0.068746; batch adversarial loss: 0.427353\n",
      "epoch 70; iter: 0; batch classifier loss: 0.054811; batch adversarial loss: 0.563044\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071862; batch adversarial loss: 0.503970\n",
      "epoch 72; iter: 0; batch classifier loss: 0.069278; batch adversarial loss: 0.457221\n",
      "epoch 73; iter: 0; batch classifier loss: 0.073419; batch adversarial loss: 0.383177\n",
      "epoch 74; iter: 0; batch classifier loss: 0.077061; batch adversarial loss: 0.474781\n",
      "epoch 75; iter: 0; batch classifier loss: 0.025234; batch adversarial loss: 0.441458\n",
      "epoch 76; iter: 0; batch classifier loss: 0.111322; batch adversarial loss: 0.411031\n",
      "epoch 77; iter: 0; batch classifier loss: 0.083539; batch adversarial loss: 0.520572\n",
      "epoch 78; iter: 0; batch classifier loss: 0.043499; batch adversarial loss: 0.493182\n",
      "epoch 79; iter: 0; batch classifier loss: 0.049397; batch adversarial loss: 0.472676\n",
      "epoch 80; iter: 0; batch classifier loss: 0.109115; batch adversarial loss: 0.461773\n",
      "epoch 81; iter: 0; batch classifier loss: 0.060492; batch adversarial loss: 0.365577\n",
      "epoch 82; iter: 0; batch classifier loss: 0.097356; batch adversarial loss: 0.354921\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080227; batch adversarial loss: 0.504608\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051666; batch adversarial loss: 0.420598\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061158; batch adversarial loss: 0.421766\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072142; batch adversarial loss: 0.447111\n",
      "epoch 87; iter: 0; batch classifier loss: 0.075480; batch adversarial loss: 0.495402\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075600; batch adversarial loss: 0.437963\n",
      "epoch 89; iter: 0; batch classifier loss: 0.062611; batch adversarial loss: 0.442252\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057231; batch adversarial loss: 0.380215\n",
      "epoch 91; iter: 0; batch classifier loss: 0.061969; batch adversarial loss: 0.374040\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051177; batch adversarial loss: 0.393595\n",
      "epoch 93; iter: 0; batch classifier loss: 0.070278; batch adversarial loss: 0.482589\n",
      "epoch 94; iter: 0; batch classifier loss: 0.031977; batch adversarial loss: 0.466631\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039894; batch adversarial loss: 0.484079\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041040; batch adversarial loss: 0.458664\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071001; batch adversarial loss: 0.434397\n",
      "epoch 98; iter: 0; batch classifier loss: 0.038618; batch adversarial loss: 0.424863\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046735; batch adversarial loss: 0.379513\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074104; batch adversarial loss: 0.444887\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046191; batch adversarial loss: 0.456776\n",
      "epoch 102; iter: 0; batch classifier loss: 0.100811; batch adversarial loss: 0.442092\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046732; batch adversarial loss: 0.425284\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053942; batch adversarial loss: 0.395891\n",
      "epoch 105; iter: 0; batch classifier loss: 0.039756; batch adversarial loss: 0.424469\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040861; batch adversarial loss: 0.430951\n",
      "epoch 107; iter: 0; batch classifier loss: 0.102088; batch adversarial loss: 0.415894\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037519; batch adversarial loss: 0.616045\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061907; batch adversarial loss: 0.456634\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030289; batch adversarial loss: 0.493877\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047113; batch adversarial loss: 0.517991\n",
      "epoch 112; iter: 0; batch classifier loss: 0.061572; batch adversarial loss: 0.396617\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039119; batch adversarial loss: 0.403488\n",
      "epoch 114; iter: 0; batch classifier loss: 0.009197; batch adversarial loss: 0.373120\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037619; batch adversarial loss: 0.534537\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052750; batch adversarial loss: 0.588612\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060661; batch adversarial loss: 0.504958\n",
      "epoch 118; iter: 0; batch classifier loss: 0.027015; batch adversarial loss: 0.501771\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073560; batch adversarial loss: 0.520409\n",
      "epoch 120; iter: 0; batch classifier loss: 0.014087; batch adversarial loss: 0.539604\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065441; batch adversarial loss: 0.420712\n",
      "epoch 122; iter: 0; batch classifier loss: 0.071851; batch adversarial loss: 0.500891\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036500; batch adversarial loss: 0.442303\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041510; batch adversarial loss: 0.416909\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029319; batch adversarial loss: 0.423310\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063331; batch adversarial loss: 0.478148\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031688; batch adversarial loss: 0.403591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.039797; batch adversarial loss: 0.479816\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041511; batch adversarial loss: 0.460729\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025951; batch adversarial loss: 0.460240\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031461; batch adversarial loss: 0.507477\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050861; batch adversarial loss: 0.554521\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040595; batch adversarial loss: 0.517838\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034364; batch adversarial loss: 0.454883\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018971; batch adversarial loss: 0.435035\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026076; batch adversarial loss: 0.531711\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054214; batch adversarial loss: 0.518423\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044572; batch adversarial loss: 0.463733\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038009; batch adversarial loss: 0.437968\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030592; batch adversarial loss: 0.457657\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022817; batch adversarial loss: 0.428870\n",
      "epoch 142; iter: 0; batch classifier loss: 0.056716; batch adversarial loss: 0.430219\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015338; batch adversarial loss: 0.489495\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032555; batch adversarial loss: 0.523709\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015514; batch adversarial loss: 0.434391\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024160; batch adversarial loss: 0.420240\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022837; batch adversarial loss: 0.493883\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043817; batch adversarial loss: 0.462524\n",
      "epoch 149; iter: 0; batch classifier loss: 0.057038; batch adversarial loss: 0.527150\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025342; batch adversarial loss: 0.449140\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018975; batch adversarial loss: 0.487681\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044112; batch adversarial loss: 0.384344\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028369; batch adversarial loss: 0.472937\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027060; batch adversarial loss: 0.533073\n",
      "epoch 155; iter: 0; batch classifier loss: 0.047345; batch adversarial loss: 0.427203\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017736; batch adversarial loss: 0.406287\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031060; batch adversarial loss: 0.340658\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034614; batch adversarial loss: 0.420207\n",
      "epoch 159; iter: 0; batch classifier loss: 0.074143; batch adversarial loss: 0.425067\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035078; batch adversarial loss: 0.488062\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019789; batch adversarial loss: 0.504952\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028267; batch adversarial loss: 0.371949\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023685; batch adversarial loss: 0.327223\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016945; batch adversarial loss: 0.496070\n",
      "epoch 165; iter: 0; batch classifier loss: 0.052499; batch adversarial loss: 0.467818\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023104; batch adversarial loss: 0.454447\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025365; batch adversarial loss: 0.427046\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041330; batch adversarial loss: 0.401321\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015363; batch adversarial loss: 0.547951\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014065; batch adversarial loss: 0.420899\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026113; batch adversarial loss: 0.471969\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033511; batch adversarial loss: 0.420078\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026929; batch adversarial loss: 0.373255\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013506; batch adversarial loss: 0.432117\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030330; batch adversarial loss: 0.527054\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015927; batch adversarial loss: 0.446242\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027998; batch adversarial loss: 0.450283\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033421; batch adversarial loss: 0.567277\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028130; batch adversarial loss: 0.536488\n",
      "epoch 180; iter: 0; batch classifier loss: 0.036875; batch adversarial loss: 0.446786\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026029; batch adversarial loss: 0.485021\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025739; batch adversarial loss: 0.355730\n",
      "epoch 183; iter: 0; batch classifier loss: 0.047000; batch adversarial loss: 0.446087\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032769; batch adversarial loss: 0.479405\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017934; batch adversarial loss: 0.491046\n",
      "epoch 186; iter: 0; batch classifier loss: 0.051115; batch adversarial loss: 0.418207\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018927; batch adversarial loss: 0.471549\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014428; batch adversarial loss: 0.480326\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008702; batch adversarial loss: 0.480114\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029155; batch adversarial loss: 0.411905\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011457; batch adversarial loss: 0.421972\n",
      "epoch 192; iter: 0; batch classifier loss: 0.093837; batch adversarial loss: 0.387896\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032550; batch adversarial loss: 0.386699\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028207; batch adversarial loss: 0.403396\n",
      "epoch 195; iter: 0; batch classifier loss: 0.062215; batch adversarial loss: 0.551388\n",
      "epoch 196; iter: 0; batch classifier loss: 0.038989; batch adversarial loss: 0.368139\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026469; batch adversarial loss: 0.448792\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025521; batch adversarial loss: 0.518852\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033659; batch adversarial loss: 0.509812\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696827; batch adversarial loss: 0.603899\n",
      "epoch 1; iter: 0; batch classifier loss: 0.486651; batch adversarial loss: 0.619614\n",
      "epoch 2; iter: 0; batch classifier loss: 0.314840; batch adversarial loss: 0.585646\n",
      "epoch 3; iter: 0; batch classifier loss: 0.367551; batch adversarial loss: 0.545328\n",
      "epoch 4; iter: 0; batch classifier loss: 0.269055; batch adversarial loss: 0.558783\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343312; batch adversarial loss: 0.552194\n",
      "epoch 6; iter: 0; batch classifier loss: 0.298107; batch adversarial loss: 0.462118\n",
      "epoch 7; iter: 0; batch classifier loss: 0.249177; batch adversarial loss: 0.533463\n",
      "epoch 8; iter: 0; batch classifier loss: 0.361973; batch adversarial loss: 0.522057\n",
      "epoch 9; iter: 0; batch classifier loss: 0.179371; batch adversarial loss: 0.496686\n",
      "epoch 10; iter: 0; batch classifier loss: 0.241482; batch adversarial loss: 0.498102\n",
      "epoch 11; iter: 0; batch classifier loss: 0.299590; batch adversarial loss: 0.552700\n",
      "epoch 12; iter: 0; batch classifier loss: 0.196120; batch adversarial loss: 0.536777\n",
      "epoch 13; iter: 0; batch classifier loss: 0.314573; batch adversarial loss: 0.439136\n",
      "epoch 14; iter: 0; batch classifier loss: 0.169891; batch adversarial loss: 0.441553\n",
      "epoch 15; iter: 0; batch classifier loss: 0.239015; batch adversarial loss: 0.513542\n",
      "epoch 16; iter: 0; batch classifier loss: 0.158373; batch adversarial loss: 0.488416\n",
      "epoch 17; iter: 0; batch classifier loss: 0.165093; batch adversarial loss: 0.493903\n",
      "epoch 18; iter: 0; batch classifier loss: 0.279019; batch adversarial loss: 0.536063\n",
      "epoch 19; iter: 0; batch classifier loss: 0.254748; batch adversarial loss: 0.544919\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220828; batch adversarial loss: 0.559396\n",
      "epoch 21; iter: 0; batch classifier loss: 0.163201; batch adversarial loss: 0.433582\n",
      "epoch 22; iter: 0; batch classifier loss: 0.222904; batch adversarial loss: 0.530476\n",
      "epoch 23; iter: 0; batch classifier loss: 0.192157; batch adversarial loss: 0.426240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.275107; batch adversarial loss: 0.516072\n",
      "epoch 25; iter: 0; batch classifier loss: 0.255420; batch adversarial loss: 0.567951\n",
      "epoch 26; iter: 0; batch classifier loss: 0.284577; batch adversarial loss: 0.535458\n",
      "epoch 27; iter: 0; batch classifier loss: 0.287165; batch adversarial loss: 0.488626\n",
      "epoch 28; iter: 0; batch classifier loss: 0.300882; batch adversarial loss: 0.424023\n",
      "epoch 29; iter: 0; batch classifier loss: 0.342686; batch adversarial loss: 0.476940\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205577; batch adversarial loss: 0.390180\n",
      "epoch 31; iter: 0; batch classifier loss: 0.161149; batch adversarial loss: 0.414093\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140070; batch adversarial loss: 0.407275\n",
      "epoch 33; iter: 0; batch classifier loss: 0.113357; batch adversarial loss: 0.480784\n",
      "epoch 34; iter: 0; batch classifier loss: 0.086708; batch adversarial loss: 0.535760\n",
      "epoch 35; iter: 0; batch classifier loss: 0.101902; batch adversarial loss: 0.489988\n",
      "epoch 36; iter: 0; batch classifier loss: 0.062112; batch adversarial loss: 0.492785\n",
      "epoch 37; iter: 0; batch classifier loss: 0.058118; batch adversarial loss: 0.534286\n",
      "epoch 38; iter: 0; batch classifier loss: 0.128788; batch adversarial loss: 0.517205\n",
      "epoch 39; iter: 0; batch classifier loss: 0.096154; batch adversarial loss: 0.447480\n",
      "epoch 40; iter: 0; batch classifier loss: 0.133631; batch adversarial loss: 0.446688\n",
      "epoch 41; iter: 0; batch classifier loss: 0.059068; batch adversarial loss: 0.504823\n",
      "epoch 42; iter: 0; batch classifier loss: 0.123746; batch adversarial loss: 0.586879\n",
      "epoch 43; iter: 0; batch classifier loss: 0.135239; batch adversarial loss: 0.489658\n",
      "epoch 44; iter: 0; batch classifier loss: 0.089288; batch adversarial loss: 0.374107\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117374; batch adversarial loss: 0.398526\n",
      "epoch 46; iter: 0; batch classifier loss: 0.094967; batch adversarial loss: 0.457709\n",
      "epoch 47; iter: 0; batch classifier loss: 0.080818; batch adversarial loss: 0.415701\n",
      "epoch 48; iter: 0; batch classifier loss: 0.103475; batch adversarial loss: 0.457024\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096933; batch adversarial loss: 0.483382\n",
      "epoch 50; iter: 0; batch classifier loss: 0.059487; batch adversarial loss: 0.536504\n",
      "epoch 51; iter: 0; batch classifier loss: 0.087012; batch adversarial loss: 0.501377\n",
      "epoch 52; iter: 0; batch classifier loss: 0.085893; batch adversarial loss: 0.484852\n",
      "epoch 53; iter: 0; batch classifier loss: 0.092004; batch adversarial loss: 0.574538\n",
      "epoch 54; iter: 0; batch classifier loss: 0.088167; batch adversarial loss: 0.442473\n",
      "epoch 55; iter: 0; batch classifier loss: 0.080928; batch adversarial loss: 0.399127\n",
      "epoch 56; iter: 0; batch classifier loss: 0.057197; batch adversarial loss: 0.504405\n",
      "epoch 57; iter: 0; batch classifier loss: 0.051612; batch adversarial loss: 0.426896\n",
      "epoch 58; iter: 0; batch classifier loss: 0.083651; batch adversarial loss: 0.471543\n",
      "epoch 59; iter: 0; batch classifier loss: 0.065952; batch adversarial loss: 0.434761\n",
      "epoch 60; iter: 0; batch classifier loss: 0.073325; batch adversarial loss: 0.554232\n",
      "epoch 61; iter: 0; batch classifier loss: 0.108188; batch adversarial loss: 0.450593\n",
      "epoch 62; iter: 0; batch classifier loss: 0.058794; batch adversarial loss: 0.391914\n",
      "epoch 63; iter: 0; batch classifier loss: 0.115671; batch adversarial loss: 0.310318\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078828; batch adversarial loss: 0.477034\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077019; batch adversarial loss: 0.494429\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078196; batch adversarial loss: 0.520921\n",
      "epoch 67; iter: 0; batch classifier loss: 0.040239; batch adversarial loss: 0.458219\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061792; batch adversarial loss: 0.509394\n",
      "epoch 69; iter: 0; batch classifier loss: 0.057412; batch adversarial loss: 0.360698\n",
      "epoch 70; iter: 0; batch classifier loss: 0.040762; batch adversarial loss: 0.536547\n",
      "epoch 71; iter: 0; batch classifier loss: 0.032637; batch adversarial loss: 0.406718\n",
      "epoch 72; iter: 0; batch classifier loss: 0.101558; batch adversarial loss: 0.396875\n",
      "epoch 73; iter: 0; batch classifier loss: 0.066397; batch adversarial loss: 0.457733\n",
      "epoch 74; iter: 0; batch classifier loss: 0.045450; batch adversarial loss: 0.483464\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076059; batch adversarial loss: 0.400333\n",
      "epoch 76; iter: 0; batch classifier loss: 0.080778; batch adversarial loss: 0.387982\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067655; batch adversarial loss: 0.471228\n",
      "epoch 78; iter: 0; batch classifier loss: 0.069094; batch adversarial loss: 0.458606\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064083; batch adversarial loss: 0.443599\n",
      "epoch 80; iter: 0; batch classifier loss: 0.049549; batch adversarial loss: 0.461529\n",
      "epoch 81; iter: 0; batch classifier loss: 0.051036; batch adversarial loss: 0.426378\n",
      "epoch 82; iter: 0; batch classifier loss: 0.039527; batch adversarial loss: 0.469893\n",
      "epoch 83; iter: 0; batch classifier loss: 0.051186; batch adversarial loss: 0.488935\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051727; batch adversarial loss: 0.572076\n",
      "epoch 85; iter: 0; batch classifier loss: 0.062936; batch adversarial loss: 0.445742\n",
      "epoch 86; iter: 0; batch classifier loss: 0.031201; batch adversarial loss: 0.578759\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082189; batch adversarial loss: 0.426475\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070525; batch adversarial loss: 0.419369\n",
      "epoch 89; iter: 0; batch classifier loss: 0.036053; batch adversarial loss: 0.386344\n",
      "epoch 90; iter: 0; batch classifier loss: 0.084827; batch adversarial loss: 0.544882\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075023; batch adversarial loss: 0.498647\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051931; batch adversarial loss: 0.475901\n",
      "epoch 93; iter: 0; batch classifier loss: 0.045822; batch adversarial loss: 0.403035\n",
      "epoch 94; iter: 0; batch classifier loss: 0.080498; batch adversarial loss: 0.479777\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043584; batch adversarial loss: 0.437216\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045127; batch adversarial loss: 0.583642\n",
      "epoch 97; iter: 0; batch classifier loss: 0.027935; batch adversarial loss: 0.431090\n",
      "epoch 98; iter: 0; batch classifier loss: 0.078957; batch adversarial loss: 0.439276\n",
      "epoch 99; iter: 0; batch classifier loss: 0.029784; batch adversarial loss: 0.492243\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065287; batch adversarial loss: 0.376324\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044902; batch adversarial loss: 0.469118\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053620; batch adversarial loss: 0.467883\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036747; batch adversarial loss: 0.407355\n",
      "epoch 104; iter: 0; batch classifier loss: 0.054344; batch adversarial loss: 0.357931\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034605; batch adversarial loss: 0.385511\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058490; batch adversarial loss: 0.419646\n",
      "epoch 107; iter: 0; batch classifier loss: 0.021680; batch adversarial loss: 0.449049\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042108; batch adversarial loss: 0.510555\n",
      "epoch 109; iter: 0; batch classifier loss: 0.116734; batch adversarial loss: 0.318898\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038945; batch adversarial loss: 0.462758\n",
      "epoch 111; iter: 0; batch classifier loss: 0.016641; batch adversarial loss: 0.450136\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041256; batch adversarial loss: 0.416360\n",
      "epoch 113; iter: 0; batch classifier loss: 0.060667; batch adversarial loss: 0.471388\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046611; batch adversarial loss: 0.427006\n",
      "epoch 115; iter: 0; batch classifier loss: 0.073587; batch adversarial loss: 0.437265\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040567; batch adversarial loss: 0.355009\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042094; batch adversarial loss: 0.470241\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032786; batch adversarial loss: 0.563545\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053667; batch adversarial loss: 0.462185\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024031; batch adversarial loss: 0.460413\n",
      "epoch 121; iter: 0; batch classifier loss: 0.056036; batch adversarial loss: 0.423610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.055629; batch adversarial loss: 0.551520\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024473; batch adversarial loss: 0.428495\n",
      "epoch 124; iter: 0; batch classifier loss: 0.071653; batch adversarial loss: 0.494330\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048161; batch adversarial loss: 0.453168\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039684; batch adversarial loss: 0.403789\n",
      "epoch 127; iter: 0; batch classifier loss: 0.072974; batch adversarial loss: 0.394995\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018131; batch adversarial loss: 0.486729\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048452; batch adversarial loss: 0.516153\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033388; batch adversarial loss: 0.396727\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049563; batch adversarial loss: 0.484823\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039209; batch adversarial loss: 0.557374\n",
      "epoch 133; iter: 0; batch classifier loss: 0.079397; batch adversarial loss: 0.490355\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042288; batch adversarial loss: 0.437879\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037623; batch adversarial loss: 0.450770\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040725; batch adversarial loss: 0.476045\n",
      "epoch 137; iter: 0; batch classifier loss: 0.063315; batch adversarial loss: 0.530335\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034082; batch adversarial loss: 0.472671\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014637; batch adversarial loss: 0.460569\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025703; batch adversarial loss: 0.437923\n",
      "epoch 141; iter: 0; batch classifier loss: 0.068010; batch adversarial loss: 0.437575\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035603; batch adversarial loss: 0.542760\n",
      "epoch 143; iter: 0; batch classifier loss: 0.045064; batch adversarial loss: 0.313558\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030369; batch adversarial loss: 0.496807\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014153; batch adversarial loss: 0.379878\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037093; batch adversarial loss: 0.556944\n",
      "epoch 147; iter: 0; batch classifier loss: 0.062138; batch adversarial loss: 0.456694\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036144; batch adversarial loss: 0.411929\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028063; batch adversarial loss: 0.465179\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039338; batch adversarial loss: 0.466141\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017614; batch adversarial loss: 0.503604\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027806; batch adversarial loss: 0.550577\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023782; batch adversarial loss: 0.419890\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040621; batch adversarial loss: 0.426767\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028972; batch adversarial loss: 0.402384\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031406; batch adversarial loss: 0.454611\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018910; batch adversarial loss: 0.498673\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014746; batch adversarial loss: 0.370664\n",
      "epoch 159; iter: 0; batch classifier loss: 0.046124; batch adversarial loss: 0.420369\n",
      "epoch 160; iter: 0; batch classifier loss: 0.006356; batch adversarial loss: 0.516966\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036275; batch adversarial loss: 0.420157\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009092; batch adversarial loss: 0.465816\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021489; batch adversarial loss: 0.423064\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043409; batch adversarial loss: 0.450862\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016242; batch adversarial loss: 0.449673\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021165; batch adversarial loss: 0.469061\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024306; batch adversarial loss: 0.475273\n",
      "epoch 168; iter: 0; batch classifier loss: 0.046012; batch adversarial loss: 0.517126\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036399; batch adversarial loss: 0.452409\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011705; batch adversarial loss: 0.485396\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034948; batch adversarial loss: 0.439585\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030130; batch adversarial loss: 0.349451\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033707; batch adversarial loss: 0.460021\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023012; batch adversarial loss: 0.391374\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042654; batch adversarial loss: 0.510451\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018787; batch adversarial loss: 0.425360\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022228; batch adversarial loss: 0.390903\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034875; batch adversarial loss: 0.492448\n",
      "epoch 179; iter: 0; batch classifier loss: 0.057869; batch adversarial loss: 0.485815\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016561; batch adversarial loss: 0.511395\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035991; batch adversarial loss: 0.386102\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026154; batch adversarial loss: 0.425733\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017524; batch adversarial loss: 0.475273\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014001; batch adversarial loss: 0.400551\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023824; batch adversarial loss: 0.439448\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022334; batch adversarial loss: 0.350671\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011638; batch adversarial loss: 0.421414\n",
      "epoch 188; iter: 0; batch classifier loss: 0.037223; batch adversarial loss: 0.414917\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021267; batch adversarial loss: 0.490017\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014376; batch adversarial loss: 0.464046\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034731; batch adversarial loss: 0.459157\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014347; batch adversarial loss: 0.435658\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009011; batch adversarial loss: 0.452586\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007981; batch adversarial loss: 0.512577\n",
      "epoch 195; iter: 0; batch classifier loss: 0.057408; batch adversarial loss: 0.484962\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020523; batch adversarial loss: 0.422122\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013026; batch adversarial loss: 0.420365\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014583; batch adversarial loss: 0.430041\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035661; batch adversarial loss: 0.405550\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707743; batch adversarial loss: 0.761684\n",
      "epoch 1; iter: 0; batch classifier loss: 0.415979; batch adversarial loss: 0.723256\n",
      "epoch 2; iter: 0; batch classifier loss: 0.343010; batch adversarial loss: 0.681584\n",
      "epoch 3; iter: 0; batch classifier loss: 0.306969; batch adversarial loss: 0.656375\n",
      "epoch 4; iter: 0; batch classifier loss: 0.404193; batch adversarial loss: 0.635023\n",
      "epoch 5; iter: 0; batch classifier loss: 0.390848; batch adversarial loss: 0.615133\n",
      "epoch 6; iter: 0; batch classifier loss: 0.285851; batch adversarial loss: 0.580339\n",
      "epoch 7; iter: 0; batch classifier loss: 0.235279; batch adversarial loss: 0.565021\n",
      "epoch 8; iter: 0; batch classifier loss: 0.349467; batch adversarial loss: 0.508427\n",
      "epoch 9; iter: 0; batch classifier loss: 0.294552; batch adversarial loss: 0.474958\n",
      "epoch 10; iter: 0; batch classifier loss: 0.317931; batch adversarial loss: 0.477614\n",
      "epoch 11; iter: 0; batch classifier loss: 0.220048; batch adversarial loss: 0.427215\n",
      "epoch 12; iter: 0; batch classifier loss: 0.241981; batch adversarial loss: 0.483143\n",
      "epoch 13; iter: 0; batch classifier loss: 0.258621; batch adversarial loss: 0.479261\n",
      "epoch 14; iter: 0; batch classifier loss: 0.206840; batch adversarial loss: 0.519289\n",
      "epoch 15; iter: 0; batch classifier loss: 0.167954; batch adversarial loss: 0.543057\n",
      "epoch 16; iter: 0; batch classifier loss: 0.126453; batch adversarial loss: 0.462201\n",
      "epoch 17; iter: 0; batch classifier loss: 0.233687; batch adversarial loss: 0.415295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.160245; batch adversarial loss: 0.460468\n",
      "epoch 19; iter: 0; batch classifier loss: 0.203715; batch adversarial loss: 0.399398\n",
      "epoch 20; iter: 0; batch classifier loss: 0.132067; batch adversarial loss: 0.443695\n",
      "epoch 21; iter: 0; batch classifier loss: 0.165480; batch adversarial loss: 0.463649\n",
      "epoch 22; iter: 0; batch classifier loss: 0.148550; batch adversarial loss: 0.410489\n",
      "epoch 23; iter: 0; batch classifier loss: 0.114497; batch adversarial loss: 0.479299\n",
      "epoch 24; iter: 0; batch classifier loss: 0.209489; batch adversarial loss: 0.457124\n",
      "epoch 25; iter: 0; batch classifier loss: 0.164016; batch adversarial loss: 0.482553\n",
      "epoch 26; iter: 0; batch classifier loss: 0.166839; batch adversarial loss: 0.395725\n",
      "epoch 27; iter: 0; batch classifier loss: 0.129797; batch adversarial loss: 0.399830\n",
      "epoch 28; iter: 0; batch classifier loss: 0.112297; batch adversarial loss: 0.359275\n",
      "epoch 29; iter: 0; batch classifier loss: 0.153815; batch adversarial loss: 0.419526\n",
      "epoch 30; iter: 0; batch classifier loss: 0.159078; batch adversarial loss: 0.476596\n",
      "epoch 31; iter: 0; batch classifier loss: 0.136788; batch adversarial loss: 0.390952\n",
      "epoch 32; iter: 0; batch classifier loss: 0.151410; batch adversarial loss: 0.385571\n",
      "epoch 33; iter: 0; batch classifier loss: 0.120483; batch adversarial loss: 0.413646\n",
      "epoch 34; iter: 0; batch classifier loss: 0.121878; batch adversarial loss: 0.396006\n",
      "epoch 35; iter: 0; batch classifier loss: 0.145559; batch adversarial loss: 0.424001\n",
      "epoch 36; iter: 0; batch classifier loss: 0.107767; batch adversarial loss: 0.421223\n",
      "epoch 37; iter: 0; batch classifier loss: 0.129897; batch adversarial loss: 0.370024\n",
      "epoch 38; iter: 0; batch classifier loss: 0.142024; batch adversarial loss: 0.434864\n",
      "epoch 39; iter: 0; batch classifier loss: 0.134813; batch adversarial loss: 0.437583\n",
      "epoch 40; iter: 0; batch classifier loss: 0.140842; batch adversarial loss: 0.435003\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111554; batch adversarial loss: 0.398656\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120468; batch adversarial loss: 0.440087\n",
      "epoch 43; iter: 0; batch classifier loss: 0.121872; batch adversarial loss: 0.418857\n",
      "epoch 44; iter: 0; batch classifier loss: 0.096390; batch adversarial loss: 0.403199\n",
      "epoch 45; iter: 0; batch classifier loss: 0.166604; batch adversarial loss: 0.433270\n",
      "epoch 46; iter: 0; batch classifier loss: 0.109055; batch adversarial loss: 0.367918\n",
      "epoch 47; iter: 0; batch classifier loss: 0.139410; batch adversarial loss: 0.363794\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104476; batch adversarial loss: 0.458369\n",
      "epoch 49; iter: 0; batch classifier loss: 0.121010; batch adversarial loss: 0.399880\n",
      "epoch 50; iter: 0; batch classifier loss: 0.115104; batch adversarial loss: 0.433195\n",
      "epoch 51; iter: 0; batch classifier loss: 0.097616; batch adversarial loss: 0.460967\n",
      "epoch 52; iter: 0; batch classifier loss: 0.104719; batch adversarial loss: 0.420853\n",
      "epoch 53; iter: 0; batch classifier loss: 0.124987; batch adversarial loss: 0.340915\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127023; batch adversarial loss: 0.465613\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103965; batch adversarial loss: 0.332074\n",
      "epoch 56; iter: 0; batch classifier loss: 0.140256; batch adversarial loss: 0.435992\n",
      "epoch 57; iter: 0; batch classifier loss: 0.099156; batch adversarial loss: 0.532624\n",
      "epoch 58; iter: 0; batch classifier loss: 0.122653; batch adversarial loss: 0.370053\n",
      "epoch 59; iter: 0; batch classifier loss: 0.056351; batch adversarial loss: 0.401228\n",
      "epoch 60; iter: 0; batch classifier loss: 0.100033; batch adversarial loss: 0.461109\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105461; batch adversarial loss: 0.418312\n",
      "epoch 62; iter: 0; batch classifier loss: 0.062179; batch adversarial loss: 0.382505\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097031; batch adversarial loss: 0.416355\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106549; batch adversarial loss: 0.297935\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110406; batch adversarial loss: 0.399415\n",
      "epoch 66; iter: 0; batch classifier loss: 0.095307; batch adversarial loss: 0.395684\n",
      "epoch 67; iter: 0; batch classifier loss: 0.071970; batch adversarial loss: 0.397531\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082081; batch adversarial loss: 0.385105\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082319; batch adversarial loss: 0.409534\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079261; batch adversarial loss: 0.463032\n",
      "epoch 71; iter: 0; batch classifier loss: 0.074873; batch adversarial loss: 0.464066\n",
      "epoch 72; iter: 0; batch classifier loss: 0.050226; batch adversarial loss: 0.375661\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089171; batch adversarial loss: 0.454128\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079478; batch adversarial loss: 0.403603\n",
      "epoch 75; iter: 0; batch classifier loss: 0.070235; batch adversarial loss: 0.382494\n",
      "epoch 76; iter: 0; batch classifier loss: 0.120674; batch adversarial loss: 0.406412\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087409; batch adversarial loss: 0.373739\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062428; batch adversarial loss: 0.362145\n",
      "epoch 79; iter: 0; batch classifier loss: 0.038559; batch adversarial loss: 0.455484\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083617; batch adversarial loss: 0.397705\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069253; batch adversarial loss: 0.363443\n",
      "epoch 82; iter: 0; batch classifier loss: 0.042086; batch adversarial loss: 0.453094\n",
      "epoch 83; iter: 0; batch classifier loss: 0.057537; batch adversarial loss: 0.430554\n",
      "epoch 84; iter: 0; batch classifier loss: 0.092662; batch adversarial loss: 0.447338\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059577; batch adversarial loss: 0.425535\n",
      "epoch 86; iter: 0; batch classifier loss: 0.050551; batch adversarial loss: 0.371299\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053948; batch adversarial loss: 0.316097\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051839; batch adversarial loss: 0.379121\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069278; batch adversarial loss: 0.443695\n",
      "epoch 90; iter: 0; batch classifier loss: 0.090432; batch adversarial loss: 0.461745\n",
      "epoch 91; iter: 0; batch classifier loss: 0.087811; batch adversarial loss: 0.368400\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050210; batch adversarial loss: 0.303978\n",
      "epoch 93; iter: 0; batch classifier loss: 0.070744; batch adversarial loss: 0.503937\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053635; batch adversarial loss: 0.405530\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080301; batch adversarial loss: 0.496947\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056281; batch adversarial loss: 0.371757\n",
      "epoch 97; iter: 0; batch classifier loss: 0.089962; batch adversarial loss: 0.346731\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052206; batch adversarial loss: 0.428142\n",
      "epoch 99; iter: 0; batch classifier loss: 0.070326; batch adversarial loss: 0.537782\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057082; batch adversarial loss: 0.414744\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055761; batch adversarial loss: 0.411381\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055043; batch adversarial loss: 0.460785\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035281; batch adversarial loss: 0.425201\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063177; batch adversarial loss: 0.409962\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058208; batch adversarial loss: 0.426407\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054001; batch adversarial loss: 0.340936\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044751; batch adversarial loss: 0.415201\n",
      "epoch 108; iter: 0; batch classifier loss: 0.107952; batch adversarial loss: 0.449471\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048561; batch adversarial loss: 0.431425\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060417; batch adversarial loss: 0.426313\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045815; batch adversarial loss: 0.378613\n",
      "epoch 112; iter: 0; batch classifier loss: 0.062595; batch adversarial loss: 0.467634\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053942; batch adversarial loss: 0.420544\n",
      "epoch 114; iter: 0; batch classifier loss: 0.078051; batch adversarial loss: 0.395233\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060542; batch adversarial loss: 0.376047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.047961; batch adversarial loss: 0.447602\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038669; batch adversarial loss: 0.349120\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026863; batch adversarial loss: 0.391265\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073494; batch adversarial loss: 0.389547\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039900; batch adversarial loss: 0.409455\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058465; batch adversarial loss: 0.399652\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040414; batch adversarial loss: 0.423999\n",
      "epoch 123; iter: 0; batch classifier loss: 0.054260; batch adversarial loss: 0.470061\n",
      "epoch 124; iter: 0; batch classifier loss: 0.045460; batch adversarial loss: 0.347245\n",
      "epoch 125; iter: 0; batch classifier loss: 0.080508; batch adversarial loss: 0.464156\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040225; batch adversarial loss: 0.451887\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039489; batch adversarial loss: 0.462979\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039951; batch adversarial loss: 0.482464\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045995; batch adversarial loss: 0.408919\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041778; batch adversarial loss: 0.440095\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042362; batch adversarial loss: 0.460673\n",
      "epoch 132; iter: 0; batch classifier loss: 0.071722; batch adversarial loss: 0.452759\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029549; batch adversarial loss: 0.448695\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052583; batch adversarial loss: 0.410470\n",
      "epoch 135; iter: 0; batch classifier loss: 0.058151; batch adversarial loss: 0.398070\n",
      "epoch 136; iter: 0; batch classifier loss: 0.072631; batch adversarial loss: 0.513593\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046636; batch adversarial loss: 0.365588\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030456; batch adversarial loss: 0.468748\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037390; batch adversarial loss: 0.412062\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035967; batch adversarial loss: 0.362392\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043848; batch adversarial loss: 0.380850\n",
      "epoch 142; iter: 0; batch classifier loss: 0.047242; batch adversarial loss: 0.405497\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021021; batch adversarial loss: 0.407125\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027444; batch adversarial loss: 0.552588\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034286; batch adversarial loss: 0.460346\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013866; batch adversarial loss: 0.468615\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038117; batch adversarial loss: 0.426180\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034453; batch adversarial loss: 0.467946\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030744; batch adversarial loss: 0.407354\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024818; batch adversarial loss: 0.433284\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037260; batch adversarial loss: 0.345956\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019508; batch adversarial loss: 0.465141\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011693; batch adversarial loss: 0.460657\n",
      "epoch 154; iter: 0; batch classifier loss: 0.047331; batch adversarial loss: 0.316618\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022876; batch adversarial loss: 0.416680\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016648; batch adversarial loss: 0.480232\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019240; batch adversarial loss: 0.525267\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047869; batch adversarial loss: 0.400368\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043420; batch adversarial loss: 0.432011\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029559; batch adversarial loss: 0.394746\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024242; batch adversarial loss: 0.435035\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027786; batch adversarial loss: 0.442830\n",
      "epoch 163; iter: 0; batch classifier loss: 0.060771; batch adversarial loss: 0.532591\n",
      "epoch 164; iter: 0; batch classifier loss: 0.056855; batch adversarial loss: 0.552630\n",
      "epoch 165; iter: 0; batch classifier loss: 0.058770; batch adversarial loss: 0.496912\n",
      "epoch 166; iter: 0; batch classifier loss: 0.055195; batch adversarial loss: 0.555591\n",
      "epoch 167; iter: 0; batch classifier loss: 0.066273; batch adversarial loss: 0.542188\n",
      "epoch 168; iter: 0; batch classifier loss: 0.083934; batch adversarial loss: 0.556258\n",
      "epoch 169; iter: 0; batch classifier loss: 0.088034; batch adversarial loss: 0.500957\n",
      "epoch 170; iter: 0; batch classifier loss: 0.112107; batch adversarial loss: 0.739824\n",
      "epoch 171; iter: 0; batch classifier loss: 0.159613; batch adversarial loss: 0.592682\n",
      "epoch 172; iter: 0; batch classifier loss: 0.141784; batch adversarial loss: 0.734309\n",
      "epoch 173; iter: 0; batch classifier loss: 0.070567; batch adversarial loss: 0.561609\n",
      "epoch 174; iter: 0; batch classifier loss: 0.119692; batch adversarial loss: 0.532147\n",
      "epoch 175; iter: 0; batch classifier loss: 0.225365; batch adversarial loss: 0.743195\n",
      "epoch 176; iter: 0; batch classifier loss: 0.141574; batch adversarial loss: 0.728276\n",
      "epoch 177; iter: 0; batch classifier loss: 0.184447; batch adversarial loss: 0.708438\n",
      "epoch 178; iter: 0; batch classifier loss: 0.230448; batch adversarial loss: 0.849167\n",
      "epoch 179; iter: 0; batch classifier loss: 0.136337; batch adversarial loss: 0.638016\n",
      "epoch 180; iter: 0; batch classifier loss: 0.136369; batch adversarial loss: 0.619570\n",
      "epoch 181; iter: 0; batch classifier loss: 0.145751; batch adversarial loss: 0.662440\n",
      "epoch 182; iter: 0; batch classifier loss: 0.220370; batch adversarial loss: 0.806545\n",
      "epoch 183; iter: 0; batch classifier loss: 0.162786; batch adversarial loss: 0.635815\n",
      "epoch 184; iter: 0; batch classifier loss: 0.156955; batch adversarial loss: 0.534466\n",
      "epoch 185; iter: 0; batch classifier loss: 0.187533; batch adversarial loss: 0.704667\n",
      "epoch 186; iter: 0; batch classifier loss: 0.167892; batch adversarial loss: 0.627383\n",
      "epoch 187; iter: 0; batch classifier loss: 0.211444; batch adversarial loss: 0.673359\n",
      "epoch 188; iter: 0; batch classifier loss: 0.183663; batch adversarial loss: 0.676632\n",
      "epoch 189; iter: 0; batch classifier loss: 0.153156; batch adversarial loss: 0.592488\n",
      "epoch 190; iter: 0; batch classifier loss: 0.144378; batch adversarial loss: 0.595523\n",
      "epoch 191; iter: 0; batch classifier loss: 0.218946; batch adversarial loss: 0.768703\n",
      "epoch 192; iter: 0; batch classifier loss: 0.253388; batch adversarial loss: 0.713364\n",
      "epoch 193; iter: 0; batch classifier loss: 0.112839; batch adversarial loss: 0.569344\n",
      "epoch 194; iter: 0; batch classifier loss: 0.147888; batch adversarial loss: 0.526543\n",
      "epoch 195; iter: 0; batch classifier loss: 0.137390; batch adversarial loss: 0.557397\n",
      "epoch 196; iter: 0; batch classifier loss: 0.193335; batch adversarial loss: 0.575307\n",
      "epoch 197; iter: 0; batch classifier loss: 0.117817; batch adversarial loss: 0.413955\n",
      "epoch 198; iter: 0; batch classifier loss: 0.224694; batch adversarial loss: 0.727050\n",
      "epoch 199; iter: 0; batch classifier loss: 0.154377; batch adversarial loss: 0.517172\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673231; batch adversarial loss: 0.564279\n",
      "epoch 1; iter: 0; batch classifier loss: 0.378423; batch adversarial loss: 0.654174\n",
      "epoch 2; iter: 0; batch classifier loss: 0.461006; batch adversarial loss: 0.626617\n",
      "epoch 3; iter: 0; batch classifier loss: 0.428469; batch adversarial loss: 0.597763\n",
      "epoch 4; iter: 0; batch classifier loss: 0.391904; batch adversarial loss: 0.554086\n",
      "epoch 5; iter: 0; batch classifier loss: 0.380343; batch adversarial loss: 0.479942\n",
      "epoch 6; iter: 0; batch classifier loss: 0.327759; batch adversarial loss: 0.583952\n",
      "epoch 7; iter: 0; batch classifier loss: 0.370515; batch adversarial loss: 0.725617\n",
      "epoch 8; iter: 0; batch classifier loss: 0.244505; batch adversarial loss: 0.614940\n",
      "epoch 9; iter: 0; batch classifier loss: 0.352259; batch adversarial loss: 0.545389\n",
      "epoch 10; iter: 0; batch classifier loss: 0.385083; batch adversarial loss: 0.549459\n",
      "epoch 11; iter: 0; batch classifier loss: 0.385426; batch adversarial loss: 0.500064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.341108; batch adversarial loss: 0.552264\n",
      "epoch 13; iter: 0; batch classifier loss: 0.285780; batch adversarial loss: 0.578033\n",
      "epoch 14; iter: 0; batch classifier loss: 0.365800; batch adversarial loss: 0.456643\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516831; batch adversarial loss: 0.513600\n",
      "epoch 16; iter: 0; batch classifier loss: 0.465733; batch adversarial loss: 0.553209\n",
      "epoch 17; iter: 0; batch classifier loss: 0.498716; batch adversarial loss: 0.482930\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534323; batch adversarial loss: 0.537013\n",
      "epoch 19; iter: 0; batch classifier loss: 0.303553; batch adversarial loss: 0.504313\n",
      "epoch 20; iter: 0; batch classifier loss: 0.209999; batch adversarial loss: 0.504642\n",
      "epoch 21; iter: 0; batch classifier loss: 0.176277; batch adversarial loss: 0.475207\n",
      "epoch 22; iter: 0; batch classifier loss: 0.171048; batch adversarial loss: 0.431683\n",
      "epoch 23; iter: 0; batch classifier loss: 0.235989; batch adversarial loss: 0.439310\n",
      "epoch 24; iter: 0; batch classifier loss: 0.154758; batch adversarial loss: 0.371494\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209441; batch adversarial loss: 0.525458\n",
      "epoch 26; iter: 0; batch classifier loss: 0.136871; batch adversarial loss: 0.501299\n",
      "epoch 27; iter: 0; batch classifier loss: 0.128565; batch adversarial loss: 0.491573\n",
      "epoch 28; iter: 0; batch classifier loss: 0.156106; batch adversarial loss: 0.492771\n",
      "epoch 29; iter: 0; batch classifier loss: 0.136543; batch adversarial loss: 0.459242\n",
      "epoch 30; iter: 0; batch classifier loss: 0.139271; batch adversarial loss: 0.459876\n",
      "epoch 31; iter: 0; batch classifier loss: 0.157396; batch adversarial loss: 0.546524\n",
      "epoch 32; iter: 0; batch classifier loss: 0.167773; batch adversarial loss: 0.404971\n",
      "epoch 33; iter: 0; batch classifier loss: 0.139611; batch adversarial loss: 0.411524\n",
      "epoch 34; iter: 0; batch classifier loss: 0.114277; batch adversarial loss: 0.396957\n",
      "epoch 35; iter: 0; batch classifier loss: 0.128133; batch adversarial loss: 0.516690\n",
      "epoch 36; iter: 0; batch classifier loss: 0.119313; batch adversarial loss: 0.492102\n",
      "epoch 37; iter: 0; batch classifier loss: 0.129862; batch adversarial loss: 0.486451\n",
      "epoch 38; iter: 0; batch classifier loss: 0.100956; batch adversarial loss: 0.524688\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106627; batch adversarial loss: 0.396110\n",
      "epoch 40; iter: 0; batch classifier loss: 0.155588; batch adversarial loss: 0.373704\n",
      "epoch 41; iter: 0; batch classifier loss: 0.101748; batch adversarial loss: 0.423312\n",
      "epoch 42; iter: 0; batch classifier loss: 0.128643; batch adversarial loss: 0.453618\n",
      "epoch 43; iter: 0; batch classifier loss: 0.098347; batch adversarial loss: 0.438457\n",
      "epoch 44; iter: 0; batch classifier loss: 0.088507; batch adversarial loss: 0.500642\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102489; batch adversarial loss: 0.488636\n",
      "epoch 46; iter: 0; batch classifier loss: 0.108098; batch adversarial loss: 0.405030\n",
      "epoch 47; iter: 0; batch classifier loss: 0.132930; batch adversarial loss: 0.488766\n",
      "epoch 48; iter: 0; batch classifier loss: 0.144686; batch adversarial loss: 0.449197\n",
      "epoch 49; iter: 0; batch classifier loss: 0.072655; batch adversarial loss: 0.471633\n",
      "epoch 50; iter: 0; batch classifier loss: 0.095681; batch adversarial loss: 0.448508\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106665; batch adversarial loss: 0.495205\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099173; batch adversarial loss: 0.421495\n",
      "epoch 53; iter: 0; batch classifier loss: 0.097349; batch adversarial loss: 0.505783\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101439; batch adversarial loss: 0.532932\n",
      "epoch 55; iter: 0; batch classifier loss: 0.104640; batch adversarial loss: 0.452553\n",
      "epoch 56; iter: 0; batch classifier loss: 0.094946; batch adversarial loss: 0.494948\n",
      "epoch 57; iter: 0; batch classifier loss: 0.096764; batch adversarial loss: 0.478965\n",
      "epoch 58; iter: 0; batch classifier loss: 0.068328; batch adversarial loss: 0.553435\n",
      "epoch 59; iter: 0; batch classifier loss: 0.124888; batch adversarial loss: 0.472804\n",
      "epoch 60; iter: 0; batch classifier loss: 0.120822; batch adversarial loss: 0.349857\n",
      "epoch 61; iter: 0; batch classifier loss: 0.110763; batch adversarial loss: 0.407070\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104688; batch adversarial loss: 0.340870\n",
      "epoch 63; iter: 0; batch classifier loss: 0.127437; batch adversarial loss: 0.449417\n",
      "epoch 64; iter: 0; batch classifier loss: 0.121554; batch adversarial loss: 0.461571\n",
      "epoch 65; iter: 0; batch classifier loss: 0.085682; batch adversarial loss: 0.367981\n",
      "epoch 66; iter: 0; batch classifier loss: 0.101998; batch adversarial loss: 0.475782\n",
      "epoch 67; iter: 0; batch classifier loss: 0.076313; batch adversarial loss: 0.429426\n",
      "epoch 68; iter: 0; batch classifier loss: 0.126351; batch adversarial loss: 0.359868\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102253; batch adversarial loss: 0.471320\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095048; batch adversarial loss: 0.425169\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089111; batch adversarial loss: 0.488896\n",
      "epoch 72; iter: 0; batch classifier loss: 0.111214; batch adversarial loss: 0.514877\n",
      "epoch 73; iter: 0; batch classifier loss: 0.086758; batch adversarial loss: 0.396422\n",
      "epoch 74; iter: 0; batch classifier loss: 0.105328; batch adversarial loss: 0.389654\n",
      "epoch 75; iter: 0; batch classifier loss: 0.080807; batch adversarial loss: 0.443703\n",
      "epoch 76; iter: 0; batch classifier loss: 0.132867; batch adversarial loss: 0.347042\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074412; batch adversarial loss: 0.528407\n",
      "epoch 78; iter: 0; batch classifier loss: 0.083278; batch adversarial loss: 0.426065\n",
      "epoch 79; iter: 0; batch classifier loss: 0.129371; batch adversarial loss: 0.433244\n",
      "epoch 80; iter: 0; batch classifier loss: 0.055405; batch adversarial loss: 0.389621\n",
      "epoch 81; iter: 0; batch classifier loss: 0.126864; batch adversarial loss: 0.462781\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083097; batch adversarial loss: 0.488126\n",
      "epoch 83; iter: 0; batch classifier loss: 0.076707; batch adversarial loss: 0.512998\n",
      "epoch 84; iter: 0; batch classifier loss: 0.097266; batch adversarial loss: 0.485052\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074568; batch adversarial loss: 0.421580\n",
      "epoch 86; iter: 0; batch classifier loss: 0.141560; batch adversarial loss: 0.551498\n",
      "epoch 87; iter: 0; batch classifier loss: 0.058383; batch adversarial loss: 0.510333\n",
      "epoch 88; iter: 0; batch classifier loss: 0.114028; batch adversarial loss: 0.448019\n",
      "epoch 89; iter: 0; batch classifier loss: 0.136241; batch adversarial loss: 0.411637\n",
      "epoch 90; iter: 0; batch classifier loss: 0.126094; batch adversarial loss: 0.471023\n",
      "epoch 91; iter: 0; batch classifier loss: 0.104220; batch adversarial loss: 0.458090\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044987; batch adversarial loss: 0.409693\n",
      "epoch 93; iter: 0; batch classifier loss: 0.090561; batch adversarial loss: 0.469819\n",
      "epoch 94; iter: 0; batch classifier loss: 0.101022; batch adversarial loss: 0.384990\n",
      "epoch 95; iter: 0; batch classifier loss: 0.102551; batch adversarial loss: 0.468948\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096737; batch adversarial loss: 0.364156\n",
      "epoch 97; iter: 0; batch classifier loss: 0.089248; batch adversarial loss: 0.469516\n",
      "epoch 98; iter: 0; batch classifier loss: 0.091112; batch adversarial loss: 0.494451\n",
      "epoch 99; iter: 0; batch classifier loss: 0.095627; batch adversarial loss: 0.464354\n",
      "epoch 100; iter: 0; batch classifier loss: 0.083227; batch adversarial loss: 0.498856\n",
      "epoch 101; iter: 0; batch classifier loss: 0.106206; batch adversarial loss: 0.459270\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066581; batch adversarial loss: 0.376540\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072290; batch adversarial loss: 0.416080\n",
      "epoch 104; iter: 0; batch classifier loss: 0.086965; batch adversarial loss: 0.512259\n",
      "epoch 105; iter: 0; batch classifier loss: 0.103545; batch adversarial loss: 0.418792\n",
      "epoch 106; iter: 0; batch classifier loss: 0.100517; batch adversarial loss: 0.476790\n",
      "epoch 107; iter: 0; batch classifier loss: 0.075410; batch adversarial loss: 0.410453\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069425; batch adversarial loss: 0.501571\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037207; batch adversarial loss: 0.562083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.114487; batch adversarial loss: 0.473949\n",
      "epoch 111; iter: 0; batch classifier loss: 0.081719; batch adversarial loss: 0.471855\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060794; batch adversarial loss: 0.475202\n",
      "epoch 113; iter: 0; batch classifier loss: 0.068752; batch adversarial loss: 0.411579\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053137; batch adversarial loss: 0.528877\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062817; batch adversarial loss: 0.382232\n",
      "epoch 116; iter: 0; batch classifier loss: 0.084559; batch adversarial loss: 0.478380\n",
      "epoch 117; iter: 0; batch classifier loss: 0.059399; batch adversarial loss: 0.463490\n",
      "epoch 118; iter: 0; batch classifier loss: 0.104662; batch adversarial loss: 0.457703\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065187; batch adversarial loss: 0.405434\n",
      "epoch 120; iter: 0; batch classifier loss: 0.090686; batch adversarial loss: 0.429694\n",
      "epoch 121; iter: 0; batch classifier loss: 0.080073; batch adversarial loss: 0.440902\n",
      "epoch 122; iter: 0; batch classifier loss: 0.073265; batch adversarial loss: 0.460064\n",
      "epoch 123; iter: 0; batch classifier loss: 0.066395; batch adversarial loss: 0.460405\n",
      "epoch 124; iter: 0; batch classifier loss: 0.056143; batch adversarial loss: 0.496067\n",
      "epoch 125; iter: 0; batch classifier loss: 0.071220; batch adversarial loss: 0.445758\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056731; batch adversarial loss: 0.538888\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060602; batch adversarial loss: 0.445333\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046162; batch adversarial loss: 0.463853\n",
      "epoch 129; iter: 0; batch classifier loss: 0.105982; batch adversarial loss: 0.451836\n",
      "epoch 130; iter: 0; batch classifier loss: 0.070119; batch adversarial loss: 0.508414\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051956; batch adversarial loss: 0.414642\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029050; batch adversarial loss: 0.369546\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046890; batch adversarial loss: 0.468677\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054970; batch adversarial loss: 0.463649\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012997; batch adversarial loss: 0.576391\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043635; batch adversarial loss: 0.366707\n",
      "epoch 137; iter: 0; batch classifier loss: 0.084618; batch adversarial loss: 0.457100\n",
      "epoch 138; iter: 0; batch classifier loss: 0.079247; batch adversarial loss: 0.350790\n",
      "epoch 139; iter: 0; batch classifier loss: 0.067411; batch adversarial loss: 0.451006\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044425; batch adversarial loss: 0.516040\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022738; batch adversarial loss: 0.456664\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037659; batch adversarial loss: 0.395369\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037399; batch adversarial loss: 0.416375\n",
      "epoch 144; iter: 0; batch classifier loss: 0.046812; batch adversarial loss: 0.370183\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037814; batch adversarial loss: 0.511948\n",
      "epoch 146; iter: 0; batch classifier loss: 0.083334; batch adversarial loss: 0.477405\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017409; batch adversarial loss: 0.502920\n",
      "epoch 148; iter: 0; batch classifier loss: 0.047404; batch adversarial loss: 0.461948\n",
      "epoch 149; iter: 0; batch classifier loss: 0.047748; batch adversarial loss: 0.436238\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017714; batch adversarial loss: 0.442954\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034677; batch adversarial loss: 0.451420\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041447; batch adversarial loss: 0.536493\n",
      "epoch 153; iter: 0; batch classifier loss: 0.083144; batch adversarial loss: 0.467943\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035924; batch adversarial loss: 0.384267\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029361; batch adversarial loss: 0.485458\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038699; batch adversarial loss: 0.412153\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015448; batch adversarial loss: 0.497434\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026783; batch adversarial loss: 0.465619\n",
      "epoch 159; iter: 0; batch classifier loss: 0.009512; batch adversarial loss: 0.547609\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015528; batch adversarial loss: 0.443657\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033572; batch adversarial loss: 0.511392\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046001; batch adversarial loss: 0.450371\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039716; batch adversarial loss: 0.499985\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035726; batch adversarial loss: 0.421360\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030128; batch adversarial loss: 0.379110\n",
      "epoch 166; iter: 0; batch classifier loss: 0.042399; batch adversarial loss: 0.423592\n",
      "epoch 167; iter: 0; batch classifier loss: 0.005222; batch adversarial loss: 0.513044\n",
      "epoch 168; iter: 0; batch classifier loss: 0.053825; batch adversarial loss: 0.378899\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022816; batch adversarial loss: 0.491563\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030385; batch adversarial loss: 0.381443\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024224; batch adversarial loss: 0.501620\n",
      "epoch 172; iter: 0; batch classifier loss: 0.037829; batch adversarial loss: 0.452472\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025250; batch adversarial loss: 0.490169\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032536; batch adversarial loss: 0.472184\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023852; batch adversarial loss: 0.446681\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027735; batch adversarial loss: 0.400330\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022955; batch adversarial loss: 0.440265\n",
      "epoch 178; iter: 0; batch classifier loss: 0.063542; batch adversarial loss: 0.505149\n",
      "epoch 179; iter: 0; batch classifier loss: 0.041104; batch adversarial loss: 0.420373\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014418; batch adversarial loss: 0.490515\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014289; batch adversarial loss: 0.476649\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032310; batch adversarial loss: 0.523214\n",
      "epoch 183; iter: 0; batch classifier loss: 0.045326; batch adversarial loss: 0.406558\n",
      "epoch 184; iter: 0; batch classifier loss: 0.056896; batch adversarial loss: 0.412391\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020297; batch adversarial loss: 0.424567\n",
      "epoch 186; iter: 0; batch classifier loss: 0.046407; batch adversarial loss: 0.422239\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005693; batch adversarial loss: 0.448193\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022187; batch adversarial loss: 0.472598\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011517; batch adversarial loss: 0.472453\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008014; batch adversarial loss: 0.396391\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010417; batch adversarial loss: 0.539577\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027702; batch adversarial loss: 0.396361\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032187; batch adversarial loss: 0.497441\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017132; batch adversarial loss: 0.457291\n",
      "epoch 195; iter: 0; batch classifier loss: 0.043309; batch adversarial loss: 0.345294\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007854; batch adversarial loss: 0.410473\n",
      "epoch 197; iter: 0; batch classifier loss: 0.055513; batch adversarial loss: 0.400579\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011582; batch adversarial loss: 0.511729\n",
      "epoch 199; iter: 0; batch classifier loss: 0.042471; batch adversarial loss: 0.554076\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683248; batch adversarial loss: 0.653185\n",
      "epoch 1; iter: 0; batch classifier loss: 0.501890; batch adversarial loss: 0.645872\n",
      "epoch 2; iter: 0; batch classifier loss: 0.402719; batch adversarial loss: 0.617317\n",
      "epoch 3; iter: 0; batch classifier loss: 0.468478; batch adversarial loss: 0.596620\n",
      "epoch 4; iter: 0; batch classifier loss: 0.470910; batch adversarial loss: 0.638922\n",
      "epoch 5; iter: 0; batch classifier loss: 0.527792; batch adversarial loss: 0.581211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.494493; batch adversarial loss: 0.584065\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555801; batch adversarial loss: 0.551532\n",
      "epoch 8; iter: 0; batch classifier loss: 0.477269; batch adversarial loss: 0.582596\n",
      "epoch 9; iter: 0; batch classifier loss: 0.482884; batch adversarial loss: 0.514494\n",
      "epoch 10; iter: 0; batch classifier loss: 0.370236; batch adversarial loss: 0.543971\n",
      "epoch 11; iter: 0; batch classifier loss: 0.386473; batch adversarial loss: 0.472718\n",
      "epoch 12; iter: 0; batch classifier loss: 0.429983; batch adversarial loss: 0.504257\n",
      "epoch 13; iter: 0; batch classifier loss: 0.380005; batch adversarial loss: 0.534524\n",
      "epoch 14; iter: 0; batch classifier loss: 0.341214; batch adversarial loss: 0.503899\n",
      "epoch 15; iter: 0; batch classifier loss: 0.324551; batch adversarial loss: 0.543196\n",
      "epoch 16; iter: 0; batch classifier loss: 0.378795; batch adversarial loss: 0.504935\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262937; batch adversarial loss: 0.524205\n",
      "epoch 18; iter: 0; batch classifier loss: 0.354504; batch adversarial loss: 0.488727\n",
      "epoch 19; iter: 0; batch classifier loss: 0.355056; batch adversarial loss: 0.431055\n",
      "epoch 20; iter: 0; batch classifier loss: 0.311416; batch adversarial loss: 0.413118\n",
      "epoch 21; iter: 0; batch classifier loss: 0.280126; batch adversarial loss: 0.469634\n",
      "epoch 22; iter: 0; batch classifier loss: 0.241908; batch adversarial loss: 0.482674\n",
      "epoch 23; iter: 0; batch classifier loss: 0.238256; batch adversarial loss: 0.586650\n",
      "epoch 24; iter: 0; batch classifier loss: 0.243962; batch adversarial loss: 0.404985\n",
      "epoch 25; iter: 0; batch classifier loss: 0.254211; batch adversarial loss: 0.455704\n",
      "epoch 26; iter: 0; batch classifier loss: 0.205929; batch adversarial loss: 0.527675\n",
      "epoch 27; iter: 0; batch classifier loss: 0.286313; batch adversarial loss: 0.448964\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169907; batch adversarial loss: 0.462488\n",
      "epoch 29; iter: 0; batch classifier loss: 0.155373; batch adversarial loss: 0.415803\n",
      "epoch 30; iter: 0; batch classifier loss: 0.208851; batch adversarial loss: 0.480055\n",
      "epoch 31; iter: 0; batch classifier loss: 0.198425; batch adversarial loss: 0.415804\n",
      "epoch 32; iter: 0; batch classifier loss: 0.167304; batch adversarial loss: 0.449564\n",
      "epoch 33; iter: 0; batch classifier loss: 0.201479; batch adversarial loss: 0.440970\n",
      "epoch 34; iter: 0; batch classifier loss: 0.208083; batch adversarial loss: 0.455900\n",
      "epoch 35; iter: 0; batch classifier loss: 0.177869; batch adversarial loss: 0.428579\n",
      "epoch 36; iter: 0; batch classifier loss: 0.212004; batch adversarial loss: 0.489675\n",
      "epoch 37; iter: 0; batch classifier loss: 0.161690; batch adversarial loss: 0.493968\n",
      "epoch 38; iter: 0; batch classifier loss: 0.195162; batch adversarial loss: 0.467986\n",
      "epoch 39; iter: 0; batch classifier loss: 0.159722; batch adversarial loss: 0.458964\n",
      "epoch 40; iter: 0; batch classifier loss: 0.149899; batch adversarial loss: 0.515752\n",
      "epoch 41; iter: 0; batch classifier loss: 0.196445; batch adversarial loss: 0.467296\n",
      "epoch 42; iter: 0; batch classifier loss: 0.183062; batch adversarial loss: 0.318240\n",
      "epoch 43; iter: 0; batch classifier loss: 0.197644; batch adversarial loss: 0.372867\n",
      "epoch 44; iter: 0; batch classifier loss: 0.179009; batch adversarial loss: 0.489322\n",
      "epoch 45; iter: 0; batch classifier loss: 0.160852; batch adversarial loss: 0.485819\n",
      "epoch 46; iter: 0; batch classifier loss: 0.169848; batch adversarial loss: 0.411817\n",
      "epoch 47; iter: 0; batch classifier loss: 0.173473; batch adversarial loss: 0.471711\n",
      "epoch 48; iter: 0; batch classifier loss: 0.167068; batch adversarial loss: 0.535443\n",
      "epoch 49; iter: 0; batch classifier loss: 0.175022; batch adversarial loss: 0.426169\n",
      "epoch 50; iter: 0; batch classifier loss: 0.263105; batch adversarial loss: 0.460627\n",
      "epoch 51; iter: 0; batch classifier loss: 0.164177; batch adversarial loss: 0.363738\n",
      "epoch 52; iter: 0; batch classifier loss: 0.217575; batch adversarial loss: 0.407885\n",
      "epoch 53; iter: 0; batch classifier loss: 0.120079; batch adversarial loss: 0.462556\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127692; batch adversarial loss: 0.397697\n",
      "epoch 55; iter: 0; batch classifier loss: 0.150856; batch adversarial loss: 0.400715\n",
      "epoch 56; iter: 0; batch classifier loss: 0.150893; batch adversarial loss: 0.466771\n",
      "epoch 57; iter: 0; batch classifier loss: 0.187041; batch adversarial loss: 0.469788\n",
      "epoch 58; iter: 0; batch classifier loss: 0.173203; batch adversarial loss: 0.526966\n",
      "epoch 59; iter: 0; batch classifier loss: 0.180093; batch adversarial loss: 0.506392\n",
      "epoch 60; iter: 0; batch classifier loss: 0.168172; batch adversarial loss: 0.344307\n",
      "epoch 61; iter: 0; batch classifier loss: 0.184546; batch adversarial loss: 0.435812\n",
      "epoch 62; iter: 0; batch classifier loss: 0.137525; batch adversarial loss: 0.481089\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116968; batch adversarial loss: 0.445912\n",
      "epoch 64; iter: 0; batch classifier loss: 0.141962; batch adversarial loss: 0.421197\n",
      "epoch 65; iter: 0; batch classifier loss: 0.162225; batch adversarial loss: 0.434105\n",
      "epoch 66; iter: 0; batch classifier loss: 0.120353; batch adversarial loss: 0.469025\n",
      "epoch 67; iter: 0; batch classifier loss: 0.127019; batch adversarial loss: 0.495169\n",
      "epoch 68; iter: 0; batch classifier loss: 0.153451; batch adversarial loss: 0.399623\n",
      "epoch 69; iter: 0; batch classifier loss: 0.147669; batch adversarial loss: 0.529105\n",
      "epoch 70; iter: 0; batch classifier loss: 0.135924; batch adversarial loss: 0.484521\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081899; batch adversarial loss: 0.444460\n",
      "epoch 72; iter: 0; batch classifier loss: 0.116703; batch adversarial loss: 0.509377\n",
      "epoch 73; iter: 0; batch classifier loss: 0.111054; batch adversarial loss: 0.445826\n",
      "epoch 74; iter: 0; batch classifier loss: 0.122877; batch adversarial loss: 0.419449\n",
      "epoch 75; iter: 0; batch classifier loss: 0.095522; batch adversarial loss: 0.524832\n",
      "epoch 76; iter: 0; batch classifier loss: 0.099711; batch adversarial loss: 0.420524\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084236; batch adversarial loss: 0.515831\n",
      "epoch 78; iter: 0; batch classifier loss: 0.138648; batch adversarial loss: 0.481148\n",
      "epoch 79; iter: 0; batch classifier loss: 0.097346; batch adversarial loss: 0.465297\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061454; batch adversarial loss: 0.461546\n",
      "epoch 81; iter: 0; batch classifier loss: 0.103717; batch adversarial loss: 0.524374\n",
      "epoch 82; iter: 0; batch classifier loss: 0.093087; batch adversarial loss: 0.425489\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065937; batch adversarial loss: 0.390792\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085474; batch adversarial loss: 0.424746\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073055; batch adversarial loss: 0.422452\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064153; batch adversarial loss: 0.432907\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046502; batch adversarial loss: 0.372849\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054972; batch adversarial loss: 0.363080\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057731; batch adversarial loss: 0.424227\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054741; batch adversarial loss: 0.464876\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068072; batch adversarial loss: 0.362724\n",
      "epoch 92; iter: 0; batch classifier loss: 0.104020; batch adversarial loss: 0.379875\n",
      "epoch 93; iter: 0; batch classifier loss: 0.130339; batch adversarial loss: 0.439426\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050982; batch adversarial loss: 0.401166\n",
      "epoch 95; iter: 0; batch classifier loss: 0.069909; batch adversarial loss: 0.393579\n",
      "epoch 96; iter: 0; batch classifier loss: 0.095352; batch adversarial loss: 0.366085\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066222; batch adversarial loss: 0.445571\n",
      "epoch 98; iter: 0; batch classifier loss: 0.099139; batch adversarial loss: 0.378063\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038943; batch adversarial loss: 0.453555\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034177; batch adversarial loss: 0.484309\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044224; batch adversarial loss: 0.456045\n",
      "epoch 102; iter: 0; batch classifier loss: 0.023743; batch adversarial loss: 0.408152\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043397; batch adversarial loss: 0.508309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.047984; batch adversarial loss: 0.454261\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040630; batch adversarial loss: 0.525080\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052774; batch adversarial loss: 0.412696\n",
      "epoch 107; iter: 0; batch classifier loss: 0.026985; batch adversarial loss: 0.468542\n",
      "epoch 108; iter: 0; batch classifier loss: 0.072082; batch adversarial loss: 0.472851\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050200; batch adversarial loss: 0.421510\n",
      "epoch 110; iter: 0; batch classifier loss: 0.032822; batch adversarial loss: 0.433327\n",
      "epoch 111; iter: 0; batch classifier loss: 0.025677; batch adversarial loss: 0.453680\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048301; batch adversarial loss: 0.372082\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049460; batch adversarial loss: 0.520990\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036395; batch adversarial loss: 0.553549\n",
      "epoch 115; iter: 0; batch classifier loss: 0.026917; batch adversarial loss: 0.414124\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053885; batch adversarial loss: 0.573271\n",
      "epoch 117; iter: 0; batch classifier loss: 0.021029; batch adversarial loss: 0.432166\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036864; batch adversarial loss: 0.554379\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020985; batch adversarial loss: 0.416019\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028420; batch adversarial loss: 0.460212\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034132; batch adversarial loss: 0.530409\n",
      "epoch 122; iter: 0; batch classifier loss: 0.075741; batch adversarial loss: 0.445239\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028346; batch adversarial loss: 0.518569\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039987; batch adversarial loss: 0.465488\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031370; batch adversarial loss: 0.440468\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050335; batch adversarial loss: 0.478990\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020371; batch adversarial loss: 0.459475\n",
      "epoch 128; iter: 0; batch classifier loss: 0.013235; batch adversarial loss: 0.422215\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042433; batch adversarial loss: 0.423558\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057252; batch adversarial loss: 0.405136\n",
      "epoch 131; iter: 0; batch classifier loss: 0.071504; batch adversarial loss: 0.507809\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029488; batch adversarial loss: 0.475208\n",
      "epoch 133; iter: 0; batch classifier loss: 0.017822; batch adversarial loss: 0.415650\n",
      "epoch 134; iter: 0; batch classifier loss: 0.089004; batch adversarial loss: 0.346460\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041028; batch adversarial loss: 0.442303\n",
      "epoch 136; iter: 0; batch classifier loss: 0.012956; batch adversarial loss: 0.444668\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018955; batch adversarial loss: 0.432129\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025375; batch adversarial loss: 0.486829\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021550; batch adversarial loss: 0.479811\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014212; batch adversarial loss: 0.536416\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019039; batch adversarial loss: 0.361723\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044679; batch adversarial loss: 0.428852\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015884; batch adversarial loss: 0.416910\n",
      "epoch 144; iter: 0; batch classifier loss: 0.057920; batch adversarial loss: 0.444313\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034025; batch adversarial loss: 0.402103\n",
      "epoch 146; iter: 0; batch classifier loss: 0.046594; batch adversarial loss: 0.423845\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017111; batch adversarial loss: 0.456935\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023754; batch adversarial loss: 0.378762\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030377; batch adversarial loss: 0.459411\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020055; batch adversarial loss: 0.420094\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019765; batch adversarial loss: 0.462449\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044687; batch adversarial loss: 0.428621\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012748; batch adversarial loss: 0.523087\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025265; batch adversarial loss: 0.397183\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024888; batch adversarial loss: 0.370840\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013657; batch adversarial loss: 0.487653\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037538; batch adversarial loss: 0.436154\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028423; batch adversarial loss: 0.399616\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019070; batch adversarial loss: 0.488327\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022142; batch adversarial loss: 0.404889\n",
      "epoch 161; iter: 0; batch classifier loss: 0.052759; batch adversarial loss: 0.369377\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043684; batch adversarial loss: 0.405837\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026242; batch adversarial loss: 0.431476\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020474; batch adversarial loss: 0.456972\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014413; batch adversarial loss: 0.459287\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031357; batch adversarial loss: 0.506177\n",
      "epoch 167; iter: 0; batch classifier loss: 0.055430; batch adversarial loss: 0.480661\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038095; batch adversarial loss: 0.470267\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038994; batch adversarial loss: 0.409716\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021561; batch adversarial loss: 0.382750\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029453; batch adversarial loss: 0.471050\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029005; batch adversarial loss: 0.406178\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009223; batch adversarial loss: 0.489105\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018026; batch adversarial loss: 0.347968\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012787; batch adversarial loss: 0.414374\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015474; batch adversarial loss: 0.512684\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011676; batch adversarial loss: 0.456116\n",
      "epoch 178; iter: 0; batch classifier loss: 0.049608; batch adversarial loss: 0.462232\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023000; batch adversarial loss: 0.470873\n",
      "epoch 180; iter: 0; batch classifier loss: 0.045224; batch adversarial loss: 0.454747\n",
      "epoch 181; iter: 0; batch classifier loss: 0.040286; batch adversarial loss: 0.378801\n",
      "epoch 182; iter: 0; batch classifier loss: 0.051566; batch adversarial loss: 0.467085\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031862; batch adversarial loss: 0.479476\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017207; batch adversarial loss: 0.504625\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010952; batch adversarial loss: 0.510763\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015563; batch adversarial loss: 0.410579\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032515; batch adversarial loss: 0.460810\n",
      "epoch 188; iter: 0; batch classifier loss: 0.055435; batch adversarial loss: 0.424246\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013941; batch adversarial loss: 0.494294\n",
      "epoch 190; iter: 0; batch classifier loss: 0.046744; batch adversarial loss: 0.537841\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016772; batch adversarial loss: 0.435632\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013316; batch adversarial loss: 0.497830\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010463; batch adversarial loss: 0.484943\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010492; batch adversarial loss: 0.424392\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009354; batch adversarial loss: 0.492528\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021786; batch adversarial loss: 0.334672\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005760; batch adversarial loss: 0.472093\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005821; batch adversarial loss: 0.467064\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009988; batch adversarial loss: 0.438244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.693309; batch adversarial loss: 0.814601\n",
      "epoch 1; iter: 0; batch classifier loss: 0.531838; batch adversarial loss: 0.809055\n",
      "epoch 2; iter: 0; batch classifier loss: 0.780366; batch adversarial loss: 0.809255\n",
      "epoch 3; iter: 0; batch classifier loss: 0.745519; batch adversarial loss: 0.720394\n",
      "epoch 4; iter: 0; batch classifier loss: 0.740147; batch adversarial loss: 0.666532\n",
      "epoch 5; iter: 0; batch classifier loss: 0.497506; batch adversarial loss: 0.616339\n",
      "epoch 6; iter: 0; batch classifier loss: 0.462395; batch adversarial loss: 0.558362\n",
      "epoch 7; iter: 0; batch classifier loss: 0.330757; batch adversarial loss: 0.519786\n",
      "epoch 8; iter: 0; batch classifier loss: 0.305476; batch adversarial loss: 0.564491\n",
      "epoch 9; iter: 0; batch classifier loss: 0.230362; batch adversarial loss: 0.506600\n",
      "epoch 10; iter: 0; batch classifier loss: 0.306062; batch adversarial loss: 0.497178\n",
      "epoch 11; iter: 0; batch classifier loss: 0.298203; batch adversarial loss: 0.506348\n",
      "epoch 12; iter: 0; batch classifier loss: 0.306011; batch adversarial loss: 0.494432\n",
      "epoch 13; iter: 0; batch classifier loss: 0.264132; batch adversarial loss: 0.532928\n",
      "epoch 14; iter: 0; batch classifier loss: 0.208193; batch adversarial loss: 0.496736\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289917; batch adversarial loss: 0.511428\n",
      "epoch 16; iter: 0; batch classifier loss: 0.226034; batch adversarial loss: 0.543188\n",
      "epoch 17; iter: 0; batch classifier loss: 0.267009; batch adversarial loss: 0.529843\n",
      "epoch 18; iter: 0; batch classifier loss: 0.300833; batch adversarial loss: 0.525451\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237294; batch adversarial loss: 0.499900\n",
      "epoch 20; iter: 0; batch classifier loss: 0.177591; batch adversarial loss: 0.513926\n",
      "epoch 21; iter: 0; batch classifier loss: 0.200269; batch adversarial loss: 0.456341\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226503; batch adversarial loss: 0.481560\n",
      "epoch 23; iter: 0; batch classifier loss: 0.240213; batch adversarial loss: 0.439480\n",
      "epoch 24; iter: 0; batch classifier loss: 0.151528; batch adversarial loss: 0.489025\n",
      "epoch 25; iter: 0; batch classifier loss: 0.262078; batch adversarial loss: 0.470580\n",
      "epoch 26; iter: 0; batch classifier loss: 0.179380; batch adversarial loss: 0.420112\n",
      "epoch 27; iter: 0; batch classifier loss: 0.134630; batch adversarial loss: 0.522214\n",
      "epoch 28; iter: 0; batch classifier loss: 0.176806; batch adversarial loss: 0.462391\n",
      "epoch 29; iter: 0; batch classifier loss: 0.158225; batch adversarial loss: 0.510522\n",
      "epoch 30; iter: 0; batch classifier loss: 0.230162; batch adversarial loss: 0.438897\n",
      "epoch 31; iter: 0; batch classifier loss: 0.186866; batch adversarial loss: 0.470100\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126231; batch adversarial loss: 0.469235\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143114; batch adversarial loss: 0.429365\n",
      "epoch 34; iter: 0; batch classifier loss: 0.130357; batch adversarial loss: 0.477615\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122603; batch adversarial loss: 0.461332\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109722; batch adversarial loss: 0.506315\n",
      "epoch 37; iter: 0; batch classifier loss: 0.115040; batch adversarial loss: 0.369819\n",
      "epoch 38; iter: 0; batch classifier loss: 0.097993; batch adversarial loss: 0.501975\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107624; batch adversarial loss: 0.439827\n",
      "epoch 40; iter: 0; batch classifier loss: 0.185328; batch adversarial loss: 0.533684\n",
      "epoch 41; iter: 0; batch classifier loss: 0.174799; batch adversarial loss: 0.420739\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116342; batch adversarial loss: 0.493512\n",
      "epoch 43; iter: 0; batch classifier loss: 0.091344; batch adversarial loss: 0.500074\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123226; batch adversarial loss: 0.436891\n",
      "epoch 45; iter: 0; batch classifier loss: 0.084265; batch adversarial loss: 0.504405\n",
      "epoch 46; iter: 0; batch classifier loss: 0.122235; batch adversarial loss: 0.414442\n",
      "epoch 47; iter: 0; batch classifier loss: 0.102629; batch adversarial loss: 0.464372\n",
      "epoch 48; iter: 0; batch classifier loss: 0.095694; batch adversarial loss: 0.541902\n",
      "epoch 49; iter: 0; batch classifier loss: 0.079668; batch adversarial loss: 0.467917\n",
      "epoch 50; iter: 0; batch classifier loss: 0.054139; batch adversarial loss: 0.468811\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098683; batch adversarial loss: 0.456520\n",
      "epoch 52; iter: 0; batch classifier loss: 0.087671; batch adversarial loss: 0.414472\n",
      "epoch 53; iter: 0; batch classifier loss: 0.070217; batch adversarial loss: 0.427007\n",
      "epoch 54; iter: 0; batch classifier loss: 0.091049; batch adversarial loss: 0.396409\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077839; batch adversarial loss: 0.428870\n",
      "epoch 56; iter: 0; batch classifier loss: 0.089207; batch adversarial loss: 0.432187\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082957; batch adversarial loss: 0.468915\n",
      "epoch 58; iter: 0; batch classifier loss: 0.065610; batch adversarial loss: 0.459746\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067233; batch adversarial loss: 0.482278\n",
      "epoch 60; iter: 0; batch classifier loss: 0.058679; batch adversarial loss: 0.474826\n",
      "epoch 61; iter: 0; batch classifier loss: 0.057328; batch adversarial loss: 0.498850\n",
      "epoch 62; iter: 0; batch classifier loss: 0.068700; batch adversarial loss: 0.443476\n",
      "epoch 63; iter: 0; batch classifier loss: 0.066391; batch adversarial loss: 0.398001\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084172; batch adversarial loss: 0.416752\n",
      "epoch 65; iter: 0; batch classifier loss: 0.100282; batch adversarial loss: 0.404745\n",
      "epoch 66; iter: 0; batch classifier loss: 0.057507; batch adversarial loss: 0.416181\n",
      "epoch 67; iter: 0; batch classifier loss: 0.062892; batch adversarial loss: 0.444268\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060610; batch adversarial loss: 0.424802\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072892; batch adversarial loss: 0.443589\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078612; batch adversarial loss: 0.386200\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082123; batch adversarial loss: 0.443005\n",
      "epoch 72; iter: 0; batch classifier loss: 0.040459; batch adversarial loss: 0.423289\n",
      "epoch 73; iter: 0; batch classifier loss: 0.049216; batch adversarial loss: 0.386417\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053584; batch adversarial loss: 0.466470\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063097; batch adversarial loss: 0.322999\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046939; batch adversarial loss: 0.440002\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064259; batch adversarial loss: 0.395783\n",
      "epoch 78; iter: 0; batch classifier loss: 0.032001; batch adversarial loss: 0.486935\n",
      "epoch 79; iter: 0; batch classifier loss: 0.059185; batch adversarial loss: 0.404928\n",
      "epoch 80; iter: 0; batch classifier loss: 0.062510; batch adversarial loss: 0.381453\n",
      "epoch 81; iter: 0; batch classifier loss: 0.053436; batch adversarial loss: 0.385934\n",
      "epoch 82; iter: 0; batch classifier loss: 0.069517; batch adversarial loss: 0.405134\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073455; batch adversarial loss: 0.466237\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051000; batch adversarial loss: 0.520423\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055489; batch adversarial loss: 0.360861\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040601; batch adversarial loss: 0.469503\n",
      "epoch 87; iter: 0; batch classifier loss: 0.063801; batch adversarial loss: 0.421843\n",
      "epoch 88; iter: 0; batch classifier loss: 0.034069; batch adversarial loss: 0.482639\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050809; batch adversarial loss: 0.493928\n",
      "epoch 90; iter: 0; batch classifier loss: 0.119821; batch adversarial loss: 0.467979\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052277; batch adversarial loss: 0.421984\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047867; batch adversarial loss: 0.496925\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041065; batch adversarial loss: 0.554782\n",
      "epoch 94; iter: 0; batch classifier loss: 0.024592; batch adversarial loss: 0.413673\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050541; batch adversarial loss: 0.426663\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064466; batch adversarial loss: 0.421269\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043071; batch adversarial loss: 0.426210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.037140; batch adversarial loss: 0.399473\n",
      "epoch 99; iter: 0; batch classifier loss: 0.068593; batch adversarial loss: 0.491937\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039674; batch adversarial loss: 0.419500\n",
      "epoch 101; iter: 0; batch classifier loss: 0.034192; batch adversarial loss: 0.457275\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032825; batch adversarial loss: 0.452494\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042811; batch adversarial loss: 0.485191\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035177; batch adversarial loss: 0.498925\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041714; batch adversarial loss: 0.529646\n",
      "epoch 106; iter: 0; batch classifier loss: 0.038792; batch adversarial loss: 0.443913\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052794; batch adversarial loss: 0.403530\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040279; batch adversarial loss: 0.411124\n",
      "epoch 109; iter: 0; batch classifier loss: 0.014342; batch adversarial loss: 0.496462\n",
      "epoch 110; iter: 0; batch classifier loss: 0.022989; batch adversarial loss: 0.418199\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036353; batch adversarial loss: 0.351032\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031885; batch adversarial loss: 0.438115\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057617; batch adversarial loss: 0.463715\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034467; batch adversarial loss: 0.470216\n",
      "epoch 115; iter: 0; batch classifier loss: 0.020026; batch adversarial loss: 0.468423\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024984; batch adversarial loss: 0.461978\n",
      "epoch 117; iter: 0; batch classifier loss: 0.015030; batch adversarial loss: 0.435505\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047031; batch adversarial loss: 0.476591\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038617; batch adversarial loss: 0.446819\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054444; batch adversarial loss: 0.429914\n",
      "epoch 121; iter: 0; batch classifier loss: 0.012822; batch adversarial loss: 0.454361\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032380; batch adversarial loss: 0.412663\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040012; batch adversarial loss: 0.419882\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021971; batch adversarial loss: 0.463422\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032016; batch adversarial loss: 0.415674\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017803; batch adversarial loss: 0.438743\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031505; batch adversarial loss: 0.388202\n",
      "epoch 128; iter: 0; batch classifier loss: 0.020594; batch adversarial loss: 0.380156\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020696; batch adversarial loss: 0.510851\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019853; batch adversarial loss: 0.426011\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041622; batch adversarial loss: 0.464066\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034993; batch adversarial loss: 0.481767\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018202; batch adversarial loss: 0.472498\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035092; batch adversarial loss: 0.444164\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012929; batch adversarial loss: 0.496086\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032100; batch adversarial loss: 0.393219\n",
      "epoch 137; iter: 0; batch classifier loss: 0.007451; batch adversarial loss: 0.371608\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017286; batch adversarial loss: 0.488896\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038430; batch adversarial loss: 0.414316\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026996; batch adversarial loss: 0.402602\n",
      "epoch 141; iter: 0; batch classifier loss: 0.014544; batch adversarial loss: 0.436759\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014627; batch adversarial loss: 0.586623\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021329; batch adversarial loss: 0.523631\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028613; batch adversarial loss: 0.450028\n",
      "epoch 145; iter: 0; batch classifier loss: 0.062983; batch adversarial loss: 0.442850\n",
      "epoch 146; iter: 0; batch classifier loss: 0.006250; batch adversarial loss: 0.436127\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026288; batch adversarial loss: 0.469898\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035851; batch adversarial loss: 0.370721\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014029; batch adversarial loss: 0.461728\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024016; batch adversarial loss: 0.390596\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020821; batch adversarial loss: 0.423087\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024835; batch adversarial loss: 0.414012\n",
      "epoch 153; iter: 0; batch classifier loss: 0.007618; batch adversarial loss: 0.457707\n",
      "epoch 154; iter: 0; batch classifier loss: 0.008176; batch adversarial loss: 0.379442\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035455; batch adversarial loss: 0.409417\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025577; batch adversarial loss: 0.376415\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006579; batch adversarial loss: 0.501791\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008448; batch adversarial loss: 0.481374\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015094; batch adversarial loss: 0.402058\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016581; batch adversarial loss: 0.445859\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019657; batch adversarial loss: 0.414340\n",
      "epoch 162; iter: 0; batch classifier loss: 0.003438; batch adversarial loss: 0.443166\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009359; batch adversarial loss: 0.401124\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026999; batch adversarial loss: 0.455065\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007656; batch adversarial loss: 0.460217\n",
      "epoch 166; iter: 0; batch classifier loss: 0.008333; batch adversarial loss: 0.577432\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016011; batch adversarial loss: 0.515309\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021397; batch adversarial loss: 0.441746\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034571; batch adversarial loss: 0.483396\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007762; batch adversarial loss: 0.422587\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012625; batch adversarial loss: 0.493922\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024315; batch adversarial loss: 0.424899\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018747; batch adversarial loss: 0.497668\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008303; batch adversarial loss: 0.383181\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018903; batch adversarial loss: 0.489241\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011760; batch adversarial loss: 0.361639\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015237; batch adversarial loss: 0.408291\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012492; batch adversarial loss: 0.419949\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019028; batch adversarial loss: 0.473678\n",
      "epoch 180; iter: 0; batch classifier loss: 0.005763; batch adversarial loss: 0.488251\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008658; batch adversarial loss: 0.376475\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013447; batch adversarial loss: 0.388713\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023417; batch adversarial loss: 0.443627\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030610; batch adversarial loss: 0.419288\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009866; batch adversarial loss: 0.387479\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009442; batch adversarial loss: 0.479094\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017596; batch adversarial loss: 0.444367\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010024; batch adversarial loss: 0.442379\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016311; batch adversarial loss: 0.465353\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009817; batch adversarial loss: 0.428449\n",
      "epoch 191; iter: 0; batch classifier loss: 0.040550; batch adversarial loss: 0.487983\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015107; batch adversarial loss: 0.481759\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004303; batch adversarial loss: 0.469418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.006943; batch adversarial loss: 0.432536\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026757; batch adversarial loss: 0.527279\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007708; batch adversarial loss: 0.596009\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029787; batch adversarial loss: 0.421697\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005489; batch adversarial loss: 0.485025\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007946; batch adversarial loss: 0.404984\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706189; batch adversarial loss: 0.597728\n",
      "epoch 1; iter: 0; batch classifier loss: 0.379457; batch adversarial loss: 0.609153\n",
      "epoch 2; iter: 0; batch classifier loss: 0.450905; batch adversarial loss: 0.633789\n",
      "epoch 3; iter: 0; batch classifier loss: 0.445329; batch adversarial loss: 0.656990\n",
      "epoch 4; iter: 0; batch classifier loss: 0.523991; batch adversarial loss: 0.604806\n",
      "epoch 5; iter: 0; batch classifier loss: 0.562593; batch adversarial loss: 0.624043\n",
      "epoch 6; iter: 0; batch classifier loss: 0.537291; batch adversarial loss: 0.632416\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588243; batch adversarial loss: 0.553050\n",
      "epoch 8; iter: 0; batch classifier loss: 0.498546; batch adversarial loss: 0.576920\n",
      "epoch 9; iter: 0; batch classifier loss: 0.464680; batch adversarial loss: 0.510507\n",
      "epoch 10; iter: 0; batch classifier loss: 0.299144; batch adversarial loss: 0.521202\n",
      "epoch 11; iter: 0; batch classifier loss: 0.392287; batch adversarial loss: 0.464930\n",
      "epoch 12; iter: 0; batch classifier loss: 0.335168; batch adversarial loss: 0.545979\n",
      "epoch 13; iter: 0; batch classifier loss: 0.318106; batch adversarial loss: 0.525670\n",
      "epoch 14; iter: 0; batch classifier loss: 0.321872; batch adversarial loss: 0.494050\n",
      "epoch 15; iter: 0; batch classifier loss: 0.294922; batch adversarial loss: 0.471760\n",
      "epoch 16; iter: 0; batch classifier loss: 0.282614; batch adversarial loss: 0.445936\n",
      "epoch 17; iter: 0; batch classifier loss: 0.283421; batch adversarial loss: 0.503088\n",
      "epoch 18; iter: 0; batch classifier loss: 0.275759; batch adversarial loss: 0.469840\n",
      "epoch 19; iter: 0; batch classifier loss: 0.251094; batch adversarial loss: 0.443099\n",
      "epoch 20; iter: 0; batch classifier loss: 0.294031; batch adversarial loss: 0.425511\n",
      "epoch 21; iter: 0; batch classifier loss: 0.226739; batch adversarial loss: 0.456047\n",
      "epoch 22; iter: 0; batch classifier loss: 0.297600; batch adversarial loss: 0.449046\n",
      "epoch 23; iter: 0; batch classifier loss: 0.254411; batch adversarial loss: 0.470343\n",
      "epoch 24; iter: 0; batch classifier loss: 0.227396; batch adversarial loss: 0.491730\n",
      "epoch 25; iter: 0; batch classifier loss: 0.212999; batch adversarial loss: 0.470554\n",
      "epoch 26; iter: 0; batch classifier loss: 0.276650; batch adversarial loss: 0.483607\n",
      "epoch 27; iter: 0; batch classifier loss: 0.184658; batch adversarial loss: 0.483584\n",
      "epoch 28; iter: 0; batch classifier loss: 0.230881; batch adversarial loss: 0.463802\n",
      "epoch 29; iter: 0; batch classifier loss: 0.218359; batch adversarial loss: 0.512620\n",
      "epoch 30; iter: 0; batch classifier loss: 0.215492; batch adversarial loss: 0.405404\n",
      "epoch 31; iter: 0; batch classifier loss: 0.177516; batch adversarial loss: 0.519050\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181147; batch adversarial loss: 0.466823\n",
      "epoch 33; iter: 0; batch classifier loss: 0.180140; batch adversarial loss: 0.447852\n",
      "epoch 34; iter: 0; batch classifier loss: 0.179184; batch adversarial loss: 0.483506\n",
      "epoch 35; iter: 0; batch classifier loss: 0.257132; batch adversarial loss: 0.409681\n",
      "epoch 36; iter: 0; batch classifier loss: 0.165368; batch adversarial loss: 0.438449\n",
      "epoch 37; iter: 0; batch classifier loss: 0.203156; batch adversarial loss: 0.380783\n",
      "epoch 38; iter: 0; batch classifier loss: 0.222988; batch adversarial loss: 0.472561\n",
      "epoch 39; iter: 0; batch classifier loss: 0.219807; batch adversarial loss: 0.464100\n",
      "epoch 40; iter: 0; batch classifier loss: 0.221613; batch adversarial loss: 0.426959\n",
      "epoch 41; iter: 0; batch classifier loss: 0.243615; batch adversarial loss: 0.403609\n",
      "epoch 42; iter: 0; batch classifier loss: 0.187066; batch adversarial loss: 0.465249\n",
      "epoch 43; iter: 0; batch classifier loss: 0.215341; batch adversarial loss: 0.448082\n",
      "epoch 44; iter: 0; batch classifier loss: 0.187372; batch adversarial loss: 0.516413\n",
      "epoch 45; iter: 0; batch classifier loss: 0.238371; batch adversarial loss: 0.417520\n",
      "epoch 46; iter: 0; batch classifier loss: 0.156976; batch adversarial loss: 0.381209\n",
      "epoch 47; iter: 0; batch classifier loss: 0.213053; batch adversarial loss: 0.479974\n",
      "epoch 48; iter: 0; batch classifier loss: 0.213578; batch adversarial loss: 0.435707\n",
      "epoch 49; iter: 0; batch classifier loss: 0.183612; batch adversarial loss: 0.358446\n",
      "epoch 50; iter: 0; batch classifier loss: 0.197071; batch adversarial loss: 0.444349\n",
      "epoch 51; iter: 0; batch classifier loss: 0.214915; batch adversarial loss: 0.547251\n",
      "epoch 52; iter: 0; batch classifier loss: 0.219270; batch adversarial loss: 0.423758\n",
      "epoch 53; iter: 0; batch classifier loss: 0.239750; batch adversarial loss: 0.421438\n",
      "epoch 54; iter: 0; batch classifier loss: 0.228877; batch adversarial loss: 0.376532\n",
      "epoch 55; iter: 0; batch classifier loss: 0.217552; batch adversarial loss: 0.374901\n",
      "epoch 56; iter: 0; batch classifier loss: 0.227349; batch adversarial loss: 0.508528\n",
      "epoch 57; iter: 0; batch classifier loss: 0.208985; batch adversarial loss: 0.446887\n",
      "epoch 58; iter: 0; batch classifier loss: 0.252584; batch adversarial loss: 0.445120\n",
      "epoch 59; iter: 0; batch classifier loss: 0.212605; batch adversarial loss: 0.366007\n",
      "epoch 60; iter: 0; batch classifier loss: 0.257075; batch adversarial loss: 0.476599\n",
      "epoch 61; iter: 0; batch classifier loss: 0.243061; batch adversarial loss: 0.468559\n",
      "epoch 62; iter: 0; batch classifier loss: 0.236541; batch adversarial loss: 0.545972\n",
      "epoch 63; iter: 0; batch classifier loss: 0.214430; batch adversarial loss: 0.412530\n",
      "epoch 64; iter: 0; batch classifier loss: 0.198574; batch adversarial loss: 0.495479\n",
      "epoch 65; iter: 0; batch classifier loss: 0.209463; batch adversarial loss: 0.426440\n",
      "epoch 66; iter: 0; batch classifier loss: 0.222282; batch adversarial loss: 0.544446\n",
      "epoch 67; iter: 0; batch classifier loss: 0.233325; batch adversarial loss: 0.421258\n",
      "epoch 68; iter: 0; batch classifier loss: 0.234853; batch adversarial loss: 0.530027\n",
      "epoch 69; iter: 0; batch classifier loss: 0.159082; batch adversarial loss: 0.458877\n",
      "epoch 70; iter: 0; batch classifier loss: 0.267562; batch adversarial loss: 0.565817\n",
      "epoch 71; iter: 0; batch classifier loss: 0.207770; batch adversarial loss: 0.557147\n",
      "epoch 72; iter: 0; batch classifier loss: 0.277620; batch adversarial loss: 0.421857\n",
      "epoch 73; iter: 0; batch classifier loss: 0.259325; batch adversarial loss: 0.422321\n",
      "epoch 74; iter: 0; batch classifier loss: 0.205674; batch adversarial loss: 0.458825\n",
      "epoch 75; iter: 0; batch classifier loss: 0.213490; batch adversarial loss: 0.434859\n",
      "epoch 76; iter: 0; batch classifier loss: 0.301672; batch adversarial loss: 0.495447\n",
      "epoch 77; iter: 0; batch classifier loss: 0.109360; batch adversarial loss: 0.484202\n",
      "epoch 78; iter: 0; batch classifier loss: 0.208335; batch adversarial loss: 0.383435\n",
      "epoch 79; iter: 0; batch classifier loss: 0.235541; batch adversarial loss: 0.435334\n",
      "epoch 80; iter: 0; batch classifier loss: 0.271799; batch adversarial loss: 0.520539\n",
      "epoch 81; iter: 0; batch classifier loss: 0.187417; batch adversarial loss: 0.446705\n",
      "epoch 82; iter: 0; batch classifier loss: 0.237115; batch adversarial loss: 0.545738\n",
      "epoch 83; iter: 0; batch classifier loss: 0.200820; batch adversarial loss: 0.484232\n",
      "epoch 84; iter: 0; batch classifier loss: 0.240736; batch adversarial loss: 0.487491\n",
      "epoch 85; iter: 0; batch classifier loss: 0.208933; batch adversarial loss: 0.471152\n",
      "epoch 86; iter: 0; batch classifier loss: 0.231354; batch adversarial loss: 0.482882\n",
      "epoch 87; iter: 0; batch classifier loss: 0.172213; batch adversarial loss: 0.507754\n",
      "epoch 88; iter: 0; batch classifier loss: 0.244097; batch adversarial loss: 0.483953\n",
      "epoch 89; iter: 0; batch classifier loss: 0.205542; batch adversarial loss: 0.508205\n",
      "epoch 90; iter: 0; batch classifier loss: 0.171387; batch adversarial loss: 0.471437\n",
      "epoch 91; iter: 0; batch classifier loss: 0.181856; batch adversarial loss: 0.482990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.174684; batch adversarial loss: 0.458696\n",
      "epoch 93; iter: 0; batch classifier loss: 0.232011; batch adversarial loss: 0.422217\n",
      "epoch 94; iter: 0; batch classifier loss: 0.151447; batch adversarial loss: 0.483444\n",
      "epoch 95; iter: 0; batch classifier loss: 0.148668; batch adversarial loss: 0.532891\n",
      "epoch 96; iter: 0; batch classifier loss: 0.220135; batch adversarial loss: 0.485607\n",
      "epoch 97; iter: 0; batch classifier loss: 0.173766; batch adversarial loss: 0.384563\n",
      "epoch 98; iter: 0; batch classifier loss: 0.225295; batch adversarial loss: 0.483267\n",
      "epoch 99; iter: 0; batch classifier loss: 0.217311; batch adversarial loss: 0.519713\n",
      "epoch 100; iter: 0; batch classifier loss: 0.156909; batch adversarial loss: 0.483938\n",
      "epoch 101; iter: 0; batch classifier loss: 0.258802; batch adversarial loss: 0.372855\n",
      "epoch 102; iter: 0; batch classifier loss: 0.182174; batch adversarial loss: 0.470385\n",
      "epoch 103; iter: 0; batch classifier loss: 0.220475; batch adversarial loss: 0.384592\n",
      "epoch 104; iter: 0; batch classifier loss: 0.213418; batch adversarial loss: 0.409806\n",
      "epoch 105; iter: 0; batch classifier loss: 0.260920; batch adversarial loss: 0.507532\n",
      "epoch 106; iter: 0; batch classifier loss: 0.240911; batch adversarial loss: 0.484129\n",
      "epoch 107; iter: 0; batch classifier loss: 0.220325; batch adversarial loss: 0.422262\n",
      "epoch 108; iter: 0; batch classifier loss: 0.122273; batch adversarial loss: 0.483512\n",
      "epoch 109; iter: 0; batch classifier loss: 0.161898; batch adversarial loss: 0.481574\n",
      "epoch 110; iter: 0; batch classifier loss: 0.171838; batch adversarial loss: 0.383399\n",
      "epoch 111; iter: 0; batch classifier loss: 0.182739; batch adversarial loss: 0.421509\n",
      "epoch 112; iter: 0; batch classifier loss: 0.179318; batch adversarial loss: 0.483676\n",
      "epoch 113; iter: 0; batch classifier loss: 0.111359; batch adversarial loss: 0.458229\n",
      "epoch 114; iter: 0; batch classifier loss: 0.171452; batch adversarial loss: 0.420735\n",
      "epoch 115; iter: 0; batch classifier loss: 0.154364; batch adversarial loss: 0.458730\n",
      "epoch 116; iter: 0; batch classifier loss: 0.183681; batch adversarial loss: 0.364926\n",
      "epoch 117; iter: 0; batch classifier loss: 0.137962; batch adversarial loss: 0.443960\n",
      "epoch 118; iter: 0; batch classifier loss: 0.122228; batch adversarial loss: 0.667705\n",
      "epoch 119; iter: 0; batch classifier loss: 0.163552; batch adversarial loss: 0.470457\n",
      "epoch 120; iter: 0; batch classifier loss: 0.150532; batch adversarial loss: 0.443582\n",
      "epoch 121; iter: 0; batch classifier loss: 0.093068; batch adversarial loss: 0.405869\n",
      "epoch 122; iter: 0; batch classifier loss: 0.100705; batch adversarial loss: 0.430187\n",
      "epoch 123; iter: 0; batch classifier loss: 0.068230; batch adversarial loss: 0.492963\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057681; batch adversarial loss: 0.383175\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050042; batch adversarial loss: 0.497231\n",
      "epoch 126; iter: 0; batch classifier loss: 0.070091; batch adversarial loss: 0.395814\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034403; batch adversarial loss: 0.446324\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033855; batch adversarial loss: 0.477555\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056336; batch adversarial loss: 0.504200\n",
      "epoch 130; iter: 0; batch classifier loss: 0.064517; batch adversarial loss: 0.423737\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054007; batch adversarial loss: 0.467735\n",
      "epoch 132; iter: 0; batch classifier loss: 0.072940; batch adversarial loss: 0.453424\n",
      "epoch 133; iter: 0; batch classifier loss: 0.057140; batch adversarial loss: 0.407392\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025436; batch adversarial loss: 0.490956\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022287; batch adversarial loss: 0.530245\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030679; batch adversarial loss: 0.517291\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029908; batch adversarial loss: 0.280475\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032911; batch adversarial loss: 0.517792\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016633; batch adversarial loss: 0.482759\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048029; batch adversarial loss: 0.478409\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037609; batch adversarial loss: 0.409452\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013020; batch adversarial loss: 0.472518\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037139; batch adversarial loss: 0.458231\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014915; batch adversarial loss: 0.492290\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019529; batch adversarial loss: 0.382802\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051058; batch adversarial loss: 0.469909\n",
      "epoch 147; iter: 0; batch classifier loss: 0.058569; batch adversarial loss: 0.492449\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021833; batch adversarial loss: 0.367057\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053728; batch adversarial loss: 0.517570\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052349; batch adversarial loss: 0.382174\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012060; batch adversarial loss: 0.448708\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016627; batch adversarial loss: 0.448558\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028577; batch adversarial loss: 0.424813\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022980; batch adversarial loss: 0.468674\n",
      "epoch 155; iter: 0; batch classifier loss: 0.065850; batch adversarial loss: 0.449169\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015385; batch adversarial loss: 0.475576\n",
      "epoch 157; iter: 0; batch classifier loss: 0.052427; batch adversarial loss: 0.485805\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019462; batch adversarial loss: 0.466089\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013000; batch adversarial loss: 0.355792\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016580; batch adversarial loss: 0.432176\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028218; batch adversarial loss: 0.474098\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027769; batch adversarial loss: 0.447935\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034303; batch adversarial loss: 0.345889\n",
      "epoch 164; iter: 0; batch classifier loss: 0.041898; batch adversarial loss: 0.330404\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020142; batch adversarial loss: 0.453554\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027249; batch adversarial loss: 0.414950\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024415; batch adversarial loss: 0.418884\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024912; batch adversarial loss: 0.417319\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016105; batch adversarial loss: 0.449152\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015783; batch adversarial loss: 0.438930\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028361; batch adversarial loss: 0.393665\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011246; batch adversarial loss: 0.460242\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035714; batch adversarial loss: 0.439236\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029894; batch adversarial loss: 0.511162\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026852; batch adversarial loss: 0.436647\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009352; batch adversarial loss: 0.525789\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031192; batch adversarial loss: 0.376560\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013201; batch adversarial loss: 0.457776\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034678; batch adversarial loss: 0.479962\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015114; batch adversarial loss: 0.502452\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014988; batch adversarial loss: 0.422039\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008065; batch adversarial loss: 0.461956\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009088; batch adversarial loss: 0.464204\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024462; batch adversarial loss: 0.503771\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025916; batch adversarial loss: 0.443552\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010734; batch adversarial loss: 0.534763\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030134; batch adversarial loss: 0.432007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.033353; batch adversarial loss: 0.422560\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028027; batch adversarial loss: 0.403639\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006108; batch adversarial loss: 0.458914\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021729; batch adversarial loss: 0.456247\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021102; batch adversarial loss: 0.506512\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007191; batch adversarial loss: 0.479218\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014422; batch adversarial loss: 0.396561\n",
      "epoch 195; iter: 0; batch classifier loss: 0.041882; batch adversarial loss: 0.493423\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015194; batch adversarial loss: 0.457427\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011883; batch adversarial loss: 0.489387\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017309; batch adversarial loss: 0.413657\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009241; batch adversarial loss: 0.453454\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676584; batch adversarial loss: 0.704784\n",
      "epoch 1; iter: 0; batch classifier loss: 0.550717; batch adversarial loss: 0.642468\n",
      "epoch 2; iter: 0; batch classifier loss: 0.484492; batch adversarial loss: 0.628163\n",
      "epoch 3; iter: 0; batch classifier loss: 0.470515; batch adversarial loss: 0.615757\n",
      "epoch 4; iter: 0; batch classifier loss: 0.498966; batch adversarial loss: 0.603374\n",
      "epoch 5; iter: 0; batch classifier loss: 0.524777; batch adversarial loss: 0.589105\n",
      "epoch 6; iter: 0; batch classifier loss: 0.459252; batch adversarial loss: 0.611487\n",
      "epoch 7; iter: 0; batch classifier loss: 0.476110; batch adversarial loss: 0.583256\n",
      "epoch 8; iter: 0; batch classifier loss: 0.501588; batch adversarial loss: 0.563020\n",
      "epoch 9; iter: 0; batch classifier loss: 0.415168; batch adversarial loss: 0.571870\n",
      "epoch 10; iter: 0; batch classifier loss: 0.394626; batch adversarial loss: 0.554658\n",
      "epoch 11; iter: 0; batch classifier loss: 0.384757; batch adversarial loss: 0.502861\n",
      "epoch 12; iter: 0; batch classifier loss: 0.304178; batch adversarial loss: 0.504780\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331814; batch adversarial loss: 0.559810\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302653; batch adversarial loss: 0.480858\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310196; batch adversarial loss: 0.487350\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336411; batch adversarial loss: 0.439656\n",
      "epoch 17; iter: 0; batch classifier loss: 0.297903; batch adversarial loss: 0.453324\n",
      "epoch 18; iter: 0; batch classifier loss: 0.310458; batch adversarial loss: 0.500777\n",
      "epoch 19; iter: 0; batch classifier loss: 0.271294; batch adversarial loss: 0.502910\n",
      "epoch 20; iter: 0; batch classifier loss: 0.284876; batch adversarial loss: 0.585690\n",
      "epoch 21; iter: 0; batch classifier loss: 0.271995; batch adversarial loss: 0.441213\n",
      "epoch 22; iter: 0; batch classifier loss: 0.240613; batch adversarial loss: 0.489123\n",
      "epoch 23; iter: 0; batch classifier loss: 0.297312; batch adversarial loss: 0.471567\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213274; batch adversarial loss: 0.545559\n",
      "epoch 25; iter: 0; batch classifier loss: 0.212164; batch adversarial loss: 0.525378\n",
      "epoch 26; iter: 0; batch classifier loss: 0.251236; batch adversarial loss: 0.350688\n",
      "epoch 27; iter: 0; batch classifier loss: 0.221339; batch adversarial loss: 0.455745\n",
      "epoch 28; iter: 0; batch classifier loss: 0.198051; batch adversarial loss: 0.411775\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176448; batch adversarial loss: 0.435233\n",
      "epoch 30; iter: 0; batch classifier loss: 0.216185; batch adversarial loss: 0.495095\n",
      "epoch 31; iter: 0; batch classifier loss: 0.223119; batch adversarial loss: 0.453114\n",
      "epoch 32; iter: 0; batch classifier loss: 0.211606; batch adversarial loss: 0.442229\n",
      "epoch 33; iter: 0; batch classifier loss: 0.212366; batch adversarial loss: 0.433846\n",
      "epoch 34; iter: 0; batch classifier loss: 0.220855; batch adversarial loss: 0.480536\n",
      "epoch 35; iter: 0; batch classifier loss: 0.230754; batch adversarial loss: 0.412201\n",
      "epoch 36; iter: 0; batch classifier loss: 0.211071; batch adversarial loss: 0.490985\n",
      "epoch 37; iter: 0; batch classifier loss: 0.199199; batch adversarial loss: 0.456098\n",
      "epoch 38; iter: 0; batch classifier loss: 0.220282; batch adversarial loss: 0.501651\n",
      "epoch 39; iter: 0; batch classifier loss: 0.282765; batch adversarial loss: 0.405532\n",
      "epoch 40; iter: 0; batch classifier loss: 0.247812; batch adversarial loss: 0.466645\n",
      "epoch 41; iter: 0; batch classifier loss: 0.246944; batch adversarial loss: 0.447200\n",
      "epoch 42; iter: 0; batch classifier loss: 0.221975; batch adversarial loss: 0.478980\n",
      "epoch 43; iter: 0; batch classifier loss: 0.206461; batch adversarial loss: 0.379564\n",
      "epoch 44; iter: 0; batch classifier loss: 0.203503; batch adversarial loss: 0.424504\n",
      "epoch 45; iter: 0; batch classifier loss: 0.233921; batch adversarial loss: 0.518345\n",
      "epoch 46; iter: 0; batch classifier loss: 0.242090; batch adversarial loss: 0.472230\n",
      "epoch 47; iter: 0; batch classifier loss: 0.244640; batch adversarial loss: 0.435224\n",
      "epoch 48; iter: 0; batch classifier loss: 0.179398; batch adversarial loss: 0.400514\n",
      "epoch 49; iter: 0; batch classifier loss: 0.225936; batch adversarial loss: 0.483050\n",
      "epoch 50; iter: 0; batch classifier loss: 0.223635; batch adversarial loss: 0.412347\n",
      "epoch 51; iter: 0; batch classifier loss: 0.192994; batch adversarial loss: 0.494367\n",
      "epoch 52; iter: 0; batch classifier loss: 0.159965; batch adversarial loss: 0.471037\n",
      "epoch 53; iter: 0; batch classifier loss: 0.222376; batch adversarial loss: 0.554527\n",
      "epoch 54; iter: 0; batch classifier loss: 0.178884; batch adversarial loss: 0.482900\n",
      "epoch 55; iter: 0; batch classifier loss: 0.280492; batch adversarial loss: 0.435335\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102252; batch adversarial loss: 0.398025\n",
      "epoch 57; iter: 0; batch classifier loss: 0.124975; batch adversarial loss: 0.407174\n",
      "epoch 58; iter: 0; batch classifier loss: 0.154128; batch adversarial loss: 0.472714\n",
      "epoch 59; iter: 0; batch classifier loss: 0.151495; batch adversarial loss: 0.406676\n",
      "epoch 60; iter: 0; batch classifier loss: 0.127222; batch adversarial loss: 0.444519\n",
      "epoch 61; iter: 0; batch classifier loss: 0.158377; batch adversarial loss: 0.443861\n",
      "epoch 62; iter: 0; batch classifier loss: 0.174425; batch adversarial loss: 0.462280\n",
      "epoch 63; iter: 0; batch classifier loss: 0.216538; batch adversarial loss: 0.484150\n",
      "epoch 64; iter: 0; batch classifier loss: 0.220954; batch adversarial loss: 0.542088\n",
      "epoch 65; iter: 0; batch classifier loss: 0.145050; batch adversarial loss: 0.460883\n",
      "epoch 66; iter: 0; batch classifier loss: 0.219558; batch adversarial loss: 0.358617\n",
      "epoch 67; iter: 0; batch classifier loss: 0.160764; batch adversarial loss: 0.459659\n",
      "epoch 68; iter: 0; batch classifier loss: 0.175355; batch adversarial loss: 0.459635\n",
      "epoch 69; iter: 0; batch classifier loss: 0.165696; batch adversarial loss: 0.434275\n",
      "epoch 70; iter: 0; batch classifier loss: 0.184599; batch adversarial loss: 0.521375\n",
      "epoch 71; iter: 0; batch classifier loss: 0.259434; batch adversarial loss: 0.371749\n",
      "epoch 72; iter: 0; batch classifier loss: 0.166992; batch adversarial loss: 0.533326\n",
      "epoch 73; iter: 0; batch classifier loss: 0.154975; batch adversarial loss: 0.484514\n",
      "epoch 74; iter: 0; batch classifier loss: 0.180593; batch adversarial loss: 0.459801\n",
      "epoch 75; iter: 0; batch classifier loss: 0.192530; batch adversarial loss: 0.520400\n",
      "epoch 76; iter: 0; batch classifier loss: 0.206402; batch adversarial loss: 0.510271\n",
      "epoch 77; iter: 0; batch classifier loss: 0.170765; batch adversarial loss: 0.447056\n",
      "epoch 78; iter: 0; batch classifier loss: 0.211388; batch adversarial loss: 0.459257\n",
      "epoch 79; iter: 0; batch classifier loss: 0.198680; batch adversarial loss: 0.494996\n",
      "epoch 80; iter: 0; batch classifier loss: 0.202823; batch adversarial loss: 0.544820\n",
      "epoch 81; iter: 0; batch classifier loss: 0.145301; batch adversarial loss: 0.471448\n",
      "epoch 82; iter: 0; batch classifier loss: 0.222832; batch adversarial loss: 0.348206\n",
      "epoch 83; iter: 0; batch classifier loss: 0.164021; batch adversarial loss: 0.532926\n",
      "epoch 84; iter: 0; batch classifier loss: 0.159830; batch adversarial loss: 0.409115\n",
      "epoch 85; iter: 0; batch classifier loss: 0.178736; batch adversarial loss: 0.409202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.228258; batch adversarial loss: 0.459394\n",
      "epoch 87; iter: 0; batch classifier loss: 0.253847; batch adversarial loss: 0.470384\n",
      "epoch 88; iter: 0; batch classifier loss: 0.122506; batch adversarial loss: 0.517218\n",
      "epoch 89; iter: 0; batch classifier loss: 0.149347; batch adversarial loss: 0.581802\n",
      "epoch 90; iter: 0; batch classifier loss: 0.116488; batch adversarial loss: 0.481275\n",
      "epoch 91; iter: 0; batch classifier loss: 0.176064; batch adversarial loss: 0.544754\n",
      "epoch 92; iter: 0; batch classifier loss: 0.208193; batch adversarial loss: 0.481808\n",
      "epoch 93; iter: 0; batch classifier loss: 0.143584; batch adversarial loss: 0.483529\n",
      "epoch 94; iter: 0; batch classifier loss: 0.135467; batch adversarial loss: 0.517610\n",
      "epoch 95; iter: 0; batch classifier loss: 0.144615; batch adversarial loss: 0.461414\n",
      "epoch 96; iter: 0; batch classifier loss: 0.142891; batch adversarial loss: 0.508778\n",
      "epoch 97; iter: 0; batch classifier loss: 0.132666; batch adversarial loss: 0.467547\n",
      "epoch 98; iter: 0; batch classifier loss: 0.160835; batch adversarial loss: 0.437834\n",
      "epoch 99; iter: 0; batch classifier loss: 0.134681; batch adversarial loss: 0.454598\n",
      "epoch 100; iter: 0; batch classifier loss: 0.127042; batch adversarial loss: 0.482578\n",
      "epoch 101; iter: 0; batch classifier loss: 0.163759; batch adversarial loss: 0.533083\n",
      "epoch 102; iter: 0; batch classifier loss: 0.134829; batch adversarial loss: 0.496209\n",
      "epoch 103; iter: 0; batch classifier loss: 0.091332; batch adversarial loss: 0.364017\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061552; batch adversarial loss: 0.434593\n",
      "epoch 105; iter: 0; batch classifier loss: 0.131249; batch adversarial loss: 0.440386\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062547; batch adversarial loss: 0.505951\n",
      "epoch 107; iter: 0; batch classifier loss: 0.075907; batch adversarial loss: 0.453110\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057522; batch adversarial loss: 0.406951\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053220; batch adversarial loss: 0.429449\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068168; batch adversarial loss: 0.465449\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037693; batch adversarial loss: 0.506521\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044996; batch adversarial loss: 0.421399\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058616; batch adversarial loss: 0.422688\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042959; batch adversarial loss: 0.469439\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070045; batch adversarial loss: 0.421029\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037531; batch adversarial loss: 0.375699\n",
      "epoch 117; iter: 0; batch classifier loss: 0.062105; batch adversarial loss: 0.482924\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050751; batch adversarial loss: 0.442110\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030240; batch adversarial loss: 0.376830\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039818; batch adversarial loss: 0.452721\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027455; batch adversarial loss: 0.388134\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032241; batch adversarial loss: 0.536810\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017489; batch adversarial loss: 0.403514\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031112; batch adversarial loss: 0.434418\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043655; batch adversarial loss: 0.417331\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031144; batch adversarial loss: 0.488795\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025006; batch adversarial loss: 0.406586\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025456; batch adversarial loss: 0.447548\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042624; batch adversarial loss: 0.485244\n",
      "epoch 130; iter: 0; batch classifier loss: 0.015834; batch adversarial loss: 0.425456\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027570; batch adversarial loss: 0.489818\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025081; batch adversarial loss: 0.459453\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023107; batch adversarial loss: 0.428839\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040044; batch adversarial loss: 0.480952\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022167; batch adversarial loss: 0.487310\n",
      "epoch 136; iter: 0; batch classifier loss: 0.011054; batch adversarial loss: 0.411716\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029237; batch adversarial loss: 0.527171\n",
      "epoch 138; iter: 0; batch classifier loss: 0.084384; batch adversarial loss: 0.480405\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028484; batch adversarial loss: 0.408246\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030036; batch adversarial loss: 0.441650\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024872; batch adversarial loss: 0.497709\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030037; batch adversarial loss: 0.453705\n",
      "epoch 143; iter: 0; batch classifier loss: 0.084013; batch adversarial loss: 0.464247\n",
      "epoch 144; iter: 0; batch classifier loss: 0.009524; batch adversarial loss: 0.428369\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032977; batch adversarial loss: 0.560444\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032054; batch adversarial loss: 0.417442\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020582; batch adversarial loss: 0.425177\n",
      "epoch 148; iter: 0; batch classifier loss: 0.082305; batch adversarial loss: 0.426902\n",
      "epoch 149; iter: 0; batch classifier loss: 0.058890; batch adversarial loss: 0.440696\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025587; batch adversarial loss: 0.522754\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033327; batch adversarial loss: 0.453968\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014168; batch adversarial loss: 0.444907\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027106; batch adversarial loss: 0.429478\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022940; batch adversarial loss: 0.377068\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021770; batch adversarial loss: 0.416087\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011892; batch adversarial loss: 0.504220\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012718; batch adversarial loss: 0.453240\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027795; batch adversarial loss: 0.517365\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024031; batch adversarial loss: 0.493348\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012827; batch adversarial loss: 0.478927\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011763; batch adversarial loss: 0.471808\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017920; batch adversarial loss: 0.462400\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014563; batch adversarial loss: 0.472264\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043680; batch adversarial loss: 0.439001\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017386; batch adversarial loss: 0.412144\n",
      "epoch 166; iter: 0; batch classifier loss: 0.006635; batch adversarial loss: 0.392579\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031771; batch adversarial loss: 0.494514\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031115; batch adversarial loss: 0.465101\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036909; batch adversarial loss: 0.446415\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034915; batch adversarial loss: 0.422242\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015813; batch adversarial loss: 0.422902\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017759; batch adversarial loss: 0.502567\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016483; batch adversarial loss: 0.430648\n",
      "epoch 174; iter: 0; batch classifier loss: 0.056991; batch adversarial loss: 0.424401\n",
      "epoch 175; iter: 0; batch classifier loss: 0.005719; batch adversarial loss: 0.510068\n",
      "epoch 176; iter: 0; batch classifier loss: 0.059825; batch adversarial loss: 0.333712\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010037; batch adversarial loss: 0.339932\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014028; batch adversarial loss: 0.488721\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019229; batch adversarial loss: 0.433907\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034856; batch adversarial loss: 0.425351\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014034; batch adversarial loss: 0.528517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.020422; batch adversarial loss: 0.503537\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005012; batch adversarial loss: 0.401792\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035379; batch adversarial loss: 0.332261\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009650; batch adversarial loss: 0.456208\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022575; batch adversarial loss: 0.402570\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015539; batch adversarial loss: 0.365532\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004336; batch adversarial loss: 0.442656\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027340; batch adversarial loss: 0.475564\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014877; batch adversarial loss: 0.413876\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007715; batch adversarial loss: 0.478094\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017560; batch adversarial loss: 0.442651\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015557; batch adversarial loss: 0.443595\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012884; batch adversarial loss: 0.525864\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009988; batch adversarial loss: 0.444693\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027849; batch adversarial loss: 0.416465\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022071; batch adversarial loss: 0.430390\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029850; batch adversarial loss: 0.493334\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022951; batch adversarial loss: 0.540882\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687582; batch adversarial loss: 0.557290\n",
      "epoch 1; iter: 0; batch classifier loss: 0.332527; batch adversarial loss: 0.611733\n",
      "epoch 2; iter: 0; batch classifier loss: 0.316222; batch adversarial loss: 0.593113\n",
      "epoch 3; iter: 0; batch classifier loss: 0.368049; batch adversarial loss: 0.577219\n",
      "epoch 4; iter: 0; batch classifier loss: 0.318663; batch adversarial loss: 0.564546\n",
      "epoch 5; iter: 0; batch classifier loss: 0.292437; batch adversarial loss: 0.598325\n",
      "epoch 6; iter: 0; batch classifier loss: 0.335016; batch adversarial loss: 0.565031\n",
      "epoch 7; iter: 0; batch classifier loss: 0.341354; batch adversarial loss: 0.492023\n",
      "epoch 8; iter: 0; batch classifier loss: 0.225036; batch adversarial loss: 0.560640\n",
      "epoch 9; iter: 0; batch classifier loss: 0.253553; batch adversarial loss: 0.449412\n",
      "epoch 10; iter: 0; batch classifier loss: 0.320975; batch adversarial loss: 0.504662\n",
      "epoch 11; iter: 0; batch classifier loss: 0.256485; batch adversarial loss: 0.497902\n",
      "epoch 12; iter: 0; batch classifier loss: 0.302994; batch adversarial loss: 0.576716\n",
      "epoch 13; iter: 0; batch classifier loss: 0.284392; batch adversarial loss: 0.552797\n",
      "epoch 14; iter: 0; batch classifier loss: 0.435426; batch adversarial loss: 0.579129\n",
      "epoch 15; iter: 0; batch classifier loss: 0.335122; batch adversarial loss: 0.542780\n",
      "epoch 16; iter: 0; batch classifier loss: 0.347379; batch adversarial loss: 0.504127\n",
      "epoch 17; iter: 0; batch classifier loss: 0.303382; batch adversarial loss: 0.535679\n",
      "epoch 18; iter: 0; batch classifier loss: 0.330246; batch adversarial loss: 0.496326\n",
      "epoch 19; iter: 0; batch classifier loss: 0.344835; batch adversarial loss: 0.538147\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490340; batch adversarial loss: 0.484982\n",
      "epoch 21; iter: 0; batch classifier loss: 0.407640; batch adversarial loss: 0.482644\n",
      "epoch 22; iter: 0; batch classifier loss: 0.266105; batch adversarial loss: 0.372077\n",
      "epoch 23; iter: 0; batch classifier loss: 0.217671; batch adversarial loss: 0.439003\n",
      "epoch 24; iter: 0; batch classifier loss: 0.152152; batch adversarial loss: 0.453000\n",
      "epoch 25; iter: 0; batch classifier loss: 0.170109; batch adversarial loss: 0.456835\n",
      "epoch 26; iter: 0; batch classifier loss: 0.179181; batch adversarial loss: 0.406815\n",
      "epoch 27; iter: 0; batch classifier loss: 0.160444; batch adversarial loss: 0.398073\n",
      "epoch 28; iter: 0; batch classifier loss: 0.150804; batch adversarial loss: 0.423227\n",
      "epoch 29; iter: 0; batch classifier loss: 0.232786; batch adversarial loss: 0.469934\n",
      "epoch 30; iter: 0; batch classifier loss: 0.178836; batch adversarial loss: 0.419903\n",
      "epoch 31; iter: 0; batch classifier loss: 0.129557; batch adversarial loss: 0.396112\n",
      "epoch 32; iter: 0; batch classifier loss: 0.122802; batch adversarial loss: 0.445853\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128637; batch adversarial loss: 0.446606\n",
      "epoch 34; iter: 0; batch classifier loss: 0.104608; batch adversarial loss: 0.423804\n",
      "epoch 35; iter: 0; batch classifier loss: 0.094274; batch adversarial loss: 0.374502\n",
      "epoch 36; iter: 0; batch classifier loss: 0.092665; batch adversarial loss: 0.503330\n",
      "epoch 37; iter: 0; batch classifier loss: 0.125474; batch adversarial loss: 0.423184\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148312; batch adversarial loss: 0.392136\n",
      "epoch 39; iter: 0; batch classifier loss: 0.116283; batch adversarial loss: 0.419195\n",
      "epoch 40; iter: 0; batch classifier loss: 0.114009; batch adversarial loss: 0.505149\n",
      "epoch 41; iter: 0; batch classifier loss: 0.131265; batch adversarial loss: 0.396625\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105831; batch adversarial loss: 0.388742\n",
      "epoch 43; iter: 0; batch classifier loss: 0.116011; batch adversarial loss: 0.476677\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124235; batch adversarial loss: 0.413493\n",
      "epoch 45; iter: 0; batch classifier loss: 0.129685; batch adversarial loss: 0.452061\n",
      "epoch 46; iter: 0; batch classifier loss: 0.165961; batch adversarial loss: 0.363837\n",
      "epoch 47; iter: 0; batch classifier loss: 0.128183; batch adversarial loss: 0.457390\n",
      "epoch 48; iter: 0; batch classifier loss: 0.182208; batch adversarial loss: 0.499116\n",
      "epoch 49; iter: 0; batch classifier loss: 0.159635; batch adversarial loss: 0.468190\n",
      "epoch 50; iter: 0; batch classifier loss: 0.106312; batch adversarial loss: 0.477135\n",
      "epoch 51; iter: 0; batch classifier loss: 0.113323; batch adversarial loss: 0.428403\n",
      "epoch 52; iter: 0; batch classifier loss: 0.178647; batch adversarial loss: 0.456937\n",
      "epoch 53; iter: 0; batch classifier loss: 0.137248; batch adversarial loss: 0.454220\n",
      "epoch 54; iter: 0; batch classifier loss: 0.146043; batch adversarial loss: 0.437298\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117296; batch adversarial loss: 0.440859\n",
      "epoch 56; iter: 0; batch classifier loss: 0.115493; batch adversarial loss: 0.516365\n",
      "epoch 57; iter: 0; batch classifier loss: 0.083802; batch adversarial loss: 0.461678\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101611; batch adversarial loss: 0.410532\n",
      "epoch 59; iter: 0; batch classifier loss: 0.159372; batch adversarial loss: 0.406239\n",
      "epoch 60; iter: 0; batch classifier loss: 0.140287; batch adversarial loss: 0.462538\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078614; batch adversarial loss: 0.450833\n",
      "epoch 62; iter: 0; batch classifier loss: 0.124087; batch adversarial loss: 0.431119\n",
      "epoch 63; iter: 0; batch classifier loss: 0.141658; batch adversarial loss: 0.463830\n",
      "epoch 64; iter: 0; batch classifier loss: 0.128767; batch adversarial loss: 0.425852\n",
      "epoch 65; iter: 0; batch classifier loss: 0.106334; batch adversarial loss: 0.481893\n",
      "epoch 66; iter: 0; batch classifier loss: 0.139186; batch adversarial loss: 0.400652\n",
      "epoch 67; iter: 0; batch classifier loss: 0.142737; batch adversarial loss: 0.455538\n",
      "epoch 68; iter: 0; batch classifier loss: 0.151307; batch adversarial loss: 0.428232\n",
      "epoch 69; iter: 0; batch classifier loss: 0.123200; batch adversarial loss: 0.441105\n",
      "epoch 70; iter: 0; batch classifier loss: 0.153990; batch adversarial loss: 0.435000\n",
      "epoch 71; iter: 0; batch classifier loss: 0.111979; batch adversarial loss: 0.417599\n",
      "epoch 72; iter: 0; batch classifier loss: 0.135718; batch adversarial loss: 0.433771\n",
      "epoch 73; iter: 0; batch classifier loss: 0.187244; batch adversarial loss: 0.411620\n",
      "epoch 74; iter: 0; batch classifier loss: 0.166734; batch adversarial loss: 0.449756\n",
      "epoch 75; iter: 0; batch classifier loss: 0.177098; batch adversarial loss: 0.400614\n",
      "epoch 76; iter: 0; batch classifier loss: 0.157130; batch adversarial loss: 0.430535\n",
      "epoch 77; iter: 0; batch classifier loss: 0.095814; batch adversarial loss: 0.404055\n",
      "epoch 78; iter: 0; batch classifier loss: 0.164776; batch adversarial loss: 0.457657\n",
      "epoch 79; iter: 0; batch classifier loss: 0.128844; batch adversarial loss: 0.348196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.229891; batch adversarial loss: 0.407338\n",
      "epoch 81; iter: 0; batch classifier loss: 0.123823; batch adversarial loss: 0.395189\n",
      "epoch 82; iter: 0; batch classifier loss: 0.124682; batch adversarial loss: 0.433390\n",
      "epoch 83; iter: 0; batch classifier loss: 0.172569; batch adversarial loss: 0.395020\n",
      "epoch 84; iter: 0; batch classifier loss: 0.146760; batch adversarial loss: 0.519146\n",
      "epoch 85; iter: 0; batch classifier loss: 0.183774; batch adversarial loss: 0.465302\n",
      "epoch 86; iter: 0; batch classifier loss: 0.162227; batch adversarial loss: 0.475152\n",
      "epoch 87; iter: 0; batch classifier loss: 0.119750; batch adversarial loss: 0.517024\n",
      "epoch 88; iter: 0; batch classifier loss: 0.176040; batch adversarial loss: 0.442379\n",
      "epoch 89; iter: 0; batch classifier loss: 0.079530; batch adversarial loss: 0.496751\n",
      "epoch 90; iter: 0; batch classifier loss: 0.194876; batch adversarial loss: 0.474837\n",
      "epoch 91; iter: 0; batch classifier loss: 0.142974; batch adversarial loss: 0.422396\n",
      "epoch 92; iter: 0; batch classifier loss: 0.163631; batch adversarial loss: 0.504174\n",
      "epoch 93; iter: 0; batch classifier loss: 0.196500; batch adversarial loss: 0.393669\n",
      "epoch 94; iter: 0; batch classifier loss: 0.149212; batch adversarial loss: 0.321604\n",
      "epoch 95; iter: 0; batch classifier loss: 0.160270; batch adversarial loss: 0.449600\n",
      "epoch 96; iter: 0; batch classifier loss: 0.154600; batch adversarial loss: 0.565912\n",
      "epoch 97; iter: 0; batch classifier loss: 0.205020; batch adversarial loss: 0.395965\n",
      "epoch 98; iter: 0; batch classifier loss: 0.148612; batch adversarial loss: 0.432555\n",
      "epoch 99; iter: 0; batch classifier loss: 0.235548; batch adversarial loss: 0.458477\n",
      "epoch 100; iter: 0; batch classifier loss: 0.163979; batch adversarial loss: 0.484185\n",
      "epoch 101; iter: 0; batch classifier loss: 0.129327; batch adversarial loss: 0.479428\n",
      "epoch 102; iter: 0; batch classifier loss: 0.175249; batch adversarial loss: 0.488991\n",
      "epoch 103; iter: 0; batch classifier loss: 0.119434; batch adversarial loss: 0.520617\n",
      "epoch 104; iter: 0; batch classifier loss: 0.159761; batch adversarial loss: 0.466666\n",
      "epoch 105; iter: 0; batch classifier loss: 0.164258; batch adversarial loss: 0.412755\n",
      "epoch 106; iter: 0; batch classifier loss: 0.141454; batch adversarial loss: 0.421356\n",
      "epoch 107; iter: 0; batch classifier loss: 0.120069; batch adversarial loss: 0.434914\n",
      "epoch 108; iter: 0; batch classifier loss: 0.117065; batch adversarial loss: 0.488634\n",
      "epoch 109; iter: 0; batch classifier loss: 0.095218; batch adversarial loss: 0.461620\n",
      "epoch 110; iter: 0; batch classifier loss: 0.165383; batch adversarial loss: 0.406437\n",
      "epoch 111; iter: 0; batch classifier loss: 0.125441; batch adversarial loss: 0.499030\n",
      "epoch 112; iter: 0; batch classifier loss: 0.227990; batch adversarial loss: 0.477723\n",
      "epoch 113; iter: 0; batch classifier loss: 0.139676; batch adversarial loss: 0.419612\n",
      "epoch 114; iter: 0; batch classifier loss: 0.109871; batch adversarial loss: 0.459953\n",
      "epoch 115; iter: 0; batch classifier loss: 0.157121; batch adversarial loss: 0.407756\n",
      "epoch 116; iter: 0; batch classifier loss: 0.103777; batch adversarial loss: 0.371509\n",
      "epoch 117; iter: 0; batch classifier loss: 0.133691; batch adversarial loss: 0.407262\n",
      "epoch 118; iter: 0; batch classifier loss: 0.208481; batch adversarial loss: 0.434036\n",
      "epoch 119; iter: 0; batch classifier loss: 0.167368; batch adversarial loss: 0.434496\n",
      "epoch 120; iter: 0; batch classifier loss: 0.153816; batch adversarial loss: 0.419850\n",
      "epoch 121; iter: 0; batch classifier loss: 0.090705; batch adversarial loss: 0.464983\n",
      "epoch 122; iter: 0; batch classifier loss: 0.148311; batch adversarial loss: 0.329868\n",
      "epoch 123; iter: 0; batch classifier loss: 0.108561; batch adversarial loss: 0.392548\n",
      "epoch 124; iter: 0; batch classifier loss: 0.125936; batch adversarial loss: 0.496514\n",
      "epoch 125; iter: 0; batch classifier loss: 0.175672; batch adversarial loss: 0.470295\n",
      "epoch 126; iter: 0; batch classifier loss: 0.139756; batch adversarial loss: 0.504319\n",
      "epoch 127; iter: 0; batch classifier loss: 0.079902; batch adversarial loss: 0.478054\n",
      "epoch 128; iter: 0; batch classifier loss: 0.209944; batch adversarial loss: 0.487007\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056129; batch adversarial loss: 0.489529\n",
      "epoch 130; iter: 0; batch classifier loss: 0.120894; batch adversarial loss: 0.427826\n",
      "epoch 131; iter: 0; batch classifier loss: 0.173372; batch adversarial loss: 0.484886\n",
      "epoch 132; iter: 0; batch classifier loss: 0.064224; batch adversarial loss: 0.481184\n",
      "epoch 133; iter: 0; batch classifier loss: 0.083407; batch adversarial loss: 0.490763\n",
      "epoch 134; iter: 0; batch classifier loss: 0.146646; batch adversarial loss: 0.528637\n",
      "epoch 135; iter: 0; batch classifier loss: 0.124042; batch adversarial loss: 0.414755\n",
      "epoch 136; iter: 0; batch classifier loss: 0.101061; batch adversarial loss: 0.463674\n",
      "epoch 137; iter: 0; batch classifier loss: 0.129962; batch adversarial loss: 0.444470\n",
      "epoch 138; iter: 0; batch classifier loss: 0.107007; batch adversarial loss: 0.499039\n",
      "epoch 139; iter: 0; batch classifier loss: 0.067752; batch adversarial loss: 0.418336\n",
      "epoch 140; iter: 0; batch classifier loss: 0.128640; batch adversarial loss: 0.420948\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045006; batch adversarial loss: 0.395046\n",
      "epoch 142; iter: 0; batch classifier loss: 0.038228; batch adversarial loss: 0.495425\n",
      "epoch 143; iter: 0; batch classifier loss: 0.048213; batch adversarial loss: 0.520289\n",
      "epoch 144; iter: 0; batch classifier loss: 0.069976; batch adversarial loss: 0.484317\n",
      "epoch 145; iter: 0; batch classifier loss: 0.062481; batch adversarial loss: 0.301875\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039241; batch adversarial loss: 0.497038\n",
      "epoch 147; iter: 0; batch classifier loss: 0.141643; batch adversarial loss: 0.416572\n",
      "epoch 148; iter: 0; batch classifier loss: 0.093634; batch adversarial loss: 0.441491\n",
      "epoch 149; iter: 0; batch classifier loss: 0.045296; batch adversarial loss: 0.534895\n",
      "epoch 150; iter: 0; batch classifier loss: 0.045494; batch adversarial loss: 0.485327\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017138; batch adversarial loss: 0.567566\n",
      "epoch 152; iter: 0; batch classifier loss: 0.047143; batch adversarial loss: 0.506622\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040903; batch adversarial loss: 0.472930\n",
      "epoch 154; iter: 0; batch classifier loss: 0.056311; batch adversarial loss: 0.430534\n",
      "epoch 155; iter: 0; batch classifier loss: 0.057367; batch adversarial loss: 0.448197\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034735; batch adversarial loss: 0.404365\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038112; batch adversarial loss: 0.537882\n",
      "epoch 158; iter: 0; batch classifier loss: 0.069686; batch adversarial loss: 0.482329\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014277; batch adversarial loss: 0.498854\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044996; batch adversarial loss: 0.460319\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032743; batch adversarial loss: 0.471613\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033672; batch adversarial loss: 0.464344\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039474; batch adversarial loss: 0.462419\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032569; batch adversarial loss: 0.318348\n",
      "epoch 165; iter: 0; batch classifier loss: 0.079713; batch adversarial loss: 0.445360\n",
      "epoch 166; iter: 0; batch classifier loss: 0.062363; batch adversarial loss: 0.446498\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031426; batch adversarial loss: 0.384696\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024581; batch adversarial loss: 0.510166\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023898; batch adversarial loss: 0.438505\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024459; batch adversarial loss: 0.471508\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047510; batch adversarial loss: 0.475389\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015313; batch adversarial loss: 0.495788\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018240; batch adversarial loss: 0.534008\n",
      "epoch 174; iter: 0; batch classifier loss: 0.048666; batch adversarial loss: 0.557024\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019934; batch adversarial loss: 0.453938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.035632; batch adversarial loss: 0.477989\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037975; batch adversarial loss: 0.453834\n",
      "epoch 178; iter: 0; batch classifier loss: 0.046705; batch adversarial loss: 0.489710\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026001; batch adversarial loss: 0.447248\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026907; batch adversarial loss: 0.428069\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021392; batch adversarial loss: 0.435542\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034037; batch adversarial loss: 0.578707\n",
      "epoch 183; iter: 0; batch classifier loss: 0.066098; batch adversarial loss: 0.407162\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020314; batch adversarial loss: 0.351182\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012118; batch adversarial loss: 0.503950\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013730; batch adversarial loss: 0.388530\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017796; batch adversarial loss: 0.488220\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008917; batch adversarial loss: 0.475807\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013722; batch adversarial loss: 0.557054\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029691; batch adversarial loss: 0.494736\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015922; batch adversarial loss: 0.380294\n",
      "epoch 192; iter: 0; batch classifier loss: 0.039518; batch adversarial loss: 0.479554\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031245; batch adversarial loss: 0.463913\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008230; batch adversarial loss: 0.389614\n",
      "epoch 195; iter: 0; batch classifier loss: 0.039996; batch adversarial loss: 0.386417\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027262; batch adversarial loss: 0.508765\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019536; batch adversarial loss: 0.521148\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028148; batch adversarial loss: 0.393725\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011628; batch adversarial loss: 0.472464\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697135; batch adversarial loss: 0.676944\n",
      "epoch 1; iter: 0; batch classifier loss: 0.549863; batch adversarial loss: 0.606731\n",
      "epoch 2; iter: 0; batch classifier loss: 0.455936; batch adversarial loss: 0.620447\n",
      "epoch 3; iter: 0; batch classifier loss: 0.511437; batch adversarial loss: 0.614070\n",
      "epoch 4; iter: 0; batch classifier loss: 0.374937; batch adversarial loss: 0.598939\n",
      "epoch 5; iter: 0; batch classifier loss: 0.480975; batch adversarial loss: 0.605436\n",
      "epoch 6; iter: 0; batch classifier loss: 0.418399; batch adversarial loss: 0.584696\n",
      "epoch 7; iter: 0; batch classifier loss: 0.440945; batch adversarial loss: 0.561846\n",
      "epoch 8; iter: 0; batch classifier loss: 0.402967; batch adversarial loss: 0.576315\n",
      "epoch 9; iter: 0; batch classifier loss: 0.442039; batch adversarial loss: 0.554942\n",
      "epoch 10; iter: 0; batch classifier loss: 0.441278; batch adversarial loss: 0.574978\n",
      "epoch 11; iter: 0; batch classifier loss: 0.361446; batch adversarial loss: 0.520814\n",
      "epoch 12; iter: 0; batch classifier loss: 0.287822; batch adversarial loss: 0.541531\n",
      "epoch 13; iter: 0; batch classifier loss: 0.341536; batch adversarial loss: 0.537844\n",
      "epoch 14; iter: 0; batch classifier loss: 0.289258; batch adversarial loss: 0.472340\n",
      "epoch 15; iter: 0; batch classifier loss: 0.234176; batch adversarial loss: 0.486189\n",
      "epoch 16; iter: 0; batch classifier loss: 0.318953; batch adversarial loss: 0.512113\n",
      "epoch 17; iter: 0; batch classifier loss: 0.273709; batch adversarial loss: 0.571953\n",
      "epoch 18; iter: 0; batch classifier loss: 0.235832; batch adversarial loss: 0.507945\n",
      "epoch 19; iter: 0; batch classifier loss: 0.243500; batch adversarial loss: 0.539505\n",
      "epoch 20; iter: 0; batch classifier loss: 0.278267; batch adversarial loss: 0.437927\n",
      "epoch 21; iter: 0; batch classifier loss: 0.279723; batch adversarial loss: 0.492942\n",
      "epoch 22; iter: 0; batch classifier loss: 0.229807; batch adversarial loss: 0.537443\n",
      "epoch 23; iter: 0; batch classifier loss: 0.340742; batch adversarial loss: 0.470654\n",
      "epoch 24; iter: 0; batch classifier loss: 0.286219; batch adversarial loss: 0.440840\n",
      "epoch 25; iter: 0; batch classifier loss: 0.221850; batch adversarial loss: 0.475779\n",
      "epoch 26; iter: 0; batch classifier loss: 0.238933; batch adversarial loss: 0.589658\n",
      "epoch 27; iter: 0; batch classifier loss: 0.204255; batch adversarial loss: 0.559612\n",
      "epoch 28; iter: 0; batch classifier loss: 0.265004; batch adversarial loss: 0.447908\n",
      "epoch 29; iter: 0; batch classifier loss: 0.244270; batch adversarial loss: 0.460945\n",
      "epoch 30; iter: 0; batch classifier loss: 0.280370; batch adversarial loss: 0.450934\n",
      "epoch 31; iter: 0; batch classifier loss: 0.276077; batch adversarial loss: 0.441166\n",
      "epoch 32; iter: 0; batch classifier loss: 0.287926; batch adversarial loss: 0.381278\n",
      "epoch 33; iter: 0; batch classifier loss: 0.260366; batch adversarial loss: 0.484954\n",
      "epoch 34; iter: 0; batch classifier loss: 0.232493; batch adversarial loss: 0.391196\n",
      "epoch 35; iter: 0; batch classifier loss: 0.267541; batch adversarial loss: 0.480177\n",
      "epoch 36; iter: 0; batch classifier loss: 0.211702; batch adversarial loss: 0.533428\n",
      "epoch 37; iter: 0; batch classifier loss: 0.204752; batch adversarial loss: 0.460742\n",
      "epoch 38; iter: 0; batch classifier loss: 0.317641; batch adversarial loss: 0.420780\n",
      "epoch 39; iter: 0; batch classifier loss: 0.223888; batch adversarial loss: 0.437171\n",
      "epoch 40; iter: 0; batch classifier loss: 0.207062; batch adversarial loss: 0.475193\n",
      "epoch 41; iter: 0; batch classifier loss: 0.249531; batch adversarial loss: 0.488642\n",
      "epoch 42; iter: 0; batch classifier loss: 0.308062; batch adversarial loss: 0.412709\n",
      "epoch 43; iter: 0; batch classifier loss: 0.347725; batch adversarial loss: 0.389470\n",
      "epoch 44; iter: 0; batch classifier loss: 0.262226; batch adversarial loss: 0.445093\n",
      "epoch 45; iter: 0; batch classifier loss: 0.240615; batch adversarial loss: 0.462799\n",
      "epoch 46; iter: 0; batch classifier loss: 0.275909; batch adversarial loss: 0.493730\n",
      "epoch 47; iter: 0; batch classifier loss: 0.299984; batch adversarial loss: 0.345675\n",
      "epoch 48; iter: 0; batch classifier loss: 0.335084; batch adversarial loss: 0.436493\n",
      "epoch 49; iter: 0; batch classifier loss: 0.191233; batch adversarial loss: 0.528813\n",
      "epoch 50; iter: 0; batch classifier loss: 0.141822; batch adversarial loss: 0.492337\n",
      "epoch 51; iter: 0; batch classifier loss: 0.071995; batch adversarial loss: 0.468132\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100309; batch adversarial loss: 0.554911\n",
      "epoch 53; iter: 0; batch classifier loss: 0.070023; batch adversarial loss: 0.464515\n",
      "epoch 54; iter: 0; batch classifier loss: 0.086002; batch adversarial loss: 0.460581\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077794; batch adversarial loss: 0.430735\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098578; batch adversarial loss: 0.516780\n",
      "epoch 57; iter: 0; batch classifier loss: 0.064342; batch adversarial loss: 0.419084\n",
      "epoch 58; iter: 0; batch classifier loss: 0.124844; batch adversarial loss: 0.415223\n",
      "epoch 59; iter: 0; batch classifier loss: 0.094228; batch adversarial loss: 0.345931\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061169; batch adversarial loss: 0.405964\n",
      "epoch 61; iter: 0; batch classifier loss: 0.084856; batch adversarial loss: 0.404748\n",
      "epoch 62; iter: 0; batch classifier loss: 0.106504; batch adversarial loss: 0.439714\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100968; batch adversarial loss: 0.434178\n",
      "epoch 64; iter: 0; batch classifier loss: 0.044475; batch adversarial loss: 0.481505\n",
      "epoch 65; iter: 0; batch classifier loss: 0.071790; batch adversarial loss: 0.541278\n",
      "epoch 66; iter: 0; batch classifier loss: 0.056093; batch adversarial loss: 0.432278\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087187; batch adversarial loss: 0.367953\n",
      "epoch 68; iter: 0; batch classifier loss: 0.065665; batch adversarial loss: 0.426829\n",
      "epoch 69; iter: 0; batch classifier loss: 0.096621; batch adversarial loss: 0.467085\n",
      "epoch 70; iter: 0; batch classifier loss: 0.122084; batch adversarial loss: 0.477250\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081519; batch adversarial loss: 0.520598\n",
      "epoch 72; iter: 0; batch classifier loss: 0.050761; batch adversarial loss: 0.377355\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068937; batch adversarial loss: 0.456609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.089652; batch adversarial loss: 0.460984\n",
      "epoch 75; iter: 0; batch classifier loss: 0.123688; batch adversarial loss: 0.317357\n",
      "epoch 76; iter: 0; batch classifier loss: 0.091747; batch adversarial loss: 0.405645\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076785; batch adversarial loss: 0.473443\n",
      "epoch 78; iter: 0; batch classifier loss: 0.092106; batch adversarial loss: 0.571941\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074903; batch adversarial loss: 0.502250\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056504; batch adversarial loss: 0.348206\n",
      "epoch 81; iter: 0; batch classifier loss: 0.059409; batch adversarial loss: 0.400865\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090158; batch adversarial loss: 0.562987\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083297; batch adversarial loss: 0.388888\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051454; batch adversarial loss: 0.484110\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084805; batch adversarial loss: 0.399996\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061877; batch adversarial loss: 0.483190\n",
      "epoch 87; iter: 0; batch classifier loss: 0.039778; batch adversarial loss: 0.411651\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050378; batch adversarial loss: 0.489371\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056127; batch adversarial loss: 0.449782\n",
      "epoch 90; iter: 0; batch classifier loss: 0.034024; batch adversarial loss: 0.391986\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071122; batch adversarial loss: 0.420710\n",
      "epoch 92; iter: 0; batch classifier loss: 0.093930; batch adversarial loss: 0.440315\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065942; batch adversarial loss: 0.431880\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053117; batch adversarial loss: 0.394820\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065176; batch adversarial loss: 0.462316\n",
      "epoch 96; iter: 0; batch classifier loss: 0.110633; batch adversarial loss: 0.450866\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062299; batch adversarial loss: 0.430259\n",
      "epoch 98; iter: 0; batch classifier loss: 0.090730; batch adversarial loss: 0.413222\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059663; batch adversarial loss: 0.465746\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054667; batch adversarial loss: 0.514186\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061673; batch adversarial loss: 0.459275\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078607; batch adversarial loss: 0.491871\n",
      "epoch 103; iter: 0; batch classifier loss: 0.120251; batch adversarial loss: 0.457545\n",
      "epoch 104; iter: 0; batch classifier loss: 0.042414; batch adversarial loss: 0.495871\n",
      "epoch 105; iter: 0; batch classifier loss: 0.063438; batch adversarial loss: 0.419989\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041348; batch adversarial loss: 0.433250\n",
      "epoch 107; iter: 0; batch classifier loss: 0.060893; batch adversarial loss: 0.394186\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058392; batch adversarial loss: 0.499666\n",
      "epoch 109; iter: 0; batch classifier loss: 0.084136; batch adversarial loss: 0.431777\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045981; batch adversarial loss: 0.427031\n",
      "epoch 111; iter: 0; batch classifier loss: 0.074557; batch adversarial loss: 0.468608\n",
      "epoch 112; iter: 0; batch classifier loss: 0.098364; batch adversarial loss: 0.512921\n",
      "epoch 113; iter: 0; batch classifier loss: 0.074457; batch adversarial loss: 0.438931\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062583; batch adversarial loss: 0.452458\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048916; batch adversarial loss: 0.460262\n",
      "epoch 116; iter: 0; batch classifier loss: 0.067081; batch adversarial loss: 0.425632\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053651; batch adversarial loss: 0.465242\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056269; batch adversarial loss: 0.403082\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036795; batch adversarial loss: 0.417436\n",
      "epoch 120; iter: 0; batch classifier loss: 0.076131; batch adversarial loss: 0.479411\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035674; batch adversarial loss: 0.497065\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031937; batch adversarial loss: 0.426291\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048351; batch adversarial loss: 0.517052\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022682; batch adversarial loss: 0.479865\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062695; batch adversarial loss: 0.543680\n",
      "epoch 126; iter: 0; batch classifier loss: 0.064913; batch adversarial loss: 0.404285\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029884; batch adversarial loss: 0.549510\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045273; batch adversarial loss: 0.412344\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033573; batch adversarial loss: 0.386580\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035981; batch adversarial loss: 0.476320\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049736; batch adversarial loss: 0.330133\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042312; batch adversarial loss: 0.381292\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026152; batch adversarial loss: 0.420304\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032672; batch adversarial loss: 0.524283\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039688; batch adversarial loss: 0.479129\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033903; batch adversarial loss: 0.455118\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035771; batch adversarial loss: 0.491652\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046450; batch adversarial loss: 0.453113\n",
      "epoch 139; iter: 0; batch classifier loss: 0.053110; batch adversarial loss: 0.395662\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023402; batch adversarial loss: 0.428049\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032690; batch adversarial loss: 0.408233\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024267; batch adversarial loss: 0.477320\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020730; batch adversarial loss: 0.447970\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029866; batch adversarial loss: 0.490451\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026713; batch adversarial loss: 0.451661\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026762; batch adversarial loss: 0.409173\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036658; batch adversarial loss: 0.397584\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021436; batch adversarial loss: 0.318543\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033267; batch adversarial loss: 0.508326\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024555; batch adversarial loss: 0.498437\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044285; batch adversarial loss: 0.532747\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015850; batch adversarial loss: 0.482691\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035682; batch adversarial loss: 0.522885\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013920; batch adversarial loss: 0.461351\n",
      "epoch 155; iter: 0; batch classifier loss: 0.054179; batch adversarial loss: 0.448901\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032020; batch adversarial loss: 0.543058\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017881; batch adversarial loss: 0.545831\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015250; batch adversarial loss: 0.530454\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030747; batch adversarial loss: 0.442271\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037276; batch adversarial loss: 0.510074\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016517; batch adversarial loss: 0.437498\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014030; batch adversarial loss: 0.475104\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038737; batch adversarial loss: 0.456034\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009178; batch adversarial loss: 0.454905\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031680; batch adversarial loss: 0.357293\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011486; batch adversarial loss: 0.424139\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012703; batch adversarial loss: 0.613670\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034353; batch adversarial loss: 0.513033\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018398; batch adversarial loss: 0.415027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.012672; batch adversarial loss: 0.531590\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036442; batch adversarial loss: 0.530618\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032973; batch adversarial loss: 0.496292\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022715; batch adversarial loss: 0.423643\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037375; batch adversarial loss: 0.531632\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016279; batch adversarial loss: 0.506562\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023007; batch adversarial loss: 0.501835\n",
      "epoch 177; iter: 0; batch classifier loss: 0.063997; batch adversarial loss: 0.543416\n",
      "epoch 178; iter: 0; batch classifier loss: 0.050109; batch adversarial loss: 0.435834\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024958; batch adversarial loss: 0.571775\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017712; batch adversarial loss: 0.374702\n",
      "epoch 181; iter: 0; batch classifier loss: 0.043682; batch adversarial loss: 0.397630\n",
      "epoch 182; iter: 0; batch classifier loss: 0.058636; batch adversarial loss: 0.432896\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031277; batch adversarial loss: 0.502028\n",
      "epoch 184; iter: 0; batch classifier loss: 0.072121; batch adversarial loss: 0.562026\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018889; batch adversarial loss: 0.520792\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031450; batch adversarial loss: 0.489064\n",
      "epoch 187; iter: 0; batch classifier loss: 0.062995; batch adversarial loss: 0.479243\n",
      "epoch 188; iter: 0; batch classifier loss: 0.042540; batch adversarial loss: 0.480988\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027142; batch adversarial loss: 0.411973\n",
      "epoch 190; iter: 0; batch classifier loss: 0.080036; batch adversarial loss: 0.503099\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025751; batch adversarial loss: 0.421316\n",
      "epoch 192; iter: 0; batch classifier loss: 0.060895; batch adversarial loss: 0.587863\n",
      "epoch 193; iter: 0; batch classifier loss: 0.077736; batch adversarial loss: 0.541115\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019775; batch adversarial loss: 0.497271\n",
      "epoch 195; iter: 0; batch classifier loss: 0.051586; batch adversarial loss: 0.573630\n",
      "epoch 196; iter: 0; batch classifier loss: 0.044239; batch adversarial loss: 0.560270\n",
      "epoch 197; iter: 0; batch classifier loss: 0.111776; batch adversarial loss: 0.636678\n",
      "epoch 198; iter: 0; batch classifier loss: 0.042720; batch adversarial loss: 0.435119\n",
      "epoch 199; iter: 0; batch classifier loss: 0.161525; batch adversarial loss: 0.594913\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688197; batch adversarial loss: 0.813381\n",
      "epoch 1; iter: 0; batch classifier loss: 0.478821; batch adversarial loss: 0.801966\n",
      "epoch 2; iter: 0; batch classifier loss: 0.472643; batch adversarial loss: 0.758653\n",
      "epoch 3; iter: 0; batch classifier loss: 0.468910; batch adversarial loss: 0.724148\n",
      "epoch 4; iter: 0; batch classifier loss: 0.479736; batch adversarial loss: 0.676274\n",
      "epoch 5; iter: 0; batch classifier loss: 0.637330; batch adversarial loss: 0.602950\n",
      "epoch 6; iter: 0; batch classifier loss: 0.357806; batch adversarial loss: 0.567707\n",
      "epoch 7; iter: 0; batch classifier loss: 0.276274; batch adversarial loss: 0.562508\n",
      "epoch 8; iter: 0; batch classifier loss: 0.263179; batch adversarial loss: 0.554451\n",
      "epoch 9; iter: 0; batch classifier loss: 0.265625; batch adversarial loss: 0.566432\n",
      "epoch 10; iter: 0; batch classifier loss: 0.238805; batch adversarial loss: 0.530039\n",
      "epoch 11; iter: 0; batch classifier loss: 0.207128; batch adversarial loss: 0.528876\n",
      "epoch 12; iter: 0; batch classifier loss: 0.232722; batch adversarial loss: 0.516122\n",
      "epoch 13; iter: 0; batch classifier loss: 0.280551; batch adversarial loss: 0.498208\n",
      "epoch 14; iter: 0; batch classifier loss: 0.281475; batch adversarial loss: 0.503965\n",
      "epoch 15; iter: 0; batch classifier loss: 0.218809; batch adversarial loss: 0.510109\n",
      "epoch 16; iter: 0; batch classifier loss: 0.260330; batch adversarial loss: 0.517207\n",
      "epoch 17; iter: 0; batch classifier loss: 0.301533; batch adversarial loss: 0.438436\n",
      "epoch 18; iter: 0; batch classifier loss: 0.342013; batch adversarial loss: 0.458707\n",
      "epoch 19; iter: 0; batch classifier loss: 0.390347; batch adversarial loss: 0.523777\n",
      "epoch 20; iter: 0; batch classifier loss: 0.357718; batch adversarial loss: 0.614688\n",
      "epoch 21; iter: 0; batch classifier loss: 0.320686; batch adversarial loss: 0.519864\n",
      "epoch 22; iter: 0; batch classifier loss: 0.347339; batch adversarial loss: 0.488734\n",
      "epoch 23; iter: 0; batch classifier loss: 0.355051; batch adversarial loss: 0.504066\n",
      "epoch 24; iter: 0; batch classifier loss: 0.234836; batch adversarial loss: 0.561079\n",
      "epoch 25; iter: 0; batch classifier loss: 0.217715; batch adversarial loss: 0.546420\n",
      "epoch 26; iter: 0; batch classifier loss: 0.298649; batch adversarial loss: 0.426542\n",
      "epoch 27; iter: 0; batch classifier loss: 0.174399; batch adversarial loss: 0.462916\n",
      "epoch 28; iter: 0; batch classifier loss: 0.180812; batch adversarial loss: 0.487393\n",
      "epoch 29; iter: 0; batch classifier loss: 0.242322; batch adversarial loss: 0.481735\n",
      "epoch 30; iter: 0; batch classifier loss: 0.197561; batch adversarial loss: 0.432154\n",
      "epoch 31; iter: 0; batch classifier loss: 0.246918; batch adversarial loss: 0.470594\n",
      "epoch 32; iter: 0; batch classifier loss: 0.182376; batch adversarial loss: 0.453573\n",
      "epoch 33; iter: 0; batch classifier loss: 0.240840; batch adversarial loss: 0.445157\n",
      "epoch 34; iter: 0; batch classifier loss: 0.202051; batch adversarial loss: 0.462417\n",
      "epoch 35; iter: 0; batch classifier loss: 0.172926; batch adversarial loss: 0.438609\n",
      "epoch 36; iter: 0; batch classifier loss: 0.211003; batch adversarial loss: 0.474771\n",
      "epoch 37; iter: 0; batch classifier loss: 0.215095; batch adversarial loss: 0.475497\n",
      "epoch 38; iter: 0; batch classifier loss: 0.203998; batch adversarial loss: 0.448368\n",
      "epoch 39; iter: 0; batch classifier loss: 0.206159; batch adversarial loss: 0.414535\n",
      "epoch 40; iter: 0; batch classifier loss: 0.229694; batch adversarial loss: 0.448520\n",
      "epoch 41; iter: 0; batch classifier loss: 0.159655; batch adversarial loss: 0.535349\n",
      "epoch 42; iter: 0; batch classifier loss: 0.230970; batch adversarial loss: 0.413691\n",
      "epoch 43; iter: 0; batch classifier loss: 0.164240; batch adversarial loss: 0.441945\n",
      "epoch 44; iter: 0; batch classifier loss: 0.201159; batch adversarial loss: 0.487468\n",
      "epoch 45; iter: 0; batch classifier loss: 0.206173; batch adversarial loss: 0.536879\n",
      "epoch 46; iter: 0; batch classifier loss: 0.171597; batch adversarial loss: 0.504423\n",
      "epoch 47; iter: 0; batch classifier loss: 0.175929; batch adversarial loss: 0.439179\n",
      "epoch 48; iter: 0; batch classifier loss: 0.162918; batch adversarial loss: 0.490538\n",
      "epoch 49; iter: 0; batch classifier loss: 0.174758; batch adversarial loss: 0.451452\n",
      "epoch 50; iter: 0; batch classifier loss: 0.256403; batch adversarial loss: 0.409593\n",
      "epoch 51; iter: 0; batch classifier loss: 0.138827; batch adversarial loss: 0.462814\n",
      "epoch 52; iter: 0; batch classifier loss: 0.228598; batch adversarial loss: 0.440138\n",
      "epoch 53; iter: 0; batch classifier loss: 0.171175; batch adversarial loss: 0.435659\n",
      "epoch 54; iter: 0; batch classifier loss: 0.128325; batch adversarial loss: 0.481106\n",
      "epoch 55; iter: 0; batch classifier loss: 0.201479; batch adversarial loss: 0.437467\n",
      "epoch 56; iter: 0; batch classifier loss: 0.197068; batch adversarial loss: 0.505827\n",
      "epoch 57; iter: 0; batch classifier loss: 0.163333; batch adversarial loss: 0.369542\n",
      "epoch 58; iter: 0; batch classifier loss: 0.137098; batch adversarial loss: 0.418138\n",
      "epoch 59; iter: 0; batch classifier loss: 0.161760; batch adversarial loss: 0.448153\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118444; batch adversarial loss: 0.432425\n",
      "epoch 61; iter: 0; batch classifier loss: 0.094020; batch adversarial loss: 0.381420\n",
      "epoch 62; iter: 0; batch classifier loss: 0.143364; batch adversarial loss: 0.432727\n",
      "epoch 63; iter: 0; batch classifier loss: 0.108219; batch adversarial loss: 0.385720\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106637; batch adversarial loss: 0.592059\n",
      "epoch 65; iter: 0; batch classifier loss: 0.083863; batch adversarial loss: 0.504209\n",
      "epoch 66; iter: 0; batch classifier loss: 0.127094; batch adversarial loss: 0.420420\n",
      "epoch 67; iter: 0; batch classifier loss: 0.102440; batch adversarial loss: 0.363028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.097641; batch adversarial loss: 0.495257\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081250; batch adversarial loss: 0.415151\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095182; batch adversarial loss: 0.346713\n",
      "epoch 71; iter: 0; batch classifier loss: 0.074498; batch adversarial loss: 0.419671\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077250; batch adversarial loss: 0.476765\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089060; batch adversarial loss: 0.419841\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089008; batch adversarial loss: 0.435915\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069081; batch adversarial loss: 0.427433\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086993; batch adversarial loss: 0.460387\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050689; batch adversarial loss: 0.593097\n",
      "epoch 78; iter: 0; batch classifier loss: 0.051063; batch adversarial loss: 0.393285\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070925; batch adversarial loss: 0.494342\n",
      "epoch 80; iter: 0; batch classifier loss: 0.073648; batch adversarial loss: 0.530361\n",
      "epoch 81; iter: 0; batch classifier loss: 0.052916; batch adversarial loss: 0.436978\n",
      "epoch 82; iter: 0; batch classifier loss: 0.109615; batch adversarial loss: 0.358166\n",
      "epoch 83; iter: 0; batch classifier loss: 0.095685; batch adversarial loss: 0.455265\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068085; batch adversarial loss: 0.421174\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074562; batch adversarial loss: 0.444725\n",
      "epoch 86; iter: 0; batch classifier loss: 0.050147; batch adversarial loss: 0.406550\n",
      "epoch 87; iter: 0; batch classifier loss: 0.065461; batch adversarial loss: 0.497851\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059856; batch adversarial loss: 0.501819\n",
      "epoch 89; iter: 0; batch classifier loss: 0.076117; batch adversarial loss: 0.507902\n",
      "epoch 90; iter: 0; batch classifier loss: 0.041656; batch adversarial loss: 0.437738\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068585; batch adversarial loss: 0.359991\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043208; batch adversarial loss: 0.477845\n",
      "epoch 93; iter: 0; batch classifier loss: 0.034904; batch adversarial loss: 0.512899\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050793; batch adversarial loss: 0.514399\n",
      "epoch 95; iter: 0; batch classifier loss: 0.103741; batch adversarial loss: 0.399799\n",
      "epoch 96; iter: 0; batch classifier loss: 0.085047; batch adversarial loss: 0.487482\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054177; batch adversarial loss: 0.424519\n",
      "epoch 98; iter: 0; batch classifier loss: 0.041241; batch adversarial loss: 0.443971\n",
      "epoch 99; iter: 0; batch classifier loss: 0.028787; batch adversarial loss: 0.513517\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048579; batch adversarial loss: 0.470532\n",
      "epoch 101; iter: 0; batch classifier loss: 0.020239; batch adversarial loss: 0.491535\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067644; batch adversarial loss: 0.454881\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039465; batch adversarial loss: 0.415031\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048814; batch adversarial loss: 0.416898\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040846; batch adversarial loss: 0.361211\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031699; batch adversarial loss: 0.421724\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053724; batch adversarial loss: 0.424152\n",
      "epoch 108; iter: 0; batch classifier loss: 0.025195; batch adversarial loss: 0.435648\n",
      "epoch 109; iter: 0; batch classifier loss: 0.023737; batch adversarial loss: 0.371703\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045489; batch adversarial loss: 0.477120\n",
      "epoch 111; iter: 0; batch classifier loss: 0.021418; batch adversarial loss: 0.485414\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054616; batch adversarial loss: 0.436525\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058949; batch adversarial loss: 0.445614\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062143; batch adversarial loss: 0.404202\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045934; batch adversarial loss: 0.463942\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050349; batch adversarial loss: 0.529863\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032122; batch adversarial loss: 0.493449\n",
      "epoch 118; iter: 0; batch classifier loss: 0.012140; batch adversarial loss: 0.448386\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031562; batch adversarial loss: 0.473694\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044114; batch adversarial loss: 0.443817\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057202; batch adversarial loss: 0.415780\n",
      "epoch 122; iter: 0; batch classifier loss: 0.006905; batch adversarial loss: 0.319592\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028647; batch adversarial loss: 0.547085\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038661; batch adversarial loss: 0.340147\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030203; batch adversarial loss: 0.389101\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032786; batch adversarial loss: 0.390880\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028921; batch adversarial loss: 0.467956\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045497; batch adversarial loss: 0.548548\n",
      "epoch 129; iter: 0; batch classifier loss: 0.010531; batch adversarial loss: 0.449585\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027328; batch adversarial loss: 0.492422\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052660; batch adversarial loss: 0.497955\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015283; batch adversarial loss: 0.422221\n",
      "epoch 133; iter: 0; batch classifier loss: 0.009538; batch adversarial loss: 0.545848\n",
      "epoch 134; iter: 0; batch classifier loss: 0.055144; batch adversarial loss: 0.521438\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051363; batch adversarial loss: 0.518456\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013682; batch adversarial loss: 0.502310\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012413; batch adversarial loss: 0.410353\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031578; batch adversarial loss: 0.383070\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025855; batch adversarial loss: 0.417211\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046260; batch adversarial loss: 0.390814\n",
      "epoch 141; iter: 0; batch classifier loss: 0.009012; batch adversarial loss: 0.512141\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048857; batch adversarial loss: 0.381856\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020888; batch adversarial loss: 0.477121\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014043; batch adversarial loss: 0.459242\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026729; batch adversarial loss: 0.397956\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020208; batch adversarial loss: 0.475021\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011261; batch adversarial loss: 0.407397\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014225; batch adversarial loss: 0.520833\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027827; batch adversarial loss: 0.470385\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017396; batch adversarial loss: 0.585236\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017445; batch adversarial loss: 0.417751\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031328; batch adversarial loss: 0.509717\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017382; batch adversarial loss: 0.473602\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029173; batch adversarial loss: 0.454325\n",
      "epoch 155; iter: 0; batch classifier loss: 0.047710; batch adversarial loss: 0.399173\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025752; batch adversarial loss: 0.372215\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012739; batch adversarial loss: 0.480862\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012228; batch adversarial loss: 0.438421\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007799; batch adversarial loss: 0.430384\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013083; batch adversarial loss: 0.525352\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011236; batch adversarial loss: 0.402138\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019584; batch adversarial loss: 0.499452\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038866; batch adversarial loss: 0.440505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.007438; batch adversarial loss: 0.537890\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038975; batch adversarial loss: 0.398172\n",
      "epoch 166; iter: 0; batch classifier loss: 0.039480; batch adversarial loss: 0.485571\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012145; batch adversarial loss: 0.497972\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010226; batch adversarial loss: 0.450828\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020696; batch adversarial loss: 0.523453\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013037; batch adversarial loss: 0.451180\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023019; batch adversarial loss: 0.486489\n",
      "epoch 172; iter: 0; batch classifier loss: 0.041550; batch adversarial loss: 0.460332\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008310; batch adversarial loss: 0.476543\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027741; batch adversarial loss: 0.538299\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031511; batch adversarial loss: 0.437524\n",
      "epoch 176; iter: 0; batch classifier loss: 0.054406; batch adversarial loss: 0.480770\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015149; batch adversarial loss: 0.484734\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011846; batch adversarial loss: 0.388979\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016661; batch adversarial loss: 0.512218\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015498; batch adversarial loss: 0.449675\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025702; batch adversarial loss: 0.405398\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014245; batch adversarial loss: 0.493703\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007037; batch adversarial loss: 0.485706\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013044; batch adversarial loss: 0.374701\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011844; batch adversarial loss: 0.476870\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005713; batch adversarial loss: 0.474742\n",
      "epoch 187; iter: 0; batch classifier loss: 0.065252; batch adversarial loss: 0.420282\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009564; batch adversarial loss: 0.370428\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015731; batch adversarial loss: 0.518655\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025186; batch adversarial loss: 0.406512\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024859; batch adversarial loss: 0.439734\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018049; batch adversarial loss: 0.526402\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007583; batch adversarial loss: 0.525353\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015500; batch adversarial loss: 0.494348\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004515; batch adversarial loss: 0.429146\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027401; batch adversarial loss: 0.467268\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023866; batch adversarial loss: 0.382578\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005184; batch adversarial loss: 0.369288\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013172; batch adversarial loss: 0.476168\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711477; batch adversarial loss: 1.129788\n",
      "epoch 1; iter: 0; batch classifier loss: 0.799989; batch adversarial loss: 1.317346\n",
      "epoch 2; iter: 0; batch classifier loss: 0.833876; batch adversarial loss: 1.387058\n",
      "epoch 3; iter: 0; batch classifier loss: 1.037290; batch adversarial loss: 1.239011\n",
      "epoch 4; iter: 0; batch classifier loss: 1.122631; batch adversarial loss: 1.150034\n",
      "epoch 5; iter: 0; batch classifier loss: 1.152658; batch adversarial loss: 1.049904\n",
      "epoch 6; iter: 0; batch classifier loss: 1.094313; batch adversarial loss: 0.948971\n",
      "epoch 7; iter: 0; batch classifier loss: 1.366212; batch adversarial loss: 0.874353\n",
      "epoch 8; iter: 0; batch classifier loss: 1.128692; batch adversarial loss: 0.805787\n",
      "epoch 9; iter: 0; batch classifier loss: 1.220412; batch adversarial loss: 0.725864\n",
      "epoch 10; iter: 0; batch classifier loss: 1.074797; batch adversarial loss: 0.689878\n",
      "epoch 11; iter: 0; batch classifier loss: 1.086941; batch adversarial loss: 0.620469\n",
      "epoch 12; iter: 0; batch classifier loss: 1.135183; batch adversarial loss: 0.587905\n",
      "epoch 13; iter: 0; batch classifier loss: 0.984794; batch adversarial loss: 0.572958\n",
      "epoch 14; iter: 0; batch classifier loss: 1.030975; batch adversarial loss: 0.500541\n",
      "epoch 15; iter: 0; batch classifier loss: 0.474180; batch adversarial loss: 0.461574\n",
      "epoch 16; iter: 0; batch classifier loss: 0.348955; batch adversarial loss: 0.509182\n",
      "epoch 17; iter: 0; batch classifier loss: 0.345456; batch adversarial loss: 0.479493\n",
      "epoch 18; iter: 0; batch classifier loss: 0.306058; batch adversarial loss: 0.505511\n",
      "epoch 19; iter: 0; batch classifier loss: 0.290522; batch adversarial loss: 0.480031\n",
      "epoch 20; iter: 0; batch classifier loss: 0.273178; batch adversarial loss: 0.486775\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234567; batch adversarial loss: 0.489638\n",
      "epoch 22; iter: 0; batch classifier loss: 0.209474; batch adversarial loss: 0.445960\n",
      "epoch 23; iter: 0; batch classifier loss: 0.289359; batch adversarial loss: 0.477044\n",
      "epoch 24; iter: 0; batch classifier loss: 0.251265; batch adversarial loss: 0.514059\n",
      "epoch 25; iter: 0; batch classifier loss: 0.266599; batch adversarial loss: 0.445729\n",
      "epoch 26; iter: 0; batch classifier loss: 0.258730; batch adversarial loss: 0.442181\n",
      "epoch 27; iter: 0; batch classifier loss: 0.338278; batch adversarial loss: 0.442367\n",
      "epoch 28; iter: 0; batch classifier loss: 0.260928; batch adversarial loss: 0.496229\n",
      "epoch 29; iter: 0; batch classifier loss: 0.250219; batch adversarial loss: 0.537502\n",
      "epoch 30; iter: 0; batch classifier loss: 0.217751; batch adversarial loss: 0.476399\n",
      "epoch 31; iter: 0; batch classifier loss: 0.243040; batch adversarial loss: 0.423425\n",
      "epoch 32; iter: 0; batch classifier loss: 0.288348; batch adversarial loss: 0.426429\n",
      "epoch 33; iter: 0; batch classifier loss: 0.300982; batch adversarial loss: 0.442769\n",
      "epoch 34; iter: 0; batch classifier loss: 0.215117; batch adversarial loss: 0.482164\n",
      "epoch 35; iter: 0; batch classifier loss: 0.270971; batch adversarial loss: 0.431128\n",
      "epoch 36; iter: 0; batch classifier loss: 0.281627; batch adversarial loss: 0.476459\n",
      "epoch 37; iter: 0; batch classifier loss: 0.281421; batch adversarial loss: 0.486545\n",
      "epoch 38; iter: 0; batch classifier loss: 0.232287; batch adversarial loss: 0.519081\n",
      "epoch 39; iter: 0; batch classifier loss: 0.211478; batch adversarial loss: 0.478693\n",
      "epoch 40; iter: 0; batch classifier loss: 0.252618; batch adversarial loss: 0.505996\n",
      "epoch 41; iter: 0; batch classifier loss: 0.203759; batch adversarial loss: 0.377296\n",
      "epoch 42; iter: 0; batch classifier loss: 0.336047; batch adversarial loss: 0.420074\n",
      "epoch 43; iter: 0; batch classifier loss: 0.201616; batch adversarial loss: 0.475215\n",
      "epoch 44; iter: 0; batch classifier loss: 0.261922; batch adversarial loss: 0.390924\n",
      "epoch 45; iter: 0; batch classifier loss: 0.182852; batch adversarial loss: 0.446131\n",
      "epoch 46; iter: 0; batch classifier loss: 0.211982; batch adversarial loss: 0.407530\n",
      "epoch 47; iter: 0; batch classifier loss: 0.277609; batch adversarial loss: 0.439527\n",
      "epoch 48; iter: 0; batch classifier loss: 0.203859; batch adversarial loss: 0.445870\n",
      "epoch 49; iter: 0; batch classifier loss: 0.192366; batch adversarial loss: 0.472262\n",
      "epoch 50; iter: 0; batch classifier loss: 0.162886; batch adversarial loss: 0.505746\n",
      "epoch 51; iter: 0; batch classifier loss: 0.229326; batch adversarial loss: 0.468175\n",
      "epoch 52; iter: 0; batch classifier loss: 0.193791; batch adversarial loss: 0.469200\n",
      "epoch 53; iter: 0; batch classifier loss: 0.188033; batch adversarial loss: 0.546798\n",
      "epoch 54; iter: 0; batch classifier loss: 0.151126; batch adversarial loss: 0.507493\n",
      "epoch 55; iter: 0; batch classifier loss: 0.143934; batch adversarial loss: 0.407183\n",
      "epoch 56; iter: 0; batch classifier loss: 0.145598; batch adversarial loss: 0.478137\n",
      "epoch 57; iter: 0; batch classifier loss: 0.221048; batch adversarial loss: 0.344643\n",
      "epoch 58; iter: 0; batch classifier loss: 0.189481; batch adversarial loss: 0.451737\n",
      "epoch 59; iter: 0; batch classifier loss: 0.145287; batch adversarial loss: 0.416627\n",
      "epoch 60; iter: 0; batch classifier loss: 0.234377; batch adversarial loss: 0.362968\n",
      "epoch 61; iter: 0; batch classifier loss: 0.174965; batch adversarial loss: 0.407612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.167082; batch adversarial loss: 0.514484\n",
      "epoch 63; iter: 0; batch classifier loss: 0.173554; batch adversarial loss: 0.442747\n",
      "epoch 64; iter: 0; batch classifier loss: 0.170645; batch adversarial loss: 0.434213\n",
      "epoch 65; iter: 0; batch classifier loss: 0.151500; batch adversarial loss: 0.453509\n",
      "epoch 66; iter: 0; batch classifier loss: 0.143968; batch adversarial loss: 0.490758\n",
      "epoch 67; iter: 0; batch classifier loss: 0.168535; batch adversarial loss: 0.395577\n",
      "epoch 68; iter: 0; batch classifier loss: 0.103384; batch adversarial loss: 0.581593\n",
      "epoch 69; iter: 0; batch classifier loss: 0.121089; batch adversarial loss: 0.444345\n",
      "epoch 70; iter: 0; batch classifier loss: 0.107150; batch adversarial loss: 0.494037\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083092; batch adversarial loss: 0.475025\n",
      "epoch 72; iter: 0; batch classifier loss: 0.120750; batch adversarial loss: 0.474255\n",
      "epoch 73; iter: 0; batch classifier loss: 0.116880; batch adversarial loss: 0.499786\n",
      "epoch 74; iter: 0; batch classifier loss: 0.151477; batch adversarial loss: 0.448350\n",
      "epoch 75; iter: 0; batch classifier loss: 0.111715; batch adversarial loss: 0.444841\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075386; batch adversarial loss: 0.366983\n",
      "epoch 77; iter: 0; batch classifier loss: 0.114450; batch adversarial loss: 0.396170\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085265; batch adversarial loss: 0.413619\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080189; batch adversarial loss: 0.450148\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070881; batch adversarial loss: 0.439846\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079142; batch adversarial loss: 0.572878\n",
      "epoch 82; iter: 0; batch classifier loss: 0.094737; batch adversarial loss: 0.452913\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114752; batch adversarial loss: 0.510962\n",
      "epoch 84; iter: 0; batch classifier loss: 0.131281; batch adversarial loss: 0.430803\n",
      "epoch 85; iter: 0; batch classifier loss: 0.112770; batch adversarial loss: 0.388713\n",
      "epoch 86; iter: 0; batch classifier loss: 0.100741; batch adversarial loss: 0.463075\n",
      "epoch 87; iter: 0; batch classifier loss: 0.086891; batch adversarial loss: 0.441177\n",
      "epoch 88; iter: 0; batch classifier loss: 0.072640; batch adversarial loss: 0.446774\n",
      "epoch 89; iter: 0; batch classifier loss: 0.128765; batch adversarial loss: 0.452216\n",
      "epoch 90; iter: 0; batch classifier loss: 0.072720; batch adversarial loss: 0.450377\n",
      "epoch 91; iter: 0; batch classifier loss: 0.100295; batch adversarial loss: 0.419982\n",
      "epoch 92; iter: 0; batch classifier loss: 0.049791; batch adversarial loss: 0.475750\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064157; batch adversarial loss: 0.463082\n",
      "epoch 94; iter: 0; batch classifier loss: 0.093492; batch adversarial loss: 0.403428\n",
      "epoch 95; iter: 0; batch classifier loss: 0.096474; batch adversarial loss: 0.517617\n",
      "epoch 96; iter: 0; batch classifier loss: 0.074349; batch adversarial loss: 0.521587\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071951; batch adversarial loss: 0.426031\n",
      "epoch 98; iter: 0; batch classifier loss: 0.100133; batch adversarial loss: 0.450587\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073875; batch adversarial loss: 0.385718\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061305; batch adversarial loss: 0.462487\n",
      "epoch 101; iter: 0; batch classifier loss: 0.131898; batch adversarial loss: 0.474443\n",
      "epoch 102; iter: 0; batch classifier loss: 0.089395; batch adversarial loss: 0.451489\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037639; batch adversarial loss: 0.478534\n",
      "epoch 104; iter: 0; batch classifier loss: 0.072318; batch adversarial loss: 0.548318\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066769; batch adversarial loss: 0.481071\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043277; batch adversarial loss: 0.422821\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072430; batch adversarial loss: 0.444333\n",
      "epoch 108; iter: 0; batch classifier loss: 0.061424; batch adversarial loss: 0.432816\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032296; batch adversarial loss: 0.388496\n",
      "epoch 110; iter: 0; batch classifier loss: 0.083640; batch adversarial loss: 0.444289\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039411; batch adversarial loss: 0.412273\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046587; batch adversarial loss: 0.442166\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059273; batch adversarial loss: 0.451683\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050290; batch adversarial loss: 0.477300\n",
      "epoch 115; iter: 0; batch classifier loss: 0.084609; batch adversarial loss: 0.469003\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042437; batch adversarial loss: 0.486579\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051679; batch adversarial loss: 0.482949\n",
      "epoch 118; iter: 0; batch classifier loss: 0.075327; batch adversarial loss: 0.477427\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034144; batch adversarial loss: 0.371325\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033400; batch adversarial loss: 0.518340\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030115; batch adversarial loss: 0.513680\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040434; batch adversarial loss: 0.432748\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036076; batch adversarial loss: 0.458166\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030471; batch adversarial loss: 0.386287\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041132; batch adversarial loss: 0.395141\n",
      "epoch 126; iter: 0; batch classifier loss: 0.062477; batch adversarial loss: 0.432889\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043407; batch adversarial loss: 0.412997\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041970; batch adversarial loss: 0.414386\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023426; batch adversarial loss: 0.337634\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019690; batch adversarial loss: 0.424105\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042822; batch adversarial loss: 0.484713\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032136; batch adversarial loss: 0.459886\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037121; batch adversarial loss: 0.486167\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030089; batch adversarial loss: 0.526367\n",
      "epoch 135; iter: 0; batch classifier loss: 0.005380; batch adversarial loss: 0.455762\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035432; batch adversarial loss: 0.398616\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027202; batch adversarial loss: 0.421319\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031419; batch adversarial loss: 0.457354\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018268; batch adversarial loss: 0.461764\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021673; batch adversarial loss: 0.469434\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028265; batch adversarial loss: 0.507157\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032286; batch adversarial loss: 0.422212\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020129; batch adversarial loss: 0.453646\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026292; batch adversarial loss: 0.455420\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026266; batch adversarial loss: 0.535182\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041425; batch adversarial loss: 0.439834\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034753; batch adversarial loss: 0.414920\n",
      "epoch 148; iter: 0; batch classifier loss: 0.056079; batch adversarial loss: 0.377124\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024982; batch adversarial loss: 0.368592\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026451; batch adversarial loss: 0.465480\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035009; batch adversarial loss: 0.490842\n",
      "epoch 152; iter: 0; batch classifier loss: 0.060813; batch adversarial loss: 0.390043\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014351; batch adversarial loss: 0.367118\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031941; batch adversarial loss: 0.417767\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015828; batch adversarial loss: 0.509380\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013459; batch adversarial loss: 0.380863\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019126; batch adversarial loss: 0.474258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.043342; batch adversarial loss: 0.346042\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029480; batch adversarial loss: 0.484936\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036693; batch adversarial loss: 0.399435\n",
      "epoch 161; iter: 0; batch classifier loss: 0.052967; batch adversarial loss: 0.380634\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031248; batch adversarial loss: 0.360790\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018585; batch adversarial loss: 0.420716\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012029; batch adversarial loss: 0.387205\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011553; batch adversarial loss: 0.394995\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027862; batch adversarial loss: 0.453988\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015564; batch adversarial loss: 0.501463\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034234; batch adversarial loss: 0.472788\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016567; batch adversarial loss: 0.494300\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024828; batch adversarial loss: 0.472479\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033418; batch adversarial loss: 0.430980\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032225; batch adversarial loss: 0.456096\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017301; batch adversarial loss: 0.472249\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012185; batch adversarial loss: 0.530073\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011919; batch adversarial loss: 0.467621\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009856; batch adversarial loss: 0.457033\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026247; batch adversarial loss: 0.435535\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029619; batch adversarial loss: 0.522064\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023453; batch adversarial loss: 0.432521\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019158; batch adversarial loss: 0.421519\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018761; batch adversarial loss: 0.324864\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020678; batch adversarial loss: 0.488677\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036487; batch adversarial loss: 0.509402\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015214; batch adversarial loss: 0.326733\n",
      "epoch 185; iter: 0; batch classifier loss: 0.041079; batch adversarial loss: 0.370337\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035668; batch adversarial loss: 0.426717\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013524; batch adversarial loss: 0.406255\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024583; batch adversarial loss: 0.410252\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016754; batch adversarial loss: 0.461109\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013925; batch adversarial loss: 0.486282\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028593; batch adversarial loss: 0.510571\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010287; batch adversarial loss: 0.438934\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018259; batch adversarial loss: 0.458916\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007837; batch adversarial loss: 0.440509\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023016; batch adversarial loss: 0.457872\n",
      "epoch 196; iter: 0; batch classifier loss: 0.066451; batch adversarial loss: 0.468077\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013189; batch adversarial loss: 0.468943\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019906; batch adversarial loss: 0.473533\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017788; batch adversarial loss: 0.522799\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688075; batch adversarial loss: 0.561488\n",
      "epoch 1; iter: 0; batch classifier loss: 0.453002; batch adversarial loss: 0.606004\n",
      "epoch 2; iter: 0; batch classifier loss: 0.374172; batch adversarial loss: 0.571875\n",
      "epoch 3; iter: 0; batch classifier loss: 0.361394; batch adversarial loss: 0.541797\n",
      "epoch 4; iter: 0; batch classifier loss: 0.347853; batch adversarial loss: 0.560960\n",
      "epoch 5; iter: 0; batch classifier loss: 0.309052; batch adversarial loss: 0.549544\n",
      "epoch 6; iter: 0; batch classifier loss: 0.305671; batch adversarial loss: 0.516657\n",
      "epoch 7; iter: 0; batch classifier loss: 0.288407; batch adversarial loss: 0.541151\n",
      "epoch 8; iter: 0; batch classifier loss: 0.284716; batch adversarial loss: 0.497466\n",
      "epoch 9; iter: 0; batch classifier loss: 0.308234; batch adversarial loss: 0.505744\n",
      "epoch 10; iter: 0; batch classifier loss: 0.280924; batch adversarial loss: 0.551116\n",
      "epoch 11; iter: 0; batch classifier loss: 0.321192; batch adversarial loss: 0.548655\n",
      "epoch 12; iter: 0; batch classifier loss: 0.302523; batch adversarial loss: 0.485380\n",
      "epoch 13; iter: 0; batch classifier loss: 0.243202; batch adversarial loss: 0.545281\n",
      "epoch 14; iter: 0; batch classifier loss: 0.234576; batch adversarial loss: 0.497984\n",
      "epoch 15; iter: 0; batch classifier loss: 0.266981; batch adversarial loss: 0.534316\n",
      "epoch 16; iter: 0; batch classifier loss: 0.286399; batch adversarial loss: 0.581721\n",
      "epoch 17; iter: 0; batch classifier loss: 0.284772; batch adversarial loss: 0.568951\n",
      "epoch 18; iter: 0; batch classifier loss: 0.289343; batch adversarial loss: 0.561872\n",
      "epoch 19; iter: 0; batch classifier loss: 0.251939; batch adversarial loss: 0.611438\n",
      "epoch 20; iter: 0; batch classifier loss: 0.334121; batch adversarial loss: 0.594984\n",
      "epoch 21; iter: 0; batch classifier loss: 0.329445; batch adversarial loss: 0.538377\n",
      "epoch 22; iter: 0; batch classifier loss: 0.234366; batch adversarial loss: 0.468357\n",
      "epoch 23; iter: 0; batch classifier loss: 0.494006; batch adversarial loss: 0.438862\n",
      "epoch 24; iter: 0; batch classifier loss: 0.323248; batch adversarial loss: 0.458795\n",
      "epoch 25; iter: 0; batch classifier loss: 0.268039; batch adversarial loss: 0.408005\n",
      "epoch 26; iter: 0; batch classifier loss: 0.173391; batch adversarial loss: 0.364378\n",
      "epoch 27; iter: 0; batch classifier loss: 0.137546; batch adversarial loss: 0.466352\n",
      "epoch 28; iter: 0; batch classifier loss: 0.130317; batch adversarial loss: 0.463414\n",
      "epoch 29; iter: 0; batch classifier loss: 0.120297; batch adversarial loss: 0.443166\n",
      "epoch 30; iter: 0; batch classifier loss: 0.104208; batch adversarial loss: 0.389199\n",
      "epoch 31; iter: 0; batch classifier loss: 0.144697; batch adversarial loss: 0.519143\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146067; batch adversarial loss: 0.436658\n",
      "epoch 33; iter: 0; batch classifier loss: 0.109268; batch adversarial loss: 0.398074\n",
      "epoch 34; iter: 0; batch classifier loss: 0.212155; batch adversarial loss: 0.419277\n",
      "epoch 35; iter: 0; batch classifier loss: 0.146583; batch adversarial loss: 0.344636\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128700; batch adversarial loss: 0.512400\n",
      "epoch 37; iter: 0; batch classifier loss: 0.124430; batch adversarial loss: 0.438843\n",
      "epoch 38; iter: 0; batch classifier loss: 0.109886; batch adversarial loss: 0.450160\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131329; batch adversarial loss: 0.475782\n",
      "epoch 40; iter: 0; batch classifier loss: 0.094991; batch adversarial loss: 0.414428\n",
      "epoch 41; iter: 0; batch classifier loss: 0.065972; batch adversarial loss: 0.458861\n",
      "epoch 42; iter: 0; batch classifier loss: 0.152597; batch adversarial loss: 0.420805\n",
      "epoch 43; iter: 0; batch classifier loss: 0.073810; batch adversarial loss: 0.362132\n",
      "epoch 44; iter: 0; batch classifier loss: 0.061175; batch adversarial loss: 0.414129\n",
      "epoch 45; iter: 0; batch classifier loss: 0.072665; batch adversarial loss: 0.414009\n",
      "epoch 46; iter: 0; batch classifier loss: 0.081202; batch adversarial loss: 0.472157\n",
      "epoch 47; iter: 0; batch classifier loss: 0.080175; batch adversarial loss: 0.428494\n",
      "epoch 48; iter: 0; batch classifier loss: 0.123107; batch adversarial loss: 0.485370\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113799; batch adversarial loss: 0.492104\n",
      "epoch 50; iter: 0; batch classifier loss: 0.090315; batch adversarial loss: 0.391763\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112551; batch adversarial loss: 0.417708\n",
      "epoch 52; iter: 0; batch classifier loss: 0.076094; batch adversarial loss: 0.426974\n",
      "epoch 53; iter: 0; batch classifier loss: 0.132705; batch adversarial loss: 0.513291\n",
      "epoch 54; iter: 0; batch classifier loss: 0.105662; batch adversarial loss: 0.424279\n",
      "epoch 55; iter: 0; batch classifier loss: 0.095424; batch adversarial loss: 0.474489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.138524; batch adversarial loss: 0.537061\n",
      "epoch 57; iter: 0; batch classifier loss: 0.137656; batch adversarial loss: 0.437819\n",
      "epoch 58; iter: 0; batch classifier loss: 0.060300; batch adversarial loss: 0.500373\n",
      "epoch 59; iter: 0; batch classifier loss: 0.132491; batch adversarial loss: 0.398026\n",
      "epoch 60; iter: 0; batch classifier loss: 0.129909; batch adversarial loss: 0.448822\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090061; batch adversarial loss: 0.424241\n",
      "epoch 62; iter: 0; batch classifier loss: 0.099192; batch adversarial loss: 0.438265\n",
      "epoch 63; iter: 0; batch classifier loss: 0.118911; batch adversarial loss: 0.419978\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076168; batch adversarial loss: 0.498124\n",
      "epoch 65; iter: 0; batch classifier loss: 0.139326; batch adversarial loss: 0.447025\n",
      "epoch 66; iter: 0; batch classifier loss: 0.126418; batch adversarial loss: 0.428257\n",
      "epoch 67; iter: 0; batch classifier loss: 0.113454; batch adversarial loss: 0.428037\n",
      "epoch 68; iter: 0; batch classifier loss: 0.103090; batch adversarial loss: 0.402523\n",
      "epoch 69; iter: 0; batch classifier loss: 0.164373; batch adversarial loss: 0.417061\n",
      "epoch 70; iter: 0; batch classifier loss: 0.107173; batch adversarial loss: 0.386548\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078406; batch adversarial loss: 0.380547\n",
      "epoch 72; iter: 0; batch classifier loss: 0.063721; batch adversarial loss: 0.462594\n",
      "epoch 73; iter: 0; batch classifier loss: 0.128366; batch adversarial loss: 0.475984\n",
      "epoch 74; iter: 0; batch classifier loss: 0.127139; batch adversarial loss: 0.467516\n",
      "epoch 75; iter: 0; batch classifier loss: 0.102938; batch adversarial loss: 0.409591\n",
      "epoch 76; iter: 0; batch classifier loss: 0.100011; batch adversarial loss: 0.394509\n",
      "epoch 77; iter: 0; batch classifier loss: 0.110457; batch adversarial loss: 0.461048\n",
      "epoch 78; iter: 0; batch classifier loss: 0.168445; batch adversarial loss: 0.500886\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082630; batch adversarial loss: 0.455030\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088449; batch adversarial loss: 0.363274\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065229; batch adversarial loss: 0.528002\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090292; batch adversarial loss: 0.480469\n",
      "epoch 83; iter: 0; batch classifier loss: 0.152030; batch adversarial loss: 0.446553\n",
      "epoch 84; iter: 0; batch classifier loss: 0.107711; batch adversarial loss: 0.401547\n",
      "epoch 85; iter: 0; batch classifier loss: 0.094800; batch adversarial loss: 0.436336\n",
      "epoch 86; iter: 0; batch classifier loss: 0.108671; batch adversarial loss: 0.408377\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078518; batch adversarial loss: 0.431059\n",
      "epoch 88; iter: 0; batch classifier loss: 0.071999; batch adversarial loss: 0.509193\n",
      "epoch 89; iter: 0; batch classifier loss: 0.188463; batch adversarial loss: 0.536169\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051464; batch adversarial loss: 0.433365\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071861; batch adversarial loss: 0.537003\n",
      "epoch 92; iter: 0; batch classifier loss: 0.106615; batch adversarial loss: 0.478624\n",
      "epoch 93; iter: 0; batch classifier loss: 0.090522; batch adversarial loss: 0.441849\n",
      "epoch 94; iter: 0; batch classifier loss: 0.132187; batch adversarial loss: 0.493913\n",
      "epoch 95; iter: 0; batch classifier loss: 0.134389; batch adversarial loss: 0.456663\n",
      "epoch 96; iter: 0; batch classifier loss: 0.150700; batch adversarial loss: 0.466593\n",
      "epoch 97; iter: 0; batch classifier loss: 0.068156; batch adversarial loss: 0.418305\n",
      "epoch 98; iter: 0; batch classifier loss: 0.101499; batch adversarial loss: 0.408948\n",
      "epoch 99; iter: 0; batch classifier loss: 0.099943; batch adversarial loss: 0.430778\n",
      "epoch 100; iter: 0; batch classifier loss: 0.138024; batch adversarial loss: 0.371686\n",
      "epoch 101; iter: 0; batch classifier loss: 0.116687; batch adversarial loss: 0.370617\n",
      "epoch 102; iter: 0; batch classifier loss: 0.072719; batch adversarial loss: 0.480500\n",
      "epoch 103; iter: 0; batch classifier loss: 0.154480; batch adversarial loss: 0.400361\n",
      "epoch 104; iter: 0; batch classifier loss: 0.108978; batch adversarial loss: 0.445961\n",
      "epoch 105; iter: 0; batch classifier loss: 0.117041; batch adversarial loss: 0.422760\n",
      "epoch 106; iter: 0; batch classifier loss: 0.112934; batch adversarial loss: 0.365722\n",
      "epoch 107; iter: 0; batch classifier loss: 0.144007; batch adversarial loss: 0.448133\n",
      "epoch 108; iter: 0; batch classifier loss: 0.097600; batch adversarial loss: 0.449630\n",
      "epoch 109; iter: 0; batch classifier loss: 0.113262; batch adversarial loss: 0.427604\n",
      "epoch 110; iter: 0; batch classifier loss: 0.095383; batch adversarial loss: 0.496655\n",
      "epoch 111; iter: 0; batch classifier loss: 0.130255; batch adversarial loss: 0.474818\n",
      "epoch 112; iter: 0; batch classifier loss: 0.102128; batch adversarial loss: 0.384160\n",
      "epoch 113; iter: 0; batch classifier loss: 0.091943; batch adversarial loss: 0.454651\n",
      "epoch 114; iter: 0; batch classifier loss: 0.127878; batch adversarial loss: 0.377803\n",
      "epoch 115; iter: 0; batch classifier loss: 0.076941; batch adversarial loss: 0.533552\n",
      "epoch 116; iter: 0; batch classifier loss: 0.083653; batch adversarial loss: 0.567767\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060013; batch adversarial loss: 0.422526\n",
      "epoch 118; iter: 0; batch classifier loss: 0.086958; batch adversarial loss: 0.516762\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032901; batch adversarial loss: 0.483710\n",
      "epoch 120; iter: 0; batch classifier loss: 0.072034; batch adversarial loss: 0.331294\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065145; batch adversarial loss: 0.507769\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052466; batch adversarial loss: 0.445396\n",
      "epoch 123; iter: 0; batch classifier loss: 0.079497; batch adversarial loss: 0.409365\n",
      "epoch 124; iter: 0; batch classifier loss: 0.070016; batch adversarial loss: 0.404513\n",
      "epoch 125; iter: 0; batch classifier loss: 0.065212; batch adversarial loss: 0.470753\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043124; batch adversarial loss: 0.462568\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041916; batch adversarial loss: 0.491023\n",
      "epoch 128; iter: 0; batch classifier loss: 0.108903; batch adversarial loss: 0.360680\n",
      "epoch 129; iter: 0; batch classifier loss: 0.049119; batch adversarial loss: 0.334492\n",
      "epoch 130; iter: 0; batch classifier loss: 0.054372; batch adversarial loss: 0.357397\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042299; batch adversarial loss: 0.425035\n",
      "epoch 132; iter: 0; batch classifier loss: 0.079284; batch adversarial loss: 0.448550\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045514; batch adversarial loss: 0.511862\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050792; batch adversarial loss: 0.504242\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029201; batch adversarial loss: 0.464390\n",
      "epoch 136; iter: 0; batch classifier loss: 0.074821; batch adversarial loss: 0.429725\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044703; batch adversarial loss: 0.417115\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041299; batch adversarial loss: 0.485503\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042102; batch adversarial loss: 0.324701\n",
      "epoch 140; iter: 0; batch classifier loss: 0.060542; batch adversarial loss: 0.506759\n",
      "epoch 141; iter: 0; batch classifier loss: 0.080008; batch adversarial loss: 0.448940\n",
      "epoch 142; iter: 0; batch classifier loss: 0.060137; batch adversarial loss: 0.462555\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034822; batch adversarial loss: 0.433298\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037537; batch adversarial loss: 0.524823\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031421; batch adversarial loss: 0.424093\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044656; batch adversarial loss: 0.549854\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041960; batch adversarial loss: 0.460946\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045830; batch adversarial loss: 0.426770\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031581; batch adversarial loss: 0.372566\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021142; batch adversarial loss: 0.530959\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022196; batch adversarial loss: 0.474000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.028580; batch adversarial loss: 0.334232\n",
      "epoch 153; iter: 0; batch classifier loss: 0.047167; batch adversarial loss: 0.488220\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032806; batch adversarial loss: 0.486771\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035042; batch adversarial loss: 0.444786\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032949; batch adversarial loss: 0.533204\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047596; batch adversarial loss: 0.444257\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021231; batch adversarial loss: 0.473429\n",
      "epoch 159; iter: 0; batch classifier loss: 0.058582; batch adversarial loss: 0.383041\n",
      "epoch 160; iter: 0; batch classifier loss: 0.049872; batch adversarial loss: 0.466115\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017349; batch adversarial loss: 0.383919\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025765; batch adversarial loss: 0.444457\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009379; batch adversarial loss: 0.457585\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028158; batch adversarial loss: 0.482048\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027061; batch adversarial loss: 0.543299\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034263; batch adversarial loss: 0.534596\n",
      "epoch 167; iter: 0; batch classifier loss: 0.045910; batch adversarial loss: 0.372649\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015371; batch adversarial loss: 0.466153\n",
      "epoch 169; iter: 0; batch classifier loss: 0.045571; batch adversarial loss: 0.415875\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025966; batch adversarial loss: 0.469801\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033264; batch adversarial loss: 0.408441\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031881; batch adversarial loss: 0.432463\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018638; batch adversarial loss: 0.471601\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019646; batch adversarial loss: 0.364292\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017736; batch adversarial loss: 0.556824\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030934; batch adversarial loss: 0.474622\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030868; batch adversarial loss: 0.482998\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025885; batch adversarial loss: 0.479061\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031094; batch adversarial loss: 0.453452\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033378; batch adversarial loss: 0.412110\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018003; batch adversarial loss: 0.424872\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013930; batch adversarial loss: 0.379978\n",
      "epoch 183; iter: 0; batch classifier loss: 0.053343; batch adversarial loss: 0.464263\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024669; batch adversarial loss: 0.396497\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020420; batch adversarial loss: 0.433184\n",
      "epoch 186; iter: 0; batch classifier loss: 0.075736; batch adversarial loss: 0.416019\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008146; batch adversarial loss: 0.482771\n",
      "epoch 188; iter: 0; batch classifier loss: 0.046852; batch adversarial loss: 0.500921\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014629; batch adversarial loss: 0.392843\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026345; batch adversarial loss: 0.351639\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011137; batch adversarial loss: 0.458894\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013723; batch adversarial loss: 0.479977\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037625; batch adversarial loss: 0.438472\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013817; batch adversarial loss: 0.473582\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036128; batch adversarial loss: 0.414212\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028756; batch adversarial loss: 0.494198\n",
      "epoch 197; iter: 0; batch classifier loss: 0.046840; batch adversarial loss: 0.422732\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024757; batch adversarial loss: 0.456240\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019872; batch adversarial loss: 0.362280\n",
      "epoch 0; iter: 0; batch classifier loss: 0.665842; batch adversarial loss: 0.704910\n",
      "epoch 1; iter: 0; batch classifier loss: 0.496440; batch adversarial loss: 0.651540\n",
      "epoch 2; iter: 0; batch classifier loss: 0.469753; batch adversarial loss: 0.634981\n",
      "epoch 3; iter: 0; batch classifier loss: 0.489276; batch adversarial loss: 0.633780\n",
      "epoch 4; iter: 0; batch classifier loss: 0.447895; batch adversarial loss: 0.582299\n",
      "epoch 5; iter: 0; batch classifier loss: 0.455405; batch adversarial loss: 0.601218\n",
      "epoch 6; iter: 0; batch classifier loss: 0.358827; batch adversarial loss: 0.609207\n",
      "epoch 7; iter: 0; batch classifier loss: 0.520017; batch adversarial loss: 0.533913\n",
      "epoch 8; iter: 0; batch classifier loss: 0.359691; batch adversarial loss: 0.565766\n",
      "epoch 9; iter: 0; batch classifier loss: 0.374317; batch adversarial loss: 0.536467\n",
      "epoch 10; iter: 0; batch classifier loss: 0.445537; batch adversarial loss: 0.451842\n",
      "epoch 11; iter: 0; batch classifier loss: 0.467462; batch adversarial loss: 0.481446\n",
      "epoch 12; iter: 0; batch classifier loss: 0.317719; batch adversarial loss: 0.534741\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448180; batch adversarial loss: 0.539614\n",
      "epoch 14; iter: 0; batch classifier loss: 0.448464; batch adversarial loss: 0.508338\n",
      "epoch 15; iter: 0; batch classifier loss: 0.350470; batch adversarial loss: 0.471131\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336010; batch adversarial loss: 0.497059\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348421; batch adversarial loss: 0.470669\n",
      "epoch 18; iter: 0; batch classifier loss: 0.337537; batch adversarial loss: 0.583050\n",
      "epoch 19; iter: 0; batch classifier loss: 0.420668; batch adversarial loss: 0.437891\n",
      "epoch 20; iter: 0; batch classifier loss: 0.267574; batch adversarial loss: 0.501282\n",
      "epoch 21; iter: 0; batch classifier loss: 0.260716; batch adversarial loss: 0.437452\n",
      "epoch 22; iter: 0; batch classifier loss: 0.344661; batch adversarial loss: 0.472484\n",
      "epoch 23; iter: 0; batch classifier loss: 0.245185; batch adversarial loss: 0.492636\n",
      "epoch 24; iter: 0; batch classifier loss: 0.278453; batch adversarial loss: 0.454967\n",
      "epoch 25; iter: 0; batch classifier loss: 0.290587; batch adversarial loss: 0.473393\n",
      "epoch 26; iter: 0; batch classifier loss: 0.239602; batch adversarial loss: 0.505964\n",
      "epoch 27; iter: 0; batch classifier loss: 0.240655; batch adversarial loss: 0.453475\n",
      "epoch 28; iter: 0; batch classifier loss: 0.226489; batch adversarial loss: 0.443703\n",
      "epoch 29; iter: 0; batch classifier loss: 0.231362; batch adversarial loss: 0.421258\n",
      "epoch 30; iter: 0; batch classifier loss: 0.305006; batch adversarial loss: 0.428889\n",
      "epoch 31; iter: 0; batch classifier loss: 0.207000; batch adversarial loss: 0.443774\n",
      "epoch 32; iter: 0; batch classifier loss: 0.226644; batch adversarial loss: 0.462100\n",
      "epoch 33; iter: 0; batch classifier loss: 0.241107; batch adversarial loss: 0.495508\n",
      "epoch 34; iter: 0; batch classifier loss: 0.264433; batch adversarial loss: 0.484159\n",
      "epoch 35; iter: 0; batch classifier loss: 0.204652; batch adversarial loss: 0.432251\n",
      "epoch 36; iter: 0; batch classifier loss: 0.291504; batch adversarial loss: 0.508832\n",
      "epoch 37; iter: 0; batch classifier loss: 0.195897; batch adversarial loss: 0.530345\n",
      "epoch 38; iter: 0; batch classifier loss: 0.273136; batch adversarial loss: 0.367767\n",
      "epoch 39; iter: 0; batch classifier loss: 0.221200; batch adversarial loss: 0.522374\n",
      "epoch 40; iter: 0; batch classifier loss: 0.186526; batch adversarial loss: 0.453207\n",
      "epoch 41; iter: 0; batch classifier loss: 0.209367; batch adversarial loss: 0.432013\n",
      "epoch 42; iter: 0; batch classifier loss: 0.206259; batch adversarial loss: 0.495988\n",
      "epoch 43; iter: 0; batch classifier loss: 0.156789; batch adversarial loss: 0.487484\n",
      "epoch 44; iter: 0; batch classifier loss: 0.217903; batch adversarial loss: 0.449889\n",
      "epoch 45; iter: 0; batch classifier loss: 0.163896; batch adversarial loss: 0.514133\n",
      "epoch 46; iter: 0; batch classifier loss: 0.183367; batch adversarial loss: 0.429564\n",
      "epoch 47; iter: 0; batch classifier loss: 0.216362; batch adversarial loss: 0.496656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.217120; batch adversarial loss: 0.476004\n",
      "epoch 49; iter: 0; batch classifier loss: 0.158114; batch adversarial loss: 0.466340\n",
      "epoch 50; iter: 0; batch classifier loss: 0.211430; batch adversarial loss: 0.312518\n",
      "epoch 51; iter: 0; batch classifier loss: 0.269088; batch adversarial loss: 0.494128\n",
      "epoch 52; iter: 0; batch classifier loss: 0.187620; batch adversarial loss: 0.517069\n",
      "epoch 53; iter: 0; batch classifier loss: 0.200233; batch adversarial loss: 0.418177\n",
      "epoch 54; iter: 0; batch classifier loss: 0.130941; batch adversarial loss: 0.370240\n",
      "epoch 55; iter: 0; batch classifier loss: 0.188585; batch adversarial loss: 0.439623\n",
      "epoch 56; iter: 0; batch classifier loss: 0.295458; batch adversarial loss: 0.450364\n",
      "epoch 57; iter: 0; batch classifier loss: 0.179548; batch adversarial loss: 0.477165\n",
      "epoch 58; iter: 0; batch classifier loss: 0.183845; batch adversarial loss: 0.419679\n",
      "epoch 59; iter: 0; batch classifier loss: 0.163616; batch adversarial loss: 0.495316\n",
      "epoch 60; iter: 0; batch classifier loss: 0.160305; batch adversarial loss: 0.423875\n",
      "epoch 61; iter: 0; batch classifier loss: 0.251062; batch adversarial loss: 0.409299\n",
      "epoch 62; iter: 0; batch classifier loss: 0.268977; batch adversarial loss: 0.411935\n",
      "epoch 63; iter: 0; batch classifier loss: 0.158588; batch adversarial loss: 0.400432\n",
      "epoch 64; iter: 0; batch classifier loss: 0.181019; batch adversarial loss: 0.446996\n",
      "epoch 65; iter: 0; batch classifier loss: 0.111678; batch adversarial loss: 0.492075\n",
      "epoch 66; iter: 0; batch classifier loss: 0.221338; batch adversarial loss: 0.441641\n",
      "epoch 67; iter: 0; batch classifier loss: 0.218208; batch adversarial loss: 0.455362\n",
      "epoch 68; iter: 0; batch classifier loss: 0.242997; batch adversarial loss: 0.470874\n",
      "epoch 69; iter: 0; batch classifier loss: 0.219245; batch adversarial loss: 0.471685\n",
      "epoch 70; iter: 0; batch classifier loss: 0.217975; batch adversarial loss: 0.461225\n",
      "epoch 71; iter: 0; batch classifier loss: 0.122810; batch adversarial loss: 0.446149\n",
      "epoch 72; iter: 0; batch classifier loss: 0.205650; batch adversarial loss: 0.457425\n",
      "epoch 73; iter: 0; batch classifier loss: 0.211208; batch adversarial loss: 0.483966\n",
      "epoch 74; iter: 0; batch classifier loss: 0.179926; batch adversarial loss: 0.448218\n",
      "epoch 75; iter: 0; batch classifier loss: 0.237099; batch adversarial loss: 0.433143\n",
      "epoch 76; iter: 0; batch classifier loss: 0.193672; batch adversarial loss: 0.344837\n",
      "epoch 77; iter: 0; batch classifier loss: 0.156547; batch adversarial loss: 0.423615\n",
      "epoch 78; iter: 0; batch classifier loss: 0.192483; batch adversarial loss: 0.460066\n",
      "epoch 79; iter: 0; batch classifier loss: 0.143790; batch adversarial loss: 0.475278\n",
      "epoch 80; iter: 0; batch classifier loss: 0.164363; batch adversarial loss: 0.484570\n",
      "epoch 81; iter: 0; batch classifier loss: 0.107288; batch adversarial loss: 0.417673\n",
      "epoch 82; iter: 0; batch classifier loss: 0.182806; batch adversarial loss: 0.481079\n",
      "epoch 83; iter: 0; batch classifier loss: 0.119924; batch adversarial loss: 0.386290\n",
      "epoch 84; iter: 0; batch classifier loss: 0.230286; batch adversarial loss: 0.473294\n",
      "epoch 85; iter: 0; batch classifier loss: 0.194149; batch adversarial loss: 0.461330\n",
      "epoch 86; iter: 0; batch classifier loss: 0.098886; batch adversarial loss: 0.442524\n",
      "epoch 87; iter: 0; batch classifier loss: 0.126223; batch adversarial loss: 0.506539\n",
      "epoch 88; iter: 0; batch classifier loss: 0.138635; batch adversarial loss: 0.408926\n",
      "epoch 89; iter: 0; batch classifier loss: 0.093258; batch adversarial loss: 0.518633\n",
      "epoch 90; iter: 0; batch classifier loss: 0.071254; batch adversarial loss: 0.439455\n",
      "epoch 91; iter: 0; batch classifier loss: 0.127547; batch adversarial loss: 0.404800\n",
      "epoch 92; iter: 0; batch classifier loss: 0.154712; batch adversarial loss: 0.428378\n",
      "epoch 93; iter: 0; batch classifier loss: 0.091304; batch adversarial loss: 0.464963\n",
      "epoch 94; iter: 0; batch classifier loss: 0.084233; batch adversarial loss: 0.498463\n",
      "epoch 95; iter: 0; batch classifier loss: 0.076106; batch adversarial loss: 0.365331\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057628; batch adversarial loss: 0.419486\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047062; batch adversarial loss: 0.420013\n",
      "epoch 98; iter: 0; batch classifier loss: 0.028306; batch adversarial loss: 0.433532\n",
      "epoch 99; iter: 0; batch classifier loss: 0.113716; batch adversarial loss: 0.434648\n",
      "epoch 100; iter: 0; batch classifier loss: 0.072462; batch adversarial loss: 0.496226\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065141; batch adversarial loss: 0.373582\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060574; batch adversarial loss: 0.468871\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064202; batch adversarial loss: 0.527987\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069500; batch adversarial loss: 0.353083\n",
      "epoch 105; iter: 0; batch classifier loss: 0.065344; batch adversarial loss: 0.464684\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056346; batch adversarial loss: 0.458925\n",
      "epoch 107; iter: 0; batch classifier loss: 0.023670; batch adversarial loss: 0.428358\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048292; batch adversarial loss: 0.395828\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043244; batch adversarial loss: 0.474690\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044202; batch adversarial loss: 0.429860\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060686; batch adversarial loss: 0.432184\n",
      "epoch 112; iter: 0; batch classifier loss: 0.080680; batch adversarial loss: 0.492006\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056595; batch adversarial loss: 0.404965\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061815; batch adversarial loss: 0.447252\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042045; batch adversarial loss: 0.448541\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044834; batch adversarial loss: 0.413079\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039463; batch adversarial loss: 0.466518\n",
      "epoch 118; iter: 0; batch classifier loss: 0.072172; batch adversarial loss: 0.455689\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035854; batch adversarial loss: 0.506642\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043401; batch adversarial loss: 0.476496\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052465; batch adversarial loss: 0.433005\n",
      "epoch 122; iter: 0; batch classifier loss: 0.057302; batch adversarial loss: 0.544298\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024513; batch adversarial loss: 0.460596\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025565; batch adversarial loss: 0.498161\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025624; batch adversarial loss: 0.451752\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055044; batch adversarial loss: 0.559017\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035726; batch adversarial loss: 0.470946\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025193; batch adversarial loss: 0.479327\n",
      "epoch 129; iter: 0; batch classifier loss: 0.013497; batch adversarial loss: 0.459431\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032328; batch adversarial loss: 0.414975\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029852; batch adversarial loss: 0.412103\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058772; batch adversarial loss: 0.452236\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027918; batch adversarial loss: 0.390848\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048518; batch adversarial loss: 0.451094\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025930; batch adversarial loss: 0.376395\n",
      "epoch 136; iter: 0; batch classifier loss: 0.060717; batch adversarial loss: 0.471237\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054424; batch adversarial loss: 0.444442\n",
      "epoch 138; iter: 0; batch classifier loss: 0.051518; batch adversarial loss: 0.409689\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037822; batch adversarial loss: 0.441485\n",
      "epoch 140; iter: 0; batch classifier loss: 0.064194; batch adversarial loss: 0.436722\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020336; batch adversarial loss: 0.408188\n",
      "epoch 142; iter: 0; batch classifier loss: 0.047912; batch adversarial loss: 0.523853\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026566; batch adversarial loss: 0.412787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.023984; batch adversarial loss: 0.437950\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021764; batch adversarial loss: 0.349580\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048365; batch adversarial loss: 0.432602\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011108; batch adversarial loss: 0.341335\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035383; batch adversarial loss: 0.458281\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034028; batch adversarial loss: 0.386268\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013308; batch adversarial loss: 0.477125\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016295; batch adversarial loss: 0.498753\n",
      "epoch 152; iter: 0; batch classifier loss: 0.007741; batch adversarial loss: 0.476422\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030278; batch adversarial loss: 0.420863\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013840; batch adversarial loss: 0.458625\n",
      "epoch 155; iter: 0; batch classifier loss: 0.074355; batch adversarial loss: 0.366839\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019973; batch adversarial loss: 0.400376\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030444; batch adversarial loss: 0.457202\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034991; batch adversarial loss: 0.450293\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042219; batch adversarial loss: 0.483638\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031611; batch adversarial loss: 0.432798\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032362; batch adversarial loss: 0.503143\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031843; batch adversarial loss: 0.488399\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009655; batch adversarial loss: 0.445499\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023592; batch adversarial loss: 0.424005\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010284; batch adversarial loss: 0.487267\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014229; batch adversarial loss: 0.435886\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026455; batch adversarial loss: 0.388309\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017783; batch adversarial loss: 0.522102\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022690; batch adversarial loss: 0.367816\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031602; batch adversarial loss: 0.416895\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013356; batch adversarial loss: 0.432258\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033956; batch adversarial loss: 0.430398\n",
      "epoch 173; iter: 0; batch classifier loss: 0.051168; batch adversarial loss: 0.541195\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037166; batch adversarial loss: 0.380922\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011593; batch adversarial loss: 0.536277\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015550; batch adversarial loss: 0.352619\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017619; batch adversarial loss: 0.439291\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026631; batch adversarial loss: 0.496702\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013680; batch adversarial loss: 0.455703\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029521; batch adversarial loss: 0.397936\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020065; batch adversarial loss: 0.470923\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009398; batch adversarial loss: 0.466322\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006686; batch adversarial loss: 0.490457\n",
      "epoch 184; iter: 0; batch classifier loss: 0.041936; batch adversarial loss: 0.489531\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024883; batch adversarial loss: 0.428640\n",
      "epoch 186; iter: 0; batch classifier loss: 0.042389; batch adversarial loss: 0.406528\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018652; batch adversarial loss: 0.442588\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023211; batch adversarial loss: 0.513923\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011987; batch adversarial loss: 0.493715\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014005; batch adversarial loss: 0.496301\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007013; batch adversarial loss: 0.414466\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019138; batch adversarial loss: 0.508902\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018449; batch adversarial loss: 0.389528\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016907; batch adversarial loss: 0.441594\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008393; batch adversarial loss: 0.571583\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008818; batch adversarial loss: 0.450639\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021849; batch adversarial loss: 0.406033\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027744; batch adversarial loss: 0.406594\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009695; batch adversarial loss: 0.448369\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697134; batch adversarial loss: 0.532309\n",
      "epoch 1; iter: 0; batch classifier loss: 0.539054; batch adversarial loss: 0.607686\n",
      "epoch 2; iter: 0; batch classifier loss: 0.465353; batch adversarial loss: 0.584640\n",
      "epoch 3; iter: 0; batch classifier loss: 0.444324; batch adversarial loss: 0.603879\n",
      "epoch 4; iter: 0; batch classifier loss: 0.467102; batch adversarial loss: 0.586009\n",
      "epoch 5; iter: 0; batch classifier loss: 0.440286; batch adversarial loss: 0.572670\n",
      "epoch 6; iter: 0; batch classifier loss: 0.524611; batch adversarial loss: 0.554353\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550270; batch adversarial loss: 0.595381\n",
      "epoch 8; iter: 0; batch classifier loss: 0.763052; batch adversarial loss: 0.552228\n",
      "epoch 9; iter: 0; batch classifier loss: 0.635230; batch adversarial loss: 0.530164\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472869; batch adversarial loss: 0.523506\n",
      "epoch 11; iter: 0; batch classifier loss: 0.454250; batch adversarial loss: 0.544334\n",
      "epoch 12; iter: 0; batch classifier loss: 0.364817; batch adversarial loss: 0.474773\n",
      "epoch 13; iter: 0; batch classifier loss: 0.349639; batch adversarial loss: 0.457417\n",
      "epoch 14; iter: 0; batch classifier loss: 0.290972; batch adversarial loss: 0.480254\n",
      "epoch 15; iter: 0; batch classifier loss: 0.347374; batch adversarial loss: 0.467615\n",
      "epoch 16; iter: 0; batch classifier loss: 0.273521; batch adversarial loss: 0.516373\n",
      "epoch 17; iter: 0; batch classifier loss: 0.257741; batch adversarial loss: 0.416282\n",
      "epoch 18; iter: 0; batch classifier loss: 0.306196; batch adversarial loss: 0.459217\n",
      "epoch 19; iter: 0; batch classifier loss: 0.244184; batch adversarial loss: 0.382361\n",
      "epoch 20; iter: 0; batch classifier loss: 0.197313; batch adversarial loss: 0.381561\n",
      "epoch 21; iter: 0; batch classifier loss: 0.231267; batch adversarial loss: 0.550715\n",
      "epoch 22; iter: 0; batch classifier loss: 0.213263; batch adversarial loss: 0.474942\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285682; batch adversarial loss: 0.403636\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182206; batch adversarial loss: 0.458914\n",
      "epoch 25; iter: 0; batch classifier loss: 0.183887; batch adversarial loss: 0.460817\n",
      "epoch 26; iter: 0; batch classifier loss: 0.149359; batch adversarial loss: 0.414629\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152959; batch adversarial loss: 0.546974\n",
      "epoch 28; iter: 0; batch classifier loss: 0.132776; batch adversarial loss: 0.466695\n",
      "epoch 29; iter: 0; batch classifier loss: 0.151017; batch adversarial loss: 0.482205\n",
      "epoch 30; iter: 0; batch classifier loss: 0.127768; batch adversarial loss: 0.446864\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141009; batch adversarial loss: 0.446749\n",
      "epoch 32; iter: 0; batch classifier loss: 0.128283; batch adversarial loss: 0.489164\n",
      "epoch 33; iter: 0; batch classifier loss: 0.155060; batch adversarial loss: 0.455175\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122030; batch adversarial loss: 0.433062\n",
      "epoch 35; iter: 0; batch classifier loss: 0.110620; batch adversarial loss: 0.544447\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187292; batch adversarial loss: 0.428981\n",
      "epoch 37; iter: 0; batch classifier loss: 0.121419; batch adversarial loss: 0.427013\n",
      "epoch 38; iter: 0; batch classifier loss: 0.137659; batch adversarial loss: 0.463017\n",
      "epoch 39; iter: 0; batch classifier loss: 0.096602; batch adversarial loss: 0.438818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.135581; batch adversarial loss: 0.496676\n",
      "epoch 41; iter: 0; batch classifier loss: 0.102655; batch adversarial loss: 0.508393\n",
      "epoch 42; iter: 0; batch classifier loss: 0.154483; batch adversarial loss: 0.456509\n",
      "epoch 43; iter: 0; batch classifier loss: 0.126973; batch adversarial loss: 0.439192\n",
      "epoch 44; iter: 0; batch classifier loss: 0.095586; batch adversarial loss: 0.462612\n",
      "epoch 45; iter: 0; batch classifier loss: 0.077054; batch adversarial loss: 0.462608\n",
      "epoch 46; iter: 0; batch classifier loss: 0.099025; batch adversarial loss: 0.483778\n",
      "epoch 47; iter: 0; batch classifier loss: 0.121076; batch adversarial loss: 0.570530\n",
      "epoch 48; iter: 0; batch classifier loss: 0.087478; batch adversarial loss: 0.453213\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074582; batch adversarial loss: 0.570047\n",
      "epoch 50; iter: 0; batch classifier loss: 0.144749; batch adversarial loss: 0.407144\n",
      "epoch 51; iter: 0; batch classifier loss: 0.058063; batch adversarial loss: 0.634613\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082668; batch adversarial loss: 0.585034\n",
      "epoch 53; iter: 0; batch classifier loss: 0.097250; batch adversarial loss: 0.400019\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080276; batch adversarial loss: 0.486226\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119003; batch adversarial loss: 0.452192\n",
      "epoch 56; iter: 0; batch classifier loss: 0.142266; batch adversarial loss: 0.517981\n",
      "epoch 57; iter: 0; batch classifier loss: 0.062034; batch adversarial loss: 0.408547\n",
      "epoch 58; iter: 0; batch classifier loss: 0.070381; batch adversarial loss: 0.541360\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105949; batch adversarial loss: 0.412117\n",
      "epoch 60; iter: 0; batch classifier loss: 0.142015; batch adversarial loss: 0.444667\n",
      "epoch 61; iter: 0; batch classifier loss: 0.096011; batch adversarial loss: 0.476825\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094466; batch adversarial loss: 0.442698\n",
      "epoch 63; iter: 0; batch classifier loss: 0.113321; batch adversarial loss: 0.444478\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082568; batch adversarial loss: 0.450507\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088321; batch adversarial loss: 0.419734\n",
      "epoch 66; iter: 0; batch classifier loss: 0.094896; batch adversarial loss: 0.548726\n",
      "epoch 67; iter: 0; batch classifier loss: 0.068241; batch adversarial loss: 0.421789\n",
      "epoch 68; iter: 0; batch classifier loss: 0.058116; batch adversarial loss: 0.546432\n",
      "epoch 69; iter: 0; batch classifier loss: 0.045345; batch adversarial loss: 0.518406\n",
      "epoch 70; iter: 0; batch classifier loss: 0.064632; batch adversarial loss: 0.422975\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104923; batch adversarial loss: 0.491644\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062674; batch adversarial loss: 0.362364\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081865; batch adversarial loss: 0.424014\n",
      "epoch 74; iter: 0; batch classifier loss: 0.043720; batch adversarial loss: 0.445986\n",
      "epoch 75; iter: 0; batch classifier loss: 0.052963; batch adversarial loss: 0.418611\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059949; batch adversarial loss: 0.417477\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067715; batch adversarial loss: 0.462600\n",
      "epoch 78; iter: 0; batch classifier loss: 0.047592; batch adversarial loss: 0.499716\n",
      "epoch 79; iter: 0; batch classifier loss: 0.123714; batch adversarial loss: 0.432939\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067674; batch adversarial loss: 0.434348\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050619; batch adversarial loss: 0.503171\n",
      "epoch 82; iter: 0; batch classifier loss: 0.088108; batch adversarial loss: 0.433043\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094148; batch adversarial loss: 0.427156\n",
      "epoch 84; iter: 0; batch classifier loss: 0.040738; batch adversarial loss: 0.396429\n",
      "epoch 85; iter: 0; batch classifier loss: 0.085958; batch adversarial loss: 0.417031\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054658; batch adversarial loss: 0.461362\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067213; batch adversarial loss: 0.454393\n",
      "epoch 88; iter: 0; batch classifier loss: 0.121478; batch adversarial loss: 0.380622\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080132; batch adversarial loss: 0.428918\n",
      "epoch 90; iter: 0; batch classifier loss: 0.081708; batch adversarial loss: 0.451510\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050443; batch adversarial loss: 0.508215\n",
      "epoch 92; iter: 0; batch classifier loss: 0.110389; batch adversarial loss: 0.516468\n",
      "epoch 93; iter: 0; batch classifier loss: 0.037453; batch adversarial loss: 0.441426\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066433; batch adversarial loss: 0.534265\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070552; batch adversarial loss: 0.454895\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055433; batch adversarial loss: 0.473218\n",
      "epoch 97; iter: 0; batch classifier loss: 0.041087; batch adversarial loss: 0.456397\n",
      "epoch 98; iter: 0; batch classifier loss: 0.082087; batch adversarial loss: 0.455862\n",
      "epoch 99; iter: 0; batch classifier loss: 0.115394; batch adversarial loss: 0.457234\n",
      "epoch 100; iter: 0; batch classifier loss: 0.092360; batch adversarial loss: 0.335562\n",
      "epoch 101; iter: 0; batch classifier loss: 0.111517; batch adversarial loss: 0.484371\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051069; batch adversarial loss: 0.448249\n",
      "epoch 103; iter: 0; batch classifier loss: 0.094478; batch adversarial loss: 0.458215\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048157; batch adversarial loss: 0.536865\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048649; batch adversarial loss: 0.476893\n",
      "epoch 106; iter: 0; batch classifier loss: 0.129653; batch adversarial loss: 0.446210\n",
      "epoch 107; iter: 0; batch classifier loss: 0.078277; batch adversarial loss: 0.388241\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046977; batch adversarial loss: 0.457950\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062306; batch adversarial loss: 0.472761\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046446; batch adversarial loss: 0.407003\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064781; batch adversarial loss: 0.517165\n",
      "epoch 112; iter: 0; batch classifier loss: 0.096386; batch adversarial loss: 0.414663\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055769; batch adversarial loss: 0.400796\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046337; batch adversarial loss: 0.576322\n",
      "epoch 115; iter: 0; batch classifier loss: 0.030468; batch adversarial loss: 0.515419\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054545; batch adversarial loss: 0.479257\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031280; batch adversarial loss: 0.532555\n",
      "epoch 118; iter: 0; batch classifier loss: 0.014151; batch adversarial loss: 0.428752\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055274; batch adversarial loss: 0.490046\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064664; batch adversarial loss: 0.452804\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047612; batch adversarial loss: 0.469992\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046195; batch adversarial loss: 0.352789\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025707; batch adversarial loss: 0.475928\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033770; batch adversarial loss: 0.398059\n",
      "epoch 125; iter: 0; batch classifier loss: 0.016258; batch adversarial loss: 0.458833\n",
      "epoch 126; iter: 0; batch classifier loss: 0.072225; batch adversarial loss: 0.509699\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026343; batch adversarial loss: 0.504207\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035760; batch adversarial loss: 0.453964\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051266; batch adversarial loss: 0.387705\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061298; batch adversarial loss: 0.448949\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015862; batch adversarial loss: 0.480280\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042021; batch adversarial loss: 0.407438\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043552; batch adversarial loss: 0.404865\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045027; batch adversarial loss: 0.433522\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018380; batch adversarial loss: 0.492758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.044804; batch adversarial loss: 0.440327\n",
      "epoch 137; iter: 0; batch classifier loss: 0.065246; batch adversarial loss: 0.462545\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025459; batch adversarial loss: 0.553481\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043256; batch adversarial loss: 0.460519\n",
      "epoch 140; iter: 0; batch classifier loss: 0.071966; batch adversarial loss: 0.400570\n",
      "epoch 141; iter: 0; batch classifier loss: 0.059633; batch adversarial loss: 0.353958\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031834; batch adversarial loss: 0.461558\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018675; batch adversarial loss: 0.457318\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019844; batch adversarial loss: 0.433533\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038422; batch adversarial loss: 0.446454\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013756; batch adversarial loss: 0.484974\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052099; batch adversarial loss: 0.491562\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046905; batch adversarial loss: 0.407843\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019301; batch adversarial loss: 0.390161\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044744; batch adversarial loss: 0.378334\n",
      "epoch 151; iter: 0; batch classifier loss: 0.053767; batch adversarial loss: 0.438140\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041980; batch adversarial loss: 0.401527\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032003; batch adversarial loss: 0.431456\n",
      "epoch 154; iter: 0; batch classifier loss: 0.009463; batch adversarial loss: 0.482937\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022768; batch adversarial loss: 0.389764\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016901; batch adversarial loss: 0.446750\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021933; batch adversarial loss: 0.461550\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026602; batch adversarial loss: 0.452312\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019596; batch adversarial loss: 0.483211\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021596; batch adversarial loss: 0.520679\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038846; batch adversarial loss: 0.474836\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024375; batch adversarial loss: 0.488118\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016445; batch adversarial loss: 0.464875\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043141; batch adversarial loss: 0.469630\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014093; batch adversarial loss: 0.515915\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043099; batch adversarial loss: 0.554763\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017056; batch adversarial loss: 0.447284\n",
      "epoch 168; iter: 0; batch classifier loss: 0.042870; batch adversarial loss: 0.418586\n",
      "epoch 169; iter: 0; batch classifier loss: 0.051957; batch adversarial loss: 0.448774\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017926; batch adversarial loss: 0.505478\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020289; batch adversarial loss: 0.430446\n",
      "epoch 172; iter: 0; batch classifier loss: 0.047577; batch adversarial loss: 0.371474\n",
      "epoch 173; iter: 0; batch classifier loss: 0.061729; batch adversarial loss: 0.336890\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028130; batch adversarial loss: 0.465411\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023054; batch adversarial loss: 0.354300\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008741; batch adversarial loss: 0.426344\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015715; batch adversarial loss: 0.462372\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023721; batch adversarial loss: 0.459737\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022676; batch adversarial loss: 0.368147\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035320; batch adversarial loss: 0.389315\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024713; batch adversarial loss: 0.531302\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029831; batch adversarial loss: 0.461502\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034297; batch adversarial loss: 0.614916\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009308; batch adversarial loss: 0.467234\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022218; batch adversarial loss: 0.583829\n",
      "epoch 186; iter: 0; batch classifier loss: 0.050847; batch adversarial loss: 0.392503\n",
      "epoch 187; iter: 0; batch classifier loss: 0.004956; batch adversarial loss: 0.464657\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008226; batch adversarial loss: 0.409704\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014423; batch adversarial loss: 0.537286\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035437; batch adversarial loss: 0.524803\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022142; batch adversarial loss: 0.555452\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007203; batch adversarial loss: 0.507076\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025413; batch adversarial loss: 0.469105\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023088; batch adversarial loss: 0.481648\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014875; batch adversarial loss: 0.452526\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031555; batch adversarial loss: 0.429646\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018938; batch adversarial loss: 0.448948\n",
      "epoch 198; iter: 0; batch classifier loss: 0.042887; batch adversarial loss: 0.411158\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014120; batch adversarial loss: 0.413376\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711104; batch adversarial loss: 0.901180\n",
      "epoch 1; iter: 0; batch classifier loss: 0.435910; batch adversarial loss: 0.903670\n",
      "epoch 2; iter: 0; batch classifier loss: 0.318935; batch adversarial loss: 0.891496\n",
      "epoch 3; iter: 0; batch classifier loss: 0.411898; batch adversarial loss: 0.805889\n",
      "epoch 4; iter: 0; batch classifier loss: 0.319855; batch adversarial loss: 0.786485\n",
      "epoch 5; iter: 0; batch classifier loss: 0.326621; batch adversarial loss: 0.705207\n",
      "epoch 6; iter: 0; batch classifier loss: 0.345785; batch adversarial loss: 0.691154\n",
      "epoch 7; iter: 0; batch classifier loss: 0.290406; batch adversarial loss: 0.654633\n",
      "epoch 8; iter: 0; batch classifier loss: 0.394016; batch adversarial loss: 0.628760\n",
      "epoch 9; iter: 0; batch classifier loss: 0.333778; batch adversarial loss: 0.566877\n",
      "epoch 10; iter: 0; batch classifier loss: 0.273671; batch adversarial loss: 0.559712\n",
      "epoch 11; iter: 0; batch classifier loss: 0.330418; batch adversarial loss: 0.514001\n",
      "epoch 12; iter: 0; batch classifier loss: 0.247195; batch adversarial loss: 0.509144\n",
      "epoch 13; iter: 0; batch classifier loss: 0.272559; batch adversarial loss: 0.522808\n",
      "epoch 14; iter: 0; batch classifier loss: 0.223171; batch adversarial loss: 0.557394\n",
      "epoch 15; iter: 0; batch classifier loss: 0.199943; batch adversarial loss: 0.507258\n",
      "epoch 16; iter: 0; batch classifier loss: 0.297549; batch adversarial loss: 0.485048\n",
      "epoch 17; iter: 0; batch classifier loss: 0.218442; batch adversarial loss: 0.447725\n",
      "epoch 18; iter: 0; batch classifier loss: 0.240202; batch adversarial loss: 0.504524\n",
      "epoch 19; iter: 0; batch classifier loss: 0.352500; batch adversarial loss: 0.409926\n",
      "epoch 20; iter: 0; batch classifier loss: 0.296330; batch adversarial loss: 0.378561\n",
      "epoch 21; iter: 0; batch classifier loss: 0.305035; batch adversarial loss: 0.416430\n",
      "epoch 22; iter: 0; batch classifier loss: 0.241401; batch adversarial loss: 0.408956\n",
      "epoch 23; iter: 0; batch classifier loss: 0.281096; batch adversarial loss: 0.371793\n",
      "epoch 24; iter: 0; batch classifier loss: 0.309013; batch adversarial loss: 0.371415\n",
      "epoch 25; iter: 0; batch classifier loss: 0.239063; batch adversarial loss: 0.371488\n",
      "epoch 26; iter: 0; batch classifier loss: 0.287772; batch adversarial loss: 0.368316\n",
      "epoch 27; iter: 0; batch classifier loss: 0.256906; batch adversarial loss: 0.454278\n",
      "epoch 28; iter: 0; batch classifier loss: 0.214651; batch adversarial loss: 0.339167\n",
      "epoch 29; iter: 0; batch classifier loss: 0.278592; batch adversarial loss: 0.418512\n",
      "epoch 30; iter: 0; batch classifier loss: 0.184786; batch adversarial loss: 0.327742\n",
      "epoch 31; iter: 0; batch classifier loss: 0.215189; batch adversarial loss: 0.353889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.189996; batch adversarial loss: 0.399875\n",
      "epoch 33; iter: 0; batch classifier loss: 0.182114; batch adversarial loss: 0.381137\n",
      "epoch 34; iter: 0; batch classifier loss: 0.218331; batch adversarial loss: 0.445965\n",
      "epoch 35; iter: 0; batch classifier loss: 0.178829; batch adversarial loss: 0.323443\n",
      "epoch 36; iter: 0; batch classifier loss: 0.201911; batch adversarial loss: 0.397319\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166698; batch adversarial loss: 0.468157\n",
      "epoch 38; iter: 0; batch classifier loss: 0.159686; batch adversarial loss: 0.356481\n",
      "epoch 39; iter: 0; batch classifier loss: 0.151400; batch adversarial loss: 0.490956\n",
      "epoch 40; iter: 0; batch classifier loss: 0.148773; batch adversarial loss: 0.353720\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123599; batch adversarial loss: 0.380224\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096749; batch adversarial loss: 0.385978\n",
      "epoch 43; iter: 0; batch classifier loss: 0.107648; batch adversarial loss: 0.387739\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098255; batch adversarial loss: 0.398119\n",
      "epoch 45; iter: 0; batch classifier loss: 0.194542; batch adversarial loss: 0.435127\n",
      "epoch 46; iter: 0; batch classifier loss: 0.134633; batch adversarial loss: 0.450253\n",
      "epoch 47; iter: 0; batch classifier loss: 0.166304; batch adversarial loss: 0.285082\n",
      "epoch 48; iter: 0; batch classifier loss: 0.120177; batch adversarial loss: 0.415846\n",
      "epoch 49; iter: 0; batch classifier loss: 0.124031; batch adversarial loss: 0.352854\n",
      "epoch 50; iter: 0; batch classifier loss: 0.162996; batch adversarial loss: 0.384886\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122631; batch adversarial loss: 0.421762\n",
      "epoch 52; iter: 0; batch classifier loss: 0.104901; batch adversarial loss: 0.477229\n",
      "epoch 53; iter: 0; batch classifier loss: 0.180422; batch adversarial loss: 0.390109\n",
      "epoch 54; iter: 0; batch classifier loss: 0.104834; batch adversarial loss: 0.366304\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086897; batch adversarial loss: 0.389752\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101656; batch adversarial loss: 0.365003\n",
      "epoch 57; iter: 0; batch classifier loss: 0.134523; batch adversarial loss: 0.419656\n",
      "epoch 58; iter: 0; batch classifier loss: 0.085041; batch adversarial loss: 0.353850\n",
      "epoch 59; iter: 0; batch classifier loss: 0.096136; batch adversarial loss: 0.324211\n",
      "epoch 60; iter: 0; batch classifier loss: 0.141354; batch adversarial loss: 0.304905\n",
      "epoch 61; iter: 0; batch classifier loss: 0.128365; batch adversarial loss: 0.397568\n",
      "epoch 62; iter: 0; batch classifier loss: 0.107078; batch adversarial loss: 0.334684\n",
      "epoch 63; iter: 0; batch classifier loss: 0.110595; batch adversarial loss: 0.463379\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080294; batch adversarial loss: 0.451768\n",
      "epoch 65; iter: 0; batch classifier loss: 0.106512; batch adversarial loss: 0.417736\n",
      "epoch 66; iter: 0; batch classifier loss: 0.108409; batch adversarial loss: 0.409305\n",
      "epoch 67; iter: 0; batch classifier loss: 0.108202; batch adversarial loss: 0.384336\n",
      "epoch 68; iter: 0; batch classifier loss: 0.117164; batch adversarial loss: 0.390468\n",
      "epoch 69; iter: 0; batch classifier loss: 0.108936; batch adversarial loss: 0.343304\n",
      "epoch 70; iter: 0; batch classifier loss: 0.077253; batch adversarial loss: 0.346686\n",
      "epoch 71; iter: 0; batch classifier loss: 0.135308; batch adversarial loss: 0.456468\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081944; batch adversarial loss: 0.397758\n",
      "epoch 73; iter: 0; batch classifier loss: 0.072015; batch adversarial loss: 0.425776\n",
      "epoch 74; iter: 0; batch classifier loss: 0.095687; batch adversarial loss: 0.408403\n",
      "epoch 75; iter: 0; batch classifier loss: 0.080657; batch adversarial loss: 0.511386\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065380; batch adversarial loss: 0.434644\n",
      "epoch 77; iter: 0; batch classifier loss: 0.121331; batch adversarial loss: 0.436048\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066603; batch adversarial loss: 0.382304\n",
      "epoch 79; iter: 0; batch classifier loss: 0.139476; batch adversarial loss: 0.432941\n",
      "epoch 80; iter: 0; batch classifier loss: 0.096391; batch adversarial loss: 0.573648\n",
      "epoch 81; iter: 0; batch classifier loss: 0.088375; batch adversarial loss: 0.374056\n",
      "epoch 82; iter: 0; batch classifier loss: 0.078580; batch adversarial loss: 0.345327\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062033; batch adversarial loss: 0.320686\n",
      "epoch 84; iter: 0; batch classifier loss: 0.058763; batch adversarial loss: 0.483963\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083340; batch adversarial loss: 0.417584\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065185; batch adversarial loss: 0.476915\n",
      "epoch 87; iter: 0; batch classifier loss: 0.063696; batch adversarial loss: 0.468658\n",
      "epoch 88; iter: 0; batch classifier loss: 0.045579; batch adversarial loss: 0.452836\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075682; batch adversarial loss: 0.496366\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061405; batch adversarial loss: 0.453443\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039634; batch adversarial loss: 0.329194\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059670; batch adversarial loss: 0.398696\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062779; batch adversarial loss: 0.454587\n",
      "epoch 94; iter: 0; batch classifier loss: 0.073160; batch adversarial loss: 0.494544\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057486; batch adversarial loss: 0.382287\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064356; batch adversarial loss: 0.450544\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053268; batch adversarial loss: 0.448612\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039567; batch adversarial loss: 0.469162\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041243; batch adversarial loss: 0.391492\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065885; batch adversarial loss: 0.465182\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048521; batch adversarial loss: 0.457171\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060855; batch adversarial loss: 0.411007\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060241; batch adversarial loss: 0.424195\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045654; batch adversarial loss: 0.367556\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040175; batch adversarial loss: 0.437948\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047330; batch adversarial loss: 0.592810\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033479; batch adversarial loss: 0.409566\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043244; batch adversarial loss: 0.412986\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026102; batch adversarial loss: 0.463565\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043896; batch adversarial loss: 0.450060\n",
      "epoch 111; iter: 0; batch classifier loss: 0.071474; batch adversarial loss: 0.580630\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034297; batch adversarial loss: 0.518658\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028004; batch adversarial loss: 0.406039\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042911; batch adversarial loss: 0.428774\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045023; batch adversarial loss: 0.504427\n",
      "epoch 116; iter: 0; batch classifier loss: 0.020232; batch adversarial loss: 0.439617\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035661; batch adversarial loss: 0.416847\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042434; batch adversarial loss: 0.423191\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031752; batch adversarial loss: 0.454471\n",
      "epoch 120; iter: 0; batch classifier loss: 0.029194; batch adversarial loss: 0.472083\n",
      "epoch 121; iter: 0; batch classifier loss: 0.022272; batch adversarial loss: 0.500319\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033345; batch adversarial loss: 0.408429\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034190; batch adversarial loss: 0.418272\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043626; batch adversarial loss: 0.442258\n",
      "epoch 125; iter: 0; batch classifier loss: 0.071542; batch adversarial loss: 0.489385\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046117; batch adversarial loss: 0.479010\n",
      "epoch 127; iter: 0; batch classifier loss: 0.105659; batch adversarial loss: 0.642619\n",
      "epoch 128; iter: 0; batch classifier loss: 0.079625; batch adversarial loss: 0.532035\n",
      "epoch 129; iter: 0; batch classifier loss: 0.109706; batch adversarial loss: 0.713881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.071030; batch adversarial loss: 0.575205\n",
      "epoch 131; iter: 0; batch classifier loss: 0.086606; batch adversarial loss: 0.582964\n",
      "epoch 132; iter: 0; batch classifier loss: 0.122318; batch adversarial loss: 0.566827\n",
      "epoch 133; iter: 0; batch classifier loss: 0.096181; batch adversarial loss: 0.452604\n",
      "epoch 134; iter: 0; batch classifier loss: 0.095342; batch adversarial loss: 0.589182\n",
      "epoch 135; iter: 0; batch classifier loss: 0.116264; batch adversarial loss: 0.526708\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057819; batch adversarial loss: 0.517069\n",
      "epoch 137; iter: 0; batch classifier loss: 0.117156; batch adversarial loss: 0.534329\n",
      "epoch 138; iter: 0; batch classifier loss: 0.085296; batch adversarial loss: 0.574475\n",
      "epoch 139; iter: 0; batch classifier loss: 0.081444; batch adversarial loss: 0.514913\n",
      "epoch 140; iter: 0; batch classifier loss: 0.109175; batch adversarial loss: 0.593331\n",
      "epoch 141; iter: 0; batch classifier loss: 0.110302; batch adversarial loss: 0.579221\n",
      "epoch 142; iter: 0; batch classifier loss: 0.117415; batch adversarial loss: 0.624201\n",
      "epoch 143; iter: 0; batch classifier loss: 0.157845; batch adversarial loss: 0.585517\n",
      "epoch 144; iter: 0; batch classifier loss: 0.131471; batch adversarial loss: 0.611108\n",
      "epoch 145; iter: 0; batch classifier loss: 0.249087; batch adversarial loss: 0.768032\n",
      "epoch 146; iter: 0; batch classifier loss: 0.199553; batch adversarial loss: 0.697257\n",
      "epoch 147; iter: 0; batch classifier loss: 0.125179; batch adversarial loss: 0.528680\n",
      "epoch 148; iter: 0; batch classifier loss: 0.107967; batch adversarial loss: 0.561957\n",
      "epoch 149; iter: 0; batch classifier loss: 0.104357; batch adversarial loss: 0.492882\n",
      "epoch 150; iter: 0; batch classifier loss: 0.159147; batch adversarial loss: 0.625507\n",
      "epoch 151; iter: 0; batch classifier loss: 0.155620; batch adversarial loss: 0.503163\n",
      "epoch 152; iter: 0; batch classifier loss: 0.175116; batch adversarial loss: 0.559312\n",
      "epoch 153; iter: 0; batch classifier loss: 0.110148; batch adversarial loss: 0.476461\n",
      "epoch 154; iter: 0; batch classifier loss: 0.148184; batch adversarial loss: 0.591441\n",
      "epoch 155; iter: 0; batch classifier loss: 0.121651; batch adversarial loss: 0.474966\n",
      "epoch 156; iter: 0; batch classifier loss: 0.112989; batch adversarial loss: 0.492772\n",
      "epoch 157; iter: 0; batch classifier loss: 0.096221; batch adversarial loss: 0.483754\n",
      "epoch 158; iter: 0; batch classifier loss: 0.098235; batch adversarial loss: 0.432870\n",
      "epoch 159; iter: 0; batch classifier loss: 0.167871; batch adversarial loss: 0.601894\n",
      "epoch 160; iter: 0; batch classifier loss: 0.076295; batch adversarial loss: 0.443318\n",
      "epoch 161; iter: 0; batch classifier loss: 0.137747; batch adversarial loss: 0.563112\n",
      "epoch 162; iter: 0; batch classifier loss: 0.104839; batch adversarial loss: 0.540564\n",
      "epoch 163; iter: 0; batch classifier loss: 0.127811; batch adversarial loss: 0.513752\n",
      "epoch 164; iter: 0; batch classifier loss: 0.124735; batch adversarial loss: 0.463542\n",
      "epoch 165; iter: 0; batch classifier loss: 0.138497; batch adversarial loss: 0.521807\n",
      "epoch 166; iter: 0; batch classifier loss: 0.087099; batch adversarial loss: 0.423084\n",
      "epoch 167; iter: 0; batch classifier loss: 0.118310; batch adversarial loss: 0.461215\n",
      "epoch 168; iter: 0; batch classifier loss: 0.110868; batch adversarial loss: 0.462664\n",
      "epoch 169; iter: 0; batch classifier loss: 0.111392; batch adversarial loss: 0.501455\n",
      "epoch 170; iter: 0; batch classifier loss: 0.149196; batch adversarial loss: 0.504297\n",
      "epoch 171; iter: 0; batch classifier loss: 0.082506; batch adversarial loss: 0.437281\n",
      "epoch 172; iter: 0; batch classifier loss: 0.095864; batch adversarial loss: 0.440929\n",
      "epoch 173; iter: 0; batch classifier loss: 0.180165; batch adversarial loss: 0.511011\n",
      "epoch 174; iter: 0; batch classifier loss: 0.098408; batch adversarial loss: 0.491102\n",
      "epoch 175; iter: 0; batch classifier loss: 0.064698; batch adversarial loss: 0.381297\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035157; batch adversarial loss: 0.561672\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046325; batch adversarial loss: 0.503426\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020090; batch adversarial loss: 0.363578\n",
      "epoch 179; iter: 0; batch classifier loss: 0.103613; batch adversarial loss: 0.416830\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040732; batch adversarial loss: 0.404303\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024725; batch adversarial loss: 0.442797\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034205; batch adversarial loss: 0.400645\n",
      "epoch 183; iter: 0; batch classifier loss: 0.050204; batch adversarial loss: 0.431148\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016240; batch adversarial loss: 0.459661\n",
      "epoch 185; iter: 0; batch classifier loss: 0.052596; batch adversarial loss: 0.503373\n",
      "epoch 186; iter: 0; batch classifier loss: 0.053995; batch adversarial loss: 0.495102\n",
      "epoch 187; iter: 0; batch classifier loss: 0.055907; batch adversarial loss: 0.487824\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028484; batch adversarial loss: 0.363475\n",
      "epoch 189; iter: 0; batch classifier loss: 0.057397; batch adversarial loss: 0.545977\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038371; batch adversarial loss: 0.476697\n",
      "epoch 191; iter: 0; batch classifier loss: 0.081355; batch adversarial loss: 0.467555\n",
      "epoch 192; iter: 0; batch classifier loss: 0.116619; batch adversarial loss: 0.428888\n",
      "epoch 193; iter: 0; batch classifier loss: 0.089137; batch adversarial loss: 0.463965\n",
      "epoch 194; iter: 0; batch classifier loss: 0.054522; batch adversarial loss: 0.446048\n",
      "epoch 195; iter: 0; batch classifier loss: 0.084747; batch adversarial loss: 0.470045\n",
      "epoch 196; iter: 0; batch classifier loss: 0.080324; batch adversarial loss: 0.458678\n",
      "epoch 197; iter: 0; batch classifier loss: 0.058314; batch adversarial loss: 0.493731\n",
      "epoch 198; iter: 0; batch classifier loss: 0.125427; batch adversarial loss: 0.538624\n",
      "epoch 199; iter: 0; batch classifier loss: 0.061238; batch adversarial loss: 0.501698\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663022; batch adversarial loss: 0.529486\n",
      "epoch 1; iter: 0; batch classifier loss: 0.449052; batch adversarial loss: 0.595137\n",
      "epoch 2; iter: 0; batch classifier loss: 0.417791; batch adversarial loss: 0.603598\n",
      "epoch 3; iter: 0; batch classifier loss: 0.378200; batch adversarial loss: 0.668117\n",
      "epoch 4; iter: 0; batch classifier loss: 0.395773; batch adversarial loss: 0.602548\n",
      "epoch 5; iter: 0; batch classifier loss: 0.416343; batch adversarial loss: 0.638403\n",
      "epoch 6; iter: 0; batch classifier loss: 0.424480; batch adversarial loss: 0.685252\n",
      "epoch 7; iter: 0; batch classifier loss: 0.571699; batch adversarial loss: 0.550714\n",
      "epoch 8; iter: 0; batch classifier loss: 0.603833; batch adversarial loss: 0.602559\n",
      "epoch 9; iter: 0; batch classifier loss: 0.595481; batch adversarial loss: 0.551696\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503756; batch adversarial loss: 0.584298\n",
      "epoch 11; iter: 0; batch classifier loss: 0.427626; batch adversarial loss: 0.562265\n",
      "epoch 12; iter: 0; batch classifier loss: 0.397861; batch adversarial loss: 0.567539\n",
      "epoch 13; iter: 0; batch classifier loss: 0.436879; batch adversarial loss: 0.455980\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283612; batch adversarial loss: 0.484110\n",
      "epoch 15; iter: 0; batch classifier loss: 0.333205; batch adversarial loss: 0.500977\n",
      "epoch 16; iter: 0; batch classifier loss: 0.225310; batch adversarial loss: 0.441995\n",
      "epoch 17; iter: 0; batch classifier loss: 0.270073; batch adversarial loss: 0.518313\n",
      "epoch 18; iter: 0; batch classifier loss: 0.212051; batch adversarial loss: 0.504501\n",
      "epoch 19; iter: 0; batch classifier loss: 0.231776; batch adversarial loss: 0.408735\n",
      "epoch 20; iter: 0; batch classifier loss: 0.231580; batch adversarial loss: 0.402665\n",
      "epoch 21; iter: 0; batch classifier loss: 0.194284; batch adversarial loss: 0.490072\n",
      "epoch 22; iter: 0; batch classifier loss: 0.187502; batch adversarial loss: 0.470092\n",
      "epoch 23; iter: 0; batch classifier loss: 0.172383; batch adversarial loss: 0.479664\n",
      "epoch 24; iter: 0; batch classifier loss: 0.200670; batch adversarial loss: 0.471364\n",
      "epoch 25; iter: 0; batch classifier loss: 0.175500; batch adversarial loss: 0.522655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.193196; batch adversarial loss: 0.510242\n",
      "epoch 27; iter: 0; batch classifier loss: 0.149726; batch adversarial loss: 0.399159\n",
      "epoch 28; iter: 0; batch classifier loss: 0.170175; batch adversarial loss: 0.400460\n",
      "epoch 29; iter: 0; batch classifier loss: 0.112798; batch adversarial loss: 0.494826\n",
      "epoch 30; iter: 0; batch classifier loss: 0.106241; batch adversarial loss: 0.603457\n",
      "epoch 31; iter: 0; batch classifier loss: 0.121531; batch adversarial loss: 0.435257\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172381; batch adversarial loss: 0.379443\n",
      "epoch 33; iter: 0; batch classifier loss: 0.113747; batch adversarial loss: 0.432411\n",
      "epoch 34; iter: 0; batch classifier loss: 0.128206; batch adversarial loss: 0.464753\n",
      "epoch 35; iter: 0; batch classifier loss: 0.159058; batch adversarial loss: 0.429371\n",
      "epoch 36; iter: 0; batch classifier loss: 0.075440; batch adversarial loss: 0.477891\n",
      "epoch 37; iter: 0; batch classifier loss: 0.116319; batch adversarial loss: 0.423189\n",
      "epoch 38; iter: 0; batch classifier loss: 0.109280; batch adversarial loss: 0.479677\n",
      "epoch 39; iter: 0; batch classifier loss: 0.145601; batch adversarial loss: 0.405624\n",
      "epoch 40; iter: 0; batch classifier loss: 0.085712; batch adversarial loss: 0.455291\n",
      "epoch 41; iter: 0; batch classifier loss: 0.102930; batch adversarial loss: 0.363337\n",
      "epoch 42; iter: 0; batch classifier loss: 0.072206; batch adversarial loss: 0.404799\n",
      "epoch 43; iter: 0; batch classifier loss: 0.087673; batch adversarial loss: 0.571452\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097297; batch adversarial loss: 0.337784\n",
      "epoch 45; iter: 0; batch classifier loss: 0.113643; batch adversarial loss: 0.412796\n",
      "epoch 46; iter: 0; batch classifier loss: 0.107159; batch adversarial loss: 0.417294\n",
      "epoch 47; iter: 0; batch classifier loss: 0.141621; batch adversarial loss: 0.479959\n",
      "epoch 48; iter: 0; batch classifier loss: 0.105254; batch adversarial loss: 0.470823\n",
      "epoch 49; iter: 0; batch classifier loss: 0.151226; batch adversarial loss: 0.398703\n",
      "epoch 50; iter: 0; batch classifier loss: 0.123527; batch adversarial loss: 0.589628\n",
      "epoch 51; iter: 0; batch classifier loss: 0.143084; batch adversarial loss: 0.464140\n",
      "epoch 52; iter: 0; batch classifier loss: 0.115280; batch adversarial loss: 0.447888\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095148; batch adversarial loss: 0.456881\n",
      "epoch 54; iter: 0; batch classifier loss: 0.067749; batch adversarial loss: 0.424517\n",
      "epoch 55; iter: 0; batch classifier loss: 0.075751; batch adversarial loss: 0.513552\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083894; batch adversarial loss: 0.507557\n",
      "epoch 57; iter: 0; batch classifier loss: 0.071542; batch adversarial loss: 0.405423\n",
      "epoch 58; iter: 0; batch classifier loss: 0.140200; batch adversarial loss: 0.464599\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087557; batch adversarial loss: 0.480178\n",
      "epoch 60; iter: 0; batch classifier loss: 0.119927; batch adversarial loss: 0.461970\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099996; batch adversarial loss: 0.461294\n",
      "epoch 62; iter: 0; batch classifier loss: 0.048973; batch adversarial loss: 0.396230\n",
      "epoch 63; iter: 0; batch classifier loss: 0.111123; batch adversarial loss: 0.383684\n",
      "epoch 64; iter: 0; batch classifier loss: 0.096306; batch adversarial loss: 0.437010\n",
      "epoch 65; iter: 0; batch classifier loss: 0.081572; batch adversarial loss: 0.493645\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068482; batch adversarial loss: 0.361325\n",
      "epoch 67; iter: 0; batch classifier loss: 0.050149; batch adversarial loss: 0.427893\n",
      "epoch 68; iter: 0; batch classifier loss: 0.067887; batch adversarial loss: 0.457323\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070694; batch adversarial loss: 0.537175\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086479; batch adversarial loss: 0.486200\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058460; batch adversarial loss: 0.395207\n",
      "epoch 72; iter: 0; batch classifier loss: 0.118543; batch adversarial loss: 0.516032\n",
      "epoch 73; iter: 0; batch classifier loss: 0.097903; batch adversarial loss: 0.396689\n",
      "epoch 74; iter: 0; batch classifier loss: 0.095381; batch adversarial loss: 0.391773\n",
      "epoch 75; iter: 0; batch classifier loss: 0.048039; batch adversarial loss: 0.471296\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069529; batch adversarial loss: 0.358603\n",
      "epoch 77; iter: 0; batch classifier loss: 0.046571; batch adversarial loss: 0.471191\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073007; batch adversarial loss: 0.467323\n",
      "epoch 79; iter: 0; batch classifier loss: 0.078051; batch adversarial loss: 0.404657\n",
      "epoch 80; iter: 0; batch classifier loss: 0.108456; batch adversarial loss: 0.492330\n",
      "epoch 81; iter: 0; batch classifier loss: 0.126315; batch adversarial loss: 0.530906\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052752; batch adversarial loss: 0.472787\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062115; batch adversarial loss: 0.381539\n",
      "epoch 84; iter: 0; batch classifier loss: 0.110283; batch adversarial loss: 0.487266\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058817; batch adversarial loss: 0.383687\n",
      "epoch 86; iter: 0; batch classifier loss: 0.085365; batch adversarial loss: 0.394967\n",
      "epoch 87; iter: 0; batch classifier loss: 0.063119; batch adversarial loss: 0.444710\n",
      "epoch 88; iter: 0; batch classifier loss: 0.030278; batch adversarial loss: 0.406928\n",
      "epoch 89; iter: 0; batch classifier loss: 0.117879; batch adversarial loss: 0.408444\n",
      "epoch 90; iter: 0; batch classifier loss: 0.147357; batch adversarial loss: 0.477883\n",
      "epoch 91; iter: 0; batch classifier loss: 0.094909; batch adversarial loss: 0.461813\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041725; batch adversarial loss: 0.455389\n",
      "epoch 93; iter: 0; batch classifier loss: 0.057200; batch adversarial loss: 0.645469\n",
      "epoch 94; iter: 0; batch classifier loss: 0.060194; batch adversarial loss: 0.586762\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053271; batch adversarial loss: 0.421518\n",
      "epoch 96; iter: 0; batch classifier loss: 0.069009; batch adversarial loss: 0.469043\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053943; batch adversarial loss: 0.486302\n",
      "epoch 98; iter: 0; batch classifier loss: 0.043059; batch adversarial loss: 0.447818\n",
      "epoch 99; iter: 0; batch classifier loss: 0.031324; batch adversarial loss: 0.456735\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051197; batch adversarial loss: 0.443871\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063893; batch adversarial loss: 0.395671\n",
      "epoch 102; iter: 0; batch classifier loss: 0.073800; batch adversarial loss: 0.454106\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055260; batch adversarial loss: 0.457616\n",
      "epoch 104; iter: 0; batch classifier loss: 0.028921; batch adversarial loss: 0.483601\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046605; batch adversarial loss: 0.457253\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055192; batch adversarial loss: 0.396786\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031151; batch adversarial loss: 0.454584\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051709; batch adversarial loss: 0.422558\n",
      "epoch 109; iter: 0; batch classifier loss: 0.052587; batch adversarial loss: 0.504195\n",
      "epoch 110; iter: 0; batch classifier loss: 0.074067; batch adversarial loss: 0.465191\n",
      "epoch 111; iter: 0; batch classifier loss: 0.099123; batch adversarial loss: 0.448401\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039803; batch adversarial loss: 0.419513\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052009; batch adversarial loss: 0.484247\n",
      "epoch 114; iter: 0; batch classifier loss: 0.019181; batch adversarial loss: 0.498580\n",
      "epoch 115; iter: 0; batch classifier loss: 0.055566; batch adversarial loss: 0.450646\n",
      "epoch 116; iter: 0; batch classifier loss: 0.049385; batch adversarial loss: 0.454578\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051377; batch adversarial loss: 0.502175\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029286; batch adversarial loss: 0.449860\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031176; batch adversarial loss: 0.400490\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046540; batch adversarial loss: 0.524716\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039721; batch adversarial loss: 0.510959\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066594; batch adversarial loss: 0.454153\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041525; batch adversarial loss: 0.536779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.037270; batch adversarial loss: 0.429136\n",
      "epoch 125; iter: 0; batch classifier loss: 0.080248; batch adversarial loss: 0.396165\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019907; batch adversarial loss: 0.482876\n",
      "epoch 127; iter: 0; batch classifier loss: 0.064670; batch adversarial loss: 0.415084\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051691; batch adversarial loss: 0.362957\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038407; batch adversarial loss: 0.364971\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047503; batch adversarial loss: 0.414564\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028361; batch adversarial loss: 0.473859\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027327; batch adversarial loss: 0.438241\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040861; batch adversarial loss: 0.428929\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033799; batch adversarial loss: 0.495459\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032567; batch adversarial loss: 0.480010\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031620; batch adversarial loss: 0.550752\n",
      "epoch 137; iter: 0; batch classifier loss: 0.007875; batch adversarial loss: 0.414035\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036104; batch adversarial loss: 0.400397\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041923; batch adversarial loss: 0.440841\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025743; batch adversarial loss: 0.469328\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026529; batch adversarial loss: 0.431819\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034030; batch adversarial loss: 0.532768\n",
      "epoch 143; iter: 0; batch classifier loss: 0.049897; batch adversarial loss: 0.492144\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029450; batch adversarial loss: 0.474288\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027085; batch adversarial loss: 0.454834\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051719; batch adversarial loss: 0.474642\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030878; batch adversarial loss: 0.560587\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036395; batch adversarial loss: 0.471643\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027891; batch adversarial loss: 0.384298\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017738; batch adversarial loss: 0.497510\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011590; batch adversarial loss: 0.437399\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040277; batch adversarial loss: 0.454626\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018566; batch adversarial loss: 0.485373\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030331; batch adversarial loss: 0.396113\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016390; batch adversarial loss: 0.454325\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012011; batch adversarial loss: 0.432497\n",
      "epoch 157; iter: 0; batch classifier loss: 0.060229; batch adversarial loss: 0.482827\n",
      "epoch 158; iter: 0; batch classifier loss: 0.050292; batch adversarial loss: 0.399343\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020343; batch adversarial loss: 0.492267\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020269; batch adversarial loss: 0.399858\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017548; batch adversarial loss: 0.496125\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017715; batch adversarial loss: 0.445433\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026467; batch adversarial loss: 0.542511\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038503; batch adversarial loss: 0.429423\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019307; batch adversarial loss: 0.468638\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028759; batch adversarial loss: 0.453054\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027202; batch adversarial loss: 0.388545\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022738; batch adversarial loss: 0.372801\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013945; batch adversarial loss: 0.478417\n",
      "epoch 170; iter: 0; batch classifier loss: 0.058793; batch adversarial loss: 0.420497\n",
      "epoch 171; iter: 0; batch classifier loss: 0.006623; batch adversarial loss: 0.374236\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017308; batch adversarial loss: 0.476131\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011699; batch adversarial loss: 0.383739\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024125; batch adversarial loss: 0.470596\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022649; batch adversarial loss: 0.475486\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020011; batch adversarial loss: 0.349490\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025567; batch adversarial loss: 0.404949\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023413; batch adversarial loss: 0.470318\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009516; batch adversarial loss: 0.436954\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031961; batch adversarial loss: 0.449319\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006200; batch adversarial loss: 0.438050\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017701; batch adversarial loss: 0.432542\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018295; batch adversarial loss: 0.456284\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013074; batch adversarial loss: 0.385876\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017569; batch adversarial loss: 0.464627\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019736; batch adversarial loss: 0.403492\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012622; batch adversarial loss: 0.535144\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027027; batch adversarial loss: 0.472006\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023986; batch adversarial loss: 0.505335\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012648; batch adversarial loss: 0.492026\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029765; batch adversarial loss: 0.541953\n",
      "epoch 192; iter: 0; batch classifier loss: 0.058700; batch adversarial loss: 0.443560\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007350; batch adversarial loss: 0.364043\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007753; batch adversarial loss: 0.534720\n",
      "epoch 195; iter: 0; batch classifier loss: 0.062933; batch adversarial loss: 0.534741\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015511; batch adversarial loss: 0.469950\n",
      "epoch 197; iter: 0; batch classifier loss: 0.038747; batch adversarial loss: 0.370908\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009327; batch adversarial loss: 0.527117\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016565; batch adversarial loss: 0.541688\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714777; batch adversarial loss: 0.717976\n",
      "epoch 1; iter: 0; batch classifier loss: 0.459082; batch adversarial loss: 0.647931\n",
      "epoch 2; iter: 0; batch classifier loss: 0.356720; batch adversarial loss: 0.617270\n",
      "epoch 3; iter: 0; batch classifier loss: 0.341115; batch adversarial loss: 0.608025\n",
      "epoch 4; iter: 0; batch classifier loss: 0.378689; batch adversarial loss: 0.567190\n",
      "epoch 5; iter: 0; batch classifier loss: 0.288421; batch adversarial loss: 0.571480\n",
      "epoch 6; iter: 0; batch classifier loss: 0.321450; batch adversarial loss: 0.542478\n",
      "epoch 7; iter: 0; batch classifier loss: 0.385657; batch adversarial loss: 0.556909\n",
      "epoch 8; iter: 0; batch classifier loss: 0.261786; batch adversarial loss: 0.546761\n",
      "epoch 9; iter: 0; batch classifier loss: 0.306336; batch adversarial loss: 0.513487\n",
      "epoch 10; iter: 0; batch classifier loss: 0.209038; batch adversarial loss: 0.559365\n",
      "epoch 11; iter: 0; batch classifier loss: 0.238619; batch adversarial loss: 0.470439\n",
      "epoch 12; iter: 0; batch classifier loss: 0.266718; batch adversarial loss: 0.496335\n",
      "epoch 13; iter: 0; batch classifier loss: 0.282224; batch adversarial loss: 0.533917\n",
      "epoch 14; iter: 0; batch classifier loss: 0.275599; batch adversarial loss: 0.482873\n",
      "epoch 15; iter: 0; batch classifier loss: 0.292112; batch adversarial loss: 0.512322\n",
      "epoch 16; iter: 0; batch classifier loss: 0.320138; batch adversarial loss: 0.481773\n",
      "epoch 17; iter: 0; batch classifier loss: 0.356706; batch adversarial loss: 0.511073\n",
      "epoch 18; iter: 0; batch classifier loss: 0.258933; batch adversarial loss: 0.514128\n",
      "epoch 19; iter: 0; batch classifier loss: 0.270774; batch adversarial loss: 0.499331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.216644; batch adversarial loss: 0.560127\n",
      "epoch 21; iter: 0; batch classifier loss: 0.191116; batch adversarial loss: 0.486015\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224146; batch adversarial loss: 0.453221\n",
      "epoch 23; iter: 0; batch classifier loss: 0.303401; batch adversarial loss: 0.497244\n",
      "epoch 24; iter: 0; batch classifier loss: 0.196462; batch adversarial loss: 0.431819\n",
      "epoch 25; iter: 0; batch classifier loss: 0.122218; batch adversarial loss: 0.551196\n",
      "epoch 26; iter: 0; batch classifier loss: 0.164947; batch adversarial loss: 0.452205\n",
      "epoch 27; iter: 0; batch classifier loss: 0.250701; batch adversarial loss: 0.480407\n",
      "epoch 28; iter: 0; batch classifier loss: 0.197030; batch adversarial loss: 0.342174\n",
      "epoch 29; iter: 0; batch classifier loss: 0.181101; batch adversarial loss: 0.506903\n",
      "epoch 30; iter: 0; batch classifier loss: 0.149486; batch adversarial loss: 0.427554\n",
      "epoch 31; iter: 0; batch classifier loss: 0.219953; batch adversarial loss: 0.375797\n",
      "epoch 32; iter: 0; batch classifier loss: 0.242252; batch adversarial loss: 0.476723\n",
      "epoch 33; iter: 0; batch classifier loss: 0.223793; batch adversarial loss: 0.389086\n",
      "epoch 34; iter: 0; batch classifier loss: 0.158743; batch adversarial loss: 0.487895\n",
      "epoch 35; iter: 0; batch classifier loss: 0.181635; batch adversarial loss: 0.444716\n",
      "epoch 36; iter: 0; batch classifier loss: 0.206535; batch adversarial loss: 0.453942\n",
      "epoch 37; iter: 0; batch classifier loss: 0.163821; batch adversarial loss: 0.449372\n",
      "epoch 38; iter: 0; batch classifier loss: 0.227584; batch adversarial loss: 0.455715\n",
      "epoch 39; iter: 0; batch classifier loss: 0.183494; batch adversarial loss: 0.473812\n",
      "epoch 40; iter: 0; batch classifier loss: 0.148589; batch adversarial loss: 0.442896\n",
      "epoch 41; iter: 0; batch classifier loss: 0.168314; batch adversarial loss: 0.421854\n",
      "epoch 42; iter: 0; batch classifier loss: 0.205179; batch adversarial loss: 0.530578\n",
      "epoch 43; iter: 0; batch classifier loss: 0.167944; batch adversarial loss: 0.390396\n",
      "epoch 44; iter: 0; batch classifier loss: 0.187359; batch adversarial loss: 0.423699\n",
      "epoch 45; iter: 0; batch classifier loss: 0.190189; batch adversarial loss: 0.613391\n",
      "epoch 46; iter: 0; batch classifier loss: 0.241344; batch adversarial loss: 0.445727\n",
      "epoch 47; iter: 0; batch classifier loss: 0.192727; batch adversarial loss: 0.462049\n",
      "epoch 48; iter: 0; batch classifier loss: 0.245251; batch adversarial loss: 0.484885\n",
      "epoch 49; iter: 0; batch classifier loss: 0.248645; batch adversarial loss: 0.461370\n",
      "epoch 50; iter: 0; batch classifier loss: 0.116078; batch adversarial loss: 0.499864\n",
      "epoch 51; iter: 0; batch classifier loss: 0.265693; batch adversarial loss: 0.471621\n",
      "epoch 52; iter: 0; batch classifier loss: 0.283295; batch adversarial loss: 0.367482\n",
      "epoch 53; iter: 0; batch classifier loss: 0.206726; batch adversarial loss: 0.506050\n",
      "epoch 54; iter: 0; batch classifier loss: 0.211744; batch adversarial loss: 0.403990\n",
      "epoch 55; iter: 0; batch classifier loss: 0.162745; batch adversarial loss: 0.505747\n",
      "epoch 56; iter: 0; batch classifier loss: 0.152953; batch adversarial loss: 0.552233\n",
      "epoch 57; iter: 0; batch classifier loss: 0.224375; batch adversarial loss: 0.452173\n",
      "epoch 58; iter: 0; batch classifier loss: 0.221132; batch adversarial loss: 0.399815\n",
      "epoch 59; iter: 0; batch classifier loss: 0.187957; batch adversarial loss: 0.414173\n",
      "epoch 60; iter: 0; batch classifier loss: 0.117982; batch adversarial loss: 0.481886\n",
      "epoch 61; iter: 0; batch classifier loss: 0.186063; batch adversarial loss: 0.401536\n",
      "epoch 62; iter: 0; batch classifier loss: 0.216310; batch adversarial loss: 0.459717\n",
      "epoch 63; iter: 0; batch classifier loss: 0.218038; batch adversarial loss: 0.470653\n",
      "epoch 64; iter: 0; batch classifier loss: 0.183726; batch adversarial loss: 0.483107\n",
      "epoch 65; iter: 0; batch classifier loss: 0.202740; batch adversarial loss: 0.565759\n",
      "epoch 66; iter: 0; batch classifier loss: 0.176659; batch adversarial loss: 0.542713\n",
      "epoch 67; iter: 0; batch classifier loss: 0.169792; batch adversarial loss: 0.542154\n",
      "epoch 68; iter: 0; batch classifier loss: 0.203521; batch adversarial loss: 0.389426\n",
      "epoch 69; iter: 0; batch classifier loss: 0.170158; batch adversarial loss: 0.400656\n",
      "epoch 70; iter: 0; batch classifier loss: 0.191462; batch adversarial loss: 0.482371\n",
      "epoch 71; iter: 0; batch classifier loss: 0.238977; batch adversarial loss: 0.460190\n",
      "epoch 72; iter: 0; batch classifier loss: 0.243942; batch adversarial loss: 0.494531\n",
      "epoch 73; iter: 0; batch classifier loss: 0.189530; batch adversarial loss: 0.518371\n",
      "epoch 74; iter: 0; batch classifier loss: 0.199072; batch adversarial loss: 0.458549\n",
      "epoch 75; iter: 0; batch classifier loss: 0.281954; batch adversarial loss: 0.494949\n",
      "epoch 76; iter: 0; batch classifier loss: 0.157708; batch adversarial loss: 0.542143\n",
      "epoch 77; iter: 0; batch classifier loss: 0.112262; batch adversarial loss: 0.482334\n",
      "epoch 78; iter: 0; batch classifier loss: 0.196573; batch adversarial loss: 0.435380\n",
      "epoch 79; iter: 0; batch classifier loss: 0.231001; batch adversarial loss: 0.483559\n",
      "epoch 80; iter: 0; batch classifier loss: 0.163675; batch adversarial loss: 0.457301\n",
      "epoch 81; iter: 0; batch classifier loss: 0.285014; batch adversarial loss: 0.482207\n",
      "epoch 82; iter: 0; batch classifier loss: 0.165893; batch adversarial loss: 0.470117\n",
      "epoch 83; iter: 0; batch classifier loss: 0.223660; batch adversarial loss: 0.519604\n",
      "epoch 84; iter: 0; batch classifier loss: 0.162199; batch adversarial loss: 0.447707\n",
      "epoch 85; iter: 0; batch classifier loss: 0.155721; batch adversarial loss: 0.435115\n",
      "epoch 86; iter: 0; batch classifier loss: 0.191304; batch adversarial loss: 0.435931\n",
      "epoch 87; iter: 0; batch classifier loss: 0.175462; batch adversarial loss: 0.424435\n",
      "epoch 88; iter: 0; batch classifier loss: 0.156048; batch adversarial loss: 0.412683\n",
      "epoch 89; iter: 0; batch classifier loss: 0.145427; batch adversarial loss: 0.458582\n",
      "epoch 90; iter: 0; batch classifier loss: 0.183893; batch adversarial loss: 0.483264\n",
      "epoch 91; iter: 0; batch classifier loss: 0.232136; batch adversarial loss: 0.505940\n",
      "epoch 92; iter: 0; batch classifier loss: 0.190255; batch adversarial loss: 0.399391\n",
      "epoch 93; iter: 0; batch classifier loss: 0.193080; batch adversarial loss: 0.458947\n",
      "epoch 94; iter: 0; batch classifier loss: 0.149460; batch adversarial loss: 0.494107\n",
      "epoch 95; iter: 0; batch classifier loss: 0.124129; batch adversarial loss: 0.529557\n",
      "epoch 96; iter: 0; batch classifier loss: 0.180420; batch adversarial loss: 0.494364\n",
      "epoch 97; iter: 0; batch classifier loss: 0.199114; batch adversarial loss: 0.435349\n",
      "epoch 98; iter: 0; batch classifier loss: 0.192417; batch adversarial loss: 0.496492\n",
      "epoch 99; iter: 0; batch classifier loss: 0.178127; batch adversarial loss: 0.408097\n",
      "epoch 100; iter: 0; batch classifier loss: 0.181610; batch adversarial loss: 0.470344\n",
      "epoch 101; iter: 0; batch classifier loss: 0.139059; batch adversarial loss: 0.509724\n",
      "epoch 102; iter: 0; batch classifier loss: 0.144187; batch adversarial loss: 0.458652\n",
      "epoch 103; iter: 0; batch classifier loss: 0.096250; batch adversarial loss: 0.542823\n",
      "epoch 104; iter: 0; batch classifier loss: 0.089971; batch adversarial loss: 0.466562\n",
      "epoch 105; iter: 0; batch classifier loss: 0.129115; batch adversarial loss: 0.482852\n",
      "epoch 106; iter: 0; batch classifier loss: 0.093911; batch adversarial loss: 0.444848\n",
      "epoch 107; iter: 0; batch classifier loss: 0.080558; batch adversarial loss: 0.496883\n",
      "epoch 108; iter: 0; batch classifier loss: 0.096265; batch adversarial loss: 0.476970\n",
      "epoch 109; iter: 0; batch classifier loss: 0.092141; batch adversarial loss: 0.432718\n",
      "epoch 110; iter: 0; batch classifier loss: 0.089702; batch adversarial loss: 0.407174\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059501; batch adversarial loss: 0.481134\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041051; batch adversarial loss: 0.452039\n",
      "epoch 113; iter: 0; batch classifier loss: 0.092635; batch adversarial loss: 0.525758\n",
      "epoch 114; iter: 0; batch classifier loss: 0.073699; batch adversarial loss: 0.402632\n",
      "epoch 115; iter: 0; batch classifier loss: 0.081255; batch adversarial loss: 0.490242\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042897; batch adversarial loss: 0.444871\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040115; batch adversarial loss: 0.368623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.036023; batch adversarial loss: 0.567539\n",
      "epoch 119; iter: 0; batch classifier loss: 0.066169; batch adversarial loss: 0.417978\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053015; batch adversarial loss: 0.353125\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054335; batch adversarial loss: 0.435335\n",
      "epoch 122; iter: 0; batch classifier loss: 0.047388; batch adversarial loss: 0.440495\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049001; batch adversarial loss: 0.454353\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051733; batch adversarial loss: 0.520400\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029344; batch adversarial loss: 0.405550\n",
      "epoch 126; iter: 0; batch classifier loss: 0.060448; batch adversarial loss: 0.417174\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030055; batch adversarial loss: 0.502474\n",
      "epoch 128; iter: 0; batch classifier loss: 0.020944; batch adversarial loss: 0.515447\n",
      "epoch 129; iter: 0; batch classifier loss: 0.076632; batch adversarial loss: 0.470957\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029541; batch adversarial loss: 0.479264\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038772; batch adversarial loss: 0.555417\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033243; batch adversarial loss: 0.391312\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025589; batch adversarial loss: 0.305323\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035000; batch adversarial loss: 0.503308\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036996; batch adversarial loss: 0.532632\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032753; batch adversarial loss: 0.453777\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040293; batch adversarial loss: 0.459966\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032802; batch adversarial loss: 0.516769\n",
      "epoch 139; iter: 0; batch classifier loss: 0.053607; batch adversarial loss: 0.396223\n",
      "epoch 140; iter: 0; batch classifier loss: 0.043222; batch adversarial loss: 0.495071\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022268; batch adversarial loss: 0.468948\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040714; batch adversarial loss: 0.486464\n",
      "epoch 143; iter: 0; batch classifier loss: 0.082893; batch adversarial loss: 0.506317\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016957; batch adversarial loss: 0.460376\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035906; batch adversarial loss: 0.475273\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022129; batch adversarial loss: 0.570553\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037895; batch adversarial loss: 0.347850\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017768; batch adversarial loss: 0.422265\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026986; batch adversarial loss: 0.534995\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035340; batch adversarial loss: 0.478392\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017622; batch adversarial loss: 0.434645\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042286; batch adversarial loss: 0.485665\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023234; batch adversarial loss: 0.462283\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020703; batch adversarial loss: 0.383520\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052273; batch adversarial loss: 0.477051\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014744; batch adversarial loss: 0.496652\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039801; batch adversarial loss: 0.421094\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015485; batch adversarial loss: 0.542538\n",
      "epoch 159; iter: 0; batch classifier loss: 0.051562; batch adversarial loss: 0.353468\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034841; batch adversarial loss: 0.473559\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031444; batch adversarial loss: 0.512845\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046324; batch adversarial loss: 0.379686\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024291; batch adversarial loss: 0.475412\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025317; batch adversarial loss: 0.495765\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031235; batch adversarial loss: 0.478619\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027308; batch adversarial loss: 0.488224\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013555; batch adversarial loss: 0.406216\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013021; batch adversarial loss: 0.537474\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035379; batch adversarial loss: 0.462814\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035085; batch adversarial loss: 0.495565\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029782; batch adversarial loss: 0.399699\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021049; batch adversarial loss: 0.448369\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013247; batch adversarial loss: 0.462570\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019089; batch adversarial loss: 0.482464\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024805; batch adversarial loss: 0.404796\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031478; batch adversarial loss: 0.471745\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015778; batch adversarial loss: 0.514404\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027014; batch adversarial loss: 0.403135\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025740; batch adversarial loss: 0.430998\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041300; batch adversarial loss: 0.464615\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033215; batch adversarial loss: 0.465825\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032159; batch adversarial loss: 0.433882\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034331; batch adversarial loss: 0.475103\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029200; batch adversarial loss: 0.403397\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024449; batch adversarial loss: 0.453052\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009089; batch adversarial loss: 0.414393\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024242; batch adversarial loss: 0.422666\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012416; batch adversarial loss: 0.505214\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022551; batch adversarial loss: 0.467322\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018074; batch adversarial loss: 0.406053\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020875; batch adversarial loss: 0.451522\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040686; batch adversarial loss: 0.574600\n",
      "epoch 193; iter: 0; batch classifier loss: 0.044789; batch adversarial loss: 0.550529\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020846; batch adversarial loss: 0.466014\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021031; batch adversarial loss: 0.469808\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014739; batch adversarial loss: 0.411948\n",
      "epoch 197; iter: 0; batch classifier loss: 0.043525; batch adversarial loss: 0.405164\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013533; batch adversarial loss: 0.500981\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019318; batch adversarial loss: 0.420095\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671023; batch adversarial loss: 0.947087\n",
      "epoch 1; iter: 0; batch classifier loss: 0.703587; batch adversarial loss: 1.162520\n",
      "epoch 2; iter: 0; batch classifier loss: 0.985425; batch adversarial loss: 1.237846\n",
      "epoch 3; iter: 0; batch classifier loss: 1.104741; batch adversarial loss: 1.136376\n",
      "epoch 4; iter: 0; batch classifier loss: 1.014244; batch adversarial loss: 0.998801\n",
      "epoch 5; iter: 0; batch classifier loss: 1.066184; batch adversarial loss: 0.906345\n",
      "epoch 6; iter: 0; batch classifier loss: 1.128314; batch adversarial loss: 0.846731\n",
      "epoch 7; iter: 0; batch classifier loss: 1.448608; batch adversarial loss: 0.813657\n",
      "epoch 8; iter: 0; batch classifier loss: 1.046715; batch adversarial loss: 0.723232\n",
      "epoch 9; iter: 0; batch classifier loss: 0.939270; batch adversarial loss: 0.668475\n",
      "epoch 10; iter: 0; batch classifier loss: 0.768973; batch adversarial loss: 0.621516\n",
      "epoch 11; iter: 0; batch classifier loss: 0.611961; batch adversarial loss: 0.594198\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550819; batch adversarial loss: 0.558659\n",
      "epoch 13; iter: 0; batch classifier loss: 0.412745; batch adversarial loss: 0.515826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.344750; batch adversarial loss: 0.494826\n",
      "epoch 15; iter: 0; batch classifier loss: 0.285561; batch adversarial loss: 0.493770\n",
      "epoch 16; iter: 0; batch classifier loss: 0.291075; batch adversarial loss: 0.529419\n",
      "epoch 17; iter: 0; batch classifier loss: 0.268254; batch adversarial loss: 0.529666\n",
      "epoch 18; iter: 0; batch classifier loss: 0.277376; batch adversarial loss: 0.544940\n",
      "epoch 19; iter: 0; batch classifier loss: 0.199372; batch adversarial loss: 0.462660\n",
      "epoch 20; iter: 0; batch classifier loss: 0.255642; batch adversarial loss: 0.480027\n",
      "epoch 21; iter: 0; batch classifier loss: 0.222748; batch adversarial loss: 0.479676\n",
      "epoch 22; iter: 0; batch classifier loss: 0.217069; batch adversarial loss: 0.527090\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203902; batch adversarial loss: 0.405727\n",
      "epoch 24; iter: 0; batch classifier loss: 0.185355; batch adversarial loss: 0.479796\n",
      "epoch 25; iter: 0; batch classifier loss: 0.203088; batch adversarial loss: 0.400964\n",
      "epoch 26; iter: 0; batch classifier loss: 0.276917; batch adversarial loss: 0.507513\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151316; batch adversarial loss: 0.501003\n",
      "epoch 28; iter: 0; batch classifier loss: 0.175139; batch adversarial loss: 0.473123\n",
      "epoch 29; iter: 0; batch classifier loss: 0.237011; batch adversarial loss: 0.475450\n",
      "epoch 30; iter: 0; batch classifier loss: 0.214093; batch adversarial loss: 0.404387\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170263; batch adversarial loss: 0.460589\n",
      "epoch 32; iter: 0; batch classifier loss: 0.278061; batch adversarial loss: 0.405523\n",
      "epoch 33; iter: 0; batch classifier loss: 0.238936; batch adversarial loss: 0.441472\n",
      "epoch 34; iter: 0; batch classifier loss: 0.155955; batch adversarial loss: 0.471284\n",
      "epoch 35; iter: 0; batch classifier loss: 0.150916; batch adversarial loss: 0.463880\n",
      "epoch 36; iter: 0; batch classifier loss: 0.218010; batch adversarial loss: 0.438719\n",
      "epoch 37; iter: 0; batch classifier loss: 0.177795; batch adversarial loss: 0.503001\n",
      "epoch 38; iter: 0; batch classifier loss: 0.149686; batch adversarial loss: 0.455346\n",
      "epoch 39; iter: 0; batch classifier loss: 0.208010; batch adversarial loss: 0.447838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.187126; batch adversarial loss: 0.425979\n",
      "epoch 41; iter: 0; batch classifier loss: 0.220577; batch adversarial loss: 0.485078\n",
      "epoch 42; iter: 0; batch classifier loss: 0.177646; batch adversarial loss: 0.463654\n",
      "epoch 43; iter: 0; batch classifier loss: 0.161946; batch adversarial loss: 0.480188\n",
      "epoch 44; iter: 0; batch classifier loss: 0.161879; batch adversarial loss: 0.502672\n",
      "epoch 45; iter: 0; batch classifier loss: 0.167445; batch adversarial loss: 0.466493\n",
      "epoch 46; iter: 0; batch classifier loss: 0.190520; batch adversarial loss: 0.490126\n",
      "epoch 47; iter: 0; batch classifier loss: 0.156470; batch adversarial loss: 0.463381\n",
      "epoch 48; iter: 0; batch classifier loss: 0.207644; batch adversarial loss: 0.419088\n",
      "epoch 49; iter: 0; batch classifier loss: 0.130551; batch adversarial loss: 0.474988\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129985; batch adversarial loss: 0.468634\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100194; batch adversarial loss: 0.530584\n",
      "epoch 52; iter: 0; batch classifier loss: 0.119433; batch adversarial loss: 0.456216\n",
      "epoch 53; iter: 0; batch classifier loss: 0.134409; batch adversarial loss: 0.513794\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114666; batch adversarial loss: 0.442029\n",
      "epoch 55; iter: 0; batch classifier loss: 0.133123; batch adversarial loss: 0.469634\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095146; batch adversarial loss: 0.470384\n",
      "epoch 57; iter: 0; batch classifier loss: 0.178692; batch adversarial loss: 0.487680\n",
      "epoch 58; iter: 0; batch classifier loss: 0.179709; batch adversarial loss: 0.465030\n",
      "epoch 59; iter: 0; batch classifier loss: 0.168571; batch adversarial loss: 0.432383\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101360; batch adversarial loss: 0.579821\n",
      "epoch 61; iter: 0; batch classifier loss: 0.127679; batch adversarial loss: 0.456818\n",
      "epoch 62; iter: 0; batch classifier loss: 0.174671; batch adversarial loss: 0.390865\n",
      "epoch 63; iter: 0; batch classifier loss: 0.134846; batch adversarial loss: 0.435663\n",
      "epoch 64; iter: 0; batch classifier loss: 0.118555; batch adversarial loss: 0.542482\n",
      "epoch 65; iter: 0; batch classifier loss: 0.171795; batch adversarial loss: 0.479526\n",
      "epoch 66; iter: 0; batch classifier loss: 0.197432; batch adversarial loss: 0.439319\n",
      "epoch 67; iter: 0; batch classifier loss: 0.120620; batch adversarial loss: 0.433431\n",
      "epoch 68; iter: 0; batch classifier loss: 0.156959; batch adversarial loss: 0.448281\n",
      "epoch 69; iter: 0; batch classifier loss: 0.121334; batch adversarial loss: 0.449327\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144246; batch adversarial loss: 0.507192\n",
      "epoch 71; iter: 0; batch classifier loss: 0.105690; batch adversarial loss: 0.443009\n",
      "epoch 72; iter: 0; batch classifier loss: 0.104207; batch adversarial loss: 0.457232\n",
      "epoch 73; iter: 0; batch classifier loss: 0.107478; batch adversarial loss: 0.312643\n",
      "epoch 74; iter: 0; batch classifier loss: 0.138699; batch adversarial loss: 0.431537\n",
      "epoch 75; iter: 0; batch classifier loss: 0.155429; batch adversarial loss: 0.335637\n",
      "epoch 76; iter: 0; batch classifier loss: 0.138376; batch adversarial loss: 0.467522\n",
      "epoch 77; iter: 0; batch classifier loss: 0.120079; batch adversarial loss: 0.490806\n",
      "epoch 78; iter: 0; batch classifier loss: 0.091289; batch adversarial loss: 0.424595\n",
      "epoch 79; iter: 0; batch classifier loss: 0.123730; batch adversarial loss: 0.363209\n",
      "epoch 80; iter: 0; batch classifier loss: 0.129939; batch adversarial loss: 0.346708\n",
      "epoch 81; iter: 0; batch classifier loss: 0.139682; batch adversarial loss: 0.476375\n",
      "epoch 82; iter: 0; batch classifier loss: 0.115448; batch adversarial loss: 0.386093\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078322; batch adversarial loss: 0.518875\n",
      "epoch 84; iter: 0; batch classifier loss: 0.104291; batch adversarial loss: 0.498373\n",
      "epoch 85; iter: 0; batch classifier loss: 0.132217; batch adversarial loss: 0.447106\n",
      "epoch 86; iter: 0; batch classifier loss: 0.105641; batch adversarial loss: 0.566216\n",
      "epoch 87; iter: 0; batch classifier loss: 0.124754; batch adversarial loss: 0.443365\n",
      "epoch 88; iter: 0; batch classifier loss: 0.117323; batch adversarial loss: 0.425374\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074088; batch adversarial loss: 0.500241\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075042; batch adversarial loss: 0.497709\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067232; batch adversarial loss: 0.427712\n",
      "epoch 92; iter: 0; batch classifier loss: 0.073104; batch adversarial loss: 0.433005\n",
      "epoch 93; iter: 0; batch classifier loss: 0.101910; batch adversarial loss: 0.427876\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058144; batch adversarial loss: 0.452817\n",
      "epoch 95; iter: 0; batch classifier loss: 0.114437; batch adversarial loss: 0.409793\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075050; batch adversarial loss: 0.377462\n",
      "epoch 97; iter: 0; batch classifier loss: 0.119859; batch adversarial loss: 0.409240\n",
      "epoch 98; iter: 0; batch classifier loss: 0.086364; batch adversarial loss: 0.426975\n",
      "epoch 99; iter: 0; batch classifier loss: 0.123669; batch adversarial loss: 0.519837\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044863; batch adversarial loss: 0.527488\n",
      "epoch 101; iter: 0; batch classifier loss: 0.139545; batch adversarial loss: 0.522813\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060063; batch adversarial loss: 0.478040\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054369; batch adversarial loss: 0.520988\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046775; batch adversarial loss: 0.472033\n",
      "epoch 105; iter: 0; batch classifier loss: 0.073481; batch adversarial loss: 0.491325\n",
      "epoch 106; iter: 0; batch classifier loss: 0.065768; batch adversarial loss: 0.420980\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049880; batch adversarial loss: 0.457718\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073586; batch adversarial loss: 0.504675\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050484; batch adversarial loss: 0.425076\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033868; batch adversarial loss: 0.479261\n",
      "epoch 111; iter: 0; batch classifier loss: 0.072689; batch adversarial loss: 0.367829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.043818; batch adversarial loss: 0.420777\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028668; batch adversarial loss: 0.456124\n",
      "epoch 114; iter: 0; batch classifier loss: 0.063715; batch adversarial loss: 0.417878\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022314; batch adversarial loss: 0.539288\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034780; batch adversarial loss: 0.437991\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034048; batch adversarial loss: 0.383282\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050506; batch adversarial loss: 0.468474\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059064; batch adversarial loss: 0.601525\n",
      "epoch 120; iter: 0; batch classifier loss: 0.056393; batch adversarial loss: 0.434523\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052570; batch adversarial loss: 0.467548\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043428; batch adversarial loss: 0.475983\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028609; batch adversarial loss: 0.467316\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048314; batch adversarial loss: 0.448768\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046795; batch adversarial loss: 0.353872\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042273; batch adversarial loss: 0.445221\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046261; batch adversarial loss: 0.471411\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016678; batch adversarial loss: 0.449047\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045944; batch adversarial loss: 0.441093\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043303; batch adversarial loss: 0.488936\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038913; batch adversarial loss: 0.323008\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040073; batch adversarial loss: 0.424522\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015480; batch adversarial loss: 0.444465\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027270; batch adversarial loss: 0.427853\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028308; batch adversarial loss: 0.415394\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019704; batch adversarial loss: 0.475674\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039850; batch adversarial loss: 0.456413\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025902; batch adversarial loss: 0.474602\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036754; batch adversarial loss: 0.495855\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029237; batch adversarial loss: 0.578173\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021672; batch adversarial loss: 0.448527\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031178; batch adversarial loss: 0.447556\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034144; batch adversarial loss: 0.432239\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038892; batch adversarial loss: 0.432094\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030953; batch adversarial loss: 0.428134\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024229; batch adversarial loss: 0.361189\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010971; batch adversarial loss: 0.437110\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018324; batch adversarial loss: 0.522788\n",
      "epoch 149; iter: 0; batch classifier loss: 0.007327; batch adversarial loss: 0.429162\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013752; batch adversarial loss: 0.507366\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040143; batch adversarial loss: 0.524066\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022842; batch adversarial loss: 0.559108\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012495; batch adversarial loss: 0.384039\n",
      "epoch 154; iter: 0; batch classifier loss: 0.007507; batch adversarial loss: 0.366721\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036810; batch adversarial loss: 0.409780\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026647; batch adversarial loss: 0.467397\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030255; batch adversarial loss: 0.446813\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014484; batch adversarial loss: 0.392575\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026508; batch adversarial loss: 0.411480\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010955; batch adversarial loss: 0.390568\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010003; batch adversarial loss: 0.463090\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012690; batch adversarial loss: 0.512293\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011635; batch adversarial loss: 0.587919\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037440; batch adversarial loss: 0.315030\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026074; batch adversarial loss: 0.477941\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018891; batch adversarial loss: 0.418856\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011378; batch adversarial loss: 0.395244\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010217; batch adversarial loss: 0.461583\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013883; batch adversarial loss: 0.507027\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021098; batch adversarial loss: 0.510635\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015400; batch adversarial loss: 0.540473\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019068; batch adversarial loss: 0.440459\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024375; batch adversarial loss: 0.367449\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008408; batch adversarial loss: 0.543708\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027820; batch adversarial loss: 0.509048\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039095; batch adversarial loss: 0.539854\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023033; batch adversarial loss: 0.506330\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012020; batch adversarial loss: 0.420047\n",
      "epoch 179; iter: 0; batch classifier loss: 0.004351; batch adversarial loss: 0.463015\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012572; batch adversarial loss: 0.457231\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013445; batch adversarial loss: 0.418038\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008728; batch adversarial loss: 0.528521\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012014; batch adversarial loss: 0.408143\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013829; batch adversarial loss: 0.465700\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040757; batch adversarial loss: 0.379138\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017725; batch adversarial loss: 0.537052\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006200; batch adversarial loss: 0.490708\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008453; batch adversarial loss: 0.367939\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018340; batch adversarial loss: 0.388597\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008110; batch adversarial loss: 0.409560\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015361; batch adversarial loss: 0.390954\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013345; batch adversarial loss: 0.338604\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021829; batch adversarial loss: 0.452318\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024744; batch adversarial loss: 0.497114\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021813; batch adversarial loss: 0.454412\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010937; batch adversarial loss: 0.542625\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008697; batch adversarial loss: 0.368252\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023370; batch adversarial loss: 0.502872\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012179; batch adversarial loss: 0.367824\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683359; batch adversarial loss: 0.770242\n",
      "epoch 1; iter: 0; batch classifier loss: 0.544618; batch adversarial loss: 0.740684\n",
      "epoch 2; iter: 0; batch classifier loss: 0.604796; batch adversarial loss: 0.699933\n",
      "epoch 3; iter: 0; batch classifier loss: 0.623401; batch adversarial loss: 0.627613\n",
      "epoch 4; iter: 0; batch classifier loss: 0.401880; batch adversarial loss: 0.594237\n",
      "epoch 5; iter: 0; batch classifier loss: 0.345967; batch adversarial loss: 0.578076\n",
      "epoch 6; iter: 0; batch classifier loss: 0.376826; batch adversarial loss: 0.548631\n",
      "epoch 7; iter: 0; batch classifier loss: 0.343712; batch adversarial loss: 0.553646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.373713; batch adversarial loss: 0.534607\n",
      "epoch 9; iter: 0; batch classifier loss: 0.336476; batch adversarial loss: 0.562148\n",
      "epoch 10; iter: 0; batch classifier loss: 0.381141; batch adversarial loss: 0.531090\n",
      "epoch 11; iter: 0; batch classifier loss: 0.379073; batch adversarial loss: 0.502742\n",
      "epoch 12; iter: 0; batch classifier loss: 0.347731; batch adversarial loss: 0.516325\n",
      "epoch 13; iter: 0; batch classifier loss: 0.286687; batch adversarial loss: 0.530405\n",
      "epoch 14; iter: 0; batch classifier loss: 0.332377; batch adversarial loss: 0.522645\n",
      "epoch 15; iter: 0; batch classifier loss: 0.291173; batch adversarial loss: 0.412179\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281346; batch adversarial loss: 0.513706\n",
      "epoch 17; iter: 0; batch classifier loss: 0.270507; batch adversarial loss: 0.431949\n",
      "epoch 18; iter: 0; batch classifier loss: 0.362005; batch adversarial loss: 0.483804\n",
      "epoch 19; iter: 0; batch classifier loss: 0.294256; batch adversarial loss: 0.488143\n",
      "epoch 20; iter: 0; batch classifier loss: 0.360389; batch adversarial loss: 0.488439\n",
      "epoch 21; iter: 0; batch classifier loss: 0.254339; batch adversarial loss: 0.441725\n",
      "epoch 22; iter: 0; batch classifier loss: 0.315161; batch adversarial loss: 0.439752\n",
      "epoch 23; iter: 0; batch classifier loss: 0.302846; batch adversarial loss: 0.465541\n",
      "epoch 24; iter: 0; batch classifier loss: 0.387916; batch adversarial loss: 0.435704\n",
      "epoch 25; iter: 0; batch classifier loss: 0.290520; batch adversarial loss: 0.498937\n",
      "epoch 26; iter: 0; batch classifier loss: 0.276550; batch adversarial loss: 0.449391\n",
      "epoch 27; iter: 0; batch classifier loss: 0.285254; batch adversarial loss: 0.443997\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212341; batch adversarial loss: 0.470787\n",
      "epoch 29; iter: 0; batch classifier loss: 0.282057; batch adversarial loss: 0.468238\n",
      "epoch 30; iter: 0; batch classifier loss: 0.278012; batch adversarial loss: 0.423489\n",
      "epoch 31; iter: 0; batch classifier loss: 0.195666; batch adversarial loss: 0.553203\n",
      "epoch 32; iter: 0; batch classifier loss: 0.230395; batch adversarial loss: 0.373353\n",
      "epoch 33; iter: 0; batch classifier loss: 0.218711; batch adversarial loss: 0.426827\n",
      "epoch 34; iter: 0; batch classifier loss: 0.217863; batch adversarial loss: 0.377533\n",
      "epoch 35; iter: 0; batch classifier loss: 0.277583; batch adversarial loss: 0.339295\n",
      "epoch 36; iter: 0; batch classifier loss: 0.177213; batch adversarial loss: 0.440650\n",
      "epoch 37; iter: 0; batch classifier loss: 0.233209; batch adversarial loss: 0.416763\n",
      "epoch 38; iter: 0; batch classifier loss: 0.218072; batch adversarial loss: 0.507515\n",
      "epoch 39; iter: 0; batch classifier loss: 0.220666; batch adversarial loss: 0.485991\n",
      "epoch 40; iter: 0; batch classifier loss: 0.204313; batch adversarial loss: 0.501295\n",
      "epoch 41; iter: 0; batch classifier loss: 0.131896; batch adversarial loss: 0.444893\n",
      "epoch 42; iter: 0; batch classifier loss: 0.152077; batch adversarial loss: 0.523281\n",
      "epoch 43; iter: 0; batch classifier loss: 0.224120; batch adversarial loss: 0.409594\n",
      "epoch 44; iter: 0; batch classifier loss: 0.213698; batch adversarial loss: 0.439306\n",
      "epoch 45; iter: 0; batch classifier loss: 0.160228; batch adversarial loss: 0.393426\n",
      "epoch 46; iter: 0; batch classifier loss: 0.239779; batch adversarial loss: 0.454126\n",
      "epoch 47; iter: 0; batch classifier loss: 0.182775; batch adversarial loss: 0.476818\n",
      "epoch 48; iter: 0; batch classifier loss: 0.164881; batch adversarial loss: 0.382340\n",
      "epoch 49; iter: 0; batch classifier loss: 0.181056; batch adversarial loss: 0.489467\n",
      "epoch 50; iter: 0; batch classifier loss: 0.184726; batch adversarial loss: 0.439417\n",
      "epoch 51; iter: 0; batch classifier loss: 0.099472; batch adversarial loss: 0.482654\n",
      "epoch 52; iter: 0; batch classifier loss: 0.182938; batch adversarial loss: 0.465288\n",
      "epoch 53; iter: 0; batch classifier loss: 0.129710; batch adversarial loss: 0.381160\n",
      "epoch 54; iter: 0; batch classifier loss: 0.167896; batch adversarial loss: 0.415483\n",
      "epoch 55; iter: 0; batch classifier loss: 0.144877; batch adversarial loss: 0.393590\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099045; batch adversarial loss: 0.499617\n",
      "epoch 57; iter: 0; batch classifier loss: 0.173599; batch adversarial loss: 0.397125\n",
      "epoch 58; iter: 0; batch classifier loss: 0.133976; batch adversarial loss: 0.482685\n",
      "epoch 59; iter: 0; batch classifier loss: 0.109911; batch adversarial loss: 0.476218\n",
      "epoch 60; iter: 0; batch classifier loss: 0.075338; batch adversarial loss: 0.432386\n",
      "epoch 61; iter: 0; batch classifier loss: 0.112745; batch adversarial loss: 0.419935\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082367; batch adversarial loss: 0.467372\n",
      "epoch 63; iter: 0; batch classifier loss: 0.094929; batch adversarial loss: 0.563553\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106097; batch adversarial loss: 0.376663\n",
      "epoch 65; iter: 0; batch classifier loss: 0.101034; batch adversarial loss: 0.502208\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089933; batch adversarial loss: 0.417017\n",
      "epoch 67; iter: 0; batch classifier loss: 0.118908; batch adversarial loss: 0.377366\n",
      "epoch 68; iter: 0; batch classifier loss: 0.095774; batch adversarial loss: 0.404965\n",
      "epoch 69; iter: 0; batch classifier loss: 0.093789; batch adversarial loss: 0.490558\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090074; batch adversarial loss: 0.425404\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078768; batch adversarial loss: 0.423704\n",
      "epoch 72; iter: 0; batch classifier loss: 0.132050; batch adversarial loss: 0.428174\n",
      "epoch 73; iter: 0; batch classifier loss: 0.059064; batch adversarial loss: 0.397578\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053762; batch adversarial loss: 0.454672\n",
      "epoch 75; iter: 0; batch classifier loss: 0.044416; batch adversarial loss: 0.511228\n",
      "epoch 76; iter: 0; batch classifier loss: 0.089082; batch adversarial loss: 0.362786\n",
      "epoch 77; iter: 0; batch classifier loss: 0.043003; batch adversarial loss: 0.326934\n",
      "epoch 78; iter: 0; batch classifier loss: 0.081985; batch adversarial loss: 0.435054\n",
      "epoch 79; iter: 0; batch classifier loss: 0.051546; batch adversarial loss: 0.418242\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076320; batch adversarial loss: 0.418306\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067053; batch adversarial loss: 0.415294\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059872; batch adversarial loss: 0.353158\n",
      "epoch 83; iter: 0; batch classifier loss: 0.129934; batch adversarial loss: 0.389908\n",
      "epoch 84; iter: 0; batch classifier loss: 0.094795; batch adversarial loss: 0.456916\n",
      "epoch 85; iter: 0; batch classifier loss: 0.071343; batch adversarial loss: 0.502227\n",
      "epoch 86; iter: 0; batch classifier loss: 0.037632; batch adversarial loss: 0.474826\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064677; batch adversarial loss: 0.441584\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054371; batch adversarial loss: 0.350763\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035980; batch adversarial loss: 0.492566\n",
      "epoch 90; iter: 0; batch classifier loss: 0.058530; batch adversarial loss: 0.384713\n",
      "epoch 91; iter: 0; batch classifier loss: 0.013148; batch adversarial loss: 0.486813\n",
      "epoch 92; iter: 0; batch classifier loss: 0.075312; batch adversarial loss: 0.460270\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072257; batch adversarial loss: 0.493916\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081256; batch adversarial loss: 0.451274\n",
      "epoch 95; iter: 0; batch classifier loss: 0.062915; batch adversarial loss: 0.417406\n",
      "epoch 96; iter: 0; batch classifier loss: 0.073867; batch adversarial loss: 0.483175\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049103; batch adversarial loss: 0.476346\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044355; batch adversarial loss: 0.382230\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074843; batch adversarial loss: 0.312845\n",
      "epoch 100; iter: 0; batch classifier loss: 0.063397; batch adversarial loss: 0.477741\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062796; batch adversarial loss: 0.410315\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041714; batch adversarial loss: 0.403497\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049252; batch adversarial loss: 0.409247\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053376; batch adversarial loss: 0.407156\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051315; batch adversarial loss: 0.473023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.019019; batch adversarial loss: 0.371402\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040304; batch adversarial loss: 0.435322\n",
      "epoch 108; iter: 0; batch classifier loss: 0.022327; batch adversarial loss: 0.477757\n",
      "epoch 109; iter: 0; batch classifier loss: 0.078275; batch adversarial loss: 0.487162\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060395; batch adversarial loss: 0.450293\n",
      "epoch 111; iter: 0; batch classifier loss: 0.021842; batch adversarial loss: 0.408154\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042401; batch adversarial loss: 0.527074\n",
      "epoch 113; iter: 0; batch classifier loss: 0.084191; batch adversarial loss: 0.405398\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035280; batch adversarial loss: 0.478351\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056353; batch adversarial loss: 0.360704\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038211; batch adversarial loss: 0.403994\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029325; batch adversarial loss: 0.466374\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048853; batch adversarial loss: 0.434222\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043903; batch adversarial loss: 0.420992\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055564; batch adversarial loss: 0.467710\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034141; batch adversarial loss: 0.451693\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017718; batch adversarial loss: 0.419799\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020801; batch adversarial loss: 0.457965\n",
      "epoch 124; iter: 0; batch classifier loss: 0.007892; batch adversarial loss: 0.396576\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062776; batch adversarial loss: 0.383631\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027788; batch adversarial loss: 0.426777\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022567; batch adversarial loss: 0.387275\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037839; batch adversarial loss: 0.370645\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016305; batch adversarial loss: 0.596917\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022693; batch adversarial loss: 0.374613\n",
      "epoch 131; iter: 0; batch classifier loss: 0.007036; batch adversarial loss: 0.384014\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030351; batch adversarial loss: 0.459250\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024321; batch adversarial loss: 0.392696\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021454; batch adversarial loss: 0.396360\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027473; batch adversarial loss: 0.455587\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035994; batch adversarial loss: 0.450746\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015919; batch adversarial loss: 0.465891\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030564; batch adversarial loss: 0.407449\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025374; batch adversarial loss: 0.475280\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013228; batch adversarial loss: 0.435040\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021983; batch adversarial loss: 0.458317\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023017; batch adversarial loss: 0.451097\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024015; batch adversarial loss: 0.433516\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017585; batch adversarial loss: 0.421531\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019953; batch adversarial loss: 0.561982\n",
      "epoch 146; iter: 0; batch classifier loss: 0.036950; batch adversarial loss: 0.425184\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024192; batch adversarial loss: 0.461532\n",
      "epoch 148; iter: 0; batch classifier loss: 0.009402; batch adversarial loss: 0.436408\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028766; batch adversarial loss: 0.464125\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011404; batch adversarial loss: 0.351287\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036836; batch adversarial loss: 0.419990\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019267; batch adversarial loss: 0.387788\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011308; batch adversarial loss: 0.449213\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040299; batch adversarial loss: 0.420077\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029227; batch adversarial loss: 0.566333\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035541; batch adversarial loss: 0.465081\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034848; batch adversarial loss: 0.421455\n",
      "epoch 158; iter: 0; batch classifier loss: 0.060332; batch adversarial loss: 0.581852\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013545; batch adversarial loss: 0.438495\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016394; batch adversarial loss: 0.359148\n",
      "epoch 161; iter: 0; batch classifier loss: 0.003800; batch adversarial loss: 0.493118\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019254; batch adversarial loss: 0.421213\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018918; batch adversarial loss: 0.439493\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020991; batch adversarial loss: 0.432918\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018171; batch adversarial loss: 0.385771\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021851; batch adversarial loss: 0.376013\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008248; batch adversarial loss: 0.452877\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017911; batch adversarial loss: 0.507260\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014308; batch adversarial loss: 0.307687\n",
      "epoch 170; iter: 0; batch classifier loss: 0.005446; batch adversarial loss: 0.439013\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005812; batch adversarial loss: 0.410719\n",
      "epoch 172; iter: 0; batch classifier loss: 0.071633; batch adversarial loss: 0.424339\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007228; batch adversarial loss: 0.402926\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026804; batch adversarial loss: 0.489178\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019831; batch adversarial loss: 0.399872\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029164; batch adversarial loss: 0.495566\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025234; batch adversarial loss: 0.426508\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006733; batch adversarial loss: 0.413577\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027982; batch adversarial loss: 0.426937\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037014; batch adversarial loss: 0.357283\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010467; batch adversarial loss: 0.418795\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033519; batch adversarial loss: 0.468872\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013935; batch adversarial loss: 0.359748\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007417; batch adversarial loss: 0.390983\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009224; batch adversarial loss: 0.427053\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011003; batch adversarial loss: 0.489855\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020041; batch adversarial loss: 0.435811\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017329; batch adversarial loss: 0.511953\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015292; batch adversarial loss: 0.479927\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030839; batch adversarial loss: 0.507158\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010714; batch adversarial loss: 0.593103\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018780; batch adversarial loss: 0.395510\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005624; batch adversarial loss: 0.408427\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013021; batch adversarial loss: 0.476443\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006068; batch adversarial loss: 0.435211\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012238; batch adversarial loss: 0.431023\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015807; batch adversarial loss: 0.460527\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020841; batch adversarial loss: 0.351102\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008110; batch adversarial loss: 0.370205\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706518; batch adversarial loss: 0.634666\n",
      "epoch 1; iter: 0; batch classifier loss: 0.378467; batch adversarial loss: 0.622886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.399693; batch adversarial loss: 0.588894\n",
      "epoch 3; iter: 0; batch classifier loss: 0.326801; batch adversarial loss: 0.569668\n",
      "epoch 4; iter: 0; batch classifier loss: 0.321184; batch adversarial loss: 0.530023\n",
      "epoch 5; iter: 0; batch classifier loss: 0.305649; batch adversarial loss: 0.544178\n",
      "epoch 6; iter: 0; batch classifier loss: 0.276523; batch adversarial loss: 0.565802\n",
      "epoch 7; iter: 0; batch classifier loss: 0.239563; batch adversarial loss: 0.517620\n",
      "epoch 8; iter: 0; batch classifier loss: 0.304894; batch adversarial loss: 0.541257\n",
      "epoch 9; iter: 0; batch classifier loss: 0.268375; batch adversarial loss: 0.572050\n",
      "epoch 10; iter: 0; batch classifier loss: 0.299863; batch adversarial loss: 0.474005\n",
      "epoch 11; iter: 0; batch classifier loss: 0.265115; batch adversarial loss: 0.528418\n",
      "epoch 12; iter: 0; batch classifier loss: 0.239818; batch adversarial loss: 0.459599\n",
      "epoch 13; iter: 0; batch classifier loss: 0.247328; batch adversarial loss: 0.477688\n",
      "epoch 14; iter: 0; batch classifier loss: 0.222181; batch adversarial loss: 0.429888\n",
      "epoch 15; iter: 0; batch classifier loss: 0.182658; batch adversarial loss: 0.496267\n",
      "epoch 16; iter: 0; batch classifier loss: 0.199483; batch adversarial loss: 0.545618\n",
      "epoch 17; iter: 0; batch classifier loss: 0.253371; batch adversarial loss: 0.508879\n",
      "epoch 18; iter: 0; batch classifier loss: 0.260173; batch adversarial loss: 0.479409\n",
      "epoch 19; iter: 0; batch classifier loss: 0.228130; batch adversarial loss: 0.461693\n",
      "epoch 20; iter: 0; batch classifier loss: 0.207374; batch adversarial loss: 0.541528\n",
      "epoch 21; iter: 0; batch classifier loss: 0.318752; batch adversarial loss: 0.555994\n",
      "epoch 22; iter: 0; batch classifier loss: 0.236847; batch adversarial loss: 0.410940\n",
      "epoch 23; iter: 0; batch classifier loss: 0.227302; batch adversarial loss: 0.453447\n",
      "epoch 24; iter: 0; batch classifier loss: 0.289540; batch adversarial loss: 0.524677\n",
      "epoch 25; iter: 0; batch classifier loss: 0.373515; batch adversarial loss: 0.458191\n",
      "epoch 26; iter: 0; batch classifier loss: 0.266757; batch adversarial loss: 0.513761\n",
      "epoch 27; iter: 0; batch classifier loss: 0.182167; batch adversarial loss: 0.518307\n",
      "epoch 28; iter: 0; batch classifier loss: 0.201274; batch adversarial loss: 0.432781\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170856; batch adversarial loss: 0.484455\n",
      "epoch 30; iter: 0; batch classifier loss: 0.142303; batch adversarial loss: 0.442402\n",
      "epoch 31; iter: 0; batch classifier loss: 0.130060; batch adversarial loss: 0.463110\n",
      "epoch 32; iter: 0; batch classifier loss: 0.101682; batch adversarial loss: 0.371824\n",
      "epoch 33; iter: 0; batch classifier loss: 0.117288; batch adversarial loss: 0.418668\n",
      "epoch 34; iter: 0; batch classifier loss: 0.193975; batch adversarial loss: 0.345819\n",
      "epoch 35; iter: 0; batch classifier loss: 0.143543; batch adversarial loss: 0.543445\n",
      "epoch 36; iter: 0; batch classifier loss: 0.142743; batch adversarial loss: 0.430040\n",
      "epoch 37; iter: 0; batch classifier loss: 0.137762; batch adversarial loss: 0.482330\n",
      "epoch 38; iter: 0; batch classifier loss: 0.118452; batch adversarial loss: 0.450402\n",
      "epoch 39; iter: 0; batch classifier loss: 0.123247; batch adversarial loss: 0.518983\n",
      "epoch 40; iter: 0; batch classifier loss: 0.156423; batch adversarial loss: 0.483828\n",
      "epoch 41; iter: 0; batch classifier loss: 0.174762; batch adversarial loss: 0.492613\n",
      "epoch 42; iter: 0; batch classifier loss: 0.095117; batch adversarial loss: 0.422385\n",
      "epoch 43; iter: 0; batch classifier loss: 0.173594; batch adversarial loss: 0.425254\n",
      "epoch 44; iter: 0; batch classifier loss: 0.117390; batch adversarial loss: 0.505829\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124642; batch adversarial loss: 0.539894\n",
      "epoch 46; iter: 0; batch classifier loss: 0.119877; batch adversarial loss: 0.391120\n",
      "epoch 47; iter: 0; batch classifier loss: 0.092008; batch adversarial loss: 0.408419\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141317; batch adversarial loss: 0.350114\n",
      "epoch 49; iter: 0; batch classifier loss: 0.082180; batch adversarial loss: 0.495289\n",
      "epoch 50; iter: 0; batch classifier loss: 0.121811; batch adversarial loss: 0.434592\n",
      "epoch 51; iter: 0; batch classifier loss: 0.187076; batch adversarial loss: 0.420309\n",
      "epoch 52; iter: 0; batch classifier loss: 0.147536; batch adversarial loss: 0.429524\n",
      "epoch 53; iter: 0; batch classifier loss: 0.165821; batch adversarial loss: 0.385154\n",
      "epoch 54; iter: 0; batch classifier loss: 0.156970; batch adversarial loss: 0.386736\n",
      "epoch 55; iter: 0; batch classifier loss: 0.149259; batch adversarial loss: 0.411881\n",
      "epoch 56; iter: 0; batch classifier loss: 0.153904; batch adversarial loss: 0.383718\n",
      "epoch 57; iter: 0; batch classifier loss: 0.100712; batch adversarial loss: 0.477802\n",
      "epoch 58; iter: 0; batch classifier loss: 0.215394; batch adversarial loss: 0.422269\n",
      "epoch 59; iter: 0; batch classifier loss: 0.103191; batch adversarial loss: 0.549060\n",
      "epoch 60; iter: 0; batch classifier loss: 0.102449; batch adversarial loss: 0.383985\n",
      "epoch 61; iter: 0; batch classifier loss: 0.148811; batch adversarial loss: 0.498164\n",
      "epoch 62; iter: 0; batch classifier loss: 0.173130; batch adversarial loss: 0.437381\n",
      "epoch 63; iter: 0; batch classifier loss: 0.126302; batch adversarial loss: 0.430750\n",
      "epoch 64; iter: 0; batch classifier loss: 0.126032; batch adversarial loss: 0.374865\n",
      "epoch 65; iter: 0; batch classifier loss: 0.144002; batch adversarial loss: 0.426791\n",
      "epoch 66; iter: 0; batch classifier loss: 0.164151; batch adversarial loss: 0.516698\n",
      "epoch 67; iter: 0; batch classifier loss: 0.105442; batch adversarial loss: 0.541386\n",
      "epoch 68; iter: 0; batch classifier loss: 0.228391; batch adversarial loss: 0.528073\n",
      "epoch 69; iter: 0; batch classifier loss: 0.116672; batch adversarial loss: 0.408768\n",
      "epoch 70; iter: 0; batch classifier loss: 0.083640; batch adversarial loss: 0.513806\n",
      "epoch 71; iter: 0; batch classifier loss: 0.109922; batch adversarial loss: 0.439272\n",
      "epoch 72; iter: 0; batch classifier loss: 0.108508; batch adversarial loss: 0.607294\n",
      "epoch 73; iter: 0; batch classifier loss: 0.135961; batch adversarial loss: 0.426193\n",
      "epoch 74; iter: 0; batch classifier loss: 0.189724; batch adversarial loss: 0.460850\n",
      "epoch 75; iter: 0; batch classifier loss: 0.088667; batch adversarial loss: 0.433569\n",
      "epoch 76; iter: 0; batch classifier loss: 0.139329; batch adversarial loss: 0.467704\n",
      "epoch 77; iter: 0; batch classifier loss: 0.147051; batch adversarial loss: 0.446347\n",
      "epoch 78; iter: 0; batch classifier loss: 0.118830; batch adversarial loss: 0.454334\n",
      "epoch 79; iter: 0; batch classifier loss: 0.142491; batch adversarial loss: 0.431091\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078180; batch adversarial loss: 0.441711\n",
      "epoch 81; iter: 0; batch classifier loss: 0.181263; batch adversarial loss: 0.450978\n",
      "epoch 82; iter: 0; batch classifier loss: 0.106748; batch adversarial loss: 0.413802\n",
      "epoch 83; iter: 0; batch classifier loss: 0.197693; batch adversarial loss: 0.488382\n",
      "epoch 84; iter: 0; batch classifier loss: 0.172614; batch adversarial loss: 0.441670\n",
      "epoch 85; iter: 0; batch classifier loss: 0.141985; batch adversarial loss: 0.535926\n",
      "epoch 86; iter: 0; batch classifier loss: 0.131799; batch adversarial loss: 0.407026\n",
      "epoch 87; iter: 0; batch classifier loss: 0.149817; batch adversarial loss: 0.494416\n",
      "epoch 88; iter: 0; batch classifier loss: 0.141772; batch adversarial loss: 0.481052\n",
      "epoch 89; iter: 0; batch classifier loss: 0.141892; batch adversarial loss: 0.394612\n",
      "epoch 90; iter: 0; batch classifier loss: 0.164348; batch adversarial loss: 0.554762\n",
      "epoch 91; iter: 0; batch classifier loss: 0.163286; batch adversarial loss: 0.524481\n",
      "epoch 92; iter: 0; batch classifier loss: 0.128308; batch adversarial loss: 0.358637\n",
      "epoch 93; iter: 0; batch classifier loss: 0.120883; batch adversarial loss: 0.502816\n",
      "epoch 94; iter: 0; batch classifier loss: 0.098854; batch adversarial loss: 0.429289\n",
      "epoch 95; iter: 0; batch classifier loss: 0.175722; batch adversarial loss: 0.491174\n",
      "epoch 96; iter: 0; batch classifier loss: 0.105226; batch adversarial loss: 0.425033\n",
      "epoch 97; iter: 0; batch classifier loss: 0.083312; batch adversarial loss: 0.404037\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067818; batch adversarial loss: 0.380511\n",
      "epoch 99; iter: 0; batch classifier loss: 0.146602; batch adversarial loss: 0.411432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.161932; batch adversarial loss: 0.500526\n",
      "epoch 101; iter: 0; batch classifier loss: 0.127590; batch adversarial loss: 0.388431\n",
      "epoch 102; iter: 0; batch classifier loss: 0.100543; batch adversarial loss: 0.488777\n",
      "epoch 103; iter: 0; batch classifier loss: 0.105271; batch adversarial loss: 0.336007\n",
      "epoch 104; iter: 0; batch classifier loss: 0.118372; batch adversarial loss: 0.418931\n",
      "epoch 105; iter: 0; batch classifier loss: 0.134473; batch adversarial loss: 0.387130\n",
      "epoch 106; iter: 0; batch classifier loss: 0.120805; batch adversarial loss: 0.543745\n",
      "epoch 107; iter: 0; batch classifier loss: 0.100061; batch adversarial loss: 0.398505\n",
      "epoch 108; iter: 0; batch classifier loss: 0.102440; batch adversarial loss: 0.388041\n",
      "epoch 109; iter: 0; batch classifier loss: 0.079950; batch adversarial loss: 0.411871\n",
      "epoch 110; iter: 0; batch classifier loss: 0.089005; batch adversarial loss: 0.481785\n",
      "epoch 111; iter: 0; batch classifier loss: 0.218603; batch adversarial loss: 0.483347\n",
      "epoch 112; iter: 0; batch classifier loss: 0.090370; batch adversarial loss: 0.527473\n",
      "epoch 113; iter: 0; batch classifier loss: 0.061652; batch adversarial loss: 0.470078\n",
      "epoch 114; iter: 0; batch classifier loss: 0.093295; batch adversarial loss: 0.349259\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048122; batch adversarial loss: 0.520759\n",
      "epoch 116; iter: 0; batch classifier loss: 0.085821; batch adversarial loss: 0.492694\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056356; batch adversarial loss: 0.421692\n",
      "epoch 118; iter: 0; batch classifier loss: 0.058144; batch adversarial loss: 0.445019\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057651; batch adversarial loss: 0.486350\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046410; batch adversarial loss: 0.473802\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042145; batch adversarial loss: 0.494235\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052891; batch adversarial loss: 0.506733\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064223; batch adversarial loss: 0.424981\n",
      "epoch 124; iter: 0; batch classifier loss: 0.062848; batch adversarial loss: 0.441713\n",
      "epoch 125; iter: 0; batch classifier loss: 0.095790; batch adversarial loss: 0.415354\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034732; batch adversarial loss: 0.454752\n",
      "epoch 127; iter: 0; batch classifier loss: 0.064058; batch adversarial loss: 0.437084\n",
      "epoch 128; iter: 0; batch classifier loss: 0.064715; batch adversarial loss: 0.440048\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037819; batch adversarial loss: 0.357213\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035951; batch adversarial loss: 0.384742\n",
      "epoch 131; iter: 0; batch classifier loss: 0.057671; batch adversarial loss: 0.443429\n",
      "epoch 132; iter: 0; batch classifier loss: 0.075486; batch adversarial loss: 0.400401\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036017; batch adversarial loss: 0.428625\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054319; batch adversarial loss: 0.411113\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039532; batch adversarial loss: 0.434571\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050391; batch adversarial loss: 0.555767\n",
      "epoch 137; iter: 0; batch classifier loss: 0.063460; batch adversarial loss: 0.553069\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029597; batch adversarial loss: 0.372967\n",
      "epoch 139; iter: 0; batch classifier loss: 0.062247; batch adversarial loss: 0.452767\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019610; batch adversarial loss: 0.507318\n",
      "epoch 141; iter: 0; batch classifier loss: 0.080753; batch adversarial loss: 0.483320\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050699; batch adversarial loss: 0.401479\n",
      "epoch 143; iter: 0; batch classifier loss: 0.052679; batch adversarial loss: 0.440429\n",
      "epoch 144; iter: 0; batch classifier loss: 0.044495; batch adversarial loss: 0.389828\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030553; batch adversarial loss: 0.476057\n",
      "epoch 146; iter: 0; batch classifier loss: 0.053404; batch adversarial loss: 0.449836\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039585; batch adversarial loss: 0.476200\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033899; batch adversarial loss: 0.395055\n",
      "epoch 149; iter: 0; batch classifier loss: 0.049146; batch adversarial loss: 0.469445\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023376; batch adversarial loss: 0.424420\n",
      "epoch 151; iter: 0; batch classifier loss: 0.066048; batch adversarial loss: 0.416927\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043152; batch adversarial loss: 0.408815\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025313; batch adversarial loss: 0.471607\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018821; batch adversarial loss: 0.426451\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052054; batch adversarial loss: 0.382360\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036793; batch adversarial loss: 0.444387\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042331; batch adversarial loss: 0.453911\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048703; batch adversarial loss: 0.470268\n",
      "epoch 159; iter: 0; batch classifier loss: 0.073908; batch adversarial loss: 0.450775\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046057; batch adversarial loss: 0.409841\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025407; batch adversarial loss: 0.418990\n",
      "epoch 162; iter: 0; batch classifier loss: 0.047851; batch adversarial loss: 0.458533\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013379; batch adversarial loss: 0.491248\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021924; batch adversarial loss: 0.494760\n",
      "epoch 165; iter: 0; batch classifier loss: 0.074285; batch adversarial loss: 0.353692\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011559; batch adversarial loss: 0.496283\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042571; batch adversarial loss: 0.425516\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024641; batch adversarial loss: 0.361848\n",
      "epoch 169; iter: 0; batch classifier loss: 0.067205; batch adversarial loss: 0.421253\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034157; batch adversarial loss: 0.518600\n",
      "epoch 171; iter: 0; batch classifier loss: 0.053614; batch adversarial loss: 0.471629\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010330; batch adversarial loss: 0.541820\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028910; batch adversarial loss: 0.394571\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031319; batch adversarial loss: 0.365105\n",
      "epoch 175; iter: 0; batch classifier loss: 0.050857; batch adversarial loss: 0.496285\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011092; batch adversarial loss: 0.389539\n",
      "epoch 177; iter: 0; batch classifier loss: 0.043598; batch adversarial loss: 0.409342\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037375; batch adversarial loss: 0.386746\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012262; batch adversarial loss: 0.498262\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023889; batch adversarial loss: 0.388159\n",
      "epoch 181; iter: 0; batch classifier loss: 0.056080; batch adversarial loss: 0.336215\n",
      "epoch 182; iter: 0; batch classifier loss: 0.040637; batch adversarial loss: 0.429358\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020602; batch adversarial loss: 0.370539\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021351; batch adversarial loss: 0.404305\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018281; batch adversarial loss: 0.457915\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035647; batch adversarial loss: 0.389884\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016868; batch adversarial loss: 0.418654\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033768; batch adversarial loss: 0.377975\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034780; batch adversarial loss: 0.433335\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007007; batch adversarial loss: 0.418834\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020876; batch adversarial loss: 0.499231\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025848; batch adversarial loss: 0.406929\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014074; batch adversarial loss: 0.354986\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033178; batch adversarial loss: 0.346191\n",
      "epoch 195; iter: 0; batch classifier loss: 0.032830; batch adversarial loss: 0.449098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.010770; batch adversarial loss: 0.431217\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011183; batch adversarial loss: 0.429442\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024981; batch adversarial loss: 0.388329\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021982; batch adversarial loss: 0.465112\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692862; batch adversarial loss: 0.570341\n",
      "epoch 1; iter: 0; batch classifier loss: 0.419030; batch adversarial loss: 0.618592\n",
      "epoch 2; iter: 0; batch classifier loss: 0.361797; batch adversarial loss: 0.596292\n",
      "epoch 3; iter: 0; batch classifier loss: 0.460973; batch adversarial loss: 0.582320\n",
      "epoch 4; iter: 0; batch classifier loss: 0.403370; batch adversarial loss: 0.613794\n",
      "epoch 5; iter: 0; batch classifier loss: 0.414304; batch adversarial loss: 0.571297\n",
      "epoch 6; iter: 0; batch classifier loss: 0.440091; batch adversarial loss: 0.575876\n",
      "epoch 7; iter: 0; batch classifier loss: 0.489638; batch adversarial loss: 0.592877\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539659; batch adversarial loss: 0.561074\n",
      "epoch 9; iter: 0; batch classifier loss: 0.496602; batch adversarial loss: 0.524858\n",
      "epoch 10; iter: 0; batch classifier loss: 0.671150; batch adversarial loss: 0.541008\n",
      "epoch 11; iter: 0; batch classifier loss: 0.550029; batch adversarial loss: 0.566283\n",
      "epoch 12; iter: 0; batch classifier loss: 0.496119; batch adversarial loss: 0.515356\n",
      "epoch 13; iter: 0; batch classifier loss: 0.352575; batch adversarial loss: 0.455011\n",
      "epoch 14; iter: 0; batch classifier loss: 0.277038; batch adversarial loss: 0.538467\n",
      "epoch 15; iter: 0; batch classifier loss: 0.318437; batch adversarial loss: 0.451408\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227809; batch adversarial loss: 0.435720\n",
      "epoch 17; iter: 0; batch classifier loss: 0.232207; batch adversarial loss: 0.529733\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243392; batch adversarial loss: 0.487196\n",
      "epoch 19; iter: 0; batch classifier loss: 0.206000; batch adversarial loss: 0.508667\n",
      "epoch 20; iter: 0; batch classifier loss: 0.240052; batch adversarial loss: 0.407523\n",
      "epoch 21; iter: 0; batch classifier loss: 0.221671; batch adversarial loss: 0.447815\n",
      "epoch 22; iter: 0; batch classifier loss: 0.261616; batch adversarial loss: 0.423110\n",
      "epoch 23; iter: 0; batch classifier loss: 0.138087; batch adversarial loss: 0.581582\n",
      "epoch 24; iter: 0; batch classifier loss: 0.178060; batch adversarial loss: 0.480805\n",
      "epoch 25; iter: 0; batch classifier loss: 0.169225; batch adversarial loss: 0.503810\n",
      "epoch 26; iter: 0; batch classifier loss: 0.178600; batch adversarial loss: 0.376936\n",
      "epoch 27; iter: 0; batch classifier loss: 0.195189; batch adversarial loss: 0.528042\n",
      "epoch 28; iter: 0; batch classifier loss: 0.178064; batch adversarial loss: 0.537857\n",
      "epoch 29; iter: 0; batch classifier loss: 0.184645; batch adversarial loss: 0.487601\n",
      "epoch 30; iter: 0; batch classifier loss: 0.158524; batch adversarial loss: 0.432727\n",
      "epoch 31; iter: 0; batch classifier loss: 0.157166; batch adversarial loss: 0.474299\n",
      "epoch 32; iter: 0; batch classifier loss: 0.141778; batch adversarial loss: 0.409031\n",
      "epoch 33; iter: 0; batch classifier loss: 0.125213; batch adversarial loss: 0.529653\n",
      "epoch 34; iter: 0; batch classifier loss: 0.118709; batch adversarial loss: 0.453332\n",
      "epoch 35; iter: 0; batch classifier loss: 0.116000; batch adversarial loss: 0.425498\n",
      "epoch 36; iter: 0; batch classifier loss: 0.191584; batch adversarial loss: 0.426183\n",
      "epoch 37; iter: 0; batch classifier loss: 0.084772; batch adversarial loss: 0.439976\n",
      "epoch 38; iter: 0; batch classifier loss: 0.112179; batch adversarial loss: 0.419205\n",
      "epoch 39; iter: 0; batch classifier loss: 0.101908; batch adversarial loss: 0.511991\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135370; batch adversarial loss: 0.499947\n",
      "epoch 41; iter: 0; batch classifier loss: 0.160054; batch adversarial loss: 0.449678\n",
      "epoch 42; iter: 0; batch classifier loss: 0.168491; batch adversarial loss: 0.528411\n",
      "epoch 43; iter: 0; batch classifier loss: 0.080882; batch adversarial loss: 0.451419\n",
      "epoch 44; iter: 0; batch classifier loss: 0.089454; batch adversarial loss: 0.466199\n",
      "epoch 45; iter: 0; batch classifier loss: 0.085193; batch adversarial loss: 0.426893\n",
      "epoch 46; iter: 0; batch classifier loss: 0.110566; batch adversarial loss: 0.508063\n",
      "epoch 47; iter: 0; batch classifier loss: 0.107935; batch adversarial loss: 0.445382\n",
      "epoch 48; iter: 0; batch classifier loss: 0.143469; batch adversarial loss: 0.500436\n",
      "epoch 49; iter: 0; batch classifier loss: 0.103605; batch adversarial loss: 0.386779\n",
      "epoch 50; iter: 0; batch classifier loss: 0.106768; batch adversarial loss: 0.446291\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122182; batch adversarial loss: 0.455201\n",
      "epoch 52; iter: 0; batch classifier loss: 0.087152; batch adversarial loss: 0.513205\n",
      "epoch 53; iter: 0; batch classifier loss: 0.118626; batch adversarial loss: 0.466917\n",
      "epoch 54; iter: 0; batch classifier loss: 0.129650; batch adversarial loss: 0.488381\n",
      "epoch 55; iter: 0; batch classifier loss: 0.078232; batch adversarial loss: 0.393692\n",
      "epoch 56; iter: 0; batch classifier loss: 0.093639; batch adversarial loss: 0.422692\n",
      "epoch 57; iter: 0; batch classifier loss: 0.103726; batch adversarial loss: 0.580558\n",
      "epoch 58; iter: 0; batch classifier loss: 0.119848; batch adversarial loss: 0.525973\n",
      "epoch 59; iter: 0; batch classifier loss: 0.108506; batch adversarial loss: 0.414877\n",
      "epoch 60; iter: 0; batch classifier loss: 0.084781; batch adversarial loss: 0.441607\n",
      "epoch 61; iter: 0; batch classifier loss: 0.120299; batch adversarial loss: 0.436947\n",
      "epoch 62; iter: 0; batch classifier loss: 0.106910; batch adversarial loss: 0.504340\n",
      "epoch 63; iter: 0; batch classifier loss: 0.120584; batch adversarial loss: 0.464606\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076451; batch adversarial loss: 0.489658\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118329; batch adversarial loss: 0.494776\n",
      "epoch 66; iter: 0; batch classifier loss: 0.090166; batch adversarial loss: 0.457204\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101764; batch adversarial loss: 0.436487\n",
      "epoch 68; iter: 0; batch classifier loss: 0.129966; batch adversarial loss: 0.411685\n",
      "epoch 69; iter: 0; batch classifier loss: 0.086591; batch adversarial loss: 0.513784\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091499; batch adversarial loss: 0.414513\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076607; batch adversarial loss: 0.544119\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062755; batch adversarial loss: 0.451490\n",
      "epoch 73; iter: 0; batch classifier loss: 0.104559; batch adversarial loss: 0.417351\n",
      "epoch 74; iter: 0; batch classifier loss: 0.091002; batch adversarial loss: 0.540015\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069242; batch adversarial loss: 0.545403\n",
      "epoch 76; iter: 0; batch classifier loss: 0.122320; batch adversarial loss: 0.473937\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084748; batch adversarial loss: 0.467779\n",
      "epoch 78; iter: 0; batch classifier loss: 0.068716; batch adversarial loss: 0.499725\n",
      "epoch 79; iter: 0; batch classifier loss: 0.084064; batch adversarial loss: 0.475904\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088762; batch adversarial loss: 0.460622\n",
      "epoch 81; iter: 0; batch classifier loss: 0.088901; batch adversarial loss: 0.500560\n",
      "epoch 82; iter: 0; batch classifier loss: 0.055149; batch adversarial loss: 0.445327\n",
      "epoch 83; iter: 0; batch classifier loss: 0.092393; batch adversarial loss: 0.555840\n",
      "epoch 84; iter: 0; batch classifier loss: 0.073842; batch adversarial loss: 0.403450\n",
      "epoch 85; iter: 0; batch classifier loss: 0.095068; batch adversarial loss: 0.506390\n",
      "epoch 86; iter: 0; batch classifier loss: 0.120840; batch adversarial loss: 0.503975\n",
      "epoch 87; iter: 0; batch classifier loss: 0.077866; batch adversarial loss: 0.432356\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041443; batch adversarial loss: 0.534190\n",
      "epoch 89; iter: 0; batch classifier loss: 0.082979; batch adversarial loss: 0.468333\n",
      "epoch 90; iter: 0; batch classifier loss: 0.113349; batch adversarial loss: 0.498783\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068042; batch adversarial loss: 0.511638\n",
      "epoch 92; iter: 0; batch classifier loss: 0.095262; batch adversarial loss: 0.416548\n",
      "epoch 93; iter: 0; batch classifier loss: 0.131299; batch adversarial loss: 0.476824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.052622; batch adversarial loss: 0.502122\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087047; batch adversarial loss: 0.447293\n",
      "epoch 96; iter: 0; batch classifier loss: 0.086439; batch adversarial loss: 0.511775\n",
      "epoch 97; iter: 0; batch classifier loss: 0.078483; batch adversarial loss: 0.457722\n",
      "epoch 98; iter: 0; batch classifier loss: 0.065559; batch adversarial loss: 0.465873\n",
      "epoch 99; iter: 0; batch classifier loss: 0.075472; batch adversarial loss: 0.496039\n",
      "epoch 100; iter: 0; batch classifier loss: 0.088211; batch adversarial loss: 0.444120\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075429; batch adversarial loss: 0.488341\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067388; batch adversarial loss: 0.475720\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039883; batch adversarial loss: 0.561057\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059178; batch adversarial loss: 0.454168\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061025; batch adversarial loss: 0.540413\n",
      "epoch 106; iter: 0; batch classifier loss: 0.107913; batch adversarial loss: 0.504181\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050196; batch adversarial loss: 0.456519\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055125; batch adversarial loss: 0.451376\n",
      "epoch 109; iter: 0; batch classifier loss: 0.052768; batch adversarial loss: 0.465844\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059346; batch adversarial loss: 0.517910\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035046; batch adversarial loss: 0.458229\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046670; batch adversarial loss: 0.497243\n",
      "epoch 113; iter: 0; batch classifier loss: 0.079795; batch adversarial loss: 0.444723\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059038; batch adversarial loss: 0.505674\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031289; batch adversarial loss: 0.378579\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037461; batch adversarial loss: 0.470098\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031960; batch adversarial loss: 0.502152\n",
      "epoch 118; iter: 0; batch classifier loss: 0.066066; batch adversarial loss: 0.457860\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050686; batch adversarial loss: 0.492329\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030701; batch adversarial loss: 0.380568\n",
      "epoch 121; iter: 0; batch classifier loss: 0.067188; batch adversarial loss: 0.447065\n",
      "epoch 122; iter: 0; batch classifier loss: 0.075283; batch adversarial loss: 0.434633\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040513; batch adversarial loss: 0.539924\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031353; batch adversarial loss: 0.391191\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033711; batch adversarial loss: 0.476511\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039439; batch adversarial loss: 0.384811\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045395; batch adversarial loss: 0.490022\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025363; batch adversarial loss: 0.520583\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022042; batch adversarial loss: 0.465804\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035942; batch adversarial loss: 0.455897\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037112; batch adversarial loss: 0.531324\n",
      "epoch 132; iter: 0; batch classifier loss: 0.052001; batch adversarial loss: 0.445546\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046797; batch adversarial loss: 0.500074\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020715; batch adversarial loss: 0.454307\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013529; batch adversarial loss: 0.573083\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013190; batch adversarial loss: 0.523754\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033991; batch adversarial loss: 0.453661\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036491; batch adversarial loss: 0.387864\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034888; batch adversarial loss: 0.434696\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018689; batch adversarial loss: 0.476782\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028628; batch adversarial loss: 0.402923\n",
      "epoch 142; iter: 0; batch classifier loss: 0.066928; batch adversarial loss: 0.491441\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034683; batch adversarial loss: 0.490443\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036685; batch adversarial loss: 0.497347\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022192; batch adversarial loss: 0.555954\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013491; batch adversarial loss: 0.455802\n",
      "epoch 147; iter: 0; batch classifier loss: 0.051846; batch adversarial loss: 0.437836\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040178; batch adversarial loss: 0.475244\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053730; batch adversarial loss: 0.428687\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015793; batch adversarial loss: 0.542514\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040824; batch adversarial loss: 0.479816\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039368; batch adversarial loss: 0.450948\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031136; batch adversarial loss: 0.535793\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038994; batch adversarial loss: 0.527015\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014464; batch adversarial loss: 0.519112\n",
      "epoch 156; iter: 0; batch classifier loss: 0.070495; batch adversarial loss: 0.381108\n",
      "epoch 157; iter: 0; batch classifier loss: 0.045639; batch adversarial loss: 0.445197\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023954; batch adversarial loss: 0.523542\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011012; batch adversarial loss: 0.487028\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022269; batch adversarial loss: 0.468434\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013415; batch adversarial loss: 0.498497\n",
      "epoch 162; iter: 0; batch classifier loss: 0.047719; batch adversarial loss: 0.425072\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022284; batch adversarial loss: 0.529108\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014468; batch adversarial loss: 0.439645\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025721; batch adversarial loss: 0.522140\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029081; batch adversarial loss: 0.481944\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013437; batch adversarial loss: 0.472909\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026027; batch adversarial loss: 0.432096\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018621; batch adversarial loss: 0.433133\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009652; batch adversarial loss: 0.445585\n",
      "epoch 171; iter: 0; batch classifier loss: 0.039558; batch adversarial loss: 0.381607\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024281; batch adversarial loss: 0.448489\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030586; batch adversarial loss: 0.458046\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027723; batch adversarial loss: 0.417927\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036924; batch adversarial loss: 0.470667\n",
      "epoch 176; iter: 0; batch classifier loss: 0.042404; batch adversarial loss: 0.527325\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029482; batch adversarial loss: 0.472848\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032087; batch adversarial loss: 0.477875\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011917; batch adversarial loss: 0.479437\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016675; batch adversarial loss: 0.441855\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030627; batch adversarial loss: 0.427294\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029306; batch adversarial loss: 0.469115\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011539; batch adversarial loss: 0.475384\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012336; batch adversarial loss: 0.460365\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032610; batch adversarial loss: 0.426835\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024963; batch adversarial loss: 0.446321\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011077; batch adversarial loss: 0.554389\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018689; batch adversarial loss: 0.473303\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009644; batch adversarial loss: 0.526625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.013069; batch adversarial loss: 0.490331\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011321; batch adversarial loss: 0.430211\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012292; batch adversarial loss: 0.424330\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007970; batch adversarial loss: 0.459922\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013735; batch adversarial loss: 0.504766\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016291; batch adversarial loss: 0.489108\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033939; batch adversarial loss: 0.552170\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025148; batch adversarial loss: 0.391068\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009890; batch adversarial loss: 0.433734\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011627; batch adversarial loss: 0.433378\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701342; batch adversarial loss: 0.631723\n",
      "epoch 1; iter: 0; batch classifier loss: 0.425886; batch adversarial loss: 0.610025\n",
      "epoch 2; iter: 0; batch classifier loss: 0.372493; batch adversarial loss: 0.622220\n",
      "epoch 3; iter: 0; batch classifier loss: 0.346826; batch adversarial loss: 0.595727\n",
      "epoch 4; iter: 0; batch classifier loss: 0.336611; batch adversarial loss: 0.584832\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343204; batch adversarial loss: 0.565002\n",
      "epoch 6; iter: 0; batch classifier loss: 0.298661; batch adversarial loss: 0.548470\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306936; batch adversarial loss: 0.542387\n",
      "epoch 8; iter: 0; batch classifier loss: 0.247087; batch adversarial loss: 0.469627\n",
      "epoch 9; iter: 0; batch classifier loss: 0.249772; batch adversarial loss: 0.515537\n",
      "epoch 10; iter: 0; batch classifier loss: 0.270250; batch adversarial loss: 0.482288\n",
      "epoch 11; iter: 0; batch classifier loss: 0.248302; batch adversarial loss: 0.533396\n",
      "epoch 12; iter: 0; batch classifier loss: 0.273852; batch adversarial loss: 0.548226\n",
      "epoch 13; iter: 0; batch classifier loss: 0.328325; batch adversarial loss: 0.560801\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263827; batch adversarial loss: 0.505268\n",
      "epoch 15; iter: 0; batch classifier loss: 0.280174; batch adversarial loss: 0.549043\n",
      "epoch 16; iter: 0; batch classifier loss: 0.283289; batch adversarial loss: 0.475344\n",
      "epoch 17; iter: 0; batch classifier loss: 0.293504; batch adversarial loss: 0.535612\n",
      "epoch 18; iter: 0; batch classifier loss: 0.293539; batch adversarial loss: 0.487617\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482176; batch adversarial loss: 0.569305\n",
      "epoch 20; iter: 0; batch classifier loss: 0.441774; batch adversarial loss: 0.536487\n",
      "epoch 21; iter: 0; batch classifier loss: 0.224586; batch adversarial loss: 0.509173\n",
      "epoch 22; iter: 0; batch classifier loss: 0.187589; batch adversarial loss: 0.481100\n",
      "epoch 23; iter: 0; batch classifier loss: 0.166227; batch adversarial loss: 0.469901\n",
      "epoch 24; iter: 0; batch classifier loss: 0.255049; batch adversarial loss: 0.538912\n",
      "epoch 25; iter: 0; batch classifier loss: 0.164096; batch adversarial loss: 0.372608\n",
      "epoch 26; iter: 0; batch classifier loss: 0.149943; batch adversarial loss: 0.459317\n",
      "epoch 27; iter: 0; batch classifier loss: 0.153253; batch adversarial loss: 0.478362\n",
      "epoch 28; iter: 0; batch classifier loss: 0.130348; batch adversarial loss: 0.486490\n",
      "epoch 29; iter: 0; batch classifier loss: 0.162599; batch adversarial loss: 0.481322\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130274; batch adversarial loss: 0.470468\n",
      "epoch 31; iter: 0; batch classifier loss: 0.154282; batch adversarial loss: 0.618202\n",
      "epoch 32; iter: 0; batch classifier loss: 0.215177; batch adversarial loss: 0.390742\n",
      "epoch 33; iter: 0; batch classifier loss: 0.180549; batch adversarial loss: 0.489052\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142495; batch adversarial loss: 0.434071\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137073; batch adversarial loss: 0.523319\n",
      "epoch 36; iter: 0; batch classifier loss: 0.111646; batch adversarial loss: 0.457172\n",
      "epoch 37; iter: 0; batch classifier loss: 0.147971; batch adversarial loss: 0.509420\n",
      "epoch 38; iter: 0; batch classifier loss: 0.160575; batch adversarial loss: 0.500053\n",
      "epoch 39; iter: 0; batch classifier loss: 0.164441; batch adversarial loss: 0.373483\n",
      "epoch 40; iter: 0; batch classifier loss: 0.206559; batch adversarial loss: 0.462241\n",
      "epoch 41; iter: 0; batch classifier loss: 0.128361; batch adversarial loss: 0.463178\n",
      "epoch 42; iter: 0; batch classifier loss: 0.156438; batch adversarial loss: 0.443571\n",
      "epoch 43; iter: 0; batch classifier loss: 0.180957; batch adversarial loss: 0.534900\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127179; batch adversarial loss: 0.432501\n",
      "epoch 45; iter: 0; batch classifier loss: 0.160940; batch adversarial loss: 0.454039\n",
      "epoch 46; iter: 0; batch classifier loss: 0.139555; batch adversarial loss: 0.522877\n",
      "epoch 47; iter: 0; batch classifier loss: 0.173676; batch adversarial loss: 0.519893\n",
      "epoch 48; iter: 0; batch classifier loss: 0.209633; batch adversarial loss: 0.408944\n",
      "epoch 49; iter: 0; batch classifier loss: 0.133428; batch adversarial loss: 0.425528\n",
      "epoch 50; iter: 0; batch classifier loss: 0.223344; batch adversarial loss: 0.493492\n",
      "epoch 51; iter: 0; batch classifier loss: 0.197237; batch adversarial loss: 0.514127\n",
      "epoch 52; iter: 0; batch classifier loss: 0.157751; batch adversarial loss: 0.385906\n",
      "epoch 53; iter: 0; batch classifier loss: 0.199909; batch adversarial loss: 0.485923\n",
      "epoch 54; iter: 0; batch classifier loss: 0.136366; batch adversarial loss: 0.531305\n",
      "epoch 55; iter: 0; batch classifier loss: 0.168760; batch adversarial loss: 0.503527\n",
      "epoch 56; iter: 0; batch classifier loss: 0.123233; batch adversarial loss: 0.480397\n",
      "epoch 57; iter: 0; batch classifier loss: 0.133389; batch adversarial loss: 0.459629\n",
      "epoch 58; iter: 0; batch classifier loss: 0.166109; batch adversarial loss: 0.465490\n",
      "epoch 59; iter: 0; batch classifier loss: 0.182652; batch adversarial loss: 0.488431\n",
      "epoch 60; iter: 0; batch classifier loss: 0.182453; batch adversarial loss: 0.373987\n",
      "epoch 61; iter: 0; batch classifier loss: 0.168474; batch adversarial loss: 0.481460\n",
      "epoch 62; iter: 0; batch classifier loss: 0.226208; batch adversarial loss: 0.482080\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088898; batch adversarial loss: 0.412581\n",
      "epoch 64; iter: 0; batch classifier loss: 0.194103; batch adversarial loss: 0.472823\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122917; batch adversarial loss: 0.448574\n",
      "epoch 66; iter: 0; batch classifier loss: 0.106768; batch adversarial loss: 0.420612\n",
      "epoch 67; iter: 0; batch classifier loss: 0.116889; batch adversarial loss: 0.492610\n",
      "epoch 68; iter: 0; batch classifier loss: 0.099622; batch adversarial loss: 0.441248\n",
      "epoch 69; iter: 0; batch classifier loss: 0.146317; batch adversarial loss: 0.456939\n",
      "epoch 70; iter: 0; batch classifier loss: 0.138256; batch adversarial loss: 0.400524\n",
      "epoch 71; iter: 0; batch classifier loss: 0.180354; batch adversarial loss: 0.441671\n",
      "epoch 72; iter: 0; batch classifier loss: 0.195652; batch adversarial loss: 0.491949\n",
      "epoch 73; iter: 0; batch classifier loss: 0.142928; batch adversarial loss: 0.498563\n",
      "epoch 74; iter: 0; batch classifier loss: 0.177785; batch adversarial loss: 0.591034\n",
      "epoch 75; iter: 0; batch classifier loss: 0.135634; batch adversarial loss: 0.461909\n",
      "epoch 76; iter: 0; batch classifier loss: 0.182023; batch adversarial loss: 0.445156\n",
      "epoch 77; iter: 0; batch classifier loss: 0.132064; batch adversarial loss: 0.467608\n",
      "epoch 78; iter: 0; batch classifier loss: 0.163358; batch adversarial loss: 0.391969\n",
      "epoch 79; iter: 0; batch classifier loss: 0.207710; batch adversarial loss: 0.435773\n",
      "epoch 80; iter: 0; batch classifier loss: 0.152228; batch adversarial loss: 0.443503\n",
      "epoch 81; iter: 0; batch classifier loss: 0.127711; batch adversarial loss: 0.487324\n",
      "epoch 82; iter: 0; batch classifier loss: 0.113842; batch adversarial loss: 0.633030\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066691; batch adversarial loss: 0.478194\n",
      "epoch 84; iter: 0; batch classifier loss: 0.092463; batch adversarial loss: 0.473757\n",
      "epoch 85; iter: 0; batch classifier loss: 0.114235; batch adversarial loss: 0.549592\n",
      "epoch 86; iter: 0; batch classifier loss: 0.148310; batch adversarial loss: 0.479807\n",
      "epoch 87; iter: 0; batch classifier loss: 0.131843; batch adversarial loss: 0.505048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.108589; batch adversarial loss: 0.430090\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078233; batch adversarial loss: 0.539975\n",
      "epoch 90; iter: 0; batch classifier loss: 0.094085; batch adversarial loss: 0.486265\n",
      "epoch 91; iter: 0; batch classifier loss: 0.095684; batch adversarial loss: 0.488591\n",
      "epoch 92; iter: 0; batch classifier loss: 0.095790; batch adversarial loss: 0.458027\n",
      "epoch 93; iter: 0; batch classifier loss: 0.091826; batch adversarial loss: 0.390216\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070907; batch adversarial loss: 0.499819\n",
      "epoch 95; iter: 0; batch classifier loss: 0.108714; batch adversarial loss: 0.406354\n",
      "epoch 96; iter: 0; batch classifier loss: 0.116415; batch adversarial loss: 0.504199\n",
      "epoch 97; iter: 0; batch classifier loss: 0.106058; batch adversarial loss: 0.377554\n",
      "epoch 98; iter: 0; batch classifier loss: 0.065524; batch adversarial loss: 0.434666\n",
      "epoch 99; iter: 0; batch classifier loss: 0.101926; batch adversarial loss: 0.487986\n",
      "epoch 100; iter: 0; batch classifier loss: 0.100045; batch adversarial loss: 0.541623\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061362; batch adversarial loss: 0.454604\n",
      "epoch 102; iter: 0; batch classifier loss: 0.105782; batch adversarial loss: 0.491791\n",
      "epoch 103; iter: 0; batch classifier loss: 0.103922; batch adversarial loss: 0.578060\n",
      "epoch 104; iter: 0; batch classifier loss: 0.092329; batch adversarial loss: 0.448102\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055101; batch adversarial loss: 0.393904\n",
      "epoch 106; iter: 0; batch classifier loss: 0.135563; batch adversarial loss: 0.455403\n",
      "epoch 107; iter: 0; batch classifier loss: 0.138871; batch adversarial loss: 0.497810\n",
      "epoch 108; iter: 0; batch classifier loss: 0.050881; batch adversarial loss: 0.440844\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064701; batch adversarial loss: 0.421559\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059138; batch adversarial loss: 0.533692\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035912; batch adversarial loss: 0.550847\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042267; batch adversarial loss: 0.484200\n",
      "epoch 113; iter: 0; batch classifier loss: 0.092188; batch adversarial loss: 0.511150\n",
      "epoch 114; iter: 0; batch classifier loss: 0.058411; batch adversarial loss: 0.415983\n",
      "epoch 115; iter: 0; batch classifier loss: 0.078624; batch adversarial loss: 0.472680\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044853; batch adversarial loss: 0.456778\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039850; batch adversarial loss: 0.455195\n",
      "epoch 118; iter: 0; batch classifier loss: 0.066229; batch adversarial loss: 0.423442\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045693; batch adversarial loss: 0.505117\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050592; batch adversarial loss: 0.448308\n",
      "epoch 121; iter: 0; batch classifier loss: 0.063194; batch adversarial loss: 0.502271\n",
      "epoch 122; iter: 0; batch classifier loss: 0.063860; batch adversarial loss: 0.342275\n",
      "epoch 123; iter: 0; batch classifier loss: 0.018850; batch adversarial loss: 0.504333\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024156; batch adversarial loss: 0.507882\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058672; batch adversarial loss: 0.491349\n",
      "epoch 126; iter: 0; batch classifier loss: 0.087294; batch adversarial loss: 0.468933\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042128; batch adversarial loss: 0.345486\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054116; batch adversarial loss: 0.432777\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035132; batch adversarial loss: 0.389425\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036761; batch adversarial loss: 0.497452\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041223; batch adversarial loss: 0.427113\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058411; batch adversarial loss: 0.477404\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043159; batch adversarial loss: 0.469545\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038623; batch adversarial loss: 0.371826\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060924; batch adversarial loss: 0.464011\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019929; batch adversarial loss: 0.475766\n",
      "epoch 137; iter: 0; batch classifier loss: 0.062122; batch adversarial loss: 0.415361\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028211; batch adversarial loss: 0.567181\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033435; batch adversarial loss: 0.481949\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027721; batch adversarial loss: 0.448970\n",
      "epoch 141; iter: 0; batch classifier loss: 0.079883; batch adversarial loss: 0.476903\n",
      "epoch 142; iter: 0; batch classifier loss: 0.038608; batch adversarial loss: 0.425871\n",
      "epoch 143; iter: 0; batch classifier loss: 0.058458; batch adversarial loss: 0.420759\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034829; batch adversarial loss: 0.480747\n",
      "epoch 145; iter: 0; batch classifier loss: 0.063404; batch adversarial loss: 0.435449\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048351; batch adversarial loss: 0.487625\n",
      "epoch 147; iter: 0; batch classifier loss: 0.062799; batch adversarial loss: 0.467358\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026420; batch adversarial loss: 0.410198\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034655; batch adversarial loss: 0.444170\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038866; batch adversarial loss: 0.458295\n",
      "epoch 151; iter: 0; batch classifier loss: 0.092664; batch adversarial loss: 0.452086\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043912; batch adversarial loss: 0.494472\n",
      "epoch 153; iter: 0; batch classifier loss: 0.054385; batch adversarial loss: 0.447583\n",
      "epoch 154; iter: 0; batch classifier loss: 0.045458; batch adversarial loss: 0.448639\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029310; batch adversarial loss: 0.506478\n",
      "epoch 156; iter: 0; batch classifier loss: 0.051180; batch adversarial loss: 0.463971\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024241; batch adversarial loss: 0.511971\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048837; batch adversarial loss: 0.456582\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011989; batch adversarial loss: 0.534145\n",
      "epoch 160; iter: 0; batch classifier loss: 0.042823; batch adversarial loss: 0.461725\n",
      "epoch 161; iter: 0; batch classifier loss: 0.048868; batch adversarial loss: 0.525382\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038154; batch adversarial loss: 0.442377\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016893; batch adversarial loss: 0.504266\n",
      "epoch 164; iter: 0; batch classifier loss: 0.040758; batch adversarial loss: 0.487219\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044189; batch adversarial loss: 0.404719\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014101; batch adversarial loss: 0.358149\n",
      "epoch 167; iter: 0; batch classifier loss: 0.049753; batch adversarial loss: 0.590479\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020696; batch adversarial loss: 0.458191\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031594; batch adversarial loss: 0.514118\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021709; batch adversarial loss: 0.404596\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022051; batch adversarial loss: 0.480123\n",
      "epoch 172; iter: 0; batch classifier loss: 0.053568; batch adversarial loss: 0.393341\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018182; batch adversarial loss: 0.443084\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040806; batch adversarial loss: 0.504976\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035679; batch adversarial loss: 0.403645\n",
      "epoch 176; iter: 0; batch classifier loss: 0.071790; batch adversarial loss: 0.472309\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032651; batch adversarial loss: 0.447752\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014071; batch adversarial loss: 0.503983\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012904; batch adversarial loss: 0.461505\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030576; batch adversarial loss: 0.402086\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032875; batch adversarial loss: 0.426739\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027542; batch adversarial loss: 0.448739\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030748; batch adversarial loss: 0.396065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.038656; batch adversarial loss: 0.494693\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006539; batch adversarial loss: 0.548114\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034116; batch adversarial loss: 0.546352\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017126; batch adversarial loss: 0.392508\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033784; batch adversarial loss: 0.451981\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013700; batch adversarial loss: 0.413468\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015733; batch adversarial loss: 0.452591\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032838; batch adversarial loss: 0.386362\n",
      "epoch 192; iter: 0; batch classifier loss: 0.052543; batch adversarial loss: 0.441954\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023246; batch adversarial loss: 0.455662\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011930; batch adversarial loss: 0.377298\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024242; batch adversarial loss: 0.435309\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015930; batch adversarial loss: 0.451016\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025557; batch adversarial loss: 0.564428\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017058; batch adversarial loss: 0.512389\n",
      "epoch 199; iter: 0; batch classifier loss: 0.041309; batch adversarial loss: 0.449403\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680170; batch adversarial loss: 0.706906\n",
      "epoch 1; iter: 0; batch classifier loss: 0.517830; batch adversarial loss: 0.696898\n",
      "epoch 2; iter: 0; batch classifier loss: 0.421765; batch adversarial loss: 0.649829\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393620; batch adversarial loss: 0.604976\n",
      "epoch 4; iter: 0; batch classifier loss: 0.298135; batch adversarial loss: 0.564561\n",
      "epoch 5; iter: 0; batch classifier loss: 0.289751; batch adversarial loss: 0.556164\n",
      "epoch 6; iter: 0; batch classifier loss: 0.276937; batch adversarial loss: 0.550499\n",
      "epoch 7; iter: 0; batch classifier loss: 0.275544; batch adversarial loss: 0.505086\n",
      "epoch 8; iter: 0; batch classifier loss: 0.199690; batch adversarial loss: 0.518747\n",
      "epoch 9; iter: 0; batch classifier loss: 0.240038; batch adversarial loss: 0.497154\n",
      "epoch 10; iter: 0; batch classifier loss: 0.246057; batch adversarial loss: 0.449312\n",
      "epoch 11; iter: 0; batch classifier loss: 0.270190; batch adversarial loss: 0.481182\n",
      "epoch 12; iter: 0; batch classifier loss: 0.232725; batch adversarial loss: 0.468075\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232160; batch adversarial loss: 0.470112\n",
      "epoch 14; iter: 0; batch classifier loss: 0.230902; batch adversarial loss: 0.465428\n",
      "epoch 15; iter: 0; batch classifier loss: 0.131548; batch adversarial loss: 0.493369\n",
      "epoch 16; iter: 0; batch classifier loss: 0.188514; batch adversarial loss: 0.432249\n",
      "epoch 17; iter: 0; batch classifier loss: 0.190185; batch adversarial loss: 0.393229\n",
      "epoch 18; iter: 0; batch classifier loss: 0.151974; batch adversarial loss: 0.452563\n",
      "epoch 19; iter: 0; batch classifier loss: 0.133519; batch adversarial loss: 0.458683\n",
      "epoch 20; iter: 0; batch classifier loss: 0.158796; batch adversarial loss: 0.448703\n",
      "epoch 21; iter: 0; batch classifier loss: 0.163842; batch adversarial loss: 0.509633\n",
      "epoch 22; iter: 0; batch classifier loss: 0.150787; batch adversarial loss: 0.435555\n",
      "epoch 23; iter: 0; batch classifier loss: 0.204124; batch adversarial loss: 0.453768\n",
      "epoch 24; iter: 0; batch classifier loss: 0.128645; batch adversarial loss: 0.354618\n",
      "epoch 25; iter: 0; batch classifier loss: 0.191486; batch adversarial loss: 0.426380\n",
      "epoch 26; iter: 0; batch classifier loss: 0.146109; batch adversarial loss: 0.393744\n",
      "epoch 27; iter: 0; batch classifier loss: 0.180374; batch adversarial loss: 0.419119\n",
      "epoch 28; iter: 0; batch classifier loss: 0.170869; batch adversarial loss: 0.361165\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179707; batch adversarial loss: 0.344684\n",
      "epoch 30; iter: 0; batch classifier loss: 0.154005; batch adversarial loss: 0.346359\n",
      "epoch 31; iter: 0; batch classifier loss: 0.110301; batch adversarial loss: 0.345148\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140134; batch adversarial loss: 0.380611\n",
      "epoch 33; iter: 0; batch classifier loss: 0.104241; batch adversarial loss: 0.365956\n",
      "epoch 34; iter: 0; batch classifier loss: 0.129548; batch adversarial loss: 0.388315\n",
      "epoch 35; iter: 0; batch classifier loss: 0.187004; batch adversarial loss: 0.383377\n",
      "epoch 36; iter: 0; batch classifier loss: 0.137732; batch adversarial loss: 0.425221\n",
      "epoch 37; iter: 0; batch classifier loss: 0.150900; batch adversarial loss: 0.402443\n",
      "epoch 38; iter: 0; batch classifier loss: 0.178195; batch adversarial loss: 0.432961\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125714; batch adversarial loss: 0.399659\n",
      "epoch 40; iter: 0; batch classifier loss: 0.140256; batch adversarial loss: 0.396749\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116852; batch adversarial loss: 0.386126\n",
      "epoch 42; iter: 0; batch classifier loss: 0.195787; batch adversarial loss: 0.359878\n",
      "epoch 43; iter: 0; batch classifier loss: 0.100311; batch adversarial loss: 0.394940\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105318; batch adversarial loss: 0.318803\n",
      "epoch 45; iter: 0; batch classifier loss: 0.076225; batch adversarial loss: 0.438196\n",
      "epoch 46; iter: 0; batch classifier loss: 0.074034; batch adversarial loss: 0.367873\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103233; batch adversarial loss: 0.451718\n",
      "epoch 48; iter: 0; batch classifier loss: 0.111409; batch adversarial loss: 0.378053\n",
      "epoch 49; iter: 0; batch classifier loss: 0.122845; batch adversarial loss: 0.417311\n",
      "epoch 50; iter: 0; batch classifier loss: 0.095980; batch adversarial loss: 0.406192\n",
      "epoch 51; iter: 0; batch classifier loss: 0.085815; batch adversarial loss: 0.401266\n",
      "epoch 52; iter: 0; batch classifier loss: 0.083264; batch adversarial loss: 0.388380\n",
      "epoch 53; iter: 0; batch classifier loss: 0.137167; batch adversarial loss: 0.435924\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096709; batch adversarial loss: 0.392612\n",
      "epoch 55; iter: 0; batch classifier loss: 0.081889; batch adversarial loss: 0.423583\n",
      "epoch 56; iter: 0; batch classifier loss: 0.080330; batch adversarial loss: 0.340203\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072865; batch adversarial loss: 0.441704\n",
      "epoch 58; iter: 0; batch classifier loss: 0.132261; batch adversarial loss: 0.467999\n",
      "epoch 59; iter: 0; batch classifier loss: 0.093378; batch adversarial loss: 0.349078\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081903; batch adversarial loss: 0.416668\n",
      "epoch 61; iter: 0; batch classifier loss: 0.098038; batch adversarial loss: 0.467097\n",
      "epoch 62; iter: 0; batch classifier loss: 0.053035; batch adversarial loss: 0.341826\n",
      "epoch 63; iter: 0; batch classifier loss: 0.069806; batch adversarial loss: 0.470027\n",
      "epoch 64; iter: 0; batch classifier loss: 0.071476; batch adversarial loss: 0.425657\n",
      "epoch 65; iter: 0; batch classifier loss: 0.123827; batch adversarial loss: 0.440335\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089248; batch adversarial loss: 0.402610\n",
      "epoch 67; iter: 0; batch classifier loss: 0.072127; batch adversarial loss: 0.378028\n",
      "epoch 68; iter: 0; batch classifier loss: 0.089278; batch adversarial loss: 0.455786\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102665; batch adversarial loss: 0.382650\n",
      "epoch 70; iter: 0; batch classifier loss: 0.075159; batch adversarial loss: 0.423207\n",
      "epoch 71; iter: 0; batch classifier loss: 0.095613; batch adversarial loss: 0.410741\n",
      "epoch 72; iter: 0; batch classifier loss: 0.067006; batch adversarial loss: 0.400256\n",
      "epoch 73; iter: 0; batch classifier loss: 0.071769; batch adversarial loss: 0.465054\n",
      "epoch 74; iter: 0; batch classifier loss: 0.096422; batch adversarial loss: 0.456821\n",
      "epoch 75; iter: 0; batch classifier loss: 0.112796; batch adversarial loss: 0.480757\n",
      "epoch 76; iter: 0; batch classifier loss: 0.067239; batch adversarial loss: 0.403767\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062930; batch adversarial loss: 0.444682\n",
      "epoch 78; iter: 0; batch classifier loss: 0.052561; batch adversarial loss: 0.450621\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063085; batch adversarial loss: 0.337125\n",
      "epoch 80; iter: 0; batch classifier loss: 0.099417; batch adversarial loss: 0.411886\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067812; batch adversarial loss: 0.407315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.037421; batch adversarial loss: 0.389914\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068613; batch adversarial loss: 0.329044\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051327; batch adversarial loss: 0.370867\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065190; batch adversarial loss: 0.430509\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081518; batch adversarial loss: 0.429503\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066840; batch adversarial loss: 0.375823\n",
      "epoch 88; iter: 0; batch classifier loss: 0.077697; batch adversarial loss: 0.446930\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075851; batch adversarial loss: 0.338244\n",
      "epoch 90; iter: 0; batch classifier loss: 0.096192; batch adversarial loss: 0.467512\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067667; batch adversarial loss: 0.395190\n",
      "epoch 92; iter: 0; batch classifier loss: 0.049233; batch adversarial loss: 0.475601\n",
      "epoch 93; iter: 0; batch classifier loss: 0.070778; batch adversarial loss: 0.424970\n",
      "epoch 94; iter: 0; batch classifier loss: 0.059022; batch adversarial loss: 0.395580\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080553; batch adversarial loss: 0.439151\n",
      "epoch 96; iter: 0; batch classifier loss: 0.067593; batch adversarial loss: 0.305116\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048725; batch adversarial loss: 0.396138\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048305; batch adversarial loss: 0.352598\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061186; batch adversarial loss: 0.468886\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054329; batch adversarial loss: 0.549906\n",
      "epoch 101; iter: 0; batch classifier loss: 0.069760; batch adversarial loss: 0.394500\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055924; batch adversarial loss: 0.483191\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038955; batch adversarial loss: 0.459778\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037915; batch adversarial loss: 0.428622\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047041; batch adversarial loss: 0.421477\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064371; batch adversarial loss: 0.475022\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024658; batch adversarial loss: 0.426753\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073050; batch adversarial loss: 0.423314\n",
      "epoch 109; iter: 0; batch classifier loss: 0.025062; batch adversarial loss: 0.491606\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027460; batch adversarial loss: 0.509597\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062533; batch adversarial loss: 0.460366\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047605; batch adversarial loss: 0.501273\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039648; batch adversarial loss: 0.524599\n",
      "epoch 114; iter: 0; batch classifier loss: 0.017875; batch adversarial loss: 0.507703\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024200; batch adversarial loss: 0.427448\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042106; batch adversarial loss: 0.468398\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039681; batch adversarial loss: 0.431638\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049780; batch adversarial loss: 0.432732\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039367; batch adversarial loss: 0.481235\n",
      "epoch 120; iter: 0; batch classifier loss: 0.121174; batch adversarial loss: 0.671782\n",
      "epoch 121; iter: 0; batch classifier loss: 0.075275; batch adversarial loss: 0.589705\n",
      "epoch 122; iter: 0; batch classifier loss: 0.103883; batch adversarial loss: 0.616152\n",
      "epoch 123; iter: 0; batch classifier loss: 0.066006; batch adversarial loss: 0.475339\n",
      "epoch 124; iter: 0; batch classifier loss: 0.128306; batch adversarial loss: 0.589189\n",
      "epoch 125; iter: 0; batch classifier loss: 0.067992; batch adversarial loss: 0.598067\n",
      "epoch 126; iter: 0; batch classifier loss: 0.257149; batch adversarial loss: 0.792797\n",
      "epoch 127; iter: 0; batch classifier loss: 0.109364; batch adversarial loss: 0.603335\n",
      "epoch 128; iter: 0; batch classifier loss: 0.085955; batch adversarial loss: 0.584054\n",
      "epoch 129; iter: 0; batch classifier loss: 0.160685; batch adversarial loss: 0.651389\n",
      "epoch 130; iter: 0; batch classifier loss: 0.133231; batch adversarial loss: 0.543431\n",
      "epoch 131; iter: 0; batch classifier loss: 0.119583; batch adversarial loss: 0.536031\n",
      "epoch 132; iter: 0; batch classifier loss: 0.184229; batch adversarial loss: 0.611202\n",
      "epoch 133; iter: 0; batch classifier loss: 0.114614; batch adversarial loss: 0.516274\n",
      "epoch 134; iter: 0; batch classifier loss: 0.132234; batch adversarial loss: 0.539994\n",
      "epoch 135; iter: 0; batch classifier loss: 0.143239; batch adversarial loss: 0.692407\n",
      "epoch 136; iter: 0; batch classifier loss: 0.074948; batch adversarial loss: 0.463551\n",
      "epoch 137; iter: 0; batch classifier loss: 0.148053; batch adversarial loss: 0.542963\n",
      "epoch 138; iter: 0; batch classifier loss: 0.143550; batch adversarial loss: 0.603478\n",
      "epoch 139; iter: 0; batch classifier loss: 0.148170; batch adversarial loss: 0.594560\n",
      "epoch 140; iter: 0; batch classifier loss: 0.119590; batch adversarial loss: 0.472037\n",
      "epoch 141; iter: 0; batch classifier loss: 0.105651; batch adversarial loss: 0.565243\n",
      "epoch 142; iter: 0; batch classifier loss: 0.142338; batch adversarial loss: 0.612044\n",
      "epoch 143; iter: 0; batch classifier loss: 0.202438; batch adversarial loss: 0.556742\n",
      "epoch 144; iter: 0; batch classifier loss: 0.122170; batch adversarial loss: 0.479191\n",
      "epoch 145; iter: 0; batch classifier loss: 0.119456; batch adversarial loss: 0.494266\n",
      "epoch 146; iter: 0; batch classifier loss: 0.146764; batch adversarial loss: 0.586226\n",
      "epoch 147; iter: 0; batch classifier loss: 0.119900; batch adversarial loss: 0.506188\n",
      "epoch 148; iter: 0; batch classifier loss: 0.149068; batch adversarial loss: 0.514980\n",
      "epoch 149; iter: 0; batch classifier loss: 0.125537; batch adversarial loss: 0.477702\n",
      "epoch 150; iter: 0; batch classifier loss: 0.104896; batch adversarial loss: 0.526056\n",
      "epoch 151; iter: 0; batch classifier loss: 0.095873; batch adversarial loss: 0.422574\n",
      "epoch 152; iter: 0; batch classifier loss: 0.126165; batch adversarial loss: 0.463563\n",
      "epoch 153; iter: 0; batch classifier loss: 0.089694; batch adversarial loss: 0.526919\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031959; batch adversarial loss: 0.371484\n",
      "epoch 155; iter: 0; batch classifier loss: 0.141832; batch adversarial loss: 0.543916\n",
      "epoch 156; iter: 0; batch classifier loss: 0.086589; batch adversarial loss: 0.480910\n",
      "epoch 157; iter: 0; batch classifier loss: 0.123435; batch adversarial loss: 0.518736\n",
      "epoch 158; iter: 0; batch classifier loss: 0.087282; batch adversarial loss: 0.434034\n",
      "epoch 159; iter: 0; batch classifier loss: 0.089175; batch adversarial loss: 0.481180\n",
      "epoch 160; iter: 0; batch classifier loss: 0.066273; batch adversarial loss: 0.445483\n",
      "epoch 161; iter: 0; batch classifier loss: 0.157671; batch adversarial loss: 0.543444\n",
      "epoch 162; iter: 0; batch classifier loss: 0.099461; batch adversarial loss: 0.508378\n",
      "epoch 163; iter: 0; batch classifier loss: 0.084418; batch adversarial loss: 0.489224\n",
      "epoch 164; iter: 0; batch classifier loss: 0.105723; batch adversarial loss: 0.453789\n",
      "epoch 165; iter: 0; batch classifier loss: 0.136053; batch adversarial loss: 0.482919\n",
      "epoch 166; iter: 0; batch classifier loss: 0.084817; batch adversarial loss: 0.459241\n",
      "epoch 167; iter: 0; batch classifier loss: 0.044522; batch adversarial loss: 0.460064\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036691; batch adversarial loss: 0.491032\n",
      "epoch 169; iter: 0; batch classifier loss: 0.054429; batch adversarial loss: 0.373813\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040656; batch adversarial loss: 0.496851\n",
      "epoch 171; iter: 0; batch classifier loss: 0.042614; batch adversarial loss: 0.372792\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026896; batch adversarial loss: 0.554547\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019824; batch adversarial loss: 0.565802\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027898; batch adversarial loss: 0.395033\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034217; batch adversarial loss: 0.483272\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045407; batch adversarial loss: 0.446732\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037679; batch adversarial loss: 0.502447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.069294; batch adversarial loss: 0.457889\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044271; batch adversarial loss: 0.451954\n",
      "epoch 180; iter: 0; batch classifier loss: 0.043954; batch adversarial loss: 0.444198\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029889; batch adversarial loss: 0.341448\n",
      "epoch 182; iter: 0; batch classifier loss: 0.099806; batch adversarial loss: 0.535565\n",
      "epoch 183; iter: 0; batch classifier loss: 0.072869; batch adversarial loss: 0.436596\n",
      "epoch 184; iter: 0; batch classifier loss: 0.080626; batch adversarial loss: 0.458583\n",
      "epoch 185; iter: 0; batch classifier loss: 0.089968; batch adversarial loss: 0.461102\n",
      "epoch 186; iter: 0; batch classifier loss: 0.068275; batch adversarial loss: 0.447376\n",
      "epoch 187; iter: 0; batch classifier loss: 0.048029; batch adversarial loss: 0.513626\n",
      "epoch 188; iter: 0; batch classifier loss: 0.105442; batch adversarial loss: 0.388700\n",
      "epoch 189; iter: 0; batch classifier loss: 0.056163; batch adversarial loss: 0.401849\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050962; batch adversarial loss: 0.444932\n",
      "epoch 191; iter: 0; batch classifier loss: 0.071050; batch adversarial loss: 0.534825\n",
      "epoch 192; iter: 0; batch classifier loss: 0.047116; batch adversarial loss: 0.447891\n",
      "epoch 193; iter: 0; batch classifier loss: 0.049986; batch adversarial loss: 0.548166\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031105; batch adversarial loss: 0.545926\n",
      "epoch 195; iter: 0; batch classifier loss: 0.089228; batch adversarial loss: 0.475793\n",
      "epoch 196; iter: 0; batch classifier loss: 0.101589; batch adversarial loss: 0.515551\n",
      "epoch 197; iter: 0; batch classifier loss: 0.065746; batch adversarial loss: 0.512711\n",
      "epoch 198; iter: 0; batch classifier loss: 0.069500; batch adversarial loss: 0.539122\n",
      "epoch 199; iter: 0; batch classifier loss: 0.105342; batch adversarial loss: 0.490265\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685711; batch adversarial loss: 0.751504\n",
      "epoch 1; iter: 0; batch classifier loss: 0.418767; batch adversarial loss: 0.712487\n",
      "epoch 2; iter: 0; batch classifier loss: 0.410664; batch adversarial loss: 0.682927\n",
      "epoch 3; iter: 0; batch classifier loss: 0.386779; batch adversarial loss: 0.646339\n",
      "epoch 4; iter: 0; batch classifier loss: 0.347121; batch adversarial loss: 0.608286\n",
      "epoch 5; iter: 0; batch classifier loss: 0.322336; batch adversarial loss: 0.567561\n",
      "epoch 6; iter: 0; batch classifier loss: 0.334153; batch adversarial loss: 0.569354\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300635; batch adversarial loss: 0.532900\n",
      "epoch 8; iter: 0; batch classifier loss: 0.270570; batch adversarial loss: 0.505254\n",
      "epoch 9; iter: 0; batch classifier loss: 0.277869; batch adversarial loss: 0.540836\n",
      "epoch 10; iter: 0; batch classifier loss: 0.233970; batch adversarial loss: 0.486542\n",
      "epoch 11; iter: 0; batch classifier loss: 0.240140; batch adversarial loss: 0.526191\n",
      "epoch 12; iter: 0; batch classifier loss: 0.299833; batch adversarial loss: 0.503280\n",
      "epoch 13; iter: 0; batch classifier loss: 0.218915; batch adversarial loss: 0.531166\n",
      "epoch 14; iter: 0; batch classifier loss: 0.284894; batch adversarial loss: 0.504545\n",
      "epoch 15; iter: 0; batch classifier loss: 0.157692; batch adversarial loss: 0.486672\n",
      "epoch 16; iter: 0; batch classifier loss: 0.139870; batch adversarial loss: 0.411686\n",
      "epoch 17; iter: 0; batch classifier loss: 0.163665; batch adversarial loss: 0.463032\n",
      "epoch 18; iter: 0; batch classifier loss: 0.170750; batch adversarial loss: 0.466335\n",
      "epoch 19; iter: 0; batch classifier loss: 0.196255; batch adversarial loss: 0.399004\n",
      "epoch 20; iter: 0; batch classifier loss: 0.156126; batch adversarial loss: 0.551377\n",
      "epoch 21; iter: 0; batch classifier loss: 0.146291; batch adversarial loss: 0.497386\n",
      "epoch 22; iter: 0; batch classifier loss: 0.145532; batch adversarial loss: 0.531339\n",
      "epoch 23; iter: 0; batch classifier loss: 0.145497; batch adversarial loss: 0.379125\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213465; batch adversarial loss: 0.406901\n",
      "epoch 25; iter: 0; batch classifier loss: 0.150225; batch adversarial loss: 0.389104\n",
      "epoch 26; iter: 0; batch classifier loss: 0.169254; batch adversarial loss: 0.413691\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152099; batch adversarial loss: 0.366978\n",
      "epoch 28; iter: 0; batch classifier loss: 0.196025; batch adversarial loss: 0.452225\n",
      "epoch 29; iter: 0; batch classifier loss: 0.153894; batch adversarial loss: 0.446254\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138565; batch adversarial loss: 0.376517\n",
      "epoch 31; iter: 0; batch classifier loss: 0.150890; batch adversarial loss: 0.425355\n",
      "epoch 32; iter: 0; batch classifier loss: 0.130087; batch adversarial loss: 0.423254\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163400; batch adversarial loss: 0.429140\n",
      "epoch 34; iter: 0; batch classifier loss: 0.189276; batch adversarial loss: 0.406170\n",
      "epoch 35; iter: 0; batch classifier loss: 0.175461; batch adversarial loss: 0.277277\n",
      "epoch 36; iter: 0; batch classifier loss: 0.133767; batch adversarial loss: 0.458108\n",
      "epoch 37; iter: 0; batch classifier loss: 0.120115; batch adversarial loss: 0.407072\n",
      "epoch 38; iter: 0; batch classifier loss: 0.133553; batch adversarial loss: 0.399614\n",
      "epoch 39; iter: 0; batch classifier loss: 0.108384; batch adversarial loss: 0.365794\n",
      "epoch 40; iter: 0; batch classifier loss: 0.130621; batch adversarial loss: 0.401528\n",
      "epoch 41; iter: 0; batch classifier loss: 0.165917; batch adversarial loss: 0.535011\n",
      "epoch 42; iter: 0; batch classifier loss: 0.130067; batch adversarial loss: 0.451780\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104432; batch adversarial loss: 0.313602\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136051; batch adversarial loss: 0.415502\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097023; batch adversarial loss: 0.415381\n",
      "epoch 46; iter: 0; batch classifier loss: 0.090803; batch adversarial loss: 0.384167\n",
      "epoch 47; iter: 0; batch classifier loss: 0.090017; batch adversarial loss: 0.366192\n",
      "epoch 48; iter: 0; batch classifier loss: 0.069518; batch adversarial loss: 0.410283\n",
      "epoch 49; iter: 0; batch classifier loss: 0.160098; batch adversarial loss: 0.391073\n",
      "epoch 50; iter: 0; batch classifier loss: 0.120092; batch adversarial loss: 0.434611\n",
      "epoch 51; iter: 0; batch classifier loss: 0.095144; batch adversarial loss: 0.377238\n",
      "epoch 52; iter: 0; batch classifier loss: 0.137658; batch adversarial loss: 0.359842\n",
      "epoch 53; iter: 0; batch classifier loss: 0.100353; batch adversarial loss: 0.469930\n",
      "epoch 54; iter: 0; batch classifier loss: 0.088794; batch adversarial loss: 0.401311\n",
      "epoch 55; iter: 0; batch classifier loss: 0.108323; batch adversarial loss: 0.459419\n",
      "epoch 56; iter: 0; batch classifier loss: 0.075051; batch adversarial loss: 0.380953\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079849; batch adversarial loss: 0.359257\n",
      "epoch 58; iter: 0; batch classifier loss: 0.073757; batch adversarial loss: 0.449258\n",
      "epoch 59; iter: 0; batch classifier loss: 0.094476; batch adversarial loss: 0.466902\n",
      "epoch 60; iter: 0; batch classifier loss: 0.069131; batch adversarial loss: 0.421874\n",
      "epoch 61; iter: 0; batch classifier loss: 0.094737; batch adversarial loss: 0.502381\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087424; batch adversarial loss: 0.319701\n",
      "epoch 63; iter: 0; batch classifier loss: 0.058551; batch adversarial loss: 0.389899\n",
      "epoch 64; iter: 0; batch classifier loss: 0.094885; batch adversarial loss: 0.347627\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070002; batch adversarial loss: 0.443591\n",
      "epoch 66; iter: 0; batch classifier loss: 0.051182; batch adversarial loss: 0.415590\n",
      "epoch 67; iter: 0; batch classifier loss: 0.120016; batch adversarial loss: 0.369690\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109898; batch adversarial loss: 0.411993\n",
      "epoch 69; iter: 0; batch classifier loss: 0.077101; batch adversarial loss: 0.445084\n",
      "epoch 70; iter: 0; batch classifier loss: 0.061556; batch adversarial loss: 0.423991\n",
      "epoch 71; iter: 0; batch classifier loss: 0.094962; batch adversarial loss: 0.442889\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062036; batch adversarial loss: 0.454226\n",
      "epoch 73; iter: 0; batch classifier loss: 0.097949; batch adversarial loss: 0.453326\n",
      "epoch 74; iter: 0; batch classifier loss: 0.047535; batch adversarial loss: 0.339564\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068642; batch adversarial loss: 0.448550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.087739; batch adversarial loss: 0.399731\n",
      "epoch 77; iter: 0; batch classifier loss: 0.047885; batch adversarial loss: 0.478684\n",
      "epoch 78; iter: 0; batch classifier loss: 0.120371; batch adversarial loss: 0.382752\n",
      "epoch 79; iter: 0; batch classifier loss: 0.110515; batch adversarial loss: 0.419480\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064054; batch adversarial loss: 0.391047\n",
      "epoch 81; iter: 0; batch classifier loss: 0.100605; batch adversarial loss: 0.486227\n",
      "epoch 82; iter: 0; batch classifier loss: 0.134992; batch adversarial loss: 0.382173\n",
      "epoch 83; iter: 0; batch classifier loss: 0.088836; batch adversarial loss: 0.437792\n",
      "epoch 84; iter: 0; batch classifier loss: 0.099477; batch adversarial loss: 0.542869\n",
      "epoch 85; iter: 0; batch classifier loss: 0.081854; batch adversarial loss: 0.449000\n",
      "epoch 86; iter: 0; batch classifier loss: 0.112356; batch adversarial loss: 0.420090\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062132; batch adversarial loss: 0.365385\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070649; batch adversarial loss: 0.422502\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050017; batch adversarial loss: 0.393661\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064008; batch adversarial loss: 0.374238\n",
      "epoch 91; iter: 0; batch classifier loss: 0.098184; batch adversarial loss: 0.469656\n",
      "epoch 92; iter: 0; batch classifier loss: 0.083173; batch adversarial loss: 0.422562\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067102; batch adversarial loss: 0.360835\n",
      "epoch 94; iter: 0; batch classifier loss: 0.065316; batch adversarial loss: 0.372086\n",
      "epoch 95; iter: 0; batch classifier loss: 0.086764; batch adversarial loss: 0.435561\n",
      "epoch 96; iter: 0; batch classifier loss: 0.091542; batch adversarial loss: 0.510960\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081214; batch adversarial loss: 0.383781\n",
      "epoch 98; iter: 0; batch classifier loss: 0.073763; batch adversarial loss: 0.390510\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078327; batch adversarial loss: 0.470379\n",
      "epoch 100; iter: 0; batch classifier loss: 0.117893; batch adversarial loss: 0.385334\n",
      "epoch 101; iter: 0; batch classifier loss: 0.076212; batch adversarial loss: 0.486055\n",
      "epoch 102; iter: 0; batch classifier loss: 0.072111; batch adversarial loss: 0.377920\n",
      "epoch 103; iter: 0; batch classifier loss: 0.117354; batch adversarial loss: 0.417204\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031481; batch adversarial loss: 0.396692\n",
      "epoch 105; iter: 0; batch classifier loss: 0.074167; batch adversarial loss: 0.395260\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050062; batch adversarial loss: 0.425750\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059862; batch adversarial loss: 0.384691\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039067; batch adversarial loss: 0.492403\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051898; batch adversarial loss: 0.368990\n",
      "epoch 110; iter: 0; batch classifier loss: 0.072992; batch adversarial loss: 0.365831\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055131; batch adversarial loss: 0.371315\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040506; batch adversarial loss: 0.429242\n",
      "epoch 113; iter: 0; batch classifier loss: 0.068478; batch adversarial loss: 0.442058\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040249; batch adversarial loss: 0.390989\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054110; batch adversarial loss: 0.354452\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039399; batch adversarial loss: 0.483153\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029267; batch adversarial loss: 0.410229\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041202; batch adversarial loss: 0.414651\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025101; batch adversarial loss: 0.486731\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031709; batch adversarial loss: 0.421376\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049230; batch adversarial loss: 0.396276\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032468; batch adversarial loss: 0.434292\n",
      "epoch 123; iter: 0; batch classifier loss: 0.087471; batch adversarial loss: 0.477268\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036286; batch adversarial loss: 0.397481\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031964; batch adversarial loss: 0.476899\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042998; batch adversarial loss: 0.400419\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025192; batch adversarial loss: 0.445166\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021187; batch adversarial loss: 0.493019\n",
      "epoch 129; iter: 0; batch classifier loss: 0.065869; batch adversarial loss: 0.467454\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030714; batch adversarial loss: 0.488233\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041615; batch adversarial loss: 0.523181\n",
      "epoch 132; iter: 0; batch classifier loss: 0.075182; batch adversarial loss: 0.573918\n",
      "epoch 133; iter: 0; batch classifier loss: 0.063906; batch adversarial loss: 0.541247\n",
      "epoch 134; iter: 0; batch classifier loss: 0.078853; batch adversarial loss: 0.547924\n",
      "epoch 135; iter: 0; batch classifier loss: 0.065461; batch adversarial loss: 0.564162\n",
      "epoch 136; iter: 0; batch classifier loss: 0.090989; batch adversarial loss: 0.569852\n",
      "epoch 137; iter: 0; batch classifier loss: 0.100705; batch adversarial loss: 0.530094\n",
      "epoch 138; iter: 0; batch classifier loss: 0.113548; batch adversarial loss: 0.706483\n",
      "epoch 139; iter: 0; batch classifier loss: 0.267127; batch adversarial loss: 0.887766\n",
      "epoch 140; iter: 0; batch classifier loss: 0.124821; batch adversarial loss: 0.527366\n",
      "epoch 141; iter: 0; batch classifier loss: 0.092005; batch adversarial loss: 0.589631\n",
      "epoch 142; iter: 0; batch classifier loss: 0.133814; batch adversarial loss: 0.607380\n",
      "epoch 143; iter: 0; batch classifier loss: 0.185425; batch adversarial loss: 0.672251\n",
      "epoch 144; iter: 0; batch classifier loss: 0.197832; batch adversarial loss: 0.652959\n",
      "epoch 145; iter: 0; batch classifier loss: 0.117333; batch adversarial loss: 0.562589\n",
      "epoch 146; iter: 0; batch classifier loss: 0.195122; batch adversarial loss: 0.684206\n",
      "epoch 147; iter: 0; batch classifier loss: 0.187432; batch adversarial loss: 0.719431\n",
      "epoch 148; iter: 0; batch classifier loss: 0.150777; batch adversarial loss: 0.563943\n",
      "epoch 149; iter: 0; batch classifier loss: 0.187863; batch adversarial loss: 0.581808\n",
      "epoch 150; iter: 0; batch classifier loss: 0.160803; batch adversarial loss: 0.667675\n",
      "epoch 151; iter: 0; batch classifier loss: 0.174745; batch adversarial loss: 0.672560\n",
      "epoch 152; iter: 0; batch classifier loss: 0.189942; batch adversarial loss: 0.615017\n",
      "epoch 153; iter: 0; batch classifier loss: 0.172188; batch adversarial loss: 0.657951\n",
      "epoch 154; iter: 0; batch classifier loss: 0.127217; batch adversarial loss: 0.511569\n",
      "epoch 155; iter: 0; batch classifier loss: 0.186709; batch adversarial loss: 0.635969\n",
      "epoch 156; iter: 0; batch classifier loss: 0.124319; batch adversarial loss: 0.579578\n",
      "epoch 157; iter: 0; batch classifier loss: 0.175414; batch adversarial loss: 0.631674\n",
      "epoch 158; iter: 0; batch classifier loss: 0.162364; batch adversarial loss: 0.657815\n",
      "epoch 159; iter: 0; batch classifier loss: 0.203386; batch adversarial loss: 0.555846\n",
      "epoch 160; iter: 0; batch classifier loss: 0.151099; batch adversarial loss: 0.639543\n",
      "epoch 161; iter: 0; batch classifier loss: 0.151321; batch adversarial loss: 0.492052\n",
      "epoch 162; iter: 0; batch classifier loss: 0.179634; batch adversarial loss: 0.593920\n",
      "epoch 163; iter: 0; batch classifier loss: 0.111580; batch adversarial loss: 0.448506\n",
      "epoch 164; iter: 0; batch classifier loss: 0.096194; batch adversarial loss: 0.493923\n",
      "epoch 165; iter: 0; batch classifier loss: 0.113008; batch adversarial loss: 0.366912\n",
      "epoch 166; iter: 0; batch classifier loss: 0.120560; batch adversarial loss: 0.446341\n",
      "epoch 167; iter: 0; batch classifier loss: 0.115322; batch adversarial loss: 0.491444\n",
      "epoch 168; iter: 0; batch classifier loss: 0.094239; batch adversarial loss: 0.435560\n",
      "epoch 169; iter: 0; batch classifier loss: 0.115999; batch adversarial loss: 0.474909\n",
      "epoch 170; iter: 0; batch classifier loss: 0.084417; batch adversarial loss: 0.402475\n",
      "epoch 171; iter: 0; batch classifier loss: 0.124964; batch adversarial loss: 0.502617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.086126; batch adversarial loss: 0.470031\n",
      "epoch 173; iter: 0; batch classifier loss: 0.122912; batch adversarial loss: 0.482275\n",
      "epoch 174; iter: 0; batch classifier loss: 0.103883; batch adversarial loss: 0.478914\n",
      "epoch 175; iter: 0; batch classifier loss: 0.124104; batch adversarial loss: 0.425573\n",
      "epoch 176; iter: 0; batch classifier loss: 0.132533; batch adversarial loss: 0.413285\n",
      "epoch 177; iter: 0; batch classifier loss: 0.089873; batch adversarial loss: 0.422900\n",
      "epoch 178; iter: 0; batch classifier loss: 0.080948; batch adversarial loss: 0.433731\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027574; batch adversarial loss: 0.469596\n",
      "epoch 180; iter: 0; batch classifier loss: 0.060701; batch adversarial loss: 0.445545\n",
      "epoch 181; iter: 0; batch classifier loss: 0.055261; batch adversarial loss: 0.495099\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037851; batch adversarial loss: 0.421230\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033041; batch adversarial loss: 0.459968\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029028; batch adversarial loss: 0.435124\n",
      "epoch 185; iter: 0; batch classifier loss: 0.043794; batch adversarial loss: 0.479041\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040026; batch adversarial loss: 0.418532\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020441; batch adversarial loss: 0.499606\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032360; batch adversarial loss: 0.428378\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034556; batch adversarial loss: 0.436782\n",
      "epoch 190; iter: 0; batch classifier loss: 0.052077; batch adversarial loss: 0.490257\n",
      "epoch 191; iter: 0; batch classifier loss: 0.076862; batch adversarial loss: 0.497920\n",
      "epoch 192; iter: 0; batch classifier loss: 0.067093; batch adversarial loss: 0.460662\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035284; batch adversarial loss: 0.433790\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035653; batch adversarial loss: 0.471535\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027951; batch adversarial loss: 0.487839\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026555; batch adversarial loss: 0.450915\n",
      "epoch 197; iter: 0; batch classifier loss: 0.071427; batch adversarial loss: 0.492300\n",
      "epoch 198; iter: 0; batch classifier loss: 0.053915; batch adversarial loss: 0.341733\n",
      "epoch 199; iter: 0; batch classifier loss: 0.049067; batch adversarial loss: 0.498941\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701904; batch adversarial loss: 0.853537\n",
      "epoch 1; iter: 0; batch classifier loss: 0.443582; batch adversarial loss: 0.826937\n",
      "epoch 2; iter: 0; batch classifier loss: 0.438761; batch adversarial loss: 0.769528\n",
      "epoch 3; iter: 0; batch classifier loss: 0.383743; batch adversarial loss: 0.715497\n",
      "epoch 4; iter: 0; batch classifier loss: 0.381067; batch adversarial loss: 0.665925\n",
      "epoch 5; iter: 0; batch classifier loss: 0.327656; batch adversarial loss: 0.627307\n",
      "epoch 6; iter: 0; batch classifier loss: 0.264359; batch adversarial loss: 0.605858\n",
      "epoch 7; iter: 0; batch classifier loss: 0.296438; batch adversarial loss: 0.592158\n",
      "epoch 8; iter: 0; batch classifier loss: 0.290067; batch adversarial loss: 0.567705\n",
      "epoch 9; iter: 0; batch classifier loss: 0.269333; batch adversarial loss: 0.541124\n",
      "epoch 10; iter: 0; batch classifier loss: 0.225488; batch adversarial loss: 0.521297\n",
      "epoch 11; iter: 0; batch classifier loss: 0.251001; batch adversarial loss: 0.474862\n",
      "epoch 12; iter: 0; batch classifier loss: 0.232936; batch adversarial loss: 0.520330\n",
      "epoch 13; iter: 0; batch classifier loss: 0.228874; batch adversarial loss: 0.529128\n",
      "epoch 14; iter: 0; batch classifier loss: 0.173201; batch adversarial loss: 0.524264\n",
      "epoch 15; iter: 0; batch classifier loss: 0.171413; batch adversarial loss: 0.505131\n",
      "epoch 16; iter: 0; batch classifier loss: 0.189549; batch adversarial loss: 0.471265\n",
      "epoch 17; iter: 0; batch classifier loss: 0.175648; batch adversarial loss: 0.518735\n",
      "epoch 18; iter: 0; batch classifier loss: 0.185660; batch adversarial loss: 0.474942\n",
      "epoch 19; iter: 0; batch classifier loss: 0.205747; batch adversarial loss: 0.479288\n",
      "epoch 20; iter: 0; batch classifier loss: 0.140786; batch adversarial loss: 0.446284\n",
      "epoch 21; iter: 0; batch classifier loss: 0.203733; batch adversarial loss: 0.468875\n",
      "epoch 22; iter: 0; batch classifier loss: 0.180912; batch adversarial loss: 0.475146\n",
      "epoch 23; iter: 0; batch classifier loss: 0.185497; batch adversarial loss: 0.479805\n",
      "epoch 24; iter: 0; batch classifier loss: 0.126287; batch adversarial loss: 0.498631\n",
      "epoch 25; iter: 0; batch classifier loss: 0.135716; batch adversarial loss: 0.447303\n",
      "epoch 26; iter: 0; batch classifier loss: 0.161706; batch adversarial loss: 0.469110\n",
      "epoch 27; iter: 0; batch classifier loss: 0.136562; batch adversarial loss: 0.397844\n",
      "epoch 28; iter: 0; batch classifier loss: 0.148569; batch adversarial loss: 0.433370\n",
      "epoch 29; iter: 0; batch classifier loss: 0.136802; batch adversarial loss: 0.422866\n",
      "epoch 30; iter: 0; batch classifier loss: 0.179382; batch adversarial loss: 0.416222\n",
      "epoch 31; iter: 0; batch classifier loss: 0.135654; batch adversarial loss: 0.377379\n",
      "epoch 32; iter: 0; batch classifier loss: 0.106872; batch adversarial loss: 0.483664\n",
      "epoch 33; iter: 0; batch classifier loss: 0.134364; batch adversarial loss: 0.466263\n",
      "epoch 34; iter: 0; batch classifier loss: 0.106531; batch adversarial loss: 0.450798\n",
      "epoch 35; iter: 0; batch classifier loss: 0.126209; batch adversarial loss: 0.432858\n",
      "epoch 36; iter: 0; batch classifier loss: 0.170284; batch adversarial loss: 0.447010\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132957; batch adversarial loss: 0.527958\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099204; batch adversarial loss: 0.458257\n",
      "epoch 39; iter: 0; batch classifier loss: 0.149730; batch adversarial loss: 0.367487\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124644; batch adversarial loss: 0.420933\n",
      "epoch 41; iter: 0; batch classifier loss: 0.150759; batch adversarial loss: 0.446625\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115262; batch adversarial loss: 0.414040\n",
      "epoch 43; iter: 0; batch classifier loss: 0.123897; batch adversarial loss: 0.430200\n",
      "epoch 44; iter: 0; batch classifier loss: 0.100220; batch adversarial loss: 0.449227\n",
      "epoch 45; iter: 0; batch classifier loss: 0.130334; batch adversarial loss: 0.457805\n",
      "epoch 46; iter: 0; batch classifier loss: 0.075472; batch adversarial loss: 0.405179\n",
      "epoch 47; iter: 0; batch classifier loss: 0.133201; batch adversarial loss: 0.460984\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125415; batch adversarial loss: 0.468125\n",
      "epoch 49; iter: 0; batch classifier loss: 0.077407; batch adversarial loss: 0.477544\n",
      "epoch 50; iter: 0; batch classifier loss: 0.114578; batch adversarial loss: 0.480092\n",
      "epoch 51; iter: 0; batch classifier loss: 0.089028; batch adversarial loss: 0.417668\n",
      "epoch 52; iter: 0; batch classifier loss: 0.115631; batch adversarial loss: 0.393077\n",
      "epoch 53; iter: 0; batch classifier loss: 0.148340; batch adversarial loss: 0.473632\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074124; batch adversarial loss: 0.423435\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119671; batch adversarial loss: 0.548686\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067431; batch adversarial loss: 0.385400\n",
      "epoch 57; iter: 0; batch classifier loss: 0.075817; batch adversarial loss: 0.365041\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090945; batch adversarial loss: 0.492030\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067762; batch adversarial loss: 0.412326\n",
      "epoch 60; iter: 0; batch classifier loss: 0.107049; batch adversarial loss: 0.453830\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090114; batch adversarial loss: 0.490140\n",
      "epoch 62; iter: 0; batch classifier loss: 0.054264; batch adversarial loss: 0.502308\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088991; batch adversarial loss: 0.434669\n",
      "epoch 64; iter: 0; batch classifier loss: 0.120575; batch adversarial loss: 0.368220\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070650; batch adversarial loss: 0.399696\n",
      "epoch 66; iter: 0; batch classifier loss: 0.080744; batch adversarial loss: 0.408137\n",
      "epoch 67; iter: 0; batch classifier loss: 0.070733; batch adversarial loss: 0.432072\n",
      "epoch 68; iter: 0; batch classifier loss: 0.080986; batch adversarial loss: 0.382702\n",
      "epoch 69; iter: 0; batch classifier loss: 0.091216; batch adversarial loss: 0.430251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.111608; batch adversarial loss: 0.453600\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063593; batch adversarial loss: 0.359256\n",
      "epoch 72; iter: 0; batch classifier loss: 0.078654; batch adversarial loss: 0.352482\n",
      "epoch 73; iter: 0; batch classifier loss: 0.095628; batch adversarial loss: 0.374168\n",
      "epoch 74; iter: 0; batch classifier loss: 0.107201; batch adversarial loss: 0.418977\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061155; batch adversarial loss: 0.476767\n",
      "epoch 76; iter: 0; batch classifier loss: 0.112386; batch adversarial loss: 0.364604\n",
      "epoch 77; iter: 0; batch classifier loss: 0.068742; batch adversarial loss: 0.436855\n",
      "epoch 78; iter: 0; batch classifier loss: 0.068262; batch adversarial loss: 0.431937\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061933; batch adversarial loss: 0.497007\n",
      "epoch 80; iter: 0; batch classifier loss: 0.048512; batch adversarial loss: 0.487715\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073370; batch adversarial loss: 0.385675\n",
      "epoch 82; iter: 0; batch classifier loss: 0.070192; batch adversarial loss: 0.443984\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068651; batch adversarial loss: 0.373461\n",
      "epoch 84; iter: 0; batch classifier loss: 0.099126; batch adversarial loss: 0.414861\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077389; batch adversarial loss: 0.500807\n",
      "epoch 86; iter: 0; batch classifier loss: 0.071428; batch adversarial loss: 0.482127\n",
      "epoch 87; iter: 0; batch classifier loss: 0.085548; batch adversarial loss: 0.437470\n",
      "epoch 88; iter: 0; batch classifier loss: 0.079151; batch adversarial loss: 0.450590\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057088; batch adversarial loss: 0.418597\n",
      "epoch 90; iter: 0; batch classifier loss: 0.046613; batch adversarial loss: 0.460077\n",
      "epoch 91; iter: 0; batch classifier loss: 0.114790; batch adversarial loss: 0.488286\n",
      "epoch 92; iter: 0; batch classifier loss: 0.032537; batch adversarial loss: 0.393678\n",
      "epoch 93; iter: 0; batch classifier loss: 0.082555; batch adversarial loss: 0.465820\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064728; batch adversarial loss: 0.337817\n",
      "epoch 95; iter: 0; batch classifier loss: 0.067524; batch adversarial loss: 0.572877\n",
      "epoch 96; iter: 0; batch classifier loss: 0.104276; batch adversarial loss: 0.414668\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056675; batch adversarial loss: 0.373911\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047931; batch adversarial loss: 0.420356\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056754; batch adversarial loss: 0.471896\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066602; batch adversarial loss: 0.416492\n",
      "epoch 101; iter: 0; batch classifier loss: 0.095371; batch adversarial loss: 0.363564\n",
      "epoch 102; iter: 0; batch classifier loss: 0.087540; batch adversarial loss: 0.428077\n",
      "epoch 103; iter: 0; batch classifier loss: 0.069673; batch adversarial loss: 0.374113\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046239; batch adversarial loss: 0.445947\n",
      "epoch 105; iter: 0; batch classifier loss: 0.089985; batch adversarial loss: 0.412958\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040563; batch adversarial loss: 0.451389\n",
      "epoch 107; iter: 0; batch classifier loss: 0.092329; batch adversarial loss: 0.451177\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069906; batch adversarial loss: 0.470458\n",
      "epoch 109; iter: 0; batch classifier loss: 0.081292; batch adversarial loss: 0.488256\n",
      "epoch 110; iter: 0; batch classifier loss: 0.076496; batch adversarial loss: 0.488911\n",
      "epoch 111; iter: 0; batch classifier loss: 0.103967; batch adversarial loss: 0.470128\n",
      "epoch 112; iter: 0; batch classifier loss: 0.096872; batch adversarial loss: 0.394559\n",
      "epoch 113; iter: 0; batch classifier loss: 0.075699; batch adversarial loss: 0.407652\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050929; batch adversarial loss: 0.343637\n",
      "epoch 115; iter: 0; batch classifier loss: 0.066733; batch adversarial loss: 0.348699\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053939; batch adversarial loss: 0.439915\n",
      "epoch 117; iter: 0; batch classifier loss: 0.076892; batch adversarial loss: 0.352935\n",
      "epoch 118; iter: 0; batch classifier loss: 0.074687; batch adversarial loss: 0.478397\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051931; batch adversarial loss: 0.409961\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041857; batch adversarial loss: 0.422650\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047368; batch adversarial loss: 0.435781\n",
      "epoch 122; iter: 0; batch classifier loss: 0.082425; batch adversarial loss: 0.417426\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046628; batch adversarial loss: 0.391142\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051907; batch adversarial loss: 0.402214\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050558; batch adversarial loss: 0.395262\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052261; batch adversarial loss: 0.445277\n",
      "epoch 127; iter: 0; batch classifier loss: 0.091825; batch adversarial loss: 0.419288\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058049; batch adversarial loss: 0.486477\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045089; batch adversarial loss: 0.441944\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051544; batch adversarial loss: 0.450999\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051807; batch adversarial loss: 0.493498\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043783; batch adversarial loss: 0.456256\n",
      "epoch 133; iter: 0; batch classifier loss: 0.076086; batch adversarial loss: 0.376239\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057118; batch adversarial loss: 0.484667\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031933; batch adversarial loss: 0.390717\n",
      "epoch 136; iter: 0; batch classifier loss: 0.051304; batch adversarial loss: 0.433788\n",
      "epoch 137; iter: 0; batch classifier loss: 0.080361; batch adversarial loss: 0.485673\n",
      "epoch 138; iter: 0; batch classifier loss: 0.059348; batch adversarial loss: 0.402608\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046864; batch adversarial loss: 0.382426\n",
      "epoch 140; iter: 0; batch classifier loss: 0.059314; batch adversarial loss: 0.418526\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024726; batch adversarial loss: 0.445146\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033586; batch adversarial loss: 0.480112\n",
      "epoch 143; iter: 0; batch classifier loss: 0.057839; batch adversarial loss: 0.408729\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052814; batch adversarial loss: 0.373548\n",
      "epoch 145; iter: 0; batch classifier loss: 0.058036; batch adversarial loss: 0.512003\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051160; batch adversarial loss: 0.451161\n",
      "epoch 147; iter: 0; batch classifier loss: 0.045603; batch adversarial loss: 0.369833\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036597; batch adversarial loss: 0.368661\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051495; batch adversarial loss: 0.455426\n",
      "epoch 150; iter: 0; batch classifier loss: 0.056388; batch adversarial loss: 0.420443\n",
      "epoch 151; iter: 0; batch classifier loss: 0.053295; batch adversarial loss: 0.419261\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042572; batch adversarial loss: 0.493420\n",
      "epoch 153; iter: 0; batch classifier loss: 0.060319; batch adversarial loss: 0.423890\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036780; batch adversarial loss: 0.391638\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046468; batch adversarial loss: 0.401618\n",
      "epoch 156; iter: 0; batch classifier loss: 0.071178; batch adversarial loss: 0.507893\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041370; batch adversarial loss: 0.462843\n",
      "epoch 158; iter: 0; batch classifier loss: 0.071673; batch adversarial loss: 0.452693\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037064; batch adversarial loss: 0.365846\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036272; batch adversarial loss: 0.451652\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043296; batch adversarial loss: 0.385950\n",
      "epoch 162; iter: 0; batch classifier loss: 0.057007; batch adversarial loss: 0.402851\n",
      "epoch 163; iter: 0; batch classifier loss: 0.057566; batch adversarial loss: 0.510216\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027677; batch adversarial loss: 0.528961\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019551; batch adversarial loss: 0.401652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.025170; batch adversarial loss: 0.403762\n",
      "epoch 167; iter: 0; batch classifier loss: 0.044995; batch adversarial loss: 0.447344\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029256; batch adversarial loss: 0.446183\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025058; batch adversarial loss: 0.509963\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035451; batch adversarial loss: 0.598036\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033362; batch adversarial loss: 0.491739\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029842; batch adversarial loss: 0.409102\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022909; batch adversarial loss: 0.562868\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027366; batch adversarial loss: 0.401219\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020053; batch adversarial loss: 0.443645\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017793; batch adversarial loss: 0.429669\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022987; batch adversarial loss: 0.414147\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016346; batch adversarial loss: 0.433357\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011226; batch adversarial loss: 0.421752\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025293; batch adversarial loss: 0.481302\n",
      "epoch 181; iter: 0; batch classifier loss: 0.052939; batch adversarial loss: 0.409899\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036663; batch adversarial loss: 0.406050\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024660; batch adversarial loss: 0.497829\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040226; batch adversarial loss: 0.629046\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025264; batch adversarial loss: 0.523427\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021422; batch adversarial loss: 0.461828\n",
      "epoch 187; iter: 0; batch classifier loss: 0.058828; batch adversarial loss: 0.512103\n",
      "epoch 188; iter: 0; batch classifier loss: 0.049837; batch adversarial loss: 0.493643\n",
      "epoch 189; iter: 0; batch classifier loss: 0.149492; batch adversarial loss: 0.736995\n",
      "epoch 190; iter: 0; batch classifier loss: 0.073579; batch adversarial loss: 0.524684\n",
      "epoch 191; iter: 0; batch classifier loss: 0.144779; batch adversarial loss: 0.633291\n",
      "epoch 192; iter: 0; batch classifier loss: 0.121625; batch adversarial loss: 0.709152\n",
      "epoch 193; iter: 0; batch classifier loss: 0.112848; batch adversarial loss: 0.548913\n",
      "epoch 194; iter: 0; batch classifier loss: 0.234627; batch adversarial loss: 0.834779\n",
      "epoch 195; iter: 0; batch classifier loss: 0.154923; batch adversarial loss: 0.657975\n",
      "epoch 196; iter: 0; batch classifier loss: 0.215434; batch adversarial loss: 0.738892\n",
      "epoch 197; iter: 0; batch classifier loss: 0.090801; batch adversarial loss: 0.552657\n",
      "epoch 198; iter: 0; batch classifier loss: 0.132085; batch adversarial loss: 0.710372\n",
      "epoch 199; iter: 0; batch classifier loss: 0.165508; batch adversarial loss: 0.701541\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709979; batch adversarial loss: 0.705045\n",
      "epoch 1; iter: 0; batch classifier loss: 0.511931; batch adversarial loss: 0.656218\n",
      "epoch 2; iter: 0; batch classifier loss: 0.458316; batch adversarial loss: 0.614955\n",
      "epoch 3; iter: 0; batch classifier loss: 0.344231; batch adversarial loss: 0.604116\n",
      "epoch 4; iter: 0; batch classifier loss: 0.270726; batch adversarial loss: 0.568355\n",
      "epoch 5; iter: 0; batch classifier loss: 0.396434; batch adversarial loss: 0.532957\n",
      "epoch 6; iter: 0; batch classifier loss: 0.241222; batch adversarial loss: 0.539718\n",
      "epoch 7; iter: 0; batch classifier loss: 0.231059; batch adversarial loss: 0.518991\n",
      "epoch 8; iter: 0; batch classifier loss: 0.299109; batch adversarial loss: 0.459337\n",
      "epoch 9; iter: 0; batch classifier loss: 0.243658; batch adversarial loss: 0.518775\n",
      "epoch 10; iter: 0; batch classifier loss: 0.263773; batch adversarial loss: 0.483584\n",
      "epoch 11; iter: 0; batch classifier loss: 0.286574; batch adversarial loss: 0.464852\n",
      "epoch 12; iter: 0; batch classifier loss: 0.230283; batch adversarial loss: 0.494997\n",
      "epoch 13; iter: 0; batch classifier loss: 0.155660; batch adversarial loss: 0.496910\n",
      "epoch 14; iter: 0; batch classifier loss: 0.199364; batch adversarial loss: 0.464167\n",
      "epoch 15; iter: 0; batch classifier loss: 0.191753; batch adversarial loss: 0.381180\n",
      "epoch 16; iter: 0; batch classifier loss: 0.140099; batch adversarial loss: 0.511821\n",
      "epoch 17; iter: 0; batch classifier loss: 0.167693; batch adversarial loss: 0.441609\n",
      "epoch 18; iter: 0; batch classifier loss: 0.166035; batch adversarial loss: 0.501462\n",
      "epoch 19; iter: 0; batch classifier loss: 0.118807; batch adversarial loss: 0.362280\n",
      "epoch 20; iter: 0; batch classifier loss: 0.155136; batch adversarial loss: 0.389507\n",
      "epoch 21; iter: 0; batch classifier loss: 0.168284; batch adversarial loss: 0.424348\n",
      "epoch 22; iter: 0; batch classifier loss: 0.194674; batch adversarial loss: 0.451462\n",
      "epoch 23; iter: 0; batch classifier loss: 0.173194; batch adversarial loss: 0.412623\n",
      "epoch 24; iter: 0; batch classifier loss: 0.148857; batch adversarial loss: 0.404333\n",
      "epoch 25; iter: 0; batch classifier loss: 0.163784; batch adversarial loss: 0.371412\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165467; batch adversarial loss: 0.432746\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140873; batch adversarial loss: 0.411759\n",
      "epoch 28; iter: 0; batch classifier loss: 0.161501; batch adversarial loss: 0.433354\n",
      "epoch 29; iter: 0; batch classifier loss: 0.135712; batch adversarial loss: 0.336598\n",
      "epoch 30; iter: 0; batch classifier loss: 0.132976; batch adversarial loss: 0.405752\n",
      "epoch 31; iter: 0; batch classifier loss: 0.121670; batch adversarial loss: 0.474410\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126873; batch adversarial loss: 0.412904\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145250; batch adversarial loss: 0.372314\n",
      "epoch 34; iter: 0; batch classifier loss: 0.110449; batch adversarial loss: 0.463997\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113904; batch adversarial loss: 0.363565\n",
      "epoch 36; iter: 0; batch classifier loss: 0.137236; batch adversarial loss: 0.507701\n",
      "epoch 37; iter: 0; batch classifier loss: 0.096643; batch adversarial loss: 0.444932\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115059; batch adversarial loss: 0.407137\n",
      "epoch 39; iter: 0; batch classifier loss: 0.111263; batch adversarial loss: 0.379056\n",
      "epoch 40; iter: 0; batch classifier loss: 0.140308; batch adversarial loss: 0.426698\n",
      "epoch 41; iter: 0; batch classifier loss: 0.119611; batch adversarial loss: 0.475999\n",
      "epoch 42; iter: 0; batch classifier loss: 0.076182; batch adversarial loss: 0.362241\n",
      "epoch 43; iter: 0; batch classifier loss: 0.121881; batch adversarial loss: 0.545677\n",
      "epoch 44; iter: 0; batch classifier loss: 0.072314; batch adversarial loss: 0.334314\n",
      "epoch 45; iter: 0; batch classifier loss: 0.079168; batch adversarial loss: 0.442791\n",
      "epoch 46; iter: 0; batch classifier loss: 0.119691; batch adversarial loss: 0.450089\n",
      "epoch 47; iter: 0; batch classifier loss: 0.111833; batch adversarial loss: 0.409940\n",
      "epoch 48; iter: 0; batch classifier loss: 0.117497; batch adversarial loss: 0.340000\n",
      "epoch 49; iter: 0; batch classifier loss: 0.091189; batch adversarial loss: 0.391952\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074726; batch adversarial loss: 0.412693\n",
      "epoch 51; iter: 0; batch classifier loss: 0.108938; batch adversarial loss: 0.405414\n",
      "epoch 52; iter: 0; batch classifier loss: 0.104119; batch adversarial loss: 0.337555\n",
      "epoch 53; iter: 0; batch classifier loss: 0.104203; batch adversarial loss: 0.397627\n",
      "epoch 54; iter: 0; batch classifier loss: 0.107816; batch adversarial loss: 0.515679\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072068; batch adversarial loss: 0.403792\n",
      "epoch 56; iter: 0; batch classifier loss: 0.120027; batch adversarial loss: 0.334352\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107082; batch adversarial loss: 0.411213\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097699; batch adversarial loss: 0.488989\n",
      "epoch 59; iter: 0; batch classifier loss: 0.086235; batch adversarial loss: 0.504410\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104892; batch adversarial loss: 0.496545\n",
      "epoch 61; iter: 0; batch classifier loss: 0.048940; batch adversarial loss: 0.405234\n",
      "epoch 62; iter: 0; batch classifier loss: 0.044109; batch adversarial loss: 0.373750\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059919; batch adversarial loss: 0.452666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.093020; batch adversarial loss: 0.401104\n",
      "epoch 65; iter: 0; batch classifier loss: 0.047034; batch adversarial loss: 0.387800\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096999; batch adversarial loss: 0.476856\n",
      "epoch 67; iter: 0; batch classifier loss: 0.084461; batch adversarial loss: 0.500372\n",
      "epoch 68; iter: 0; batch classifier loss: 0.088487; batch adversarial loss: 0.358452\n",
      "epoch 69; iter: 0; batch classifier loss: 0.060747; batch adversarial loss: 0.446052\n",
      "epoch 70; iter: 0; batch classifier loss: 0.150352; batch adversarial loss: 0.384759\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058576; batch adversarial loss: 0.298068\n",
      "epoch 72; iter: 0; batch classifier loss: 0.095335; batch adversarial loss: 0.399675\n",
      "epoch 73; iter: 0; batch classifier loss: 0.046368; batch adversarial loss: 0.431910\n",
      "epoch 74; iter: 0; batch classifier loss: 0.062828; batch adversarial loss: 0.449912\n",
      "epoch 75; iter: 0; batch classifier loss: 0.085219; batch adversarial loss: 0.457028\n",
      "epoch 76; iter: 0; batch classifier loss: 0.074278; batch adversarial loss: 0.384386\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108253; batch adversarial loss: 0.417126\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064733; batch adversarial loss: 0.409596\n",
      "epoch 79; iter: 0; batch classifier loss: 0.077736; batch adversarial loss: 0.343824\n",
      "epoch 80; iter: 0; batch classifier loss: 0.062446; batch adversarial loss: 0.442150\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079761; batch adversarial loss: 0.333533\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067085; batch adversarial loss: 0.403720\n",
      "epoch 83; iter: 0; batch classifier loss: 0.058467; batch adversarial loss: 0.368399\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048468; batch adversarial loss: 0.389313\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084589; batch adversarial loss: 0.438280\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052541; batch adversarial loss: 0.476474\n",
      "epoch 87; iter: 0; batch classifier loss: 0.104523; batch adversarial loss: 0.346618\n",
      "epoch 88; iter: 0; batch classifier loss: 0.080197; batch adversarial loss: 0.352038\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042696; batch adversarial loss: 0.489772\n",
      "epoch 90; iter: 0; batch classifier loss: 0.044631; batch adversarial loss: 0.419002\n",
      "epoch 91; iter: 0; batch classifier loss: 0.084957; batch adversarial loss: 0.464536\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063447; batch adversarial loss: 0.526138\n",
      "epoch 93; iter: 0; batch classifier loss: 0.094313; batch adversarial loss: 0.443101\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053050; batch adversarial loss: 0.450097\n",
      "epoch 95; iter: 0; batch classifier loss: 0.136259; batch adversarial loss: 0.440179\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061836; batch adversarial loss: 0.506413\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056618; batch adversarial loss: 0.463527\n",
      "epoch 98; iter: 0; batch classifier loss: 0.095354; batch adversarial loss: 0.413461\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054841; batch adversarial loss: 0.443130\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057855; batch adversarial loss: 0.419932\n",
      "epoch 101; iter: 0; batch classifier loss: 0.073996; batch adversarial loss: 0.420828\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054361; batch adversarial loss: 0.417304\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059463; batch adversarial loss: 0.479404\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057820; batch adversarial loss: 0.445153\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051255; batch adversarial loss: 0.433100\n",
      "epoch 106; iter: 0; batch classifier loss: 0.065151; batch adversarial loss: 0.416987\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049717; batch adversarial loss: 0.468412\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055409; batch adversarial loss: 0.438744\n",
      "epoch 109; iter: 0; batch classifier loss: 0.082805; batch adversarial loss: 0.436348\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047506; batch adversarial loss: 0.469865\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058389; batch adversarial loss: 0.470940\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049098; batch adversarial loss: 0.499054\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071083; batch adversarial loss: 0.395015\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057996; batch adversarial loss: 0.366918\n",
      "epoch 115; iter: 0; batch classifier loss: 0.080346; batch adversarial loss: 0.398938\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032694; batch adversarial loss: 0.437905\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056722; batch adversarial loss: 0.417908\n",
      "epoch 118; iter: 0; batch classifier loss: 0.068505; batch adversarial loss: 0.541940\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042867; batch adversarial loss: 0.417684\n",
      "epoch 120; iter: 0; batch classifier loss: 0.066090; batch adversarial loss: 0.430872\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048524; batch adversarial loss: 0.398013\n",
      "epoch 122; iter: 0; batch classifier loss: 0.070944; batch adversarial loss: 0.369456\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024201; batch adversarial loss: 0.416518\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035523; batch adversarial loss: 0.418470\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056092; batch adversarial loss: 0.415744\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045555; batch adversarial loss: 0.478367\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037597; batch adversarial loss: 0.549347\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044219; batch adversarial loss: 0.402128\n",
      "epoch 129; iter: 0; batch classifier loss: 0.071122; batch adversarial loss: 0.466106\n",
      "epoch 130; iter: 0; batch classifier loss: 0.060671; batch adversarial loss: 0.386406\n",
      "epoch 131; iter: 0; batch classifier loss: 0.053600; batch adversarial loss: 0.408917\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027654; batch adversarial loss: 0.482408\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046045; batch adversarial loss: 0.342976\n",
      "epoch 134; iter: 0; batch classifier loss: 0.083263; batch adversarial loss: 0.455863\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034743; batch adversarial loss: 0.462124\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037556; batch adversarial loss: 0.437883\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018164; batch adversarial loss: 0.448654\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035499; batch adversarial loss: 0.443228\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015052; batch adversarial loss: 0.501475\n",
      "epoch 140; iter: 0; batch classifier loss: 0.059558; batch adversarial loss: 0.354167\n",
      "epoch 141; iter: 0; batch classifier loss: 0.062894; batch adversarial loss: 0.473962\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026264; batch adversarial loss: 0.409987\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033979; batch adversarial loss: 0.446329\n",
      "epoch 144; iter: 0; batch classifier loss: 0.060859; batch adversarial loss: 0.516068\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040825; batch adversarial loss: 0.376060\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052570; batch adversarial loss: 0.443351\n",
      "epoch 147; iter: 0; batch classifier loss: 0.088706; batch adversarial loss: 0.318444\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023038; batch adversarial loss: 0.563580\n",
      "epoch 149; iter: 0; batch classifier loss: 0.055632; batch adversarial loss: 0.531760\n",
      "epoch 150; iter: 0; batch classifier loss: 0.055384; batch adversarial loss: 0.439464\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030834; batch adversarial loss: 0.455205\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019241; batch adversarial loss: 0.520167\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038026; batch adversarial loss: 0.613433\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026409; batch adversarial loss: 0.507683\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044887; batch adversarial loss: 0.527029\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045408; batch adversarial loss: 0.563811\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026604; batch adversarial loss: 0.448329\n",
      "epoch 158; iter: 0; batch classifier loss: 0.093482; batch adversarial loss: 0.514423\n",
      "epoch 159; iter: 0; batch classifier loss: 0.097442; batch adversarial loss: 0.561955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.052774; batch adversarial loss: 0.518301\n",
      "epoch 161; iter: 0; batch classifier loss: 0.091026; batch adversarial loss: 0.540639\n",
      "epoch 162; iter: 0; batch classifier loss: 0.132246; batch adversarial loss: 0.617800\n",
      "epoch 163; iter: 0; batch classifier loss: 0.132715; batch adversarial loss: 0.769086\n",
      "epoch 164; iter: 0; batch classifier loss: 0.109214; batch adversarial loss: 0.530016\n",
      "epoch 165; iter: 0; batch classifier loss: 0.196412; batch adversarial loss: 0.708097\n",
      "epoch 166; iter: 0; batch classifier loss: 0.130862; batch adversarial loss: 0.761717\n",
      "epoch 167; iter: 0; batch classifier loss: 0.111154; batch adversarial loss: 0.688922\n",
      "epoch 168; iter: 0; batch classifier loss: 0.147765; batch adversarial loss: 0.694396\n",
      "epoch 169; iter: 0; batch classifier loss: 0.112956; batch adversarial loss: 0.569126\n",
      "epoch 170; iter: 0; batch classifier loss: 0.124300; batch adversarial loss: 0.596517\n",
      "epoch 171; iter: 0; batch classifier loss: 0.117608; batch adversarial loss: 0.629976\n",
      "epoch 172; iter: 0; batch classifier loss: 0.201309; batch adversarial loss: 0.705843\n",
      "epoch 173; iter: 0; batch classifier loss: 0.121896; batch adversarial loss: 0.564303\n",
      "epoch 174; iter: 0; batch classifier loss: 0.123763; batch adversarial loss: 0.569551\n",
      "epoch 175; iter: 0; batch classifier loss: 0.142456; batch adversarial loss: 0.606105\n",
      "epoch 176; iter: 0; batch classifier loss: 0.081986; batch adversarial loss: 0.505400\n",
      "epoch 177; iter: 0; batch classifier loss: 0.138510; batch adversarial loss: 0.576256\n",
      "epoch 178; iter: 0; batch classifier loss: 0.134613; batch adversarial loss: 0.550519\n",
      "epoch 179; iter: 0; batch classifier loss: 0.182575; batch adversarial loss: 0.677703\n",
      "epoch 180; iter: 0; batch classifier loss: 0.167961; batch adversarial loss: 0.618167\n",
      "epoch 181; iter: 0; batch classifier loss: 0.177986; batch adversarial loss: 0.645239\n",
      "epoch 182; iter: 0; batch classifier loss: 0.120775; batch adversarial loss: 0.597934\n",
      "epoch 183; iter: 0; batch classifier loss: 0.088155; batch adversarial loss: 0.494411\n",
      "epoch 184; iter: 0; batch classifier loss: 0.198917; batch adversarial loss: 0.681195\n",
      "epoch 185; iter: 0; batch classifier loss: 0.123315; batch adversarial loss: 0.431429\n",
      "epoch 186; iter: 0; batch classifier loss: 0.120158; batch adversarial loss: 0.586738\n",
      "epoch 187; iter: 0; batch classifier loss: 0.143847; batch adversarial loss: 0.563512\n",
      "epoch 188; iter: 0; batch classifier loss: 0.200304; batch adversarial loss: 0.631329\n",
      "epoch 189; iter: 0; batch classifier loss: 0.144036; batch adversarial loss: 0.692060\n",
      "epoch 190; iter: 0; batch classifier loss: 0.082818; batch adversarial loss: 0.510847\n",
      "epoch 191; iter: 0; batch classifier loss: 0.115607; batch adversarial loss: 0.515927\n",
      "epoch 192; iter: 0; batch classifier loss: 0.133452; batch adversarial loss: 0.547174\n",
      "epoch 193; iter: 0; batch classifier loss: 0.146921; batch adversarial loss: 0.539627\n",
      "epoch 194; iter: 0; batch classifier loss: 0.084195; batch adversarial loss: 0.410972\n",
      "epoch 195; iter: 0; batch classifier loss: 0.135697; batch adversarial loss: 0.529734\n",
      "epoch 196; iter: 0; batch classifier loss: 0.111799; batch adversarial loss: 0.442786\n",
      "epoch 197; iter: 0; batch classifier loss: 0.074496; batch adversarial loss: 0.488549\n",
      "epoch 198; iter: 0; batch classifier loss: 0.162010; batch adversarial loss: 0.600050\n",
      "epoch 199; iter: 0; batch classifier loss: 0.137969; batch adversarial loss: 0.590963\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694918; batch adversarial loss: 0.468657\n",
      "epoch 1; iter: 0; batch classifier loss: 0.438346; batch adversarial loss: 0.618423\n",
      "epoch 2; iter: 0; batch classifier loss: 0.361668; batch adversarial loss: 0.596504\n",
      "epoch 3; iter: 0; batch classifier loss: 0.422591; batch adversarial loss: 0.555197\n",
      "epoch 4; iter: 0; batch classifier loss: 0.328383; batch adversarial loss: 0.568785\n",
      "epoch 5; iter: 0; batch classifier loss: 0.344257; batch adversarial loss: 0.623399\n",
      "epoch 6; iter: 0; batch classifier loss: 0.314761; batch adversarial loss: 0.626974\n",
      "epoch 7; iter: 0; batch classifier loss: 0.314055; batch adversarial loss: 0.613468\n",
      "epoch 8; iter: 0; batch classifier loss: 0.280329; batch adversarial loss: 0.501113\n",
      "epoch 9; iter: 0; batch classifier loss: 0.283460; batch adversarial loss: 0.550589\n",
      "epoch 10; iter: 0; batch classifier loss: 0.376676; batch adversarial loss: 0.555251\n",
      "epoch 11; iter: 0; batch classifier loss: 0.422831; batch adversarial loss: 0.505883\n",
      "epoch 12; iter: 0; batch classifier loss: 0.422472; batch adversarial loss: 0.563851\n",
      "epoch 13; iter: 0; batch classifier loss: 0.432988; batch adversarial loss: 0.484651\n",
      "epoch 14; iter: 0; batch classifier loss: 0.496513; batch adversarial loss: 0.534603\n",
      "epoch 15; iter: 0; batch classifier loss: 0.285332; batch adversarial loss: 0.487288\n",
      "epoch 16; iter: 0; batch classifier loss: 0.348747; batch adversarial loss: 0.476121\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192886; batch adversarial loss: 0.436255\n",
      "epoch 18; iter: 0; batch classifier loss: 0.162518; batch adversarial loss: 0.551899\n",
      "epoch 19; iter: 0; batch classifier loss: 0.182651; batch adversarial loss: 0.433322\n",
      "epoch 20; iter: 0; batch classifier loss: 0.159574; batch adversarial loss: 0.457703\n",
      "epoch 21; iter: 0; batch classifier loss: 0.162624; batch adversarial loss: 0.423448\n",
      "epoch 22; iter: 0; batch classifier loss: 0.160562; batch adversarial loss: 0.429555\n",
      "epoch 23; iter: 0; batch classifier loss: 0.139841; batch adversarial loss: 0.397647\n",
      "epoch 24; iter: 0; batch classifier loss: 0.169369; batch adversarial loss: 0.381675\n",
      "epoch 25; iter: 0; batch classifier loss: 0.130834; batch adversarial loss: 0.532860\n",
      "epoch 26; iter: 0; batch classifier loss: 0.117461; batch adversarial loss: 0.410687\n",
      "epoch 27; iter: 0; batch classifier loss: 0.135541; batch adversarial loss: 0.521905\n",
      "epoch 28; iter: 0; batch classifier loss: 0.145700; batch adversarial loss: 0.485909\n",
      "epoch 29; iter: 0; batch classifier loss: 0.131484; batch adversarial loss: 0.418768\n",
      "epoch 30; iter: 0; batch classifier loss: 0.100850; batch adversarial loss: 0.530069\n",
      "epoch 31; iter: 0; batch classifier loss: 0.122592; batch adversarial loss: 0.526462\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159673; batch adversarial loss: 0.407163\n",
      "epoch 33; iter: 0; batch classifier loss: 0.113977; batch adversarial loss: 0.605002\n",
      "epoch 34; iter: 0; batch classifier loss: 0.077180; batch adversarial loss: 0.463351\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122470; batch adversarial loss: 0.531468\n",
      "epoch 36; iter: 0; batch classifier loss: 0.170466; batch adversarial loss: 0.439902\n",
      "epoch 37; iter: 0; batch classifier loss: 0.105610; batch adversarial loss: 0.460981\n",
      "epoch 38; iter: 0; batch classifier loss: 0.156925; batch adversarial loss: 0.432588\n",
      "epoch 39; iter: 0; batch classifier loss: 0.184123; batch adversarial loss: 0.462567\n",
      "epoch 40; iter: 0; batch classifier loss: 0.158770; batch adversarial loss: 0.415902\n",
      "epoch 41; iter: 0; batch classifier loss: 0.108968; batch adversarial loss: 0.457557\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102815; batch adversarial loss: 0.472422\n",
      "epoch 43; iter: 0; batch classifier loss: 0.107629; batch adversarial loss: 0.454668\n",
      "epoch 44; iter: 0; batch classifier loss: 0.075382; batch adversarial loss: 0.378624\n",
      "epoch 45; iter: 0; batch classifier loss: 0.093351; batch adversarial loss: 0.472588\n",
      "epoch 46; iter: 0; batch classifier loss: 0.073142; batch adversarial loss: 0.477654\n",
      "epoch 47; iter: 0; batch classifier loss: 0.161847; batch adversarial loss: 0.448369\n",
      "epoch 48; iter: 0; batch classifier loss: 0.120827; batch adversarial loss: 0.515429\n",
      "epoch 49; iter: 0; batch classifier loss: 0.059290; batch adversarial loss: 0.405930\n",
      "epoch 50; iter: 0; batch classifier loss: 0.070928; batch adversarial loss: 0.465668\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083994; batch adversarial loss: 0.569226\n",
      "epoch 52; iter: 0; batch classifier loss: 0.073778; batch adversarial loss: 0.526153\n",
      "epoch 53; iter: 0; batch classifier loss: 0.085467; batch adversarial loss: 0.466299\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122179; batch adversarial loss: 0.484536\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101129; batch adversarial loss: 0.382766\n",
      "epoch 56; iter: 0; batch classifier loss: 0.110693; batch adversarial loss: 0.381814\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086622; batch adversarial loss: 0.468187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.064960; batch adversarial loss: 0.452025\n",
      "epoch 59; iter: 0; batch classifier loss: 0.039130; batch adversarial loss: 0.489671\n",
      "epoch 60; iter: 0; batch classifier loss: 0.071082; batch adversarial loss: 0.515161\n",
      "epoch 61; iter: 0; batch classifier loss: 0.059757; batch adversarial loss: 0.459594\n",
      "epoch 62; iter: 0; batch classifier loss: 0.079646; batch adversarial loss: 0.417207\n",
      "epoch 63; iter: 0; batch classifier loss: 0.071270; batch adversarial loss: 0.573150\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080758; batch adversarial loss: 0.446758\n",
      "epoch 65; iter: 0; batch classifier loss: 0.066059; batch adversarial loss: 0.410234\n",
      "epoch 66; iter: 0; batch classifier loss: 0.097868; batch adversarial loss: 0.441809\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082402; batch adversarial loss: 0.501730\n",
      "epoch 68; iter: 0; batch classifier loss: 0.053084; batch adversarial loss: 0.447079\n",
      "epoch 69; iter: 0; batch classifier loss: 0.049119; batch adversarial loss: 0.472676\n",
      "epoch 70; iter: 0; batch classifier loss: 0.093776; batch adversarial loss: 0.446976\n",
      "epoch 71; iter: 0; batch classifier loss: 0.035578; batch adversarial loss: 0.447562\n",
      "epoch 72; iter: 0; batch classifier loss: 0.128671; batch adversarial loss: 0.425931\n",
      "epoch 73; iter: 0; batch classifier loss: 0.035170; batch adversarial loss: 0.442590\n",
      "epoch 74; iter: 0; batch classifier loss: 0.093091; batch adversarial loss: 0.417282\n",
      "epoch 75; iter: 0; batch classifier loss: 0.084990; batch adversarial loss: 0.391541\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055056; batch adversarial loss: 0.419540\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064779; batch adversarial loss: 0.465240\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071332; batch adversarial loss: 0.516531\n",
      "epoch 79; iter: 0; batch classifier loss: 0.153116; batch adversarial loss: 0.422596\n",
      "epoch 80; iter: 0; batch classifier loss: 0.071428; batch adversarial loss: 0.404487\n",
      "epoch 81; iter: 0; batch classifier loss: 0.048871; batch adversarial loss: 0.522331\n",
      "epoch 82; iter: 0; batch classifier loss: 0.078638; batch adversarial loss: 0.444299\n",
      "epoch 83; iter: 0; batch classifier loss: 0.045464; batch adversarial loss: 0.497305\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069183; batch adversarial loss: 0.411691\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056689; batch adversarial loss: 0.430440\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046647; batch adversarial loss: 0.398056\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067373; batch adversarial loss: 0.494977\n",
      "epoch 88; iter: 0; batch classifier loss: 0.061414; batch adversarial loss: 0.489854\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069708; batch adversarial loss: 0.388713\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042006; batch adversarial loss: 0.531328\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045387; batch adversarial loss: 0.455850\n",
      "epoch 92; iter: 0; batch classifier loss: 0.089455; batch adversarial loss: 0.517230\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047996; batch adversarial loss: 0.491061\n",
      "epoch 94; iter: 0; batch classifier loss: 0.052090; batch adversarial loss: 0.437759\n",
      "epoch 95; iter: 0; batch classifier loss: 0.088480; batch adversarial loss: 0.439550\n",
      "epoch 96; iter: 0; batch classifier loss: 0.021015; batch adversarial loss: 0.402441\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057953; batch adversarial loss: 0.438993\n",
      "epoch 98; iter: 0; batch classifier loss: 0.068868; batch adversarial loss: 0.493734\n",
      "epoch 99; iter: 0; batch classifier loss: 0.025060; batch adversarial loss: 0.482885\n",
      "epoch 100; iter: 0; batch classifier loss: 0.071941; batch adversarial loss: 0.413068\n",
      "epoch 101; iter: 0; batch classifier loss: 0.080106; batch adversarial loss: 0.496170\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062710; batch adversarial loss: 0.472939\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035943; batch adversarial loss: 0.444320\n",
      "epoch 104; iter: 0; batch classifier loss: 0.096425; batch adversarial loss: 0.505437\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049911; batch adversarial loss: 0.469596\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030135; batch adversarial loss: 0.457415\n",
      "epoch 107; iter: 0; batch classifier loss: 0.079881; batch adversarial loss: 0.466703\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045786; batch adversarial loss: 0.484138\n",
      "epoch 109; iter: 0; batch classifier loss: 0.065557; batch adversarial loss: 0.416318\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045773; batch adversarial loss: 0.415221\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043305; batch adversarial loss: 0.468664\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043769; batch adversarial loss: 0.464334\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043848; batch adversarial loss: 0.489381\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048763; batch adversarial loss: 0.541195\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060997; batch adversarial loss: 0.500927\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022333; batch adversarial loss: 0.458682\n",
      "epoch 117; iter: 0; batch classifier loss: 0.017365; batch adversarial loss: 0.432384\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040657; batch adversarial loss: 0.419435\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032963; batch adversarial loss: 0.492007\n",
      "epoch 120; iter: 0; batch classifier loss: 0.067012; batch adversarial loss: 0.405987\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049409; batch adversarial loss: 0.468953\n",
      "epoch 122; iter: 0; batch classifier loss: 0.092088; batch adversarial loss: 0.464265\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029393; batch adversarial loss: 0.413658\n",
      "epoch 124; iter: 0; batch classifier loss: 0.014191; batch adversarial loss: 0.473515\n",
      "epoch 125; iter: 0; batch classifier loss: 0.019295; batch adversarial loss: 0.493716\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019978; batch adversarial loss: 0.457715\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051111; batch adversarial loss: 0.496578\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034152; batch adversarial loss: 0.460610\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033059; batch adversarial loss: 0.431505\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032239; batch adversarial loss: 0.457869\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055498; batch adversarial loss: 0.456211\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045969; batch adversarial loss: 0.413165\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037284; batch adversarial loss: 0.515648\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028923; batch adversarial loss: 0.554148\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026522; batch adversarial loss: 0.469149\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035064; batch adversarial loss: 0.392635\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033707; batch adversarial loss: 0.449154\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037057; batch adversarial loss: 0.546346\n",
      "epoch 139; iter: 0; batch classifier loss: 0.055094; batch adversarial loss: 0.460504\n",
      "epoch 140; iter: 0; batch classifier loss: 0.061729; batch adversarial loss: 0.436836\n",
      "epoch 141; iter: 0; batch classifier loss: 0.072105; batch adversarial loss: 0.494359\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013209; batch adversarial loss: 0.397848\n",
      "epoch 143; iter: 0; batch classifier loss: 0.049969; batch adversarial loss: 0.382015\n",
      "epoch 144; iter: 0; batch classifier loss: 0.061014; batch adversarial loss: 0.471629\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045015; batch adversarial loss: 0.393142\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013560; batch adversarial loss: 0.392306\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028490; batch adversarial loss: 0.498497\n",
      "epoch 148; iter: 0; batch classifier loss: 0.079650; batch adversarial loss: 0.460036\n",
      "epoch 149; iter: 0; batch classifier loss: 0.008543; batch adversarial loss: 0.460997\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021716; batch adversarial loss: 0.525445\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018760; batch adversarial loss: 0.414293\n",
      "epoch 152; iter: 0; batch classifier loss: 0.007584; batch adversarial loss: 0.446171\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040640; batch adversarial loss: 0.388711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.019815; batch adversarial loss: 0.513751\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025896; batch adversarial loss: 0.482908\n",
      "epoch 156; iter: 0; batch classifier loss: 0.049272; batch adversarial loss: 0.416403\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039635; batch adversarial loss: 0.455427\n",
      "epoch 158; iter: 0; batch classifier loss: 0.043325; batch adversarial loss: 0.471654\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028002; batch adversarial loss: 0.471182\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032455; batch adversarial loss: 0.393263\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028072; batch adversarial loss: 0.484310\n",
      "epoch 162; iter: 0; batch classifier loss: 0.053143; batch adversarial loss: 0.500050\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013937; batch adversarial loss: 0.470834\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032537; batch adversarial loss: 0.477630\n",
      "epoch 165; iter: 0; batch classifier loss: 0.051150; batch adversarial loss: 0.469676\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034646; batch adversarial loss: 0.473980\n",
      "epoch 167; iter: 0; batch classifier loss: 0.048554; batch adversarial loss: 0.455387\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019152; batch adversarial loss: 0.399419\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018029; batch adversarial loss: 0.473350\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021721; batch adversarial loss: 0.491133\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019826; batch adversarial loss: 0.517449\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026658; batch adversarial loss: 0.353023\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026789; batch adversarial loss: 0.470348\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037454; batch adversarial loss: 0.484814\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036182; batch adversarial loss: 0.427570\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021551; batch adversarial loss: 0.455261\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025251; batch adversarial loss: 0.412390\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040829; batch adversarial loss: 0.375500\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012146; batch adversarial loss: 0.533529\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025547; batch adversarial loss: 0.576116\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015216; batch adversarial loss: 0.424715\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008289; batch adversarial loss: 0.459207\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005079; batch adversarial loss: 0.534155\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016451; batch adversarial loss: 0.459756\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022458; batch adversarial loss: 0.454448\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020171; batch adversarial loss: 0.427637\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018949; batch adversarial loss: 0.457393\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020349; batch adversarial loss: 0.445219\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035117; batch adversarial loss: 0.410377\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021521; batch adversarial loss: 0.415252\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030118; batch adversarial loss: 0.350512\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019808; batch adversarial loss: 0.523473\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018082; batch adversarial loss: 0.408728\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039953; batch adversarial loss: 0.445806\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031273; batch adversarial loss: 0.454587\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009540; batch adversarial loss: 0.372596\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022199; batch adversarial loss: 0.460354\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018350; batch adversarial loss: 0.495961\n",
      "epoch 199; iter: 0; batch classifier loss: 0.041433; batch adversarial loss: 0.390927\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677722; batch adversarial loss: 0.737457\n",
      "epoch 1; iter: 0; batch classifier loss: 0.559451; batch adversarial loss: 0.722876\n",
      "epoch 2; iter: 0; batch classifier loss: 0.535197; batch adversarial loss: 0.669123\n",
      "epoch 3; iter: 0; batch classifier loss: 0.437781; batch adversarial loss: 0.590443\n",
      "epoch 4; iter: 0; batch classifier loss: 0.346931; batch adversarial loss: 0.577250\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362360; batch adversarial loss: 0.561657\n",
      "epoch 6; iter: 0; batch classifier loss: 0.385239; batch adversarial loss: 0.541596\n",
      "epoch 7; iter: 0; batch classifier loss: 0.348959; batch adversarial loss: 0.562210\n",
      "epoch 8; iter: 0; batch classifier loss: 0.315758; batch adversarial loss: 0.547219\n",
      "epoch 9; iter: 0; batch classifier loss: 0.317111; batch adversarial loss: 0.538405\n",
      "epoch 10; iter: 0; batch classifier loss: 0.312672; batch adversarial loss: 0.578820\n",
      "epoch 11; iter: 0; batch classifier loss: 0.274200; batch adversarial loss: 0.523951\n",
      "epoch 12; iter: 0; batch classifier loss: 0.248960; batch adversarial loss: 0.441356\n",
      "epoch 13; iter: 0; batch classifier loss: 0.263963; batch adversarial loss: 0.474195\n",
      "epoch 14; iter: 0; batch classifier loss: 0.397220; batch adversarial loss: 0.504095\n",
      "epoch 15; iter: 0; batch classifier loss: 0.253148; batch adversarial loss: 0.506310\n",
      "epoch 16; iter: 0; batch classifier loss: 0.212018; batch adversarial loss: 0.485054\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225839; batch adversarial loss: 0.505794\n",
      "epoch 18; iter: 0; batch classifier loss: 0.175390; batch adversarial loss: 0.522353\n",
      "epoch 19; iter: 0; batch classifier loss: 0.254167; batch adversarial loss: 0.450703\n",
      "epoch 20; iter: 0; batch classifier loss: 0.166124; batch adversarial loss: 0.470525\n",
      "epoch 21; iter: 0; batch classifier loss: 0.241001; batch adversarial loss: 0.513682\n",
      "epoch 22; iter: 0; batch classifier loss: 0.186104; batch adversarial loss: 0.444574\n",
      "epoch 23; iter: 0; batch classifier loss: 0.200128; batch adversarial loss: 0.472468\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168130; batch adversarial loss: 0.455611\n",
      "epoch 25; iter: 0; batch classifier loss: 0.162694; batch adversarial loss: 0.439446\n",
      "epoch 26; iter: 0; batch classifier loss: 0.113201; batch adversarial loss: 0.480568\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181091; batch adversarial loss: 0.464272\n",
      "epoch 28; iter: 0; batch classifier loss: 0.177421; batch adversarial loss: 0.418458\n",
      "epoch 29; iter: 0; batch classifier loss: 0.148362; batch adversarial loss: 0.526867\n",
      "epoch 30; iter: 0; batch classifier loss: 0.118234; batch adversarial loss: 0.428054\n",
      "epoch 31; iter: 0; batch classifier loss: 0.145051; batch adversarial loss: 0.465756\n",
      "epoch 32; iter: 0; batch classifier loss: 0.150238; batch adversarial loss: 0.495918\n",
      "epoch 33; iter: 0; batch classifier loss: 0.149180; batch adversarial loss: 0.533005\n",
      "epoch 34; iter: 0; batch classifier loss: 0.153739; batch adversarial loss: 0.473811\n",
      "epoch 35; iter: 0; batch classifier loss: 0.131127; batch adversarial loss: 0.468484\n",
      "epoch 36; iter: 0; batch classifier loss: 0.087803; batch adversarial loss: 0.515126\n",
      "epoch 37; iter: 0; batch classifier loss: 0.136223; batch adversarial loss: 0.369109\n",
      "epoch 38; iter: 0; batch classifier loss: 0.142260; batch adversarial loss: 0.476582\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107664; batch adversarial loss: 0.517807\n",
      "epoch 40; iter: 0; batch classifier loss: 0.169301; batch adversarial loss: 0.520514\n",
      "epoch 41; iter: 0; batch classifier loss: 0.121853; batch adversarial loss: 0.412656\n",
      "epoch 42; iter: 0; batch classifier loss: 0.134342; batch adversarial loss: 0.348697\n",
      "epoch 43; iter: 0; batch classifier loss: 0.111951; batch adversarial loss: 0.515729\n",
      "epoch 44; iter: 0; batch classifier loss: 0.109872; batch adversarial loss: 0.500110\n",
      "epoch 45; iter: 0; batch classifier loss: 0.078692; batch adversarial loss: 0.502403\n",
      "epoch 46; iter: 0; batch classifier loss: 0.097465; batch adversarial loss: 0.386090\n",
      "epoch 47; iter: 0; batch classifier loss: 0.055243; batch adversarial loss: 0.497264\n",
      "epoch 48; iter: 0; batch classifier loss: 0.094096; batch adversarial loss: 0.430683\n",
      "epoch 49; iter: 0; batch classifier loss: 0.067193; batch adversarial loss: 0.392986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.118592; batch adversarial loss: 0.429136\n",
      "epoch 51; iter: 0; batch classifier loss: 0.082528; batch adversarial loss: 0.474182\n",
      "epoch 52; iter: 0; batch classifier loss: 0.070644; batch adversarial loss: 0.393155\n",
      "epoch 53; iter: 0; batch classifier loss: 0.127270; batch adversarial loss: 0.557051\n",
      "epoch 54; iter: 0; batch classifier loss: 0.086986; batch adversarial loss: 0.461732\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101301; batch adversarial loss: 0.408821\n",
      "epoch 56; iter: 0; batch classifier loss: 0.055386; batch adversarial loss: 0.493325\n",
      "epoch 57; iter: 0; batch classifier loss: 0.126557; batch adversarial loss: 0.432864\n",
      "epoch 58; iter: 0; batch classifier loss: 0.075131; batch adversarial loss: 0.466116\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083087; batch adversarial loss: 0.409456\n",
      "epoch 60; iter: 0; batch classifier loss: 0.067106; batch adversarial loss: 0.409592\n",
      "epoch 61; iter: 0; batch classifier loss: 0.059485; batch adversarial loss: 0.366925\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078305; batch adversarial loss: 0.420916\n",
      "epoch 63; iter: 0; batch classifier loss: 0.094884; batch adversarial loss: 0.487871\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070089; batch adversarial loss: 0.507242\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065468; batch adversarial loss: 0.386738\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070105; batch adversarial loss: 0.502035\n",
      "epoch 67; iter: 0; batch classifier loss: 0.099961; batch adversarial loss: 0.420494\n",
      "epoch 68; iter: 0; batch classifier loss: 0.047495; batch adversarial loss: 0.451353\n",
      "epoch 69; iter: 0; batch classifier loss: 0.112836; batch adversarial loss: 0.371599\n",
      "epoch 70; iter: 0; batch classifier loss: 0.039593; batch adversarial loss: 0.501448\n",
      "epoch 71; iter: 0; batch classifier loss: 0.059812; batch adversarial loss: 0.417516\n",
      "epoch 72; iter: 0; batch classifier loss: 0.063613; batch adversarial loss: 0.498810\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081660; batch adversarial loss: 0.429904\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076042; batch adversarial loss: 0.378786\n",
      "epoch 75; iter: 0; batch classifier loss: 0.121424; batch adversarial loss: 0.430923\n",
      "epoch 76; iter: 0; batch classifier loss: 0.071926; batch adversarial loss: 0.545123\n",
      "epoch 77; iter: 0; batch classifier loss: 0.051101; batch adversarial loss: 0.479794\n",
      "epoch 78; iter: 0; batch classifier loss: 0.050583; batch adversarial loss: 0.410857\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074383; batch adversarial loss: 0.434238\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064658; batch adversarial loss: 0.462467\n",
      "epoch 81; iter: 0; batch classifier loss: 0.056483; batch adversarial loss: 0.483482\n",
      "epoch 82; iter: 0; batch classifier loss: 0.069540; batch adversarial loss: 0.372959\n",
      "epoch 83; iter: 0; batch classifier loss: 0.036140; batch adversarial loss: 0.483784\n",
      "epoch 84; iter: 0; batch classifier loss: 0.027026; batch adversarial loss: 0.533917\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067034; batch adversarial loss: 0.409334\n",
      "epoch 86; iter: 0; batch classifier loss: 0.037462; batch adversarial loss: 0.445772\n",
      "epoch 87; iter: 0; batch classifier loss: 0.070944; batch adversarial loss: 0.475763\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051872; batch adversarial loss: 0.393414\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058015; batch adversarial loss: 0.562574\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059958; batch adversarial loss: 0.541011\n",
      "epoch 91; iter: 0; batch classifier loss: 0.053847; batch adversarial loss: 0.447150\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079328; batch adversarial loss: 0.500228\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063959; batch adversarial loss: 0.494542\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048896; batch adversarial loss: 0.455753\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045098; batch adversarial loss: 0.428043\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071070; batch adversarial loss: 0.476364\n",
      "epoch 97; iter: 0; batch classifier loss: 0.033748; batch adversarial loss: 0.458674\n",
      "epoch 98; iter: 0; batch classifier loss: 0.031555; batch adversarial loss: 0.588539\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049628; batch adversarial loss: 0.509014\n",
      "epoch 100; iter: 0; batch classifier loss: 0.087201; batch adversarial loss: 0.533290\n",
      "epoch 101; iter: 0; batch classifier loss: 0.066089; batch adversarial loss: 0.419505\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060753; batch adversarial loss: 0.427688\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049167; batch adversarial loss: 0.451309\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065692; batch adversarial loss: 0.549710\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045103; batch adversarial loss: 0.526879\n",
      "epoch 106; iter: 0; batch classifier loss: 0.021418; batch adversarial loss: 0.342957\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048646; batch adversarial loss: 0.439972\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030944; batch adversarial loss: 0.436557\n",
      "epoch 109; iter: 0; batch classifier loss: 0.035562; batch adversarial loss: 0.497806\n",
      "epoch 110; iter: 0; batch classifier loss: 0.018904; batch adversarial loss: 0.432366\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033654; batch adversarial loss: 0.449330\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034389; batch adversarial loss: 0.541720\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025444; batch adversarial loss: 0.545783\n",
      "epoch 114; iter: 0; batch classifier loss: 0.058192; batch adversarial loss: 0.403273\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027790; batch adversarial loss: 0.554941\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052461; batch adversarial loss: 0.499926\n",
      "epoch 117; iter: 0; batch classifier loss: 0.057684; batch adversarial loss: 0.413989\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040145; batch adversarial loss: 0.450624\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033593; batch adversarial loss: 0.435188\n",
      "epoch 120; iter: 0; batch classifier loss: 0.019707; batch adversarial loss: 0.449152\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023775; batch adversarial loss: 0.440371\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051669; batch adversarial loss: 0.416299\n",
      "epoch 123; iter: 0; batch classifier loss: 0.061896; batch adversarial loss: 0.469604\n",
      "epoch 124; iter: 0; batch classifier loss: 0.018048; batch adversarial loss: 0.371291\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027193; batch adversarial loss: 0.403413\n",
      "epoch 126; iter: 0; batch classifier loss: 0.041275; batch adversarial loss: 0.386639\n",
      "epoch 127; iter: 0; batch classifier loss: 0.066600; batch adversarial loss: 0.441294\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033687; batch adversarial loss: 0.454521\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025249; batch adversarial loss: 0.546358\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035953; batch adversarial loss: 0.455028\n",
      "epoch 131; iter: 0; batch classifier loss: 0.007080; batch adversarial loss: 0.483668\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029800; batch adversarial loss: 0.520690\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032188; batch adversarial loss: 0.472402\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032173; batch adversarial loss: 0.518326\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022837; batch adversarial loss: 0.511866\n",
      "epoch 136; iter: 0; batch classifier loss: 0.012399; batch adversarial loss: 0.386917\n",
      "epoch 137; iter: 0; batch classifier loss: 0.053992; batch adversarial loss: 0.393194\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035384; batch adversarial loss: 0.480886\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036111; batch adversarial loss: 0.519134\n",
      "epoch 140; iter: 0; batch classifier loss: 0.009492; batch adversarial loss: 0.576449\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040940; batch adversarial loss: 0.416579\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049438; batch adversarial loss: 0.406720\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034339; batch adversarial loss: 0.397118\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027551; batch adversarial loss: 0.457177\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022310; batch adversarial loss: 0.521983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.024305; batch adversarial loss: 0.357650\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040000; batch adversarial loss: 0.440865\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011923; batch adversarial loss: 0.451996\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024040; batch adversarial loss: 0.447459\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011946; batch adversarial loss: 0.473639\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033746; batch adversarial loss: 0.451178\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022472; batch adversarial loss: 0.484553\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018611; batch adversarial loss: 0.383260\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018555; batch adversarial loss: 0.552098\n",
      "epoch 155; iter: 0; batch classifier loss: 0.073120; batch adversarial loss: 0.440170\n",
      "epoch 156; iter: 0; batch classifier loss: 0.087744; batch adversarial loss: 0.366694\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032886; batch adversarial loss: 0.398414\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013315; batch adversarial loss: 0.418802\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013546; batch adversarial loss: 0.497014\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028719; batch adversarial loss: 0.448640\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012203; batch adversarial loss: 0.484085\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025690; batch adversarial loss: 0.442717\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020555; batch adversarial loss: 0.472949\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022571; batch adversarial loss: 0.472944\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008938; batch adversarial loss: 0.501318\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032210; batch adversarial loss: 0.517964\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022575; batch adversarial loss: 0.508644\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010897; batch adversarial loss: 0.493544\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008048; batch adversarial loss: 0.439168\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039700; batch adversarial loss: 0.404581\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032435; batch adversarial loss: 0.513916\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015850; batch adversarial loss: 0.457293\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024796; batch adversarial loss: 0.475618\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017170; batch adversarial loss: 0.446538\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019536; batch adversarial loss: 0.505425\n",
      "epoch 176; iter: 0; batch classifier loss: 0.047570; batch adversarial loss: 0.504370\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012885; batch adversarial loss: 0.439190\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018678; batch adversarial loss: 0.468958\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020137; batch adversarial loss: 0.414821\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022678; batch adversarial loss: 0.387291\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013598; batch adversarial loss: 0.432334\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018252; batch adversarial loss: 0.435818\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006637; batch adversarial loss: 0.425544\n",
      "epoch 184; iter: 0; batch classifier loss: 0.063045; batch adversarial loss: 0.466436\n",
      "epoch 185; iter: 0; batch classifier loss: 0.046760; batch adversarial loss: 0.525985\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020662; batch adversarial loss: 0.377635\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019485; batch adversarial loss: 0.446450\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022762; batch adversarial loss: 0.458963\n",
      "epoch 189; iter: 0; batch classifier loss: 0.047677; batch adversarial loss: 0.378803\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017491; batch adversarial loss: 0.448351\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017724; batch adversarial loss: 0.416279\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018605; batch adversarial loss: 0.511514\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027486; batch adversarial loss: 0.388528\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025134; batch adversarial loss: 0.464762\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006259; batch adversarial loss: 0.461061\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010057; batch adversarial loss: 0.402033\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009151; batch adversarial loss: 0.353729\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018985; batch adversarial loss: 0.452290\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005811; batch adversarial loss: 0.331851\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703071; batch adversarial loss: 0.898541\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591722; batch adversarial loss: 0.930895\n",
      "epoch 2; iter: 0; batch classifier loss: 0.761580; batch adversarial loss: 0.940389\n",
      "epoch 3; iter: 0; batch classifier loss: 0.974030; batch adversarial loss: 0.876586\n",
      "epoch 4; iter: 0; batch classifier loss: 1.042507; batch adversarial loss: 0.788572\n",
      "epoch 5; iter: 0; batch classifier loss: 1.096749; batch adversarial loss: 0.713967\n",
      "epoch 6; iter: 0; batch classifier loss: 1.059009; batch adversarial loss: 0.643588\n",
      "epoch 7; iter: 0; batch classifier loss: 0.827614; batch adversarial loss: 0.599369\n",
      "epoch 8; iter: 0; batch classifier loss: 0.497249; batch adversarial loss: 0.540717\n",
      "epoch 9; iter: 0; batch classifier loss: 0.312819; batch adversarial loss: 0.556446\n",
      "epoch 10; iter: 0; batch classifier loss: 0.353470; batch adversarial loss: 0.545300\n",
      "epoch 11; iter: 0; batch classifier loss: 0.309119; batch adversarial loss: 0.537352\n",
      "epoch 12; iter: 0; batch classifier loss: 0.343506; batch adversarial loss: 0.532377\n",
      "epoch 13; iter: 0; batch classifier loss: 0.343043; batch adversarial loss: 0.553825\n",
      "epoch 14; iter: 0; batch classifier loss: 0.351682; batch adversarial loss: 0.533352\n",
      "epoch 15; iter: 0; batch classifier loss: 0.340862; batch adversarial loss: 0.552288\n",
      "epoch 16; iter: 0; batch classifier loss: 0.260103; batch adversarial loss: 0.476731\n",
      "epoch 17; iter: 0; batch classifier loss: 0.288248; batch adversarial loss: 0.492685\n",
      "epoch 18; iter: 0; batch classifier loss: 0.360852; batch adversarial loss: 0.506677\n",
      "epoch 19; iter: 0; batch classifier loss: 0.291517; batch adversarial loss: 0.490849\n",
      "epoch 20; iter: 0; batch classifier loss: 0.243486; batch adversarial loss: 0.501987\n",
      "epoch 21; iter: 0; batch classifier loss: 0.312442; batch adversarial loss: 0.524576\n",
      "epoch 22; iter: 0; batch classifier loss: 0.356488; batch adversarial loss: 0.451587\n",
      "epoch 23; iter: 0; batch classifier loss: 0.265451; batch adversarial loss: 0.440263\n",
      "epoch 24; iter: 0; batch classifier loss: 0.335483; batch adversarial loss: 0.488220\n",
      "epoch 25; iter: 0; batch classifier loss: 0.279420; batch adversarial loss: 0.535587\n",
      "epoch 26; iter: 0; batch classifier loss: 0.286215; batch adversarial loss: 0.450450\n",
      "epoch 27; iter: 0; batch classifier loss: 0.274604; batch adversarial loss: 0.443033\n",
      "epoch 28; iter: 0; batch classifier loss: 0.292997; batch adversarial loss: 0.382324\n",
      "epoch 29; iter: 0; batch classifier loss: 0.289680; batch adversarial loss: 0.507058\n",
      "epoch 30; iter: 0; batch classifier loss: 0.316205; batch adversarial loss: 0.484852\n",
      "epoch 31; iter: 0; batch classifier loss: 0.238292; batch adversarial loss: 0.509022\n",
      "epoch 32; iter: 0; batch classifier loss: 0.299242; batch adversarial loss: 0.468607\n",
      "epoch 33; iter: 0; batch classifier loss: 0.309015; batch adversarial loss: 0.474393\n",
      "epoch 34; iter: 0; batch classifier loss: 0.284945; batch adversarial loss: 0.499959\n",
      "epoch 35; iter: 0; batch classifier loss: 0.240417; batch adversarial loss: 0.433646\n",
      "epoch 36; iter: 0; batch classifier loss: 0.271497; batch adversarial loss: 0.495301\n",
      "epoch 37; iter: 0; batch classifier loss: 0.210940; batch adversarial loss: 0.466633\n",
      "epoch 38; iter: 0; batch classifier loss: 0.219965; batch adversarial loss: 0.485509\n",
      "epoch 39; iter: 0; batch classifier loss: 0.275597; batch adversarial loss: 0.492592\n",
      "epoch 40; iter: 0; batch classifier loss: 0.238589; batch adversarial loss: 0.443405\n",
      "epoch 41; iter: 0; batch classifier loss: 0.264831; batch adversarial loss: 0.499741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.175579; batch adversarial loss: 0.527471\n",
      "epoch 43; iter: 0; batch classifier loss: 0.187768; batch adversarial loss: 0.496150\n",
      "epoch 44; iter: 0; batch classifier loss: 0.262758; batch adversarial loss: 0.447278\n",
      "epoch 45; iter: 0; batch classifier loss: 0.227697; batch adversarial loss: 0.461881\n",
      "epoch 46; iter: 0; batch classifier loss: 0.236969; batch adversarial loss: 0.438305\n",
      "epoch 47; iter: 0; batch classifier loss: 0.162732; batch adversarial loss: 0.336372\n",
      "epoch 48; iter: 0; batch classifier loss: 0.255131; batch adversarial loss: 0.507665\n",
      "epoch 49; iter: 0; batch classifier loss: 0.227287; batch adversarial loss: 0.468235\n",
      "epoch 50; iter: 0; batch classifier loss: 0.206914; batch adversarial loss: 0.401200\n",
      "epoch 51; iter: 0; batch classifier loss: 0.174692; batch adversarial loss: 0.484860\n",
      "epoch 52; iter: 0; batch classifier loss: 0.173521; batch adversarial loss: 0.490831\n",
      "epoch 53; iter: 0; batch classifier loss: 0.193982; batch adversarial loss: 0.461710\n",
      "epoch 54; iter: 0; batch classifier loss: 0.192856; batch adversarial loss: 0.365371\n",
      "epoch 55; iter: 0; batch classifier loss: 0.155080; batch adversarial loss: 0.598014\n",
      "epoch 56; iter: 0; batch classifier loss: 0.223640; batch adversarial loss: 0.480380\n",
      "epoch 57; iter: 0; batch classifier loss: 0.207838; batch adversarial loss: 0.368497\n",
      "epoch 58; iter: 0; batch classifier loss: 0.127178; batch adversarial loss: 0.577767\n",
      "epoch 59; iter: 0; batch classifier loss: 0.224967; batch adversarial loss: 0.446313\n",
      "epoch 60; iter: 0; batch classifier loss: 0.213684; batch adversarial loss: 0.505971\n",
      "epoch 61; iter: 0; batch classifier loss: 0.216816; batch adversarial loss: 0.352255\n",
      "epoch 62; iter: 0; batch classifier loss: 0.203988; batch adversarial loss: 0.470865\n",
      "epoch 63; iter: 0; batch classifier loss: 0.156832; batch adversarial loss: 0.460036\n",
      "epoch 64; iter: 0; batch classifier loss: 0.146829; batch adversarial loss: 0.432805\n",
      "epoch 65; iter: 0; batch classifier loss: 0.171011; batch adversarial loss: 0.568812\n",
      "epoch 66; iter: 0; batch classifier loss: 0.204359; batch adversarial loss: 0.458489\n",
      "epoch 67; iter: 0; batch classifier loss: 0.255244; batch adversarial loss: 0.436673\n",
      "epoch 68; iter: 0; batch classifier loss: 0.235269; batch adversarial loss: 0.469634\n",
      "epoch 69; iter: 0; batch classifier loss: 0.198840; batch adversarial loss: 0.508237\n",
      "epoch 70; iter: 0; batch classifier loss: 0.179284; batch adversarial loss: 0.448008\n",
      "epoch 71; iter: 0; batch classifier loss: 0.154388; batch adversarial loss: 0.373719\n",
      "epoch 72; iter: 0; batch classifier loss: 0.210562; batch adversarial loss: 0.410341\n",
      "epoch 73; iter: 0; batch classifier loss: 0.171524; batch adversarial loss: 0.495449\n",
      "epoch 74; iter: 0; batch classifier loss: 0.181293; batch adversarial loss: 0.460585\n",
      "epoch 75; iter: 0; batch classifier loss: 0.248126; batch adversarial loss: 0.471358\n",
      "epoch 76; iter: 0; batch classifier loss: 0.224844; batch adversarial loss: 0.435666\n",
      "epoch 77; iter: 0; batch classifier loss: 0.240362; batch adversarial loss: 0.470365\n",
      "epoch 78; iter: 0; batch classifier loss: 0.212844; batch adversarial loss: 0.566236\n",
      "epoch 79; iter: 0; batch classifier loss: 0.186593; batch adversarial loss: 0.482371\n",
      "epoch 80; iter: 0; batch classifier loss: 0.176603; batch adversarial loss: 0.435094\n",
      "epoch 81; iter: 0; batch classifier loss: 0.255657; batch adversarial loss: 0.482892\n",
      "epoch 82; iter: 0; batch classifier loss: 0.149083; batch adversarial loss: 0.470923\n",
      "epoch 83; iter: 0; batch classifier loss: 0.153836; batch adversarial loss: 0.434601\n",
      "epoch 84; iter: 0; batch classifier loss: 0.129553; batch adversarial loss: 0.569013\n",
      "epoch 85; iter: 0; batch classifier loss: 0.174381; batch adversarial loss: 0.507127\n",
      "epoch 86; iter: 0; batch classifier loss: 0.125135; batch adversarial loss: 0.446386\n",
      "epoch 87; iter: 0; batch classifier loss: 0.170913; batch adversarial loss: 0.471722\n",
      "epoch 88; iter: 0; batch classifier loss: 0.208017; batch adversarial loss: 0.506146\n",
      "epoch 89; iter: 0; batch classifier loss: 0.205728; batch adversarial loss: 0.579746\n",
      "epoch 90; iter: 0; batch classifier loss: 0.200427; batch adversarial loss: 0.495031\n",
      "epoch 91; iter: 0; batch classifier loss: 0.160157; batch adversarial loss: 0.482981\n",
      "epoch 92; iter: 0; batch classifier loss: 0.191797; batch adversarial loss: 0.410449\n",
      "epoch 93; iter: 0; batch classifier loss: 0.197004; batch adversarial loss: 0.410868\n",
      "epoch 94; iter: 0; batch classifier loss: 0.118472; batch adversarial loss: 0.482999\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053569; batch adversarial loss: 0.435045\n",
      "epoch 96; iter: 0; batch classifier loss: 0.080309; batch adversarial loss: 0.433149\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056848; batch adversarial loss: 0.490370\n",
      "epoch 98; iter: 0; batch classifier loss: 0.076892; batch adversarial loss: 0.431885\n",
      "epoch 99; iter: 0; batch classifier loss: 0.097973; batch adversarial loss: 0.411069\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064980; batch adversarial loss: 0.522445\n",
      "epoch 101; iter: 0; batch classifier loss: 0.079861; batch adversarial loss: 0.381149\n",
      "epoch 102; iter: 0; batch classifier loss: 0.085097; batch adversarial loss: 0.550083\n",
      "epoch 103; iter: 0; batch classifier loss: 0.102754; batch adversarial loss: 0.426134\n",
      "epoch 104; iter: 0; batch classifier loss: 0.102597; batch adversarial loss: 0.450125\n",
      "epoch 105; iter: 0; batch classifier loss: 0.068059; batch adversarial loss: 0.402149\n",
      "epoch 106; iter: 0; batch classifier loss: 0.078275; batch adversarial loss: 0.491757\n",
      "epoch 107; iter: 0; batch classifier loss: 0.043527; batch adversarial loss: 0.497304\n",
      "epoch 108; iter: 0; batch classifier loss: 0.097914; batch adversarial loss: 0.617513\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059945; batch adversarial loss: 0.499637\n",
      "epoch 110; iter: 0; batch classifier loss: 0.092777; batch adversarial loss: 0.395558\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046711; batch adversarial loss: 0.539559\n",
      "epoch 112; iter: 0; batch classifier loss: 0.084049; batch adversarial loss: 0.414943\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055707; batch adversarial loss: 0.448386\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048221; batch adversarial loss: 0.500805\n",
      "epoch 115; iter: 0; batch classifier loss: 0.073936; batch adversarial loss: 0.469782\n",
      "epoch 116; iter: 0; batch classifier loss: 0.071086; batch adversarial loss: 0.439503\n",
      "epoch 117; iter: 0; batch classifier loss: 0.058724; batch adversarial loss: 0.427262\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046773; batch adversarial loss: 0.450022\n",
      "epoch 119; iter: 0; batch classifier loss: 0.075935; batch adversarial loss: 0.501944\n",
      "epoch 120; iter: 0; batch classifier loss: 0.106363; batch adversarial loss: 0.448065\n",
      "epoch 121; iter: 0; batch classifier loss: 0.070173; batch adversarial loss: 0.375514\n",
      "epoch 122; iter: 0; batch classifier loss: 0.075441; batch adversarial loss: 0.488944\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036211; batch adversarial loss: 0.462642\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032907; batch adversarial loss: 0.443760\n",
      "epoch 125; iter: 0; batch classifier loss: 0.013717; batch adversarial loss: 0.450002\n",
      "epoch 126; iter: 0; batch classifier loss: 0.013376; batch adversarial loss: 0.370296\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040799; batch adversarial loss: 0.491369\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052739; batch adversarial loss: 0.501666\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036242; batch adversarial loss: 0.546126\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017704; batch adversarial loss: 0.437781\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028875; batch adversarial loss: 0.468008\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034434; batch adversarial loss: 0.455296\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037664; batch adversarial loss: 0.493644\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020312; batch adversarial loss: 0.396309\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057497; batch adversarial loss: 0.456649\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020744; batch adversarial loss: 0.417394\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025551; batch adversarial loss: 0.457509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.061997; batch adversarial loss: 0.518589\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042402; batch adversarial loss: 0.521111\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048306; batch adversarial loss: 0.458081\n",
      "epoch 141; iter: 0; batch classifier loss: 0.055927; batch adversarial loss: 0.443558\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023825; batch adversarial loss: 0.447117\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034299; batch adversarial loss: 0.525531\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053859; batch adversarial loss: 0.479789\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027807; batch adversarial loss: 0.540119\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020987; batch adversarial loss: 0.491544\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019489; batch adversarial loss: 0.456693\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021327; batch adversarial loss: 0.508900\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031141; batch adversarial loss: 0.508237\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025968; batch adversarial loss: 0.470196\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020889; batch adversarial loss: 0.519847\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022193; batch adversarial loss: 0.499008\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017114; batch adversarial loss: 0.444926\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043982; batch adversarial loss: 0.520895\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017875; batch adversarial loss: 0.439427\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026601; batch adversarial loss: 0.381124\n",
      "epoch 157; iter: 0; batch classifier loss: 0.044698; batch adversarial loss: 0.606409\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021951; batch adversarial loss: 0.404403\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037064; batch adversarial loss: 0.535513\n",
      "epoch 160; iter: 0; batch classifier loss: 0.049747; batch adversarial loss: 0.426501\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035747; batch adversarial loss: 0.571201\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015489; batch adversarial loss: 0.430205\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013525; batch adversarial loss: 0.495358\n",
      "epoch 164; iter: 0; batch classifier loss: 0.040288; batch adversarial loss: 0.414636\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041040; batch adversarial loss: 0.469502\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031135; batch adversarial loss: 0.424833\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013804; batch adversarial loss: 0.469981\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016999; batch adversarial loss: 0.518195\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018552; batch adversarial loss: 0.487136\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020870; batch adversarial loss: 0.457735\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011954; batch adversarial loss: 0.476158\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017071; batch adversarial loss: 0.431422\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022511; batch adversarial loss: 0.461192\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009747; batch adversarial loss: 0.406487\n",
      "epoch 175; iter: 0; batch classifier loss: 0.003785; batch adversarial loss: 0.545188\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007200; batch adversarial loss: 0.444486\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023799; batch adversarial loss: 0.396883\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014561; batch adversarial loss: 0.408028\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009219; batch adversarial loss: 0.549990\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034326; batch adversarial loss: 0.438311\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012765; batch adversarial loss: 0.465238\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013977; batch adversarial loss: 0.461237\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018521; batch adversarial loss: 0.554761\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022184; batch adversarial loss: 0.407472\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017952; batch adversarial loss: 0.413132\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014700; batch adversarial loss: 0.574370\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015325; batch adversarial loss: 0.430884\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004094; batch adversarial loss: 0.437388\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006764; batch adversarial loss: 0.524070\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011642; batch adversarial loss: 0.464524\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010279; batch adversarial loss: 0.404103\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015394; batch adversarial loss: 0.434183\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027576; batch adversarial loss: 0.433078\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015263; batch adversarial loss: 0.460344\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006201; batch adversarial loss: 0.527098\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016419; batch adversarial loss: 0.503357\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005562; batch adversarial loss: 0.490647\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006734; batch adversarial loss: 0.465148\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010672; batch adversarial loss: 0.517898\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692105; batch adversarial loss: 0.591795\n",
      "epoch 1; iter: 0; batch classifier loss: 0.438179; batch adversarial loss: 0.599749\n",
      "epoch 2; iter: 0; batch classifier loss: 0.373014; batch adversarial loss: 0.595225\n",
      "epoch 3; iter: 0; batch classifier loss: 0.315592; batch adversarial loss: 0.546429\n",
      "epoch 4; iter: 0; batch classifier loss: 0.319308; batch adversarial loss: 0.537522\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343431; batch adversarial loss: 0.551837\n",
      "epoch 6; iter: 0; batch classifier loss: 0.323128; batch adversarial loss: 0.582336\n",
      "epoch 7; iter: 0; batch classifier loss: 0.278568; batch adversarial loss: 0.524454\n",
      "epoch 8; iter: 0; batch classifier loss: 0.285449; batch adversarial loss: 0.521433\n",
      "epoch 9; iter: 0; batch classifier loss: 0.292812; batch adversarial loss: 0.548932\n",
      "epoch 10; iter: 0; batch classifier loss: 0.265653; batch adversarial loss: 0.548139\n",
      "epoch 11; iter: 0; batch classifier loss: 0.288106; batch adversarial loss: 0.532238\n",
      "epoch 12; iter: 0; batch classifier loss: 0.292028; batch adversarial loss: 0.543461\n",
      "epoch 13; iter: 0; batch classifier loss: 0.381653; batch adversarial loss: 0.536070\n",
      "epoch 14; iter: 0; batch classifier loss: 0.517340; batch adversarial loss: 0.543206\n",
      "epoch 15; iter: 0; batch classifier loss: 0.383095; batch adversarial loss: 0.569948\n",
      "epoch 16; iter: 0; batch classifier loss: 0.545895; batch adversarial loss: 0.493018\n",
      "epoch 17; iter: 0; batch classifier loss: 0.453930; batch adversarial loss: 0.485156\n",
      "epoch 18; iter: 0; batch classifier loss: 0.312253; batch adversarial loss: 0.465490\n",
      "epoch 19; iter: 0; batch classifier loss: 0.193836; batch adversarial loss: 0.444500\n",
      "epoch 20; iter: 0; batch classifier loss: 0.217067; batch adversarial loss: 0.475869\n",
      "epoch 21; iter: 0; batch classifier loss: 0.181713; batch adversarial loss: 0.438458\n",
      "epoch 22; iter: 0; batch classifier loss: 0.161721; batch adversarial loss: 0.431337\n",
      "epoch 23; iter: 0; batch classifier loss: 0.184571; batch adversarial loss: 0.436738\n",
      "epoch 24; iter: 0; batch classifier loss: 0.171569; batch adversarial loss: 0.493752\n",
      "epoch 25; iter: 0; batch classifier loss: 0.159435; batch adversarial loss: 0.505136\n",
      "epoch 26; iter: 0; batch classifier loss: 0.150167; batch adversarial loss: 0.435445\n",
      "epoch 27; iter: 0; batch classifier loss: 0.104247; batch adversarial loss: 0.466556\n",
      "epoch 28; iter: 0; batch classifier loss: 0.116327; batch adversarial loss: 0.496289\n",
      "epoch 29; iter: 0; batch classifier loss: 0.284049; batch adversarial loss: 0.444399\n",
      "epoch 30; iter: 0; batch classifier loss: 0.102780; batch adversarial loss: 0.426115\n",
      "epoch 31; iter: 0; batch classifier loss: 0.168161; batch adversarial loss: 0.451780\n",
      "epoch 32; iter: 0; batch classifier loss: 0.107116; batch adversarial loss: 0.412814\n",
      "epoch 33; iter: 0; batch classifier loss: 0.092824; batch adversarial loss: 0.473511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.140883; batch adversarial loss: 0.451779\n",
      "epoch 35; iter: 0; batch classifier loss: 0.108006; batch adversarial loss: 0.503649\n",
      "epoch 36; iter: 0; batch classifier loss: 0.136785; batch adversarial loss: 0.504763\n",
      "epoch 37; iter: 0; batch classifier loss: 0.136339; batch adversarial loss: 0.415199\n",
      "epoch 38; iter: 0; batch classifier loss: 0.150664; batch adversarial loss: 0.442158\n",
      "epoch 39; iter: 0; batch classifier loss: 0.159001; batch adversarial loss: 0.385358\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099014; batch adversarial loss: 0.519551\n",
      "epoch 41; iter: 0; batch classifier loss: 0.087699; batch adversarial loss: 0.429748\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116446; batch adversarial loss: 0.519975\n",
      "epoch 43; iter: 0; batch classifier loss: 0.124386; batch adversarial loss: 0.436795\n",
      "epoch 44; iter: 0; batch classifier loss: 0.064382; batch adversarial loss: 0.494863\n",
      "epoch 45; iter: 0; batch classifier loss: 0.083393; batch adversarial loss: 0.443588\n",
      "epoch 46; iter: 0; batch classifier loss: 0.081640; batch adversarial loss: 0.426572\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096478; batch adversarial loss: 0.430937\n",
      "epoch 48; iter: 0; batch classifier loss: 0.155534; batch adversarial loss: 0.409962\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096627; batch adversarial loss: 0.470524\n",
      "epoch 50; iter: 0; batch classifier loss: 0.131537; batch adversarial loss: 0.443676\n",
      "epoch 51; iter: 0; batch classifier loss: 0.114427; batch adversarial loss: 0.464304\n",
      "epoch 52; iter: 0; batch classifier loss: 0.106032; batch adversarial loss: 0.466202\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098446; batch adversarial loss: 0.483826\n",
      "epoch 54; iter: 0; batch classifier loss: 0.106531; batch adversarial loss: 0.452497\n",
      "epoch 55; iter: 0; batch classifier loss: 0.126548; batch adversarial loss: 0.437702\n",
      "epoch 56; iter: 0; batch classifier loss: 0.094024; batch adversarial loss: 0.475904\n",
      "epoch 57; iter: 0; batch classifier loss: 0.124227; batch adversarial loss: 0.410207\n",
      "epoch 58; iter: 0; batch classifier loss: 0.116426; batch adversarial loss: 0.467765\n",
      "epoch 59; iter: 0; batch classifier loss: 0.121343; batch adversarial loss: 0.615580\n",
      "epoch 60; iter: 0; batch classifier loss: 0.109123; batch adversarial loss: 0.498220\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088940; batch adversarial loss: 0.514528\n",
      "epoch 62; iter: 0; batch classifier loss: 0.070591; batch adversarial loss: 0.441397\n",
      "epoch 63; iter: 0; batch classifier loss: 0.071246; batch adversarial loss: 0.514738\n",
      "epoch 64; iter: 0; batch classifier loss: 0.103743; batch adversarial loss: 0.479523\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079465; batch adversarial loss: 0.433181\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093174; batch adversarial loss: 0.493849\n",
      "epoch 67; iter: 0; batch classifier loss: 0.129316; batch adversarial loss: 0.476977\n",
      "epoch 68; iter: 0; batch classifier loss: 0.083139; batch adversarial loss: 0.482122\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081714; batch adversarial loss: 0.520507\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078822; batch adversarial loss: 0.482044\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079240; batch adversarial loss: 0.539580\n",
      "epoch 72; iter: 0; batch classifier loss: 0.078613; batch adversarial loss: 0.467068\n",
      "epoch 73; iter: 0; batch classifier loss: 0.105133; batch adversarial loss: 0.444980\n",
      "epoch 74; iter: 0; batch classifier loss: 0.072381; batch adversarial loss: 0.528060\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069202; batch adversarial loss: 0.430120\n",
      "epoch 76; iter: 0; batch classifier loss: 0.090263; batch adversarial loss: 0.522643\n",
      "epoch 77; iter: 0; batch classifier loss: 0.070712; batch adversarial loss: 0.393445\n",
      "epoch 78; iter: 0; batch classifier loss: 0.099111; batch adversarial loss: 0.475412\n",
      "epoch 79; iter: 0; batch classifier loss: 0.050981; batch adversarial loss: 0.483816\n",
      "epoch 80; iter: 0; batch classifier loss: 0.082718; batch adversarial loss: 0.455914\n",
      "epoch 81; iter: 0; batch classifier loss: 0.056804; batch adversarial loss: 0.404134\n",
      "epoch 82; iter: 0; batch classifier loss: 0.087964; batch adversarial loss: 0.547281\n",
      "epoch 83; iter: 0; batch classifier loss: 0.100178; batch adversarial loss: 0.461749\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065938; batch adversarial loss: 0.431468\n",
      "epoch 85; iter: 0; batch classifier loss: 0.053333; batch adversarial loss: 0.366468\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067654; batch adversarial loss: 0.407859\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053962; batch adversarial loss: 0.401279\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049174; batch adversarial loss: 0.423986\n",
      "epoch 89; iter: 0; batch classifier loss: 0.041241; batch adversarial loss: 0.463301\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050889; batch adversarial loss: 0.397677\n",
      "epoch 91; iter: 0; batch classifier loss: 0.061862; batch adversarial loss: 0.477144\n",
      "epoch 92; iter: 0; batch classifier loss: 0.076024; batch adversarial loss: 0.394197\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064497; batch adversarial loss: 0.416650\n",
      "epoch 94; iter: 0; batch classifier loss: 0.118642; batch adversarial loss: 0.411645\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071968; batch adversarial loss: 0.437662\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059561; batch adversarial loss: 0.477469\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046889; batch adversarial loss: 0.489168\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061206; batch adversarial loss: 0.363833\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052048; batch adversarial loss: 0.524563\n",
      "epoch 100; iter: 0; batch classifier loss: 0.080822; batch adversarial loss: 0.366481\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046533; batch adversarial loss: 0.537480\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060267; batch adversarial loss: 0.469442\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062081; batch adversarial loss: 0.545675\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061069; batch adversarial loss: 0.427411\n",
      "epoch 105; iter: 0; batch classifier loss: 0.081234; batch adversarial loss: 0.455184\n",
      "epoch 106; iter: 0; batch classifier loss: 0.082041; batch adversarial loss: 0.547459\n",
      "epoch 107; iter: 0; batch classifier loss: 0.100498; batch adversarial loss: 0.489062\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048209; batch adversarial loss: 0.460457\n",
      "epoch 109; iter: 0; batch classifier loss: 0.086180; batch adversarial loss: 0.452884\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025399; batch adversarial loss: 0.533108\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053338; batch adversarial loss: 0.419459\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025676; batch adversarial loss: 0.446619\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034848; batch adversarial loss: 0.422222\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035250; batch adversarial loss: 0.454954\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039402; batch adversarial loss: 0.516435\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033656; batch adversarial loss: 0.438307\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040465; batch adversarial loss: 0.453144\n",
      "epoch 118; iter: 0; batch classifier loss: 0.068741; batch adversarial loss: 0.481186\n",
      "epoch 119; iter: 0; batch classifier loss: 0.075800; batch adversarial loss: 0.501116\n",
      "epoch 120; iter: 0; batch classifier loss: 0.018392; batch adversarial loss: 0.413824\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043600; batch adversarial loss: 0.524666\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026677; batch adversarial loss: 0.320603\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053256; batch adversarial loss: 0.469962\n",
      "epoch 124; iter: 0; batch classifier loss: 0.028351; batch adversarial loss: 0.469767\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030624; batch adversarial loss: 0.545265\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039609; batch adversarial loss: 0.427592\n",
      "epoch 127; iter: 0; batch classifier loss: 0.049250; batch adversarial loss: 0.375053\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052260; batch adversarial loss: 0.430580\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021567; batch adversarial loss: 0.373748\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042119; batch adversarial loss: 0.431376\n",
      "epoch 131; iter: 0; batch classifier loss: 0.074867; batch adversarial loss: 0.633249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.050510; batch adversarial loss: 0.531236\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037259; batch adversarial loss: 0.439830\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054456; batch adversarial loss: 0.396729\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031628; batch adversarial loss: 0.383295\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042917; batch adversarial loss: 0.524332\n",
      "epoch 137; iter: 0; batch classifier loss: 0.053134; batch adversarial loss: 0.526119\n",
      "epoch 138; iter: 0; batch classifier loss: 0.047751; batch adversarial loss: 0.405910\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037561; batch adversarial loss: 0.421952\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031747; batch adversarial loss: 0.434013\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034891; batch adversarial loss: 0.428818\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024796; batch adversarial loss: 0.436565\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040152; batch adversarial loss: 0.510785\n",
      "epoch 144; iter: 0; batch classifier loss: 0.057999; batch adversarial loss: 0.474677\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025275; batch adversarial loss: 0.476523\n",
      "epoch 146; iter: 0; batch classifier loss: 0.050576; batch adversarial loss: 0.421437\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014373; batch adversarial loss: 0.477749\n",
      "epoch 148; iter: 0; batch classifier loss: 0.050010; batch adversarial loss: 0.443437\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011919; batch adversarial loss: 0.401553\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027253; batch adversarial loss: 0.490692\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008811; batch adversarial loss: 0.500874\n",
      "epoch 152; iter: 0; batch classifier loss: 0.046868; batch adversarial loss: 0.403149\n",
      "epoch 153; iter: 0; batch classifier loss: 0.065881; batch adversarial loss: 0.450329\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011382; batch adversarial loss: 0.479971\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031254; batch adversarial loss: 0.356999\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017699; batch adversarial loss: 0.440150\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047459; batch adversarial loss: 0.427655\n",
      "epoch 158; iter: 0; batch classifier loss: 0.041314; batch adversarial loss: 0.323464\n",
      "epoch 159; iter: 0; batch classifier loss: 0.053126; batch adversarial loss: 0.497941\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044444; batch adversarial loss: 0.529491\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043698; batch adversarial loss: 0.471733\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017435; batch adversarial loss: 0.547735\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021500; batch adversarial loss: 0.412631\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035796; batch adversarial loss: 0.405269\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012618; batch adversarial loss: 0.433367\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030702; batch adversarial loss: 0.443089\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017923; batch adversarial loss: 0.530523\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016264; batch adversarial loss: 0.484378\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023500; batch adversarial loss: 0.477050\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027521; batch adversarial loss: 0.373478\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012970; batch adversarial loss: 0.502095\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024575; batch adversarial loss: 0.414043\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012320; batch adversarial loss: 0.512851\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011621; batch adversarial loss: 0.484709\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036839; batch adversarial loss: 0.519120\n",
      "epoch 176; iter: 0; batch classifier loss: 0.038546; batch adversarial loss: 0.420869\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026252; batch adversarial loss: 0.482479\n",
      "epoch 178; iter: 0; batch classifier loss: 0.055132; batch adversarial loss: 0.408135\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024652; batch adversarial loss: 0.552452\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040434; batch adversarial loss: 0.426607\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026727; batch adversarial loss: 0.387008\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027650; batch adversarial loss: 0.429739\n",
      "epoch 183; iter: 0; batch classifier loss: 0.048276; batch adversarial loss: 0.397484\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015346; batch adversarial loss: 0.503142\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024213; batch adversarial loss: 0.444435\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022742; batch adversarial loss: 0.460432\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040784; batch adversarial loss: 0.409998\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013286; batch adversarial loss: 0.442694\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034600; batch adversarial loss: 0.539810\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013397; batch adversarial loss: 0.369944\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028771; batch adversarial loss: 0.516808\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024554; batch adversarial loss: 0.414769\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037949; batch adversarial loss: 0.418594\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030412; batch adversarial loss: 0.403508\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018677; batch adversarial loss: 0.466222\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033986; batch adversarial loss: 0.434136\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012034; batch adversarial loss: 0.371019\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012591; batch adversarial loss: 0.566511\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008768; batch adversarial loss: 0.522937\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722421; batch adversarial loss: 0.698663\n",
      "epoch 1; iter: 0; batch classifier loss: 0.520810; batch adversarial loss: 0.666826\n",
      "epoch 2; iter: 0; batch classifier loss: 0.429184; batch adversarial loss: 0.604285\n",
      "epoch 3; iter: 0; batch classifier loss: 0.273784; batch adversarial loss: 0.600082\n",
      "epoch 4; iter: 0; batch classifier loss: 0.331964; batch adversarial loss: 0.573008\n",
      "epoch 5; iter: 0; batch classifier loss: 0.311452; batch adversarial loss: 0.547102\n",
      "epoch 6; iter: 0; batch classifier loss: 0.291205; batch adversarial loss: 0.484118\n",
      "epoch 7; iter: 0; batch classifier loss: 0.269183; batch adversarial loss: 0.512345\n",
      "epoch 8; iter: 0; batch classifier loss: 0.297085; batch adversarial loss: 0.492056\n",
      "epoch 9; iter: 0; batch classifier loss: 0.182482; batch adversarial loss: 0.527014\n",
      "epoch 10; iter: 0; batch classifier loss: 0.252152; batch adversarial loss: 0.489367\n",
      "epoch 11; iter: 0; batch classifier loss: 0.237374; batch adversarial loss: 0.493363\n",
      "epoch 12; iter: 0; batch classifier loss: 0.248586; batch adversarial loss: 0.523803\n",
      "epoch 13; iter: 0; batch classifier loss: 0.202944; batch adversarial loss: 0.443137\n",
      "epoch 14; iter: 0; batch classifier loss: 0.212616; batch adversarial loss: 0.408990\n",
      "epoch 15; iter: 0; batch classifier loss: 0.192582; batch adversarial loss: 0.457866\n",
      "epoch 16; iter: 0; batch classifier loss: 0.170206; batch adversarial loss: 0.503337\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192603; batch adversarial loss: 0.404848\n",
      "epoch 18; iter: 0; batch classifier loss: 0.149111; batch adversarial loss: 0.532084\n",
      "epoch 19; iter: 0; batch classifier loss: 0.155728; batch adversarial loss: 0.442494\n",
      "epoch 20; iter: 0; batch classifier loss: 0.148495; batch adversarial loss: 0.437947\n",
      "epoch 21; iter: 0; batch classifier loss: 0.164792; batch adversarial loss: 0.436750\n",
      "epoch 22; iter: 0; batch classifier loss: 0.136812; batch adversarial loss: 0.343316\n",
      "epoch 23; iter: 0; batch classifier loss: 0.156963; batch adversarial loss: 0.405129\n",
      "epoch 24; iter: 0; batch classifier loss: 0.183491; batch adversarial loss: 0.388081\n",
      "epoch 25; iter: 0; batch classifier loss: 0.143557; batch adversarial loss: 0.410158\n",
      "epoch 26; iter: 0; batch classifier loss: 0.109880; batch adversarial loss: 0.334718\n",
      "epoch 27; iter: 0; batch classifier loss: 0.135781; batch adversarial loss: 0.397608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.128916; batch adversarial loss: 0.416008\n",
      "epoch 29; iter: 0; batch classifier loss: 0.136529; batch adversarial loss: 0.383565\n",
      "epoch 30; iter: 0; batch classifier loss: 0.192054; batch adversarial loss: 0.467184\n",
      "epoch 31; iter: 0; batch classifier loss: 0.132966; batch adversarial loss: 0.424650\n",
      "epoch 32; iter: 0; batch classifier loss: 0.147438; batch adversarial loss: 0.414408\n",
      "epoch 33; iter: 0; batch classifier loss: 0.174151; batch adversarial loss: 0.536360\n",
      "epoch 34; iter: 0; batch classifier loss: 0.125924; batch adversarial loss: 0.294304\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122434; batch adversarial loss: 0.397295\n",
      "epoch 36; iter: 0; batch classifier loss: 0.135183; batch adversarial loss: 0.430325\n",
      "epoch 37; iter: 0; batch classifier loss: 0.127485; batch adversarial loss: 0.363313\n",
      "epoch 38; iter: 0; batch classifier loss: 0.121172; batch adversarial loss: 0.393273\n",
      "epoch 39; iter: 0; batch classifier loss: 0.110456; batch adversarial loss: 0.334082\n",
      "epoch 40; iter: 0; batch classifier loss: 0.180017; batch adversarial loss: 0.462548\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098136; batch adversarial loss: 0.389779\n",
      "epoch 42; iter: 0; batch classifier loss: 0.158392; batch adversarial loss: 0.386181\n",
      "epoch 43; iter: 0; batch classifier loss: 0.168454; batch adversarial loss: 0.418993\n",
      "epoch 44; iter: 0; batch classifier loss: 0.149903; batch adversarial loss: 0.382702\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104710; batch adversarial loss: 0.403230\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126053; batch adversarial loss: 0.417350\n",
      "epoch 47; iter: 0; batch classifier loss: 0.088411; batch adversarial loss: 0.394089\n",
      "epoch 48; iter: 0; batch classifier loss: 0.153738; batch adversarial loss: 0.511892\n",
      "epoch 49; iter: 0; batch classifier loss: 0.072156; batch adversarial loss: 0.388502\n",
      "epoch 50; iter: 0; batch classifier loss: 0.116992; batch adversarial loss: 0.461039\n",
      "epoch 51; iter: 0; batch classifier loss: 0.095142; batch adversarial loss: 0.440988\n",
      "epoch 52; iter: 0; batch classifier loss: 0.147783; batch adversarial loss: 0.452936\n",
      "epoch 53; iter: 0; batch classifier loss: 0.093306; batch adversarial loss: 0.380148\n",
      "epoch 54; iter: 0; batch classifier loss: 0.094879; batch adversarial loss: 0.423961\n",
      "epoch 55; iter: 0; batch classifier loss: 0.100462; batch adversarial loss: 0.415791\n",
      "epoch 56; iter: 0; batch classifier loss: 0.134154; batch adversarial loss: 0.406721\n",
      "epoch 57; iter: 0; batch classifier loss: 0.068158; batch adversarial loss: 0.424069\n",
      "epoch 58; iter: 0; batch classifier loss: 0.163899; batch adversarial loss: 0.474064\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092853; batch adversarial loss: 0.455432\n",
      "epoch 60; iter: 0; batch classifier loss: 0.078969; batch adversarial loss: 0.468513\n",
      "epoch 61; iter: 0; batch classifier loss: 0.077023; batch adversarial loss: 0.371110\n",
      "epoch 62; iter: 0; batch classifier loss: 0.077991; batch adversarial loss: 0.316895\n",
      "epoch 63; iter: 0; batch classifier loss: 0.083820; batch adversarial loss: 0.447538\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106258; batch adversarial loss: 0.466763\n",
      "epoch 65; iter: 0; batch classifier loss: 0.047329; batch adversarial loss: 0.394181\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093321; batch adversarial loss: 0.396429\n",
      "epoch 67; iter: 0; batch classifier loss: 0.063002; batch adversarial loss: 0.383483\n",
      "epoch 68; iter: 0; batch classifier loss: 0.077597; batch adversarial loss: 0.365220\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071154; batch adversarial loss: 0.345842\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098199; batch adversarial loss: 0.544746\n",
      "epoch 71; iter: 0; batch classifier loss: 0.080535; batch adversarial loss: 0.359239\n",
      "epoch 72; iter: 0; batch classifier loss: 0.108990; batch adversarial loss: 0.428871\n",
      "epoch 73; iter: 0; batch classifier loss: 0.051526; batch adversarial loss: 0.317309\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069342; batch adversarial loss: 0.387520\n",
      "epoch 75; iter: 0; batch classifier loss: 0.114141; batch adversarial loss: 0.379928\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083697; batch adversarial loss: 0.359501\n",
      "epoch 77; iter: 0; batch classifier loss: 0.057546; batch adversarial loss: 0.444902\n",
      "epoch 78; iter: 0; batch classifier loss: 0.086015; batch adversarial loss: 0.396508\n",
      "epoch 79; iter: 0; batch classifier loss: 0.094214; batch adversarial loss: 0.509812\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074623; batch adversarial loss: 0.410419\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057025; batch adversarial loss: 0.454799\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052659; batch adversarial loss: 0.392205\n",
      "epoch 83; iter: 0; batch classifier loss: 0.098049; batch adversarial loss: 0.384205\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062224; batch adversarial loss: 0.450322\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068250; batch adversarial loss: 0.354356\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064946; batch adversarial loss: 0.402843\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067066; batch adversarial loss: 0.392519\n",
      "epoch 88; iter: 0; batch classifier loss: 0.093855; batch adversarial loss: 0.481511\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053935; batch adversarial loss: 0.395888\n",
      "epoch 90; iter: 0; batch classifier loss: 0.088661; batch adversarial loss: 0.408933\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043433; batch adversarial loss: 0.533629\n",
      "epoch 92; iter: 0; batch classifier loss: 0.049568; batch adversarial loss: 0.433404\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079813; batch adversarial loss: 0.361823\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075921; batch adversarial loss: 0.502781\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056209; batch adversarial loss: 0.416976\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065213; batch adversarial loss: 0.436671\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081290; batch adversarial loss: 0.475922\n",
      "epoch 98; iter: 0; batch classifier loss: 0.076985; batch adversarial loss: 0.436267\n",
      "epoch 99; iter: 0; batch classifier loss: 0.116420; batch adversarial loss: 0.470314\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043515; batch adversarial loss: 0.469914\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061808; batch adversarial loss: 0.410211\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071677; batch adversarial loss: 0.457639\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056431; batch adversarial loss: 0.407619\n",
      "epoch 104; iter: 0; batch classifier loss: 0.084339; batch adversarial loss: 0.465187\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052927; batch adversarial loss: 0.366972\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044924; batch adversarial loss: 0.425496\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061452; batch adversarial loss: 0.440599\n",
      "epoch 108; iter: 0; batch classifier loss: 0.082795; batch adversarial loss: 0.486660\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050239; batch adversarial loss: 0.347580\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031824; batch adversarial loss: 0.388861\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052331; batch adversarial loss: 0.438370\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040289; batch adversarial loss: 0.487727\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040534; batch adversarial loss: 0.410191\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042995; batch adversarial loss: 0.411335\n",
      "epoch 115; iter: 0; batch classifier loss: 0.061124; batch adversarial loss: 0.400657\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055494; batch adversarial loss: 0.432770\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053028; batch adversarial loss: 0.380928\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044085; batch adversarial loss: 0.537699\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030560; batch adversarial loss: 0.465471\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062989; batch adversarial loss: 0.534846\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028335; batch adversarial loss: 0.484989\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032492; batch adversarial loss: 0.547221\n",
      "epoch 123; iter: 0; batch classifier loss: 0.018107; batch adversarial loss: 0.441830\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067936; batch adversarial loss: 0.497736\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048900; batch adversarial loss: 0.361346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.056905; batch adversarial loss: 0.543420\n",
      "epoch 127; iter: 0; batch classifier loss: 0.083893; batch adversarial loss: 0.493139\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044424; batch adversarial loss: 0.491338\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022171; batch adversarial loss: 0.411296\n",
      "epoch 130; iter: 0; batch classifier loss: 0.103532; batch adversarial loss: 0.653266\n",
      "epoch 131; iter: 0; batch classifier loss: 0.152828; batch adversarial loss: 0.705470\n",
      "epoch 132; iter: 0; batch classifier loss: 0.124701; batch adversarial loss: 0.588505\n",
      "epoch 133; iter: 0; batch classifier loss: 0.106326; batch adversarial loss: 0.594974\n",
      "epoch 134; iter: 0; batch classifier loss: 0.143464; batch adversarial loss: 0.606871\n",
      "epoch 135; iter: 0; batch classifier loss: 0.143449; batch adversarial loss: 0.620551\n",
      "epoch 136; iter: 0; batch classifier loss: 0.078185; batch adversarial loss: 0.538579\n",
      "epoch 137; iter: 0; batch classifier loss: 0.242869; batch adversarial loss: 0.628571\n",
      "epoch 138; iter: 0; batch classifier loss: 0.159412; batch adversarial loss: 0.568317\n",
      "epoch 139; iter: 0; batch classifier loss: 0.179503; batch adversarial loss: 0.611191\n",
      "epoch 140; iter: 0; batch classifier loss: 0.068065; batch adversarial loss: 0.552188\n",
      "epoch 141; iter: 0; batch classifier loss: 0.126832; batch adversarial loss: 0.583099\n",
      "epoch 142; iter: 0; batch classifier loss: 0.126600; batch adversarial loss: 0.438538\n",
      "epoch 143; iter: 0; batch classifier loss: 0.151556; batch adversarial loss: 0.544070\n",
      "epoch 144; iter: 0; batch classifier loss: 0.138573; batch adversarial loss: 0.494060\n",
      "epoch 145; iter: 0; batch classifier loss: 0.065445; batch adversarial loss: 0.396274\n",
      "epoch 146; iter: 0; batch classifier loss: 0.179774; batch adversarial loss: 0.558398\n",
      "epoch 147; iter: 0; batch classifier loss: 0.088663; batch adversarial loss: 0.527340\n",
      "epoch 148; iter: 0; batch classifier loss: 0.093343; batch adversarial loss: 0.550490\n",
      "epoch 149; iter: 0; batch classifier loss: 0.119444; batch adversarial loss: 0.543435\n",
      "epoch 150; iter: 0; batch classifier loss: 0.151921; batch adversarial loss: 0.632439\n",
      "epoch 151; iter: 0; batch classifier loss: 0.126092; batch adversarial loss: 0.493555\n",
      "epoch 152; iter: 0; batch classifier loss: 0.090253; batch adversarial loss: 0.492374\n",
      "epoch 153; iter: 0; batch classifier loss: 0.132822; batch adversarial loss: 0.524335\n",
      "epoch 154; iter: 0; batch classifier loss: 0.106380; batch adversarial loss: 0.501806\n",
      "epoch 155; iter: 0; batch classifier loss: 0.145916; batch adversarial loss: 0.546461\n",
      "epoch 156; iter: 0; batch classifier loss: 0.081493; batch adversarial loss: 0.438299\n",
      "epoch 157; iter: 0; batch classifier loss: 0.110867; batch adversarial loss: 0.547720\n",
      "epoch 158; iter: 0; batch classifier loss: 0.054016; batch adversarial loss: 0.374442\n",
      "epoch 159; iter: 0; batch classifier loss: 0.134952; batch adversarial loss: 0.492807\n",
      "epoch 160; iter: 0; batch classifier loss: 0.113235; batch adversarial loss: 0.511509\n",
      "epoch 161; iter: 0; batch classifier loss: 0.150490; batch adversarial loss: 0.502988\n",
      "epoch 162; iter: 0; batch classifier loss: 0.142164; batch adversarial loss: 0.429042\n",
      "epoch 163; iter: 0; batch classifier loss: 0.061820; batch adversarial loss: 0.414158\n",
      "epoch 164; iter: 0; batch classifier loss: 0.093572; batch adversarial loss: 0.459753\n",
      "epoch 165; iter: 0; batch classifier loss: 0.107413; batch adversarial loss: 0.533198\n",
      "epoch 166; iter: 0; batch classifier loss: 0.093885; batch adversarial loss: 0.394530\n",
      "epoch 167; iter: 0; batch classifier loss: 0.080189; batch adversarial loss: 0.455947\n",
      "epoch 168; iter: 0; batch classifier loss: 0.098228; batch adversarial loss: 0.498240\n",
      "epoch 169; iter: 0; batch classifier loss: 0.110663; batch adversarial loss: 0.519651\n",
      "epoch 170; iter: 0; batch classifier loss: 0.101370; batch adversarial loss: 0.541778\n",
      "epoch 171; iter: 0; batch classifier loss: 0.092634; batch adversarial loss: 0.447096\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033033; batch adversarial loss: 0.416562\n",
      "epoch 173; iter: 0; batch classifier loss: 0.047852; batch adversarial loss: 0.445392\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023508; batch adversarial loss: 0.398448\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040251; batch adversarial loss: 0.460307\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020176; batch adversarial loss: 0.457919\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022459; batch adversarial loss: 0.436037\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040815; batch adversarial loss: 0.490244\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032944; batch adversarial loss: 0.400149\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034128; batch adversarial loss: 0.456322\n",
      "epoch 181; iter: 0; batch classifier loss: 0.045585; batch adversarial loss: 0.375428\n",
      "epoch 182; iter: 0; batch classifier loss: 0.047533; batch adversarial loss: 0.415437\n",
      "epoch 183; iter: 0; batch classifier loss: 0.050860; batch adversarial loss: 0.460809\n",
      "epoch 184; iter: 0; batch classifier loss: 0.044820; batch adversarial loss: 0.484673\n",
      "epoch 185; iter: 0; batch classifier loss: 0.048024; batch adversarial loss: 0.451707\n",
      "epoch 186; iter: 0; batch classifier loss: 0.155354; batch adversarial loss: 0.373281\n",
      "epoch 187; iter: 0; batch classifier loss: 0.069259; batch adversarial loss: 0.483009\n",
      "epoch 188; iter: 0; batch classifier loss: 0.068476; batch adversarial loss: 0.463054\n",
      "epoch 189; iter: 0; batch classifier loss: 0.049472; batch adversarial loss: 0.533963\n",
      "epoch 190; iter: 0; batch classifier loss: 0.117141; batch adversarial loss: 0.421897\n",
      "epoch 191; iter: 0; batch classifier loss: 0.084441; batch adversarial loss: 0.462932\n",
      "epoch 192; iter: 0; batch classifier loss: 0.143446; batch adversarial loss: 0.401836\n",
      "epoch 193; iter: 0; batch classifier loss: 0.055247; batch adversarial loss: 0.457274\n",
      "epoch 194; iter: 0; batch classifier loss: 0.083143; batch adversarial loss: 0.475551\n",
      "epoch 195; iter: 0; batch classifier loss: 0.077912; batch adversarial loss: 0.467203\n",
      "epoch 196; iter: 0; batch classifier loss: 0.083114; batch adversarial loss: 0.422343\n",
      "epoch 197; iter: 0; batch classifier loss: 0.111516; batch adversarial loss: 0.435304\n",
      "epoch 198; iter: 0; batch classifier loss: 0.045250; batch adversarial loss: 0.445647\n",
      "epoch 199; iter: 0; batch classifier loss: 0.051989; batch adversarial loss: 0.500539\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695001; batch adversarial loss: 0.773299\n",
      "epoch 1; iter: 0; batch classifier loss: 0.428071; batch adversarial loss: 0.701339\n",
      "epoch 2; iter: 0; batch classifier loss: 0.395703; batch adversarial loss: 0.685820\n",
      "epoch 3; iter: 0; batch classifier loss: 0.488717; batch adversarial loss: 0.659104\n",
      "epoch 4; iter: 0; batch classifier loss: 0.345643; batch adversarial loss: 0.632601\n",
      "epoch 5; iter: 0; batch classifier loss: 0.326744; batch adversarial loss: 0.609841\n",
      "epoch 6; iter: 0; batch classifier loss: 0.393323; batch adversarial loss: 0.555227\n",
      "epoch 7; iter: 0; batch classifier loss: 0.346857; batch adversarial loss: 0.514546\n",
      "epoch 8; iter: 0; batch classifier loss: 0.330294; batch adversarial loss: 0.497405\n",
      "epoch 9; iter: 0; batch classifier loss: 0.293508; batch adversarial loss: 0.529705\n",
      "epoch 10; iter: 0; batch classifier loss: 0.241194; batch adversarial loss: 0.500823\n",
      "epoch 11; iter: 0; batch classifier loss: 0.272203; batch adversarial loss: 0.468462\n",
      "epoch 12; iter: 0; batch classifier loss: 0.248292; batch adversarial loss: 0.426961\n",
      "epoch 13; iter: 0; batch classifier loss: 0.206437; batch adversarial loss: 0.476377\n",
      "epoch 14; iter: 0; batch classifier loss: 0.267177; batch adversarial loss: 0.516740\n",
      "epoch 15; iter: 0; batch classifier loss: 0.195086; batch adversarial loss: 0.471021\n",
      "epoch 16; iter: 0; batch classifier loss: 0.217774; batch adversarial loss: 0.463325\n",
      "epoch 17; iter: 0; batch classifier loss: 0.158712; batch adversarial loss: 0.417117\n",
      "epoch 18; iter: 0; batch classifier loss: 0.207888; batch adversarial loss: 0.514333\n",
      "epoch 19; iter: 0; batch classifier loss: 0.201196; batch adversarial loss: 0.418435\n",
      "epoch 20; iter: 0; batch classifier loss: 0.232155; batch adversarial loss: 0.462599\n",
      "epoch 21; iter: 0; batch classifier loss: 0.293428; batch adversarial loss: 0.497670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.251186; batch adversarial loss: 0.399655\n",
      "epoch 23; iter: 0; batch classifier loss: 0.188538; batch adversarial loss: 0.441514\n",
      "epoch 24; iter: 0; batch classifier loss: 0.129704; batch adversarial loss: 0.417108\n",
      "epoch 25; iter: 0; batch classifier loss: 0.175509; batch adversarial loss: 0.451319\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181173; batch adversarial loss: 0.482683\n",
      "epoch 27; iter: 0; batch classifier loss: 0.145690; batch adversarial loss: 0.380680\n",
      "epoch 28; iter: 0; batch classifier loss: 0.149608; batch adversarial loss: 0.328444\n",
      "epoch 29; iter: 0; batch classifier loss: 0.185593; batch adversarial loss: 0.432921\n",
      "epoch 30; iter: 0; batch classifier loss: 0.209729; batch adversarial loss: 0.373494\n",
      "epoch 31; iter: 0; batch classifier loss: 0.149687; batch adversarial loss: 0.436457\n",
      "epoch 32; iter: 0; batch classifier loss: 0.120165; batch adversarial loss: 0.464993\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145678; batch adversarial loss: 0.447788\n",
      "epoch 34; iter: 0; batch classifier loss: 0.194442; batch adversarial loss: 0.532591\n",
      "epoch 35; iter: 0; batch classifier loss: 0.134892; batch adversarial loss: 0.387451\n",
      "epoch 36; iter: 0; batch classifier loss: 0.153339; batch adversarial loss: 0.366751\n",
      "epoch 37; iter: 0; batch classifier loss: 0.148484; batch adversarial loss: 0.411572\n",
      "epoch 38; iter: 0; batch classifier loss: 0.197102; batch adversarial loss: 0.388596\n",
      "epoch 39; iter: 0; batch classifier loss: 0.161717; batch adversarial loss: 0.358934\n",
      "epoch 40; iter: 0; batch classifier loss: 0.092548; batch adversarial loss: 0.493761\n",
      "epoch 41; iter: 0; batch classifier loss: 0.137348; batch adversarial loss: 0.416256\n",
      "epoch 42; iter: 0; batch classifier loss: 0.104625; batch adversarial loss: 0.363538\n",
      "epoch 43; iter: 0; batch classifier loss: 0.113163; batch adversarial loss: 0.394375\n",
      "epoch 44; iter: 0; batch classifier loss: 0.073436; batch adversarial loss: 0.400390\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117221; batch adversarial loss: 0.465579\n",
      "epoch 46; iter: 0; batch classifier loss: 0.144309; batch adversarial loss: 0.465794\n",
      "epoch 47; iter: 0; batch classifier loss: 0.109458; batch adversarial loss: 0.360410\n",
      "epoch 48; iter: 0; batch classifier loss: 0.131684; batch adversarial loss: 0.501014\n",
      "epoch 49; iter: 0; batch classifier loss: 0.108230; batch adversarial loss: 0.354219\n",
      "epoch 50; iter: 0; batch classifier loss: 0.093610; batch adversarial loss: 0.454033\n",
      "epoch 51; iter: 0; batch classifier loss: 0.182536; batch adversarial loss: 0.392665\n",
      "epoch 52; iter: 0; batch classifier loss: 0.092725; batch adversarial loss: 0.346220\n",
      "epoch 53; iter: 0; batch classifier loss: 0.093723; batch adversarial loss: 0.388043\n",
      "epoch 54; iter: 0; batch classifier loss: 0.085401; batch adversarial loss: 0.379131\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117618; batch adversarial loss: 0.381466\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084095; batch adversarial loss: 0.432349\n",
      "epoch 57; iter: 0; batch classifier loss: 0.080448; batch adversarial loss: 0.435687\n",
      "epoch 58; iter: 0; batch classifier loss: 0.088900; batch adversarial loss: 0.497847\n",
      "epoch 59; iter: 0; batch classifier loss: 0.077377; batch adversarial loss: 0.509805\n",
      "epoch 60; iter: 0; batch classifier loss: 0.111930; batch adversarial loss: 0.487595\n",
      "epoch 61; iter: 0; batch classifier loss: 0.089970; batch adversarial loss: 0.445623\n",
      "epoch 62; iter: 0; batch classifier loss: 0.105841; batch adversarial loss: 0.455651\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098486; batch adversarial loss: 0.506585\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084638; batch adversarial loss: 0.360737\n",
      "epoch 65; iter: 0; batch classifier loss: 0.091387; batch adversarial loss: 0.452490\n",
      "epoch 66; iter: 0; batch classifier loss: 0.101179; batch adversarial loss: 0.503677\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100970; batch adversarial loss: 0.395869\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082930; batch adversarial loss: 0.540469\n",
      "epoch 69; iter: 0; batch classifier loss: 0.079486; batch adversarial loss: 0.382112\n",
      "epoch 70; iter: 0; batch classifier loss: 0.087320; batch adversarial loss: 0.325999\n",
      "epoch 71; iter: 0; batch classifier loss: 0.072980; batch adversarial loss: 0.445702\n",
      "epoch 72; iter: 0; batch classifier loss: 0.079650; batch adversarial loss: 0.420349\n",
      "epoch 73; iter: 0; batch classifier loss: 0.072628; batch adversarial loss: 0.379187\n",
      "epoch 74; iter: 0; batch classifier loss: 0.057500; batch adversarial loss: 0.448313\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068432; batch adversarial loss: 0.368322\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070360; batch adversarial loss: 0.460652\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090201; batch adversarial loss: 0.534065\n",
      "epoch 78; iter: 0; batch classifier loss: 0.081580; batch adversarial loss: 0.443169\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067150; batch adversarial loss: 0.501688\n",
      "epoch 80; iter: 0; batch classifier loss: 0.103028; batch adversarial loss: 0.500146\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079355; batch adversarial loss: 0.454046\n",
      "epoch 82; iter: 0; batch classifier loss: 0.107319; batch adversarial loss: 0.381080\n",
      "epoch 83; iter: 0; batch classifier loss: 0.119381; batch adversarial loss: 0.430922\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080835; batch adversarial loss: 0.447069\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070742; batch adversarial loss: 0.397533\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067613; batch adversarial loss: 0.441571\n",
      "epoch 87; iter: 0; batch classifier loss: 0.040000; batch adversarial loss: 0.421609\n",
      "epoch 88; iter: 0; batch classifier loss: 0.045316; batch adversarial loss: 0.370528\n",
      "epoch 89; iter: 0; batch classifier loss: 0.077125; batch adversarial loss: 0.433014\n",
      "epoch 90; iter: 0; batch classifier loss: 0.076397; batch adversarial loss: 0.415685\n",
      "epoch 91; iter: 0; batch classifier loss: 0.087636; batch adversarial loss: 0.418974\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051352; batch adversarial loss: 0.405909\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062601; batch adversarial loss: 0.440204\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072562; batch adversarial loss: 0.408511\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068393; batch adversarial loss: 0.406493\n",
      "epoch 96; iter: 0; batch classifier loss: 0.089845; batch adversarial loss: 0.405741\n",
      "epoch 97; iter: 0; batch classifier loss: 0.097822; batch adversarial loss: 0.419791\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079448; batch adversarial loss: 0.415329\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055911; batch adversarial loss: 0.391055\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050129; batch adversarial loss: 0.522505\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070094; batch adversarial loss: 0.441066\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031489; batch adversarial loss: 0.449813\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066126; batch adversarial loss: 0.446803\n",
      "epoch 104; iter: 0; batch classifier loss: 0.051804; batch adversarial loss: 0.553267\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059129; batch adversarial loss: 0.526265\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032581; batch adversarial loss: 0.489200\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046142; batch adversarial loss: 0.470647\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028769; batch adversarial loss: 0.448427\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034336; batch adversarial loss: 0.360306\n",
      "epoch 110; iter: 0; batch classifier loss: 0.024867; batch adversarial loss: 0.480822\n",
      "epoch 111; iter: 0; batch classifier loss: 0.021716; batch adversarial loss: 0.489970\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039171; batch adversarial loss: 0.397165\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028402; batch adversarial loss: 0.438572\n",
      "epoch 114; iter: 0; batch classifier loss: 0.020028; batch adversarial loss: 0.433295\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042182; batch adversarial loss: 0.495158\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042017; batch adversarial loss: 0.411394\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031541; batch adversarial loss: 0.481105\n",
      "epoch 118; iter: 0; batch classifier loss: 0.094791; batch adversarial loss: 0.646265\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055641; batch adversarial loss: 0.426976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.053387; batch adversarial loss: 0.504022\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052746; batch adversarial loss: 0.528253\n",
      "epoch 122; iter: 0; batch classifier loss: 0.109983; batch adversarial loss: 0.628463\n",
      "epoch 123; iter: 0; batch classifier loss: 0.079978; batch adversarial loss: 0.525457\n",
      "epoch 124; iter: 0; batch classifier loss: 0.082773; batch adversarial loss: 0.474411\n",
      "epoch 125; iter: 0; batch classifier loss: 0.179604; batch adversarial loss: 0.752687\n",
      "epoch 126; iter: 0; batch classifier loss: 0.133526; batch adversarial loss: 0.599372\n",
      "epoch 127; iter: 0; batch classifier loss: 0.126175; batch adversarial loss: 0.610466\n",
      "epoch 128; iter: 0; batch classifier loss: 0.201898; batch adversarial loss: 0.666122\n",
      "epoch 129; iter: 0; batch classifier loss: 0.187322; batch adversarial loss: 0.641940\n",
      "epoch 130; iter: 0; batch classifier loss: 0.159131; batch adversarial loss: 0.770085\n",
      "epoch 131; iter: 0; batch classifier loss: 0.174478; batch adversarial loss: 0.508911\n",
      "epoch 132; iter: 0; batch classifier loss: 0.192299; batch adversarial loss: 0.580084\n",
      "epoch 133; iter: 0; batch classifier loss: 0.211200; batch adversarial loss: 0.616681\n",
      "epoch 134; iter: 0; batch classifier loss: 0.123248; batch adversarial loss: 0.640302\n",
      "epoch 135; iter: 0; batch classifier loss: 0.101511; batch adversarial loss: 0.562513\n",
      "epoch 136; iter: 0; batch classifier loss: 0.155898; batch adversarial loss: 0.615593\n",
      "epoch 137; iter: 0; batch classifier loss: 0.255217; batch adversarial loss: 0.728277\n",
      "epoch 138; iter: 0; batch classifier loss: 0.190645; batch adversarial loss: 0.573154\n",
      "epoch 139; iter: 0; batch classifier loss: 0.159521; batch adversarial loss: 0.642486\n",
      "epoch 140; iter: 0; batch classifier loss: 0.252057; batch adversarial loss: 0.658293\n",
      "epoch 141; iter: 0; batch classifier loss: 0.094903; batch adversarial loss: 0.517136\n",
      "epoch 142; iter: 0; batch classifier loss: 0.120708; batch adversarial loss: 0.542149\n",
      "epoch 143; iter: 0; batch classifier loss: 0.135712; batch adversarial loss: 0.526127\n",
      "epoch 144; iter: 0; batch classifier loss: 0.181794; batch adversarial loss: 0.561346\n",
      "epoch 145; iter: 0; batch classifier loss: 0.135078; batch adversarial loss: 0.473984\n",
      "epoch 146; iter: 0; batch classifier loss: 0.145648; batch adversarial loss: 0.550203\n",
      "epoch 147; iter: 0; batch classifier loss: 0.126954; batch adversarial loss: 0.464732\n",
      "epoch 148; iter: 0; batch classifier loss: 0.147429; batch adversarial loss: 0.539521\n",
      "epoch 149; iter: 0; batch classifier loss: 0.061238; batch adversarial loss: 0.515931\n",
      "epoch 150; iter: 0; batch classifier loss: 0.187890; batch adversarial loss: 0.583336\n",
      "epoch 151; iter: 0; batch classifier loss: 0.088183; batch adversarial loss: 0.427456\n",
      "epoch 152; iter: 0; batch classifier loss: 0.125723; batch adversarial loss: 0.516012\n",
      "epoch 153; iter: 0; batch classifier loss: 0.153844; batch adversarial loss: 0.561274\n",
      "epoch 154; iter: 0; batch classifier loss: 0.060751; batch adversarial loss: 0.407769\n",
      "epoch 155; iter: 0; batch classifier loss: 0.115826; batch adversarial loss: 0.509665\n",
      "epoch 156; iter: 0; batch classifier loss: 0.120010; batch adversarial loss: 0.494299\n",
      "epoch 157; iter: 0; batch classifier loss: 0.111608; batch adversarial loss: 0.522150\n",
      "epoch 158; iter: 0; batch classifier loss: 0.076435; batch adversarial loss: 0.420516\n",
      "epoch 159; iter: 0; batch classifier loss: 0.136438; batch adversarial loss: 0.507455\n",
      "epoch 160; iter: 0; batch classifier loss: 0.085131; batch adversarial loss: 0.480127\n",
      "epoch 161; iter: 0; batch classifier loss: 0.086563; batch adversarial loss: 0.441168\n",
      "epoch 162; iter: 0; batch classifier loss: 0.135330; batch adversarial loss: 0.485862\n",
      "epoch 163; iter: 0; batch classifier loss: 0.091070; batch adversarial loss: 0.414721\n",
      "epoch 164; iter: 0; batch classifier loss: 0.050275; batch adversarial loss: 0.519184\n",
      "epoch 165; iter: 0; batch classifier loss: 0.062983; batch adversarial loss: 0.526177\n",
      "epoch 166; iter: 0; batch classifier loss: 0.094022; batch adversarial loss: 0.455511\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024072; batch adversarial loss: 0.534884\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034039; batch adversarial loss: 0.462583\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024426; batch adversarial loss: 0.471118\n",
      "epoch 170; iter: 0; batch classifier loss: 0.045498; batch adversarial loss: 0.412699\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047530; batch adversarial loss: 0.441368\n",
      "epoch 172; iter: 0; batch classifier loss: 0.057234; batch adversarial loss: 0.415247\n",
      "epoch 173; iter: 0; batch classifier loss: 0.086026; batch adversarial loss: 0.495930\n",
      "epoch 174; iter: 0; batch classifier loss: 0.082307; batch adversarial loss: 0.432554\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029179; batch adversarial loss: 0.477485\n",
      "epoch 176; iter: 0; batch classifier loss: 0.066502; batch adversarial loss: 0.446378\n",
      "epoch 177; iter: 0; batch classifier loss: 0.063852; batch adversarial loss: 0.434012\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033746; batch adversarial loss: 0.485631\n",
      "epoch 179; iter: 0; batch classifier loss: 0.073324; batch adversarial loss: 0.450221\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049122; batch adversarial loss: 0.574307\n",
      "epoch 181; iter: 0; batch classifier loss: 0.112520; batch adversarial loss: 0.372848\n",
      "epoch 182; iter: 0; batch classifier loss: 0.089913; batch adversarial loss: 0.487489\n",
      "epoch 183; iter: 0; batch classifier loss: 0.056966; batch adversarial loss: 0.589600\n",
      "epoch 184; iter: 0; batch classifier loss: 0.056522; batch adversarial loss: 0.434115\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032481; batch adversarial loss: 0.568380\n",
      "epoch 186; iter: 0; batch classifier loss: 0.053529; batch adversarial loss: 0.484777\n",
      "epoch 187; iter: 0; batch classifier loss: 0.090186; batch adversarial loss: 0.450276\n",
      "epoch 188; iter: 0; batch classifier loss: 0.075326; batch adversarial loss: 0.401376\n",
      "epoch 189; iter: 0; batch classifier loss: 0.120258; batch adversarial loss: 0.397814\n",
      "epoch 190; iter: 0; batch classifier loss: 0.047219; batch adversarial loss: 0.509004\n",
      "epoch 191; iter: 0; batch classifier loss: 0.122687; batch adversarial loss: 0.443331\n",
      "epoch 192; iter: 0; batch classifier loss: 0.086556; batch adversarial loss: 0.455193\n",
      "epoch 193; iter: 0; batch classifier loss: 0.101500; batch adversarial loss: 0.488557\n",
      "epoch 194; iter: 0; batch classifier loss: 0.073711; batch adversarial loss: 0.586295\n",
      "epoch 195; iter: 0; batch classifier loss: 0.082617; batch adversarial loss: 0.499245\n",
      "epoch 196; iter: 0; batch classifier loss: 0.122520; batch adversarial loss: 0.478282\n",
      "epoch 197; iter: 0; batch classifier loss: 0.090255; batch adversarial loss: 0.413264\n",
      "epoch 198; iter: 0; batch classifier loss: 0.176990; batch adversarial loss: 0.478166\n",
      "epoch 199; iter: 0; batch classifier loss: 0.062202; batch adversarial loss: 0.510722\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688851; batch adversarial loss: 0.593630\n",
      "epoch 1; iter: 0; batch classifier loss: 0.417213; batch adversarial loss: 0.619746\n",
      "epoch 2; iter: 0; batch classifier loss: 0.380558; batch adversarial loss: 0.602574\n",
      "epoch 3; iter: 0; batch classifier loss: 0.423914; batch adversarial loss: 0.580873\n",
      "epoch 4; iter: 0; batch classifier loss: 0.362238; batch adversarial loss: 0.561571\n",
      "epoch 5; iter: 0; batch classifier loss: 0.327070; batch adversarial loss: 0.536386\n",
      "epoch 6; iter: 0; batch classifier loss: 0.318717; batch adversarial loss: 0.523075\n",
      "epoch 7; iter: 0; batch classifier loss: 0.357608; batch adversarial loss: 0.513190\n",
      "epoch 8; iter: 0; batch classifier loss: 0.321674; batch adversarial loss: 0.545997\n",
      "epoch 9; iter: 0; batch classifier loss: 0.366679; batch adversarial loss: 0.599593\n",
      "epoch 10; iter: 0; batch classifier loss: 0.299384; batch adversarial loss: 0.496288\n",
      "epoch 11; iter: 0; batch classifier loss: 0.305864; batch adversarial loss: 0.539532\n",
      "epoch 12; iter: 0; batch classifier loss: 0.292152; batch adversarial loss: 0.465568\n",
      "epoch 13; iter: 0; batch classifier loss: 0.307527; batch adversarial loss: 0.478573\n",
      "epoch 14; iter: 0; batch classifier loss: 0.382840; batch adversarial loss: 0.494991\n",
      "epoch 15; iter: 0; batch classifier loss: 0.466104; batch adversarial loss: 0.525658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.491348; batch adversarial loss: 0.497476\n",
      "epoch 17; iter: 0; batch classifier loss: 0.399513; batch adversarial loss: 0.592268\n",
      "epoch 18; iter: 0; batch classifier loss: 0.299917; batch adversarial loss: 0.443853\n",
      "epoch 19; iter: 0; batch classifier loss: 0.213400; batch adversarial loss: 0.519120\n",
      "epoch 20; iter: 0; batch classifier loss: 0.208747; batch adversarial loss: 0.438101\n",
      "epoch 21; iter: 0; batch classifier loss: 0.197347; batch adversarial loss: 0.414421\n",
      "epoch 22; iter: 0; batch classifier loss: 0.217046; batch adversarial loss: 0.458101\n",
      "epoch 23; iter: 0; batch classifier loss: 0.205018; batch adversarial loss: 0.493927\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194323; batch adversarial loss: 0.425866\n",
      "epoch 25; iter: 0; batch classifier loss: 0.127730; batch adversarial loss: 0.431328\n",
      "epoch 26; iter: 0; batch classifier loss: 0.149838; batch adversarial loss: 0.398380\n",
      "epoch 27; iter: 0; batch classifier loss: 0.170085; batch adversarial loss: 0.397170\n",
      "epoch 28; iter: 0; batch classifier loss: 0.108813; batch adversarial loss: 0.501239\n",
      "epoch 29; iter: 0; batch classifier loss: 0.149206; batch adversarial loss: 0.500685\n",
      "epoch 30; iter: 0; batch classifier loss: 0.164801; batch adversarial loss: 0.458199\n",
      "epoch 31; iter: 0; batch classifier loss: 0.142946; batch adversarial loss: 0.511611\n",
      "epoch 32; iter: 0; batch classifier loss: 0.145097; batch adversarial loss: 0.456685\n",
      "epoch 33; iter: 0; batch classifier loss: 0.102471; batch adversarial loss: 0.443671\n",
      "epoch 34; iter: 0; batch classifier loss: 0.188314; batch adversarial loss: 0.321937\n",
      "epoch 35; iter: 0; batch classifier loss: 0.101518; batch adversarial loss: 0.549071\n",
      "epoch 36; iter: 0; batch classifier loss: 0.134012; batch adversarial loss: 0.529009\n",
      "epoch 37; iter: 0; batch classifier loss: 0.104312; batch adversarial loss: 0.446753\n",
      "epoch 38; iter: 0; batch classifier loss: 0.089287; batch adversarial loss: 0.475024\n",
      "epoch 39; iter: 0; batch classifier loss: 0.111480; batch adversarial loss: 0.525863\n",
      "epoch 40; iter: 0; batch classifier loss: 0.125085; batch adversarial loss: 0.523797\n",
      "epoch 41; iter: 0; batch classifier loss: 0.102168; batch adversarial loss: 0.538656\n",
      "epoch 42; iter: 0; batch classifier loss: 0.133221; batch adversarial loss: 0.464304\n",
      "epoch 43; iter: 0; batch classifier loss: 0.077810; batch adversarial loss: 0.419464\n",
      "epoch 44; iter: 0; batch classifier loss: 0.125421; batch adversarial loss: 0.545962\n",
      "epoch 45; iter: 0; batch classifier loss: 0.122597; batch adversarial loss: 0.482790\n",
      "epoch 46; iter: 0; batch classifier loss: 0.097355; batch adversarial loss: 0.389427\n",
      "epoch 47; iter: 0; batch classifier loss: 0.088263; batch adversarial loss: 0.456094\n",
      "epoch 48; iter: 0; batch classifier loss: 0.128839; batch adversarial loss: 0.491668\n",
      "epoch 49; iter: 0; batch classifier loss: 0.156622; batch adversarial loss: 0.453434\n",
      "epoch 50; iter: 0; batch classifier loss: 0.070920; batch adversarial loss: 0.461291\n",
      "epoch 51; iter: 0; batch classifier loss: 0.089814; batch adversarial loss: 0.439723\n",
      "epoch 52; iter: 0; batch classifier loss: 0.105142; batch adversarial loss: 0.448032\n",
      "epoch 53; iter: 0; batch classifier loss: 0.100854; batch adversarial loss: 0.424557\n",
      "epoch 54; iter: 0; batch classifier loss: 0.140008; batch adversarial loss: 0.474777\n",
      "epoch 55; iter: 0; batch classifier loss: 0.058706; batch adversarial loss: 0.456875\n",
      "epoch 56; iter: 0; batch classifier loss: 0.112823; batch adversarial loss: 0.478158\n",
      "epoch 57; iter: 0; batch classifier loss: 0.089999; batch adversarial loss: 0.425219\n",
      "epoch 58; iter: 0; batch classifier loss: 0.084852; batch adversarial loss: 0.461228\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072979; batch adversarial loss: 0.463890\n",
      "epoch 60; iter: 0; batch classifier loss: 0.165138; batch adversarial loss: 0.446728\n",
      "epoch 61; iter: 0; batch classifier loss: 0.070682; batch adversarial loss: 0.345174\n",
      "epoch 62; iter: 0; batch classifier loss: 0.076157; batch adversarial loss: 0.512490\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088825; batch adversarial loss: 0.474124\n",
      "epoch 64; iter: 0; batch classifier loss: 0.077421; batch adversarial loss: 0.386946\n",
      "epoch 65; iter: 0; batch classifier loss: 0.163147; batch adversarial loss: 0.499713\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087400; batch adversarial loss: 0.393896\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107126; batch adversarial loss: 0.442094\n",
      "epoch 68; iter: 0; batch classifier loss: 0.099578; batch adversarial loss: 0.392507\n",
      "epoch 69; iter: 0; batch classifier loss: 0.137019; batch adversarial loss: 0.387739\n",
      "epoch 70; iter: 0; batch classifier loss: 0.130959; batch adversarial loss: 0.456915\n",
      "epoch 71; iter: 0; batch classifier loss: 0.088408; batch adversarial loss: 0.480088\n",
      "epoch 72; iter: 0; batch classifier loss: 0.144639; batch adversarial loss: 0.437149\n",
      "epoch 73; iter: 0; batch classifier loss: 0.135727; batch adversarial loss: 0.410361\n",
      "epoch 74; iter: 0; batch classifier loss: 0.133634; batch adversarial loss: 0.482531\n",
      "epoch 75; iter: 0; batch classifier loss: 0.159220; batch adversarial loss: 0.378656\n",
      "epoch 76; iter: 0; batch classifier loss: 0.101714; batch adversarial loss: 0.574893\n",
      "epoch 77; iter: 0; batch classifier loss: 0.115872; batch adversarial loss: 0.397023\n",
      "epoch 78; iter: 0; batch classifier loss: 0.107705; batch adversarial loss: 0.384973\n",
      "epoch 79; iter: 0; batch classifier loss: 0.115866; batch adversarial loss: 0.463469\n",
      "epoch 80; iter: 0; batch classifier loss: 0.121660; batch adversarial loss: 0.425041\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071496; batch adversarial loss: 0.531851\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090419; batch adversarial loss: 0.419434\n",
      "epoch 83; iter: 0; batch classifier loss: 0.092440; batch adversarial loss: 0.425851\n",
      "epoch 84; iter: 0; batch classifier loss: 0.092135; batch adversarial loss: 0.469126\n",
      "epoch 85; iter: 0; batch classifier loss: 0.104629; batch adversarial loss: 0.509321\n",
      "epoch 86; iter: 0; batch classifier loss: 0.124729; batch adversarial loss: 0.389345\n",
      "epoch 87; iter: 0; batch classifier loss: 0.125721; batch adversarial loss: 0.478324\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057688; batch adversarial loss: 0.416904\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050523; batch adversarial loss: 0.471242\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051124; batch adversarial loss: 0.445622\n",
      "epoch 91; iter: 0; batch classifier loss: 0.141314; batch adversarial loss: 0.396411\n",
      "epoch 92; iter: 0; batch classifier loss: 0.107587; batch adversarial loss: 0.462703\n",
      "epoch 93; iter: 0; batch classifier loss: 0.104629; batch adversarial loss: 0.421382\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075477; batch adversarial loss: 0.469983\n",
      "epoch 95; iter: 0; batch classifier loss: 0.102173; batch adversarial loss: 0.429863\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041024; batch adversarial loss: 0.399642\n",
      "epoch 97; iter: 0; batch classifier loss: 0.137301; batch adversarial loss: 0.296440\n",
      "epoch 98; iter: 0; batch classifier loss: 0.043739; batch adversarial loss: 0.510823\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058753; batch adversarial loss: 0.483918\n",
      "epoch 100; iter: 0; batch classifier loss: 0.111973; batch adversarial loss: 0.471365\n",
      "epoch 101; iter: 0; batch classifier loss: 0.099501; batch adversarial loss: 0.451999\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059588; batch adversarial loss: 0.480256\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078838; batch adversarial loss: 0.480050\n",
      "epoch 104; iter: 0; batch classifier loss: 0.126971; batch adversarial loss: 0.452229\n",
      "epoch 105; iter: 0; batch classifier loss: 0.082317; batch adversarial loss: 0.527472\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053472; batch adversarial loss: 0.513049\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055719; batch adversarial loss: 0.491781\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052122; batch adversarial loss: 0.445729\n",
      "epoch 109; iter: 0; batch classifier loss: 0.081685; batch adversarial loss: 0.446139\n",
      "epoch 110; iter: 0; batch classifier loss: 0.086499; batch adversarial loss: 0.425072\n",
      "epoch 111; iter: 0; batch classifier loss: 0.077745; batch adversarial loss: 0.433090\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030110; batch adversarial loss: 0.553358\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051017; batch adversarial loss: 0.445394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.057707; batch adversarial loss: 0.464129\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050949; batch adversarial loss: 0.441691\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048423; batch adversarial loss: 0.487160\n",
      "epoch 117; iter: 0; batch classifier loss: 0.072721; batch adversarial loss: 0.401241\n",
      "epoch 118; iter: 0; batch classifier loss: 0.070564; batch adversarial loss: 0.440982\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057932; batch adversarial loss: 0.434394\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037596; batch adversarial loss: 0.413299\n",
      "epoch 121; iter: 0; batch classifier loss: 0.096168; batch adversarial loss: 0.427528\n",
      "epoch 122; iter: 0; batch classifier loss: 0.047527; batch adversarial loss: 0.436975\n",
      "epoch 123; iter: 0; batch classifier loss: 0.085339; batch adversarial loss: 0.431409\n",
      "epoch 124; iter: 0; batch classifier loss: 0.081861; batch adversarial loss: 0.524215\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031461; batch adversarial loss: 0.416674\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051835; batch adversarial loss: 0.471544\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037730; batch adversarial loss: 0.520108\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061262; batch adversarial loss: 0.495142\n",
      "epoch 129; iter: 0; batch classifier loss: 0.071908; batch adversarial loss: 0.437164\n",
      "epoch 130; iter: 0; batch classifier loss: 0.074312; batch adversarial loss: 0.444820\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034950; batch adversarial loss: 0.464246\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048563; batch adversarial loss: 0.374510\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052789; batch adversarial loss: 0.414443\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018080; batch adversarial loss: 0.502032\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059987; batch adversarial loss: 0.433614\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038523; batch adversarial loss: 0.450995\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054904; batch adversarial loss: 0.484205\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037198; batch adversarial loss: 0.387838\n",
      "epoch 139; iter: 0; batch classifier loss: 0.047315; batch adversarial loss: 0.495337\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046902; batch adversarial loss: 0.417034\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034437; batch adversarial loss: 0.425517\n",
      "epoch 142; iter: 0; batch classifier loss: 0.010946; batch adversarial loss: 0.400935\n",
      "epoch 143; iter: 0; batch classifier loss: 0.058821; batch adversarial loss: 0.455706\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019485; batch adversarial loss: 0.512366\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022116; batch adversarial loss: 0.559026\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042429; batch adversarial loss: 0.425950\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038224; batch adversarial loss: 0.411768\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027992; batch adversarial loss: 0.399180\n",
      "epoch 149; iter: 0; batch classifier loss: 0.055167; batch adversarial loss: 0.464974\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039179; batch adversarial loss: 0.379682\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021708; batch adversarial loss: 0.433387\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034716; batch adversarial loss: 0.478208\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042542; batch adversarial loss: 0.421052\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044186; batch adversarial loss: 0.503408\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018636; batch adversarial loss: 0.345557\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024477; batch adversarial loss: 0.464808\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019607; batch adversarial loss: 0.585229\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037382; batch adversarial loss: 0.424949\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012466; batch adversarial loss: 0.468117\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021736; batch adversarial loss: 0.489711\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026449; batch adversarial loss: 0.434368\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023343; batch adversarial loss: 0.405755\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032184; batch adversarial loss: 0.527412\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021223; batch adversarial loss: 0.424396\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038156; batch adversarial loss: 0.393647\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022891; batch adversarial loss: 0.506402\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036850; batch adversarial loss: 0.358654\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040316; batch adversarial loss: 0.415873\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011923; batch adversarial loss: 0.475233\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016253; batch adversarial loss: 0.545016\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028724; batch adversarial loss: 0.318006\n",
      "epoch 172; iter: 0; batch classifier loss: 0.051440; batch adversarial loss: 0.503741\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013085; batch adversarial loss: 0.477494\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022606; batch adversarial loss: 0.440389\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010984; batch adversarial loss: 0.440773\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021124; batch adversarial loss: 0.471088\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011698; batch adversarial loss: 0.377361\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011282; batch adversarial loss: 0.446148\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017234; batch adversarial loss: 0.469128\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025548; batch adversarial loss: 0.382060\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028197; batch adversarial loss: 0.487352\n",
      "epoch 182; iter: 0; batch classifier loss: 0.043256; batch adversarial loss: 0.382299\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011829; batch adversarial loss: 0.388307\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030550; batch adversarial loss: 0.569866\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018058; batch adversarial loss: 0.400057\n",
      "epoch 186; iter: 0; batch classifier loss: 0.036692; batch adversarial loss: 0.370503\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015413; batch adversarial loss: 0.488254\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030122; batch adversarial loss: 0.435918\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006517; batch adversarial loss: 0.500044\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012024; batch adversarial loss: 0.543993\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007420; batch adversarial loss: 0.406236\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009734; batch adversarial loss: 0.412678\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020089; batch adversarial loss: 0.455016\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027599; batch adversarial loss: 0.374072\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026777; batch adversarial loss: 0.392532\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008880; batch adversarial loss: 0.349338\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009552; batch adversarial loss: 0.423675\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005763; batch adversarial loss: 0.409938\n",
      "epoch 199; iter: 0; batch classifier loss: 0.039651; batch adversarial loss: 0.508641\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715005; batch adversarial loss: 0.517016\n",
      "epoch 1; iter: 0; batch classifier loss: 0.445594; batch adversarial loss: 0.577555\n",
      "epoch 2; iter: 0; batch classifier loss: 0.432719; batch adversarial loss: 0.595743\n",
      "epoch 3; iter: 0; batch classifier loss: 0.450730; batch adversarial loss: 0.535534\n",
      "epoch 4; iter: 0; batch classifier loss: 0.450476; batch adversarial loss: 0.651877\n",
      "epoch 5; iter: 0; batch classifier loss: 0.441102; batch adversarial loss: 0.610171\n",
      "epoch 6; iter: 0; batch classifier loss: 0.496898; batch adversarial loss: 0.614341\n",
      "epoch 7; iter: 0; batch classifier loss: 0.470308; batch adversarial loss: 0.602960\n",
      "epoch 8; iter: 0; batch classifier loss: 0.589263; batch adversarial loss: 0.575417\n",
      "epoch 9; iter: 0; batch classifier loss: 0.634930; batch adversarial loss: 0.576152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.529714; batch adversarial loss: 0.583899\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539131; batch adversarial loss: 0.522581\n",
      "epoch 12; iter: 0; batch classifier loss: 0.350867; batch adversarial loss: 0.539337\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373324; batch adversarial loss: 0.494874\n",
      "epoch 14; iter: 0; batch classifier loss: 0.343237; batch adversarial loss: 0.385362\n",
      "epoch 15; iter: 0; batch classifier loss: 0.258588; batch adversarial loss: 0.471301\n",
      "epoch 16; iter: 0; batch classifier loss: 0.207015; batch adversarial loss: 0.449333\n",
      "epoch 17; iter: 0; batch classifier loss: 0.267160; batch adversarial loss: 0.540635\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237535; batch adversarial loss: 0.486518\n",
      "epoch 19; iter: 0; batch classifier loss: 0.216260; batch adversarial loss: 0.467961\n",
      "epoch 20; iter: 0; batch classifier loss: 0.214650; batch adversarial loss: 0.415809\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202540; batch adversarial loss: 0.461309\n",
      "epoch 22; iter: 0; batch classifier loss: 0.213100; batch adversarial loss: 0.526835\n",
      "epoch 23; iter: 0; batch classifier loss: 0.196550; batch adversarial loss: 0.427732\n",
      "epoch 24; iter: 0; batch classifier loss: 0.242846; batch adversarial loss: 0.513518\n",
      "epoch 25; iter: 0; batch classifier loss: 0.151714; batch adversarial loss: 0.543562\n",
      "epoch 26; iter: 0; batch classifier loss: 0.168158; batch adversarial loss: 0.551373\n",
      "epoch 27; iter: 0; batch classifier loss: 0.210216; batch adversarial loss: 0.457969\n",
      "epoch 28; iter: 0; batch classifier loss: 0.140735; batch adversarial loss: 0.408727\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197533; batch adversarial loss: 0.446922\n",
      "epoch 30; iter: 0; batch classifier loss: 0.185317; batch adversarial loss: 0.544992\n",
      "epoch 31; iter: 0; batch classifier loss: 0.150426; batch adversarial loss: 0.493105\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172916; batch adversarial loss: 0.488165\n",
      "epoch 33; iter: 0; batch classifier loss: 0.160799; batch adversarial loss: 0.491752\n",
      "epoch 34; iter: 0; batch classifier loss: 0.110226; batch adversarial loss: 0.539404\n",
      "epoch 35; iter: 0; batch classifier loss: 0.171937; batch adversarial loss: 0.499654\n",
      "epoch 36; iter: 0; batch classifier loss: 0.119302; batch adversarial loss: 0.468618\n",
      "epoch 37; iter: 0; batch classifier loss: 0.141491; batch adversarial loss: 0.450310\n",
      "epoch 38; iter: 0; batch classifier loss: 0.164693; batch adversarial loss: 0.418891\n",
      "epoch 39; iter: 0; batch classifier loss: 0.147094; batch adversarial loss: 0.387837\n",
      "epoch 40; iter: 0; batch classifier loss: 0.134270; batch adversarial loss: 0.446752\n",
      "epoch 41; iter: 0; batch classifier loss: 0.133250; batch adversarial loss: 0.446980\n",
      "epoch 42; iter: 0; batch classifier loss: 0.212254; batch adversarial loss: 0.441948\n",
      "epoch 43; iter: 0; batch classifier loss: 0.159820; batch adversarial loss: 0.424878\n",
      "epoch 44; iter: 0; batch classifier loss: 0.129832; batch adversarial loss: 0.473053\n",
      "epoch 45; iter: 0; batch classifier loss: 0.116868; batch adversarial loss: 0.420151\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102640; batch adversarial loss: 0.515561\n",
      "epoch 47; iter: 0; batch classifier loss: 0.126718; batch adversarial loss: 0.392500\n",
      "epoch 48; iter: 0; batch classifier loss: 0.135426; batch adversarial loss: 0.499632\n",
      "epoch 49; iter: 0; batch classifier loss: 0.127522; batch adversarial loss: 0.523678\n",
      "epoch 50; iter: 0; batch classifier loss: 0.147112; batch adversarial loss: 0.495752\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081031; batch adversarial loss: 0.389168\n",
      "epoch 52; iter: 0; batch classifier loss: 0.142937; batch adversarial loss: 0.480642\n",
      "epoch 53; iter: 0; batch classifier loss: 0.135866; batch adversarial loss: 0.403868\n",
      "epoch 54; iter: 0; batch classifier loss: 0.130414; batch adversarial loss: 0.414716\n",
      "epoch 55; iter: 0; batch classifier loss: 0.112254; batch adversarial loss: 0.525947\n",
      "epoch 56; iter: 0; batch classifier loss: 0.088426; batch adversarial loss: 0.402893\n",
      "epoch 57; iter: 0; batch classifier loss: 0.144544; batch adversarial loss: 0.471593\n",
      "epoch 58; iter: 0; batch classifier loss: 0.133935; batch adversarial loss: 0.433561\n",
      "epoch 59; iter: 0; batch classifier loss: 0.119330; batch adversarial loss: 0.441273\n",
      "epoch 60; iter: 0; batch classifier loss: 0.075831; batch adversarial loss: 0.401443\n",
      "epoch 61; iter: 0; batch classifier loss: 0.162428; batch adversarial loss: 0.451893\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092366; batch adversarial loss: 0.379119\n",
      "epoch 63; iter: 0; batch classifier loss: 0.080969; batch adversarial loss: 0.602138\n",
      "epoch 64; iter: 0; batch classifier loss: 0.147635; batch adversarial loss: 0.448510\n",
      "epoch 65; iter: 0; batch classifier loss: 0.142124; batch adversarial loss: 0.388856\n",
      "epoch 66; iter: 0; batch classifier loss: 0.160680; batch adversarial loss: 0.449954\n",
      "epoch 67; iter: 0; batch classifier loss: 0.152785; batch adversarial loss: 0.465007\n",
      "epoch 68; iter: 0; batch classifier loss: 0.116306; batch adversarial loss: 0.381374\n",
      "epoch 69; iter: 0; batch classifier loss: 0.160293; batch adversarial loss: 0.436684\n",
      "epoch 70; iter: 0; batch classifier loss: 0.133711; batch adversarial loss: 0.491358\n",
      "epoch 71; iter: 0; batch classifier loss: 0.102182; batch adversarial loss: 0.417212\n",
      "epoch 72; iter: 0; batch classifier loss: 0.177172; batch adversarial loss: 0.361281\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101035; batch adversarial loss: 0.399652\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066911; batch adversarial loss: 0.452487\n",
      "epoch 75; iter: 0; batch classifier loss: 0.105983; batch adversarial loss: 0.404216\n",
      "epoch 76; iter: 0; batch classifier loss: 0.156164; batch adversarial loss: 0.438947\n",
      "epoch 77; iter: 0; batch classifier loss: 0.096891; batch adversarial loss: 0.477088\n",
      "epoch 78; iter: 0; batch classifier loss: 0.155013; batch adversarial loss: 0.424938\n",
      "epoch 79; iter: 0; batch classifier loss: 0.164241; batch adversarial loss: 0.417838\n",
      "epoch 80; iter: 0; batch classifier loss: 0.100025; batch adversarial loss: 0.497082\n",
      "epoch 81; iter: 0; batch classifier loss: 0.119069; batch adversarial loss: 0.490869\n",
      "epoch 82; iter: 0; batch classifier loss: 0.140773; batch adversarial loss: 0.420294\n",
      "epoch 83; iter: 0; batch classifier loss: 0.082103; batch adversarial loss: 0.394587\n",
      "epoch 84; iter: 0; batch classifier loss: 0.094164; batch adversarial loss: 0.503303\n",
      "epoch 85; iter: 0; batch classifier loss: 0.142903; batch adversarial loss: 0.384603\n",
      "epoch 86; iter: 0; batch classifier loss: 0.115035; batch adversarial loss: 0.395149\n",
      "epoch 87; iter: 0; batch classifier loss: 0.104419; batch adversarial loss: 0.389941\n",
      "epoch 88; iter: 0; batch classifier loss: 0.093784; batch adversarial loss: 0.394220\n",
      "epoch 89; iter: 0; batch classifier loss: 0.159751; batch adversarial loss: 0.375774\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065628; batch adversarial loss: 0.467288\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057499; batch adversarial loss: 0.546173\n",
      "epoch 92; iter: 0; batch classifier loss: 0.145173; batch adversarial loss: 0.432712\n",
      "epoch 93; iter: 0; batch classifier loss: 0.085988; batch adversarial loss: 0.467097\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081419; batch adversarial loss: 0.448754\n",
      "epoch 95; iter: 0; batch classifier loss: 0.096421; batch adversarial loss: 0.479027\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059831; batch adversarial loss: 0.520141\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075674; batch adversarial loss: 0.448079\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046658; batch adversarial loss: 0.457651\n",
      "epoch 99; iter: 0; batch classifier loss: 0.092660; batch adversarial loss: 0.459233\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061533; batch adversarial loss: 0.485023\n",
      "epoch 101; iter: 0; batch classifier loss: 0.108489; batch adversarial loss: 0.386722\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048434; batch adversarial loss: 0.387429\n",
      "epoch 103; iter: 0; batch classifier loss: 0.130803; batch adversarial loss: 0.407384\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044824; batch adversarial loss: 0.434829\n",
      "epoch 105; iter: 0; batch classifier loss: 0.081227; batch adversarial loss: 0.394754\n",
      "epoch 106; iter: 0; batch classifier loss: 0.081920; batch adversarial loss: 0.408621\n",
      "epoch 107; iter: 0; batch classifier loss: 0.078681; batch adversarial loss: 0.510001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.058707; batch adversarial loss: 0.415545\n",
      "epoch 109; iter: 0; batch classifier loss: 0.056334; batch adversarial loss: 0.411718\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048371; batch adversarial loss: 0.421991\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053050; batch adversarial loss: 0.401259\n",
      "epoch 112; iter: 0; batch classifier loss: 0.094836; batch adversarial loss: 0.411618\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048242; batch adversarial loss: 0.456386\n",
      "epoch 114; iter: 0; batch classifier loss: 0.065005; batch adversarial loss: 0.484931\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046179; batch adversarial loss: 0.492930\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038499; batch adversarial loss: 0.443515\n",
      "epoch 117; iter: 0; batch classifier loss: 0.075150; batch adversarial loss: 0.424157\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032874; batch adversarial loss: 0.391398\n",
      "epoch 119; iter: 0; batch classifier loss: 0.024088; batch adversarial loss: 0.399924\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043578; batch adversarial loss: 0.404977\n",
      "epoch 121; iter: 0; batch classifier loss: 0.067793; batch adversarial loss: 0.570403\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033474; batch adversarial loss: 0.371351\n",
      "epoch 123; iter: 0; batch classifier loss: 0.076703; batch adversarial loss: 0.463005\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043299; batch adversarial loss: 0.441414\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044013; batch adversarial loss: 0.469331\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030932; batch adversarial loss: 0.397797\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035581; batch adversarial loss: 0.457552\n",
      "epoch 128; iter: 0; batch classifier loss: 0.069476; batch adversarial loss: 0.415637\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030742; batch adversarial loss: 0.535149\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042836; batch adversarial loss: 0.497599\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049921; batch adversarial loss: 0.450981\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028239; batch adversarial loss: 0.406664\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033844; batch adversarial loss: 0.442343\n",
      "epoch 134; iter: 0; batch classifier loss: 0.083916; batch adversarial loss: 0.469049\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039370; batch adversarial loss: 0.473075\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029307; batch adversarial loss: 0.518682\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023384; batch adversarial loss: 0.484774\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019175; batch adversarial loss: 0.424066\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029347; batch adversarial loss: 0.471314\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032418; batch adversarial loss: 0.482372\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049261; batch adversarial loss: 0.445711\n",
      "epoch 142; iter: 0; batch classifier loss: 0.057492; batch adversarial loss: 0.434808\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026042; batch adversarial loss: 0.459569\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032166; batch adversarial loss: 0.457041\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020761; batch adversarial loss: 0.495526\n",
      "epoch 146; iter: 0; batch classifier loss: 0.043312; batch adversarial loss: 0.402116\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035645; batch adversarial loss: 0.411165\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023817; batch adversarial loss: 0.427914\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029075; batch adversarial loss: 0.530882\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025815; batch adversarial loss: 0.458876\n",
      "epoch 151; iter: 0; batch classifier loss: 0.050638; batch adversarial loss: 0.381953\n",
      "epoch 152; iter: 0; batch classifier loss: 0.064453; batch adversarial loss: 0.408312\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014096; batch adversarial loss: 0.418391\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025975; batch adversarial loss: 0.477896\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046009; batch adversarial loss: 0.498035\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030563; batch adversarial loss: 0.443111\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035609; batch adversarial loss: 0.460567\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019669; batch adversarial loss: 0.487195\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031674; batch adversarial loss: 0.493580\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014670; batch adversarial loss: 0.415898\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042472; batch adversarial loss: 0.441184\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031077; batch adversarial loss: 0.428199\n",
      "epoch 163; iter: 0; batch classifier loss: 0.041203; batch adversarial loss: 0.393806\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024544; batch adversarial loss: 0.489972\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017176; batch adversarial loss: 0.404626\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018535; batch adversarial loss: 0.435984\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020742; batch adversarial loss: 0.488338\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028335; batch adversarial loss: 0.509567\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021166; batch adversarial loss: 0.412604\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030235; batch adversarial loss: 0.454763\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016357; batch adversarial loss: 0.477507\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018861; batch adversarial loss: 0.427283\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019147; batch adversarial loss: 0.422078\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008700; batch adversarial loss: 0.515864\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010341; batch adversarial loss: 0.518969\n",
      "epoch 176; iter: 0; batch classifier loss: 0.036778; batch adversarial loss: 0.425575\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016392; batch adversarial loss: 0.418536\n",
      "epoch 178; iter: 0; batch classifier loss: 0.052036; batch adversarial loss: 0.451245\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017583; batch adversarial loss: 0.452228\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019060; batch adversarial loss: 0.390441\n",
      "epoch 181; iter: 0; batch classifier loss: 0.043297; batch adversarial loss: 0.506092\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021498; batch adversarial loss: 0.433807\n",
      "epoch 183; iter: 0; batch classifier loss: 0.076465; batch adversarial loss: 0.358871\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010844; batch adversarial loss: 0.460802\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021195; batch adversarial loss: 0.395703\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008013; batch adversarial loss: 0.507840\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020489; batch adversarial loss: 0.414497\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030282; batch adversarial loss: 0.442288\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004738; batch adversarial loss: 0.465022\n",
      "epoch 190; iter: 0; batch classifier loss: 0.056930; batch adversarial loss: 0.497752\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018294; batch adversarial loss: 0.382239\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008058; batch adversarial loss: 0.414226\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014938; batch adversarial loss: 0.377769\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015892; batch adversarial loss: 0.529981\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025951; batch adversarial loss: 0.492521\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025285; batch adversarial loss: 0.413186\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018826; batch adversarial loss: 0.490760\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013087; batch adversarial loss: 0.502686\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009849; batch adversarial loss: 0.483331\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692685; batch adversarial loss: 0.835016\n",
      "epoch 1; iter: 0; batch classifier loss: 0.423453; batch adversarial loss: 0.793323\n",
      "epoch 2; iter: 0; batch classifier loss: 0.379515; batch adversarial loss: 0.738880\n",
      "epoch 3; iter: 0; batch classifier loss: 0.388406; batch adversarial loss: 0.686108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.316944; batch adversarial loss: 0.632612\n",
      "epoch 5; iter: 0; batch classifier loss: 0.300132; batch adversarial loss: 0.642471\n",
      "epoch 6; iter: 0; batch classifier loss: 0.306315; batch adversarial loss: 0.581539\n",
      "epoch 7; iter: 0; batch classifier loss: 0.362415; batch adversarial loss: 0.579508\n",
      "epoch 8; iter: 0; batch classifier loss: 0.331411; batch adversarial loss: 0.539539\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273939; batch adversarial loss: 0.544004\n",
      "epoch 10; iter: 0; batch classifier loss: 0.193439; batch adversarial loss: 0.484234\n",
      "epoch 11; iter: 0; batch classifier loss: 0.238479; batch adversarial loss: 0.469715\n",
      "epoch 12; iter: 0; batch classifier loss: 0.286211; batch adversarial loss: 0.453115\n",
      "epoch 13; iter: 0; batch classifier loss: 0.241360; batch adversarial loss: 0.442685\n",
      "epoch 14; iter: 0; batch classifier loss: 0.229040; batch adversarial loss: 0.448699\n",
      "epoch 15; iter: 0; batch classifier loss: 0.223858; batch adversarial loss: 0.407972\n",
      "epoch 16; iter: 0; batch classifier loss: 0.194845; batch adversarial loss: 0.468714\n",
      "epoch 17; iter: 0; batch classifier loss: 0.200085; batch adversarial loss: 0.462564\n",
      "epoch 18; iter: 0; batch classifier loss: 0.255490; batch adversarial loss: 0.418460\n",
      "epoch 19; iter: 0; batch classifier loss: 0.266424; batch adversarial loss: 0.427109\n",
      "epoch 20; iter: 0; batch classifier loss: 0.162756; batch adversarial loss: 0.477803\n",
      "epoch 21; iter: 0; batch classifier loss: 0.170291; batch adversarial loss: 0.412869\n",
      "epoch 22; iter: 0; batch classifier loss: 0.173830; batch adversarial loss: 0.438574\n",
      "epoch 23; iter: 0; batch classifier loss: 0.102437; batch adversarial loss: 0.405381\n",
      "epoch 24; iter: 0; batch classifier loss: 0.205887; batch adversarial loss: 0.418523\n",
      "epoch 25; iter: 0; batch classifier loss: 0.150690; batch adversarial loss: 0.381580\n",
      "epoch 26; iter: 0; batch classifier loss: 0.185998; batch adversarial loss: 0.451798\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159677; batch adversarial loss: 0.443184\n",
      "epoch 28; iter: 0; batch classifier loss: 0.158089; batch adversarial loss: 0.360051\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178625; batch adversarial loss: 0.411395\n",
      "epoch 30; iter: 0; batch classifier loss: 0.137727; batch adversarial loss: 0.352858\n",
      "epoch 31; iter: 0; batch classifier loss: 0.164518; batch adversarial loss: 0.370712\n",
      "epoch 32; iter: 0; batch classifier loss: 0.123112; batch adversarial loss: 0.416770\n",
      "epoch 33; iter: 0; batch classifier loss: 0.157263; batch adversarial loss: 0.424904\n",
      "epoch 34; iter: 0; batch classifier loss: 0.146969; batch adversarial loss: 0.337407\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137450; batch adversarial loss: 0.378219\n",
      "epoch 36; iter: 0; batch classifier loss: 0.129731; batch adversarial loss: 0.415537\n",
      "epoch 37; iter: 0; batch classifier loss: 0.119872; batch adversarial loss: 0.449531\n",
      "epoch 38; iter: 0; batch classifier loss: 0.177642; batch adversarial loss: 0.476218\n",
      "epoch 39; iter: 0; batch classifier loss: 0.117587; batch adversarial loss: 0.355131\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154276; batch adversarial loss: 0.480483\n",
      "epoch 41; iter: 0; batch classifier loss: 0.167661; batch adversarial loss: 0.392950\n",
      "epoch 42; iter: 0; batch classifier loss: 0.157731; batch adversarial loss: 0.519529\n",
      "epoch 43; iter: 0; batch classifier loss: 0.141560; batch adversarial loss: 0.418438\n",
      "epoch 44; iter: 0; batch classifier loss: 0.132741; batch adversarial loss: 0.369575\n",
      "epoch 45; iter: 0; batch classifier loss: 0.145804; batch adversarial loss: 0.389654\n",
      "epoch 46; iter: 0; batch classifier loss: 0.140883; batch adversarial loss: 0.478776\n",
      "epoch 47; iter: 0; batch classifier loss: 0.156873; batch adversarial loss: 0.440372\n",
      "epoch 48; iter: 0; batch classifier loss: 0.114564; batch adversarial loss: 0.435203\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098042; batch adversarial loss: 0.532701\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087383; batch adversarial loss: 0.371266\n",
      "epoch 51; iter: 0; batch classifier loss: 0.126831; batch adversarial loss: 0.506425\n",
      "epoch 52; iter: 0; batch classifier loss: 0.097946; batch adversarial loss: 0.464828\n",
      "epoch 53; iter: 0; batch classifier loss: 0.099680; batch adversarial loss: 0.361781\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102996; batch adversarial loss: 0.369149\n",
      "epoch 55; iter: 0; batch classifier loss: 0.099188; batch adversarial loss: 0.457319\n",
      "epoch 56; iter: 0; batch classifier loss: 0.090046; batch adversarial loss: 0.412106\n",
      "epoch 57; iter: 0; batch classifier loss: 0.074440; batch adversarial loss: 0.406104\n",
      "epoch 58; iter: 0; batch classifier loss: 0.117923; batch adversarial loss: 0.466537\n",
      "epoch 59; iter: 0; batch classifier loss: 0.104205; batch adversarial loss: 0.413990\n",
      "epoch 60; iter: 0; batch classifier loss: 0.054549; batch adversarial loss: 0.416077\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087156; batch adversarial loss: 0.447027\n",
      "epoch 62; iter: 0; batch classifier loss: 0.118386; batch adversarial loss: 0.372921\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098901; batch adversarial loss: 0.425272\n",
      "epoch 64; iter: 0; batch classifier loss: 0.176120; batch adversarial loss: 0.434088\n",
      "epoch 65; iter: 0; batch classifier loss: 0.081504; batch adversarial loss: 0.449987\n",
      "epoch 66; iter: 0; batch classifier loss: 0.097244; batch adversarial loss: 0.394386\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095053; batch adversarial loss: 0.376263\n",
      "epoch 68; iter: 0; batch classifier loss: 0.058395; batch adversarial loss: 0.425776\n",
      "epoch 69; iter: 0; batch classifier loss: 0.133076; batch adversarial loss: 0.486858\n",
      "epoch 70; iter: 0; batch classifier loss: 0.124749; batch adversarial loss: 0.390751\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071040; batch adversarial loss: 0.394051\n",
      "epoch 72; iter: 0; batch classifier loss: 0.069847; batch adversarial loss: 0.546311\n",
      "epoch 73; iter: 0; batch classifier loss: 0.093026; batch adversarial loss: 0.458063\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073959; batch adversarial loss: 0.525778\n",
      "epoch 75; iter: 0; batch classifier loss: 0.084114; batch adversarial loss: 0.446041\n",
      "epoch 76; iter: 0; batch classifier loss: 0.104970; batch adversarial loss: 0.428957\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062623; batch adversarial loss: 0.425757\n",
      "epoch 78; iter: 0; batch classifier loss: 0.094137; batch adversarial loss: 0.377713\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085543; batch adversarial loss: 0.435539\n",
      "epoch 80; iter: 0; batch classifier loss: 0.096924; batch adversarial loss: 0.490475\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066458; batch adversarial loss: 0.383399\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059035; batch adversarial loss: 0.397577\n",
      "epoch 83; iter: 0; batch classifier loss: 0.089902; batch adversarial loss: 0.386976\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075480; batch adversarial loss: 0.381520\n",
      "epoch 85; iter: 0; batch classifier loss: 0.071881; batch adversarial loss: 0.458781\n",
      "epoch 86; iter: 0; batch classifier loss: 0.079837; batch adversarial loss: 0.441694\n",
      "epoch 87; iter: 0; batch classifier loss: 0.074814; batch adversarial loss: 0.343346\n",
      "epoch 88; iter: 0; batch classifier loss: 0.103459; batch adversarial loss: 0.455062\n",
      "epoch 89; iter: 0; batch classifier loss: 0.034986; batch adversarial loss: 0.485493\n",
      "epoch 90; iter: 0; batch classifier loss: 0.078543; batch adversarial loss: 0.464383\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052479; batch adversarial loss: 0.436416\n",
      "epoch 92; iter: 0; batch classifier loss: 0.094588; batch adversarial loss: 0.378107\n",
      "epoch 93; iter: 0; batch classifier loss: 0.087108; batch adversarial loss: 0.510440\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070685; batch adversarial loss: 0.388145\n",
      "epoch 95; iter: 0; batch classifier loss: 0.084546; batch adversarial loss: 0.412006\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044773; batch adversarial loss: 0.336950\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080120; batch adversarial loss: 0.436594\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058877; batch adversarial loss: 0.377656\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065588; batch adversarial loss: 0.356194\n",
      "epoch 100; iter: 0; batch classifier loss: 0.120643; batch adversarial loss: 0.479339\n",
      "epoch 101; iter: 0; batch classifier loss: 0.102454; batch adversarial loss: 0.471270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.111345; batch adversarial loss: 0.364197\n",
      "epoch 103; iter: 0; batch classifier loss: 0.079303; batch adversarial loss: 0.500858\n",
      "epoch 104; iter: 0; batch classifier loss: 0.112918; batch adversarial loss: 0.493239\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076887; batch adversarial loss: 0.384828\n",
      "epoch 106; iter: 0; batch classifier loss: 0.076396; batch adversarial loss: 0.406431\n",
      "epoch 107; iter: 0; batch classifier loss: 0.057501; batch adversarial loss: 0.464166\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069560; batch adversarial loss: 0.341724\n",
      "epoch 109; iter: 0; batch classifier loss: 0.081986; batch adversarial loss: 0.442681\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061000; batch adversarial loss: 0.435076\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034518; batch adversarial loss: 0.297916\n",
      "epoch 112; iter: 0; batch classifier loss: 0.086771; batch adversarial loss: 0.473689\n",
      "epoch 113; iter: 0; batch classifier loss: 0.092537; batch adversarial loss: 0.403053\n",
      "epoch 114; iter: 0; batch classifier loss: 0.101356; batch adversarial loss: 0.368425\n",
      "epoch 115; iter: 0; batch classifier loss: 0.076570; batch adversarial loss: 0.447296\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054501; batch adversarial loss: 0.358360\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045528; batch adversarial loss: 0.400573\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057228; batch adversarial loss: 0.336464\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056773; batch adversarial loss: 0.366531\n",
      "epoch 120; iter: 0; batch classifier loss: 0.061515; batch adversarial loss: 0.365433\n",
      "epoch 121; iter: 0; batch classifier loss: 0.073103; batch adversarial loss: 0.386709\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029272; batch adversarial loss: 0.522848\n",
      "epoch 123; iter: 0; batch classifier loss: 0.061043; batch adversarial loss: 0.516303\n",
      "epoch 124; iter: 0; batch classifier loss: 0.056049; batch adversarial loss: 0.479288\n",
      "epoch 125; iter: 0; batch classifier loss: 0.073196; batch adversarial loss: 0.431933\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042659; batch adversarial loss: 0.364350\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036084; batch adversarial loss: 0.439582\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063658; batch adversarial loss: 0.459313\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043379; batch adversarial loss: 0.394679\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042942; batch adversarial loss: 0.465525\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051372; batch adversarial loss: 0.451120\n",
      "epoch 132; iter: 0; batch classifier loss: 0.080113; batch adversarial loss: 0.481631\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036712; batch adversarial loss: 0.351632\n",
      "epoch 134; iter: 0; batch classifier loss: 0.055634; batch adversarial loss: 0.474743\n",
      "epoch 135; iter: 0; batch classifier loss: 0.048977; batch adversarial loss: 0.421095\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026027; batch adversarial loss: 0.384170\n",
      "epoch 137; iter: 0; batch classifier loss: 0.050940; batch adversarial loss: 0.379499\n",
      "epoch 138; iter: 0; batch classifier loss: 0.060763; batch adversarial loss: 0.459602\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037543; batch adversarial loss: 0.367269\n",
      "epoch 140; iter: 0; batch classifier loss: 0.055042; batch adversarial loss: 0.355410\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031178; batch adversarial loss: 0.486696\n",
      "epoch 142; iter: 0; batch classifier loss: 0.015996; batch adversarial loss: 0.469752\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039924; batch adversarial loss: 0.424621\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041069; batch adversarial loss: 0.433789\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045369; batch adversarial loss: 0.445933\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031777; batch adversarial loss: 0.381073\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039622; batch adversarial loss: 0.380773\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037508; batch adversarial loss: 0.405154\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036467; batch adversarial loss: 0.498916\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023142; batch adversarial loss: 0.358215\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043643; batch adversarial loss: 0.393961\n",
      "epoch 152; iter: 0; batch classifier loss: 0.054965; batch adversarial loss: 0.454129\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025367; batch adversarial loss: 0.468214\n",
      "epoch 154; iter: 0; batch classifier loss: 0.063160; batch adversarial loss: 0.483106\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029996; batch adversarial loss: 0.441019\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025051; batch adversarial loss: 0.375721\n",
      "epoch 157; iter: 0; batch classifier loss: 0.067490; batch adversarial loss: 0.481843\n",
      "epoch 158; iter: 0; batch classifier loss: 0.057807; batch adversarial loss: 0.485956\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038801; batch adversarial loss: 0.456352\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044768; batch adversarial loss: 0.397056\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035105; batch adversarial loss: 0.419254\n",
      "epoch 162; iter: 0; batch classifier loss: 0.085400; batch adversarial loss: 0.431843\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017126; batch adversarial loss: 0.494963\n",
      "epoch 164; iter: 0; batch classifier loss: 0.039758; batch adversarial loss: 0.332248\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019836; batch adversarial loss: 0.461729\n",
      "epoch 166; iter: 0; batch classifier loss: 0.083433; batch adversarial loss: 0.439430\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036316; batch adversarial loss: 0.512408\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016095; batch adversarial loss: 0.384091\n",
      "epoch 169; iter: 0; batch classifier loss: 0.061516; batch adversarial loss: 0.524758\n",
      "epoch 170; iter: 0; batch classifier loss: 0.044793; batch adversarial loss: 0.535085\n",
      "epoch 171; iter: 0; batch classifier loss: 0.054548; batch adversarial loss: 0.510149\n",
      "epoch 172; iter: 0; batch classifier loss: 0.058904; batch adversarial loss: 0.604470\n",
      "epoch 173; iter: 0; batch classifier loss: 0.114074; batch adversarial loss: 0.640854\n",
      "epoch 174; iter: 0; batch classifier loss: 0.080257; batch adversarial loss: 0.577805\n",
      "epoch 175; iter: 0; batch classifier loss: 0.150146; batch adversarial loss: 0.692737\n",
      "epoch 176; iter: 0; batch classifier loss: 0.130150; batch adversarial loss: 0.650800\n",
      "epoch 177; iter: 0; batch classifier loss: 0.127976; batch adversarial loss: 0.650476\n",
      "epoch 178; iter: 0; batch classifier loss: 0.131311; batch adversarial loss: 0.646372\n",
      "epoch 179; iter: 0; batch classifier loss: 0.205636; batch adversarial loss: 0.774928\n",
      "epoch 180; iter: 0; batch classifier loss: 0.136439; batch adversarial loss: 0.657310\n",
      "epoch 181; iter: 0; batch classifier loss: 0.152138; batch adversarial loss: 0.669276\n",
      "epoch 182; iter: 0; batch classifier loss: 0.181997; batch adversarial loss: 0.774359\n",
      "epoch 183; iter: 0; batch classifier loss: 0.155288; batch adversarial loss: 0.610927\n",
      "epoch 184; iter: 0; batch classifier loss: 0.108464; batch adversarial loss: 0.546256\n",
      "epoch 185; iter: 0; batch classifier loss: 0.237773; batch adversarial loss: 0.851522\n",
      "epoch 186; iter: 0; batch classifier loss: 0.135803; batch adversarial loss: 0.550111\n",
      "epoch 187; iter: 0; batch classifier loss: 0.183233; batch adversarial loss: 0.588396\n",
      "epoch 188; iter: 0; batch classifier loss: 0.164587; batch adversarial loss: 0.644912\n",
      "epoch 189; iter: 0; batch classifier loss: 0.095320; batch adversarial loss: 0.489902\n",
      "epoch 190; iter: 0; batch classifier loss: 0.168347; batch adversarial loss: 0.573320\n",
      "epoch 191; iter: 0; batch classifier loss: 0.185225; batch adversarial loss: 0.609931\n",
      "epoch 192; iter: 0; batch classifier loss: 0.221846; batch adversarial loss: 0.720776\n",
      "epoch 193; iter: 0; batch classifier loss: 0.125322; batch adversarial loss: 0.610974\n",
      "epoch 194; iter: 0; batch classifier loss: 0.194931; batch adversarial loss: 0.679326\n",
      "epoch 195; iter: 0; batch classifier loss: 0.140975; batch adversarial loss: 0.633189\n",
      "epoch 196; iter: 0; batch classifier loss: 0.188772; batch adversarial loss: 0.678637\n",
      "epoch 197; iter: 0; batch classifier loss: 0.184337; batch adversarial loss: 0.604043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.141244; batch adversarial loss: 0.597118\n",
      "epoch 199; iter: 0; batch classifier loss: 0.105661; batch adversarial loss: 0.525463\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696137; batch adversarial loss: 1.000457\n",
      "epoch 1; iter: 0; batch classifier loss: 0.542382; batch adversarial loss: 1.157783\n",
      "epoch 2; iter: 0; batch classifier loss: 0.623477; batch adversarial loss: 1.056182\n",
      "epoch 3; iter: 0; batch classifier loss: 0.910040; batch adversarial loss: 1.010922\n",
      "epoch 4; iter: 0; batch classifier loss: 0.934598; batch adversarial loss: 0.917883\n",
      "epoch 5; iter: 0; batch classifier loss: 0.919985; batch adversarial loss: 0.809201\n",
      "epoch 6; iter: 0; batch classifier loss: 0.674428; batch adversarial loss: 0.768104\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491150; batch adversarial loss: 0.674473\n",
      "epoch 8; iter: 0; batch classifier loss: 0.295891; batch adversarial loss: 0.662708\n",
      "epoch 9; iter: 0; batch classifier loss: 0.263100; batch adversarial loss: 0.630125\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258198; batch adversarial loss: 0.565691\n",
      "epoch 11; iter: 0; batch classifier loss: 0.271038; batch adversarial loss: 0.589863\n",
      "epoch 12; iter: 0; batch classifier loss: 0.314014; batch adversarial loss: 0.565196\n",
      "epoch 13; iter: 0; batch classifier loss: 0.307500; batch adversarial loss: 0.558840\n",
      "epoch 14; iter: 0; batch classifier loss: 0.248489; batch adversarial loss: 0.539470\n",
      "epoch 15; iter: 0; batch classifier loss: 0.228891; batch adversarial loss: 0.591395\n",
      "epoch 16; iter: 0; batch classifier loss: 0.225258; batch adversarial loss: 0.507061\n",
      "epoch 17; iter: 0; batch classifier loss: 0.209401; batch adversarial loss: 0.524094\n",
      "epoch 18; iter: 0; batch classifier loss: 0.203854; batch adversarial loss: 0.518477\n",
      "epoch 19; iter: 0; batch classifier loss: 0.190992; batch adversarial loss: 0.500090\n",
      "epoch 20; iter: 0; batch classifier loss: 0.194189; batch adversarial loss: 0.509085\n",
      "epoch 21; iter: 0; batch classifier loss: 0.160663; batch adversarial loss: 0.495134\n",
      "epoch 22; iter: 0; batch classifier loss: 0.201981; batch adversarial loss: 0.447086\n",
      "epoch 23; iter: 0; batch classifier loss: 0.173163; batch adversarial loss: 0.440192\n",
      "epoch 24; iter: 0; batch classifier loss: 0.140768; batch adversarial loss: 0.432490\n",
      "epoch 25; iter: 0; batch classifier loss: 0.158471; batch adversarial loss: 0.471172\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181895; batch adversarial loss: 0.507759\n",
      "epoch 27; iter: 0; batch classifier loss: 0.118800; batch adversarial loss: 0.426266\n",
      "epoch 28; iter: 0; batch classifier loss: 0.143594; batch adversarial loss: 0.423973\n",
      "epoch 29; iter: 0; batch classifier loss: 0.164330; batch adversarial loss: 0.534103\n",
      "epoch 30; iter: 0; batch classifier loss: 0.165287; batch adversarial loss: 0.573669\n",
      "epoch 31; iter: 0; batch classifier loss: 0.127422; batch adversarial loss: 0.545301\n",
      "epoch 32; iter: 0; batch classifier loss: 0.136159; batch adversarial loss: 0.489904\n",
      "epoch 33; iter: 0; batch classifier loss: 0.125613; batch adversarial loss: 0.449675\n",
      "epoch 34; iter: 0; batch classifier loss: 0.109758; batch adversarial loss: 0.516808\n",
      "epoch 35; iter: 0; batch classifier loss: 0.109351; batch adversarial loss: 0.464826\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109505; batch adversarial loss: 0.434097\n",
      "epoch 37; iter: 0; batch classifier loss: 0.121894; batch adversarial loss: 0.391084\n",
      "epoch 38; iter: 0; batch classifier loss: 0.082476; batch adversarial loss: 0.330929\n",
      "epoch 39; iter: 0; batch classifier loss: 0.110127; batch adversarial loss: 0.493796\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099437; batch adversarial loss: 0.416680\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125998; batch adversarial loss: 0.535881\n",
      "epoch 42; iter: 0; batch classifier loss: 0.077999; batch adversarial loss: 0.470638\n",
      "epoch 43; iter: 0; batch classifier loss: 0.091147; batch adversarial loss: 0.317636\n",
      "epoch 44; iter: 0; batch classifier loss: 0.071145; batch adversarial loss: 0.518456\n",
      "epoch 45; iter: 0; batch classifier loss: 0.070415; batch adversarial loss: 0.494295\n",
      "epoch 46; iter: 0; batch classifier loss: 0.078454; batch adversarial loss: 0.403282\n",
      "epoch 47; iter: 0; batch classifier loss: 0.079783; batch adversarial loss: 0.464656\n",
      "epoch 48; iter: 0; batch classifier loss: 0.105185; batch adversarial loss: 0.377764\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099696; batch adversarial loss: 0.402224\n",
      "epoch 50; iter: 0; batch classifier loss: 0.050585; batch adversarial loss: 0.396442\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070464; batch adversarial loss: 0.476318\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089013; batch adversarial loss: 0.440834\n",
      "epoch 53; iter: 0; batch classifier loss: 0.052156; batch adversarial loss: 0.524075\n",
      "epoch 54; iter: 0; batch classifier loss: 0.046636; batch adversarial loss: 0.412793\n",
      "epoch 55; iter: 0; batch classifier loss: 0.073087; batch adversarial loss: 0.390438\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102611; batch adversarial loss: 0.428135\n",
      "epoch 57; iter: 0; batch classifier loss: 0.074086; batch adversarial loss: 0.425730\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078087; batch adversarial loss: 0.514852\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083724; batch adversarial loss: 0.518727\n",
      "epoch 60; iter: 0; batch classifier loss: 0.074334; batch adversarial loss: 0.463583\n",
      "epoch 61; iter: 0; batch classifier loss: 0.079642; batch adversarial loss: 0.538308\n",
      "epoch 62; iter: 0; batch classifier loss: 0.058957; batch adversarial loss: 0.452098\n",
      "epoch 63; iter: 0; batch classifier loss: 0.034365; batch adversarial loss: 0.458819\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072735; batch adversarial loss: 0.395072\n",
      "epoch 65; iter: 0; batch classifier loss: 0.057569; batch adversarial loss: 0.362402\n",
      "epoch 66; iter: 0; batch classifier loss: 0.082587; batch adversarial loss: 0.343959\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096821; batch adversarial loss: 0.463099\n",
      "epoch 68; iter: 0; batch classifier loss: 0.100443; batch adversarial loss: 0.393694\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081834; batch adversarial loss: 0.523289\n",
      "epoch 70; iter: 0; batch classifier loss: 0.060430; batch adversarial loss: 0.469239\n",
      "epoch 71; iter: 0; batch classifier loss: 0.068242; batch adversarial loss: 0.426114\n",
      "epoch 72; iter: 0; batch classifier loss: 0.055838; batch adversarial loss: 0.402887\n",
      "epoch 73; iter: 0; batch classifier loss: 0.056293; batch adversarial loss: 0.395781\n",
      "epoch 74; iter: 0; batch classifier loss: 0.072098; batch adversarial loss: 0.531082\n",
      "epoch 75; iter: 0; batch classifier loss: 0.053876; batch adversarial loss: 0.412753\n",
      "epoch 76; iter: 0; batch classifier loss: 0.045296; batch adversarial loss: 0.419673\n",
      "epoch 77; iter: 0; batch classifier loss: 0.034940; batch adversarial loss: 0.500978\n",
      "epoch 78; iter: 0; batch classifier loss: 0.089921; batch adversarial loss: 0.497248\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071435; batch adversarial loss: 0.419321\n",
      "epoch 80; iter: 0; batch classifier loss: 0.072177; batch adversarial loss: 0.408697\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073469; batch adversarial loss: 0.499477\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056023; batch adversarial loss: 0.474352\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049668; batch adversarial loss: 0.568475\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070668; batch adversarial loss: 0.473861\n",
      "epoch 85; iter: 0; batch classifier loss: 0.063639; batch adversarial loss: 0.381493\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068641; batch adversarial loss: 0.486816\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055238; batch adversarial loss: 0.541522\n",
      "epoch 88; iter: 0; batch classifier loss: 0.048243; batch adversarial loss: 0.520709\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051144; batch adversarial loss: 0.456210\n",
      "epoch 90; iter: 0; batch classifier loss: 0.071440; batch adversarial loss: 0.365148\n",
      "epoch 91; iter: 0; batch classifier loss: 0.033032; batch adversarial loss: 0.493670\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079378; batch adversarial loss: 0.505051\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052324; batch adversarial loss: 0.372263\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042633; batch adversarial loss: 0.384474\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045847; batch adversarial loss: 0.511689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.048325; batch adversarial loss: 0.462449\n",
      "epoch 97; iter: 0; batch classifier loss: 0.068348; batch adversarial loss: 0.502615\n",
      "epoch 98; iter: 0; batch classifier loss: 0.086574; batch adversarial loss: 0.366391\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064792; batch adversarial loss: 0.432811\n",
      "epoch 100; iter: 0; batch classifier loss: 0.077294; batch adversarial loss: 0.509753\n",
      "epoch 101; iter: 0; batch classifier loss: 0.038000; batch adversarial loss: 0.406404\n",
      "epoch 102; iter: 0; batch classifier loss: 0.028452; batch adversarial loss: 0.402707\n",
      "epoch 103; iter: 0; batch classifier loss: 0.095926; batch adversarial loss: 0.373966\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035467; batch adversarial loss: 0.463267\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047287; batch adversarial loss: 0.499165\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045703; batch adversarial loss: 0.420476\n",
      "epoch 107; iter: 0; batch classifier loss: 0.054627; batch adversarial loss: 0.541531\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065663; batch adversarial loss: 0.437616\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046680; batch adversarial loss: 0.498829\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044895; batch adversarial loss: 0.483511\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061006; batch adversarial loss: 0.427063\n",
      "epoch 112; iter: 0; batch classifier loss: 0.080166; batch adversarial loss: 0.548628\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034222; batch adversarial loss: 0.411111\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042701; batch adversarial loss: 0.492639\n",
      "epoch 115; iter: 0; batch classifier loss: 0.072472; batch adversarial loss: 0.415736\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045626; batch adversarial loss: 0.376461\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044495; batch adversarial loss: 0.512365\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059453; batch adversarial loss: 0.460426\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037708; batch adversarial loss: 0.421945\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036384; batch adversarial loss: 0.450546\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054027; batch adversarial loss: 0.319747\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041504; batch adversarial loss: 0.310400\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053930; batch adversarial loss: 0.379611\n",
      "epoch 124; iter: 0; batch classifier loss: 0.049511; batch adversarial loss: 0.561034\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048915; batch adversarial loss: 0.471613\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051109; batch adversarial loss: 0.444563\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046631; batch adversarial loss: 0.419823\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035100; batch adversarial loss: 0.438410\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033397; batch adversarial loss: 0.470365\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027155; batch adversarial loss: 0.428436\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047798; batch adversarial loss: 0.422959\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046286; batch adversarial loss: 0.422775\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020522; batch adversarial loss: 0.418277\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040404; batch adversarial loss: 0.480397\n",
      "epoch 135; iter: 0; batch classifier loss: 0.080911; batch adversarial loss: 0.530681\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049228; batch adversarial loss: 0.388521\n",
      "epoch 137; iter: 0; batch classifier loss: 0.057567; batch adversarial loss: 0.434119\n",
      "epoch 138; iter: 0; batch classifier loss: 0.047429; batch adversarial loss: 0.484639\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034834; batch adversarial loss: 0.448463\n",
      "epoch 140; iter: 0; batch classifier loss: 0.043843; batch adversarial loss: 0.548642\n",
      "epoch 141; iter: 0; batch classifier loss: 0.062130; batch adversarial loss: 0.385952\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028050; batch adversarial loss: 0.416137\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043703; batch adversarial loss: 0.407294\n",
      "epoch 144; iter: 0; batch classifier loss: 0.059125; batch adversarial loss: 0.455929\n",
      "epoch 145; iter: 0; batch classifier loss: 0.072533; batch adversarial loss: 0.409394\n",
      "epoch 146; iter: 0; batch classifier loss: 0.077808; batch adversarial loss: 0.513520\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016395; batch adversarial loss: 0.421683\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042061; batch adversarial loss: 0.385582\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037064; batch adversarial loss: 0.410859\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039693; batch adversarial loss: 0.434839\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040254; batch adversarial loss: 0.391912\n",
      "epoch 152; iter: 0; batch classifier loss: 0.073902; batch adversarial loss: 0.369048\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039909; batch adversarial loss: 0.416488\n",
      "epoch 154; iter: 0; batch classifier loss: 0.042433; batch adversarial loss: 0.423346\n",
      "epoch 155; iter: 0; batch classifier loss: 0.059430; batch adversarial loss: 0.465372\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039066; batch adversarial loss: 0.442555\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026177; batch adversarial loss: 0.436585\n",
      "epoch 158; iter: 0; batch classifier loss: 0.101314; batch adversarial loss: 0.420788\n",
      "epoch 159; iter: 0; batch classifier loss: 0.054338; batch adversarial loss: 0.460033\n",
      "epoch 160; iter: 0; batch classifier loss: 0.055205; batch adversarial loss: 0.442433\n",
      "epoch 161; iter: 0; batch classifier loss: 0.049236; batch adversarial loss: 0.505046\n",
      "epoch 162; iter: 0; batch classifier loss: 0.066257; batch adversarial loss: 0.403332\n",
      "epoch 163; iter: 0; batch classifier loss: 0.055576; batch adversarial loss: 0.384642\n",
      "epoch 164; iter: 0; batch classifier loss: 0.051489; batch adversarial loss: 0.511457\n",
      "epoch 165; iter: 0; batch classifier loss: 0.049221; batch adversarial loss: 0.418851\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031406; batch adversarial loss: 0.446032\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041208; batch adversarial loss: 0.437908\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026501; batch adversarial loss: 0.431837\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031232; batch adversarial loss: 0.430498\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040909; batch adversarial loss: 0.411574\n",
      "epoch 171; iter: 0; batch classifier loss: 0.061291; batch adversarial loss: 0.373551\n",
      "epoch 172; iter: 0; batch classifier loss: 0.044507; batch adversarial loss: 0.379269\n",
      "epoch 173; iter: 0; batch classifier loss: 0.062316; batch adversarial loss: 0.462980\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041863; batch adversarial loss: 0.405939\n",
      "epoch 175; iter: 0; batch classifier loss: 0.048247; batch adversarial loss: 0.515666\n",
      "epoch 176; iter: 0; batch classifier loss: 0.058387; batch adversarial loss: 0.460878\n",
      "epoch 177; iter: 0; batch classifier loss: 0.078723; batch adversarial loss: 0.471712\n",
      "epoch 178; iter: 0; batch classifier loss: 0.054687; batch adversarial loss: 0.459382\n",
      "epoch 179; iter: 0; batch classifier loss: 0.058780; batch adversarial loss: 0.453708\n",
      "epoch 180; iter: 0; batch classifier loss: 0.047540; batch adversarial loss: 0.520948\n",
      "epoch 181; iter: 0; batch classifier loss: 0.050761; batch adversarial loss: 0.512262\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029931; batch adversarial loss: 0.361492\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023134; batch adversarial loss: 0.425043\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034576; batch adversarial loss: 0.472323\n",
      "epoch 185; iter: 0; batch classifier loss: 0.059038; batch adversarial loss: 0.430057\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023331; batch adversarial loss: 0.420465\n",
      "epoch 187; iter: 0; batch classifier loss: 0.052882; batch adversarial loss: 0.453740\n",
      "epoch 188; iter: 0; batch classifier loss: 0.052050; batch adversarial loss: 0.458337\n",
      "epoch 189; iter: 0; batch classifier loss: 0.042951; batch adversarial loss: 0.508661\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017217; batch adversarial loss: 0.365005\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019399; batch adversarial loss: 0.485950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.031117; batch adversarial loss: 0.397848\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026226; batch adversarial loss: 0.396481\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026342; batch adversarial loss: 0.367588\n",
      "epoch 195; iter: 0; batch classifier loss: 0.056216; batch adversarial loss: 0.426826\n",
      "epoch 196; iter: 0; batch classifier loss: 0.036958; batch adversarial loss: 0.304618\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028316; batch adversarial loss: 0.425091\n",
      "epoch 198; iter: 0; batch classifier loss: 0.040977; batch adversarial loss: 0.442882\n",
      "epoch 199; iter: 0; batch classifier loss: 0.059273; batch adversarial loss: 0.519241\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686820; batch adversarial loss: 0.789648\n",
      "epoch 1; iter: 0; batch classifier loss: 0.585035; batch adversarial loss: 0.760643\n",
      "epoch 2; iter: 0; batch classifier loss: 0.582456; batch adversarial loss: 0.697454\n",
      "epoch 3; iter: 0; batch classifier loss: 0.667389; batch adversarial loss: 0.671506\n",
      "epoch 4; iter: 0; batch classifier loss: 0.552596; batch adversarial loss: 0.620733\n",
      "epoch 5; iter: 0; batch classifier loss: 0.474564; batch adversarial loss: 0.581889\n",
      "epoch 6; iter: 0; batch classifier loss: 0.388515; batch adversarial loss: 0.596013\n",
      "epoch 7; iter: 0; batch classifier loss: 0.388438; batch adversarial loss: 0.537779\n",
      "epoch 8; iter: 0; batch classifier loss: 0.353216; batch adversarial loss: 0.595984\n",
      "epoch 9; iter: 0; batch classifier loss: 0.405547; batch adversarial loss: 0.549957\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358072; batch adversarial loss: 0.509312\n",
      "epoch 11; iter: 0; batch classifier loss: 0.325229; batch adversarial loss: 0.521844\n",
      "epoch 12; iter: 0; batch classifier loss: 0.271195; batch adversarial loss: 0.543028\n",
      "epoch 13; iter: 0; batch classifier loss: 0.459876; batch adversarial loss: 0.491347\n",
      "epoch 14; iter: 0; batch classifier loss: 0.313732; batch adversarial loss: 0.472180\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302164; batch adversarial loss: 0.540080\n",
      "epoch 16; iter: 0; batch classifier loss: 0.373911; batch adversarial loss: 0.405119\n",
      "epoch 17; iter: 0; batch classifier loss: 0.257812; batch adversarial loss: 0.452962\n",
      "epoch 18; iter: 0; batch classifier loss: 0.394817; batch adversarial loss: 0.457274\n",
      "epoch 19; iter: 0; batch classifier loss: 0.280121; batch adversarial loss: 0.487859\n",
      "epoch 20; iter: 0; batch classifier loss: 0.226602; batch adversarial loss: 0.542689\n",
      "epoch 21; iter: 0; batch classifier loss: 0.313093; batch adversarial loss: 0.550382\n",
      "epoch 22; iter: 0; batch classifier loss: 0.275381; batch adversarial loss: 0.419373\n",
      "epoch 23; iter: 0; batch classifier loss: 0.301786; batch adversarial loss: 0.497815\n",
      "epoch 24; iter: 0; batch classifier loss: 0.273559; batch adversarial loss: 0.430834\n",
      "epoch 25; iter: 0; batch classifier loss: 0.303333; batch adversarial loss: 0.491750\n",
      "epoch 26; iter: 0; batch classifier loss: 0.301131; batch adversarial loss: 0.436086\n",
      "epoch 27; iter: 0; batch classifier loss: 0.239548; batch adversarial loss: 0.548406\n",
      "epoch 28; iter: 0; batch classifier loss: 0.188327; batch adversarial loss: 0.526254\n",
      "epoch 29; iter: 0; batch classifier loss: 0.212649; batch adversarial loss: 0.497515\n",
      "epoch 30; iter: 0; batch classifier loss: 0.224683; batch adversarial loss: 0.485693\n",
      "epoch 31; iter: 0; batch classifier loss: 0.195015; batch adversarial loss: 0.596244\n",
      "epoch 32; iter: 0; batch classifier loss: 0.252700; batch adversarial loss: 0.453807\n",
      "epoch 33; iter: 0; batch classifier loss: 0.181815; batch adversarial loss: 0.495171\n",
      "epoch 34; iter: 0; batch classifier loss: 0.224038; batch adversarial loss: 0.470614\n",
      "epoch 35; iter: 0; batch classifier loss: 0.248197; batch adversarial loss: 0.438599\n",
      "epoch 36; iter: 0; batch classifier loss: 0.211221; batch adversarial loss: 0.476556\n",
      "epoch 37; iter: 0; batch classifier loss: 0.203862; batch adversarial loss: 0.436829\n",
      "epoch 38; iter: 0; batch classifier loss: 0.158325; batch adversarial loss: 0.442105\n",
      "epoch 39; iter: 0; batch classifier loss: 0.212557; batch adversarial loss: 0.564499\n",
      "epoch 40; iter: 0; batch classifier loss: 0.290400; batch adversarial loss: 0.385024\n",
      "epoch 41; iter: 0; batch classifier loss: 0.226290; batch adversarial loss: 0.394308\n",
      "epoch 42; iter: 0; batch classifier loss: 0.245327; batch adversarial loss: 0.443781\n",
      "epoch 43; iter: 0; batch classifier loss: 0.207522; batch adversarial loss: 0.541509\n",
      "epoch 44; iter: 0; batch classifier loss: 0.237863; batch adversarial loss: 0.424935\n",
      "epoch 45; iter: 0; batch classifier loss: 0.250096; batch adversarial loss: 0.467512\n",
      "epoch 46; iter: 0; batch classifier loss: 0.179349; batch adversarial loss: 0.371457\n",
      "epoch 47; iter: 0; batch classifier loss: 0.169272; batch adversarial loss: 0.599938\n",
      "epoch 48; iter: 0; batch classifier loss: 0.186658; batch adversarial loss: 0.475081\n",
      "epoch 49; iter: 0; batch classifier loss: 0.146189; batch adversarial loss: 0.426827\n",
      "epoch 50; iter: 0; batch classifier loss: 0.215589; batch adversarial loss: 0.395217\n",
      "epoch 51; iter: 0; batch classifier loss: 0.192117; batch adversarial loss: 0.521569\n",
      "epoch 52; iter: 0; batch classifier loss: 0.228737; batch adversarial loss: 0.389319\n",
      "epoch 53; iter: 0; batch classifier loss: 0.126036; batch adversarial loss: 0.454142\n",
      "epoch 54; iter: 0; batch classifier loss: 0.118256; batch adversarial loss: 0.515306\n",
      "epoch 55; iter: 0; batch classifier loss: 0.115097; batch adversarial loss: 0.449107\n",
      "epoch 56; iter: 0; batch classifier loss: 0.114723; batch adversarial loss: 0.478441\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095384; batch adversarial loss: 0.431429\n",
      "epoch 58; iter: 0; batch classifier loss: 0.127516; batch adversarial loss: 0.402993\n",
      "epoch 59; iter: 0; batch classifier loss: 0.173331; batch adversarial loss: 0.467821\n",
      "epoch 60; iter: 0; batch classifier loss: 0.136070; batch adversarial loss: 0.419469\n",
      "epoch 61; iter: 0; batch classifier loss: 0.100685; batch adversarial loss: 0.476876\n",
      "epoch 62; iter: 0; batch classifier loss: 0.127345; batch adversarial loss: 0.524877\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079679; batch adversarial loss: 0.566437\n",
      "epoch 64; iter: 0; batch classifier loss: 0.178305; batch adversarial loss: 0.460550\n",
      "epoch 65; iter: 0; batch classifier loss: 0.133392; batch adversarial loss: 0.390902\n",
      "epoch 66; iter: 0; batch classifier loss: 0.094245; batch adversarial loss: 0.407929\n",
      "epoch 67; iter: 0; batch classifier loss: 0.052299; batch adversarial loss: 0.396939\n",
      "epoch 68; iter: 0; batch classifier loss: 0.123071; batch adversarial loss: 0.484934\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076350; batch adversarial loss: 0.414056\n",
      "epoch 70; iter: 0; batch classifier loss: 0.104519; batch adversarial loss: 0.425942\n",
      "epoch 71; iter: 0; batch classifier loss: 0.127339; batch adversarial loss: 0.415785\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082028; batch adversarial loss: 0.429109\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067580; batch adversarial loss: 0.441333\n",
      "epoch 74; iter: 0; batch classifier loss: 0.103296; batch adversarial loss: 0.422092\n",
      "epoch 75; iter: 0; batch classifier loss: 0.137930; batch adversarial loss: 0.416938\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077533; batch adversarial loss: 0.371564\n",
      "epoch 77; iter: 0; batch classifier loss: 0.060497; batch adversarial loss: 0.431027\n",
      "epoch 78; iter: 0; batch classifier loss: 0.095034; batch adversarial loss: 0.397881\n",
      "epoch 79; iter: 0; batch classifier loss: 0.046976; batch adversarial loss: 0.409339\n",
      "epoch 80; iter: 0; batch classifier loss: 0.049136; batch adversarial loss: 0.441149\n",
      "epoch 81; iter: 0; batch classifier loss: 0.041152; batch adversarial loss: 0.578961\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076327; batch adversarial loss: 0.480122\n",
      "epoch 83; iter: 0; batch classifier loss: 0.050659; batch adversarial loss: 0.609276\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045070; batch adversarial loss: 0.412205\n",
      "epoch 85; iter: 0; batch classifier loss: 0.095750; batch adversarial loss: 0.462429\n",
      "epoch 86; iter: 0; batch classifier loss: 0.056759; batch adversarial loss: 0.493738\n",
      "epoch 87; iter: 0; batch classifier loss: 0.041424; batch adversarial loss: 0.433094\n",
      "epoch 88; iter: 0; batch classifier loss: 0.031350; batch adversarial loss: 0.382283\n",
      "epoch 89; iter: 0; batch classifier loss: 0.037895; batch adversarial loss: 0.448540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.085124; batch adversarial loss: 0.426629\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077576; batch adversarial loss: 0.411338\n",
      "epoch 92; iter: 0; batch classifier loss: 0.034586; batch adversarial loss: 0.454938\n",
      "epoch 93; iter: 0; batch classifier loss: 0.120024; batch adversarial loss: 0.422275\n",
      "epoch 94; iter: 0; batch classifier loss: 0.099445; batch adversarial loss: 0.454988\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058389; batch adversarial loss: 0.520281\n",
      "epoch 96; iter: 0; batch classifier loss: 0.095776; batch adversarial loss: 0.401263\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066360; batch adversarial loss: 0.421519\n",
      "epoch 98; iter: 0; batch classifier loss: 0.037425; batch adversarial loss: 0.371443\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050177; batch adversarial loss: 0.420281\n",
      "epoch 100; iter: 0; batch classifier loss: 0.023758; batch adversarial loss: 0.449903\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040067; batch adversarial loss: 0.479585\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053599; batch adversarial loss: 0.508715\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044241; batch adversarial loss: 0.476012\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045132; batch adversarial loss: 0.432689\n",
      "epoch 105; iter: 0; batch classifier loss: 0.032619; batch adversarial loss: 0.458769\n",
      "epoch 106; iter: 0; batch classifier loss: 0.066806; batch adversarial loss: 0.410368\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041304; batch adversarial loss: 0.510363\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033633; batch adversarial loss: 0.479318\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029589; batch adversarial loss: 0.508045\n",
      "epoch 110; iter: 0; batch classifier loss: 0.071587; batch adversarial loss: 0.372653\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057386; batch adversarial loss: 0.402087\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025632; batch adversarial loss: 0.394363\n",
      "epoch 113; iter: 0; batch classifier loss: 0.078491; batch adversarial loss: 0.431816\n",
      "epoch 114; iter: 0; batch classifier loss: 0.025535; batch adversarial loss: 0.453067\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054696; batch adversarial loss: 0.485289\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026000; batch adversarial loss: 0.528415\n",
      "epoch 117; iter: 0; batch classifier loss: 0.022428; batch adversarial loss: 0.459980\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037010; batch adversarial loss: 0.407499\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044474; batch adversarial loss: 0.478464\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036860; batch adversarial loss: 0.326782\n",
      "epoch 121; iter: 0; batch classifier loss: 0.017012; batch adversarial loss: 0.447773\n",
      "epoch 122; iter: 0; batch classifier loss: 0.047131; batch adversarial loss: 0.427596\n",
      "epoch 123; iter: 0; batch classifier loss: 0.022878; batch adversarial loss: 0.492699\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027973; batch adversarial loss: 0.540509\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042274; batch adversarial loss: 0.375934\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036765; batch adversarial loss: 0.397578\n",
      "epoch 127; iter: 0; batch classifier loss: 0.015295; batch adversarial loss: 0.465084\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028954; batch adversarial loss: 0.508239\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035234; batch adversarial loss: 0.413335\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037887; batch adversarial loss: 0.585622\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018178; batch adversarial loss: 0.430656\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023914; batch adversarial loss: 0.466108\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037596; batch adversarial loss: 0.494573\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037273; batch adversarial loss: 0.523784\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024093; batch adversarial loss: 0.452193\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033778; batch adversarial loss: 0.479121\n",
      "epoch 137; iter: 0; batch classifier loss: 0.005806; batch adversarial loss: 0.406170\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023013; batch adversarial loss: 0.466834\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009690; batch adversarial loss: 0.415059\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018180; batch adversarial loss: 0.408780\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027120; batch adversarial loss: 0.487430\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036344; batch adversarial loss: 0.492546\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011728; batch adversarial loss: 0.443927\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018939; batch adversarial loss: 0.539621\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023548; batch adversarial loss: 0.442067\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028867; batch adversarial loss: 0.435622\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036294; batch adversarial loss: 0.325714\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016351; batch adversarial loss: 0.483480\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020757; batch adversarial loss: 0.455733\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036982; batch adversarial loss: 0.387764\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021157; batch adversarial loss: 0.387019\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026302; batch adversarial loss: 0.395704\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010042; batch adversarial loss: 0.368710\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021973; batch adversarial loss: 0.378380\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016142; batch adversarial loss: 0.528919\n",
      "epoch 156; iter: 0; batch classifier loss: 0.008422; batch adversarial loss: 0.451039\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022921; batch adversarial loss: 0.526511\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009490; batch adversarial loss: 0.483843\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025535; batch adversarial loss: 0.399167\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017085; batch adversarial loss: 0.496753\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010466; batch adversarial loss: 0.475256\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019660; batch adversarial loss: 0.471892\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024580; batch adversarial loss: 0.511604\n",
      "epoch 164; iter: 0; batch classifier loss: 0.047313; batch adversarial loss: 0.522955\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028292; batch adversarial loss: 0.473099\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014103; batch adversarial loss: 0.372765\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014774; batch adversarial loss: 0.449016\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021902; batch adversarial loss: 0.437319\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017581; batch adversarial loss: 0.484383\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013682; batch adversarial loss: 0.427586\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007750; batch adversarial loss: 0.457461\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009349; batch adversarial loss: 0.496778\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017265; batch adversarial loss: 0.459800\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035400; batch adversarial loss: 0.450737\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028015; batch adversarial loss: 0.420886\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034048; batch adversarial loss: 0.559947\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011107; batch adversarial loss: 0.313994\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021176; batch adversarial loss: 0.423516\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019328; batch adversarial loss: 0.419816\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023731; batch adversarial loss: 0.485683\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016211; batch adversarial loss: 0.431429\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037238; batch adversarial loss: 0.528785\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021441; batch adversarial loss: 0.470746\n",
      "epoch 184; iter: 0; batch classifier loss: 0.005273; batch adversarial loss: 0.512146\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017647; batch adversarial loss: 0.490681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.006980; batch adversarial loss: 0.396392\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018531; batch adversarial loss: 0.421194\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012761; batch adversarial loss: 0.431331\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036981; batch adversarial loss: 0.500291\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025284; batch adversarial loss: 0.402827\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016027; batch adversarial loss: 0.503934\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018991; batch adversarial loss: 0.440690\n",
      "epoch 193; iter: 0; batch classifier loss: 0.074481; batch adversarial loss: 0.417392\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025279; batch adversarial loss: 0.470779\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023534; batch adversarial loss: 0.479880\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014795; batch adversarial loss: 0.502771\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013913; batch adversarial loss: 0.391432\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021122; batch adversarial loss: 0.542305\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007056; batch adversarial loss: 0.418937\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700091; batch adversarial loss: 0.818067\n",
      "epoch 1; iter: 0; batch classifier loss: 0.648132; batch adversarial loss: 0.780970\n",
      "epoch 2; iter: 0; batch classifier loss: 0.805733; batch adversarial loss: 0.769969\n",
      "epoch 3; iter: 0; batch classifier loss: 0.623780; batch adversarial loss: 0.682212\n",
      "epoch 4; iter: 0; batch classifier loss: 0.587403; batch adversarial loss: 0.643399\n",
      "epoch 5; iter: 0; batch classifier loss: 0.481286; batch adversarial loss: 0.590493\n",
      "epoch 6; iter: 0; batch classifier loss: 0.357880; batch adversarial loss: 0.562888\n",
      "epoch 7; iter: 0; batch classifier loss: 0.358883; batch adversarial loss: 0.540455\n",
      "epoch 8; iter: 0; batch classifier loss: 0.260821; batch adversarial loss: 0.538777\n",
      "epoch 9; iter: 0; batch classifier loss: 0.352010; batch adversarial loss: 0.501987\n",
      "epoch 10; iter: 0; batch classifier loss: 0.366531; batch adversarial loss: 0.490548\n",
      "epoch 11; iter: 0; batch classifier loss: 0.321026; batch adversarial loss: 0.510381\n",
      "epoch 12; iter: 0; batch classifier loss: 0.257538; batch adversarial loss: 0.519551\n",
      "epoch 13; iter: 0; batch classifier loss: 0.178627; batch adversarial loss: 0.503546\n",
      "epoch 14; iter: 0; batch classifier loss: 0.292764; batch adversarial loss: 0.471422\n",
      "epoch 15; iter: 0; batch classifier loss: 0.258813; batch adversarial loss: 0.450119\n",
      "epoch 16; iter: 0; batch classifier loss: 0.247329; batch adversarial loss: 0.476698\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217372; batch adversarial loss: 0.479287\n",
      "epoch 18; iter: 0; batch classifier loss: 0.328209; batch adversarial loss: 0.459439\n",
      "epoch 19; iter: 0; batch classifier loss: 0.166331; batch adversarial loss: 0.510991\n",
      "epoch 20; iter: 0; batch classifier loss: 0.170949; batch adversarial loss: 0.565217\n",
      "epoch 21; iter: 0; batch classifier loss: 0.206148; batch adversarial loss: 0.437064\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224800; batch adversarial loss: 0.513636\n",
      "epoch 23; iter: 0; batch classifier loss: 0.268758; batch adversarial loss: 0.499431\n",
      "epoch 24; iter: 0; batch classifier loss: 0.153893; batch adversarial loss: 0.582700\n",
      "epoch 25; iter: 0; batch classifier loss: 0.151290; batch adversarial loss: 0.494800\n",
      "epoch 26; iter: 0; batch classifier loss: 0.138099; batch adversarial loss: 0.585888\n",
      "epoch 27; iter: 0; batch classifier loss: 0.217497; batch adversarial loss: 0.374307\n",
      "epoch 28; iter: 0; batch classifier loss: 0.115802; batch adversarial loss: 0.517411\n",
      "epoch 29; iter: 0; batch classifier loss: 0.134966; batch adversarial loss: 0.439188\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151446; batch adversarial loss: 0.516999\n",
      "epoch 31; iter: 0; batch classifier loss: 0.104525; batch adversarial loss: 0.528195\n",
      "epoch 32; iter: 0; batch classifier loss: 0.151074; batch adversarial loss: 0.415968\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143998; batch adversarial loss: 0.453913\n",
      "epoch 34; iter: 0; batch classifier loss: 0.139128; batch adversarial loss: 0.407598\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142511; batch adversarial loss: 0.466174\n",
      "epoch 36; iter: 0; batch classifier loss: 0.073385; batch adversarial loss: 0.403853\n",
      "epoch 37; iter: 0; batch classifier loss: 0.079076; batch adversarial loss: 0.498834\n",
      "epoch 38; iter: 0; batch classifier loss: 0.136528; batch adversarial loss: 0.401818\n",
      "epoch 39; iter: 0; batch classifier loss: 0.078361; batch adversarial loss: 0.414724\n",
      "epoch 40; iter: 0; batch classifier loss: 0.115593; batch adversarial loss: 0.453070\n",
      "epoch 41; iter: 0; batch classifier loss: 0.157115; batch adversarial loss: 0.356273\n",
      "epoch 42; iter: 0; batch classifier loss: 0.109810; batch adversarial loss: 0.458165\n",
      "epoch 43; iter: 0; batch classifier loss: 0.095347; batch adversarial loss: 0.502436\n",
      "epoch 44; iter: 0; batch classifier loss: 0.100957; batch adversarial loss: 0.453273\n",
      "epoch 45; iter: 0; batch classifier loss: 0.140860; batch adversarial loss: 0.485712\n",
      "epoch 46; iter: 0; batch classifier loss: 0.146440; batch adversarial loss: 0.424780\n",
      "epoch 47; iter: 0; batch classifier loss: 0.080535; batch adversarial loss: 0.563266\n",
      "epoch 48; iter: 0; batch classifier loss: 0.144312; batch adversarial loss: 0.384085\n",
      "epoch 49; iter: 0; batch classifier loss: 0.122335; batch adversarial loss: 0.430274\n",
      "epoch 50; iter: 0; batch classifier loss: 0.051615; batch adversarial loss: 0.479558\n",
      "epoch 51; iter: 0; batch classifier loss: 0.137102; batch adversarial loss: 0.411568\n",
      "epoch 52; iter: 0; batch classifier loss: 0.102628; batch adversarial loss: 0.456525\n",
      "epoch 53; iter: 0; batch classifier loss: 0.105082; batch adversarial loss: 0.385189\n",
      "epoch 54; iter: 0; batch classifier loss: 0.086667; batch adversarial loss: 0.438793\n",
      "epoch 55; iter: 0; batch classifier loss: 0.102415; batch adversarial loss: 0.557127\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101388; batch adversarial loss: 0.535258\n",
      "epoch 57; iter: 0; batch classifier loss: 0.130794; batch adversarial loss: 0.503222\n",
      "epoch 58; iter: 0; batch classifier loss: 0.098692; batch adversarial loss: 0.570811\n",
      "epoch 59; iter: 0; batch classifier loss: 0.104791; batch adversarial loss: 0.422697\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122798; batch adversarial loss: 0.407449\n",
      "epoch 61; iter: 0; batch classifier loss: 0.086994; batch adversarial loss: 0.470315\n",
      "epoch 62; iter: 0; batch classifier loss: 0.077143; batch adversarial loss: 0.427438\n",
      "epoch 63; iter: 0; batch classifier loss: 0.073203; batch adversarial loss: 0.416375\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090446; batch adversarial loss: 0.487991\n",
      "epoch 65; iter: 0; batch classifier loss: 0.153174; batch adversarial loss: 0.401917\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086333; batch adversarial loss: 0.428563\n",
      "epoch 67; iter: 0; batch classifier loss: 0.055982; batch adversarial loss: 0.417481\n",
      "epoch 68; iter: 0; batch classifier loss: 0.080880; batch adversarial loss: 0.522081\n",
      "epoch 69; iter: 0; batch classifier loss: 0.120404; batch adversarial loss: 0.417206\n",
      "epoch 70; iter: 0; batch classifier loss: 0.104317; batch adversarial loss: 0.506003\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069407; batch adversarial loss: 0.470454\n",
      "epoch 72; iter: 0; batch classifier loss: 0.112431; batch adversarial loss: 0.488704\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077759; batch adversarial loss: 0.414602\n",
      "epoch 74; iter: 0; batch classifier loss: 0.097787; batch adversarial loss: 0.480548\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073871; batch adversarial loss: 0.502392\n",
      "epoch 76; iter: 0; batch classifier loss: 0.051652; batch adversarial loss: 0.459743\n",
      "epoch 77; iter: 0; batch classifier loss: 0.072619; batch adversarial loss: 0.478146\n",
      "epoch 78; iter: 0; batch classifier loss: 0.040439; batch adversarial loss: 0.478856\n",
      "epoch 79; iter: 0; batch classifier loss: 0.079019; batch adversarial loss: 0.425104\n",
      "epoch 80; iter: 0; batch classifier loss: 0.062512; batch adversarial loss: 0.453403\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081130; batch adversarial loss: 0.455850\n",
      "epoch 82; iter: 0; batch classifier loss: 0.038617; batch adversarial loss: 0.442297\n",
      "epoch 83; iter: 0; batch classifier loss: 0.060400; batch adversarial loss: 0.386828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.051702; batch adversarial loss: 0.358918\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067081; batch adversarial loss: 0.477694\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073989; batch adversarial loss: 0.564368\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046935; batch adversarial loss: 0.437047\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069634; batch adversarial loss: 0.442223\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075963; batch adversarial loss: 0.503289\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063049; batch adversarial loss: 0.437765\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074590; batch adversarial loss: 0.583135\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050375; batch adversarial loss: 0.463838\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064402; batch adversarial loss: 0.450338\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083355; batch adversarial loss: 0.382173\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046070; batch adversarial loss: 0.425257\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058093; batch adversarial loss: 0.549294\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043530; batch adversarial loss: 0.470394\n",
      "epoch 98; iter: 0; batch classifier loss: 0.029039; batch adversarial loss: 0.480459\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040973; batch adversarial loss: 0.489272\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034109; batch adversarial loss: 0.465110\n",
      "epoch 101; iter: 0; batch classifier loss: 0.082213; batch adversarial loss: 0.356638\n",
      "epoch 102; iter: 0; batch classifier loss: 0.045581; batch adversarial loss: 0.446695\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072548; batch adversarial loss: 0.441991\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033990; batch adversarial loss: 0.463306\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038150; batch adversarial loss: 0.403243\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042430; batch adversarial loss: 0.453920\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049221; batch adversarial loss: 0.430108\n",
      "epoch 108; iter: 0; batch classifier loss: 0.023122; batch adversarial loss: 0.439608\n",
      "epoch 109; iter: 0; batch classifier loss: 0.084279; batch adversarial loss: 0.411386\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049386; batch adversarial loss: 0.468404\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053825; batch adversarial loss: 0.478722\n",
      "epoch 112; iter: 0; batch classifier loss: 0.077739; batch adversarial loss: 0.486408\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033374; batch adversarial loss: 0.537957\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037750; batch adversarial loss: 0.392537\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022401; batch adversarial loss: 0.392392\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042451; batch adversarial loss: 0.468286\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053496; batch adversarial loss: 0.367718\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049470; batch adversarial loss: 0.519052\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037811; batch adversarial loss: 0.460635\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036053; batch adversarial loss: 0.489781\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028004; batch adversarial loss: 0.393579\n",
      "epoch 122; iter: 0; batch classifier loss: 0.065128; batch adversarial loss: 0.373264\n",
      "epoch 123; iter: 0; batch classifier loss: 0.058576; batch adversarial loss: 0.456016\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035873; batch adversarial loss: 0.427884\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037709; batch adversarial loss: 0.529441\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024803; batch adversarial loss: 0.516796\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029113; batch adversarial loss: 0.412793\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032651; batch adversarial loss: 0.542974\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028691; batch adversarial loss: 0.404005\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024195; batch adversarial loss: 0.539641\n",
      "epoch 131; iter: 0; batch classifier loss: 0.071964; batch adversarial loss: 0.491474\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040300; batch adversarial loss: 0.363890\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041206; batch adversarial loss: 0.459158\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035192; batch adversarial loss: 0.501793\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025935; batch adversarial loss: 0.447641\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027685; batch adversarial loss: 0.483832\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052985; batch adversarial loss: 0.377684\n",
      "epoch 138; iter: 0; batch classifier loss: 0.015324; batch adversarial loss: 0.417913\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020076; batch adversarial loss: 0.496308\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032432; batch adversarial loss: 0.491152\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030405; batch adversarial loss: 0.445626\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013368; batch adversarial loss: 0.474475\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010286; batch adversarial loss: 0.458368\n",
      "epoch 144; iter: 0; batch classifier loss: 0.015503; batch adversarial loss: 0.394461\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039016; batch adversarial loss: 0.431711\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019160; batch adversarial loss: 0.456856\n",
      "epoch 147; iter: 0; batch classifier loss: 0.047395; batch adversarial loss: 0.496551\n",
      "epoch 148; iter: 0; batch classifier loss: 0.047750; batch adversarial loss: 0.511349\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036595; batch adversarial loss: 0.482161\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038023; batch adversarial loss: 0.432987\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035971; batch adversarial loss: 0.414211\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023678; batch adversarial loss: 0.421111\n",
      "epoch 153; iter: 0; batch classifier loss: 0.009953; batch adversarial loss: 0.455175\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029754; batch adversarial loss: 0.454110\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027322; batch adversarial loss: 0.358647\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018549; batch adversarial loss: 0.492069\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013458; batch adversarial loss: 0.448729\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036394; batch adversarial loss: 0.465135\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026704; batch adversarial loss: 0.466952\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020629; batch adversarial loss: 0.513063\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008808; batch adversarial loss: 0.531779\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007586; batch adversarial loss: 0.416416\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029428; batch adversarial loss: 0.543823\n",
      "epoch 164; iter: 0; batch classifier loss: 0.004155; batch adversarial loss: 0.456458\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028166; batch adversarial loss: 0.457850\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043707; batch adversarial loss: 0.427206\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012046; batch adversarial loss: 0.435887\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031808; batch adversarial loss: 0.474173\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022924; batch adversarial loss: 0.506124\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016776; batch adversarial loss: 0.408089\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016367; batch adversarial loss: 0.428119\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033663; batch adversarial loss: 0.399350\n",
      "epoch 173; iter: 0; batch classifier loss: 0.055327; batch adversarial loss: 0.509404\n",
      "epoch 174; iter: 0; batch classifier loss: 0.051852; batch adversarial loss: 0.511122\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025283; batch adversarial loss: 0.477469\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034350; batch adversarial loss: 0.503479\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011576; batch adversarial loss: 0.476709\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023606; batch adversarial loss: 0.433861\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006815; batch adversarial loss: 0.443857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.021751; batch adversarial loss: 0.447266\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015731; batch adversarial loss: 0.487994\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010571; batch adversarial loss: 0.399297\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014411; batch adversarial loss: 0.397280\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021821; batch adversarial loss: 0.435290\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017629; batch adversarial loss: 0.515750\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032375; batch adversarial loss: 0.415852\n",
      "epoch 187; iter: 0; batch classifier loss: 0.049685; batch adversarial loss: 0.472909\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009569; batch adversarial loss: 0.389316\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021684; batch adversarial loss: 0.415461\n",
      "epoch 190; iter: 0; batch classifier loss: 0.002622; batch adversarial loss: 0.413278\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015109; batch adversarial loss: 0.523064\n",
      "epoch 192; iter: 0; batch classifier loss: 0.049599; batch adversarial loss: 0.449063\n",
      "epoch 193; iter: 0; batch classifier loss: 0.039336; batch adversarial loss: 0.489620\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007382; batch adversarial loss: 0.501282\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021581; batch adversarial loss: 0.442050\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028033; batch adversarial loss: 0.453616\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005392; batch adversarial loss: 0.471870\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007353; batch adversarial loss: 0.468449\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030823; batch adversarial loss: 0.431217\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709062; batch adversarial loss: 0.701083\n",
      "epoch 1; iter: 0; batch classifier loss: 0.458792; batch adversarial loss: 0.676778\n",
      "epoch 2; iter: 0; batch classifier loss: 0.385742; batch adversarial loss: 0.672618\n",
      "epoch 3; iter: 0; batch classifier loss: 0.422278; batch adversarial loss: 0.604198\n",
      "epoch 4; iter: 0; batch classifier loss: 0.402493; batch adversarial loss: 0.576455\n",
      "epoch 5; iter: 0; batch classifier loss: 0.310929; batch adversarial loss: 0.534379\n",
      "epoch 6; iter: 0; batch classifier loss: 0.345808; batch adversarial loss: 0.515741\n",
      "epoch 7; iter: 0; batch classifier loss: 0.242641; batch adversarial loss: 0.506450\n",
      "epoch 8; iter: 0; batch classifier loss: 0.294119; batch adversarial loss: 0.545298\n",
      "epoch 9; iter: 0; batch classifier loss: 0.231144; batch adversarial loss: 0.481047\n",
      "epoch 10; iter: 0; batch classifier loss: 0.242626; batch adversarial loss: 0.461464\n",
      "epoch 11; iter: 0; batch classifier loss: 0.230875; batch adversarial loss: 0.509214\n",
      "epoch 12; iter: 0; batch classifier loss: 0.269862; batch adversarial loss: 0.468413\n",
      "epoch 13; iter: 0; batch classifier loss: 0.227705; batch adversarial loss: 0.505845\n",
      "epoch 14; iter: 0; batch classifier loss: 0.142697; batch adversarial loss: 0.477230\n",
      "epoch 15; iter: 0; batch classifier loss: 0.099182; batch adversarial loss: 0.445291\n",
      "epoch 16; iter: 0; batch classifier loss: 0.166731; batch adversarial loss: 0.423233\n",
      "epoch 17; iter: 0; batch classifier loss: 0.150955; batch adversarial loss: 0.534272\n",
      "epoch 18; iter: 0; batch classifier loss: 0.104804; batch adversarial loss: 0.388181\n",
      "epoch 19; iter: 0; batch classifier loss: 0.177532; batch adversarial loss: 0.418547\n",
      "epoch 20; iter: 0; batch classifier loss: 0.116544; batch adversarial loss: 0.390617\n",
      "epoch 21; iter: 0; batch classifier loss: 0.183465; batch adversarial loss: 0.436141\n",
      "epoch 22; iter: 0; batch classifier loss: 0.161891; batch adversarial loss: 0.489302\n",
      "epoch 23; iter: 0; batch classifier loss: 0.110004; batch adversarial loss: 0.498261\n",
      "epoch 24; iter: 0; batch classifier loss: 0.131691; batch adversarial loss: 0.493060\n",
      "epoch 25; iter: 0; batch classifier loss: 0.121200; batch adversarial loss: 0.443236\n",
      "epoch 26; iter: 0; batch classifier loss: 0.074663; batch adversarial loss: 0.428239\n",
      "epoch 27; iter: 0; batch classifier loss: 0.077849; batch adversarial loss: 0.380763\n",
      "epoch 28; iter: 0; batch classifier loss: 0.119956; batch adversarial loss: 0.547520\n",
      "epoch 29; iter: 0; batch classifier loss: 0.106589; batch adversarial loss: 0.345420\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152634; batch adversarial loss: 0.571064\n",
      "epoch 31; iter: 0; batch classifier loss: 0.105143; batch adversarial loss: 0.509368\n",
      "epoch 32; iter: 0; batch classifier loss: 0.135036; batch adversarial loss: 0.636855\n",
      "epoch 33; iter: 0; batch classifier loss: 0.164209; batch adversarial loss: 0.549201\n",
      "epoch 34; iter: 0; batch classifier loss: 0.189675; batch adversarial loss: 0.548213\n",
      "epoch 35; iter: 0; batch classifier loss: 0.165060; batch adversarial loss: 0.527493\n",
      "epoch 36; iter: 0; batch classifier loss: 0.151416; batch adversarial loss: 0.458845\n",
      "epoch 37; iter: 0; batch classifier loss: 0.151178; batch adversarial loss: 0.395499\n",
      "epoch 38; iter: 0; batch classifier loss: 0.132755; batch adversarial loss: 0.515431\n",
      "epoch 39; iter: 0; batch classifier loss: 0.122999; batch adversarial loss: 0.459065\n",
      "epoch 40; iter: 0; batch classifier loss: 0.216246; batch adversarial loss: 0.458888\n",
      "epoch 41; iter: 0; batch classifier loss: 0.187116; batch adversarial loss: 0.569324\n",
      "epoch 42; iter: 0; batch classifier loss: 0.164053; batch adversarial loss: 0.422517\n",
      "epoch 43; iter: 0; batch classifier loss: 0.296863; batch adversarial loss: 0.479351\n",
      "epoch 44; iter: 0; batch classifier loss: 0.219088; batch adversarial loss: 0.458923\n",
      "epoch 45; iter: 0; batch classifier loss: 0.122287; batch adversarial loss: 0.513535\n",
      "epoch 46; iter: 0; batch classifier loss: 0.078570; batch adversarial loss: 0.568703\n",
      "epoch 47; iter: 0; batch classifier loss: 0.051680; batch adversarial loss: 0.443224\n",
      "epoch 48; iter: 0; batch classifier loss: 0.108613; batch adversarial loss: 0.421403\n",
      "epoch 49; iter: 0; batch classifier loss: 0.053812; batch adversarial loss: 0.379378\n",
      "epoch 50; iter: 0; batch classifier loss: 0.055100; batch adversarial loss: 0.492840\n",
      "epoch 51; iter: 0; batch classifier loss: 0.039798; batch adversarial loss: 0.573550\n",
      "epoch 52; iter: 0; batch classifier loss: 0.104766; batch adversarial loss: 0.450407\n",
      "epoch 53; iter: 0; batch classifier loss: 0.101098; batch adversarial loss: 0.441561\n",
      "epoch 54; iter: 0; batch classifier loss: 0.049903; batch adversarial loss: 0.604283\n",
      "epoch 55; iter: 0; batch classifier loss: 0.081648; batch adversarial loss: 0.425027\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081593; batch adversarial loss: 0.496751\n",
      "epoch 57; iter: 0; batch classifier loss: 0.048614; batch adversarial loss: 0.325433\n",
      "epoch 58; iter: 0; batch classifier loss: 0.076666; batch adversarial loss: 0.542502\n",
      "epoch 59; iter: 0; batch classifier loss: 0.060603; batch adversarial loss: 0.470427\n",
      "epoch 60; iter: 0; batch classifier loss: 0.107315; batch adversarial loss: 0.419440\n",
      "epoch 61; iter: 0; batch classifier loss: 0.035046; batch adversarial loss: 0.434091\n",
      "epoch 62; iter: 0; batch classifier loss: 0.035227; batch adversarial loss: 0.419756\n",
      "epoch 63; iter: 0; batch classifier loss: 0.052594; batch adversarial loss: 0.432692\n",
      "epoch 64; iter: 0; batch classifier loss: 0.029578; batch adversarial loss: 0.464712\n",
      "epoch 65; iter: 0; batch classifier loss: 0.056821; batch adversarial loss: 0.430422\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086458; batch adversarial loss: 0.453336\n",
      "epoch 67; iter: 0; batch classifier loss: 0.092792; batch adversarial loss: 0.387484\n",
      "epoch 68; iter: 0; batch classifier loss: 0.051852; batch adversarial loss: 0.462069\n",
      "epoch 69; iter: 0; batch classifier loss: 0.052910; batch adversarial loss: 0.453893\n",
      "epoch 70; iter: 0; batch classifier loss: 0.092713; batch adversarial loss: 0.321633\n",
      "epoch 71; iter: 0; batch classifier loss: 0.056804; batch adversarial loss: 0.577440\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064586; batch adversarial loss: 0.468779\n",
      "epoch 73; iter: 0; batch classifier loss: 0.053711; batch adversarial loss: 0.492314\n",
      "epoch 74; iter: 0; batch classifier loss: 0.029248; batch adversarial loss: 0.435299\n",
      "epoch 75; iter: 0; batch classifier loss: 0.033041; batch adversarial loss: 0.418592\n",
      "epoch 76; iter: 0; batch classifier loss: 0.031920; batch adversarial loss: 0.452518\n",
      "epoch 77; iter: 0; batch classifier loss: 0.107291; batch adversarial loss: 0.452455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.054347; batch adversarial loss: 0.536826\n",
      "epoch 79; iter: 0; batch classifier loss: 0.036453; batch adversarial loss: 0.340386\n",
      "epoch 80; iter: 0; batch classifier loss: 0.098351; batch adversarial loss: 0.465586\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077578; batch adversarial loss: 0.434630\n",
      "epoch 82; iter: 0; batch classifier loss: 0.051867; batch adversarial loss: 0.496150\n",
      "epoch 83; iter: 0; batch classifier loss: 0.042414; batch adversarial loss: 0.489953\n",
      "epoch 84; iter: 0; batch classifier loss: 0.063553; batch adversarial loss: 0.395183\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084940; batch adversarial loss: 0.417213\n",
      "epoch 86; iter: 0; batch classifier loss: 0.036422; batch adversarial loss: 0.527469\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057557; batch adversarial loss: 0.509172\n",
      "epoch 88; iter: 0; batch classifier loss: 0.035037; batch adversarial loss: 0.451681\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063831; batch adversarial loss: 0.440218\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052863; batch adversarial loss: 0.415716\n",
      "epoch 91; iter: 0; batch classifier loss: 0.054614; batch adversarial loss: 0.501411\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079347; batch adversarial loss: 0.327242\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059994; batch adversarial loss: 0.402793\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058650; batch adversarial loss: 0.446903\n",
      "epoch 95; iter: 0; batch classifier loss: 0.041281; batch adversarial loss: 0.454409\n",
      "epoch 96; iter: 0; batch classifier loss: 0.087065; batch adversarial loss: 0.440733\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072031; batch adversarial loss: 0.415952\n",
      "epoch 98; iter: 0; batch classifier loss: 0.070767; batch adversarial loss: 0.434125\n",
      "epoch 99; iter: 0; batch classifier loss: 0.033001; batch adversarial loss: 0.479165\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044747; batch adversarial loss: 0.405699\n",
      "epoch 101; iter: 0; batch classifier loss: 0.066680; batch adversarial loss: 0.459948\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047451; batch adversarial loss: 0.546493\n",
      "epoch 103; iter: 0; batch classifier loss: 0.027919; batch adversarial loss: 0.415277\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069631; batch adversarial loss: 0.439738\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034833; batch adversarial loss: 0.469918\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060471; batch adversarial loss: 0.445778\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046409; batch adversarial loss: 0.442060\n",
      "epoch 108; iter: 0; batch classifier loss: 0.075896; batch adversarial loss: 0.449515\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038900; batch adversarial loss: 0.410390\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048034; batch adversarial loss: 0.340261\n",
      "epoch 111; iter: 0; batch classifier loss: 0.023533; batch adversarial loss: 0.420170\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048413; batch adversarial loss: 0.483663\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027296; batch adversarial loss: 0.488730\n",
      "epoch 114; iter: 0; batch classifier loss: 0.067115; batch adversarial loss: 0.411699\n",
      "epoch 115; iter: 0; batch classifier loss: 0.018004; batch adversarial loss: 0.518110\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037989; batch adversarial loss: 0.452212\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037577; batch adversarial loss: 0.406998\n",
      "epoch 118; iter: 0; batch classifier loss: 0.065217; batch adversarial loss: 0.543812\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044521; batch adversarial loss: 0.455365\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064286; batch adversarial loss: 0.457194\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053360; batch adversarial loss: 0.515859\n",
      "epoch 122; iter: 0; batch classifier loss: 0.086203; batch adversarial loss: 0.397252\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041847; batch adversarial loss: 0.443713\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022368; batch adversarial loss: 0.447147\n",
      "epoch 125; iter: 0; batch classifier loss: 0.067783; batch adversarial loss: 0.390322\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039283; batch adversarial loss: 0.466369\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022067; batch adversarial loss: 0.569494\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021264; batch adversarial loss: 0.401118\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026249; batch adversarial loss: 0.423261\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026847; batch adversarial loss: 0.475919\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052506; batch adversarial loss: 0.426513\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029895; batch adversarial loss: 0.434950\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018828; batch adversarial loss: 0.453931\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018903; batch adversarial loss: 0.435852\n",
      "epoch 135; iter: 0; batch classifier loss: 0.015676; batch adversarial loss: 0.430156\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038056; batch adversarial loss: 0.476520\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040554; batch adversarial loss: 0.413496\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019719; batch adversarial loss: 0.431309\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042282; batch adversarial loss: 0.380168\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017106; batch adversarial loss: 0.531147\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036745; batch adversarial loss: 0.374592\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033841; batch adversarial loss: 0.543881\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040192; batch adversarial loss: 0.437618\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030628; batch adversarial loss: 0.481501\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024907; batch adversarial loss: 0.386888\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015870; batch adversarial loss: 0.461411\n",
      "epoch 147; iter: 0; batch classifier loss: 0.054089; batch adversarial loss: 0.481667\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028300; batch adversarial loss: 0.511245\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056163; batch adversarial loss: 0.423851\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013584; batch adversarial loss: 0.423610\n",
      "epoch 151; iter: 0; batch classifier loss: 0.061685; batch adversarial loss: 0.460902\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025802; batch adversarial loss: 0.418297\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030622; batch adversarial loss: 0.388944\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016884; batch adversarial loss: 0.536835\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029173; batch adversarial loss: 0.433704\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042231; batch adversarial loss: 0.513312\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040913; batch adversarial loss: 0.416309\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031913; batch adversarial loss: 0.383976\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043146; batch adversarial loss: 0.406120\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007978; batch adversarial loss: 0.412198\n",
      "epoch 161; iter: 0; batch classifier loss: 0.062966; batch adversarial loss: 0.419366\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015706; batch adversarial loss: 0.539867\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018938; batch adversarial loss: 0.514693\n",
      "epoch 164; iter: 0; batch classifier loss: 0.061995; batch adversarial loss: 0.458485\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034810; batch adversarial loss: 0.575851\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029636; batch adversarial loss: 0.519883\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017448; batch adversarial loss: 0.474095\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019505; batch adversarial loss: 0.486982\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013920; batch adversarial loss: 0.445777\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017903; batch adversarial loss: 0.416632\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011944; batch adversarial loss: 0.483442\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012383; batch adversarial loss: 0.632133\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028221; batch adversarial loss: 0.536659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.017410; batch adversarial loss: 0.444111\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030053; batch adversarial loss: 0.445162\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018780; batch adversarial loss: 0.483878\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017796; batch adversarial loss: 0.450981\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029918; batch adversarial loss: 0.437988\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030895; batch adversarial loss: 0.366917\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026082; batch adversarial loss: 0.516099\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022010; batch adversarial loss: 0.402185\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016400; batch adversarial loss: 0.430042\n",
      "epoch 183; iter: 0; batch classifier loss: 0.048946; batch adversarial loss: 0.447183\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022754; batch adversarial loss: 0.414606\n",
      "epoch 185; iter: 0; batch classifier loss: 0.041953; batch adversarial loss: 0.444936\n",
      "epoch 186; iter: 0; batch classifier loss: 0.063662; batch adversarial loss: 0.417159\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018717; batch adversarial loss: 0.437502\n",
      "epoch 188; iter: 0; batch classifier loss: 0.062166; batch adversarial loss: 0.382687\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017641; batch adversarial loss: 0.497314\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032776; batch adversarial loss: 0.476086\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009034; batch adversarial loss: 0.525395\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010225; batch adversarial loss: 0.488398\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014321; batch adversarial loss: 0.567252\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020177; batch adversarial loss: 0.404797\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010330; batch adversarial loss: 0.482929\n",
      "epoch 196; iter: 0; batch classifier loss: 0.038159; batch adversarial loss: 0.426686\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016483; batch adversarial loss: 0.541508\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018594; batch adversarial loss: 0.516075\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021782; batch adversarial loss: 0.427799\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699490; batch adversarial loss: 0.551367\n",
      "epoch 1; iter: 0; batch classifier loss: 0.366865; batch adversarial loss: 0.592943\n",
      "epoch 2; iter: 0; batch classifier loss: 0.428626; batch adversarial loss: 0.572226\n",
      "epoch 3; iter: 0; batch classifier loss: 0.395242; batch adversarial loss: 0.556355\n",
      "epoch 4; iter: 0; batch classifier loss: 0.419349; batch adversarial loss: 0.551595\n",
      "epoch 5; iter: 0; batch classifier loss: 0.296638; batch adversarial loss: 0.561509\n",
      "epoch 6; iter: 0; batch classifier loss: 0.360413; batch adversarial loss: 0.535657\n",
      "epoch 7; iter: 0; batch classifier loss: 0.329717; batch adversarial loss: 0.556496\n",
      "epoch 8; iter: 0; batch classifier loss: 0.312064; batch adversarial loss: 0.511890\n",
      "epoch 9; iter: 0; batch classifier loss: 0.306191; batch adversarial loss: 0.471651\n",
      "epoch 10; iter: 0; batch classifier loss: 0.298491; batch adversarial loss: 0.400685\n",
      "epoch 11; iter: 0; batch classifier loss: 0.262995; batch adversarial loss: 0.504902\n",
      "epoch 12; iter: 0; batch classifier loss: 0.296908; batch adversarial loss: 0.508905\n",
      "epoch 13; iter: 0; batch classifier loss: 0.338187; batch adversarial loss: 0.544810\n",
      "epoch 14; iter: 0; batch classifier loss: 0.305757; batch adversarial loss: 0.455216\n",
      "epoch 15; iter: 0; batch classifier loss: 0.253145; batch adversarial loss: 0.488933\n",
      "epoch 16; iter: 0; batch classifier loss: 0.391752; batch adversarial loss: 0.484330\n",
      "epoch 17; iter: 0; batch classifier loss: 0.347246; batch adversarial loss: 0.541836\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471772; batch adversarial loss: 0.563295\n",
      "epoch 19; iter: 0; batch classifier loss: 0.583607; batch adversarial loss: 0.549656\n",
      "epoch 20; iter: 0; batch classifier loss: 0.403336; batch adversarial loss: 0.536575\n",
      "epoch 21; iter: 0; batch classifier loss: 0.269537; batch adversarial loss: 0.527755\n",
      "epoch 22; iter: 0; batch classifier loss: 0.228527; batch adversarial loss: 0.471342\n",
      "epoch 23; iter: 0; batch classifier loss: 0.180536; batch adversarial loss: 0.495057\n",
      "epoch 24; iter: 0; batch classifier loss: 0.160386; batch adversarial loss: 0.414800\n",
      "epoch 25; iter: 0; batch classifier loss: 0.160027; batch adversarial loss: 0.485954\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165029; batch adversarial loss: 0.554424\n",
      "epoch 27; iter: 0; batch classifier loss: 0.208148; batch adversarial loss: 0.437347\n",
      "epoch 28; iter: 0; batch classifier loss: 0.131353; batch adversarial loss: 0.537483\n",
      "epoch 29; iter: 0; batch classifier loss: 0.164371; batch adversarial loss: 0.391930\n",
      "epoch 30; iter: 0; batch classifier loss: 0.140764; batch adversarial loss: 0.464198\n",
      "epoch 31; iter: 0; batch classifier loss: 0.107311; batch adversarial loss: 0.516351\n",
      "epoch 32; iter: 0; batch classifier loss: 0.106819; batch adversarial loss: 0.476208\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163652; batch adversarial loss: 0.394599\n",
      "epoch 34; iter: 0; batch classifier loss: 0.123108; batch adversarial loss: 0.510870\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113586; batch adversarial loss: 0.467198\n",
      "epoch 36; iter: 0; batch classifier loss: 0.134282; batch adversarial loss: 0.387283\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111567; batch adversarial loss: 0.519381\n",
      "epoch 38; iter: 0; batch classifier loss: 0.129899; batch adversarial loss: 0.404101\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118812; batch adversarial loss: 0.441329\n",
      "epoch 40; iter: 0; batch classifier loss: 0.089458; batch adversarial loss: 0.487835\n",
      "epoch 41; iter: 0; batch classifier loss: 0.124366; batch adversarial loss: 0.438664\n",
      "epoch 42; iter: 0; batch classifier loss: 0.154609; batch adversarial loss: 0.400938\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112233; batch adversarial loss: 0.436643\n",
      "epoch 44; iter: 0; batch classifier loss: 0.111659; batch adversarial loss: 0.461341\n",
      "epoch 45; iter: 0; batch classifier loss: 0.082239; batch adversarial loss: 0.573308\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104306; batch adversarial loss: 0.397670\n",
      "epoch 47; iter: 0; batch classifier loss: 0.090526; batch adversarial loss: 0.424030\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125784; batch adversarial loss: 0.459535\n",
      "epoch 49; iter: 0; batch classifier loss: 0.092297; batch adversarial loss: 0.539436\n",
      "epoch 50; iter: 0; batch classifier loss: 0.061974; batch adversarial loss: 0.471138\n",
      "epoch 51; iter: 0; batch classifier loss: 0.124686; batch adversarial loss: 0.458749\n",
      "epoch 52; iter: 0; batch classifier loss: 0.117814; batch adversarial loss: 0.467844\n",
      "epoch 53; iter: 0; batch classifier loss: 0.068631; batch adversarial loss: 0.555975\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090580; batch adversarial loss: 0.430361\n",
      "epoch 55; iter: 0; batch classifier loss: 0.121341; batch adversarial loss: 0.426831\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099911; batch adversarial loss: 0.441152\n",
      "epoch 57; iter: 0; batch classifier loss: 0.126780; batch adversarial loss: 0.489172\n",
      "epoch 58; iter: 0; batch classifier loss: 0.092624; batch adversarial loss: 0.416289\n",
      "epoch 59; iter: 0; batch classifier loss: 0.131184; batch adversarial loss: 0.423039\n",
      "epoch 60; iter: 0; batch classifier loss: 0.077969; batch adversarial loss: 0.432010\n",
      "epoch 61; iter: 0; batch classifier loss: 0.086424; batch adversarial loss: 0.474694\n",
      "epoch 62; iter: 0; batch classifier loss: 0.065694; batch adversarial loss: 0.509180\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103491; batch adversarial loss: 0.547582\n",
      "epoch 64; iter: 0; batch classifier loss: 0.055248; batch adversarial loss: 0.447056\n",
      "epoch 65; iter: 0; batch classifier loss: 0.072911; batch adversarial loss: 0.579303\n",
      "epoch 66; iter: 0; batch classifier loss: 0.100581; batch adversarial loss: 0.401418\n",
      "epoch 67; iter: 0; batch classifier loss: 0.113725; batch adversarial loss: 0.383345\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079503; batch adversarial loss: 0.527701\n",
      "epoch 69; iter: 0; batch classifier loss: 0.101475; batch adversarial loss: 0.499572\n",
      "epoch 70; iter: 0; batch classifier loss: 0.100283; batch adversarial loss: 0.464865\n",
      "epoch 71; iter: 0; batch classifier loss: 0.065467; batch adversarial loss: 0.434756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.064414; batch adversarial loss: 0.493009\n",
      "epoch 73; iter: 0; batch classifier loss: 0.070097; batch adversarial loss: 0.385343\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102772; batch adversarial loss: 0.409951\n",
      "epoch 75; iter: 0; batch classifier loss: 0.133969; batch adversarial loss: 0.437725\n",
      "epoch 76; iter: 0; batch classifier loss: 0.095052; batch adversarial loss: 0.401178\n",
      "epoch 77; iter: 0; batch classifier loss: 0.049783; batch adversarial loss: 0.427497\n",
      "epoch 78; iter: 0; batch classifier loss: 0.089090; batch adversarial loss: 0.440844\n",
      "epoch 79; iter: 0; batch classifier loss: 0.131488; batch adversarial loss: 0.511276\n",
      "epoch 80; iter: 0; batch classifier loss: 0.126107; batch adversarial loss: 0.401357\n",
      "epoch 81; iter: 0; batch classifier loss: 0.086750; batch adversarial loss: 0.456959\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062106; batch adversarial loss: 0.414048\n",
      "epoch 83; iter: 0; batch classifier loss: 0.088905; batch adversarial loss: 0.503249\n",
      "epoch 84; iter: 0; batch classifier loss: 0.111273; batch adversarial loss: 0.431677\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088099; batch adversarial loss: 0.431058\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081190; batch adversarial loss: 0.568666\n",
      "epoch 87; iter: 0; batch classifier loss: 0.099714; batch adversarial loss: 0.455908\n",
      "epoch 88; iter: 0; batch classifier loss: 0.060890; batch adversarial loss: 0.470578\n",
      "epoch 89; iter: 0; batch classifier loss: 0.086576; batch adversarial loss: 0.503433\n",
      "epoch 90; iter: 0; batch classifier loss: 0.090345; batch adversarial loss: 0.391353\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062752; batch adversarial loss: 0.450650\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079762; batch adversarial loss: 0.410416\n",
      "epoch 93; iter: 0; batch classifier loss: 0.037436; batch adversarial loss: 0.469698\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046476; batch adversarial loss: 0.386428\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058797; batch adversarial loss: 0.505487\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044571; batch adversarial loss: 0.459571\n",
      "epoch 97; iter: 0; batch classifier loss: 0.045676; batch adversarial loss: 0.477722\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072020; batch adversarial loss: 0.439212\n",
      "epoch 99; iter: 0; batch classifier loss: 0.066924; batch adversarial loss: 0.578583\n",
      "epoch 100; iter: 0; batch classifier loss: 0.071006; batch adversarial loss: 0.489620\n",
      "epoch 101; iter: 0; batch classifier loss: 0.080605; batch adversarial loss: 0.457149\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054794; batch adversarial loss: 0.409028\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057817; batch adversarial loss: 0.525863\n",
      "epoch 104; iter: 0; batch classifier loss: 0.051646; batch adversarial loss: 0.409216\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076827; batch adversarial loss: 0.366017\n",
      "epoch 106; iter: 0; batch classifier loss: 0.111432; batch adversarial loss: 0.499548\n",
      "epoch 107; iter: 0; batch classifier loss: 0.076963; batch adversarial loss: 0.394457\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069955; batch adversarial loss: 0.552660\n",
      "epoch 109; iter: 0; batch classifier loss: 0.075311; batch adversarial loss: 0.593957\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049193; batch adversarial loss: 0.431945\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058579; batch adversarial loss: 0.502948\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051523; batch adversarial loss: 0.427641\n",
      "epoch 113; iter: 0; batch classifier loss: 0.079481; batch adversarial loss: 0.476112\n",
      "epoch 114; iter: 0; batch classifier loss: 0.079066; batch adversarial loss: 0.530350\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056154; batch adversarial loss: 0.502726\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068547; batch adversarial loss: 0.451080\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028982; batch adversarial loss: 0.375344\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053328; batch adversarial loss: 0.459340\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036974; batch adversarial loss: 0.282290\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051734; batch adversarial loss: 0.516106\n",
      "epoch 121; iter: 0; batch classifier loss: 0.097712; batch adversarial loss: 0.450241\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049636; batch adversarial loss: 0.463415\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055427; batch adversarial loss: 0.465939\n",
      "epoch 124; iter: 0; batch classifier loss: 0.045625; batch adversarial loss: 0.438029\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030583; batch adversarial loss: 0.474712\n",
      "epoch 126; iter: 0; batch classifier loss: 0.041692; batch adversarial loss: 0.474948\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025853; batch adversarial loss: 0.521214\n",
      "epoch 128; iter: 0; batch classifier loss: 0.048997; batch adversarial loss: 0.502947\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022599; batch adversarial loss: 0.397329\n",
      "epoch 130; iter: 0; batch classifier loss: 0.077279; batch adversarial loss: 0.441235\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044153; batch adversarial loss: 0.491921\n",
      "epoch 132; iter: 0; batch classifier loss: 0.096809; batch adversarial loss: 0.437630\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034377; batch adversarial loss: 0.464946\n",
      "epoch 134; iter: 0; batch classifier loss: 0.070945; batch adversarial loss: 0.422075\n",
      "epoch 135; iter: 0; batch classifier loss: 0.061654; batch adversarial loss: 0.489475\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032999; batch adversarial loss: 0.504496\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031396; batch adversarial loss: 0.452465\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048926; batch adversarial loss: 0.496274\n",
      "epoch 139; iter: 0; batch classifier loss: 0.073171; batch adversarial loss: 0.398362\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037320; batch adversarial loss: 0.408384\n",
      "epoch 141; iter: 0; batch classifier loss: 0.008864; batch adversarial loss: 0.441747\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048900; batch adversarial loss: 0.486199\n",
      "epoch 143; iter: 0; batch classifier loss: 0.047679; batch adversarial loss: 0.447855\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026805; batch adversarial loss: 0.510281\n",
      "epoch 145; iter: 0; batch classifier loss: 0.058404; batch adversarial loss: 0.430323\n",
      "epoch 146; iter: 0; batch classifier loss: 0.047708; batch adversarial loss: 0.464701\n",
      "epoch 147; iter: 0; batch classifier loss: 0.055685; batch adversarial loss: 0.478809\n",
      "epoch 148; iter: 0; batch classifier loss: 0.051518; batch adversarial loss: 0.414379\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044725; batch adversarial loss: 0.492375\n",
      "epoch 150; iter: 0; batch classifier loss: 0.045760; batch adversarial loss: 0.420319\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016593; batch adversarial loss: 0.462690\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042887; batch adversarial loss: 0.408001\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042688; batch adversarial loss: 0.405888\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028777; batch adversarial loss: 0.331632\n",
      "epoch 155; iter: 0; batch classifier loss: 0.060462; batch adversarial loss: 0.460202\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033728; batch adversarial loss: 0.386239\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046466; batch adversarial loss: 0.435481\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015360; batch adversarial loss: 0.534927\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024592; batch adversarial loss: 0.482461\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023785; batch adversarial loss: 0.368759\n",
      "epoch 161; iter: 0; batch classifier loss: 0.006471; batch adversarial loss: 0.478157\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021449; batch adversarial loss: 0.493585\n",
      "epoch 163; iter: 0; batch classifier loss: 0.041309; batch adversarial loss: 0.502396\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036411; batch adversarial loss: 0.477430\n",
      "epoch 165; iter: 0; batch classifier loss: 0.070842; batch adversarial loss: 0.413303\n",
      "epoch 166; iter: 0; batch classifier loss: 0.042373; batch adversarial loss: 0.451975\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029365; batch adversarial loss: 0.467395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.044126; batch adversarial loss: 0.429010\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013906; batch adversarial loss: 0.480865\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032413; batch adversarial loss: 0.384727\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029452; batch adversarial loss: 0.332076\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032888; batch adversarial loss: 0.515013\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033498; batch adversarial loss: 0.444119\n",
      "epoch 174; iter: 0; batch classifier loss: 0.063387; batch adversarial loss: 0.358265\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020169; batch adversarial loss: 0.433134\n",
      "epoch 176; iter: 0; batch classifier loss: 0.050672; batch adversarial loss: 0.385436\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020823; batch adversarial loss: 0.471437\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021661; batch adversarial loss: 0.389612\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011987; batch adversarial loss: 0.602302\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039614; batch adversarial loss: 0.541462\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016182; batch adversarial loss: 0.444819\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027959; batch adversarial loss: 0.406027\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015877; batch adversarial loss: 0.395255\n",
      "epoch 184; iter: 0; batch classifier loss: 0.046264; batch adversarial loss: 0.453395\n",
      "epoch 185; iter: 0; batch classifier loss: 0.041498; batch adversarial loss: 0.353960\n",
      "epoch 186; iter: 0; batch classifier loss: 0.039383; batch adversarial loss: 0.419899\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033154; batch adversarial loss: 0.382714\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023065; batch adversarial loss: 0.449336\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021982; batch adversarial loss: 0.355817\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022867; batch adversarial loss: 0.384249\n",
      "epoch 191; iter: 0; batch classifier loss: 0.035482; batch adversarial loss: 0.448146\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013679; batch adversarial loss: 0.465204\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024458; batch adversarial loss: 0.411500\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026277; batch adversarial loss: 0.506529\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019749; batch adversarial loss: 0.546188\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008572; batch adversarial loss: 0.453296\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006390; batch adversarial loss: 0.444852\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020148; batch adversarial loss: 0.446459\n",
      "epoch 199; iter: 0; batch classifier loss: 0.048216; batch adversarial loss: 0.412752\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707220; batch adversarial loss: 0.787162\n",
      "epoch 1; iter: 0; batch classifier loss: 0.362232; batch adversarial loss: 0.737386\n",
      "epoch 2; iter: 0; batch classifier loss: 0.397220; batch adversarial loss: 0.684144\n",
      "epoch 3; iter: 0; batch classifier loss: 0.334862; batch adversarial loss: 0.652057\n",
      "epoch 4; iter: 0; batch classifier loss: 0.285166; batch adversarial loss: 0.604422\n",
      "epoch 5; iter: 0; batch classifier loss: 0.348639; batch adversarial loss: 0.587243\n",
      "epoch 6; iter: 0; batch classifier loss: 0.247203; batch adversarial loss: 0.556512\n",
      "epoch 7; iter: 0; batch classifier loss: 0.260811; batch adversarial loss: 0.533618\n",
      "epoch 8; iter: 0; batch classifier loss: 0.205340; batch adversarial loss: 0.526643\n",
      "epoch 9; iter: 0; batch classifier loss: 0.362487; batch adversarial loss: 0.528515\n",
      "epoch 10; iter: 0; batch classifier loss: 0.288430; batch adversarial loss: 0.544697\n",
      "epoch 11; iter: 0; batch classifier loss: 0.237829; batch adversarial loss: 0.510306\n",
      "epoch 12; iter: 0; batch classifier loss: 0.207696; batch adversarial loss: 0.538554\n",
      "epoch 13; iter: 0; batch classifier loss: 0.170697; batch adversarial loss: 0.435440\n",
      "epoch 14; iter: 0; batch classifier loss: 0.262119; batch adversarial loss: 0.439008\n",
      "epoch 15; iter: 0; batch classifier loss: 0.230138; batch adversarial loss: 0.460916\n",
      "epoch 16; iter: 0; batch classifier loss: 0.332127; batch adversarial loss: 0.537214\n",
      "epoch 17; iter: 0; batch classifier loss: 0.396466; batch adversarial loss: 0.512149\n",
      "epoch 18; iter: 0; batch classifier loss: 0.491759; batch adversarial loss: 0.552632\n",
      "epoch 19; iter: 0; batch classifier loss: 0.406645; batch adversarial loss: 0.507287\n",
      "epoch 20; iter: 0; batch classifier loss: 0.381600; batch adversarial loss: 0.562933\n",
      "epoch 21; iter: 0; batch classifier loss: 0.263085; batch adversarial loss: 0.456812\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206422; batch adversarial loss: 0.482208\n",
      "epoch 23; iter: 0; batch classifier loss: 0.261094; batch adversarial loss: 0.443529\n",
      "epoch 24; iter: 0; batch classifier loss: 0.198976; batch adversarial loss: 0.504796\n",
      "epoch 25; iter: 0; batch classifier loss: 0.196059; batch adversarial loss: 0.435114\n",
      "epoch 26; iter: 0; batch classifier loss: 0.191624; batch adversarial loss: 0.458990\n",
      "epoch 27; iter: 0; batch classifier loss: 0.201554; batch adversarial loss: 0.465373\n",
      "epoch 28; iter: 0; batch classifier loss: 0.191675; batch adversarial loss: 0.460112\n",
      "epoch 29; iter: 0; batch classifier loss: 0.276347; batch adversarial loss: 0.428306\n",
      "epoch 30; iter: 0; batch classifier loss: 0.187290; batch adversarial loss: 0.427841\n",
      "epoch 31; iter: 0; batch classifier loss: 0.222931; batch adversarial loss: 0.385240\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165024; batch adversarial loss: 0.469778\n",
      "epoch 33; iter: 0; batch classifier loss: 0.131160; batch adversarial loss: 0.597676\n",
      "epoch 34; iter: 0; batch classifier loss: 0.153813; batch adversarial loss: 0.489729\n",
      "epoch 35; iter: 0; batch classifier loss: 0.184672; batch adversarial loss: 0.460820\n",
      "epoch 36; iter: 0; batch classifier loss: 0.175688; batch adversarial loss: 0.442835\n",
      "epoch 37; iter: 0; batch classifier loss: 0.125883; batch adversarial loss: 0.414732\n",
      "epoch 38; iter: 0; batch classifier loss: 0.150091; batch adversarial loss: 0.387636\n",
      "epoch 39; iter: 0; batch classifier loss: 0.120980; batch adversarial loss: 0.450998\n",
      "epoch 40; iter: 0; batch classifier loss: 0.126168; batch adversarial loss: 0.451074\n",
      "epoch 41; iter: 0; batch classifier loss: 0.140781; batch adversarial loss: 0.440348\n",
      "epoch 42; iter: 0; batch classifier loss: 0.166404; batch adversarial loss: 0.441449\n",
      "epoch 43; iter: 0; batch classifier loss: 0.138281; batch adversarial loss: 0.381558\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106712; batch adversarial loss: 0.462937\n",
      "epoch 45; iter: 0; batch classifier loss: 0.145867; batch adversarial loss: 0.348534\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126020; batch adversarial loss: 0.497895\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106935; batch adversarial loss: 0.550280\n",
      "epoch 48; iter: 0; batch classifier loss: 0.089857; batch adversarial loss: 0.476983\n",
      "epoch 49; iter: 0; batch classifier loss: 0.087297; batch adversarial loss: 0.398370\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111503; batch adversarial loss: 0.495319\n",
      "epoch 51; iter: 0; batch classifier loss: 0.084712; batch adversarial loss: 0.380112\n",
      "epoch 52; iter: 0; batch classifier loss: 0.166806; batch adversarial loss: 0.369481\n",
      "epoch 53; iter: 0; batch classifier loss: 0.177408; batch adversarial loss: 0.369208\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108219; batch adversarial loss: 0.387051\n",
      "epoch 55; iter: 0; batch classifier loss: 0.133212; batch adversarial loss: 0.399766\n",
      "epoch 56; iter: 0; batch classifier loss: 0.097278; batch adversarial loss: 0.458865\n",
      "epoch 57; iter: 0; batch classifier loss: 0.131944; batch adversarial loss: 0.417988\n",
      "epoch 58; iter: 0; batch classifier loss: 0.111326; batch adversarial loss: 0.457309\n",
      "epoch 59; iter: 0; batch classifier loss: 0.120249; batch adversarial loss: 0.368278\n",
      "epoch 60; iter: 0; batch classifier loss: 0.082829; batch adversarial loss: 0.474213\n",
      "epoch 61; iter: 0; batch classifier loss: 0.120486; batch adversarial loss: 0.515358\n",
      "epoch 62; iter: 0; batch classifier loss: 0.121802; batch adversarial loss: 0.515019\n",
      "epoch 63; iter: 0; batch classifier loss: 0.110175; batch adversarial loss: 0.367880\n",
      "epoch 64; iter: 0; batch classifier loss: 0.105988; batch adversarial loss: 0.534660\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079011; batch adversarial loss: 0.555116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.100834; batch adversarial loss: 0.452923\n",
      "epoch 67; iter: 0; batch classifier loss: 0.132089; batch adversarial loss: 0.409888\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081283; batch adversarial loss: 0.375435\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076692; batch adversarial loss: 0.450315\n",
      "epoch 70; iter: 0; batch classifier loss: 0.043035; batch adversarial loss: 0.403120\n",
      "epoch 71; iter: 0; batch classifier loss: 0.098677; batch adversarial loss: 0.467164\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087087; batch adversarial loss: 0.404537\n",
      "epoch 73; iter: 0; batch classifier loss: 0.086803; batch adversarial loss: 0.484922\n",
      "epoch 74; iter: 0; batch classifier loss: 0.087534; batch adversarial loss: 0.477176\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059108; batch adversarial loss: 0.460651\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065666; batch adversarial loss: 0.418648\n",
      "epoch 77; iter: 0; batch classifier loss: 0.058700; batch adversarial loss: 0.439936\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073964; batch adversarial loss: 0.518342\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072973; batch adversarial loss: 0.430053\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067625; batch adversarial loss: 0.452544\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079298; batch adversarial loss: 0.460919\n",
      "epoch 82; iter: 0; batch classifier loss: 0.051745; batch adversarial loss: 0.572893\n",
      "epoch 83; iter: 0; batch classifier loss: 0.051060; batch adversarial loss: 0.478293\n",
      "epoch 84; iter: 0; batch classifier loss: 0.061394; batch adversarial loss: 0.378233\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059438; batch adversarial loss: 0.407288\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062214; batch adversarial loss: 0.515862\n",
      "epoch 87; iter: 0; batch classifier loss: 0.038094; batch adversarial loss: 0.568411\n",
      "epoch 88; iter: 0; batch classifier loss: 0.082579; batch adversarial loss: 0.383584\n",
      "epoch 89; iter: 0; batch classifier loss: 0.061393; batch adversarial loss: 0.442769\n",
      "epoch 90; iter: 0; batch classifier loss: 0.030308; batch adversarial loss: 0.566806\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060734; batch adversarial loss: 0.475436\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048402; batch adversarial loss: 0.444354\n",
      "epoch 93; iter: 0; batch classifier loss: 0.019202; batch adversarial loss: 0.411321\n",
      "epoch 94; iter: 0; batch classifier loss: 0.071418; batch adversarial loss: 0.488069\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058871; batch adversarial loss: 0.403988\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056560; batch adversarial loss: 0.396740\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072633; batch adversarial loss: 0.521933\n",
      "epoch 98; iter: 0; batch classifier loss: 0.060997; batch adversarial loss: 0.290372\n",
      "epoch 99; iter: 0; batch classifier loss: 0.075373; batch adversarial loss: 0.428206\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051554; batch adversarial loss: 0.389635\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041021; batch adversarial loss: 0.402779\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063926; batch adversarial loss: 0.460128\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061677; batch adversarial loss: 0.474866\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063261; batch adversarial loss: 0.351223\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038282; batch adversarial loss: 0.447098\n",
      "epoch 106; iter: 0; batch classifier loss: 0.015562; batch adversarial loss: 0.445860\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039944; batch adversarial loss: 0.439367\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063541; batch adversarial loss: 0.481878\n",
      "epoch 109; iter: 0; batch classifier loss: 0.028112; batch adversarial loss: 0.421243\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025665; batch adversarial loss: 0.441724\n",
      "epoch 111; iter: 0; batch classifier loss: 0.022707; batch adversarial loss: 0.388359\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051928; batch adversarial loss: 0.516859\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050620; batch adversarial loss: 0.399855\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041730; batch adversarial loss: 0.350251\n",
      "epoch 115; iter: 0; batch classifier loss: 0.085697; batch adversarial loss: 0.506334\n",
      "epoch 116; iter: 0; batch classifier loss: 0.061153; batch adversarial loss: 0.494059\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028021; batch adversarial loss: 0.451139\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035504; batch adversarial loss: 0.433998\n",
      "epoch 119; iter: 0; batch classifier loss: 0.075071; batch adversarial loss: 0.527983\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038171; batch adversarial loss: 0.456988\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036190; batch adversarial loss: 0.454289\n",
      "epoch 122; iter: 0; batch classifier loss: 0.064594; batch adversarial loss: 0.488401\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020291; batch adversarial loss: 0.397378\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033049; batch adversarial loss: 0.460976\n",
      "epoch 125; iter: 0; batch classifier loss: 0.013037; batch adversarial loss: 0.474504\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029251; batch adversarial loss: 0.456285\n",
      "epoch 127; iter: 0; batch classifier loss: 0.008263; batch adversarial loss: 0.459735\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053177; batch adversarial loss: 0.497572\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032638; batch adversarial loss: 0.405439\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023298; batch adversarial loss: 0.504420\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028359; batch adversarial loss: 0.402880\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034490; batch adversarial loss: 0.384275\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053340; batch adversarial loss: 0.492673\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033245; batch adversarial loss: 0.350774\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024928; batch adversarial loss: 0.406370\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025645; batch adversarial loss: 0.512307\n",
      "epoch 137; iter: 0; batch classifier loss: 0.062566; batch adversarial loss: 0.523792\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027190; batch adversarial loss: 0.390643\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025219; batch adversarial loss: 0.367465\n",
      "epoch 140; iter: 0; batch classifier loss: 0.074908; batch adversarial loss: 0.420311\n",
      "epoch 141; iter: 0; batch classifier loss: 0.062127; batch adversarial loss: 0.461068\n",
      "epoch 142; iter: 0; batch classifier loss: 0.010059; batch adversarial loss: 0.414623\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032486; batch adversarial loss: 0.440713\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012167; batch adversarial loss: 0.457523\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011944; batch adversarial loss: 0.387850\n",
      "epoch 146; iter: 0; batch classifier loss: 0.043990; batch adversarial loss: 0.439090\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024430; batch adversarial loss: 0.425525\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036994; batch adversarial loss: 0.446107\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024517; batch adversarial loss: 0.460842\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020178; batch adversarial loss: 0.324842\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014661; batch adversarial loss: 0.328414\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014870; batch adversarial loss: 0.459741\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024806; batch adversarial loss: 0.436486\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020614; batch adversarial loss: 0.457919\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032906; batch adversarial loss: 0.467865\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015241; batch adversarial loss: 0.428892\n",
      "epoch 157; iter: 0; batch classifier loss: 0.070682; batch adversarial loss: 0.420046\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011100; batch adversarial loss: 0.375298\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012928; batch adversarial loss: 0.441247\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045024; batch adversarial loss: 0.472950\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020947; batch adversarial loss: 0.362051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.028574; batch adversarial loss: 0.411370\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019673; batch adversarial loss: 0.417967\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012346; batch adversarial loss: 0.467789\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022923; batch adversarial loss: 0.499424\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012767; batch adversarial loss: 0.532461\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019512; batch adversarial loss: 0.405386\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010154; batch adversarial loss: 0.374481\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036381; batch adversarial loss: 0.472533\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019226; batch adversarial loss: 0.429472\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021250; batch adversarial loss: 0.475527\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018737; batch adversarial loss: 0.402399\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029827; batch adversarial loss: 0.474914\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026950; batch adversarial loss: 0.544433\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040147; batch adversarial loss: 0.376570\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028063; batch adversarial loss: 0.405992\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036085; batch adversarial loss: 0.474921\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039823; batch adversarial loss: 0.381936\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023427; batch adversarial loss: 0.457417\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026075; batch adversarial loss: 0.462946\n",
      "epoch 181; iter: 0; batch classifier loss: 0.095621; batch adversarial loss: 0.444735\n",
      "epoch 182; iter: 0; batch classifier loss: 0.040140; batch adversarial loss: 0.479401\n",
      "epoch 183; iter: 0; batch classifier loss: 0.044195; batch adversarial loss: 0.461664\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013762; batch adversarial loss: 0.477792\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035256; batch adversarial loss: 0.460809\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030328; batch adversarial loss: 0.437995\n",
      "epoch 187; iter: 0; batch classifier loss: 0.045801; batch adversarial loss: 0.431265\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009616; batch adversarial loss: 0.471736\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034923; batch adversarial loss: 0.496844\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007928; batch adversarial loss: 0.441511\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009563; batch adversarial loss: 0.520700\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006873; batch adversarial loss: 0.444832\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013635; batch adversarial loss: 0.383790\n",
      "epoch 194; iter: 0; batch classifier loss: 0.053109; batch adversarial loss: 0.501346\n",
      "epoch 195; iter: 0; batch classifier loss: 0.042940; batch adversarial loss: 0.430299\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011501; batch adversarial loss: 0.429623\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008822; batch adversarial loss: 0.565613\n",
      "epoch 198; iter: 0; batch classifier loss: 0.056120; batch adversarial loss: 0.490208\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019933; batch adversarial loss: 0.376606\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697306; batch adversarial loss: 0.597521\n",
      "epoch 1; iter: 0; batch classifier loss: 0.425524; batch adversarial loss: 0.627781\n",
      "epoch 2; iter: 0; batch classifier loss: 0.329386; batch adversarial loss: 0.602340\n",
      "epoch 3; iter: 0; batch classifier loss: 0.237041; batch adversarial loss: 0.584046\n",
      "epoch 4; iter: 0; batch classifier loss: 0.289271; batch adversarial loss: 0.578754\n",
      "epoch 5; iter: 0; batch classifier loss: 0.347987; batch adversarial loss: 0.523628\n",
      "epoch 6; iter: 0; batch classifier loss: 0.281300; batch adversarial loss: 0.568710\n",
      "epoch 7; iter: 0; batch classifier loss: 0.291291; batch adversarial loss: 0.582922\n",
      "epoch 8; iter: 0; batch classifier loss: 0.247439; batch adversarial loss: 0.554480\n",
      "epoch 9; iter: 0; batch classifier loss: 0.312066; batch adversarial loss: 0.526341\n",
      "epoch 10; iter: 0; batch classifier loss: 0.289666; batch adversarial loss: 0.486956\n",
      "epoch 11; iter: 0; batch classifier loss: 0.276615; batch adversarial loss: 0.473400\n",
      "epoch 12; iter: 0; batch classifier loss: 0.213555; batch adversarial loss: 0.454780\n",
      "epoch 13; iter: 0; batch classifier loss: 0.156776; batch adversarial loss: 0.534260\n",
      "epoch 14; iter: 0; batch classifier loss: 0.208300; batch adversarial loss: 0.508928\n",
      "epoch 15; iter: 0; batch classifier loss: 0.171980; batch adversarial loss: 0.630118\n",
      "epoch 16; iter: 0; batch classifier loss: 0.208692; batch adversarial loss: 0.520439\n",
      "epoch 17; iter: 0; batch classifier loss: 0.186626; batch adversarial loss: 0.509704\n",
      "epoch 18; iter: 0; batch classifier loss: 0.213876; batch adversarial loss: 0.485213\n",
      "epoch 19; iter: 0; batch classifier loss: 0.192309; batch adversarial loss: 0.532770\n",
      "epoch 20; iter: 0; batch classifier loss: 0.198088; batch adversarial loss: 0.619750\n",
      "epoch 21; iter: 0; batch classifier loss: 0.220630; batch adversarial loss: 0.493077\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206806; batch adversarial loss: 0.490856\n",
      "epoch 23; iter: 0; batch classifier loss: 0.320177; batch adversarial loss: 0.507523\n",
      "epoch 24; iter: 0; batch classifier loss: 0.333552; batch adversarial loss: 0.564858\n",
      "epoch 25; iter: 0; batch classifier loss: 0.225718; batch adversarial loss: 0.497884\n",
      "epoch 26; iter: 0; batch classifier loss: 0.232268; batch adversarial loss: 0.439064\n",
      "epoch 27; iter: 0; batch classifier loss: 0.276656; batch adversarial loss: 0.473438\n",
      "epoch 28; iter: 0; batch classifier loss: 0.345201; batch adversarial loss: 0.465562\n",
      "epoch 29; iter: 0; batch classifier loss: 0.237675; batch adversarial loss: 0.521860\n",
      "epoch 30; iter: 0; batch classifier loss: 0.171647; batch adversarial loss: 0.496842\n",
      "epoch 31; iter: 0; batch classifier loss: 0.106758; batch adversarial loss: 0.449806\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172344; batch adversarial loss: 0.445411\n",
      "epoch 33; iter: 0; batch classifier loss: 0.137984; batch adversarial loss: 0.514419\n",
      "epoch 34; iter: 0; batch classifier loss: 0.109441; batch adversarial loss: 0.471021\n",
      "epoch 35; iter: 0; batch classifier loss: 0.098497; batch adversarial loss: 0.485162\n",
      "epoch 36; iter: 0; batch classifier loss: 0.069515; batch adversarial loss: 0.467304\n",
      "epoch 37; iter: 0; batch classifier loss: 0.095171; batch adversarial loss: 0.505885\n",
      "epoch 38; iter: 0; batch classifier loss: 0.123824; batch adversarial loss: 0.428927\n",
      "epoch 39; iter: 0; batch classifier loss: 0.098854; batch adversarial loss: 0.403320\n",
      "epoch 40; iter: 0; batch classifier loss: 0.121336; batch adversarial loss: 0.429394\n",
      "epoch 41; iter: 0; batch classifier loss: 0.085113; batch adversarial loss: 0.502543\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096051; batch adversarial loss: 0.445678\n",
      "epoch 43; iter: 0; batch classifier loss: 0.120076; batch adversarial loss: 0.386073\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105602; batch adversarial loss: 0.539937\n",
      "epoch 45; iter: 0; batch classifier loss: 0.156941; batch adversarial loss: 0.482439\n",
      "epoch 46; iter: 0; batch classifier loss: 0.109411; batch adversarial loss: 0.408670\n",
      "epoch 47; iter: 0; batch classifier loss: 0.120866; batch adversarial loss: 0.490134\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081042; batch adversarial loss: 0.479873\n",
      "epoch 49; iter: 0; batch classifier loss: 0.128517; batch adversarial loss: 0.463545\n",
      "epoch 50; iter: 0; batch classifier loss: 0.075406; batch adversarial loss: 0.433600\n",
      "epoch 51; iter: 0; batch classifier loss: 0.067485; batch adversarial loss: 0.433425\n",
      "epoch 52; iter: 0; batch classifier loss: 0.084955; batch adversarial loss: 0.550265\n",
      "epoch 53; iter: 0; batch classifier loss: 0.180663; batch adversarial loss: 0.411112\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074856; batch adversarial loss: 0.503258\n",
      "epoch 55; iter: 0; batch classifier loss: 0.062737; batch adversarial loss: 0.438410\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081991; batch adversarial loss: 0.472431\n",
      "epoch 57; iter: 0; batch classifier loss: 0.113692; batch adversarial loss: 0.450548\n",
      "epoch 58; iter: 0; batch classifier loss: 0.079949; batch adversarial loss: 0.398777\n",
      "epoch 59; iter: 0; batch classifier loss: 0.110861; batch adversarial loss: 0.459102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.107698; batch adversarial loss: 0.427880\n",
      "epoch 61; iter: 0; batch classifier loss: 0.052824; batch adversarial loss: 0.566186\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084658; batch adversarial loss: 0.361375\n",
      "epoch 63; iter: 0; batch classifier loss: 0.050266; batch adversarial loss: 0.497073\n",
      "epoch 64; iter: 0; batch classifier loss: 0.113165; batch adversarial loss: 0.464708\n",
      "epoch 65; iter: 0; batch classifier loss: 0.058444; batch adversarial loss: 0.465874\n",
      "epoch 66; iter: 0; batch classifier loss: 0.103988; batch adversarial loss: 0.429431\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079970; batch adversarial loss: 0.445809\n",
      "epoch 68; iter: 0; batch classifier loss: 0.113618; batch adversarial loss: 0.416715\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064562; batch adversarial loss: 0.451903\n",
      "epoch 70; iter: 0; batch classifier loss: 0.038556; batch adversarial loss: 0.561623\n",
      "epoch 71; iter: 0; batch classifier loss: 0.066458; batch adversarial loss: 0.544461\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087042; batch adversarial loss: 0.438024\n",
      "epoch 73; iter: 0; batch classifier loss: 0.071138; batch adversarial loss: 0.500033\n",
      "epoch 74; iter: 0; batch classifier loss: 0.108713; batch adversarial loss: 0.479951\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076706; batch adversarial loss: 0.424221\n",
      "epoch 76; iter: 0; batch classifier loss: 0.074735; batch adversarial loss: 0.391239\n",
      "epoch 77; iter: 0; batch classifier loss: 0.078163; batch adversarial loss: 0.398274\n",
      "epoch 78; iter: 0; batch classifier loss: 0.135073; batch adversarial loss: 0.442131\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053793; batch adversarial loss: 0.483133\n",
      "epoch 80; iter: 0; batch classifier loss: 0.091101; batch adversarial loss: 0.466839\n",
      "epoch 81; iter: 0; batch classifier loss: 0.082406; batch adversarial loss: 0.476644\n",
      "epoch 82; iter: 0; batch classifier loss: 0.092000; batch adversarial loss: 0.443179\n",
      "epoch 83; iter: 0; batch classifier loss: 0.043744; batch adversarial loss: 0.425627\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047758; batch adversarial loss: 0.435725\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061998; batch adversarial loss: 0.513841\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054548; batch adversarial loss: 0.489452\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062423; batch adversarial loss: 0.531814\n",
      "epoch 88; iter: 0; batch classifier loss: 0.084795; batch adversarial loss: 0.555701\n",
      "epoch 89; iter: 0; batch classifier loss: 0.071353; batch adversarial loss: 0.407594\n",
      "epoch 90; iter: 0; batch classifier loss: 0.081774; batch adversarial loss: 0.396626\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064794; batch adversarial loss: 0.379370\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055042; batch adversarial loss: 0.483289\n",
      "epoch 93; iter: 0; batch classifier loss: 0.042163; batch adversarial loss: 0.599660\n",
      "epoch 94; iter: 0; batch classifier loss: 0.057237; batch adversarial loss: 0.460197\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063657; batch adversarial loss: 0.482596\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063787; batch adversarial loss: 0.448784\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056816; batch adversarial loss: 0.508074\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063723; batch adversarial loss: 0.539638\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046940; batch adversarial loss: 0.399022\n",
      "epoch 100; iter: 0; batch classifier loss: 0.086511; batch adversarial loss: 0.443070\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041132; batch adversarial loss: 0.507796\n",
      "epoch 102; iter: 0; batch classifier loss: 0.094858; batch adversarial loss: 0.383830\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045405; batch adversarial loss: 0.458276\n",
      "epoch 104; iter: 0; batch classifier loss: 0.085499; batch adversarial loss: 0.424316\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049618; batch adversarial loss: 0.513591\n",
      "epoch 106; iter: 0; batch classifier loss: 0.038828; batch adversarial loss: 0.540530\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032620; batch adversarial loss: 0.384390\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041322; batch adversarial loss: 0.505371\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070410; batch adversarial loss: 0.490413\n",
      "epoch 110; iter: 0; batch classifier loss: 0.022611; batch adversarial loss: 0.467789\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054893; batch adversarial loss: 0.433170\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043878; batch adversarial loss: 0.411698\n",
      "epoch 113; iter: 0; batch classifier loss: 0.068183; batch adversarial loss: 0.419057\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056894; batch adversarial loss: 0.462144\n",
      "epoch 115; iter: 0; batch classifier loss: 0.026105; batch adversarial loss: 0.363363\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052589; batch adversarial loss: 0.456078\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041723; batch adversarial loss: 0.399016\n",
      "epoch 118; iter: 0; batch classifier loss: 0.023761; batch adversarial loss: 0.463722\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051485; batch adversarial loss: 0.446268\n",
      "epoch 120; iter: 0; batch classifier loss: 0.026611; batch adversarial loss: 0.524659\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033346; batch adversarial loss: 0.510794\n",
      "epoch 122; iter: 0; batch classifier loss: 0.058260; batch adversarial loss: 0.523158\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031987; batch adversarial loss: 0.392420\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046387; batch adversarial loss: 0.442781\n",
      "epoch 125; iter: 0; batch classifier loss: 0.108477; batch adversarial loss: 0.370889\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043285; batch adversarial loss: 0.434780\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039616; batch adversarial loss: 0.408542\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055312; batch adversarial loss: 0.442042\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039191; batch adversarial loss: 0.480250\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026347; batch adversarial loss: 0.494786\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027908; batch adversarial loss: 0.394674\n",
      "epoch 132; iter: 0; batch classifier loss: 0.063615; batch adversarial loss: 0.474934\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028951; batch adversarial loss: 0.488808\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034699; batch adversarial loss: 0.434939\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050944; batch adversarial loss: 0.415529\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037740; batch adversarial loss: 0.485076\n",
      "epoch 137; iter: 0; batch classifier loss: 0.061298; batch adversarial loss: 0.532961\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039576; batch adversarial loss: 0.434466\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050419; batch adversarial loss: 0.465845\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033111; batch adversarial loss: 0.392861\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049936; batch adversarial loss: 0.559938\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033226; batch adversarial loss: 0.519531\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040373; batch adversarial loss: 0.508909\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041282; batch adversarial loss: 0.475538\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027444; batch adversarial loss: 0.457058\n",
      "epoch 146; iter: 0; batch classifier loss: 0.073476; batch adversarial loss: 0.447261\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039696; batch adversarial loss: 0.372124\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033562; batch adversarial loss: 0.452106\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039534; batch adversarial loss: 0.442583\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018950; batch adversarial loss: 0.408996\n",
      "epoch 151; iter: 0; batch classifier loss: 0.046404; batch adversarial loss: 0.458213\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018430; batch adversarial loss: 0.549834\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022329; batch adversarial loss: 0.476770\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020770; batch adversarial loss: 0.469441\n",
      "epoch 155; iter: 0; batch classifier loss: 0.055336; batch adversarial loss: 0.395115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.020968; batch adversarial loss: 0.485804\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033739; batch adversarial loss: 0.448675\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048402; batch adversarial loss: 0.446034\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025365; batch adversarial loss: 0.436510\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037906; batch adversarial loss: 0.515575\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022854; batch adversarial loss: 0.410704\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022455; batch adversarial loss: 0.492431\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020372; batch adversarial loss: 0.477875\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033945; batch adversarial loss: 0.437056\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012471; batch adversarial loss: 0.481868\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035348; batch adversarial loss: 0.444012\n",
      "epoch 167; iter: 0; batch classifier loss: 0.046448; batch adversarial loss: 0.467055\n",
      "epoch 168; iter: 0; batch classifier loss: 0.053247; batch adversarial loss: 0.551752\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012139; batch adversarial loss: 0.512305\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030362; batch adversarial loss: 0.501711\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036799; batch adversarial loss: 0.419013\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014299; batch adversarial loss: 0.433317\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034368; batch adversarial loss: 0.509877\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009394; batch adversarial loss: 0.527252\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017216; batch adversarial loss: 0.439804\n",
      "epoch 176; iter: 0; batch classifier loss: 0.006855; batch adversarial loss: 0.479164\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026591; batch adversarial loss: 0.530881\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025892; batch adversarial loss: 0.485776\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037227; batch adversarial loss: 0.462847\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012759; batch adversarial loss: 0.496429\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029042; batch adversarial loss: 0.445689\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012522; batch adversarial loss: 0.449687\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042962; batch adversarial loss: 0.396442\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014097; batch adversarial loss: 0.422824\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011422; batch adversarial loss: 0.548142\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037413; batch adversarial loss: 0.336680\n",
      "epoch 187; iter: 0; batch classifier loss: 0.043254; batch adversarial loss: 0.535187\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024167; batch adversarial loss: 0.493870\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031742; batch adversarial loss: 0.433074\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015017; batch adversarial loss: 0.455202\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020838; batch adversarial loss: 0.470121\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013331; batch adversarial loss: 0.439206\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016678; batch adversarial loss: 0.503885\n",
      "epoch 194; iter: 0; batch classifier loss: 0.040432; batch adversarial loss: 0.436224\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023808; batch adversarial loss: 0.462728\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012060; batch adversarial loss: 0.381119\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031999; batch adversarial loss: 0.385231\n",
      "epoch 198; iter: 0; batch classifier loss: 0.050773; batch adversarial loss: 0.495651\n",
      "epoch 199; iter: 0; batch classifier loss: 0.056513; batch adversarial loss: 0.433928\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692222; batch adversarial loss: 0.587462\n",
      "epoch 1; iter: 0; batch classifier loss: 0.502622; batch adversarial loss: 0.641650\n",
      "epoch 2; iter: 0; batch classifier loss: 0.413797; batch adversarial loss: 0.638695\n",
      "epoch 3; iter: 0; batch classifier loss: 0.395912; batch adversarial loss: 0.563151\n",
      "epoch 4; iter: 0; batch classifier loss: 0.367972; batch adversarial loss: 0.622469\n",
      "epoch 5; iter: 0; batch classifier loss: 0.320056; batch adversarial loss: 0.567699\n",
      "epoch 6; iter: 0; batch classifier loss: 0.345924; batch adversarial loss: 0.595735\n",
      "epoch 7; iter: 0; batch classifier loss: 0.301573; batch adversarial loss: 0.582216\n",
      "epoch 8; iter: 0; batch classifier loss: 0.360376; batch adversarial loss: 0.538937\n",
      "epoch 9; iter: 0; batch classifier loss: 0.286958; batch adversarial loss: 0.547296\n",
      "epoch 10; iter: 0; batch classifier loss: 0.268553; batch adversarial loss: 0.540370\n",
      "epoch 11; iter: 0; batch classifier loss: 0.253048; batch adversarial loss: 0.536935\n",
      "epoch 12; iter: 0; batch classifier loss: 0.304162; batch adversarial loss: 0.561264\n",
      "epoch 13; iter: 0; batch classifier loss: 0.297021; batch adversarial loss: 0.514771\n",
      "epoch 14; iter: 0; batch classifier loss: 0.266512; batch adversarial loss: 0.533071\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307818; batch adversarial loss: 0.554850\n",
      "epoch 16; iter: 0; batch classifier loss: 0.218298; batch adversarial loss: 0.489553\n",
      "epoch 17; iter: 0; batch classifier loss: 0.203236; batch adversarial loss: 0.536888\n",
      "epoch 18; iter: 0; batch classifier loss: 0.239816; batch adversarial loss: 0.455828\n",
      "epoch 19; iter: 0; batch classifier loss: 0.233129; batch adversarial loss: 0.413428\n",
      "epoch 20; iter: 0; batch classifier loss: 0.137728; batch adversarial loss: 0.468505\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234492; batch adversarial loss: 0.490472\n",
      "epoch 22; iter: 0; batch classifier loss: 0.170650; batch adversarial loss: 0.461444\n",
      "epoch 23; iter: 0; batch classifier loss: 0.139345; batch adversarial loss: 0.525253\n",
      "epoch 24; iter: 0; batch classifier loss: 0.160818; batch adversarial loss: 0.535983\n",
      "epoch 25; iter: 0; batch classifier loss: 0.171335; batch adversarial loss: 0.415195\n",
      "epoch 26; iter: 0; batch classifier loss: 0.222050; batch adversarial loss: 0.465251\n",
      "epoch 27; iter: 0; batch classifier loss: 0.130425; batch adversarial loss: 0.527614\n",
      "epoch 28; iter: 0; batch classifier loss: 0.127449; batch adversarial loss: 0.471779\n",
      "epoch 29; iter: 0; batch classifier loss: 0.207539; batch adversarial loss: 0.485999\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172154; batch adversarial loss: 0.461965\n",
      "epoch 31; iter: 0; batch classifier loss: 0.160843; batch adversarial loss: 0.533154\n",
      "epoch 32; iter: 0; batch classifier loss: 0.148475; batch adversarial loss: 0.501667\n",
      "epoch 33; iter: 0; batch classifier loss: 0.169418; batch adversarial loss: 0.442883\n",
      "epoch 34; iter: 0; batch classifier loss: 0.137613; batch adversarial loss: 0.557460\n",
      "epoch 35; iter: 0; batch classifier loss: 0.138037; batch adversarial loss: 0.432736\n",
      "epoch 36; iter: 0; batch classifier loss: 0.147858; batch adversarial loss: 0.598496\n",
      "epoch 37; iter: 0; batch classifier loss: 0.202116; batch adversarial loss: 0.479264\n",
      "epoch 38; iter: 0; batch classifier loss: 0.138984; batch adversarial loss: 0.462009\n",
      "epoch 39; iter: 0; batch classifier loss: 0.109677; batch adversarial loss: 0.493393\n",
      "epoch 40; iter: 0; batch classifier loss: 0.136591; batch adversarial loss: 0.387438\n",
      "epoch 41; iter: 0; batch classifier loss: 0.191381; batch adversarial loss: 0.384239\n",
      "epoch 42; iter: 0; batch classifier loss: 0.209947; batch adversarial loss: 0.533258\n",
      "epoch 43; iter: 0; batch classifier loss: 0.128313; batch adversarial loss: 0.617219\n",
      "epoch 44; iter: 0; batch classifier loss: 0.164722; batch adversarial loss: 0.405412\n",
      "epoch 45; iter: 0; batch classifier loss: 0.138463; batch adversarial loss: 0.366147\n",
      "epoch 46; iter: 0; batch classifier loss: 0.174706; batch adversarial loss: 0.446248\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114063; batch adversarial loss: 0.393667\n",
      "epoch 48; iter: 0; batch classifier loss: 0.121020; batch adversarial loss: 0.498567\n",
      "epoch 49; iter: 0; batch classifier loss: 0.116208; batch adversarial loss: 0.388287\n",
      "epoch 50; iter: 0; batch classifier loss: 0.141279; batch adversarial loss: 0.541672\n",
      "epoch 51; iter: 0; batch classifier loss: 0.200525; batch adversarial loss: 0.477817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.118653; batch adversarial loss: 0.396202\n",
      "epoch 53; iter: 0; batch classifier loss: 0.160869; batch adversarial loss: 0.495668\n",
      "epoch 54; iter: 0; batch classifier loss: 0.139647; batch adversarial loss: 0.445775\n",
      "epoch 55; iter: 0; batch classifier loss: 0.134033; batch adversarial loss: 0.518445\n",
      "epoch 56; iter: 0; batch classifier loss: 0.090088; batch adversarial loss: 0.492272\n",
      "epoch 57; iter: 0; batch classifier loss: 0.116741; batch adversarial loss: 0.463787\n",
      "epoch 58; iter: 0; batch classifier loss: 0.156065; batch adversarial loss: 0.515076\n",
      "epoch 59; iter: 0; batch classifier loss: 0.159058; batch adversarial loss: 0.527850\n",
      "epoch 60; iter: 0; batch classifier loss: 0.090153; batch adversarial loss: 0.421887\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080500; batch adversarial loss: 0.468734\n",
      "epoch 62; iter: 0; batch classifier loss: 0.111189; batch adversarial loss: 0.438921\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091470; batch adversarial loss: 0.380189\n",
      "epoch 64; iter: 0; batch classifier loss: 0.074525; batch adversarial loss: 0.402111\n",
      "epoch 65; iter: 0; batch classifier loss: 0.134602; batch adversarial loss: 0.449991\n",
      "epoch 66; iter: 0; batch classifier loss: 0.125965; batch adversarial loss: 0.513894\n",
      "epoch 67; iter: 0; batch classifier loss: 0.125066; batch adversarial loss: 0.651523\n",
      "epoch 68; iter: 0; batch classifier loss: 0.106016; batch adversarial loss: 0.470296\n",
      "epoch 69; iter: 0; batch classifier loss: 0.108583; batch adversarial loss: 0.482891\n",
      "epoch 70; iter: 0; batch classifier loss: 0.081410; batch adversarial loss: 0.500650\n",
      "epoch 71; iter: 0; batch classifier loss: 0.137561; batch adversarial loss: 0.403926\n",
      "epoch 72; iter: 0; batch classifier loss: 0.066558; batch adversarial loss: 0.438537\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085995; batch adversarial loss: 0.424700\n",
      "epoch 74; iter: 0; batch classifier loss: 0.087012; batch adversarial loss: 0.510520\n",
      "epoch 75; iter: 0; batch classifier loss: 0.121091; batch adversarial loss: 0.372601\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077786; batch adversarial loss: 0.421779\n",
      "epoch 77; iter: 0; batch classifier loss: 0.058522; batch adversarial loss: 0.544381\n",
      "epoch 78; iter: 0; batch classifier loss: 0.101019; batch adversarial loss: 0.513664\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057394; batch adversarial loss: 0.401345\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060017; batch adversarial loss: 0.556733\n",
      "epoch 81; iter: 0; batch classifier loss: 0.103203; batch adversarial loss: 0.417593\n",
      "epoch 82; iter: 0; batch classifier loss: 0.103677; batch adversarial loss: 0.536445\n",
      "epoch 83; iter: 0; batch classifier loss: 0.101449; batch adversarial loss: 0.522189\n",
      "epoch 84; iter: 0; batch classifier loss: 0.074475; batch adversarial loss: 0.481397\n",
      "epoch 85; iter: 0; batch classifier loss: 0.092574; batch adversarial loss: 0.513797\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052416; batch adversarial loss: 0.492019\n",
      "epoch 87; iter: 0; batch classifier loss: 0.061156; batch adversarial loss: 0.446392\n",
      "epoch 88; iter: 0; batch classifier loss: 0.034876; batch adversarial loss: 0.519957\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054517; batch adversarial loss: 0.505826\n",
      "epoch 90; iter: 0; batch classifier loss: 0.082552; batch adversarial loss: 0.431869\n",
      "epoch 91; iter: 0; batch classifier loss: 0.058895; batch adversarial loss: 0.502511\n",
      "epoch 92; iter: 0; batch classifier loss: 0.088873; batch adversarial loss: 0.405729\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061918; batch adversarial loss: 0.535604\n",
      "epoch 94; iter: 0; batch classifier loss: 0.137499; batch adversarial loss: 0.447074\n",
      "epoch 95; iter: 0; batch classifier loss: 0.025276; batch adversarial loss: 0.460533\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068026; batch adversarial loss: 0.497185\n",
      "epoch 97; iter: 0; batch classifier loss: 0.035362; batch adversarial loss: 0.452974\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053028; batch adversarial loss: 0.407625\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073186; batch adversarial loss: 0.435738\n",
      "epoch 100; iter: 0; batch classifier loss: 0.032769; batch adversarial loss: 0.377635\n",
      "epoch 101; iter: 0; batch classifier loss: 0.064678; batch adversarial loss: 0.399490\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050647; batch adversarial loss: 0.483083\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046929; batch adversarial loss: 0.403287\n",
      "epoch 104; iter: 0; batch classifier loss: 0.074324; batch adversarial loss: 0.479612\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031927; batch adversarial loss: 0.484742\n",
      "epoch 106; iter: 0; batch classifier loss: 0.065374; batch adversarial loss: 0.522992\n",
      "epoch 107; iter: 0; batch classifier loss: 0.013846; batch adversarial loss: 0.415002\n",
      "epoch 108; iter: 0; batch classifier loss: 0.062427; batch adversarial loss: 0.463055\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027321; batch adversarial loss: 0.387349\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050513; batch adversarial loss: 0.400334\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043420; batch adversarial loss: 0.434394\n",
      "epoch 112; iter: 0; batch classifier loss: 0.050741; batch adversarial loss: 0.454909\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026781; batch adversarial loss: 0.474559\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027996; batch adversarial loss: 0.486296\n",
      "epoch 115; iter: 0; batch classifier loss: 0.030424; batch adversarial loss: 0.475484\n",
      "epoch 116; iter: 0; batch classifier loss: 0.020743; batch adversarial loss: 0.449061\n",
      "epoch 117; iter: 0; batch classifier loss: 0.018835; batch adversarial loss: 0.481181\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035847; batch adversarial loss: 0.509220\n",
      "epoch 119; iter: 0; batch classifier loss: 0.072559; batch adversarial loss: 0.380335\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037078; batch adversarial loss: 0.472602\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051384; batch adversarial loss: 0.494706\n",
      "epoch 122; iter: 0; batch classifier loss: 0.071301; batch adversarial loss: 0.397457\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042822; batch adversarial loss: 0.459998\n",
      "epoch 124; iter: 0; batch classifier loss: 0.058252; batch adversarial loss: 0.486939\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025373; batch adversarial loss: 0.437976\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039977; batch adversarial loss: 0.434928\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051127; batch adversarial loss: 0.433860\n",
      "epoch 128; iter: 0; batch classifier loss: 0.086992; batch adversarial loss: 0.497755\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025712; batch adversarial loss: 0.580890\n",
      "epoch 130; iter: 0; batch classifier loss: 0.011940; batch adversarial loss: 0.400430\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050038; batch adversarial loss: 0.458779\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047572; batch adversarial loss: 0.504506\n",
      "epoch 133; iter: 0; batch classifier loss: 0.073405; batch adversarial loss: 0.449501\n",
      "epoch 134; iter: 0; batch classifier loss: 0.066963; batch adversarial loss: 0.440458\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032282; batch adversarial loss: 0.308776\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024727; batch adversarial loss: 0.418414\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021387; batch adversarial loss: 0.411961\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045794; batch adversarial loss: 0.423725\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041912; batch adversarial loss: 0.490824\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028273; batch adversarial loss: 0.505468\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018450; batch adversarial loss: 0.408562\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023304; batch adversarial loss: 0.484972\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038584; batch adversarial loss: 0.482178\n",
      "epoch 144; iter: 0; batch classifier loss: 0.061263; batch adversarial loss: 0.416029\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040119; batch adversarial loss: 0.456589\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017804; batch adversarial loss: 0.493791\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015086; batch adversarial loss: 0.585181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.040914; batch adversarial loss: 0.375147\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031768; batch adversarial loss: 0.541014\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027770; batch adversarial loss: 0.397288\n",
      "epoch 151; iter: 0; batch classifier loss: 0.051658; batch adversarial loss: 0.493792\n",
      "epoch 152; iter: 0; batch classifier loss: 0.068824; batch adversarial loss: 0.556743\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024683; batch adversarial loss: 0.397695\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041580; batch adversarial loss: 0.410048\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032261; batch adversarial loss: 0.473926\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015378; batch adversarial loss: 0.435459\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010986; batch adversarial loss: 0.430672\n",
      "epoch 158; iter: 0; batch classifier loss: 0.055281; batch adversarial loss: 0.435826\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032929; batch adversarial loss: 0.519160\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010072; batch adversarial loss: 0.486741\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017767; batch adversarial loss: 0.424980\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007023; batch adversarial loss: 0.486737\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014800; batch adversarial loss: 0.429528\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016513; batch adversarial loss: 0.426948\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013079; batch adversarial loss: 0.453224\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015361; batch adversarial loss: 0.406758\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014566; batch adversarial loss: 0.469774\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012339; batch adversarial loss: 0.487055\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033133; batch adversarial loss: 0.432943\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033156; batch adversarial loss: 0.426337\n",
      "epoch 171; iter: 0; batch classifier loss: 0.052041; batch adversarial loss: 0.389896\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008800; batch adversarial loss: 0.437361\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038882; batch adversarial loss: 0.431630\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012967; batch adversarial loss: 0.419443\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021197; batch adversarial loss: 0.411338\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023594; batch adversarial loss: 0.543956\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029129; batch adversarial loss: 0.408674\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026018; batch adversarial loss: 0.388744\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029398; batch adversarial loss: 0.453188\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018979; batch adversarial loss: 0.538533\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008741; batch adversarial loss: 0.554551\n",
      "epoch 182; iter: 0; batch classifier loss: 0.004832; batch adversarial loss: 0.532297\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005313; batch adversarial loss: 0.502522\n",
      "epoch 184; iter: 0; batch classifier loss: 0.042228; batch adversarial loss: 0.525635\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014128; batch adversarial loss: 0.367905\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023003; batch adversarial loss: 0.501319\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012427; batch adversarial loss: 0.459174\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015314; batch adversarial loss: 0.484011\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036653; batch adversarial loss: 0.403671\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026585; batch adversarial loss: 0.493903\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013327; batch adversarial loss: 0.576139\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021644; batch adversarial loss: 0.526269\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017383; batch adversarial loss: 0.516908\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008238; batch adversarial loss: 0.439877\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023721; batch adversarial loss: 0.462414\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007848; batch adversarial loss: 0.531817\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013008; batch adversarial loss: 0.405210\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020481; batch adversarial loss: 0.475869\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005395; batch adversarial loss: 0.489430\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710489; batch adversarial loss: 0.576940\n",
      "epoch 1; iter: 0; batch classifier loss: 0.452385; batch adversarial loss: 0.578704\n",
      "epoch 2; iter: 0; batch classifier loss: 0.408326; batch adversarial loss: 0.583187\n",
      "epoch 3; iter: 0; batch classifier loss: 0.387583; batch adversarial loss: 0.573292\n",
      "epoch 4; iter: 0; batch classifier loss: 0.296657; batch adversarial loss: 0.554926\n",
      "epoch 5; iter: 0; batch classifier loss: 0.357087; batch adversarial loss: 0.599405\n",
      "epoch 6; iter: 0; batch classifier loss: 0.381541; batch adversarial loss: 0.597648\n",
      "epoch 7; iter: 0; batch classifier loss: 0.362136; batch adversarial loss: 0.582195\n",
      "epoch 8; iter: 0; batch classifier loss: 0.309751; batch adversarial loss: 0.522387\n",
      "epoch 9; iter: 0; batch classifier loss: 0.207878; batch adversarial loss: 0.575598\n",
      "epoch 10; iter: 0; batch classifier loss: 0.339145; batch adversarial loss: 0.515489\n",
      "epoch 11; iter: 0; batch classifier loss: 0.328998; batch adversarial loss: 0.488518\n",
      "epoch 12; iter: 0; batch classifier loss: 0.252501; batch adversarial loss: 0.528161\n",
      "epoch 13; iter: 0; batch classifier loss: 0.269716; batch adversarial loss: 0.492244\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249028; batch adversarial loss: 0.511345\n",
      "epoch 15; iter: 0; batch classifier loss: 0.248759; batch adversarial loss: 0.518617\n",
      "epoch 16; iter: 0; batch classifier loss: 0.258574; batch adversarial loss: 0.466046\n",
      "epoch 17; iter: 0; batch classifier loss: 0.216308; batch adversarial loss: 0.457671\n",
      "epoch 18; iter: 0; batch classifier loss: 0.213346; batch adversarial loss: 0.462845\n",
      "epoch 19; iter: 0; batch classifier loss: 0.239790; batch adversarial loss: 0.456934\n",
      "epoch 20; iter: 0; batch classifier loss: 0.264601; batch adversarial loss: 0.440975\n",
      "epoch 21; iter: 0; batch classifier loss: 0.248984; batch adversarial loss: 0.477048\n",
      "epoch 22; iter: 0; batch classifier loss: 0.184531; batch adversarial loss: 0.491334\n",
      "epoch 23; iter: 0; batch classifier loss: 0.277641; batch adversarial loss: 0.434603\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182945; batch adversarial loss: 0.521266\n",
      "epoch 25; iter: 0; batch classifier loss: 0.162764; batch adversarial loss: 0.450655\n",
      "epoch 26; iter: 0; batch classifier loss: 0.171400; batch adversarial loss: 0.496001\n",
      "epoch 27; iter: 0; batch classifier loss: 0.114620; batch adversarial loss: 0.480415\n",
      "epoch 28; iter: 0; batch classifier loss: 0.117973; batch adversarial loss: 0.428438\n",
      "epoch 29; iter: 0; batch classifier loss: 0.155443; batch adversarial loss: 0.528954\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172582; batch adversarial loss: 0.475690\n",
      "epoch 31; iter: 0; batch classifier loss: 0.208236; batch adversarial loss: 0.436681\n",
      "epoch 32; iter: 0; batch classifier loss: 0.184591; batch adversarial loss: 0.506303\n",
      "epoch 33; iter: 0; batch classifier loss: 0.161313; batch adversarial loss: 0.456500\n",
      "epoch 34; iter: 0; batch classifier loss: 0.166025; batch adversarial loss: 0.562829\n",
      "epoch 35; iter: 0; batch classifier loss: 0.157765; batch adversarial loss: 0.450445\n",
      "epoch 36; iter: 0; batch classifier loss: 0.180066; batch adversarial loss: 0.541206\n",
      "epoch 37; iter: 0; batch classifier loss: 0.094587; batch adversarial loss: 0.456011\n",
      "epoch 38; iter: 0; batch classifier loss: 0.147425; batch adversarial loss: 0.482073\n",
      "epoch 39; iter: 0; batch classifier loss: 0.212547; batch adversarial loss: 0.445184\n",
      "epoch 40; iter: 0; batch classifier loss: 0.252377; batch adversarial loss: 0.431573\n",
      "epoch 41; iter: 0; batch classifier loss: 0.183563; batch adversarial loss: 0.443650\n",
      "epoch 42; iter: 0; batch classifier loss: 0.137767; batch adversarial loss: 0.452365\n",
      "epoch 43; iter: 0; batch classifier loss: 0.114839; batch adversarial loss: 0.357790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.147181; batch adversarial loss: 0.476398\n",
      "epoch 45; iter: 0; batch classifier loss: 0.204448; batch adversarial loss: 0.509733\n",
      "epoch 46; iter: 0; batch classifier loss: 0.138809; batch adversarial loss: 0.468766\n",
      "epoch 47; iter: 0; batch classifier loss: 0.182152; batch adversarial loss: 0.514372\n",
      "epoch 48; iter: 0; batch classifier loss: 0.182749; batch adversarial loss: 0.580127\n",
      "epoch 49; iter: 0; batch classifier loss: 0.177423; batch adversarial loss: 0.489662\n",
      "epoch 50; iter: 0; batch classifier loss: 0.182823; batch adversarial loss: 0.429764\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121798; batch adversarial loss: 0.533433\n",
      "epoch 52; iter: 0; batch classifier loss: 0.227440; batch adversarial loss: 0.435833\n",
      "epoch 53; iter: 0; batch classifier loss: 0.218434; batch adversarial loss: 0.528666\n",
      "epoch 54; iter: 0; batch classifier loss: 0.185697; batch adversarial loss: 0.515174\n",
      "epoch 55; iter: 0; batch classifier loss: 0.174124; batch adversarial loss: 0.425519\n",
      "epoch 56; iter: 0; batch classifier loss: 0.197215; batch adversarial loss: 0.541954\n",
      "epoch 57; iter: 0; batch classifier loss: 0.135955; batch adversarial loss: 0.503813\n",
      "epoch 58; iter: 0; batch classifier loss: 0.198210; batch adversarial loss: 0.479919\n",
      "epoch 59; iter: 0; batch classifier loss: 0.220772; batch adversarial loss: 0.313319\n",
      "epoch 60; iter: 0; batch classifier loss: 0.131367; batch adversarial loss: 0.387502\n",
      "epoch 61; iter: 0; batch classifier loss: 0.197378; batch adversarial loss: 0.480013\n",
      "epoch 62; iter: 0; batch classifier loss: 0.153011; batch adversarial loss: 0.545995\n",
      "epoch 63; iter: 0; batch classifier loss: 0.195540; batch adversarial loss: 0.497690\n",
      "epoch 64; iter: 0; batch classifier loss: 0.149215; batch adversarial loss: 0.509142\n",
      "epoch 65; iter: 0; batch classifier loss: 0.158936; batch adversarial loss: 0.482171\n",
      "epoch 66; iter: 0; batch classifier loss: 0.170771; batch adversarial loss: 0.434640\n",
      "epoch 67; iter: 0; batch classifier loss: 0.129934; batch adversarial loss: 0.471934\n",
      "epoch 68; iter: 0; batch classifier loss: 0.183111; batch adversarial loss: 0.397966\n",
      "epoch 69; iter: 0; batch classifier loss: 0.125989; batch adversarial loss: 0.485822\n",
      "epoch 70; iter: 0; batch classifier loss: 0.129758; batch adversarial loss: 0.480970\n",
      "epoch 71; iter: 0; batch classifier loss: 0.159365; batch adversarial loss: 0.469330\n",
      "epoch 72; iter: 0; batch classifier loss: 0.159938; batch adversarial loss: 0.422340\n",
      "epoch 73; iter: 0; batch classifier loss: 0.124377; batch adversarial loss: 0.435166\n",
      "epoch 74; iter: 0; batch classifier loss: 0.177017; batch adversarial loss: 0.556856\n",
      "epoch 75; iter: 0; batch classifier loss: 0.210430; batch adversarial loss: 0.446072\n",
      "epoch 76; iter: 0; batch classifier loss: 0.162609; batch adversarial loss: 0.423173\n",
      "epoch 77; iter: 0; batch classifier loss: 0.187979; batch adversarial loss: 0.482385\n",
      "epoch 78; iter: 0; batch classifier loss: 0.208745; batch adversarial loss: 0.410216\n",
      "epoch 79; iter: 0; batch classifier loss: 0.189396; batch adversarial loss: 0.471181\n",
      "epoch 80; iter: 0; batch classifier loss: 0.188511; batch adversarial loss: 0.349481\n",
      "epoch 81; iter: 0; batch classifier loss: 0.228649; batch adversarial loss: 0.410406\n",
      "epoch 82; iter: 0; batch classifier loss: 0.139452; batch adversarial loss: 0.421822\n",
      "epoch 83; iter: 0; batch classifier loss: 0.142064; batch adversarial loss: 0.433909\n",
      "epoch 84; iter: 0; batch classifier loss: 0.175154; batch adversarial loss: 0.435402\n",
      "epoch 85; iter: 0; batch classifier loss: 0.174207; batch adversarial loss: 0.458681\n",
      "epoch 86; iter: 0; batch classifier loss: 0.112502; batch adversarial loss: 0.410942\n",
      "epoch 87; iter: 0; batch classifier loss: 0.220438; batch adversarial loss: 0.445336\n",
      "epoch 88; iter: 0; batch classifier loss: 0.183947; batch adversarial loss: 0.434019\n",
      "epoch 89; iter: 0; batch classifier loss: 0.152424; batch adversarial loss: 0.445640\n",
      "epoch 90; iter: 0; batch classifier loss: 0.140642; batch adversarial loss: 0.423631\n",
      "epoch 91; iter: 0; batch classifier loss: 0.233166; batch adversarial loss: 0.447479\n",
      "epoch 92; iter: 0; batch classifier loss: 0.189063; batch adversarial loss: 0.422867\n",
      "epoch 93; iter: 0; batch classifier loss: 0.153128; batch adversarial loss: 0.373258\n",
      "epoch 94; iter: 0; batch classifier loss: 0.169055; batch adversarial loss: 0.483661\n",
      "epoch 95; iter: 0; batch classifier loss: 0.164557; batch adversarial loss: 0.508284\n",
      "epoch 96; iter: 0; batch classifier loss: 0.233557; batch adversarial loss: 0.350313\n",
      "epoch 97; iter: 0; batch classifier loss: 0.120433; batch adversarial loss: 0.397573\n",
      "epoch 98; iter: 0; batch classifier loss: 0.115743; batch adversarial loss: 0.397177\n",
      "epoch 99; iter: 0; batch classifier loss: 0.107735; batch adversarial loss: 0.420157\n",
      "epoch 100; iter: 0; batch classifier loss: 0.120134; batch adversarial loss: 0.493854\n",
      "epoch 101; iter: 0; batch classifier loss: 0.234437; batch adversarial loss: 0.532179\n",
      "epoch 102; iter: 0; batch classifier loss: 0.169239; batch adversarial loss: 0.460065\n",
      "epoch 103; iter: 0; batch classifier loss: 0.112077; batch adversarial loss: 0.412605\n",
      "epoch 104; iter: 0; batch classifier loss: 0.084055; batch adversarial loss: 0.481701\n",
      "epoch 105; iter: 0; batch classifier loss: 0.077967; batch adversarial loss: 0.458625\n",
      "epoch 106; iter: 0; batch classifier loss: 0.117134; batch adversarial loss: 0.443343\n",
      "epoch 107; iter: 0; batch classifier loss: 0.070726; batch adversarial loss: 0.446441\n",
      "epoch 108; iter: 0; batch classifier loss: 0.094888; batch adversarial loss: 0.517542\n",
      "epoch 109; iter: 0; batch classifier loss: 0.110037; batch adversarial loss: 0.482650\n",
      "epoch 110; iter: 0; batch classifier loss: 0.098064; batch adversarial loss: 0.460445\n",
      "epoch 111; iter: 0; batch classifier loss: 0.098064; batch adversarial loss: 0.402050\n",
      "epoch 112; iter: 0; batch classifier loss: 0.080501; batch adversarial loss: 0.518933\n",
      "epoch 113; iter: 0; batch classifier loss: 0.074090; batch adversarial loss: 0.503964\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052843; batch adversarial loss: 0.463175\n",
      "epoch 115; iter: 0; batch classifier loss: 0.075085; batch adversarial loss: 0.558756\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062365; batch adversarial loss: 0.423520\n",
      "epoch 117; iter: 0; batch classifier loss: 0.073050; batch adversarial loss: 0.423687\n",
      "epoch 118; iter: 0; batch classifier loss: 0.088208; batch adversarial loss: 0.354498\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048220; batch adversarial loss: 0.441052\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060557; batch adversarial loss: 0.407169\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035961; batch adversarial loss: 0.568743\n",
      "epoch 122; iter: 0; batch classifier loss: 0.081704; batch adversarial loss: 0.430971\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041685; batch adversarial loss: 0.509475\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033448; batch adversarial loss: 0.456958\n",
      "epoch 125; iter: 0; batch classifier loss: 0.014880; batch adversarial loss: 0.531955\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063580; batch adversarial loss: 0.380690\n",
      "epoch 127; iter: 0; batch classifier loss: 0.086643; batch adversarial loss: 0.424408\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031258; batch adversarial loss: 0.433354\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031625; batch adversarial loss: 0.504955\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017573; batch adversarial loss: 0.533197\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055080; batch adversarial loss: 0.412567\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037031; batch adversarial loss: 0.502396\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036083; batch adversarial loss: 0.559830\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020406; batch adversarial loss: 0.507021\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035900; batch adversarial loss: 0.484195\n",
      "epoch 136; iter: 0; batch classifier loss: 0.045901; batch adversarial loss: 0.419420\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025794; batch adversarial loss: 0.442708\n",
      "epoch 138; iter: 0; batch classifier loss: 0.050061; batch adversarial loss: 0.484270\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020884; batch adversarial loss: 0.542349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.044228; batch adversarial loss: 0.536466\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053622; batch adversarial loss: 0.503195\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019010; batch adversarial loss: 0.473211\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046274; batch adversarial loss: 0.508729\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012127; batch adversarial loss: 0.486922\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023254; batch adversarial loss: 0.548351\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027414; batch adversarial loss: 0.403614\n",
      "epoch 147; iter: 0; batch classifier loss: 0.049329; batch adversarial loss: 0.470777\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042177; batch adversarial loss: 0.558574\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053341; batch adversarial loss: 0.494552\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020614; batch adversarial loss: 0.435052\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027865; batch adversarial loss: 0.445707\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023813; batch adversarial loss: 0.412574\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032775; batch adversarial loss: 0.509166\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022885; batch adversarial loss: 0.513948\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026036; batch adversarial loss: 0.506805\n",
      "epoch 156; iter: 0; batch classifier loss: 0.076988; batch adversarial loss: 0.461532\n",
      "epoch 157; iter: 0; batch classifier loss: 0.058572; batch adversarial loss: 0.469273\n",
      "epoch 158; iter: 0; batch classifier loss: 0.039852; batch adversarial loss: 0.407003\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026235; batch adversarial loss: 0.472924\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023474; batch adversarial loss: 0.477381\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025223; batch adversarial loss: 0.551190\n",
      "epoch 162; iter: 0; batch classifier loss: 0.044897; batch adversarial loss: 0.499733\n",
      "epoch 163; iter: 0; batch classifier loss: 0.051373; batch adversarial loss: 0.441355\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027544; batch adversarial loss: 0.533975\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015350; batch adversarial loss: 0.412181\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033636; batch adversarial loss: 0.478983\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012125; batch adversarial loss: 0.592570\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028087; batch adversarial loss: 0.483482\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016801; batch adversarial loss: 0.458678\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032394; batch adversarial loss: 0.496795\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009122; batch adversarial loss: 0.356172\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040746; batch adversarial loss: 0.494758\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027868; batch adversarial loss: 0.413779\n",
      "epoch 174; iter: 0; batch classifier loss: 0.042824; batch adversarial loss: 0.450658\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031840; batch adversarial loss: 0.410315\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034126; batch adversarial loss: 0.389856\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022399; batch adversarial loss: 0.583085\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018585; batch adversarial loss: 0.470178\n",
      "epoch 179; iter: 0; batch classifier loss: 0.048168; batch adversarial loss: 0.479411\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032477; batch adversarial loss: 0.430573\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036596; batch adversarial loss: 0.470433\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020572; batch adversarial loss: 0.505311\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009074; batch adversarial loss: 0.429547\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022737; batch adversarial loss: 0.453569\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038523; batch adversarial loss: 0.491244\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025718; batch adversarial loss: 0.529575\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032246; batch adversarial loss: 0.420808\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029438; batch adversarial loss: 0.436345\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023958; batch adversarial loss: 0.438932\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019815; batch adversarial loss: 0.502833\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006811; batch adversarial loss: 0.491389\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023824; batch adversarial loss: 0.418383\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028746; batch adversarial loss: 0.374794\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034087; batch adversarial loss: 0.476867\n",
      "epoch 195; iter: 0; batch classifier loss: 0.045932; batch adversarial loss: 0.455529\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017591; batch adversarial loss: 0.406613\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025176; batch adversarial loss: 0.501588\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023727; batch adversarial loss: 0.435953\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008226; batch adversarial loss: 0.504274\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717006; batch adversarial loss: 0.680021\n",
      "epoch 1; iter: 0; batch classifier loss: 0.559683; batch adversarial loss: 0.653720\n",
      "epoch 2; iter: 0; batch classifier loss: 0.443375; batch adversarial loss: 0.597775\n",
      "epoch 3; iter: 0; batch classifier loss: 0.383089; batch adversarial loss: 0.626210\n",
      "epoch 4; iter: 0; batch classifier loss: 0.327774; batch adversarial loss: 0.636679\n",
      "epoch 5; iter: 0; batch classifier loss: 0.364313; batch adversarial loss: 0.597801\n",
      "epoch 6; iter: 0; batch classifier loss: 0.433825; batch adversarial loss: 0.564409\n",
      "epoch 7; iter: 0; batch classifier loss: 0.415284; batch adversarial loss: 0.541822\n",
      "epoch 8; iter: 0; batch classifier loss: 0.382348; batch adversarial loss: 0.554425\n",
      "epoch 9; iter: 0; batch classifier loss: 0.380604; batch adversarial loss: 0.495533\n",
      "epoch 10; iter: 0; batch classifier loss: 0.413099; batch adversarial loss: 0.503580\n",
      "epoch 11; iter: 0; batch classifier loss: 0.244988; batch adversarial loss: 0.528229\n",
      "epoch 12; iter: 0; batch classifier loss: 0.364737; batch adversarial loss: 0.519267\n",
      "epoch 13; iter: 0; batch classifier loss: 0.367994; batch adversarial loss: 0.482543\n",
      "epoch 14; iter: 0; batch classifier loss: 0.445976; batch adversarial loss: 0.529653\n",
      "epoch 15; iter: 0; batch classifier loss: 0.329880; batch adversarial loss: 0.538675\n",
      "epoch 16; iter: 0; batch classifier loss: 0.318920; batch adversarial loss: 0.564570\n",
      "epoch 17; iter: 0; batch classifier loss: 0.299243; batch adversarial loss: 0.499834\n",
      "epoch 18; iter: 0; batch classifier loss: 0.329242; batch adversarial loss: 0.438260\n",
      "epoch 19; iter: 0; batch classifier loss: 0.313651; batch adversarial loss: 0.525038\n",
      "epoch 20; iter: 0; batch classifier loss: 0.245710; batch adversarial loss: 0.528273\n",
      "epoch 21; iter: 0; batch classifier loss: 0.293518; batch adversarial loss: 0.495006\n",
      "epoch 22; iter: 0; batch classifier loss: 0.273665; batch adversarial loss: 0.491274\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285636; batch adversarial loss: 0.460957\n",
      "epoch 24; iter: 0; batch classifier loss: 0.175824; batch adversarial loss: 0.449397\n",
      "epoch 25; iter: 0; batch classifier loss: 0.271622; batch adversarial loss: 0.426512\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193189; batch adversarial loss: 0.532321\n",
      "epoch 27; iter: 0; batch classifier loss: 0.197476; batch adversarial loss: 0.508926\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184897; batch adversarial loss: 0.460394\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176959; batch adversarial loss: 0.485850\n",
      "epoch 30; iter: 0; batch classifier loss: 0.226644; batch adversarial loss: 0.418058\n",
      "epoch 31; iter: 0; batch classifier loss: 0.173016; batch adversarial loss: 0.468905\n",
      "epoch 32; iter: 0; batch classifier loss: 0.143699; batch adversarial loss: 0.532428\n",
      "epoch 33; iter: 0; batch classifier loss: 0.156428; batch adversarial loss: 0.532786\n",
      "epoch 34; iter: 0; batch classifier loss: 0.126351; batch adversarial loss: 0.492871\n",
      "epoch 35; iter: 0; batch classifier loss: 0.095613; batch adversarial loss: 0.535914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.188255; batch adversarial loss: 0.453217\n",
      "epoch 37; iter: 0; batch classifier loss: 0.155858; batch adversarial loss: 0.518670\n",
      "epoch 38; iter: 0; batch classifier loss: 0.136297; batch adversarial loss: 0.442148\n",
      "epoch 39; iter: 0; batch classifier loss: 0.110319; batch adversarial loss: 0.489179\n",
      "epoch 40; iter: 0; batch classifier loss: 0.155915; batch adversarial loss: 0.534328\n",
      "epoch 41; iter: 0; batch classifier loss: 0.128796; batch adversarial loss: 0.492272\n",
      "epoch 42; iter: 0; batch classifier loss: 0.192195; batch adversarial loss: 0.469585\n",
      "epoch 43; iter: 0; batch classifier loss: 0.182268; batch adversarial loss: 0.404163\n",
      "epoch 44; iter: 0; batch classifier loss: 0.076549; batch adversarial loss: 0.498270\n",
      "epoch 45; iter: 0; batch classifier loss: 0.079463; batch adversarial loss: 0.491859\n",
      "epoch 46; iter: 0; batch classifier loss: 0.080996; batch adversarial loss: 0.544450\n",
      "epoch 47; iter: 0; batch classifier loss: 0.089004; batch adversarial loss: 0.459030\n",
      "epoch 48; iter: 0; batch classifier loss: 0.086342; batch adversarial loss: 0.554660\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129065; batch adversarial loss: 0.389736\n",
      "epoch 50; iter: 0; batch classifier loss: 0.115154; batch adversarial loss: 0.490160\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112084; batch adversarial loss: 0.415347\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101968; batch adversarial loss: 0.393334\n",
      "epoch 53; iter: 0; batch classifier loss: 0.080208; batch adversarial loss: 0.449866\n",
      "epoch 54; iter: 0; batch classifier loss: 0.083304; batch adversarial loss: 0.562322\n",
      "epoch 55; iter: 0; batch classifier loss: 0.153008; batch adversarial loss: 0.451822\n",
      "epoch 56; iter: 0; batch classifier loss: 0.132465; batch adversarial loss: 0.479947\n",
      "epoch 57; iter: 0; batch classifier loss: 0.125717; batch adversarial loss: 0.588500\n",
      "epoch 58; iter: 0; batch classifier loss: 0.088364; batch adversarial loss: 0.454371\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085277; batch adversarial loss: 0.461792\n",
      "epoch 60; iter: 0; batch classifier loss: 0.096032; batch adversarial loss: 0.496801\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105205; batch adversarial loss: 0.385084\n",
      "epoch 62; iter: 0; batch classifier loss: 0.033785; batch adversarial loss: 0.449458\n",
      "epoch 63; iter: 0; batch classifier loss: 0.107457; batch adversarial loss: 0.373818\n",
      "epoch 64; iter: 0; batch classifier loss: 0.117167; batch adversarial loss: 0.546226\n",
      "epoch 65; iter: 0; batch classifier loss: 0.091119; batch adversarial loss: 0.461342\n",
      "epoch 66; iter: 0; batch classifier loss: 0.121000; batch adversarial loss: 0.427630\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069872; batch adversarial loss: 0.477254\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060167; batch adversarial loss: 0.489421\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075376; batch adversarial loss: 0.421304\n",
      "epoch 70; iter: 0; batch classifier loss: 0.109674; batch adversarial loss: 0.450766\n",
      "epoch 71; iter: 0; batch classifier loss: 0.119514; batch adversarial loss: 0.487339\n",
      "epoch 72; iter: 0; batch classifier loss: 0.088166; batch adversarial loss: 0.418241\n",
      "epoch 73; iter: 0; batch classifier loss: 0.071395; batch adversarial loss: 0.388927\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063926; batch adversarial loss: 0.486848\n",
      "epoch 75; iter: 0; batch classifier loss: 0.090686; batch adversarial loss: 0.456316\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082927; batch adversarial loss: 0.416826\n",
      "epoch 77; iter: 0; batch classifier loss: 0.082341; batch adversarial loss: 0.395575\n",
      "epoch 78; iter: 0; batch classifier loss: 0.029458; batch adversarial loss: 0.451229\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061618; batch adversarial loss: 0.444719\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064548; batch adversarial loss: 0.391351\n",
      "epoch 81; iter: 0; batch classifier loss: 0.059055; batch adversarial loss: 0.498209\n",
      "epoch 82; iter: 0; batch classifier loss: 0.028786; batch adversarial loss: 0.605186\n",
      "epoch 83; iter: 0; batch classifier loss: 0.084277; batch adversarial loss: 0.468307\n",
      "epoch 84; iter: 0; batch classifier loss: 0.078570; batch adversarial loss: 0.435212\n",
      "epoch 85; iter: 0; batch classifier loss: 0.028336; batch adversarial loss: 0.475686\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062651; batch adversarial loss: 0.466229\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048348; batch adversarial loss: 0.398985\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076131; batch adversarial loss: 0.443742\n",
      "epoch 89; iter: 0; batch classifier loss: 0.029498; batch adversarial loss: 0.512738\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053874; batch adversarial loss: 0.466062\n",
      "epoch 91; iter: 0; batch classifier loss: 0.026858; batch adversarial loss: 0.494809\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074089; batch adversarial loss: 0.400270\n",
      "epoch 93; iter: 0; batch classifier loss: 0.042710; batch adversarial loss: 0.313206\n",
      "epoch 94; iter: 0; batch classifier loss: 0.035611; batch adversarial loss: 0.458115\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068088; batch adversarial loss: 0.507307\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048764; batch adversarial loss: 0.478881\n",
      "epoch 97; iter: 0; batch classifier loss: 0.017794; batch adversarial loss: 0.446323\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048894; batch adversarial loss: 0.423092\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049472; batch adversarial loss: 0.543519\n",
      "epoch 100; iter: 0; batch classifier loss: 0.033396; batch adversarial loss: 0.469028\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061797; batch adversarial loss: 0.479291\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041228; batch adversarial loss: 0.457637\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045262; batch adversarial loss: 0.447280\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056732; batch adversarial loss: 0.464531\n",
      "epoch 105; iter: 0; batch classifier loss: 0.065912; batch adversarial loss: 0.480424\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056847; batch adversarial loss: 0.469111\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046726; batch adversarial loss: 0.391470\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044917; batch adversarial loss: 0.477329\n",
      "epoch 109; iter: 0; batch classifier loss: 0.031637; batch adversarial loss: 0.405881\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050562; batch adversarial loss: 0.482064\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034560; batch adversarial loss: 0.527427\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035403; batch adversarial loss: 0.427026\n",
      "epoch 113; iter: 0; batch classifier loss: 0.024956; batch adversarial loss: 0.508935\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034168; batch adversarial loss: 0.442001\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028592; batch adversarial loss: 0.472397\n",
      "epoch 116; iter: 0; batch classifier loss: 0.047008; batch adversarial loss: 0.515542\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044449; batch adversarial loss: 0.464304\n",
      "epoch 118; iter: 0; batch classifier loss: 0.038570; batch adversarial loss: 0.432444\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050024; batch adversarial loss: 0.535616\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036847; batch adversarial loss: 0.491682\n",
      "epoch 121; iter: 0; batch classifier loss: 0.014266; batch adversarial loss: 0.485748\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026937; batch adversarial loss: 0.495742\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043415; batch adversarial loss: 0.499706\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021677; batch adversarial loss: 0.468589\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049811; batch adversarial loss: 0.440377\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020600; batch adversarial loss: 0.408000\n",
      "epoch 127; iter: 0; batch classifier loss: 0.054643; batch adversarial loss: 0.436267\n",
      "epoch 128; iter: 0; batch classifier loss: 0.012550; batch adversarial loss: 0.513327\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040241; batch adversarial loss: 0.487266\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061516; batch adversarial loss: 0.508715\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021606; batch adversarial loss: 0.444869\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040407; batch adversarial loss: 0.529840\n",
      "epoch 133; iter: 0; batch classifier loss: 0.047806; batch adversarial loss: 0.466845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.027883; batch adversarial loss: 0.446634\n",
      "epoch 135; iter: 0; batch classifier loss: 0.015218; batch adversarial loss: 0.411715\n",
      "epoch 136; iter: 0; batch classifier loss: 0.015200; batch adversarial loss: 0.435100\n",
      "epoch 137; iter: 0; batch classifier loss: 0.050946; batch adversarial loss: 0.495548\n",
      "epoch 138; iter: 0; batch classifier loss: 0.050762; batch adversarial loss: 0.505733\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025741; batch adversarial loss: 0.395392\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032053; batch adversarial loss: 0.485449\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029290; batch adversarial loss: 0.394745\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018796; batch adversarial loss: 0.514894\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037671; batch adversarial loss: 0.512264\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024309; batch adversarial loss: 0.551272\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011025; batch adversarial loss: 0.513190\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021587; batch adversarial loss: 0.451924\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042876; batch adversarial loss: 0.398076\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027014; batch adversarial loss: 0.456371\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034868; batch adversarial loss: 0.439325\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011791; batch adversarial loss: 0.524597\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012621; batch adversarial loss: 0.375158\n",
      "epoch 152; iter: 0; batch classifier loss: 0.056953; batch adversarial loss: 0.429696\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014383; batch adversarial loss: 0.410247\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027577; batch adversarial loss: 0.469491\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037510; batch adversarial loss: 0.408001\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013928; batch adversarial loss: 0.489602\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030495; batch adversarial loss: 0.450726\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020635; batch adversarial loss: 0.454700\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019599; batch adversarial loss: 0.546038\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013585; batch adversarial loss: 0.444689\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020988; batch adversarial loss: 0.433505\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019270; batch adversarial loss: 0.424472\n",
      "epoch 163; iter: 0; batch classifier loss: 0.046178; batch adversarial loss: 0.361404\n",
      "epoch 164; iter: 0; batch classifier loss: 0.006262; batch adversarial loss: 0.494360\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010219; batch adversarial loss: 0.487488\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015019; batch adversarial loss: 0.487726\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032595; batch adversarial loss: 0.417017\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015500; batch adversarial loss: 0.500169\n",
      "epoch 169; iter: 0; batch classifier loss: 0.052773; batch adversarial loss: 0.437831\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009290; batch adversarial loss: 0.426196\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011227; batch adversarial loss: 0.501745\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005829; batch adversarial loss: 0.523649\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034391; batch adversarial loss: 0.417256\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019281; batch adversarial loss: 0.362145\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024740; batch adversarial loss: 0.476344\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013254; batch adversarial loss: 0.422868\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006702; batch adversarial loss: 0.408982\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022754; batch adversarial loss: 0.366977\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013715; batch adversarial loss: 0.466699\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021560; batch adversarial loss: 0.524822\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029975; batch adversarial loss: 0.361646\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013425; batch adversarial loss: 0.412670\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015855; batch adversarial loss: 0.475549\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019765; batch adversarial loss: 0.323722\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028685; batch adversarial loss: 0.442783\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012758; batch adversarial loss: 0.542526\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029528; batch adversarial loss: 0.435504\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020069; batch adversarial loss: 0.410238\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010229; batch adversarial loss: 0.447740\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030685; batch adversarial loss: 0.442754\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029594; batch adversarial loss: 0.417797\n",
      "epoch 192; iter: 0; batch classifier loss: 0.047603; batch adversarial loss: 0.370934\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007542; batch adversarial loss: 0.530384\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014686; batch adversarial loss: 0.403965\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010969; batch adversarial loss: 0.421840\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012255; batch adversarial loss: 0.405266\n",
      "epoch 197; iter: 0; batch classifier loss: 0.002170; batch adversarial loss: 0.511075\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006053; batch adversarial loss: 0.402721\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021384; batch adversarial loss: 0.473965\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711955; batch adversarial loss: 0.869568\n",
      "epoch 1; iter: 0; batch classifier loss: 0.587952; batch adversarial loss: 0.851829\n",
      "epoch 2; iter: 0; batch classifier loss: 0.738088; batch adversarial loss: 0.827528\n",
      "epoch 3; iter: 0; batch classifier loss: 0.749473; batch adversarial loss: 0.753400\n",
      "epoch 4; iter: 0; batch classifier loss: 0.843977; batch adversarial loss: 0.692595\n",
      "epoch 5; iter: 0; batch classifier loss: 0.640129; batch adversarial loss: 0.626687\n",
      "epoch 6; iter: 0; batch classifier loss: 0.485666; batch adversarial loss: 0.591333\n",
      "epoch 7; iter: 0; batch classifier loss: 0.410744; batch adversarial loss: 0.554045\n",
      "epoch 8; iter: 0; batch classifier loss: 0.322840; batch adversarial loss: 0.557670\n",
      "epoch 9; iter: 0; batch classifier loss: 0.350545; batch adversarial loss: 0.578799\n",
      "epoch 10; iter: 0; batch classifier loss: 0.380908; batch adversarial loss: 0.541690\n",
      "epoch 11; iter: 0; batch classifier loss: 0.345881; batch adversarial loss: 0.546177\n",
      "epoch 12; iter: 0; batch classifier loss: 0.293434; batch adversarial loss: 0.553365\n",
      "epoch 13; iter: 0; batch classifier loss: 0.321106; batch adversarial loss: 0.530863\n",
      "epoch 14; iter: 0; batch classifier loss: 0.328588; batch adversarial loss: 0.507711\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302704; batch adversarial loss: 0.495322\n",
      "epoch 16; iter: 0; batch classifier loss: 0.297689; batch adversarial loss: 0.520726\n",
      "epoch 17; iter: 0; batch classifier loss: 0.311691; batch adversarial loss: 0.489245\n",
      "epoch 18; iter: 0; batch classifier loss: 0.189362; batch adversarial loss: 0.491568\n",
      "epoch 19; iter: 0; batch classifier loss: 0.350283; batch adversarial loss: 0.494370\n",
      "epoch 20; iter: 0; batch classifier loss: 0.285150; batch adversarial loss: 0.524787\n",
      "epoch 21; iter: 0; batch classifier loss: 0.359323; batch adversarial loss: 0.497075\n",
      "epoch 22; iter: 0; batch classifier loss: 0.343864; batch adversarial loss: 0.446239\n",
      "epoch 23; iter: 0; batch classifier loss: 0.279582; batch adversarial loss: 0.483564\n",
      "epoch 24; iter: 0; batch classifier loss: 0.242494; batch adversarial loss: 0.500848\n",
      "epoch 25; iter: 0; batch classifier loss: 0.288647; batch adversarial loss: 0.514690\n",
      "epoch 26; iter: 0; batch classifier loss: 0.242256; batch adversarial loss: 0.539486\n",
      "epoch 27; iter: 0; batch classifier loss: 0.290689; batch adversarial loss: 0.477879\n",
      "epoch 28; iter: 0; batch classifier loss: 0.345073; batch adversarial loss: 0.449719\n",
      "epoch 29; iter: 0; batch classifier loss: 0.277969; batch adversarial loss: 0.447392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.239988; batch adversarial loss: 0.495628\n",
      "epoch 31; iter: 0; batch classifier loss: 0.286153; batch adversarial loss: 0.386714\n",
      "epoch 32; iter: 0; batch classifier loss: 0.251350; batch adversarial loss: 0.570151\n",
      "epoch 33; iter: 0; batch classifier loss: 0.239054; batch adversarial loss: 0.529124\n",
      "epoch 34; iter: 0; batch classifier loss: 0.293814; batch adversarial loss: 0.540951\n",
      "epoch 35; iter: 0; batch classifier loss: 0.189612; batch adversarial loss: 0.592503\n",
      "epoch 36; iter: 0; batch classifier loss: 0.212160; batch adversarial loss: 0.457610\n",
      "epoch 37; iter: 0; batch classifier loss: 0.305078; batch adversarial loss: 0.489970\n",
      "epoch 38; iter: 0; batch classifier loss: 0.210504; batch adversarial loss: 0.536268\n",
      "epoch 39; iter: 0; batch classifier loss: 0.209469; batch adversarial loss: 0.502617\n",
      "epoch 40; iter: 0; batch classifier loss: 0.261436; batch adversarial loss: 0.451096\n",
      "epoch 41; iter: 0; batch classifier loss: 0.243006; batch adversarial loss: 0.491133\n",
      "epoch 42; iter: 0; batch classifier loss: 0.260545; batch adversarial loss: 0.487899\n",
      "epoch 43; iter: 0; batch classifier loss: 0.269309; batch adversarial loss: 0.520742\n",
      "epoch 44; iter: 0; batch classifier loss: 0.227281; batch adversarial loss: 0.532865\n",
      "epoch 45; iter: 0; batch classifier loss: 0.238859; batch adversarial loss: 0.434123\n",
      "epoch 46; iter: 0; batch classifier loss: 0.227689; batch adversarial loss: 0.468699\n",
      "epoch 47; iter: 0; batch classifier loss: 0.213289; batch adversarial loss: 0.429031\n",
      "epoch 48; iter: 0; batch classifier loss: 0.203676; batch adversarial loss: 0.413355\n",
      "epoch 49; iter: 0; batch classifier loss: 0.227652; batch adversarial loss: 0.454789\n",
      "epoch 50; iter: 0; batch classifier loss: 0.204822; batch adversarial loss: 0.414634\n",
      "epoch 51; iter: 0; batch classifier loss: 0.175548; batch adversarial loss: 0.475517\n",
      "epoch 52; iter: 0; batch classifier loss: 0.243964; batch adversarial loss: 0.401849\n",
      "epoch 53; iter: 0; batch classifier loss: 0.173550; batch adversarial loss: 0.462767\n",
      "epoch 54; iter: 0; batch classifier loss: 0.238089; batch adversarial loss: 0.469976\n",
      "epoch 55; iter: 0; batch classifier loss: 0.171431; batch adversarial loss: 0.533208\n",
      "epoch 56; iter: 0; batch classifier loss: 0.256121; batch adversarial loss: 0.422450\n",
      "epoch 57; iter: 0; batch classifier loss: 0.265040; batch adversarial loss: 0.458408\n",
      "epoch 58; iter: 0; batch classifier loss: 0.214696; batch adversarial loss: 0.481634\n",
      "epoch 59; iter: 0; batch classifier loss: 0.259530; batch adversarial loss: 0.543817\n",
      "epoch 60; iter: 0; batch classifier loss: 0.281211; batch adversarial loss: 0.409974\n",
      "epoch 61; iter: 0; batch classifier loss: 0.263681; batch adversarial loss: 0.460788\n",
      "epoch 62; iter: 0; batch classifier loss: 0.198388; batch adversarial loss: 0.470302\n",
      "epoch 63; iter: 0; batch classifier loss: 0.250287; batch adversarial loss: 0.482715\n",
      "epoch 64; iter: 0; batch classifier loss: 0.184618; batch adversarial loss: 0.458936\n",
      "epoch 65; iter: 0; batch classifier loss: 0.182490; batch adversarial loss: 0.506616\n",
      "epoch 66; iter: 0; batch classifier loss: 0.177161; batch adversarial loss: 0.459632\n",
      "epoch 67; iter: 0; batch classifier loss: 0.194029; batch adversarial loss: 0.471741\n",
      "epoch 68; iter: 0; batch classifier loss: 0.222056; batch adversarial loss: 0.470868\n",
      "epoch 69; iter: 0; batch classifier loss: 0.155551; batch adversarial loss: 0.387126\n",
      "epoch 70; iter: 0; batch classifier loss: 0.168564; batch adversarial loss: 0.434861\n",
      "epoch 71; iter: 0; batch classifier loss: 0.238962; batch adversarial loss: 0.518831\n",
      "epoch 72; iter: 0; batch classifier loss: 0.188936; batch adversarial loss: 0.446881\n",
      "epoch 73; iter: 0; batch classifier loss: 0.211855; batch adversarial loss: 0.374651\n",
      "epoch 74; iter: 0; batch classifier loss: 0.202016; batch adversarial loss: 0.482896\n",
      "epoch 75; iter: 0; batch classifier loss: 0.155721; batch adversarial loss: 0.421409\n",
      "epoch 76; iter: 0; batch classifier loss: 0.156406; batch adversarial loss: 0.531125\n",
      "epoch 77; iter: 0; batch classifier loss: 0.274578; batch adversarial loss: 0.471126\n",
      "epoch 78; iter: 0; batch classifier loss: 0.131118; batch adversarial loss: 0.519509\n",
      "epoch 79; iter: 0; batch classifier loss: 0.185081; batch adversarial loss: 0.397378\n",
      "epoch 80; iter: 0; batch classifier loss: 0.208101; batch adversarial loss: 0.507107\n",
      "epoch 81; iter: 0; batch classifier loss: 0.185947; batch adversarial loss: 0.422884\n",
      "epoch 82; iter: 0; batch classifier loss: 0.161510; batch adversarial loss: 0.410541\n",
      "epoch 83; iter: 0; batch classifier loss: 0.172757; batch adversarial loss: 0.520089\n",
      "epoch 84; iter: 0; batch classifier loss: 0.246726; batch adversarial loss: 0.483077\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090105; batch adversarial loss: 0.483052\n",
      "epoch 86; iter: 0; batch classifier loss: 0.138230; batch adversarial loss: 0.420017\n",
      "epoch 87; iter: 0; batch classifier loss: 0.118230; batch adversarial loss: 0.458287\n",
      "epoch 88; iter: 0; batch classifier loss: 0.174713; batch adversarial loss: 0.409871\n",
      "epoch 89; iter: 0; batch classifier loss: 0.246288; batch adversarial loss: 0.457170\n",
      "epoch 90; iter: 0; batch classifier loss: 0.184333; batch adversarial loss: 0.436470\n",
      "epoch 91; iter: 0; batch classifier loss: 0.155038; batch adversarial loss: 0.495116\n",
      "epoch 92; iter: 0; batch classifier loss: 0.145343; batch adversarial loss: 0.521215\n",
      "epoch 93; iter: 0; batch classifier loss: 0.147755; batch adversarial loss: 0.435595\n",
      "epoch 94; iter: 0; batch classifier loss: 0.122916; batch adversarial loss: 0.399903\n",
      "epoch 95; iter: 0; batch classifier loss: 0.141589; batch adversarial loss: 0.518003\n",
      "epoch 96; iter: 0; batch classifier loss: 0.145459; batch adversarial loss: 0.470182\n",
      "epoch 97; iter: 0; batch classifier loss: 0.148726; batch adversarial loss: 0.384166\n",
      "epoch 98; iter: 0; batch classifier loss: 0.139852; batch adversarial loss: 0.591600\n",
      "epoch 99; iter: 0; batch classifier loss: 0.121236; batch adversarial loss: 0.464677\n",
      "epoch 100; iter: 0; batch classifier loss: 0.106900; batch adversarial loss: 0.504602\n",
      "epoch 101; iter: 0; batch classifier loss: 0.097166; batch adversarial loss: 0.411337\n",
      "epoch 102; iter: 0; batch classifier loss: 0.131433; batch adversarial loss: 0.451820\n",
      "epoch 103; iter: 0; batch classifier loss: 0.101941; batch adversarial loss: 0.499081\n",
      "epoch 104; iter: 0; batch classifier loss: 0.100568; batch adversarial loss: 0.504119\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059009; batch adversarial loss: 0.417745\n",
      "epoch 106; iter: 0; batch classifier loss: 0.096490; batch adversarial loss: 0.433982\n",
      "epoch 107; iter: 0; batch classifier loss: 0.071015; batch adversarial loss: 0.479695\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033301; batch adversarial loss: 0.467963\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040204; batch adversarial loss: 0.492849\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048153; batch adversarial loss: 0.441443\n",
      "epoch 111; iter: 0; batch classifier loss: 0.027010; batch adversarial loss: 0.521493\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040788; batch adversarial loss: 0.441140\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029056; batch adversarial loss: 0.391348\n",
      "epoch 114; iter: 0; batch classifier loss: 0.063644; batch adversarial loss: 0.476907\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049414; batch adversarial loss: 0.504260\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039941; batch adversarial loss: 0.485973\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040523; batch adversarial loss: 0.413429\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046417; batch adversarial loss: 0.448454\n",
      "epoch 119; iter: 0; batch classifier loss: 0.068771; batch adversarial loss: 0.458984\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020081; batch adversarial loss: 0.405903\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048089; batch adversarial loss: 0.433958\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037282; batch adversarial loss: 0.440403\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025002; batch adversarial loss: 0.409688\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027206; batch adversarial loss: 0.484961\n",
      "epoch 125; iter: 0; batch classifier loss: 0.063837; batch adversarial loss: 0.503744\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023896; batch adversarial loss: 0.489615\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033530; batch adversarial loss: 0.540065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.024922; batch adversarial loss: 0.471717\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043188; batch adversarial loss: 0.467355\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051983; batch adversarial loss: 0.473148\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045422; batch adversarial loss: 0.516633\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037588; batch adversarial loss: 0.527219\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028420; batch adversarial loss: 0.534267\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050246; batch adversarial loss: 0.392990\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040748; batch adversarial loss: 0.458310\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025712; batch adversarial loss: 0.579666\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012541; batch adversarial loss: 0.542985\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026926; batch adversarial loss: 0.469769\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025676; batch adversarial loss: 0.436315\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032538; batch adversarial loss: 0.417304\n",
      "epoch 141; iter: 0; batch classifier loss: 0.068540; batch adversarial loss: 0.516390\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031108; batch adversarial loss: 0.427034\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018782; batch adversarial loss: 0.505810\n",
      "epoch 144; iter: 0; batch classifier loss: 0.011089; batch adversarial loss: 0.451956\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026759; batch adversarial loss: 0.495086\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040887; batch adversarial loss: 0.412818\n",
      "epoch 147; iter: 0; batch classifier loss: 0.004807; batch adversarial loss: 0.433859\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028063; batch adversarial loss: 0.467953\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013380; batch adversarial loss: 0.442183\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012546; batch adversarial loss: 0.449311\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024678; batch adversarial loss: 0.492101\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023236; batch adversarial loss: 0.433693\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010625; batch adversarial loss: 0.510161\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026979; batch adversarial loss: 0.539994\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023675; batch adversarial loss: 0.441781\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027883; batch adversarial loss: 0.476917\n",
      "epoch 157; iter: 0; batch classifier loss: 0.008930; batch adversarial loss: 0.473722\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013158; batch adversarial loss: 0.457820\n",
      "epoch 159; iter: 0; batch classifier loss: 0.004575; batch adversarial loss: 0.451228\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013240; batch adversarial loss: 0.466226\n",
      "epoch 161; iter: 0; batch classifier loss: 0.006296; batch adversarial loss: 0.464461\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010805; batch adversarial loss: 0.449481\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023829; batch adversarial loss: 0.468369\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035923; batch adversarial loss: 0.397936\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013803; batch adversarial loss: 0.458061\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026620; batch adversarial loss: 0.504707\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022143; batch adversarial loss: 0.450599\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029760; batch adversarial loss: 0.338302\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013030; batch adversarial loss: 0.559946\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024244; batch adversarial loss: 0.449176\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011369; batch adversarial loss: 0.478044\n",
      "epoch 172; iter: 0; batch classifier loss: 0.039896; batch adversarial loss: 0.427859\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024857; batch adversarial loss: 0.558846\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021976; batch adversarial loss: 0.482997\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012678; batch adversarial loss: 0.381989\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010310; batch adversarial loss: 0.441042\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010427; batch adversarial loss: 0.402520\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008301; batch adversarial loss: 0.434632\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039198; batch adversarial loss: 0.463131\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013084; batch adversarial loss: 0.495192\n",
      "epoch 181; iter: 0; batch classifier loss: 0.003682; batch adversarial loss: 0.534828\n",
      "epoch 182; iter: 0; batch classifier loss: 0.005020; batch adversarial loss: 0.494584\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024825; batch adversarial loss: 0.504738\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030638; batch adversarial loss: 0.451426\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009415; batch adversarial loss: 0.458356\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028068; batch adversarial loss: 0.525348\n",
      "epoch 187; iter: 0; batch classifier loss: 0.037334; batch adversarial loss: 0.427394\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016388; batch adversarial loss: 0.484564\n",
      "epoch 189; iter: 0; batch classifier loss: 0.043719; batch adversarial loss: 0.533563\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016106; batch adversarial loss: 0.458014\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029121; batch adversarial loss: 0.404380\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013086; batch adversarial loss: 0.412094\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012118; batch adversarial loss: 0.565960\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010907; batch adversarial loss: 0.475203\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016779; batch adversarial loss: 0.516125\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010802; batch adversarial loss: 0.524730\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022221; batch adversarial loss: 0.448962\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027070; batch adversarial loss: 0.444812\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004322; batch adversarial loss: 0.492101\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677257; batch adversarial loss: 0.990510\n",
      "epoch 1; iter: 0; batch classifier loss: 0.582706; batch adversarial loss: 1.177215\n",
      "epoch 2; iter: 0; batch classifier loss: 0.800939; batch adversarial loss: 1.175986\n",
      "epoch 3; iter: 0; batch classifier loss: 1.027165; batch adversarial loss: 1.133446\n",
      "epoch 4; iter: 0; batch classifier loss: 0.997566; batch adversarial loss: 1.031655\n",
      "epoch 5; iter: 0; batch classifier loss: 0.915758; batch adversarial loss: 0.937824\n",
      "epoch 6; iter: 0; batch classifier loss: 1.028716; batch adversarial loss: 0.846551\n",
      "epoch 7; iter: 0; batch classifier loss: 1.009234; batch adversarial loss: 0.767149\n",
      "epoch 8; iter: 0; batch classifier loss: 0.732760; batch adversarial loss: 0.721328\n",
      "epoch 9; iter: 0; batch classifier loss: 0.774587; batch adversarial loss: 0.677187\n",
      "epoch 10; iter: 0; batch classifier loss: 0.756474; batch adversarial loss: 0.620213\n",
      "epoch 11; iter: 0; batch classifier loss: 0.573416; batch adversarial loss: 0.605101\n",
      "epoch 12; iter: 0; batch classifier loss: 0.331590; batch adversarial loss: 0.572099\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232177; batch adversarial loss: 0.539874\n",
      "epoch 14; iter: 0; batch classifier loss: 0.271843; batch adversarial loss: 0.533498\n",
      "epoch 15; iter: 0; batch classifier loss: 0.208167; batch adversarial loss: 0.521862\n",
      "epoch 16; iter: 0; batch classifier loss: 0.206724; batch adversarial loss: 0.527464\n",
      "epoch 17; iter: 0; batch classifier loss: 0.252261; batch adversarial loss: 0.533946\n",
      "epoch 18; iter: 0; batch classifier loss: 0.220440; batch adversarial loss: 0.498149\n",
      "epoch 19; iter: 0; batch classifier loss: 0.207245; batch adversarial loss: 0.485685\n",
      "epoch 20; iter: 0; batch classifier loss: 0.284338; batch adversarial loss: 0.442519\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202528; batch adversarial loss: 0.469718\n",
      "epoch 22; iter: 0; batch classifier loss: 0.137274; batch adversarial loss: 0.469123\n",
      "epoch 23; iter: 0; batch classifier loss: 0.165362; batch adversarial loss: 0.489791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.130878; batch adversarial loss: 0.484009\n",
      "epoch 25; iter: 0; batch classifier loss: 0.107423; batch adversarial loss: 0.509427\n",
      "epoch 26; iter: 0; batch classifier loss: 0.116777; batch adversarial loss: 0.432920\n",
      "epoch 27; iter: 0; batch classifier loss: 0.130145; batch adversarial loss: 0.410271\n",
      "epoch 28; iter: 0; batch classifier loss: 0.147856; batch adversarial loss: 0.467112\n",
      "epoch 29; iter: 0; batch classifier loss: 0.112544; batch adversarial loss: 0.420409\n",
      "epoch 30; iter: 0; batch classifier loss: 0.092911; batch adversarial loss: 0.508216\n",
      "epoch 31; iter: 0; batch classifier loss: 0.110193; batch adversarial loss: 0.401509\n",
      "epoch 32; iter: 0; batch classifier loss: 0.157860; batch adversarial loss: 0.484699\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123864; batch adversarial loss: 0.447622\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122929; batch adversarial loss: 0.502418\n",
      "epoch 35; iter: 0; batch classifier loss: 0.102541; batch adversarial loss: 0.455016\n",
      "epoch 36; iter: 0; batch classifier loss: 0.089135; batch adversarial loss: 0.428874\n",
      "epoch 37; iter: 0; batch classifier loss: 0.080679; batch adversarial loss: 0.400294\n",
      "epoch 38; iter: 0; batch classifier loss: 0.076717; batch adversarial loss: 0.414648\n",
      "epoch 39; iter: 0; batch classifier loss: 0.064105; batch adversarial loss: 0.392480\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091382; batch adversarial loss: 0.492342\n",
      "epoch 41; iter: 0; batch classifier loss: 0.115214; batch adversarial loss: 0.387380\n",
      "epoch 42; iter: 0; batch classifier loss: 0.076600; batch adversarial loss: 0.445047\n",
      "epoch 43; iter: 0; batch classifier loss: 0.137354; batch adversarial loss: 0.425523\n",
      "epoch 44; iter: 0; batch classifier loss: 0.074777; batch adversarial loss: 0.435033\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089378; batch adversarial loss: 0.407208\n",
      "epoch 46; iter: 0; batch classifier loss: 0.039308; batch adversarial loss: 0.439432\n",
      "epoch 47; iter: 0; batch classifier loss: 0.070005; batch adversarial loss: 0.471429\n",
      "epoch 48; iter: 0; batch classifier loss: 0.053903; batch adversarial loss: 0.445899\n",
      "epoch 49; iter: 0; batch classifier loss: 0.058390; batch adversarial loss: 0.418177\n",
      "epoch 50; iter: 0; batch classifier loss: 0.049867; batch adversarial loss: 0.450666\n",
      "epoch 51; iter: 0; batch classifier loss: 0.042575; batch adversarial loss: 0.361195\n",
      "epoch 52; iter: 0; batch classifier loss: 0.069209; batch adversarial loss: 0.416197\n",
      "epoch 53; iter: 0; batch classifier loss: 0.066952; batch adversarial loss: 0.463457\n",
      "epoch 54; iter: 0; batch classifier loss: 0.055648; batch adversarial loss: 0.469224\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072435; batch adversarial loss: 0.438282\n",
      "epoch 56; iter: 0; batch classifier loss: 0.076244; batch adversarial loss: 0.454921\n",
      "epoch 57; iter: 0; batch classifier loss: 0.139399; batch adversarial loss: 0.416290\n",
      "epoch 58; iter: 0; batch classifier loss: 0.053116; batch adversarial loss: 0.522016\n",
      "epoch 59; iter: 0; batch classifier loss: 0.045470; batch adversarial loss: 0.434748\n",
      "epoch 60; iter: 0; batch classifier loss: 0.058091; batch adversarial loss: 0.585459\n",
      "epoch 61; iter: 0; batch classifier loss: 0.062978; batch adversarial loss: 0.517631\n",
      "epoch 62; iter: 0; batch classifier loss: 0.065429; batch adversarial loss: 0.383762\n",
      "epoch 63; iter: 0; batch classifier loss: 0.053717; batch adversarial loss: 0.488432\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066526; batch adversarial loss: 0.500870\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122755; batch adversarial loss: 0.466794\n",
      "epoch 66; iter: 0; batch classifier loss: 0.069250; batch adversarial loss: 0.455109\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079365; batch adversarial loss: 0.553503\n",
      "epoch 68; iter: 0; batch classifier loss: 0.052141; batch adversarial loss: 0.318667\n",
      "epoch 69; iter: 0; batch classifier loss: 0.053607; batch adversarial loss: 0.425632\n",
      "epoch 70; iter: 0; batch classifier loss: 0.036200; batch adversarial loss: 0.428684\n",
      "epoch 71; iter: 0; batch classifier loss: 0.065977; batch adversarial loss: 0.486480\n",
      "epoch 72; iter: 0; batch classifier loss: 0.086187; batch adversarial loss: 0.456968\n",
      "epoch 73; iter: 0; batch classifier loss: 0.066989; batch adversarial loss: 0.537733\n",
      "epoch 74; iter: 0; batch classifier loss: 0.077711; batch adversarial loss: 0.423302\n",
      "epoch 75; iter: 0; batch classifier loss: 0.078443; batch adversarial loss: 0.423485\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046065; batch adversarial loss: 0.585365\n",
      "epoch 77; iter: 0; batch classifier loss: 0.049888; batch adversarial loss: 0.399322\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056008; batch adversarial loss: 0.383146\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071704; batch adversarial loss: 0.447040\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053762; batch adversarial loss: 0.480047\n",
      "epoch 81; iter: 0; batch classifier loss: 0.033373; batch adversarial loss: 0.447935\n",
      "epoch 82; iter: 0; batch classifier loss: 0.024030; batch adversarial loss: 0.388429\n",
      "epoch 83; iter: 0; batch classifier loss: 0.042522; batch adversarial loss: 0.453344\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046511; batch adversarial loss: 0.404296\n",
      "epoch 85; iter: 0; batch classifier loss: 0.082409; batch adversarial loss: 0.490396\n",
      "epoch 86; iter: 0; batch classifier loss: 0.036554; batch adversarial loss: 0.453751\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049382; batch adversarial loss: 0.351649\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058486; batch adversarial loss: 0.472381\n",
      "epoch 89; iter: 0; batch classifier loss: 0.032503; batch adversarial loss: 0.412371\n",
      "epoch 90; iter: 0; batch classifier loss: 0.076312; batch adversarial loss: 0.458469\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064845; batch adversarial loss: 0.473815\n",
      "epoch 92; iter: 0; batch classifier loss: 0.053451; batch adversarial loss: 0.498236\n",
      "epoch 93; iter: 0; batch classifier loss: 0.030911; batch adversarial loss: 0.413889\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033995; batch adversarial loss: 0.462842\n",
      "epoch 95; iter: 0; batch classifier loss: 0.017951; batch adversarial loss: 0.386604\n",
      "epoch 96; iter: 0; batch classifier loss: 0.090145; batch adversarial loss: 0.421127\n",
      "epoch 97; iter: 0; batch classifier loss: 0.025124; batch adversarial loss: 0.476701\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062444; batch adversarial loss: 0.350257\n",
      "epoch 99; iter: 0; batch classifier loss: 0.099783; batch adversarial loss: 0.484168\n",
      "epoch 100; iter: 0; batch classifier loss: 0.032165; batch adversarial loss: 0.421983\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048469; batch adversarial loss: 0.499137\n",
      "epoch 102; iter: 0; batch classifier loss: 0.092796; batch adversarial loss: 0.344663\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064509; batch adversarial loss: 0.438745\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035338; batch adversarial loss: 0.403821\n",
      "epoch 105; iter: 0; batch classifier loss: 0.073682; batch adversarial loss: 0.510627\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036265; batch adversarial loss: 0.404234\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034774; batch adversarial loss: 0.433805\n",
      "epoch 108; iter: 0; batch classifier loss: 0.011628; batch adversarial loss: 0.440192\n",
      "epoch 109; iter: 0; batch classifier loss: 0.100974; batch adversarial loss: 0.493520\n",
      "epoch 110; iter: 0; batch classifier loss: 0.079542; batch adversarial loss: 0.499077\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043686; batch adversarial loss: 0.521776\n",
      "epoch 112; iter: 0; batch classifier loss: 0.069690; batch adversarial loss: 0.533679\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047890; batch adversarial loss: 0.425190\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047488; batch adversarial loss: 0.506096\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042390; batch adversarial loss: 0.453999\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041321; batch adversarial loss: 0.403188\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029207; batch adversarial loss: 0.490762\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039802; batch adversarial loss: 0.405690\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043701; batch adversarial loss: 0.428552\n",
      "epoch 120; iter: 0; batch classifier loss: 0.075902; batch adversarial loss: 0.451017\n",
      "epoch 121; iter: 0; batch classifier loss: 0.067898; batch adversarial loss: 0.390013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.044937; batch adversarial loss: 0.396369\n",
      "epoch 123; iter: 0; batch classifier loss: 0.078571; batch adversarial loss: 0.483789\n",
      "epoch 124; iter: 0; batch classifier loss: 0.028776; batch adversarial loss: 0.373083\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032458; batch adversarial loss: 0.458880\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055723; batch adversarial loss: 0.436084\n",
      "epoch 127; iter: 0; batch classifier loss: 0.071801; batch adversarial loss: 0.436579\n",
      "epoch 128; iter: 0; batch classifier loss: 0.080910; batch adversarial loss: 0.432778\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035960; batch adversarial loss: 0.389704\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050169; batch adversarial loss: 0.511204\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044473; batch adversarial loss: 0.448436\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057874; batch adversarial loss: 0.411529\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038942; batch adversarial loss: 0.443966\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043221; batch adversarial loss: 0.447632\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044513; batch adversarial loss: 0.439075\n",
      "epoch 136; iter: 0; batch classifier loss: 0.073347; batch adversarial loss: 0.400330\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028261; batch adversarial loss: 0.436450\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026471; batch adversarial loss: 0.438056\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040227; batch adversarial loss: 0.380765\n",
      "epoch 140; iter: 0; batch classifier loss: 0.073120; batch adversarial loss: 0.403863\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049997; batch adversarial loss: 0.409148\n",
      "epoch 142; iter: 0; batch classifier loss: 0.051292; batch adversarial loss: 0.393362\n",
      "epoch 143; iter: 0; batch classifier loss: 0.055104; batch adversarial loss: 0.484101\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047227; batch adversarial loss: 0.437160\n",
      "epoch 145; iter: 0; batch classifier loss: 0.047532; batch adversarial loss: 0.508730\n",
      "epoch 146; iter: 0; batch classifier loss: 0.065067; batch adversarial loss: 0.434289\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018334; batch adversarial loss: 0.344412\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040696; batch adversarial loss: 0.412401\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042440; batch adversarial loss: 0.452492\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042132; batch adversarial loss: 0.360235\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039836; batch adversarial loss: 0.506315\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028322; batch adversarial loss: 0.452344\n",
      "epoch 153; iter: 0; batch classifier loss: 0.047892; batch adversarial loss: 0.535396\n",
      "epoch 154; iter: 0; batch classifier loss: 0.057690; batch adversarial loss: 0.411163\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036236; batch adversarial loss: 0.435055\n",
      "epoch 156; iter: 0; batch classifier loss: 0.056009; batch adversarial loss: 0.446497\n",
      "epoch 157; iter: 0; batch classifier loss: 0.075476; batch adversarial loss: 0.511279\n",
      "epoch 158; iter: 0; batch classifier loss: 0.073657; batch adversarial loss: 0.449560\n",
      "epoch 159; iter: 0; batch classifier loss: 0.073395; batch adversarial loss: 0.414721\n",
      "epoch 160; iter: 0; batch classifier loss: 0.120184; batch adversarial loss: 0.349308\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028409; batch adversarial loss: 0.468129\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043500; batch adversarial loss: 0.436747\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033537; batch adversarial loss: 0.437300\n",
      "epoch 164; iter: 0; batch classifier loss: 0.059517; batch adversarial loss: 0.438505\n",
      "epoch 165; iter: 0; batch classifier loss: 0.051354; batch adversarial loss: 0.447458\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030496; batch adversarial loss: 0.488763\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020221; batch adversarial loss: 0.364290\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024328; batch adversarial loss: 0.424692\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025324; batch adversarial loss: 0.396802\n",
      "epoch 170; iter: 0; batch classifier loss: 0.074680; batch adversarial loss: 0.394187\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033123; batch adversarial loss: 0.406801\n",
      "epoch 172; iter: 0; batch classifier loss: 0.045096; batch adversarial loss: 0.508848\n",
      "epoch 173; iter: 0; batch classifier loss: 0.083515; batch adversarial loss: 0.458963\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027097; batch adversarial loss: 0.418832\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022436; batch adversarial loss: 0.473723\n",
      "epoch 176; iter: 0; batch classifier loss: 0.061292; batch adversarial loss: 0.426636\n",
      "epoch 177; iter: 0; batch classifier loss: 0.072681; batch adversarial loss: 0.396679\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040949; batch adversarial loss: 0.354712\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030994; batch adversarial loss: 0.406353\n",
      "epoch 180; iter: 0; batch classifier loss: 0.036314; batch adversarial loss: 0.433600\n",
      "epoch 181; iter: 0; batch classifier loss: 0.077129; batch adversarial loss: 0.545931\n",
      "epoch 182; iter: 0; batch classifier loss: 0.040214; batch adversarial loss: 0.449849\n",
      "epoch 183; iter: 0; batch classifier loss: 0.049420; batch adversarial loss: 0.394796\n",
      "epoch 184; iter: 0; batch classifier loss: 0.043896; batch adversarial loss: 0.379830\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025054; batch adversarial loss: 0.468859\n",
      "epoch 186; iter: 0; batch classifier loss: 0.058609; batch adversarial loss: 0.435497\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032106; batch adversarial loss: 0.396525\n",
      "epoch 188; iter: 0; batch classifier loss: 0.069794; batch adversarial loss: 0.481250\n",
      "epoch 189; iter: 0; batch classifier loss: 0.047295; batch adversarial loss: 0.446842\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037379; batch adversarial loss: 0.517924\n",
      "epoch 191; iter: 0; batch classifier loss: 0.065766; batch adversarial loss: 0.458516\n",
      "epoch 192; iter: 0; batch classifier loss: 0.056685; batch adversarial loss: 0.436987\n",
      "epoch 193; iter: 0; batch classifier loss: 0.058108; batch adversarial loss: 0.423684\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039867; batch adversarial loss: 0.436711\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034883; batch adversarial loss: 0.468617\n",
      "epoch 196; iter: 0; batch classifier loss: 0.070814; batch adversarial loss: 0.405028\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033359; batch adversarial loss: 0.438430\n",
      "epoch 198; iter: 0; batch classifier loss: 0.050150; batch adversarial loss: 0.406621\n",
      "epoch 199; iter: 0; batch classifier loss: 0.034127; batch adversarial loss: 0.486504\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693177; batch adversarial loss: 0.704455\n",
      "epoch 1; iter: 0; batch classifier loss: 0.472093; batch adversarial loss: 0.676542\n",
      "epoch 2; iter: 0; batch classifier loss: 0.410510; batch adversarial loss: 0.636255\n",
      "epoch 3; iter: 0; batch classifier loss: 0.359349; batch adversarial loss: 0.617568\n",
      "epoch 4; iter: 0; batch classifier loss: 0.389899; batch adversarial loss: 0.562324\n",
      "epoch 5; iter: 0; batch classifier loss: 0.376241; batch adversarial loss: 0.556138\n",
      "epoch 6; iter: 0; batch classifier loss: 0.305737; batch adversarial loss: 0.506611\n",
      "epoch 7; iter: 0; batch classifier loss: 0.253450; batch adversarial loss: 0.525028\n",
      "epoch 8; iter: 0; batch classifier loss: 0.304475; batch adversarial loss: 0.490571\n",
      "epoch 9; iter: 0; batch classifier loss: 0.268908; batch adversarial loss: 0.493058\n",
      "epoch 10; iter: 0; batch classifier loss: 0.249651; batch adversarial loss: 0.448920\n",
      "epoch 11; iter: 0; batch classifier loss: 0.240213; batch adversarial loss: 0.458697\n",
      "epoch 12; iter: 0; batch classifier loss: 0.273321; batch adversarial loss: 0.526512\n",
      "epoch 13; iter: 0; batch classifier loss: 0.183804; batch adversarial loss: 0.477120\n",
      "epoch 14; iter: 0; batch classifier loss: 0.191826; batch adversarial loss: 0.548436\n",
      "epoch 15; iter: 0; batch classifier loss: 0.155079; batch adversarial loss: 0.482115\n",
      "epoch 16; iter: 0; batch classifier loss: 0.202178; batch adversarial loss: 0.461243\n",
      "epoch 17; iter: 0; batch classifier loss: 0.126015; batch adversarial loss: 0.513212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.142728; batch adversarial loss: 0.415539\n",
      "epoch 19; iter: 0; batch classifier loss: 0.162217; batch adversarial loss: 0.459133\n",
      "epoch 20; iter: 0; batch classifier loss: 0.133814; batch adversarial loss: 0.489190\n",
      "epoch 21; iter: 0; batch classifier loss: 0.108269; batch adversarial loss: 0.482610\n",
      "epoch 22; iter: 0; batch classifier loss: 0.136572; batch adversarial loss: 0.506374\n",
      "epoch 23; iter: 0; batch classifier loss: 0.134526; batch adversarial loss: 0.440844\n",
      "epoch 24; iter: 0; batch classifier loss: 0.143498; batch adversarial loss: 0.426859\n",
      "epoch 25; iter: 0; batch classifier loss: 0.147543; batch adversarial loss: 0.567086\n",
      "epoch 26; iter: 0; batch classifier loss: 0.236853; batch adversarial loss: 0.509220\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152306; batch adversarial loss: 0.461261\n",
      "epoch 28; iter: 0; batch classifier loss: 0.209603; batch adversarial loss: 0.559368\n",
      "epoch 29; iter: 0; batch classifier loss: 0.172693; batch adversarial loss: 0.503818\n",
      "epoch 30; iter: 0; batch classifier loss: 0.165872; batch adversarial loss: 0.526512\n",
      "epoch 31; iter: 0; batch classifier loss: 0.116516; batch adversarial loss: 0.456911\n",
      "epoch 32; iter: 0; batch classifier loss: 0.213249; batch adversarial loss: 0.596793\n",
      "epoch 33; iter: 0; batch classifier loss: 0.201611; batch adversarial loss: 0.477201\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233160; batch adversarial loss: 0.519925\n",
      "epoch 35; iter: 0; batch classifier loss: 0.201120; batch adversarial loss: 0.546583\n",
      "epoch 36; iter: 0; batch classifier loss: 0.225791; batch adversarial loss: 0.552432\n",
      "epoch 37; iter: 0; batch classifier loss: 0.188494; batch adversarial loss: 0.430364\n",
      "epoch 38; iter: 0; batch classifier loss: 0.207775; batch adversarial loss: 0.576541\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106522; batch adversarial loss: 0.462930\n",
      "epoch 40; iter: 0; batch classifier loss: 0.097064; batch adversarial loss: 0.406630\n",
      "epoch 41; iter: 0; batch classifier loss: 0.094202; batch adversarial loss: 0.373379\n",
      "epoch 42; iter: 0; batch classifier loss: 0.072907; batch adversarial loss: 0.456407\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110027; batch adversarial loss: 0.473109\n",
      "epoch 44; iter: 0; batch classifier loss: 0.064751; batch adversarial loss: 0.498246\n",
      "epoch 45; iter: 0; batch classifier loss: 0.161394; batch adversarial loss: 0.509812\n",
      "epoch 46; iter: 0; batch classifier loss: 0.099271; batch adversarial loss: 0.487220\n",
      "epoch 47; iter: 0; batch classifier loss: 0.050628; batch adversarial loss: 0.524914\n",
      "epoch 48; iter: 0; batch classifier loss: 0.071957; batch adversarial loss: 0.430016\n",
      "epoch 49; iter: 0; batch classifier loss: 0.063229; batch adversarial loss: 0.425653\n",
      "epoch 50; iter: 0; batch classifier loss: 0.078878; batch adversarial loss: 0.488831\n",
      "epoch 51; iter: 0; batch classifier loss: 0.044883; batch adversarial loss: 0.536171\n",
      "epoch 52; iter: 0; batch classifier loss: 0.107080; batch adversarial loss: 0.500838\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076603; batch adversarial loss: 0.418093\n",
      "epoch 54; iter: 0; batch classifier loss: 0.076395; batch adversarial loss: 0.427568\n",
      "epoch 55; iter: 0; batch classifier loss: 0.038188; batch adversarial loss: 0.452849\n",
      "epoch 56; iter: 0; batch classifier loss: 0.060244; batch adversarial loss: 0.483516\n",
      "epoch 57; iter: 0; batch classifier loss: 0.049941; batch adversarial loss: 0.499792\n",
      "epoch 58; iter: 0; batch classifier loss: 0.060598; batch adversarial loss: 0.405983\n",
      "epoch 59; iter: 0; batch classifier loss: 0.053960; batch adversarial loss: 0.519454\n",
      "epoch 60; iter: 0; batch classifier loss: 0.057996; batch adversarial loss: 0.461059\n",
      "epoch 61; iter: 0; batch classifier loss: 0.065077; batch adversarial loss: 0.568980\n",
      "epoch 62; iter: 0; batch classifier loss: 0.059396; batch adversarial loss: 0.452213\n",
      "epoch 63; iter: 0; batch classifier loss: 0.053146; batch adversarial loss: 0.414459\n",
      "epoch 64; iter: 0; batch classifier loss: 0.064389; batch adversarial loss: 0.520613\n",
      "epoch 65; iter: 0; batch classifier loss: 0.037827; batch adversarial loss: 0.465267\n",
      "epoch 66; iter: 0; batch classifier loss: 0.071511; batch adversarial loss: 0.476059\n",
      "epoch 67; iter: 0; batch classifier loss: 0.077315; batch adversarial loss: 0.464428\n",
      "epoch 68; iter: 0; batch classifier loss: 0.028243; batch adversarial loss: 0.501864\n",
      "epoch 69; iter: 0; batch classifier loss: 0.054898; batch adversarial loss: 0.462404\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082255; batch adversarial loss: 0.433572\n",
      "epoch 71; iter: 0; batch classifier loss: 0.075585; batch adversarial loss: 0.412170\n",
      "epoch 72; iter: 0; batch classifier loss: 0.041999; batch adversarial loss: 0.511031\n",
      "epoch 73; iter: 0; batch classifier loss: 0.028158; batch adversarial loss: 0.408306\n",
      "epoch 74; iter: 0; batch classifier loss: 0.051521; batch adversarial loss: 0.417531\n",
      "epoch 75; iter: 0; batch classifier loss: 0.080457; batch adversarial loss: 0.385661\n",
      "epoch 76; iter: 0; batch classifier loss: 0.027999; batch adversarial loss: 0.453745\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055543; batch adversarial loss: 0.463279\n",
      "epoch 78; iter: 0; batch classifier loss: 0.049908; batch adversarial loss: 0.410507\n",
      "epoch 79; iter: 0; batch classifier loss: 0.023252; batch adversarial loss: 0.443636\n",
      "epoch 80; iter: 0; batch classifier loss: 0.028892; batch adversarial loss: 0.394971\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065988; batch adversarial loss: 0.411299\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061799; batch adversarial loss: 0.438545\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074247; batch adversarial loss: 0.469527\n",
      "epoch 84; iter: 0; batch classifier loss: 0.026228; batch adversarial loss: 0.555415\n",
      "epoch 85; iter: 0; batch classifier loss: 0.049362; batch adversarial loss: 0.455680\n",
      "epoch 86; iter: 0; batch classifier loss: 0.048737; batch adversarial loss: 0.458147\n",
      "epoch 87; iter: 0; batch classifier loss: 0.040114; batch adversarial loss: 0.435659\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051256; batch adversarial loss: 0.444657\n",
      "epoch 89; iter: 0; batch classifier loss: 0.041776; batch adversarial loss: 0.479099\n",
      "epoch 90; iter: 0; batch classifier loss: 0.019921; batch adversarial loss: 0.465799\n",
      "epoch 91; iter: 0; batch classifier loss: 0.051438; batch adversarial loss: 0.386353\n",
      "epoch 92; iter: 0; batch classifier loss: 0.042059; batch adversarial loss: 0.412360\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043472; batch adversarial loss: 0.411297\n",
      "epoch 94; iter: 0; batch classifier loss: 0.037116; batch adversarial loss: 0.545789\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042168; batch adversarial loss: 0.475162\n",
      "epoch 96; iter: 0; batch classifier loss: 0.054586; batch adversarial loss: 0.490138\n",
      "epoch 97; iter: 0; batch classifier loss: 0.024624; batch adversarial loss: 0.408801\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050977; batch adversarial loss: 0.354785\n",
      "epoch 99; iter: 0; batch classifier loss: 0.027002; batch adversarial loss: 0.389695\n",
      "epoch 100; iter: 0; batch classifier loss: 0.090786; batch adversarial loss: 0.363680\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039531; batch adversarial loss: 0.573772\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050506; batch adversarial loss: 0.438894\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046666; batch adversarial loss: 0.494451\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071986; batch adversarial loss: 0.528640\n",
      "epoch 105; iter: 0; batch classifier loss: 0.070147; batch adversarial loss: 0.450047\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042196; batch adversarial loss: 0.477879\n",
      "epoch 107; iter: 0; batch classifier loss: 0.023040; batch adversarial loss: 0.563358\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039224; batch adversarial loss: 0.463839\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029793; batch adversarial loss: 0.440862\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041692; batch adversarial loss: 0.458042\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039380; batch adversarial loss: 0.334999\n",
      "epoch 112; iter: 0; batch classifier loss: 0.020512; batch adversarial loss: 0.503905\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028474; batch adversarial loss: 0.473089\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040016; batch adversarial loss: 0.382590\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057157; batch adversarial loss: 0.456774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.030067; batch adversarial loss: 0.450568\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034606; batch adversarial loss: 0.507201\n",
      "epoch 118; iter: 0; batch classifier loss: 0.070859; batch adversarial loss: 0.401065\n",
      "epoch 119; iter: 0; batch classifier loss: 0.013866; batch adversarial loss: 0.494239\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034146; batch adversarial loss: 0.441088\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049077; batch adversarial loss: 0.505993\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035582; batch adversarial loss: 0.360698\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048377; batch adversarial loss: 0.572149\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040071; batch adversarial loss: 0.553521\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036013; batch adversarial loss: 0.472194\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042704; batch adversarial loss: 0.414157\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048638; batch adversarial loss: 0.508798\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047156; batch adversarial loss: 0.487699\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029251; batch adversarial loss: 0.406460\n",
      "epoch 130; iter: 0; batch classifier loss: 0.080601; batch adversarial loss: 0.378393\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045849; batch adversarial loss: 0.476563\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048000; batch adversarial loss: 0.443641\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052113; batch adversarial loss: 0.373498\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020402; batch adversarial loss: 0.466703\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021308; batch adversarial loss: 0.418656\n",
      "epoch 136; iter: 0; batch classifier loss: 0.014609; batch adversarial loss: 0.437840\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042070; batch adversarial loss: 0.527766\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032408; batch adversarial loss: 0.401573\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022582; batch adversarial loss: 0.459716\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045291; batch adversarial loss: 0.539895\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038011; batch adversarial loss: 0.474934\n",
      "epoch 142; iter: 0; batch classifier loss: 0.011469; batch adversarial loss: 0.443827\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026534; batch adversarial loss: 0.475622\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038621; batch adversarial loss: 0.289766\n",
      "epoch 145; iter: 0; batch classifier loss: 0.053088; batch adversarial loss: 0.523305\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034459; batch adversarial loss: 0.475660\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038755; batch adversarial loss: 0.461824\n",
      "epoch 148; iter: 0; batch classifier loss: 0.094071; batch adversarial loss: 0.409195\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015490; batch adversarial loss: 0.421825\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030004; batch adversarial loss: 0.435748\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031200; batch adversarial loss: 0.435376\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031762; batch adversarial loss: 0.588890\n",
      "epoch 153; iter: 0; batch classifier loss: 0.041931; batch adversarial loss: 0.432845\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012585; batch adversarial loss: 0.418747\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025969; batch adversarial loss: 0.496493\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026445; batch adversarial loss: 0.396815\n",
      "epoch 157; iter: 0; batch classifier loss: 0.052694; batch adversarial loss: 0.412050\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007424; batch adversarial loss: 0.476732\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016845; batch adversarial loss: 0.490756\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027748; batch adversarial loss: 0.329540\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015467; batch adversarial loss: 0.448513\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028292; batch adversarial loss: 0.527882\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022820; batch adversarial loss: 0.501149\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031283; batch adversarial loss: 0.426943\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023115; batch adversarial loss: 0.479639\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034352; batch adversarial loss: 0.509824\n",
      "epoch 167; iter: 0; batch classifier loss: 0.004263; batch adversarial loss: 0.474110\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029408; batch adversarial loss: 0.451204\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044067; batch adversarial loss: 0.436053\n",
      "epoch 170; iter: 0; batch classifier loss: 0.064357; batch adversarial loss: 0.517259\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038588; batch adversarial loss: 0.484978\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025379; batch adversarial loss: 0.500805\n",
      "epoch 173; iter: 0; batch classifier loss: 0.047082; batch adversarial loss: 0.465568\n",
      "epoch 174; iter: 0; batch classifier loss: 0.058803; batch adversarial loss: 0.439619\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029801; batch adversarial loss: 0.398609\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017702; batch adversarial loss: 0.474311\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028192; batch adversarial loss: 0.513009\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022150; batch adversarial loss: 0.416505\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017788; batch adversarial loss: 0.377436\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013143; batch adversarial loss: 0.444784\n",
      "epoch 181; iter: 0; batch classifier loss: 0.046401; batch adversarial loss: 0.399105\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009949; batch adversarial loss: 0.458829\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019659; batch adversarial loss: 0.454536\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021445; batch adversarial loss: 0.431843\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023890; batch adversarial loss: 0.467006\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030105; batch adversarial loss: 0.432497\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015958; batch adversarial loss: 0.566665\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011560; batch adversarial loss: 0.489669\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012738; batch adversarial loss: 0.418953\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029902; batch adversarial loss: 0.489521\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014779; batch adversarial loss: 0.470490\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020751; batch adversarial loss: 0.457743\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020426; batch adversarial loss: 0.471766\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013090; batch adversarial loss: 0.401098\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022010; batch adversarial loss: 0.381417\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005858; batch adversarial loss: 0.378121\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021140; batch adversarial loss: 0.447655\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030110; batch adversarial loss: 0.441003\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033541; batch adversarial loss: 0.361932\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713785; batch adversarial loss: 0.664015\n",
      "epoch 1; iter: 0; batch classifier loss: 0.429483; batch adversarial loss: 0.644956\n",
      "epoch 2; iter: 0; batch classifier loss: 0.408397; batch adversarial loss: 0.659805\n",
      "epoch 3; iter: 0; batch classifier loss: 0.460497; batch adversarial loss: 0.603064\n",
      "epoch 4; iter: 0; batch classifier loss: 0.508481; batch adversarial loss: 0.587320\n",
      "epoch 5; iter: 0; batch classifier loss: 0.486111; batch adversarial loss: 0.612092\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565003; batch adversarial loss: 0.599769\n",
      "epoch 7; iter: 0; batch classifier loss: 0.447666; batch adversarial loss: 0.572893\n",
      "epoch 8; iter: 0; batch classifier loss: 0.400282; batch adversarial loss: 0.548219\n",
      "epoch 9; iter: 0; batch classifier loss: 0.372742; batch adversarial loss: 0.597141\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374389; batch adversarial loss: 0.544266\n",
      "epoch 11; iter: 0; batch classifier loss: 0.298249; batch adversarial loss: 0.567614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.387118; batch adversarial loss: 0.507083\n",
      "epoch 13; iter: 0; batch classifier loss: 0.309299; batch adversarial loss: 0.511520\n",
      "epoch 14; iter: 0; batch classifier loss: 0.408007; batch adversarial loss: 0.601566\n",
      "epoch 15; iter: 0; batch classifier loss: 0.324600; batch adversarial loss: 0.526796\n",
      "epoch 16; iter: 0; batch classifier loss: 0.349875; batch adversarial loss: 0.453644\n",
      "epoch 17; iter: 0; batch classifier loss: 0.384466; batch adversarial loss: 0.459590\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281906; batch adversarial loss: 0.527715\n",
      "epoch 19; iter: 0; batch classifier loss: 0.248685; batch adversarial loss: 0.511680\n",
      "epoch 20; iter: 0; batch classifier loss: 0.255575; batch adversarial loss: 0.495273\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234818; batch adversarial loss: 0.406790\n",
      "epoch 22; iter: 0; batch classifier loss: 0.235842; batch adversarial loss: 0.490729\n",
      "epoch 23; iter: 0; batch classifier loss: 0.216675; batch adversarial loss: 0.505083\n",
      "epoch 24; iter: 0; batch classifier loss: 0.249489; batch adversarial loss: 0.438704\n",
      "epoch 25; iter: 0; batch classifier loss: 0.205209; batch adversarial loss: 0.478879\n",
      "epoch 26; iter: 0; batch classifier loss: 0.220648; batch adversarial loss: 0.483116\n",
      "epoch 27; iter: 0; batch classifier loss: 0.216763; batch adversarial loss: 0.415394\n",
      "epoch 28; iter: 0; batch classifier loss: 0.229830; batch adversarial loss: 0.522752\n",
      "epoch 29; iter: 0; batch classifier loss: 0.234756; batch adversarial loss: 0.514242\n",
      "epoch 30; iter: 0; batch classifier loss: 0.212071; batch adversarial loss: 0.443998\n",
      "epoch 31; iter: 0; batch classifier loss: 0.220545; batch adversarial loss: 0.472493\n",
      "epoch 32; iter: 0; batch classifier loss: 0.243355; batch adversarial loss: 0.435483\n",
      "epoch 33; iter: 0; batch classifier loss: 0.207078; batch adversarial loss: 0.450113\n",
      "epoch 34; iter: 0; batch classifier loss: 0.201636; batch adversarial loss: 0.464877\n",
      "epoch 35; iter: 0; batch classifier loss: 0.270543; batch adversarial loss: 0.482341\n",
      "epoch 36; iter: 0; batch classifier loss: 0.197243; batch adversarial loss: 0.462884\n",
      "epoch 37; iter: 0; batch classifier loss: 0.207311; batch adversarial loss: 0.463670\n",
      "epoch 38; iter: 0; batch classifier loss: 0.203611; batch adversarial loss: 0.462649\n",
      "epoch 39; iter: 0; batch classifier loss: 0.207246; batch adversarial loss: 0.438233\n",
      "epoch 40; iter: 0; batch classifier loss: 0.222891; batch adversarial loss: 0.528511\n",
      "epoch 41; iter: 0; batch classifier loss: 0.224417; batch adversarial loss: 0.404854\n",
      "epoch 42; iter: 0; batch classifier loss: 0.196499; batch adversarial loss: 0.497383\n",
      "epoch 43; iter: 0; batch classifier loss: 0.195473; batch adversarial loss: 0.492571\n",
      "epoch 44; iter: 0; batch classifier loss: 0.283528; batch adversarial loss: 0.529984\n",
      "epoch 45; iter: 0; batch classifier loss: 0.208233; batch adversarial loss: 0.549671\n",
      "epoch 46; iter: 0; batch classifier loss: 0.237733; batch adversarial loss: 0.459851\n",
      "epoch 47; iter: 0; batch classifier loss: 0.197977; batch adversarial loss: 0.392121\n",
      "epoch 48; iter: 0; batch classifier loss: 0.162812; batch adversarial loss: 0.494434\n",
      "epoch 49; iter: 0; batch classifier loss: 0.179085; batch adversarial loss: 0.402534\n",
      "epoch 50; iter: 0; batch classifier loss: 0.136143; batch adversarial loss: 0.459326\n",
      "epoch 51; iter: 0; batch classifier loss: 0.186670; batch adversarial loss: 0.494129\n",
      "epoch 52; iter: 0; batch classifier loss: 0.190839; batch adversarial loss: 0.552510\n",
      "epoch 53; iter: 0; batch classifier loss: 0.189418; batch adversarial loss: 0.412940\n",
      "epoch 54; iter: 0; batch classifier loss: 0.161391; batch adversarial loss: 0.378375\n",
      "epoch 55; iter: 0; batch classifier loss: 0.128321; batch adversarial loss: 0.517070\n",
      "epoch 56; iter: 0; batch classifier loss: 0.126085; batch adversarial loss: 0.447801\n",
      "epoch 57; iter: 0; batch classifier loss: 0.163854; batch adversarial loss: 0.483672\n",
      "epoch 58; iter: 0; batch classifier loss: 0.243944; batch adversarial loss: 0.505611\n",
      "epoch 59; iter: 0; batch classifier loss: 0.162505; batch adversarial loss: 0.424602\n",
      "epoch 60; iter: 0; batch classifier loss: 0.085699; batch adversarial loss: 0.517855\n",
      "epoch 61; iter: 0; batch classifier loss: 0.100159; batch adversarial loss: 0.459029\n",
      "epoch 62; iter: 0; batch classifier loss: 0.232141; batch adversarial loss: 0.461467\n",
      "epoch 63; iter: 0; batch classifier loss: 0.181216; batch adversarial loss: 0.473133\n",
      "epoch 64; iter: 0; batch classifier loss: 0.122896; batch adversarial loss: 0.516731\n",
      "epoch 65; iter: 0; batch classifier loss: 0.149744; batch adversarial loss: 0.518201\n",
      "epoch 66; iter: 0; batch classifier loss: 0.180141; batch adversarial loss: 0.494706\n",
      "epoch 67; iter: 0; batch classifier loss: 0.235558; batch adversarial loss: 0.388938\n",
      "epoch 68; iter: 0; batch classifier loss: 0.158467; batch adversarial loss: 0.353533\n",
      "epoch 69; iter: 0; batch classifier loss: 0.188170; batch adversarial loss: 0.459783\n",
      "epoch 70; iter: 0; batch classifier loss: 0.229231; batch adversarial loss: 0.459272\n",
      "epoch 71; iter: 0; batch classifier loss: 0.095735; batch adversarial loss: 0.481512\n",
      "epoch 72; iter: 0; batch classifier loss: 0.073078; batch adversarial loss: 0.575377\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065698; batch adversarial loss: 0.467711\n",
      "epoch 74; iter: 0; batch classifier loss: 0.057600; batch adversarial loss: 0.611896\n",
      "epoch 75; iter: 0; batch classifier loss: 0.052631; batch adversarial loss: 0.529520\n",
      "epoch 76; iter: 0; batch classifier loss: 0.057616; batch adversarial loss: 0.576300\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071663; batch adversarial loss: 0.460732\n",
      "epoch 78; iter: 0; batch classifier loss: 0.047203; batch adversarial loss: 0.495723\n",
      "epoch 79; iter: 0; batch classifier loss: 0.066099; batch adversarial loss: 0.459894\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060081; batch adversarial loss: 0.431292\n",
      "epoch 81; iter: 0; batch classifier loss: 0.070452; batch adversarial loss: 0.509195\n",
      "epoch 82; iter: 0; batch classifier loss: 0.105439; batch adversarial loss: 0.432269\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049701; batch adversarial loss: 0.466754\n",
      "epoch 84; iter: 0; batch classifier loss: 0.118968; batch adversarial loss: 0.533493\n",
      "epoch 85; iter: 0; batch classifier loss: 0.063300; batch adversarial loss: 0.508715\n",
      "epoch 86; iter: 0; batch classifier loss: 0.045008; batch adversarial loss: 0.488887\n",
      "epoch 87; iter: 0; batch classifier loss: 0.031206; batch adversarial loss: 0.488638\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058378; batch adversarial loss: 0.514019\n",
      "epoch 89; iter: 0; batch classifier loss: 0.041297; batch adversarial loss: 0.434167\n",
      "epoch 90; iter: 0; batch classifier loss: 0.070377; batch adversarial loss: 0.491095\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067041; batch adversarial loss: 0.419243\n",
      "epoch 92; iter: 0; batch classifier loss: 0.032964; batch adversarial loss: 0.506648\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039150; batch adversarial loss: 0.365029\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041623; batch adversarial loss: 0.439871\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081492; batch adversarial loss: 0.398779\n",
      "epoch 96; iter: 0; batch classifier loss: 0.033570; batch adversarial loss: 0.485860\n",
      "epoch 97; iter: 0; batch classifier loss: 0.045950; batch adversarial loss: 0.501126\n",
      "epoch 98; iter: 0; batch classifier loss: 0.033230; batch adversarial loss: 0.435299\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038902; batch adversarial loss: 0.463965\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054865; batch adversarial loss: 0.461946\n",
      "epoch 101; iter: 0; batch classifier loss: 0.033431; batch adversarial loss: 0.536962\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044174; batch adversarial loss: 0.494202\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047385; batch adversarial loss: 0.498639\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043231; batch adversarial loss: 0.466057\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047103; batch adversarial loss: 0.477757\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040876; batch adversarial loss: 0.387294\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045559; batch adversarial loss: 0.426939\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057906; batch adversarial loss: 0.455441\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067928; batch adversarial loss: 0.553698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.029825; batch adversarial loss: 0.466647\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028327; batch adversarial loss: 0.414830\n",
      "epoch 112; iter: 0; batch classifier loss: 0.016454; batch adversarial loss: 0.484663\n",
      "epoch 113; iter: 0; batch classifier loss: 0.030101; batch adversarial loss: 0.527781\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054732; batch adversarial loss: 0.612060\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053992; batch adversarial loss: 0.482401\n",
      "epoch 116; iter: 0; batch classifier loss: 0.025663; batch adversarial loss: 0.483693\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023019; batch adversarial loss: 0.461569\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032988; batch adversarial loss: 0.522052\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031615; batch adversarial loss: 0.420688\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041117; batch adversarial loss: 0.521511\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054814; batch adversarial loss: 0.437062\n",
      "epoch 122; iter: 0; batch classifier loss: 0.019862; batch adversarial loss: 0.441239\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037502; batch adversarial loss: 0.452424\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035645; batch adversarial loss: 0.433892\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029071; batch adversarial loss: 0.455766\n",
      "epoch 126; iter: 0; batch classifier loss: 0.016886; batch adversarial loss: 0.529248\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047346; batch adversarial loss: 0.566477\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022657; batch adversarial loss: 0.472826\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028464; batch adversarial loss: 0.526935\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018684; batch adversarial loss: 0.513215\n",
      "epoch 131; iter: 0; batch classifier loss: 0.011445; batch adversarial loss: 0.516224\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027390; batch adversarial loss: 0.388914\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029710; batch adversarial loss: 0.405075\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018185; batch adversarial loss: 0.377930\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019635; batch adversarial loss: 0.508109\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013030; batch adversarial loss: 0.472459\n",
      "epoch 137; iter: 0; batch classifier loss: 0.079620; batch adversarial loss: 0.439056\n",
      "epoch 138; iter: 0; batch classifier loss: 0.047656; batch adversarial loss: 0.470228\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023036; batch adversarial loss: 0.461249\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021844; batch adversarial loss: 0.433549\n",
      "epoch 141; iter: 0; batch classifier loss: 0.015387; batch adversarial loss: 0.473192\n",
      "epoch 142; iter: 0; batch classifier loss: 0.009998; batch adversarial loss: 0.578077\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041968; batch adversarial loss: 0.406149\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014350; batch adversarial loss: 0.448350\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018050; batch adversarial loss: 0.452085\n",
      "epoch 146; iter: 0; batch classifier loss: 0.004985; batch adversarial loss: 0.496557\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032425; batch adversarial loss: 0.373125\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027288; batch adversarial loss: 0.359969\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016490; batch adversarial loss: 0.374424\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010320; batch adversarial loss: 0.404228\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026706; batch adversarial loss: 0.484517\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017025; batch adversarial loss: 0.596858\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013356; batch adversarial loss: 0.455809\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014057; batch adversarial loss: 0.454691\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010805; batch adversarial loss: 0.494948\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031258; batch adversarial loss: 0.474789\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009596; batch adversarial loss: 0.457291\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020062; batch adversarial loss: 0.453273\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032353; batch adversarial loss: 0.508015\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015251; batch adversarial loss: 0.493100\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018939; batch adversarial loss: 0.546586\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012567; batch adversarial loss: 0.452589\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009793; batch adversarial loss: 0.411228\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034180; batch adversarial loss: 0.407806\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029971; batch adversarial loss: 0.471555\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013868; batch adversarial loss: 0.544549\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006185; batch adversarial loss: 0.444742\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005710; batch adversarial loss: 0.431211\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031933; batch adversarial loss: 0.478030\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019097; batch adversarial loss: 0.428591\n",
      "epoch 171; iter: 0; batch classifier loss: 0.006528; batch adversarial loss: 0.443820\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008670; batch adversarial loss: 0.425900\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009176; batch adversarial loss: 0.537888\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023790; batch adversarial loss: 0.441711\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023570; batch adversarial loss: 0.482113\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025531; batch adversarial loss: 0.501442\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006268; batch adversarial loss: 0.499354\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008105; batch adversarial loss: 0.577275\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011089; batch adversarial loss: 0.468003\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006890; batch adversarial loss: 0.544133\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037923; batch adversarial loss: 0.504218\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017155; batch adversarial loss: 0.423665\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015136; batch adversarial loss: 0.450642\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016400; batch adversarial loss: 0.512518\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027078; batch adversarial loss: 0.495022\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022278; batch adversarial loss: 0.554306\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035012; batch adversarial loss: 0.540302\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030420; batch adversarial loss: 0.575168\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024242; batch adversarial loss: 0.387644\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012166; batch adversarial loss: 0.457899\n",
      "epoch 191; iter: 0; batch classifier loss: 0.004221; batch adversarial loss: 0.352455\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005131; batch adversarial loss: 0.464735\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008235; batch adversarial loss: 0.530398\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013026; batch adversarial loss: 0.407315\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013058; batch adversarial loss: 0.462750\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022317; batch adversarial loss: 0.408168\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019067; batch adversarial loss: 0.524905\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006203; batch adversarial loss: 0.405876\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025737; batch adversarial loss: 0.562786\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682409; batch adversarial loss: 1.101672\n",
      "epoch 1; iter: 0; batch classifier loss: 0.861867; batch adversarial loss: 1.403223\n",
      "epoch 2; iter: 0; batch classifier loss: 1.092135; batch adversarial loss: 1.412417\n",
      "epoch 3; iter: 0; batch classifier loss: 1.215670; batch adversarial loss: 1.269286\n",
      "epoch 4; iter: 0; batch classifier loss: 1.274905; batch adversarial loss: 1.184172\n",
      "epoch 5; iter: 0; batch classifier loss: 1.013855; batch adversarial loss: 0.987798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 1.114499; batch adversarial loss: 0.945973\n",
      "epoch 7; iter: 0; batch classifier loss: 1.039645; batch adversarial loss: 0.859441\n",
      "epoch 8; iter: 0; batch classifier loss: 1.016479; batch adversarial loss: 0.821663\n",
      "epoch 9; iter: 0; batch classifier loss: 0.861249; batch adversarial loss: 0.732319\n",
      "epoch 10; iter: 0; batch classifier loss: 0.921674; batch adversarial loss: 0.713998\n",
      "epoch 11; iter: 0; batch classifier loss: 0.836153; batch adversarial loss: 0.664802\n",
      "epoch 12; iter: 0; batch classifier loss: 0.716637; batch adversarial loss: 0.611784\n",
      "epoch 13; iter: 0; batch classifier loss: 0.596495; batch adversarial loss: 0.556535\n",
      "epoch 14; iter: 0; batch classifier loss: 0.523157; batch adversarial loss: 0.589635\n",
      "epoch 15; iter: 0; batch classifier loss: 0.400590; batch adversarial loss: 0.508084\n",
      "epoch 16; iter: 0; batch classifier loss: 0.320823; batch adversarial loss: 0.505158\n",
      "epoch 17; iter: 0; batch classifier loss: 0.260624; batch adversarial loss: 0.514843\n",
      "epoch 18; iter: 0; batch classifier loss: 0.326260; batch adversarial loss: 0.509431\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261682; batch adversarial loss: 0.536516\n",
      "epoch 20; iter: 0; batch classifier loss: 0.229387; batch adversarial loss: 0.478150\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234174; batch adversarial loss: 0.484386\n",
      "epoch 22; iter: 0; batch classifier loss: 0.195690; batch adversarial loss: 0.496682\n",
      "epoch 23; iter: 0; batch classifier loss: 0.219247; batch adversarial loss: 0.511522\n",
      "epoch 24; iter: 0; batch classifier loss: 0.222189; batch adversarial loss: 0.519492\n",
      "epoch 25; iter: 0; batch classifier loss: 0.208605; batch adversarial loss: 0.447132\n",
      "epoch 26; iter: 0; batch classifier loss: 0.209443; batch adversarial loss: 0.504934\n",
      "epoch 27; iter: 0; batch classifier loss: 0.158619; batch adversarial loss: 0.496716\n",
      "epoch 28; iter: 0; batch classifier loss: 0.220889; batch adversarial loss: 0.459301\n",
      "epoch 29; iter: 0; batch classifier loss: 0.154964; batch adversarial loss: 0.508199\n",
      "epoch 30; iter: 0; batch classifier loss: 0.186579; batch adversarial loss: 0.442322\n",
      "epoch 31; iter: 0; batch classifier loss: 0.172163; batch adversarial loss: 0.520456\n",
      "epoch 32; iter: 0; batch classifier loss: 0.178215; batch adversarial loss: 0.485578\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145183; batch adversarial loss: 0.479712\n",
      "epoch 34; iter: 0; batch classifier loss: 0.152076; batch adversarial loss: 0.529328\n",
      "epoch 35; iter: 0; batch classifier loss: 0.176788; batch adversarial loss: 0.489817\n",
      "epoch 36; iter: 0; batch classifier loss: 0.119545; batch adversarial loss: 0.446182\n",
      "epoch 37; iter: 0; batch classifier loss: 0.208140; batch adversarial loss: 0.463685\n",
      "epoch 38; iter: 0; batch classifier loss: 0.164679; batch adversarial loss: 0.499598\n",
      "epoch 39; iter: 0; batch classifier loss: 0.181393; batch adversarial loss: 0.384594\n",
      "epoch 40; iter: 0; batch classifier loss: 0.129419; batch adversarial loss: 0.447080\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098176; batch adversarial loss: 0.398954\n",
      "epoch 42; iter: 0; batch classifier loss: 0.153278; batch adversarial loss: 0.420927\n",
      "epoch 43; iter: 0; batch classifier loss: 0.135256; batch adversarial loss: 0.531542\n",
      "epoch 44; iter: 0; batch classifier loss: 0.168820; batch adversarial loss: 0.428497\n",
      "epoch 45; iter: 0; batch classifier loss: 0.121671; batch adversarial loss: 0.484883\n",
      "epoch 46; iter: 0; batch classifier loss: 0.135947; batch adversarial loss: 0.493480\n",
      "epoch 47; iter: 0; batch classifier loss: 0.144090; batch adversarial loss: 0.517324\n",
      "epoch 48; iter: 0; batch classifier loss: 0.118609; batch adversarial loss: 0.483002\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101510; batch adversarial loss: 0.555066\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101237; batch adversarial loss: 0.481895\n",
      "epoch 51; iter: 0; batch classifier loss: 0.167380; batch adversarial loss: 0.412089\n",
      "epoch 52; iter: 0; batch classifier loss: 0.129264; batch adversarial loss: 0.449785\n",
      "epoch 53; iter: 0; batch classifier loss: 0.123383; batch adversarial loss: 0.390661\n",
      "epoch 54; iter: 0; batch classifier loss: 0.123497; batch adversarial loss: 0.503222\n",
      "epoch 55; iter: 0; batch classifier loss: 0.095392; batch adversarial loss: 0.423191\n",
      "epoch 56; iter: 0; batch classifier loss: 0.109295; batch adversarial loss: 0.486087\n",
      "epoch 57; iter: 0; batch classifier loss: 0.101156; batch adversarial loss: 0.408865\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097183; batch adversarial loss: 0.507348\n",
      "epoch 59; iter: 0; batch classifier loss: 0.149358; batch adversarial loss: 0.452868\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101739; batch adversarial loss: 0.441553\n",
      "epoch 61; iter: 0; batch classifier loss: 0.180593; batch adversarial loss: 0.506699\n",
      "epoch 62; iter: 0; batch classifier loss: 0.154586; batch adversarial loss: 0.447469\n",
      "epoch 63; iter: 0; batch classifier loss: 0.144729; batch adversarial loss: 0.481628\n",
      "epoch 64; iter: 0; batch classifier loss: 0.092812; batch adversarial loss: 0.421838\n",
      "epoch 65; iter: 0; batch classifier loss: 0.114925; batch adversarial loss: 0.420315\n",
      "epoch 66; iter: 0; batch classifier loss: 0.183022; batch adversarial loss: 0.469680\n",
      "epoch 67; iter: 0; batch classifier loss: 0.116466; batch adversarial loss: 0.473899\n",
      "epoch 68; iter: 0; batch classifier loss: 0.126144; batch adversarial loss: 0.462585\n",
      "epoch 69; iter: 0; batch classifier loss: 0.135890; batch adversarial loss: 0.411962\n",
      "epoch 70; iter: 0; batch classifier loss: 0.053338; batch adversarial loss: 0.496760\n",
      "epoch 71; iter: 0; batch classifier loss: 0.112338; batch adversarial loss: 0.416942\n",
      "epoch 72; iter: 0; batch classifier loss: 0.109828; batch adversarial loss: 0.383418\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102361; batch adversarial loss: 0.470954\n",
      "epoch 74; iter: 0; batch classifier loss: 0.085734; batch adversarial loss: 0.492374\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083533; batch adversarial loss: 0.439052\n",
      "epoch 76; iter: 0; batch classifier loss: 0.121725; batch adversarial loss: 0.549795\n",
      "epoch 77; iter: 0; batch classifier loss: 0.079370; batch adversarial loss: 0.522902\n",
      "epoch 78; iter: 0; batch classifier loss: 0.130047; batch adversarial loss: 0.362528\n",
      "epoch 79; iter: 0; batch classifier loss: 0.139160; batch adversarial loss: 0.476587\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088211; batch adversarial loss: 0.529486\n",
      "epoch 81; iter: 0; batch classifier loss: 0.157971; batch adversarial loss: 0.513512\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075916; batch adversarial loss: 0.515675\n",
      "epoch 83; iter: 0; batch classifier loss: 0.123056; batch adversarial loss: 0.461701\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082852; batch adversarial loss: 0.352380\n",
      "epoch 85; iter: 0; batch classifier loss: 0.103013; batch adversarial loss: 0.418468\n",
      "epoch 86; iter: 0; batch classifier loss: 0.098615; batch adversarial loss: 0.459319\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106736; batch adversarial loss: 0.557564\n",
      "epoch 88; iter: 0; batch classifier loss: 0.135143; batch adversarial loss: 0.447709\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069732; batch adversarial loss: 0.486316\n",
      "epoch 90; iter: 0; batch classifier loss: 0.095848; batch adversarial loss: 0.509981\n",
      "epoch 91; iter: 0; batch classifier loss: 0.078873; batch adversarial loss: 0.498215\n",
      "epoch 92; iter: 0; batch classifier loss: 0.088427; batch adversarial loss: 0.420511\n",
      "epoch 93; iter: 0; batch classifier loss: 0.126444; batch adversarial loss: 0.558102\n",
      "epoch 94; iter: 0; batch classifier loss: 0.087959; batch adversarial loss: 0.460692\n",
      "epoch 95; iter: 0; batch classifier loss: 0.091980; batch adversarial loss: 0.491611\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058399; batch adversarial loss: 0.449181\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088411; batch adversarial loss: 0.483484\n",
      "epoch 98; iter: 0; batch classifier loss: 0.081932; batch adversarial loss: 0.437420\n",
      "epoch 99; iter: 0; batch classifier loss: 0.080132; batch adversarial loss: 0.457933\n",
      "epoch 100; iter: 0; batch classifier loss: 0.103995; batch adversarial loss: 0.410061\n",
      "epoch 101; iter: 0; batch classifier loss: 0.073872; batch adversarial loss: 0.379557\n",
      "epoch 102; iter: 0; batch classifier loss: 0.116137; batch adversarial loss: 0.434133\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046708; batch adversarial loss: 0.536467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.043460; batch adversarial loss: 0.334593\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075878; batch adversarial loss: 0.386112\n",
      "epoch 106; iter: 0; batch classifier loss: 0.103167; batch adversarial loss: 0.435540\n",
      "epoch 107; iter: 0; batch classifier loss: 0.073242; batch adversarial loss: 0.466263\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067818; batch adversarial loss: 0.457486\n",
      "epoch 109; iter: 0; batch classifier loss: 0.087021; batch adversarial loss: 0.457466\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054992; batch adversarial loss: 0.490557\n",
      "epoch 111; iter: 0; batch classifier loss: 0.100056; batch adversarial loss: 0.367188\n",
      "epoch 112; iter: 0; batch classifier loss: 0.061635; batch adversarial loss: 0.450474\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071326; batch adversarial loss: 0.415678\n",
      "epoch 114; iter: 0; batch classifier loss: 0.078207; batch adversarial loss: 0.491472\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053357; batch adversarial loss: 0.451510\n",
      "epoch 116; iter: 0; batch classifier loss: 0.067132; batch adversarial loss: 0.464144\n",
      "epoch 117; iter: 0; batch classifier loss: 0.102229; batch adversarial loss: 0.517429\n",
      "epoch 118; iter: 0; batch classifier loss: 0.096423; batch adversarial loss: 0.363058\n",
      "epoch 119; iter: 0; batch classifier loss: 0.086858; batch adversarial loss: 0.559186\n",
      "epoch 120; iter: 0; batch classifier loss: 0.081107; batch adversarial loss: 0.472645\n",
      "epoch 121; iter: 0; batch classifier loss: 0.113217; batch adversarial loss: 0.517156\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062897; batch adversarial loss: 0.409777\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055181; batch adversarial loss: 0.402827\n",
      "epoch 124; iter: 0; batch classifier loss: 0.077349; batch adversarial loss: 0.515791\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052291; batch adversarial loss: 0.395117\n",
      "epoch 126; iter: 0; batch classifier loss: 0.119094; batch adversarial loss: 0.512643\n",
      "epoch 127; iter: 0; batch classifier loss: 0.108562; batch adversarial loss: 0.539158\n",
      "epoch 128; iter: 0; batch classifier loss: 0.072035; batch adversarial loss: 0.489737\n",
      "epoch 129; iter: 0; batch classifier loss: 0.091203; batch adversarial loss: 0.490672\n",
      "epoch 130; iter: 0; batch classifier loss: 0.113007; batch adversarial loss: 0.386998\n",
      "epoch 131; iter: 0; batch classifier loss: 0.084010; batch adversarial loss: 0.426642\n",
      "epoch 132; iter: 0; batch classifier loss: 0.106040; batch adversarial loss: 0.491970\n",
      "epoch 133; iter: 0; batch classifier loss: 0.057526; batch adversarial loss: 0.389446\n",
      "epoch 134; iter: 0; batch classifier loss: 0.068642; batch adversarial loss: 0.468188\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059558; batch adversarial loss: 0.481272\n",
      "epoch 136; iter: 0; batch classifier loss: 0.105840; batch adversarial loss: 0.534816\n",
      "epoch 137; iter: 0; batch classifier loss: 0.065656; batch adversarial loss: 0.421810\n",
      "epoch 138; iter: 0; batch classifier loss: 0.077546; batch adversarial loss: 0.388254\n",
      "epoch 139; iter: 0; batch classifier loss: 0.101140; batch adversarial loss: 0.544703\n",
      "epoch 140; iter: 0; batch classifier loss: 0.080389; batch adversarial loss: 0.504948\n",
      "epoch 141; iter: 0; batch classifier loss: 0.055454; batch adversarial loss: 0.562538\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050595; batch adversarial loss: 0.454013\n",
      "epoch 143; iter: 0; batch classifier loss: 0.104752; batch adversarial loss: 0.471432\n",
      "epoch 144; iter: 0; batch classifier loss: 0.072757; batch adversarial loss: 0.390676\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031022; batch adversarial loss: 0.516023\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041073; batch adversarial loss: 0.519117\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044216; batch adversarial loss: 0.469539\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038548; batch adversarial loss: 0.480020\n",
      "epoch 149; iter: 0; batch classifier loss: 0.063628; batch adversarial loss: 0.453508\n",
      "epoch 150; iter: 0; batch classifier loss: 0.081725; batch adversarial loss: 0.402354\n",
      "epoch 151; iter: 0; batch classifier loss: 0.051941; batch adversarial loss: 0.415981\n",
      "epoch 152; iter: 0; batch classifier loss: 0.059996; batch adversarial loss: 0.401234\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040324; batch adversarial loss: 0.476768\n",
      "epoch 154; iter: 0; batch classifier loss: 0.047792; batch adversarial loss: 0.445775\n",
      "epoch 155; iter: 0; batch classifier loss: 0.069904; batch adversarial loss: 0.412518\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043643; batch adversarial loss: 0.405208\n",
      "epoch 157; iter: 0; batch classifier loss: 0.104805; batch adversarial loss: 0.379377\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044996; batch adversarial loss: 0.411953\n",
      "epoch 159; iter: 0; batch classifier loss: 0.047296; batch adversarial loss: 0.367978\n",
      "epoch 160; iter: 0; batch classifier loss: 0.075246; batch adversarial loss: 0.490819\n",
      "epoch 161; iter: 0; batch classifier loss: 0.060324; batch adversarial loss: 0.532320\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042200; batch adversarial loss: 0.478890\n",
      "epoch 163; iter: 0; batch classifier loss: 0.049759; batch adversarial loss: 0.474417\n",
      "epoch 164; iter: 0; batch classifier loss: 0.063009; batch adversarial loss: 0.466032\n",
      "epoch 165; iter: 0; batch classifier loss: 0.055674; batch adversarial loss: 0.496834\n",
      "epoch 166; iter: 0; batch classifier loss: 0.051373; batch adversarial loss: 0.456839\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020577; batch adversarial loss: 0.535823\n",
      "epoch 168; iter: 0; batch classifier loss: 0.053269; batch adversarial loss: 0.400168\n",
      "epoch 169; iter: 0; batch classifier loss: 0.056760; batch adversarial loss: 0.450695\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027929; batch adversarial loss: 0.429919\n",
      "epoch 171; iter: 0; batch classifier loss: 0.035470; batch adversarial loss: 0.399303\n",
      "epoch 172; iter: 0; batch classifier loss: 0.044420; batch adversarial loss: 0.396748\n",
      "epoch 173; iter: 0; batch classifier loss: 0.056821; batch adversarial loss: 0.549851\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017393; batch adversarial loss: 0.352834\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008608; batch adversarial loss: 0.481797\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023072; batch adversarial loss: 0.458609\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027031; batch adversarial loss: 0.412986\n",
      "epoch 178; iter: 0; batch classifier loss: 0.075600; batch adversarial loss: 0.432507\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036395; batch adversarial loss: 0.380296\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023308; batch adversarial loss: 0.482012\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036130; batch adversarial loss: 0.490767\n",
      "epoch 182; iter: 0; batch classifier loss: 0.050103; batch adversarial loss: 0.423096\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028504; batch adversarial loss: 0.429182\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035625; batch adversarial loss: 0.478359\n",
      "epoch 185; iter: 0; batch classifier loss: 0.030974; batch adversarial loss: 0.483654\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010812; batch adversarial loss: 0.476999\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035386; batch adversarial loss: 0.450755\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033236; batch adversarial loss: 0.476438\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021604; batch adversarial loss: 0.454838\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010984; batch adversarial loss: 0.429962\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013882; batch adversarial loss: 0.424268\n",
      "epoch 192; iter: 0; batch classifier loss: 0.052869; batch adversarial loss: 0.486285\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006629; batch adversarial loss: 0.505554\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026462; batch adversarial loss: 0.447783\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023914; batch adversarial loss: 0.466128\n",
      "epoch 196; iter: 0; batch classifier loss: 0.038260; batch adversarial loss: 0.466100\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010507; batch adversarial loss: 0.485063\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023023; batch adversarial loss: 0.456969\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014797; batch adversarial loss: 0.432312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.681412; batch adversarial loss: 0.846743\n",
      "epoch 1; iter: 0; batch classifier loss: 0.478855; batch adversarial loss: 0.892850\n",
      "epoch 2; iter: 0; batch classifier loss: 0.547472; batch adversarial loss: 0.826230\n",
      "epoch 3; iter: 0; batch classifier loss: 0.741857; batch adversarial loss: 0.812882\n",
      "epoch 4; iter: 0; batch classifier loss: 0.882798; batch adversarial loss: 0.734544\n",
      "epoch 5; iter: 0; batch classifier loss: 0.830098; batch adversarial loss: 0.671165\n",
      "epoch 6; iter: 0; batch classifier loss: 0.677872; batch adversarial loss: 0.613544\n",
      "epoch 7; iter: 0; batch classifier loss: 0.597924; batch adversarial loss: 0.567485\n",
      "epoch 8; iter: 0; batch classifier loss: 0.369127; batch adversarial loss: 0.562797\n",
      "epoch 9; iter: 0; batch classifier loss: 0.318640; batch adversarial loss: 0.533271\n",
      "epoch 10; iter: 0; batch classifier loss: 0.439420; batch adversarial loss: 0.539923\n",
      "epoch 11; iter: 0; batch classifier loss: 0.424661; batch adversarial loss: 0.524960\n",
      "epoch 12; iter: 0; batch classifier loss: 0.267485; batch adversarial loss: 0.528547\n",
      "epoch 13; iter: 0; batch classifier loss: 0.315101; batch adversarial loss: 0.546078\n",
      "epoch 14; iter: 0; batch classifier loss: 0.390628; batch adversarial loss: 0.506868\n",
      "epoch 15; iter: 0; batch classifier loss: 0.239947; batch adversarial loss: 0.497799\n",
      "epoch 16; iter: 0; batch classifier loss: 0.348237; batch adversarial loss: 0.523600\n",
      "epoch 17; iter: 0; batch classifier loss: 0.418038; batch adversarial loss: 0.451279\n",
      "epoch 18; iter: 0; batch classifier loss: 0.340484; batch adversarial loss: 0.504090\n",
      "epoch 19; iter: 0; batch classifier loss: 0.398149; batch adversarial loss: 0.444975\n",
      "epoch 20; iter: 0; batch classifier loss: 0.340673; batch adversarial loss: 0.505496\n",
      "epoch 21; iter: 0; batch classifier loss: 0.298107; batch adversarial loss: 0.514655\n",
      "epoch 22; iter: 0; batch classifier loss: 0.277797; batch adversarial loss: 0.501788\n",
      "epoch 23; iter: 0; batch classifier loss: 0.288209; batch adversarial loss: 0.491802\n",
      "epoch 24; iter: 0; batch classifier loss: 0.264089; batch adversarial loss: 0.485765\n",
      "epoch 25; iter: 0; batch classifier loss: 0.230869; batch adversarial loss: 0.440414\n",
      "epoch 26; iter: 0; batch classifier loss: 0.277158; batch adversarial loss: 0.435755\n",
      "epoch 27; iter: 0; batch classifier loss: 0.270430; batch adversarial loss: 0.445934\n",
      "epoch 28; iter: 0; batch classifier loss: 0.269473; batch adversarial loss: 0.475379\n",
      "epoch 29; iter: 0; batch classifier loss: 0.218863; batch adversarial loss: 0.482178\n",
      "epoch 30; iter: 0; batch classifier loss: 0.210969; batch adversarial loss: 0.462716\n",
      "epoch 31; iter: 0; batch classifier loss: 0.235719; batch adversarial loss: 0.504765\n",
      "epoch 32; iter: 0; batch classifier loss: 0.214546; batch adversarial loss: 0.410373\n",
      "epoch 33; iter: 0; batch classifier loss: 0.177117; batch adversarial loss: 0.458651\n",
      "epoch 34; iter: 0; batch classifier loss: 0.136239; batch adversarial loss: 0.487923\n",
      "epoch 35; iter: 0; batch classifier loss: 0.226302; batch adversarial loss: 0.468881\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150008; batch adversarial loss: 0.414326\n",
      "epoch 37; iter: 0; batch classifier loss: 0.237117; batch adversarial loss: 0.397143\n",
      "epoch 38; iter: 0; batch classifier loss: 0.240878; batch adversarial loss: 0.444380\n",
      "epoch 39; iter: 0; batch classifier loss: 0.187713; batch adversarial loss: 0.449708\n",
      "epoch 40; iter: 0; batch classifier loss: 0.182469; batch adversarial loss: 0.444085\n",
      "epoch 41; iter: 0; batch classifier loss: 0.144366; batch adversarial loss: 0.469531\n",
      "epoch 42; iter: 0; batch classifier loss: 0.107206; batch adversarial loss: 0.487102\n",
      "epoch 43; iter: 0; batch classifier loss: 0.136247; batch adversarial loss: 0.469480\n",
      "epoch 44; iter: 0; batch classifier loss: 0.122762; batch adversarial loss: 0.373194\n",
      "epoch 45; iter: 0; batch classifier loss: 0.126827; batch adversarial loss: 0.378043\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113387; batch adversarial loss: 0.423398\n",
      "epoch 47; iter: 0; batch classifier loss: 0.179713; batch adversarial loss: 0.480545\n",
      "epoch 48; iter: 0; batch classifier loss: 0.187090; batch adversarial loss: 0.411794\n",
      "epoch 49; iter: 0; batch classifier loss: 0.189013; batch adversarial loss: 0.530042\n",
      "epoch 50; iter: 0; batch classifier loss: 0.081743; batch adversarial loss: 0.407882\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122115; batch adversarial loss: 0.491157\n",
      "epoch 52; iter: 0; batch classifier loss: 0.150391; batch adversarial loss: 0.331944\n",
      "epoch 53; iter: 0; batch classifier loss: 0.089022; batch adversarial loss: 0.491788\n",
      "epoch 54; iter: 0; batch classifier loss: 0.119734; batch adversarial loss: 0.437004\n",
      "epoch 55; iter: 0; batch classifier loss: 0.163166; batch adversarial loss: 0.462999\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102816; batch adversarial loss: 0.491846\n",
      "epoch 57; iter: 0; batch classifier loss: 0.091045; batch adversarial loss: 0.405534\n",
      "epoch 58; iter: 0; batch classifier loss: 0.061373; batch adversarial loss: 0.381087\n",
      "epoch 59; iter: 0; batch classifier loss: 0.108962; batch adversarial loss: 0.536036\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079484; batch adversarial loss: 0.400262\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114062; batch adversarial loss: 0.440678\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094690; batch adversarial loss: 0.427295\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085930; batch adversarial loss: 0.470190\n",
      "epoch 64; iter: 0; batch classifier loss: 0.050932; batch adversarial loss: 0.607293\n",
      "epoch 65; iter: 0; batch classifier loss: 0.063765; batch adversarial loss: 0.445295\n",
      "epoch 66; iter: 0; batch classifier loss: 0.114151; batch adversarial loss: 0.506948\n",
      "epoch 67; iter: 0; batch classifier loss: 0.109903; batch adversarial loss: 0.524981\n",
      "epoch 68; iter: 0; batch classifier loss: 0.053332; batch adversarial loss: 0.459195\n",
      "epoch 69; iter: 0; batch classifier loss: 0.112199; batch adversarial loss: 0.441525\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110635; batch adversarial loss: 0.416225\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067191; batch adversarial loss: 0.441491\n",
      "epoch 72; iter: 0; batch classifier loss: 0.055382; batch adversarial loss: 0.373704\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058077; batch adversarial loss: 0.475700\n",
      "epoch 74; iter: 0; batch classifier loss: 0.051330; batch adversarial loss: 0.376127\n",
      "epoch 75; iter: 0; batch classifier loss: 0.048837; batch adversarial loss: 0.459741\n",
      "epoch 76; iter: 0; batch classifier loss: 0.042266; batch adversarial loss: 0.438205\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076676; batch adversarial loss: 0.421265\n",
      "epoch 78; iter: 0; batch classifier loss: 0.036147; batch adversarial loss: 0.367474\n",
      "epoch 79; iter: 0; batch classifier loss: 0.062979; batch adversarial loss: 0.467408\n",
      "epoch 80; iter: 0; batch classifier loss: 0.039053; batch adversarial loss: 0.425859\n",
      "epoch 81; iter: 0; batch classifier loss: 0.043543; batch adversarial loss: 0.442668\n",
      "epoch 82; iter: 0; batch classifier loss: 0.050076; batch adversarial loss: 0.521690\n",
      "epoch 83; iter: 0; batch classifier loss: 0.133433; batch adversarial loss: 0.369938\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055540; batch adversarial loss: 0.453826\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065012; batch adversarial loss: 0.502026\n",
      "epoch 86; iter: 0; batch classifier loss: 0.071118; batch adversarial loss: 0.442062\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076800; batch adversarial loss: 0.452341\n",
      "epoch 88; iter: 0; batch classifier loss: 0.036960; batch adversarial loss: 0.473190\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066560; batch adversarial loss: 0.498157\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055804; batch adversarial loss: 0.425802\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067288; batch adversarial loss: 0.489279\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068651; batch adversarial loss: 0.527813\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048464; batch adversarial loss: 0.456596\n",
      "epoch 94; iter: 0; batch classifier loss: 0.030203; batch adversarial loss: 0.398771\n",
      "epoch 95; iter: 0; batch classifier loss: 0.059871; batch adversarial loss: 0.440868\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041650; batch adversarial loss: 0.432404\n",
      "epoch 97; iter: 0; batch classifier loss: 0.017829; batch adversarial loss: 0.535154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.034197; batch adversarial loss: 0.398350\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049693; batch adversarial loss: 0.418438\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051082; batch adversarial loss: 0.502314\n",
      "epoch 101; iter: 0; batch classifier loss: 0.045072; batch adversarial loss: 0.429984\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042896; batch adversarial loss: 0.415892\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039418; batch adversarial loss: 0.496717\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047146; batch adversarial loss: 0.463891\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062810; batch adversarial loss: 0.514814\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059677; batch adversarial loss: 0.470535\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034583; batch adversarial loss: 0.361959\n",
      "epoch 108; iter: 0; batch classifier loss: 0.020843; batch adversarial loss: 0.451837\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033747; batch adversarial loss: 0.548871\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044278; batch adversarial loss: 0.440955\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062355; batch adversarial loss: 0.427137\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043106; batch adversarial loss: 0.412245\n",
      "epoch 113; iter: 0; batch classifier loss: 0.007522; batch adversarial loss: 0.493971\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032193; batch adversarial loss: 0.428366\n",
      "epoch 115; iter: 0; batch classifier loss: 0.019953; batch adversarial loss: 0.498271\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050915; batch adversarial loss: 0.461075\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023120; batch adversarial loss: 0.469719\n",
      "epoch 118; iter: 0; batch classifier loss: 0.020910; batch adversarial loss: 0.447659\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073306; batch adversarial loss: 0.480151\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045983; batch adversarial loss: 0.446670\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018271; batch adversarial loss: 0.453549\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046127; batch adversarial loss: 0.479694\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019772; batch adversarial loss: 0.481965\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050229; batch adversarial loss: 0.502559\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020651; batch adversarial loss: 0.381506\n",
      "epoch 126; iter: 0; batch classifier loss: 0.008487; batch adversarial loss: 0.548573\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024881; batch adversarial loss: 0.457118\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023735; batch adversarial loss: 0.368293\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039626; batch adversarial loss: 0.554586\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023052; batch adversarial loss: 0.434028\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037987; batch adversarial loss: 0.518315\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027598; batch adversarial loss: 0.480843\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044084; batch adversarial loss: 0.408318\n",
      "epoch 134; iter: 0; batch classifier loss: 0.010494; batch adversarial loss: 0.500836\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016185; batch adversarial loss: 0.482954\n",
      "epoch 136; iter: 0; batch classifier loss: 0.045601; batch adversarial loss: 0.468590\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032158; batch adversarial loss: 0.477709\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014537; batch adversarial loss: 0.506067\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014117; batch adversarial loss: 0.527262\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017892; batch adversarial loss: 0.507377\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028777; batch adversarial loss: 0.397435\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030470; batch adversarial loss: 0.448628\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014703; batch adversarial loss: 0.398864\n",
      "epoch 144; iter: 0; batch classifier loss: 0.007301; batch adversarial loss: 0.327795\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025118; batch adversarial loss: 0.580954\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034192; batch adversarial loss: 0.493726\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017409; batch adversarial loss: 0.465737\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023578; batch adversarial loss: 0.509374\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012019; batch adversarial loss: 0.476229\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038003; batch adversarial loss: 0.316482\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014028; batch adversarial loss: 0.502433\n",
      "epoch 152; iter: 0; batch classifier loss: 0.053602; batch adversarial loss: 0.409832\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017501; batch adversarial loss: 0.509444\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015268; batch adversarial loss: 0.493154\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030942; batch adversarial loss: 0.483230\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032215; batch adversarial loss: 0.487901\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018401; batch adversarial loss: 0.527486\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018394; batch adversarial loss: 0.414915\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032719; batch adversarial loss: 0.507868\n",
      "epoch 160; iter: 0; batch classifier loss: 0.003789; batch adversarial loss: 0.424155\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026036; batch adversarial loss: 0.392972\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012127; batch adversarial loss: 0.494756\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027740; batch adversarial loss: 0.413324\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023404; batch adversarial loss: 0.347541\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026845; batch adversarial loss: 0.495464\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010978; batch adversarial loss: 0.379561\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006974; batch adversarial loss: 0.495303\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020661; batch adversarial loss: 0.432132\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009648; batch adversarial loss: 0.455844\n",
      "epoch 170; iter: 0; batch classifier loss: 0.006396; batch adversarial loss: 0.484845\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013807; batch adversarial loss: 0.427305\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021239; batch adversarial loss: 0.445228\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017246; batch adversarial loss: 0.463576\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040664; batch adversarial loss: 0.498797\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011862; batch adversarial loss: 0.415436\n",
      "epoch 176; iter: 0; batch classifier loss: 0.046085; batch adversarial loss: 0.449133\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014719; batch adversarial loss: 0.444830\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006911; batch adversarial loss: 0.547641\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022062; batch adversarial loss: 0.457730\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012385; batch adversarial loss: 0.465201\n",
      "epoch 181; iter: 0; batch classifier loss: 0.004317; batch adversarial loss: 0.517444\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028762; batch adversarial loss: 0.425328\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021950; batch adversarial loss: 0.401926\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019537; batch adversarial loss: 0.380919\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006570; batch adversarial loss: 0.472829\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015729; batch adversarial loss: 0.476248\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023106; batch adversarial loss: 0.445427\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017787; batch adversarial loss: 0.387955\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028172; batch adversarial loss: 0.472472\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034926; batch adversarial loss: 0.551988\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017651; batch adversarial loss: 0.571573\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016282; batch adversarial loss: 0.482680\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037998; batch adversarial loss: 0.384551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.011004; batch adversarial loss: 0.413441\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012019; batch adversarial loss: 0.458322\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013943; batch adversarial loss: 0.476187\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007484; batch adversarial loss: 0.332332\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016527; batch adversarial loss: 0.504247\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007405; batch adversarial loss: 0.474901\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692778; batch adversarial loss: 0.661777\n",
      "epoch 1; iter: 0; batch classifier loss: 0.483419; batch adversarial loss: 0.634110\n",
      "epoch 2; iter: 0; batch classifier loss: 0.362496; batch adversarial loss: 0.608629\n",
      "epoch 3; iter: 0; batch classifier loss: 0.387363; batch adversarial loss: 0.580249\n",
      "epoch 4; iter: 0; batch classifier loss: 0.308244; batch adversarial loss: 0.561930\n",
      "epoch 5; iter: 0; batch classifier loss: 0.332809; batch adversarial loss: 0.547600\n",
      "epoch 6; iter: 0; batch classifier loss: 0.328954; batch adversarial loss: 0.529357\n",
      "epoch 7; iter: 0; batch classifier loss: 0.271751; batch adversarial loss: 0.525941\n",
      "epoch 8; iter: 0; batch classifier loss: 0.253531; batch adversarial loss: 0.520043\n",
      "epoch 9; iter: 0; batch classifier loss: 0.336555; batch adversarial loss: 0.577368\n",
      "epoch 10; iter: 0; batch classifier loss: 0.237232; batch adversarial loss: 0.506276\n",
      "epoch 11; iter: 0; batch classifier loss: 0.246911; batch adversarial loss: 0.485681\n",
      "epoch 12; iter: 0; batch classifier loss: 0.185070; batch adversarial loss: 0.513596\n",
      "epoch 13; iter: 0; batch classifier loss: 0.269886; batch adversarial loss: 0.435708\n",
      "epoch 14; iter: 0; batch classifier loss: 0.208756; batch adversarial loss: 0.502809\n",
      "epoch 15; iter: 0; batch classifier loss: 0.165103; batch adversarial loss: 0.510994\n",
      "epoch 16; iter: 0; batch classifier loss: 0.184450; batch adversarial loss: 0.550003\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192475; batch adversarial loss: 0.476951\n",
      "epoch 18; iter: 0; batch classifier loss: 0.229124; batch adversarial loss: 0.511046\n",
      "epoch 19; iter: 0; batch classifier loss: 0.099843; batch adversarial loss: 0.507607\n",
      "epoch 20; iter: 0; batch classifier loss: 0.132483; batch adversarial loss: 0.594244\n",
      "epoch 21; iter: 0; batch classifier loss: 0.188977; batch adversarial loss: 0.461859\n",
      "epoch 22; iter: 0; batch classifier loss: 0.219586; batch adversarial loss: 0.606304\n",
      "epoch 23; iter: 0; batch classifier loss: 0.231589; batch adversarial loss: 0.588400\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214165; batch adversarial loss: 0.553847\n",
      "epoch 25; iter: 0; batch classifier loss: 0.144267; batch adversarial loss: 0.520077\n",
      "epoch 26; iter: 0; batch classifier loss: 0.250260; batch adversarial loss: 0.501119\n",
      "epoch 27; iter: 0; batch classifier loss: 0.211161; batch adversarial loss: 0.440606\n",
      "epoch 28; iter: 0; batch classifier loss: 0.195644; batch adversarial loss: 0.568715\n",
      "epoch 29; iter: 0; batch classifier loss: 0.218381; batch adversarial loss: 0.483408\n",
      "epoch 30; iter: 0; batch classifier loss: 0.165303; batch adversarial loss: 0.450622\n",
      "epoch 31; iter: 0; batch classifier loss: 0.225353; batch adversarial loss: 0.533476\n",
      "epoch 32; iter: 0; batch classifier loss: 0.267529; batch adversarial loss: 0.459426\n",
      "epoch 33; iter: 0; batch classifier loss: 0.293315; batch adversarial loss: 0.471743\n",
      "epoch 34; iter: 0; batch classifier loss: 0.219352; batch adversarial loss: 0.469358\n",
      "epoch 35; iter: 0; batch classifier loss: 0.068432; batch adversarial loss: 0.459831\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140489; batch adversarial loss: 0.511314\n",
      "epoch 37; iter: 0; batch classifier loss: 0.135164; batch adversarial loss: 0.523803\n",
      "epoch 38; iter: 0; batch classifier loss: 0.095263; batch adversarial loss: 0.413447\n",
      "epoch 39; iter: 0; batch classifier loss: 0.105007; batch adversarial loss: 0.485589\n",
      "epoch 40; iter: 0; batch classifier loss: 0.057077; batch adversarial loss: 0.445651\n",
      "epoch 41; iter: 0; batch classifier loss: 0.118667; batch adversarial loss: 0.511126\n",
      "epoch 42; iter: 0; batch classifier loss: 0.109181; batch adversarial loss: 0.582684\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110518; batch adversarial loss: 0.443976\n",
      "epoch 44; iter: 0; batch classifier loss: 0.065841; batch adversarial loss: 0.496956\n",
      "epoch 45; iter: 0; batch classifier loss: 0.087019; batch adversarial loss: 0.489917\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104954; batch adversarial loss: 0.446593\n",
      "epoch 47; iter: 0; batch classifier loss: 0.082132; batch adversarial loss: 0.495222\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100661; batch adversarial loss: 0.504802\n",
      "epoch 49; iter: 0; batch classifier loss: 0.145625; batch adversarial loss: 0.474954\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101112; batch adversarial loss: 0.411841\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098640; batch adversarial loss: 0.453807\n",
      "epoch 52; iter: 0; batch classifier loss: 0.106717; batch adversarial loss: 0.417774\n",
      "epoch 53; iter: 0; batch classifier loss: 0.144778; batch adversarial loss: 0.486752\n",
      "epoch 54; iter: 0; batch classifier loss: 0.046420; batch adversarial loss: 0.501775\n",
      "epoch 55; iter: 0; batch classifier loss: 0.088870; batch adversarial loss: 0.453597\n",
      "epoch 56; iter: 0; batch classifier loss: 0.087738; batch adversarial loss: 0.446868\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090990; batch adversarial loss: 0.544895\n",
      "epoch 58; iter: 0; batch classifier loss: 0.099356; batch adversarial loss: 0.458439\n",
      "epoch 59; iter: 0; batch classifier loss: 0.063058; batch adversarial loss: 0.479183\n",
      "epoch 60; iter: 0; batch classifier loss: 0.091948; batch adversarial loss: 0.555029\n",
      "epoch 61; iter: 0; batch classifier loss: 0.085022; batch adversarial loss: 0.483721\n",
      "epoch 62; iter: 0; batch classifier loss: 0.105058; batch adversarial loss: 0.427891\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093886; batch adversarial loss: 0.456717\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101286; batch adversarial loss: 0.547219\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073981; batch adversarial loss: 0.478596\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087676; batch adversarial loss: 0.470834\n",
      "epoch 67; iter: 0; batch classifier loss: 0.083346; batch adversarial loss: 0.525270\n",
      "epoch 68; iter: 0; batch classifier loss: 0.131343; batch adversarial loss: 0.410719\n",
      "epoch 69; iter: 0; batch classifier loss: 0.060275; batch adversarial loss: 0.465337\n",
      "epoch 70; iter: 0; batch classifier loss: 0.068327; batch adversarial loss: 0.534549\n",
      "epoch 71; iter: 0; batch classifier loss: 0.072194; batch adversarial loss: 0.574495\n",
      "epoch 72; iter: 0; batch classifier loss: 0.113139; batch adversarial loss: 0.361665\n",
      "epoch 73; iter: 0; batch classifier loss: 0.165613; batch adversarial loss: 0.399136\n",
      "epoch 74; iter: 0; batch classifier loss: 0.065920; batch adversarial loss: 0.557375\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079811; batch adversarial loss: 0.494138\n",
      "epoch 76; iter: 0; batch classifier loss: 0.090524; batch adversarial loss: 0.431412\n",
      "epoch 77; iter: 0; batch classifier loss: 0.118026; batch adversarial loss: 0.391691\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082603; batch adversarial loss: 0.540438\n",
      "epoch 79; iter: 0; batch classifier loss: 0.087178; batch adversarial loss: 0.468416\n",
      "epoch 80; iter: 0; batch classifier loss: 0.057611; batch adversarial loss: 0.586957\n",
      "epoch 81; iter: 0; batch classifier loss: 0.105701; batch adversarial loss: 0.384096\n",
      "epoch 82; iter: 0; batch classifier loss: 0.114635; batch adversarial loss: 0.410099\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074363; batch adversarial loss: 0.569202\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048726; batch adversarial loss: 0.513232\n",
      "epoch 85; iter: 0; batch classifier loss: 0.114862; batch adversarial loss: 0.423373\n",
      "epoch 86; iter: 0; batch classifier loss: 0.098948; batch adversarial loss: 0.453777\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079056; batch adversarial loss: 0.501193\n",
      "epoch 88; iter: 0; batch classifier loss: 0.100900; batch adversarial loss: 0.426199\n",
      "epoch 89; iter: 0; batch classifier loss: 0.110930; batch adversarial loss: 0.486979\n",
      "epoch 90; iter: 0; batch classifier loss: 0.082263; batch adversarial loss: 0.530680\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073270; batch adversarial loss: 0.454307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.054195; batch adversarial loss: 0.502428\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053901; batch adversarial loss: 0.504955\n",
      "epoch 94; iter: 0; batch classifier loss: 0.059657; batch adversarial loss: 0.377738\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080805; batch adversarial loss: 0.581654\n",
      "epoch 96; iter: 0; batch classifier loss: 0.033896; batch adversarial loss: 0.479223\n",
      "epoch 97; iter: 0; batch classifier loss: 0.099090; batch adversarial loss: 0.461908\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050756; batch adversarial loss: 0.478624\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062482; batch adversarial loss: 0.517251\n",
      "epoch 100; iter: 0; batch classifier loss: 0.107172; batch adversarial loss: 0.419940\n",
      "epoch 101; iter: 0; batch classifier loss: 0.060395; batch adversarial loss: 0.431434\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059646; batch adversarial loss: 0.506938\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041586; batch adversarial loss: 0.523303\n",
      "epoch 104; iter: 0; batch classifier loss: 0.064458; batch adversarial loss: 0.571639\n",
      "epoch 105; iter: 0; batch classifier loss: 0.096309; batch adversarial loss: 0.437793\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051167; batch adversarial loss: 0.469334\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044209; batch adversarial loss: 0.417130\n",
      "epoch 108; iter: 0; batch classifier loss: 0.083171; batch adversarial loss: 0.451280\n",
      "epoch 109; iter: 0; batch classifier loss: 0.035777; batch adversarial loss: 0.487723\n",
      "epoch 110; iter: 0; batch classifier loss: 0.110141; batch adversarial loss: 0.598634\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041994; batch adversarial loss: 0.518068\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042020; batch adversarial loss: 0.431448\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033297; batch adversarial loss: 0.408608\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059780; batch adversarial loss: 0.585794\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051132; batch adversarial loss: 0.556147\n",
      "epoch 116; iter: 0; batch classifier loss: 0.031394; batch adversarial loss: 0.464886\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030553; batch adversarial loss: 0.509227\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048871; batch adversarial loss: 0.516507\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038835; batch adversarial loss: 0.454890\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032289; batch adversarial loss: 0.457215\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050703; batch adversarial loss: 0.532717\n",
      "epoch 122; iter: 0; batch classifier loss: 0.016994; batch adversarial loss: 0.501821\n",
      "epoch 123; iter: 0; batch classifier loss: 0.094467; batch adversarial loss: 0.399961\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051617; batch adversarial loss: 0.466709\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033858; batch adversarial loss: 0.419859\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051230; batch adversarial loss: 0.490427\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051416; batch adversarial loss: 0.433763\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056296; batch adversarial loss: 0.512226\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036308; batch adversarial loss: 0.438589\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027566; batch adversarial loss: 0.492243\n",
      "epoch 131; iter: 0; batch classifier loss: 0.059666; batch adversarial loss: 0.450711\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053214; batch adversarial loss: 0.466307\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025605; batch adversarial loss: 0.492027\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057778; batch adversarial loss: 0.589498\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041637; batch adversarial loss: 0.385912\n",
      "epoch 136; iter: 0; batch classifier loss: 0.064584; batch adversarial loss: 0.451719\n",
      "epoch 137; iter: 0; batch classifier loss: 0.123735; batch adversarial loss: 0.409658\n",
      "epoch 138; iter: 0; batch classifier loss: 0.057932; batch adversarial loss: 0.546554\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043937; batch adversarial loss: 0.451426\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052319; batch adversarial loss: 0.566870\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038012; batch adversarial loss: 0.454326\n",
      "epoch 142; iter: 0; batch classifier loss: 0.079664; batch adversarial loss: 0.437692\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026065; batch adversarial loss: 0.490856\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017679; batch adversarial loss: 0.516321\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048849; batch adversarial loss: 0.458221\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033035; batch adversarial loss: 0.356970\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031134; batch adversarial loss: 0.483087\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015768; batch adversarial loss: 0.511121\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042471; batch adversarial loss: 0.522044\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012554; batch adversarial loss: 0.486066\n",
      "epoch 151; iter: 0; batch classifier loss: 0.049434; batch adversarial loss: 0.485610\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028197; batch adversarial loss: 0.496376\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014694; batch adversarial loss: 0.392749\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026475; batch adversarial loss: 0.481179\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010142; batch adversarial loss: 0.512227\n",
      "epoch 156; iter: 0; batch classifier loss: 0.094275; batch adversarial loss: 0.444359\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022462; batch adversarial loss: 0.446892\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035315; batch adversarial loss: 0.399421\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022240; batch adversarial loss: 0.446505\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026104; batch adversarial loss: 0.442122\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024814; batch adversarial loss: 0.550996\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019103; batch adversarial loss: 0.481253\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015730; batch adversarial loss: 0.490018\n",
      "epoch 164; iter: 0; batch classifier loss: 0.040479; batch adversarial loss: 0.406429\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013488; batch adversarial loss: 0.476324\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020674; batch adversarial loss: 0.352701\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033576; batch adversarial loss: 0.462398\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026144; batch adversarial loss: 0.483462\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023704; batch adversarial loss: 0.390771\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019289; batch adversarial loss: 0.463018\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025370; batch adversarial loss: 0.452585\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019535; batch adversarial loss: 0.506685\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019996; batch adversarial loss: 0.429412\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010155; batch adversarial loss: 0.386352\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019332; batch adversarial loss: 0.487504\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018130; batch adversarial loss: 0.441757\n",
      "epoch 177; iter: 0; batch classifier loss: 0.004649; batch adversarial loss: 0.431603\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029054; batch adversarial loss: 0.468077\n",
      "epoch 179; iter: 0; batch classifier loss: 0.042321; batch adversarial loss: 0.372139\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012373; batch adversarial loss: 0.431531\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011315; batch adversarial loss: 0.498801\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024956; batch adversarial loss: 0.504460\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034025; batch adversarial loss: 0.497784\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034462; batch adversarial loss: 0.510609\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031179; batch adversarial loss: 0.493803\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019757; batch adversarial loss: 0.428836\n",
      "epoch 187; iter: 0; batch classifier loss: 0.037676; batch adversarial loss: 0.441702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.048657; batch adversarial loss: 0.388718\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023042; batch adversarial loss: 0.522727\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032088; batch adversarial loss: 0.509776\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008839; batch adversarial loss: 0.468248\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037834; batch adversarial loss: 0.477115\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034081; batch adversarial loss: 0.488401\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005353; batch adversarial loss: 0.542144\n",
      "epoch 195; iter: 0; batch classifier loss: 0.042462; batch adversarial loss: 0.569164\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024432; batch adversarial loss: 0.437262\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027142; batch adversarial loss: 0.484590\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030519; batch adversarial loss: 0.454521\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023192; batch adversarial loss: 0.494087\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732811; batch adversarial loss: 1.220853\n",
      "epoch 1; iter: 0; batch classifier loss: 0.751045; batch adversarial loss: 1.412779\n",
      "epoch 2; iter: 0; batch classifier loss: 0.918615; batch adversarial loss: 1.361475\n",
      "epoch 3; iter: 0; batch classifier loss: 1.055432; batch adversarial loss: 1.337603\n",
      "epoch 4; iter: 0; batch classifier loss: 1.141236; batch adversarial loss: 1.252090\n",
      "epoch 5; iter: 0; batch classifier loss: 1.157190; batch adversarial loss: 1.109785\n",
      "epoch 6; iter: 0; batch classifier loss: 1.023848; batch adversarial loss: 1.012289\n",
      "epoch 7; iter: 0; batch classifier loss: 1.064697; batch adversarial loss: 0.927400\n",
      "epoch 8; iter: 0; batch classifier loss: 1.041575; batch adversarial loss: 0.854095\n",
      "epoch 9; iter: 0; batch classifier loss: 1.023265; batch adversarial loss: 0.784887\n",
      "epoch 10; iter: 0; batch classifier loss: 1.115726; batch adversarial loss: 0.720934\n",
      "epoch 11; iter: 0; batch classifier loss: 0.976029; batch adversarial loss: 0.688146\n",
      "epoch 12; iter: 0; batch classifier loss: 0.969041; batch adversarial loss: 0.629006\n",
      "epoch 13; iter: 0; batch classifier loss: 0.945598; batch adversarial loss: 0.588930\n",
      "epoch 14; iter: 0; batch classifier loss: 0.978384; batch adversarial loss: 0.534649\n",
      "epoch 15; iter: 0; batch classifier loss: 0.748855; batch adversarial loss: 0.588170\n",
      "epoch 16; iter: 0; batch classifier loss: 0.626117; batch adversarial loss: 0.527058\n",
      "epoch 17; iter: 0; batch classifier loss: 0.284321; batch adversarial loss: 0.477460\n",
      "epoch 18; iter: 0; batch classifier loss: 0.298897; batch adversarial loss: 0.474515\n",
      "epoch 19; iter: 0; batch classifier loss: 0.319641; batch adversarial loss: 0.516118\n",
      "epoch 20; iter: 0; batch classifier loss: 0.290321; batch adversarial loss: 0.472263\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234093; batch adversarial loss: 0.468788\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181272; batch adversarial loss: 0.442824\n",
      "epoch 23; iter: 0; batch classifier loss: 0.204210; batch adversarial loss: 0.512864\n",
      "epoch 24; iter: 0; batch classifier loss: 0.187559; batch adversarial loss: 0.434917\n",
      "epoch 25; iter: 0; batch classifier loss: 0.146423; batch adversarial loss: 0.444237\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188180; batch adversarial loss: 0.471840\n",
      "epoch 27; iter: 0; batch classifier loss: 0.134229; batch adversarial loss: 0.459907\n",
      "epoch 28; iter: 0; batch classifier loss: 0.150324; batch adversarial loss: 0.508965\n",
      "epoch 29; iter: 0; batch classifier loss: 0.132289; batch adversarial loss: 0.485059\n",
      "epoch 30; iter: 0; batch classifier loss: 0.107036; batch adversarial loss: 0.460790\n",
      "epoch 31; iter: 0; batch classifier loss: 0.126116; batch adversarial loss: 0.427144\n",
      "epoch 32; iter: 0; batch classifier loss: 0.143125; batch adversarial loss: 0.403614\n",
      "epoch 33; iter: 0; batch classifier loss: 0.126045; batch adversarial loss: 0.470496\n",
      "epoch 34; iter: 0; batch classifier loss: 0.097123; batch adversarial loss: 0.448281\n",
      "epoch 35; iter: 0; batch classifier loss: 0.091191; batch adversarial loss: 0.475421\n",
      "epoch 36; iter: 0; batch classifier loss: 0.098049; batch adversarial loss: 0.490716\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111297; batch adversarial loss: 0.455674\n",
      "epoch 38; iter: 0; batch classifier loss: 0.128379; batch adversarial loss: 0.466944\n",
      "epoch 39; iter: 0; batch classifier loss: 0.092605; batch adversarial loss: 0.414777\n",
      "epoch 40; iter: 0; batch classifier loss: 0.068416; batch adversarial loss: 0.483901\n",
      "epoch 41; iter: 0; batch classifier loss: 0.076934; batch adversarial loss: 0.451061\n",
      "epoch 42; iter: 0; batch classifier loss: 0.075941; batch adversarial loss: 0.491450\n",
      "epoch 43; iter: 0; batch classifier loss: 0.096209; batch adversarial loss: 0.441742\n",
      "epoch 44; iter: 0; batch classifier loss: 0.077414; batch adversarial loss: 0.496525\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086930; batch adversarial loss: 0.542405\n",
      "epoch 46; iter: 0; batch classifier loss: 0.089759; batch adversarial loss: 0.503194\n",
      "epoch 47; iter: 0; batch classifier loss: 0.063577; batch adversarial loss: 0.495047\n",
      "epoch 48; iter: 0; batch classifier loss: 0.064056; batch adversarial loss: 0.494878\n",
      "epoch 49; iter: 0; batch classifier loss: 0.062769; batch adversarial loss: 0.410228\n",
      "epoch 50; iter: 0; batch classifier loss: 0.053878; batch adversarial loss: 0.426072\n",
      "epoch 51; iter: 0; batch classifier loss: 0.091342; batch adversarial loss: 0.477344\n",
      "epoch 52; iter: 0; batch classifier loss: 0.059847; batch adversarial loss: 0.392514\n",
      "epoch 53; iter: 0; batch classifier loss: 0.049212; batch adversarial loss: 0.498814\n",
      "epoch 54; iter: 0; batch classifier loss: 0.060039; batch adversarial loss: 0.353528\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087491; batch adversarial loss: 0.468636\n",
      "epoch 56; iter: 0; batch classifier loss: 0.059455; batch adversarial loss: 0.475612\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079568; batch adversarial loss: 0.435719\n",
      "epoch 58; iter: 0; batch classifier loss: 0.068985; batch adversarial loss: 0.443002\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087789; batch adversarial loss: 0.471679\n",
      "epoch 60; iter: 0; batch classifier loss: 0.075903; batch adversarial loss: 0.360120\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074243; batch adversarial loss: 0.393290\n",
      "epoch 62; iter: 0; batch classifier loss: 0.111052; batch adversarial loss: 0.521602\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093430; batch adversarial loss: 0.470193\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106034; batch adversarial loss: 0.511187\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107329; batch adversarial loss: 0.491463\n",
      "epoch 66; iter: 0; batch classifier loss: 0.090014; batch adversarial loss: 0.510730\n",
      "epoch 67; iter: 0; batch classifier loss: 0.081559; batch adversarial loss: 0.459936\n",
      "epoch 68; iter: 0; batch classifier loss: 0.051227; batch adversarial loss: 0.547999\n",
      "epoch 69; iter: 0; batch classifier loss: 0.054312; batch adversarial loss: 0.580915\n",
      "epoch 70; iter: 0; batch classifier loss: 0.071097; batch adversarial loss: 0.500523\n",
      "epoch 71; iter: 0; batch classifier loss: 0.057111; batch adversarial loss: 0.426243\n",
      "epoch 72; iter: 0; batch classifier loss: 0.066416; batch adversarial loss: 0.455831\n",
      "epoch 73; iter: 0; batch classifier loss: 0.049185; batch adversarial loss: 0.407546\n",
      "epoch 74; iter: 0; batch classifier loss: 0.060351; batch adversarial loss: 0.491765\n",
      "epoch 75; iter: 0; batch classifier loss: 0.052219; batch adversarial loss: 0.498904\n",
      "epoch 76; iter: 0; batch classifier loss: 0.108275; batch adversarial loss: 0.523000\n",
      "epoch 77; iter: 0; batch classifier loss: 0.073881; batch adversarial loss: 0.453115\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090392; batch adversarial loss: 0.292751\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070397; batch adversarial loss: 0.373152\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043951; batch adversarial loss: 0.492289\n",
      "epoch 81; iter: 0; batch classifier loss: 0.026951; batch adversarial loss: 0.476255\n",
      "epoch 82; iter: 0; batch classifier loss: 0.026878; batch adversarial loss: 0.441245\n",
      "epoch 83; iter: 0; batch classifier loss: 0.097550; batch adversarial loss: 0.524165\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077039; batch adversarial loss: 0.432089\n",
      "epoch 85; iter: 0; batch classifier loss: 0.102289; batch adversarial loss: 0.447864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.087505; batch adversarial loss: 0.424926\n",
      "epoch 87; iter: 0; batch classifier loss: 0.061163; batch adversarial loss: 0.391069\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058914; batch adversarial loss: 0.522336\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042113; batch adversarial loss: 0.502016\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056130; batch adversarial loss: 0.465906\n",
      "epoch 91; iter: 0; batch classifier loss: 0.072623; batch adversarial loss: 0.438775\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066437; batch adversarial loss: 0.409675\n",
      "epoch 93; iter: 0; batch classifier loss: 0.027009; batch adversarial loss: 0.425597\n",
      "epoch 94; iter: 0; batch classifier loss: 0.093352; batch adversarial loss: 0.466677\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065740; batch adversarial loss: 0.476671\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047619; batch adversarial loss: 0.407334\n",
      "epoch 97; iter: 0; batch classifier loss: 0.024615; batch adversarial loss: 0.423093\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035199; batch adversarial loss: 0.433799\n",
      "epoch 99; iter: 0; batch classifier loss: 0.032508; batch adversarial loss: 0.480487\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045232; batch adversarial loss: 0.382137\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037838; batch adversarial loss: 0.441758\n",
      "epoch 102; iter: 0; batch classifier loss: 0.024073; batch adversarial loss: 0.442008\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064474; batch adversarial loss: 0.399498\n",
      "epoch 104; iter: 0; batch classifier loss: 0.040933; batch adversarial loss: 0.399877\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061787; batch adversarial loss: 0.469228\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035174; batch adversarial loss: 0.453757\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045393; batch adversarial loss: 0.420370\n",
      "epoch 108; iter: 0; batch classifier loss: 0.087646; batch adversarial loss: 0.407876\n",
      "epoch 109; iter: 0; batch classifier loss: 0.075552; batch adversarial loss: 0.483422\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067280; batch adversarial loss: 0.431461\n",
      "epoch 111; iter: 0; batch classifier loss: 0.013132; batch adversarial loss: 0.462021\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045034; batch adversarial loss: 0.491331\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043722; batch adversarial loss: 0.482063\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041142; batch adversarial loss: 0.431684\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060121; batch adversarial loss: 0.518587\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053928; batch adversarial loss: 0.479697\n",
      "epoch 117; iter: 0; batch classifier loss: 0.068128; batch adversarial loss: 0.456889\n",
      "epoch 118; iter: 0; batch classifier loss: 0.058291; batch adversarial loss: 0.510665\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022572; batch adversarial loss: 0.387572\n",
      "epoch 120; iter: 0; batch classifier loss: 0.068975; batch adversarial loss: 0.407936\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032659; batch adversarial loss: 0.375527\n",
      "epoch 122; iter: 0; batch classifier loss: 0.063254; batch adversarial loss: 0.441517\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055994; batch adversarial loss: 0.461965\n",
      "epoch 124; iter: 0; batch classifier loss: 0.015243; batch adversarial loss: 0.407635\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022910; batch adversarial loss: 0.463181\n",
      "epoch 126; iter: 0; batch classifier loss: 0.064968; batch adversarial loss: 0.425904\n",
      "epoch 127; iter: 0; batch classifier loss: 0.068993; batch adversarial loss: 0.465946\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034643; batch adversarial loss: 0.514172\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019684; batch adversarial loss: 0.517245\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061291; batch adversarial loss: 0.497213\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035266; batch adversarial loss: 0.420266\n",
      "epoch 132; iter: 0; batch classifier loss: 0.092726; batch adversarial loss: 0.373176\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034913; batch adversarial loss: 0.374431\n",
      "epoch 134; iter: 0; batch classifier loss: 0.044997; batch adversarial loss: 0.500883\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049125; batch adversarial loss: 0.535057\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049686; batch adversarial loss: 0.407680\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024641; batch adversarial loss: 0.485573\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026813; batch adversarial loss: 0.547057\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030411; batch adversarial loss: 0.425609\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028675; batch adversarial loss: 0.497649\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028181; batch adversarial loss: 0.509341\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026116; batch adversarial loss: 0.480365\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022954; batch adversarial loss: 0.482325\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047434; batch adversarial loss: 0.474513\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026261; batch adversarial loss: 0.482215\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051812; batch adversarial loss: 0.547524\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039980; batch adversarial loss: 0.472282\n",
      "epoch 148; iter: 0; batch classifier loss: 0.050927; batch adversarial loss: 0.369449\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036120; batch adversarial loss: 0.437093\n",
      "epoch 150; iter: 0; batch classifier loss: 0.045671; batch adversarial loss: 0.582579\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030957; batch adversarial loss: 0.543716\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031604; batch adversarial loss: 0.442510\n",
      "epoch 153; iter: 0; batch classifier loss: 0.056943; batch adversarial loss: 0.477068\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023978; batch adversarial loss: 0.477982\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014781; batch adversarial loss: 0.396393\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029738; batch adversarial loss: 0.422127\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037063; batch adversarial loss: 0.496197\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042181; batch adversarial loss: 0.399440\n",
      "epoch 159; iter: 0; batch classifier loss: 0.054911; batch adversarial loss: 0.466531\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032183; batch adversarial loss: 0.501574\n",
      "epoch 161; iter: 0; batch classifier loss: 0.044165; batch adversarial loss: 0.443217\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034081; batch adversarial loss: 0.424073\n",
      "epoch 163; iter: 0; batch classifier loss: 0.060381; batch adversarial loss: 0.370993\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013843; batch adversarial loss: 0.430378\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044315; batch adversarial loss: 0.487634\n",
      "epoch 166; iter: 0; batch classifier loss: 0.041117; batch adversarial loss: 0.492547\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024435; batch adversarial loss: 0.383269\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019854; batch adversarial loss: 0.410956\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030722; batch adversarial loss: 0.447611\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032399; batch adversarial loss: 0.460548\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047129; batch adversarial loss: 0.427883\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017544; batch adversarial loss: 0.309140\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030209; batch adversarial loss: 0.443488\n",
      "epoch 174; iter: 0; batch classifier loss: 0.005434; batch adversarial loss: 0.469655\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020841; batch adversarial loss: 0.514827\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024008; batch adversarial loss: 0.416127\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030004; batch adversarial loss: 0.441525\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014754; batch adversarial loss: 0.401219\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023988; batch adversarial loss: 0.498106\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033221; batch adversarial loss: 0.548100\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016145; batch adversarial loss: 0.459520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.069357; batch adversarial loss: 0.438973\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024131; batch adversarial loss: 0.471248\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020544; batch adversarial loss: 0.536357\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016252; batch adversarial loss: 0.533245\n",
      "epoch 186; iter: 0; batch classifier loss: 0.038433; batch adversarial loss: 0.450106\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027184; batch adversarial loss: 0.449714\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030062; batch adversarial loss: 0.434544\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013585; batch adversarial loss: 0.545720\n",
      "epoch 190; iter: 0; batch classifier loss: 0.053085; batch adversarial loss: 0.476802\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019605; batch adversarial loss: 0.588809\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019212; batch adversarial loss: 0.469898\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026182; batch adversarial loss: 0.466081\n",
      "epoch 194; iter: 0; batch classifier loss: 0.040675; batch adversarial loss: 0.438632\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028624; batch adversarial loss: 0.465065\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019480; batch adversarial loss: 0.440622\n",
      "epoch 197; iter: 0; batch classifier loss: 0.048066; batch adversarial loss: 0.434776\n",
      "epoch 198; iter: 0; batch classifier loss: 0.036848; batch adversarial loss: 0.382429\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016785; batch adversarial loss: 0.386169\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674741; batch adversarial loss: 0.740590\n",
      "epoch 1; iter: 0; batch classifier loss: 0.417038; batch adversarial loss: 0.709795\n",
      "epoch 2; iter: 0; batch classifier loss: 0.386916; batch adversarial loss: 0.689131\n",
      "epoch 3; iter: 0; batch classifier loss: 0.383471; batch adversarial loss: 0.649786\n",
      "epoch 4; iter: 0; batch classifier loss: 0.366210; batch adversarial loss: 0.613495\n",
      "epoch 5; iter: 0; batch classifier loss: 0.292560; batch adversarial loss: 0.580617\n",
      "epoch 6; iter: 0; batch classifier loss: 0.395511; batch adversarial loss: 0.559987\n",
      "epoch 7; iter: 0; batch classifier loss: 0.355349; batch adversarial loss: 0.542053\n",
      "epoch 8; iter: 0; batch classifier loss: 0.246327; batch adversarial loss: 0.526345\n",
      "epoch 9; iter: 0; batch classifier loss: 0.219677; batch adversarial loss: 0.464298\n",
      "epoch 10; iter: 0; batch classifier loss: 0.225368; batch adversarial loss: 0.508781\n",
      "epoch 11; iter: 0; batch classifier loss: 0.260028; batch adversarial loss: 0.500603\n",
      "epoch 12; iter: 0; batch classifier loss: 0.247444; batch adversarial loss: 0.516304\n",
      "epoch 13; iter: 0; batch classifier loss: 0.216459; batch adversarial loss: 0.470547\n",
      "epoch 14; iter: 0; batch classifier loss: 0.189155; batch adversarial loss: 0.512729\n",
      "epoch 15; iter: 0; batch classifier loss: 0.215445; batch adversarial loss: 0.480377\n",
      "epoch 16; iter: 0; batch classifier loss: 0.128818; batch adversarial loss: 0.438709\n",
      "epoch 17; iter: 0; batch classifier loss: 0.159148; batch adversarial loss: 0.483376\n",
      "epoch 18; iter: 0; batch classifier loss: 0.157195; batch adversarial loss: 0.488655\n",
      "epoch 19; iter: 0; batch classifier loss: 0.079991; batch adversarial loss: 0.400927\n",
      "epoch 20; iter: 0; batch classifier loss: 0.145278; batch adversarial loss: 0.457186\n",
      "epoch 21; iter: 0; batch classifier loss: 0.115980; batch adversarial loss: 0.402268\n",
      "epoch 22; iter: 0; batch classifier loss: 0.111608; batch adversarial loss: 0.499063\n",
      "epoch 23; iter: 0; batch classifier loss: 0.176981; batch adversarial loss: 0.443664\n",
      "epoch 24; iter: 0; batch classifier loss: 0.125235; batch adversarial loss: 0.388743\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132103; batch adversarial loss: 0.506078\n",
      "epoch 26; iter: 0; batch classifier loss: 0.130125; batch adversarial loss: 0.396876\n",
      "epoch 27; iter: 0; batch classifier loss: 0.101756; batch adversarial loss: 0.371063\n",
      "epoch 28; iter: 0; batch classifier loss: 0.119135; batch adversarial loss: 0.353344\n",
      "epoch 29; iter: 0; batch classifier loss: 0.139566; batch adversarial loss: 0.419972\n",
      "epoch 30; iter: 0; batch classifier loss: 0.099228; batch adversarial loss: 0.401588\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134956; batch adversarial loss: 0.445409\n",
      "epoch 32; iter: 0; batch classifier loss: 0.127590; batch adversarial loss: 0.452798\n",
      "epoch 33; iter: 0; batch classifier loss: 0.155447; batch adversarial loss: 0.378884\n",
      "epoch 34; iter: 0; batch classifier loss: 0.124532; batch adversarial loss: 0.362277\n",
      "epoch 35; iter: 0; batch classifier loss: 0.159839; batch adversarial loss: 0.440006\n",
      "epoch 36; iter: 0; batch classifier loss: 0.139028; batch adversarial loss: 0.489983\n",
      "epoch 37; iter: 0; batch classifier loss: 0.116916; batch adversarial loss: 0.389885\n",
      "epoch 38; iter: 0; batch classifier loss: 0.147947; batch adversarial loss: 0.375790\n",
      "epoch 39; iter: 0; batch classifier loss: 0.165928; batch adversarial loss: 0.352517\n",
      "epoch 40; iter: 0; batch classifier loss: 0.137770; batch adversarial loss: 0.431071\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104141; batch adversarial loss: 0.393261\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103374; batch adversarial loss: 0.380172\n",
      "epoch 43; iter: 0; batch classifier loss: 0.067952; batch adversarial loss: 0.371930\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105595; batch adversarial loss: 0.471684\n",
      "epoch 45; iter: 0; batch classifier loss: 0.069580; batch adversarial loss: 0.302318\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117992; batch adversarial loss: 0.335487\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114837; batch adversarial loss: 0.349658\n",
      "epoch 48; iter: 0; batch classifier loss: 0.068762; batch adversarial loss: 0.398930\n",
      "epoch 49; iter: 0; batch classifier loss: 0.085395; batch adversarial loss: 0.332492\n",
      "epoch 50; iter: 0; batch classifier loss: 0.079360; batch adversarial loss: 0.377272\n",
      "epoch 51; iter: 0; batch classifier loss: 0.134379; batch adversarial loss: 0.409900\n",
      "epoch 52; iter: 0; batch classifier loss: 0.063826; batch adversarial loss: 0.420535\n",
      "epoch 53; iter: 0; batch classifier loss: 0.081899; batch adversarial loss: 0.437588\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079050; batch adversarial loss: 0.434687\n",
      "epoch 55; iter: 0; batch classifier loss: 0.106389; batch adversarial loss: 0.425858\n",
      "epoch 56; iter: 0; batch classifier loss: 0.072366; batch adversarial loss: 0.379042\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082422; batch adversarial loss: 0.396782\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078588; batch adversarial loss: 0.401623\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099055; batch adversarial loss: 0.389087\n",
      "epoch 60; iter: 0; batch classifier loss: 0.082673; batch adversarial loss: 0.411110\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090390; batch adversarial loss: 0.388579\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083008; batch adversarial loss: 0.387914\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097350; batch adversarial loss: 0.504344\n",
      "epoch 64; iter: 0; batch classifier loss: 0.107958; batch adversarial loss: 0.402889\n",
      "epoch 65; iter: 0; batch classifier loss: 0.085860; batch adversarial loss: 0.401153\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068497; batch adversarial loss: 0.452060\n",
      "epoch 67; iter: 0; batch classifier loss: 0.113782; batch adversarial loss: 0.378370\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070538; batch adversarial loss: 0.326825\n",
      "epoch 69; iter: 0; batch classifier loss: 0.099887; batch adversarial loss: 0.398276\n",
      "epoch 70; iter: 0; batch classifier loss: 0.074215; batch adversarial loss: 0.464974\n",
      "epoch 71; iter: 0; batch classifier loss: 0.059037; batch adversarial loss: 0.477089\n",
      "epoch 72; iter: 0; batch classifier loss: 0.059372; batch adversarial loss: 0.446671\n",
      "epoch 73; iter: 0; batch classifier loss: 0.096469; batch adversarial loss: 0.407703\n",
      "epoch 74; iter: 0; batch classifier loss: 0.087460; batch adversarial loss: 0.383630\n",
      "epoch 75; iter: 0; batch classifier loss: 0.072457; batch adversarial loss: 0.414134\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058519; batch adversarial loss: 0.497290\n",
      "epoch 77; iter: 0; batch classifier loss: 0.066082; batch adversarial loss: 0.430848\n",
      "epoch 78; iter: 0; batch classifier loss: 0.086445; batch adversarial loss: 0.446264\n",
      "epoch 79; iter: 0; batch classifier loss: 0.095531; batch adversarial loss: 0.487929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.068950; batch adversarial loss: 0.438223\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071723; batch adversarial loss: 0.435733\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091993; batch adversarial loss: 0.448112\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080058; batch adversarial loss: 0.414123\n",
      "epoch 84; iter: 0; batch classifier loss: 0.098016; batch adversarial loss: 0.480246\n",
      "epoch 85; iter: 0; batch classifier loss: 0.097821; batch adversarial loss: 0.468776\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054618; batch adversarial loss: 0.449207\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072048; batch adversarial loss: 0.405652\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054200; batch adversarial loss: 0.395780\n",
      "epoch 89; iter: 0; batch classifier loss: 0.062508; batch adversarial loss: 0.363546\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073058; batch adversarial loss: 0.400012\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066955; batch adversarial loss: 0.476865\n",
      "epoch 92; iter: 0; batch classifier loss: 0.104085; batch adversarial loss: 0.327930\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051414; batch adversarial loss: 0.399888\n",
      "epoch 94; iter: 0; batch classifier loss: 0.074837; batch adversarial loss: 0.435041\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050091; batch adversarial loss: 0.429004\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047067; batch adversarial loss: 0.418953\n",
      "epoch 97; iter: 0; batch classifier loss: 0.031848; batch adversarial loss: 0.427135\n",
      "epoch 98; iter: 0; batch classifier loss: 0.060406; batch adversarial loss: 0.440466\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054247; batch adversarial loss: 0.476647\n",
      "epoch 100; iter: 0; batch classifier loss: 0.068197; batch adversarial loss: 0.461816\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048291; batch adversarial loss: 0.381511\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031213; batch adversarial loss: 0.427412\n",
      "epoch 103; iter: 0; batch classifier loss: 0.065634; batch adversarial loss: 0.404127\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045970; batch adversarial loss: 0.451533\n",
      "epoch 105; iter: 0; batch classifier loss: 0.063704; batch adversarial loss: 0.460860\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058666; batch adversarial loss: 0.476054\n",
      "epoch 107; iter: 0; batch classifier loss: 0.043485; batch adversarial loss: 0.460715\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060988; batch adversarial loss: 0.409035\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045774; batch adversarial loss: 0.394049\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046258; batch adversarial loss: 0.401728\n",
      "epoch 111; iter: 0; batch classifier loss: 0.071856; batch adversarial loss: 0.405027\n",
      "epoch 112; iter: 0; batch classifier loss: 0.068939; batch adversarial loss: 0.394438\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046819; batch adversarial loss: 0.374429\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062103; batch adversarial loss: 0.390038\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057438; batch adversarial loss: 0.433860\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035322; batch adversarial loss: 0.471944\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036166; batch adversarial loss: 0.361849\n",
      "epoch 118; iter: 0; batch classifier loss: 0.034349; batch adversarial loss: 0.431486\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033419; batch adversarial loss: 0.398682\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041776; batch adversarial loss: 0.438478\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058117; batch adversarial loss: 0.525962\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035752; batch adversarial loss: 0.459028\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041784; batch adversarial loss: 0.363979\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030895; batch adversarial loss: 0.458613\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039438; batch adversarial loss: 0.421704\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031294; batch adversarial loss: 0.421089\n",
      "epoch 127; iter: 0; batch classifier loss: 0.015568; batch adversarial loss: 0.497736\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019543; batch adversarial loss: 0.430166\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033292; batch adversarial loss: 0.494587\n",
      "epoch 130; iter: 0; batch classifier loss: 0.012743; batch adversarial loss: 0.456767\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022343; batch adversarial loss: 0.394250\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019387; batch adversarial loss: 0.462540\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020718; batch adversarial loss: 0.520340\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057030; batch adversarial loss: 0.514369\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024395; batch adversarial loss: 0.523495\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042855; batch adversarial loss: 0.440036\n",
      "epoch 137; iter: 0; batch classifier loss: 0.103722; batch adversarial loss: 0.573170\n",
      "epoch 138; iter: 0; batch classifier loss: 0.073874; batch adversarial loss: 0.611289\n",
      "epoch 139; iter: 0; batch classifier loss: 0.135485; batch adversarial loss: 0.735276\n",
      "epoch 140; iter: 0; batch classifier loss: 0.213371; batch adversarial loss: 0.717448\n",
      "epoch 141; iter: 0; batch classifier loss: 0.108297; batch adversarial loss: 0.563900\n",
      "epoch 142; iter: 0; batch classifier loss: 0.108175; batch adversarial loss: 0.496353\n",
      "epoch 143; iter: 0; batch classifier loss: 0.185204; batch adversarial loss: 0.791950\n",
      "epoch 144; iter: 0; batch classifier loss: 0.099331; batch adversarial loss: 0.574875\n",
      "epoch 145; iter: 0; batch classifier loss: 0.087205; batch adversarial loss: 0.545891\n",
      "epoch 146; iter: 0; batch classifier loss: 0.139716; batch adversarial loss: 0.621338\n",
      "epoch 147; iter: 0; batch classifier loss: 0.248588; batch adversarial loss: 0.811883\n",
      "epoch 148; iter: 0; batch classifier loss: 0.136642; batch adversarial loss: 0.676414\n",
      "epoch 149; iter: 0; batch classifier loss: 0.224057; batch adversarial loss: 0.670078\n",
      "epoch 150; iter: 0; batch classifier loss: 0.204512; batch adversarial loss: 0.704992\n",
      "epoch 151; iter: 0; batch classifier loss: 0.160775; batch adversarial loss: 0.699247\n",
      "epoch 152; iter: 0; batch classifier loss: 0.162062; batch adversarial loss: 0.688644\n",
      "epoch 153; iter: 0; batch classifier loss: 0.206532; batch adversarial loss: 0.638998\n",
      "epoch 154; iter: 0; batch classifier loss: 0.237700; batch adversarial loss: 0.691276\n",
      "epoch 155; iter: 0; batch classifier loss: 0.287237; batch adversarial loss: 0.802354\n",
      "epoch 156; iter: 0; batch classifier loss: 0.226552; batch adversarial loss: 0.714857\n",
      "epoch 157; iter: 0; batch classifier loss: 0.190740; batch adversarial loss: 0.605457\n",
      "epoch 158; iter: 0; batch classifier loss: 0.197167; batch adversarial loss: 0.579818\n",
      "epoch 159; iter: 0; batch classifier loss: 0.142605; batch adversarial loss: 0.586209\n",
      "epoch 160; iter: 0; batch classifier loss: 0.119390; batch adversarial loss: 0.531096\n",
      "epoch 161; iter: 0; batch classifier loss: 0.163520; batch adversarial loss: 0.623286\n",
      "epoch 162; iter: 0; batch classifier loss: 0.138210; batch adversarial loss: 0.538348\n",
      "epoch 163; iter: 0; batch classifier loss: 0.144222; batch adversarial loss: 0.575060\n",
      "epoch 164; iter: 0; batch classifier loss: 0.162709; batch adversarial loss: 0.590311\n",
      "epoch 165; iter: 0; batch classifier loss: 0.136042; batch adversarial loss: 0.556561\n",
      "epoch 166; iter: 0; batch classifier loss: 0.125938; batch adversarial loss: 0.510894\n",
      "epoch 167; iter: 0; batch classifier loss: 0.114974; batch adversarial loss: 0.483446\n",
      "epoch 168; iter: 0; batch classifier loss: 0.143960; batch adversarial loss: 0.502179\n",
      "epoch 169; iter: 0; batch classifier loss: 0.136024; batch adversarial loss: 0.473273\n",
      "epoch 170; iter: 0; batch classifier loss: 0.170905; batch adversarial loss: 0.573562\n",
      "epoch 171; iter: 0; batch classifier loss: 0.172424; batch adversarial loss: 0.537251\n",
      "epoch 172; iter: 0; batch classifier loss: 0.100562; batch adversarial loss: 0.462513\n",
      "epoch 173; iter: 0; batch classifier loss: 0.123904; batch adversarial loss: 0.464406\n",
      "epoch 174; iter: 0; batch classifier loss: 0.190312; batch adversarial loss: 0.582867\n",
      "epoch 175; iter: 0; batch classifier loss: 0.108530; batch adversarial loss: 0.476398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.094596; batch adversarial loss: 0.462929\n",
      "epoch 177; iter: 0; batch classifier loss: 0.121142; batch adversarial loss: 0.503444\n",
      "epoch 178; iter: 0; batch classifier loss: 0.151289; batch adversarial loss: 0.525342\n",
      "epoch 179; iter: 0; batch classifier loss: 0.142033; batch adversarial loss: 0.550090\n",
      "epoch 180; iter: 0; batch classifier loss: 0.119114; batch adversarial loss: 0.537975\n",
      "epoch 181; iter: 0; batch classifier loss: 0.086484; batch adversarial loss: 0.374111\n",
      "epoch 182; iter: 0; batch classifier loss: 0.079618; batch adversarial loss: 0.385171\n",
      "epoch 183; iter: 0; batch classifier loss: 0.158330; batch adversarial loss: 0.506862\n",
      "epoch 184; iter: 0; batch classifier loss: 0.100129; batch adversarial loss: 0.419249\n",
      "epoch 185; iter: 0; batch classifier loss: 0.199707; batch adversarial loss: 0.680843\n",
      "epoch 186; iter: 0; batch classifier loss: 0.104668; batch adversarial loss: 0.461455\n",
      "epoch 187; iter: 0; batch classifier loss: 0.087268; batch adversarial loss: 0.497879\n",
      "epoch 188; iter: 0; batch classifier loss: 0.106603; batch adversarial loss: 0.484968\n",
      "epoch 189; iter: 0; batch classifier loss: 0.148883; batch adversarial loss: 0.522325\n",
      "epoch 190; iter: 0; batch classifier loss: 0.065132; batch adversarial loss: 0.378241\n",
      "epoch 191; iter: 0; batch classifier loss: 0.094670; batch adversarial loss: 0.414117\n",
      "epoch 192; iter: 0; batch classifier loss: 0.086603; batch adversarial loss: 0.436069\n",
      "epoch 193; iter: 0; batch classifier loss: 0.112450; batch adversarial loss: 0.471072\n",
      "epoch 194; iter: 0; batch classifier loss: 0.029444; batch adversarial loss: 0.397547\n",
      "epoch 195; iter: 0; batch classifier loss: 0.058923; batch adversarial loss: 0.553134\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033803; batch adversarial loss: 0.445218\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016195; batch adversarial loss: 0.443040\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028573; batch adversarial loss: 0.317379\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026523; batch adversarial loss: 0.433023\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700878; batch adversarial loss: 0.604304\n",
      "epoch 1; iter: 0; batch classifier loss: 0.364510; batch adversarial loss: 0.641833\n",
      "epoch 2; iter: 0; batch classifier loss: 0.419471; batch adversarial loss: 0.601373\n",
      "epoch 3; iter: 0; batch classifier loss: 0.392237; batch adversarial loss: 0.585703\n",
      "epoch 4; iter: 0; batch classifier loss: 0.418578; batch adversarial loss: 0.595882\n",
      "epoch 5; iter: 0; batch classifier loss: 0.425239; batch adversarial loss: 0.607611\n",
      "epoch 6; iter: 0; batch classifier loss: 0.522616; batch adversarial loss: 0.597425\n",
      "epoch 7; iter: 0; batch classifier loss: 0.618149; batch adversarial loss: 0.573905\n",
      "epoch 8; iter: 0; batch classifier loss: 0.597426; batch adversarial loss: 0.544096\n",
      "epoch 9; iter: 0; batch classifier loss: 0.386915; batch adversarial loss: 0.551997\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472617; batch adversarial loss: 0.520724\n",
      "epoch 11; iter: 0; batch classifier loss: 0.320440; batch adversarial loss: 0.556569\n",
      "epoch 12; iter: 0; batch classifier loss: 0.319029; batch adversarial loss: 0.486060\n",
      "epoch 13; iter: 0; batch classifier loss: 0.357018; batch adversarial loss: 0.468965\n",
      "epoch 14; iter: 0; batch classifier loss: 0.333017; batch adversarial loss: 0.540343\n",
      "epoch 15; iter: 0; batch classifier loss: 0.361923; batch adversarial loss: 0.521349\n",
      "epoch 16; iter: 0; batch classifier loss: 0.363460; batch adversarial loss: 0.467136\n",
      "epoch 17; iter: 0; batch classifier loss: 0.336157; batch adversarial loss: 0.464616\n",
      "epoch 18; iter: 0; batch classifier loss: 0.250421; batch adversarial loss: 0.468615\n",
      "epoch 19; iter: 0; batch classifier loss: 0.300252; batch adversarial loss: 0.476909\n",
      "epoch 20; iter: 0; batch classifier loss: 0.276159; batch adversarial loss: 0.501129\n",
      "epoch 21; iter: 0; batch classifier loss: 0.306713; batch adversarial loss: 0.527509\n",
      "epoch 22; iter: 0; batch classifier loss: 0.205541; batch adversarial loss: 0.416383\n",
      "epoch 23; iter: 0; batch classifier loss: 0.245140; batch adversarial loss: 0.441541\n",
      "epoch 24; iter: 0; batch classifier loss: 0.249994; batch adversarial loss: 0.465956\n",
      "epoch 25; iter: 0; batch classifier loss: 0.238580; batch adversarial loss: 0.457404\n",
      "epoch 26; iter: 0; batch classifier loss: 0.294950; batch adversarial loss: 0.440382\n",
      "epoch 27; iter: 0; batch classifier loss: 0.236283; batch adversarial loss: 0.426528\n",
      "epoch 28; iter: 0; batch classifier loss: 0.232463; batch adversarial loss: 0.419698\n",
      "epoch 29; iter: 0; batch classifier loss: 0.181939; batch adversarial loss: 0.424013\n",
      "epoch 30; iter: 0; batch classifier loss: 0.221578; batch adversarial loss: 0.423367\n",
      "epoch 31; iter: 0; batch classifier loss: 0.260167; batch adversarial loss: 0.478364\n",
      "epoch 32; iter: 0; batch classifier loss: 0.195341; batch adversarial loss: 0.427523\n",
      "epoch 33; iter: 0; batch classifier loss: 0.226938; batch adversarial loss: 0.466100\n",
      "epoch 34; iter: 0; batch classifier loss: 0.261963; batch adversarial loss: 0.432929\n",
      "epoch 35; iter: 0; batch classifier loss: 0.217344; batch adversarial loss: 0.469426\n",
      "epoch 36; iter: 0; batch classifier loss: 0.191469; batch adversarial loss: 0.532315\n",
      "epoch 37; iter: 0; batch classifier loss: 0.272203; batch adversarial loss: 0.496039\n",
      "epoch 38; iter: 0; batch classifier loss: 0.271256; batch adversarial loss: 0.492655\n",
      "epoch 39; iter: 0; batch classifier loss: 0.241807; batch adversarial loss: 0.472762\n",
      "epoch 40; iter: 0; batch classifier loss: 0.263619; batch adversarial loss: 0.416260\n",
      "epoch 41; iter: 0; batch classifier loss: 0.246128; batch adversarial loss: 0.479704\n",
      "epoch 42; iter: 0; batch classifier loss: 0.239690; batch adversarial loss: 0.545716\n",
      "epoch 43; iter: 0; batch classifier loss: 0.290788; batch adversarial loss: 0.412236\n",
      "epoch 44; iter: 0; batch classifier loss: 0.239404; batch adversarial loss: 0.493054\n",
      "epoch 45; iter: 0; batch classifier loss: 0.201569; batch adversarial loss: 0.506670\n",
      "epoch 46; iter: 0; batch classifier loss: 0.195180; batch adversarial loss: 0.529612\n",
      "epoch 47; iter: 0; batch classifier loss: 0.222957; batch adversarial loss: 0.552220\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125725; batch adversarial loss: 0.411876\n",
      "epoch 49; iter: 0; batch classifier loss: 0.118438; batch adversarial loss: 0.400362\n",
      "epoch 50; iter: 0; batch classifier loss: 0.286874; batch adversarial loss: 0.459679\n",
      "epoch 51; iter: 0; batch classifier loss: 0.125876; batch adversarial loss: 0.541641\n",
      "epoch 52; iter: 0; batch classifier loss: 0.200274; batch adversarial loss: 0.433174\n",
      "epoch 53; iter: 0; batch classifier loss: 0.279865; batch adversarial loss: 0.460322\n",
      "epoch 54; iter: 0; batch classifier loss: 0.171262; batch adversarial loss: 0.457909\n",
      "epoch 55; iter: 0; batch classifier loss: 0.162186; batch adversarial loss: 0.445656\n",
      "epoch 56; iter: 0; batch classifier loss: 0.239214; batch adversarial loss: 0.506809\n",
      "epoch 57; iter: 0; batch classifier loss: 0.149000; batch adversarial loss: 0.530344\n",
      "epoch 58; iter: 0; batch classifier loss: 0.176511; batch adversarial loss: 0.386314\n",
      "epoch 59; iter: 0; batch classifier loss: 0.197701; batch adversarial loss: 0.470466\n",
      "epoch 60; iter: 0; batch classifier loss: 0.146694; batch adversarial loss: 0.433579\n",
      "epoch 61; iter: 0; batch classifier loss: 0.170899; batch adversarial loss: 0.471212\n",
      "epoch 62; iter: 0; batch classifier loss: 0.206138; batch adversarial loss: 0.447532\n",
      "epoch 63; iter: 0; batch classifier loss: 0.119661; batch adversarial loss: 0.421839\n",
      "epoch 64; iter: 0; batch classifier loss: 0.171667; batch adversarial loss: 0.544849\n",
      "epoch 65; iter: 0; batch classifier loss: 0.247645; batch adversarial loss: 0.434496\n",
      "epoch 66; iter: 0; batch classifier loss: 0.103570; batch adversarial loss: 0.519274\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107051; batch adversarial loss: 0.496762\n",
      "epoch 68; iter: 0; batch classifier loss: 0.190987; batch adversarial loss: 0.448268\n",
      "epoch 69; iter: 0; batch classifier loss: 0.297761; batch adversarial loss: 0.351251\n",
      "epoch 70; iter: 0; batch classifier loss: 0.128449; batch adversarial loss: 0.508015\n",
      "epoch 71; iter: 0; batch classifier loss: 0.151695; batch adversarial loss: 0.458501\n",
      "epoch 72; iter: 0; batch classifier loss: 0.249043; batch adversarial loss: 0.447098\n",
      "epoch 73; iter: 0; batch classifier loss: 0.218041; batch adversarial loss: 0.470967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.175533; batch adversarial loss: 0.483477\n",
      "epoch 75; iter: 0; batch classifier loss: 0.197850; batch adversarial loss: 0.374263\n",
      "epoch 76; iter: 0; batch classifier loss: 0.303874; batch adversarial loss: 0.422597\n",
      "epoch 77; iter: 0; batch classifier loss: 0.141692; batch adversarial loss: 0.518243\n",
      "epoch 78; iter: 0; batch classifier loss: 0.116377; batch adversarial loss: 0.435110\n",
      "epoch 79; iter: 0; batch classifier loss: 0.132427; batch adversarial loss: 0.410031\n",
      "epoch 80; iter: 0; batch classifier loss: 0.206359; batch adversarial loss: 0.509623\n",
      "epoch 81; iter: 0; batch classifier loss: 0.149597; batch adversarial loss: 0.422551\n",
      "epoch 82; iter: 0; batch classifier loss: 0.170903; batch adversarial loss: 0.458295\n",
      "epoch 83; iter: 0; batch classifier loss: 0.191161; batch adversarial loss: 0.483162\n",
      "epoch 84; iter: 0; batch classifier loss: 0.195088; batch adversarial loss: 0.398376\n",
      "epoch 85; iter: 0; batch classifier loss: 0.253522; batch adversarial loss: 0.458650\n",
      "epoch 86; iter: 0; batch classifier loss: 0.150723; batch adversarial loss: 0.458650\n",
      "epoch 87; iter: 0; batch classifier loss: 0.103679; batch adversarial loss: 0.456874\n",
      "epoch 88; iter: 0; batch classifier loss: 0.093606; batch adversarial loss: 0.408828\n",
      "epoch 89; iter: 0; batch classifier loss: 0.182767; batch adversarial loss: 0.482891\n",
      "epoch 90; iter: 0; batch classifier loss: 0.147021; batch adversarial loss: 0.506706\n",
      "epoch 91; iter: 0; batch classifier loss: 0.217945; batch adversarial loss: 0.387117\n",
      "epoch 92; iter: 0; batch classifier loss: 0.159791; batch adversarial loss: 0.494787\n",
      "epoch 93; iter: 0; batch classifier loss: 0.198350; batch adversarial loss: 0.411629\n",
      "epoch 94; iter: 0; batch classifier loss: 0.201535; batch adversarial loss: 0.385750\n",
      "epoch 95; iter: 0; batch classifier loss: 0.197630; batch adversarial loss: 0.495444\n",
      "epoch 96; iter: 0; batch classifier loss: 0.205084; batch adversarial loss: 0.459013\n",
      "epoch 97; iter: 0; batch classifier loss: 0.200920; batch adversarial loss: 0.458552\n",
      "epoch 98; iter: 0; batch classifier loss: 0.186966; batch adversarial loss: 0.494709\n",
      "epoch 99; iter: 0; batch classifier loss: 0.129428; batch adversarial loss: 0.361346\n",
      "epoch 100; iter: 0; batch classifier loss: 0.194812; batch adversarial loss: 0.470794\n",
      "epoch 101; iter: 0; batch classifier loss: 0.205673; batch adversarial loss: 0.519730\n",
      "epoch 102; iter: 0; batch classifier loss: 0.157640; batch adversarial loss: 0.469914\n",
      "epoch 103; iter: 0; batch classifier loss: 0.190229; batch adversarial loss: 0.407767\n",
      "epoch 104; iter: 0; batch classifier loss: 0.186672; batch adversarial loss: 0.437422\n",
      "epoch 105; iter: 0; batch classifier loss: 0.185846; batch adversarial loss: 0.508715\n",
      "epoch 106; iter: 0; batch classifier loss: 0.193961; batch adversarial loss: 0.423254\n",
      "epoch 107; iter: 0; batch classifier loss: 0.116278; batch adversarial loss: 0.471369\n",
      "epoch 108; iter: 0; batch classifier loss: 0.118461; batch adversarial loss: 0.483987\n",
      "epoch 109; iter: 0; batch classifier loss: 0.219816; batch adversarial loss: 0.568788\n",
      "epoch 110; iter: 0; batch classifier loss: 0.133275; batch adversarial loss: 0.519619\n",
      "epoch 111; iter: 0; batch classifier loss: 0.166733; batch adversarial loss: 0.497959\n",
      "epoch 112; iter: 0; batch classifier loss: 0.137313; batch adversarial loss: 0.361876\n",
      "epoch 113; iter: 0; batch classifier loss: 0.167592; batch adversarial loss: 0.406356\n",
      "epoch 114; iter: 0; batch classifier loss: 0.105063; batch adversarial loss: 0.470549\n",
      "epoch 115; iter: 0; batch classifier loss: 0.071704; batch adversarial loss: 0.334205\n",
      "epoch 116; iter: 0; batch classifier loss: 0.106868; batch adversarial loss: 0.469327\n",
      "epoch 117; iter: 0; batch classifier loss: 0.080209; batch adversarial loss: 0.410799\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059262; batch adversarial loss: 0.402160\n",
      "epoch 119; iter: 0; batch classifier loss: 0.058077; batch adversarial loss: 0.457893\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060209; batch adversarial loss: 0.442153\n",
      "epoch 121; iter: 0; batch classifier loss: 0.100313; batch adversarial loss: 0.446062\n",
      "epoch 122; iter: 0; batch classifier loss: 0.058098; batch adversarial loss: 0.497455\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055492; batch adversarial loss: 0.481929\n",
      "epoch 124; iter: 0; batch classifier loss: 0.049645; batch adversarial loss: 0.396371\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021212; batch adversarial loss: 0.537032\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024850; batch adversarial loss: 0.471898\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048479; batch adversarial loss: 0.461960\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052407; batch adversarial loss: 0.453345\n",
      "epoch 129; iter: 0; batch classifier loss: 0.049614; batch adversarial loss: 0.443664\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019244; batch adversarial loss: 0.563467\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039274; batch adversarial loss: 0.497158\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053398; batch adversarial loss: 0.432283\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026188; batch adversarial loss: 0.487172\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020199; batch adversarial loss: 0.400083\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023601; batch adversarial loss: 0.423845\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027061; batch adversarial loss: 0.537464\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036064; batch adversarial loss: 0.389054\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027525; batch adversarial loss: 0.487162\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020380; batch adversarial loss: 0.486687\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036806; batch adversarial loss: 0.467704\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034060; batch adversarial loss: 0.417291\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023143; batch adversarial loss: 0.379641\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029806; batch adversarial loss: 0.424818\n",
      "epoch 144; iter: 0; batch classifier loss: 0.011364; batch adversarial loss: 0.499290\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041053; batch adversarial loss: 0.445453\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028403; batch adversarial loss: 0.524540\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016790; batch adversarial loss: 0.455068\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018043; batch adversarial loss: 0.560438\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027754; batch adversarial loss: 0.409169\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020000; batch adversarial loss: 0.454049\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009962; batch adversarial loss: 0.523345\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016639; batch adversarial loss: 0.427107\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023130; batch adversarial loss: 0.502632\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022713; batch adversarial loss: 0.433284\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018863; batch adversarial loss: 0.495145\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032758; batch adversarial loss: 0.354920\n",
      "epoch 157; iter: 0; batch classifier loss: 0.005279; batch adversarial loss: 0.553007\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009940; batch adversarial loss: 0.524720\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042530; batch adversarial loss: 0.494983\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029352; batch adversarial loss: 0.478711\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027022; batch adversarial loss: 0.438317\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019847; batch adversarial loss: 0.454688\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026835; batch adversarial loss: 0.482200\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034045; batch adversarial loss: 0.422261\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036218; batch adversarial loss: 0.479220\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018168; batch adversarial loss: 0.511134\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009622; batch adversarial loss: 0.478311\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034729; batch adversarial loss: 0.479147\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013132; batch adversarial loss: 0.486489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.033270; batch adversarial loss: 0.502553\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038578; batch adversarial loss: 0.511432\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011336; batch adversarial loss: 0.437274\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023634; batch adversarial loss: 0.393583\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016851; batch adversarial loss: 0.427599\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014179; batch adversarial loss: 0.556540\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033730; batch adversarial loss: 0.480110\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010519; batch adversarial loss: 0.433743\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018621; batch adversarial loss: 0.511197\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006418; batch adversarial loss: 0.521215\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029537; batch adversarial loss: 0.379885\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022200; batch adversarial loss: 0.432828\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023931; batch adversarial loss: 0.435235\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010118; batch adversarial loss: 0.510290\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025340; batch adversarial loss: 0.492862\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026945; batch adversarial loss: 0.509762\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024347; batch adversarial loss: 0.385946\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017469; batch adversarial loss: 0.398202\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010957; batch adversarial loss: 0.440626\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017314; batch adversarial loss: 0.529624\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016070; batch adversarial loss: 0.447721\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015466; batch adversarial loss: 0.381595\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014100; batch adversarial loss: 0.464165\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018727; batch adversarial loss: 0.473434\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015658; batch adversarial loss: 0.454595\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014274; batch adversarial loss: 0.557154\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005773; batch adversarial loss: 0.535005\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008777; batch adversarial loss: 0.468733\n",
      "epoch 198; iter: 0; batch classifier loss: 0.054362; batch adversarial loss: 0.418084\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016697; batch adversarial loss: 0.420069\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695366; batch adversarial loss: 0.986329\n",
      "epoch 1; iter: 0; batch classifier loss: 0.804417; batch adversarial loss: 1.355833\n",
      "epoch 2; iter: 0; batch classifier loss: 0.989594; batch adversarial loss: 1.352303\n",
      "epoch 3; iter: 0; batch classifier loss: 1.128168; batch adversarial loss: 1.255743\n",
      "epoch 4; iter: 0; batch classifier loss: 1.284585; batch adversarial loss: 1.157817\n",
      "epoch 5; iter: 0; batch classifier loss: 1.173934; batch adversarial loss: 1.036233\n",
      "epoch 6; iter: 0; batch classifier loss: 1.218234; batch adversarial loss: 0.947884\n",
      "epoch 7; iter: 0; batch classifier loss: 1.167649; batch adversarial loss: 0.861036\n",
      "epoch 8; iter: 0; batch classifier loss: 1.068329; batch adversarial loss: 0.804304\n",
      "epoch 9; iter: 0; batch classifier loss: 1.061257; batch adversarial loss: 0.750705\n",
      "epoch 10; iter: 0; batch classifier loss: 0.940026; batch adversarial loss: 0.689157\n",
      "epoch 11; iter: 0; batch classifier loss: 0.794191; batch adversarial loss: 0.600333\n",
      "epoch 12; iter: 0; batch classifier loss: 0.739437; batch adversarial loss: 0.631055\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548553; batch adversarial loss: 0.609094\n",
      "epoch 14; iter: 0; batch classifier loss: 0.546010; batch adversarial loss: 0.481396\n",
      "epoch 15; iter: 0; batch classifier loss: 0.421541; batch adversarial loss: 0.511503\n",
      "epoch 16; iter: 0; batch classifier loss: 0.318532; batch adversarial loss: 0.528177\n",
      "epoch 17; iter: 0; batch classifier loss: 0.278447; batch adversarial loss: 0.539012\n",
      "epoch 18; iter: 0; batch classifier loss: 0.272181; batch adversarial loss: 0.520353\n",
      "epoch 19; iter: 0; batch classifier loss: 0.259320; batch adversarial loss: 0.472903\n",
      "epoch 20; iter: 0; batch classifier loss: 0.246862; batch adversarial loss: 0.533332\n",
      "epoch 21; iter: 0; batch classifier loss: 0.257198; batch adversarial loss: 0.490912\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224441; batch adversarial loss: 0.478270\n",
      "epoch 23; iter: 0; batch classifier loss: 0.215177; batch adversarial loss: 0.458774\n",
      "epoch 24; iter: 0; batch classifier loss: 0.228491; batch adversarial loss: 0.407312\n",
      "epoch 25; iter: 0; batch classifier loss: 0.218007; batch adversarial loss: 0.476772\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181854; batch adversarial loss: 0.475524\n",
      "epoch 27; iter: 0; batch classifier loss: 0.182612; batch adversarial loss: 0.449238\n",
      "epoch 28; iter: 0; batch classifier loss: 0.163274; batch adversarial loss: 0.500431\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209977; batch adversarial loss: 0.506981\n",
      "epoch 30; iter: 0; batch classifier loss: 0.230063; batch adversarial loss: 0.426183\n",
      "epoch 31; iter: 0; batch classifier loss: 0.212562; batch adversarial loss: 0.458748\n",
      "epoch 32; iter: 0; batch classifier loss: 0.157918; batch adversarial loss: 0.609486\n",
      "epoch 33; iter: 0; batch classifier loss: 0.186701; batch adversarial loss: 0.531314\n",
      "epoch 34; iter: 0; batch classifier loss: 0.178535; batch adversarial loss: 0.466837\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160009; batch adversarial loss: 0.476707\n",
      "epoch 36; iter: 0; batch classifier loss: 0.222570; batch adversarial loss: 0.493871\n",
      "epoch 37; iter: 0; batch classifier loss: 0.198199; batch adversarial loss: 0.493053\n",
      "epoch 38; iter: 0; batch classifier loss: 0.204135; batch adversarial loss: 0.373425\n",
      "epoch 39; iter: 0; batch classifier loss: 0.202620; batch adversarial loss: 0.421354\n",
      "epoch 40; iter: 0; batch classifier loss: 0.239294; batch adversarial loss: 0.377742\n",
      "epoch 41; iter: 0; batch classifier loss: 0.212104; batch adversarial loss: 0.467535\n",
      "epoch 42; iter: 0; batch classifier loss: 0.161268; batch adversarial loss: 0.450097\n",
      "epoch 43; iter: 0; batch classifier loss: 0.194639; batch adversarial loss: 0.396956\n",
      "epoch 44; iter: 0; batch classifier loss: 0.157427; batch adversarial loss: 0.415261\n",
      "epoch 45; iter: 0; batch classifier loss: 0.213688; batch adversarial loss: 0.400472\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131239; batch adversarial loss: 0.390567\n",
      "epoch 47; iter: 0; batch classifier loss: 0.136405; batch adversarial loss: 0.438423\n",
      "epoch 48; iter: 0; batch classifier loss: 0.174431; batch adversarial loss: 0.534818\n",
      "epoch 49; iter: 0; batch classifier loss: 0.170722; batch adversarial loss: 0.379538\n",
      "epoch 50; iter: 0; batch classifier loss: 0.162980; batch adversarial loss: 0.429969\n",
      "epoch 51; iter: 0; batch classifier loss: 0.152151; batch adversarial loss: 0.444050\n",
      "epoch 52; iter: 0; batch classifier loss: 0.175743; batch adversarial loss: 0.346349\n",
      "epoch 53; iter: 0; batch classifier loss: 0.196514; batch adversarial loss: 0.380744\n",
      "epoch 54; iter: 0; batch classifier loss: 0.185079; batch adversarial loss: 0.505972\n",
      "epoch 55; iter: 0; batch classifier loss: 0.152627; batch adversarial loss: 0.461590\n",
      "epoch 56; iter: 0; batch classifier loss: 0.198870; batch adversarial loss: 0.525254\n",
      "epoch 57; iter: 0; batch classifier loss: 0.144159; batch adversarial loss: 0.476700\n",
      "epoch 58; iter: 0; batch classifier loss: 0.175372; batch adversarial loss: 0.375402\n",
      "epoch 59; iter: 0; batch classifier loss: 0.198532; batch adversarial loss: 0.456999\n",
      "epoch 60; iter: 0; batch classifier loss: 0.125025; batch adversarial loss: 0.562573\n",
      "epoch 61; iter: 0; batch classifier loss: 0.150105; batch adversarial loss: 0.465230\n",
      "epoch 62; iter: 0; batch classifier loss: 0.169429; batch adversarial loss: 0.456155\n",
      "epoch 63; iter: 0; batch classifier loss: 0.200645; batch adversarial loss: 0.448444\n",
      "epoch 64; iter: 0; batch classifier loss: 0.177072; batch adversarial loss: 0.448682\n",
      "epoch 65; iter: 0; batch classifier loss: 0.130291; batch adversarial loss: 0.480519\n",
      "epoch 66; iter: 0; batch classifier loss: 0.124084; batch adversarial loss: 0.396956\n",
      "epoch 67; iter: 0; batch classifier loss: 0.156075; batch adversarial loss: 0.385460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.134547; batch adversarial loss: 0.415420\n",
      "epoch 69; iter: 0; batch classifier loss: 0.148423; batch adversarial loss: 0.322934\n",
      "epoch 70; iter: 0; batch classifier loss: 0.115115; batch adversarial loss: 0.452565\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084766; batch adversarial loss: 0.536211\n",
      "epoch 72; iter: 0; batch classifier loss: 0.164592; batch adversarial loss: 0.418927\n",
      "epoch 73; iter: 0; batch classifier loss: 0.151531; batch adversarial loss: 0.463005\n",
      "epoch 74; iter: 0; batch classifier loss: 0.113249; batch adversarial loss: 0.476279\n",
      "epoch 75; iter: 0; batch classifier loss: 0.157160; batch adversarial loss: 0.466331\n",
      "epoch 76; iter: 0; batch classifier loss: 0.170387; batch adversarial loss: 0.520548\n",
      "epoch 77; iter: 0; batch classifier loss: 0.129017; batch adversarial loss: 0.474644\n",
      "epoch 78; iter: 0; batch classifier loss: 0.133161; batch adversarial loss: 0.504070\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093482; batch adversarial loss: 0.478857\n",
      "epoch 80; iter: 0; batch classifier loss: 0.155651; batch adversarial loss: 0.419394\n",
      "epoch 81; iter: 0; batch classifier loss: 0.152841; batch adversarial loss: 0.560916\n",
      "epoch 82; iter: 0; batch classifier loss: 0.121490; batch adversarial loss: 0.327682\n",
      "epoch 83; iter: 0; batch classifier loss: 0.119040; batch adversarial loss: 0.454356\n",
      "epoch 84; iter: 0; batch classifier loss: 0.135516; batch adversarial loss: 0.456486\n",
      "epoch 85; iter: 0; batch classifier loss: 0.217689; batch adversarial loss: 0.379314\n",
      "epoch 86; iter: 0; batch classifier loss: 0.134688; batch adversarial loss: 0.388593\n",
      "epoch 87; iter: 0; batch classifier loss: 0.163409; batch adversarial loss: 0.495037\n",
      "epoch 88; iter: 0; batch classifier loss: 0.135957; batch adversarial loss: 0.500483\n",
      "epoch 89; iter: 0; batch classifier loss: 0.064193; batch adversarial loss: 0.473102\n",
      "epoch 90; iter: 0; batch classifier loss: 0.146828; batch adversarial loss: 0.404549\n",
      "epoch 91; iter: 0; batch classifier loss: 0.157790; batch adversarial loss: 0.471471\n",
      "epoch 92; iter: 0; batch classifier loss: 0.120918; batch adversarial loss: 0.494825\n",
      "epoch 93; iter: 0; batch classifier loss: 0.125886; batch adversarial loss: 0.451609\n",
      "epoch 94; iter: 0; batch classifier loss: 0.187558; batch adversarial loss: 0.501330\n",
      "epoch 95; iter: 0; batch classifier loss: 0.168617; batch adversarial loss: 0.420586\n",
      "epoch 96; iter: 0; batch classifier loss: 0.110313; batch adversarial loss: 0.646497\n",
      "epoch 97; iter: 0; batch classifier loss: 0.126746; batch adversarial loss: 0.496138\n",
      "epoch 98; iter: 0; batch classifier loss: 0.140468; batch adversarial loss: 0.472382\n",
      "epoch 99; iter: 0; batch classifier loss: 0.109596; batch adversarial loss: 0.391228\n",
      "epoch 100; iter: 0; batch classifier loss: 0.088046; batch adversarial loss: 0.420998\n",
      "epoch 101; iter: 0; batch classifier loss: 0.184364; batch adversarial loss: 0.417655\n",
      "epoch 102; iter: 0; batch classifier loss: 0.144298; batch adversarial loss: 0.468791\n",
      "epoch 103; iter: 0; batch classifier loss: 0.145700; batch adversarial loss: 0.376882\n",
      "epoch 104; iter: 0; batch classifier loss: 0.144720; batch adversarial loss: 0.450192\n",
      "epoch 105; iter: 0; batch classifier loss: 0.146906; batch adversarial loss: 0.451505\n",
      "epoch 106; iter: 0; batch classifier loss: 0.167670; batch adversarial loss: 0.471963\n",
      "epoch 107; iter: 0; batch classifier loss: 0.167010; batch adversarial loss: 0.437717\n",
      "epoch 108; iter: 0; batch classifier loss: 0.121006; batch adversarial loss: 0.471049\n",
      "epoch 109; iter: 0; batch classifier loss: 0.134433; batch adversarial loss: 0.393870\n",
      "epoch 110; iter: 0; batch classifier loss: 0.154713; batch adversarial loss: 0.485312\n",
      "epoch 111; iter: 0; batch classifier loss: 0.225297; batch adversarial loss: 0.431510\n",
      "epoch 112; iter: 0; batch classifier loss: 0.147428; batch adversarial loss: 0.502156\n",
      "epoch 113; iter: 0; batch classifier loss: 0.146331; batch adversarial loss: 0.516668\n",
      "epoch 114; iter: 0; batch classifier loss: 0.218749; batch adversarial loss: 0.434131\n",
      "epoch 115; iter: 0; batch classifier loss: 0.159899; batch adversarial loss: 0.477946\n",
      "epoch 116; iter: 0; batch classifier loss: 0.095018; batch adversarial loss: 0.537341\n",
      "epoch 117; iter: 0; batch classifier loss: 0.191925; batch adversarial loss: 0.359358\n",
      "epoch 118; iter: 0; batch classifier loss: 0.152582; batch adversarial loss: 0.333689\n",
      "epoch 119; iter: 0; batch classifier loss: 0.184252; batch adversarial loss: 0.393055\n",
      "epoch 120; iter: 0; batch classifier loss: 0.138292; batch adversarial loss: 0.414753\n",
      "epoch 121; iter: 0; batch classifier loss: 0.186787; batch adversarial loss: 0.394993\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062165; batch adversarial loss: 0.459346\n",
      "epoch 123; iter: 0; batch classifier loss: 0.131770; batch adversarial loss: 0.463292\n",
      "epoch 124; iter: 0; batch classifier loss: 0.164128; batch adversarial loss: 0.434263\n",
      "epoch 125; iter: 0; batch classifier loss: 0.152137; batch adversarial loss: 0.514192\n",
      "epoch 126; iter: 0; batch classifier loss: 0.156762; batch adversarial loss: 0.533461\n",
      "epoch 127; iter: 0; batch classifier loss: 0.211832; batch adversarial loss: 0.467545\n",
      "epoch 128; iter: 0; batch classifier loss: 0.177921; batch adversarial loss: 0.471402\n",
      "epoch 129; iter: 0; batch classifier loss: 0.194798; batch adversarial loss: 0.486400\n",
      "epoch 130; iter: 0; batch classifier loss: 0.182294; batch adversarial loss: 0.573462\n",
      "epoch 131; iter: 0; batch classifier loss: 0.241096; batch adversarial loss: 0.506833\n",
      "epoch 132; iter: 0; batch classifier loss: 0.267171; batch adversarial loss: 0.445828\n",
      "epoch 133; iter: 0; batch classifier loss: 0.187450; batch adversarial loss: 0.484355\n",
      "epoch 134; iter: 0; batch classifier loss: 0.319152; batch adversarial loss: 0.459722\n",
      "epoch 135; iter: 0; batch classifier loss: 0.184727; batch adversarial loss: 0.458531\n",
      "epoch 136; iter: 0; batch classifier loss: 0.142509; batch adversarial loss: 0.422027\n",
      "epoch 137; iter: 0; batch classifier loss: 0.136770; batch adversarial loss: 0.458982\n",
      "epoch 138; iter: 0; batch classifier loss: 0.143785; batch adversarial loss: 0.470099\n",
      "epoch 139; iter: 0; batch classifier loss: 0.167863; batch adversarial loss: 0.447251\n",
      "epoch 140; iter: 0; batch classifier loss: 0.198895; batch adversarial loss: 0.508117\n",
      "epoch 141; iter: 0; batch classifier loss: 0.163336; batch adversarial loss: 0.410070\n",
      "epoch 142; iter: 0; batch classifier loss: 0.179116; batch adversarial loss: 0.409957\n",
      "epoch 143; iter: 0; batch classifier loss: 0.154038; batch adversarial loss: 0.471114\n",
      "epoch 144; iter: 0; batch classifier loss: 0.055085; batch adversarial loss: 0.470306\n",
      "epoch 145; iter: 0; batch classifier loss: 0.049051; batch adversarial loss: 0.415830\n",
      "epoch 146; iter: 0; batch classifier loss: 0.079304; batch adversarial loss: 0.353865\n",
      "epoch 147; iter: 0; batch classifier loss: 0.056312; batch adversarial loss: 0.538048\n",
      "epoch 148; iter: 0; batch classifier loss: 0.081894; batch adversarial loss: 0.497103\n",
      "epoch 149; iter: 0; batch classifier loss: 0.075853; batch adversarial loss: 0.454975\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038335; batch adversarial loss: 0.408564\n",
      "epoch 151; iter: 0; batch classifier loss: 0.109554; batch adversarial loss: 0.418623\n",
      "epoch 152; iter: 0; batch classifier loss: 0.073990; batch adversarial loss: 0.367990\n",
      "epoch 153; iter: 0; batch classifier loss: 0.129517; batch adversarial loss: 0.395088\n",
      "epoch 154; iter: 0; batch classifier loss: 0.079094; batch adversarial loss: 0.501318\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052895; batch adversarial loss: 0.494042\n",
      "epoch 156; iter: 0; batch classifier loss: 0.074698; batch adversarial loss: 0.435520\n",
      "epoch 157; iter: 0; batch classifier loss: 0.078725; batch adversarial loss: 0.445051\n",
      "epoch 158; iter: 0; batch classifier loss: 0.084585; batch adversarial loss: 0.443677\n",
      "epoch 159; iter: 0; batch classifier loss: 0.052056; batch adversarial loss: 0.538174\n",
      "epoch 160; iter: 0; batch classifier loss: 0.054160; batch adversarial loss: 0.369192\n",
      "epoch 161; iter: 0; batch classifier loss: 0.057018; batch adversarial loss: 0.433748\n",
      "epoch 162; iter: 0; batch classifier loss: 0.090762; batch adversarial loss: 0.394568\n",
      "epoch 163; iter: 0; batch classifier loss: 0.043090; batch adversarial loss: 0.382535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.061095; batch adversarial loss: 0.426500\n",
      "epoch 165; iter: 0; batch classifier loss: 0.066134; batch adversarial loss: 0.424035\n",
      "epoch 166; iter: 0; batch classifier loss: 0.039754; batch adversarial loss: 0.454117\n",
      "epoch 167; iter: 0; batch classifier loss: 0.059669; batch adversarial loss: 0.423313\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040705; batch adversarial loss: 0.489018\n",
      "epoch 169; iter: 0; batch classifier loss: 0.041500; batch adversarial loss: 0.464419\n",
      "epoch 170; iter: 0; batch classifier loss: 0.061731; batch adversarial loss: 0.496494\n",
      "epoch 171; iter: 0; batch classifier loss: 0.066923; batch adversarial loss: 0.527614\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040971; batch adversarial loss: 0.446870\n",
      "epoch 173; iter: 0; batch classifier loss: 0.051702; batch adversarial loss: 0.459530\n",
      "epoch 174; iter: 0; batch classifier loss: 0.071160; batch adversarial loss: 0.438078\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031510; batch adversarial loss: 0.411380\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017811; batch adversarial loss: 0.400738\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046721; batch adversarial loss: 0.472619\n",
      "epoch 178; iter: 0; batch classifier loss: 0.052472; batch adversarial loss: 0.486369\n",
      "epoch 179; iter: 0; batch classifier loss: 0.042841; batch adversarial loss: 0.454698\n",
      "epoch 180; iter: 0; batch classifier loss: 0.069162; batch adversarial loss: 0.455806\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024740; batch adversarial loss: 0.501453\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027239; batch adversarial loss: 0.431423\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025338; batch adversarial loss: 0.461173\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034610; batch adversarial loss: 0.462961\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032448; batch adversarial loss: 0.453555\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019257; batch adversarial loss: 0.446454\n",
      "epoch 187; iter: 0; batch classifier loss: 0.047172; batch adversarial loss: 0.477374\n",
      "epoch 188; iter: 0; batch classifier loss: 0.042285; batch adversarial loss: 0.435777\n",
      "epoch 189; iter: 0; batch classifier loss: 0.051568; batch adversarial loss: 0.387292\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034487; batch adversarial loss: 0.489835\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021663; batch adversarial loss: 0.438846\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027595; batch adversarial loss: 0.450346\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023000; batch adversarial loss: 0.463156\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033072; batch adversarial loss: 0.369108\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021141; batch adversarial loss: 0.413460\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032234; batch adversarial loss: 0.488700\n",
      "epoch 197; iter: 0; batch classifier loss: 0.040367; batch adversarial loss: 0.413661\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016730; batch adversarial loss: 0.510349\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027007; batch adversarial loss: 0.475021\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699613; batch adversarial loss: 0.592217\n",
      "epoch 1; iter: 0; batch classifier loss: 0.474478; batch adversarial loss: 0.647912\n",
      "epoch 2; iter: 0; batch classifier loss: 0.434064; batch adversarial loss: 0.595488\n",
      "epoch 3; iter: 0; batch classifier loss: 0.388387; batch adversarial loss: 0.621769\n",
      "epoch 4; iter: 0; batch classifier loss: 0.440502; batch adversarial loss: 0.588968\n",
      "epoch 5; iter: 0; batch classifier loss: 0.523625; batch adversarial loss: 0.610946\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548798; batch adversarial loss: 0.552783\n",
      "epoch 7; iter: 0; batch classifier loss: 0.487291; batch adversarial loss: 0.574848\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521723; batch adversarial loss: 0.551430\n",
      "epoch 9; iter: 0; batch classifier loss: 0.458590; batch adversarial loss: 0.571319\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505047; batch adversarial loss: 0.533018\n",
      "epoch 11; iter: 0; batch classifier loss: 0.333037; batch adversarial loss: 0.508594\n",
      "epoch 12; iter: 0; batch classifier loss: 0.297120; batch adversarial loss: 0.586352\n",
      "epoch 13; iter: 0; batch classifier loss: 0.391480; batch adversarial loss: 0.539094\n",
      "epoch 14; iter: 0; batch classifier loss: 0.272174; batch adversarial loss: 0.566967\n",
      "epoch 15; iter: 0; batch classifier loss: 0.273411; batch adversarial loss: 0.462618\n",
      "epoch 16; iter: 0; batch classifier loss: 0.366920; batch adversarial loss: 0.523065\n",
      "epoch 17; iter: 0; batch classifier loss: 0.329322; batch adversarial loss: 0.517750\n",
      "epoch 18; iter: 0; batch classifier loss: 0.388577; batch adversarial loss: 0.483606\n",
      "epoch 19; iter: 0; batch classifier loss: 0.375460; batch adversarial loss: 0.539807\n",
      "epoch 20; iter: 0; batch classifier loss: 0.330875; batch adversarial loss: 0.561084\n",
      "epoch 21; iter: 0; batch classifier loss: 0.310830; batch adversarial loss: 0.424649\n",
      "epoch 22; iter: 0; batch classifier loss: 0.311246; batch adversarial loss: 0.520012\n",
      "epoch 23; iter: 0; batch classifier loss: 0.390803; batch adversarial loss: 0.440014\n",
      "epoch 24; iter: 0; batch classifier loss: 0.276536; batch adversarial loss: 0.464733\n",
      "epoch 25; iter: 0; batch classifier loss: 0.318751; batch adversarial loss: 0.491775\n",
      "epoch 26; iter: 0; batch classifier loss: 0.328619; batch adversarial loss: 0.455089\n",
      "epoch 27; iter: 0; batch classifier loss: 0.223612; batch adversarial loss: 0.416588\n",
      "epoch 28; iter: 0; batch classifier loss: 0.229941; batch adversarial loss: 0.534871\n",
      "epoch 29; iter: 0; batch classifier loss: 0.238408; batch adversarial loss: 0.465858\n",
      "epoch 30; iter: 0; batch classifier loss: 0.274431; batch adversarial loss: 0.424990\n",
      "epoch 31; iter: 0; batch classifier loss: 0.263620; batch adversarial loss: 0.449741\n",
      "epoch 32; iter: 0; batch classifier loss: 0.285296; batch adversarial loss: 0.472157\n",
      "epoch 33; iter: 0; batch classifier loss: 0.289892; batch adversarial loss: 0.443863\n",
      "epoch 34; iter: 0; batch classifier loss: 0.250327; batch adversarial loss: 0.413706\n",
      "epoch 35; iter: 0; batch classifier loss: 0.293879; batch adversarial loss: 0.417495\n",
      "epoch 36; iter: 0; batch classifier loss: 0.252311; batch adversarial loss: 0.485304\n",
      "epoch 37; iter: 0; batch classifier loss: 0.230139; batch adversarial loss: 0.462369\n",
      "epoch 38; iter: 0; batch classifier loss: 0.248414; batch adversarial loss: 0.472194\n",
      "epoch 39; iter: 0; batch classifier loss: 0.309754; batch adversarial loss: 0.572525\n",
      "epoch 40; iter: 0; batch classifier loss: 0.292479; batch adversarial loss: 0.482952\n",
      "epoch 41; iter: 0; batch classifier loss: 0.165113; batch adversarial loss: 0.459575\n",
      "epoch 42; iter: 0; batch classifier loss: 0.140749; batch adversarial loss: 0.564094\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089535; batch adversarial loss: 0.490818\n",
      "epoch 44; iter: 0; batch classifier loss: 0.141639; batch adversarial loss: 0.421342\n",
      "epoch 45; iter: 0; batch classifier loss: 0.153143; batch adversarial loss: 0.482666\n",
      "epoch 46; iter: 0; batch classifier loss: 0.221408; batch adversarial loss: 0.415290\n",
      "epoch 47; iter: 0; batch classifier loss: 0.251593; batch adversarial loss: 0.375148\n",
      "epoch 48; iter: 0; batch classifier loss: 0.170350; batch adversarial loss: 0.485274\n",
      "epoch 49; iter: 0; batch classifier loss: 0.198001; batch adversarial loss: 0.408938\n",
      "epoch 50; iter: 0; batch classifier loss: 0.168810; batch adversarial loss: 0.461984\n",
      "epoch 51; iter: 0; batch classifier loss: 0.228123; batch adversarial loss: 0.444795\n",
      "epoch 52; iter: 0; batch classifier loss: 0.206580; batch adversarial loss: 0.458662\n",
      "epoch 53; iter: 0; batch classifier loss: 0.213057; batch adversarial loss: 0.541998\n",
      "epoch 54; iter: 0; batch classifier loss: 0.219045; batch adversarial loss: 0.408966\n",
      "epoch 55; iter: 0; batch classifier loss: 0.248417; batch adversarial loss: 0.505786\n",
      "epoch 56; iter: 0; batch classifier loss: 0.263853; batch adversarial loss: 0.471395\n",
      "epoch 57; iter: 0; batch classifier loss: 0.159815; batch adversarial loss: 0.495471\n",
      "epoch 58; iter: 0; batch classifier loss: 0.258369; batch adversarial loss: 0.470985\n",
      "epoch 59; iter: 0; batch classifier loss: 0.168785; batch adversarial loss: 0.434424\n",
      "epoch 60; iter: 0; batch classifier loss: 0.191612; batch adversarial loss: 0.469660\n",
      "epoch 61; iter: 0; batch classifier loss: 0.182596; batch adversarial loss: 0.496444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.108704; batch adversarial loss: 0.373062\n",
      "epoch 63; iter: 0; batch classifier loss: 0.136744; batch adversarial loss: 0.580648\n",
      "epoch 64; iter: 0; batch classifier loss: 0.237065; batch adversarial loss: 0.434016\n",
      "epoch 65; iter: 0; batch classifier loss: 0.188351; batch adversarial loss: 0.445980\n",
      "epoch 66; iter: 0; batch classifier loss: 0.106668; batch adversarial loss: 0.471014\n",
      "epoch 67; iter: 0; batch classifier loss: 0.217936; batch adversarial loss: 0.385826\n",
      "epoch 68; iter: 0; batch classifier loss: 0.272830; batch adversarial loss: 0.470617\n",
      "epoch 69; iter: 0; batch classifier loss: 0.119451; batch adversarial loss: 0.495210\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086695; batch adversarial loss: 0.398155\n",
      "epoch 71; iter: 0; batch classifier loss: 0.126087; batch adversarial loss: 0.481180\n",
      "epoch 72; iter: 0; batch classifier loss: 0.139966; batch adversarial loss: 0.531825\n",
      "epoch 73; iter: 0; batch classifier loss: 0.180316; batch adversarial loss: 0.472679\n",
      "epoch 74; iter: 0; batch classifier loss: 0.179739; batch adversarial loss: 0.408554\n",
      "epoch 75; iter: 0; batch classifier loss: 0.156025; batch adversarial loss: 0.473984\n",
      "epoch 76; iter: 0; batch classifier loss: 0.166251; batch adversarial loss: 0.434984\n",
      "epoch 77; iter: 0; batch classifier loss: 0.201616; batch adversarial loss: 0.433633\n",
      "epoch 78; iter: 0; batch classifier loss: 0.167568; batch adversarial loss: 0.534029\n",
      "epoch 79; iter: 0; batch classifier loss: 0.153682; batch adversarial loss: 0.470620\n",
      "epoch 80; iter: 0; batch classifier loss: 0.176640; batch adversarial loss: 0.434233\n",
      "epoch 81; iter: 0; batch classifier loss: 0.251684; batch adversarial loss: 0.410557\n",
      "epoch 82; iter: 0; batch classifier loss: 0.167051; batch adversarial loss: 0.458741\n",
      "epoch 83; iter: 0; batch classifier loss: 0.150784; batch adversarial loss: 0.422214\n",
      "epoch 84; iter: 0; batch classifier loss: 0.139618; batch adversarial loss: 0.519860\n",
      "epoch 85; iter: 0; batch classifier loss: 0.184384; batch adversarial loss: 0.496886\n",
      "epoch 86; iter: 0; batch classifier loss: 0.132252; batch adversarial loss: 0.348559\n",
      "epoch 87; iter: 0; batch classifier loss: 0.213315; batch adversarial loss: 0.471135\n",
      "epoch 88; iter: 0; batch classifier loss: 0.111740; batch adversarial loss: 0.384874\n",
      "epoch 89; iter: 0; batch classifier loss: 0.084977; batch adversarial loss: 0.359055\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068074; batch adversarial loss: 0.473560\n",
      "epoch 91; iter: 0; batch classifier loss: 0.054055; batch adversarial loss: 0.399230\n",
      "epoch 92; iter: 0; batch classifier loss: 0.085966; batch adversarial loss: 0.446731\n",
      "epoch 93; iter: 0; batch classifier loss: 0.153621; batch adversarial loss: 0.431745\n",
      "epoch 94; iter: 0; batch classifier loss: 0.089756; batch adversarial loss: 0.410258\n",
      "epoch 95; iter: 0; batch classifier loss: 0.076383; batch adversarial loss: 0.378487\n",
      "epoch 96; iter: 0; batch classifier loss: 0.121034; batch adversarial loss: 0.545010\n",
      "epoch 97; iter: 0; batch classifier loss: 0.109227; batch adversarial loss: 0.431692\n",
      "epoch 98; iter: 0; batch classifier loss: 0.104474; batch adversarial loss: 0.433375\n",
      "epoch 99; iter: 0; batch classifier loss: 0.086112; batch adversarial loss: 0.530694\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046342; batch adversarial loss: 0.439282\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053460; batch adversarial loss: 0.526837\n",
      "epoch 102; iter: 0; batch classifier loss: 0.076043; batch adversarial loss: 0.496722\n",
      "epoch 103; iter: 0; batch classifier loss: 0.073961; batch adversarial loss: 0.343577\n",
      "epoch 104; iter: 0; batch classifier loss: 0.118022; batch adversarial loss: 0.417975\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066003; batch adversarial loss: 0.443738\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062948; batch adversarial loss: 0.511978\n",
      "epoch 107; iter: 0; batch classifier loss: 0.094675; batch adversarial loss: 0.432866\n",
      "epoch 108; iter: 0; batch classifier loss: 0.126183; batch adversarial loss: 0.447680\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045004; batch adversarial loss: 0.535355\n",
      "epoch 110; iter: 0; batch classifier loss: 0.126398; batch adversarial loss: 0.425452\n",
      "epoch 111; iter: 0; batch classifier loss: 0.068322; batch adversarial loss: 0.546291\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047562; batch adversarial loss: 0.401849\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025737; batch adversarial loss: 0.415007\n",
      "epoch 114; iter: 0; batch classifier loss: 0.085673; batch adversarial loss: 0.416367\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048316; batch adversarial loss: 0.507095\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053233; batch adversarial loss: 0.459417\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026586; batch adversarial loss: 0.429300\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044896; batch adversarial loss: 0.353693\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051896; batch adversarial loss: 0.434509\n",
      "epoch 120; iter: 0; batch classifier loss: 0.021623; batch adversarial loss: 0.448622\n",
      "epoch 121; iter: 0; batch classifier loss: 0.015856; batch adversarial loss: 0.497616\n",
      "epoch 122; iter: 0; batch classifier loss: 0.012193; batch adversarial loss: 0.504664\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021019; batch adversarial loss: 0.468786\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033097; batch adversarial loss: 0.447083\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033950; batch adversarial loss: 0.429631\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033900; batch adversarial loss: 0.452791\n",
      "epoch 127; iter: 0; batch classifier loss: 0.049442; batch adversarial loss: 0.410008\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038551; batch adversarial loss: 0.506642\n",
      "epoch 129; iter: 0; batch classifier loss: 0.063249; batch adversarial loss: 0.518792\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045603; batch adversarial loss: 0.425612\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032927; batch adversarial loss: 0.369336\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020250; batch adversarial loss: 0.401857\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054721; batch adversarial loss: 0.376656\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035178; batch adversarial loss: 0.472458\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045865; batch adversarial loss: 0.446690\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017545; batch adversarial loss: 0.576579\n",
      "epoch 137; iter: 0; batch classifier loss: 0.013944; batch adversarial loss: 0.398838\n",
      "epoch 138; iter: 0; batch classifier loss: 0.067713; batch adversarial loss: 0.470987\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029676; batch adversarial loss: 0.500324\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025730; batch adversarial loss: 0.392559\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036723; batch adversarial loss: 0.411885\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037033; batch adversarial loss: 0.394515\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028141; batch adversarial loss: 0.449349\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020121; batch adversarial loss: 0.503029\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016293; batch adversarial loss: 0.445913\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025450; batch adversarial loss: 0.498496\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042672; batch adversarial loss: 0.490011\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024629; batch adversarial loss: 0.453287\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029839; batch adversarial loss: 0.610383\n",
      "epoch 150; iter: 0; batch classifier loss: 0.008080; batch adversarial loss: 0.446736\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029111; batch adversarial loss: 0.343961\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031503; batch adversarial loss: 0.413144\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027795; batch adversarial loss: 0.433406\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029563; batch adversarial loss: 0.380864\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035959; batch adversarial loss: 0.410840\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031412; batch adversarial loss: 0.375424\n",
      "epoch 157; iter: 0; batch classifier loss: 0.051898; batch adversarial loss: 0.452960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.015529; batch adversarial loss: 0.434003\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019371; batch adversarial loss: 0.421515\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013412; batch adversarial loss: 0.495490\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010610; batch adversarial loss: 0.426399\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029445; batch adversarial loss: 0.503802\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006338; batch adversarial loss: 0.471320\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009061; batch adversarial loss: 0.502725\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016523; batch adversarial loss: 0.414896\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025480; batch adversarial loss: 0.409216\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025602; batch adversarial loss: 0.378142\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015518; batch adversarial loss: 0.437351\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017563; batch adversarial loss: 0.567227\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023237; batch adversarial loss: 0.473330\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015780; batch adversarial loss: 0.469204\n",
      "epoch 172; iter: 0; batch classifier loss: 0.043174; batch adversarial loss: 0.333940\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010948; batch adversarial loss: 0.402548\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010716; batch adversarial loss: 0.390428\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024255; batch adversarial loss: 0.501515\n",
      "epoch 176; iter: 0; batch classifier loss: 0.044069; batch adversarial loss: 0.486962\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046063; batch adversarial loss: 0.542508\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013665; batch adversarial loss: 0.430861\n",
      "epoch 179; iter: 0; batch classifier loss: 0.042227; batch adversarial loss: 0.437602\n",
      "epoch 180; iter: 0; batch classifier loss: 0.005657; batch adversarial loss: 0.375595\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030780; batch adversarial loss: 0.530258\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011803; batch adversarial loss: 0.393370\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033476; batch adversarial loss: 0.545677\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011306; batch adversarial loss: 0.430464\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023364; batch adversarial loss: 0.468716\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021892; batch adversarial loss: 0.372916\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025469; batch adversarial loss: 0.405524\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021939; batch adversarial loss: 0.432507\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009074; batch adversarial loss: 0.500785\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016693; batch adversarial loss: 0.527411\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019500; batch adversarial loss: 0.443056\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022602; batch adversarial loss: 0.411780\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008280; batch adversarial loss: 0.524538\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017558; batch adversarial loss: 0.511546\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011202; batch adversarial loss: 0.470740\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013128; batch adversarial loss: 0.408136\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013046; batch adversarial loss: 0.428598\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011156; batch adversarial loss: 0.341605\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015339; batch adversarial loss: 0.566067\n",
      "epoch 0; iter: 0; batch classifier loss: 0.657696; batch adversarial loss: 0.955919\n",
      "epoch 1; iter: 0; batch classifier loss: 0.434041; batch adversarial loss: 1.219807\n",
      "epoch 2; iter: 0; batch classifier loss: 0.459483; batch adversarial loss: 1.165888\n",
      "epoch 3; iter: 0; batch classifier loss: 0.372424; batch adversarial loss: 1.001707\n",
      "epoch 4; iter: 0; batch classifier loss: 0.344740; batch adversarial loss: 0.932718\n",
      "epoch 5; iter: 0; batch classifier loss: 0.258279; batch adversarial loss: 0.838121\n",
      "epoch 6; iter: 0; batch classifier loss: 0.262672; batch adversarial loss: 0.804312\n",
      "epoch 7; iter: 0; batch classifier loss: 0.330755; batch adversarial loss: 0.739591\n",
      "epoch 8; iter: 0; batch classifier loss: 0.270555; batch adversarial loss: 0.680400\n",
      "epoch 9; iter: 0; batch classifier loss: 0.265319; batch adversarial loss: 0.671673\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264985; batch adversarial loss: 0.634554\n",
      "epoch 11; iter: 0; batch classifier loss: 0.244257; batch adversarial loss: 0.646601\n",
      "epoch 12; iter: 0; batch classifier loss: 0.247693; batch adversarial loss: 0.635274\n",
      "epoch 13; iter: 0; batch classifier loss: 0.240690; batch adversarial loss: 0.601075\n",
      "epoch 14; iter: 0; batch classifier loss: 0.267636; batch adversarial loss: 0.569107\n",
      "epoch 15; iter: 0; batch classifier loss: 0.276505; batch adversarial loss: 0.557896\n",
      "epoch 16; iter: 0; batch classifier loss: 0.223247; batch adversarial loss: 0.549717\n",
      "epoch 17; iter: 0; batch classifier loss: 0.236185; batch adversarial loss: 0.556817\n",
      "epoch 18; iter: 0; batch classifier loss: 0.207490; batch adversarial loss: 0.537873\n",
      "epoch 19; iter: 0; batch classifier loss: 0.228976; batch adversarial loss: 0.553873\n",
      "epoch 20; iter: 0; batch classifier loss: 0.228292; batch adversarial loss: 0.503877\n",
      "epoch 21; iter: 0; batch classifier loss: 0.181303; batch adversarial loss: 0.473009\n",
      "epoch 22; iter: 0; batch classifier loss: 0.177872; batch adversarial loss: 0.485744\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171712; batch adversarial loss: 0.413896\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199218; batch adversarial loss: 0.401078\n",
      "epoch 25; iter: 0; batch classifier loss: 0.232638; batch adversarial loss: 0.425530\n",
      "epoch 26; iter: 0; batch classifier loss: 0.260117; batch adversarial loss: 0.441799\n",
      "epoch 27; iter: 0; batch classifier loss: 0.255052; batch adversarial loss: 0.462555\n",
      "epoch 28; iter: 0; batch classifier loss: 0.272988; batch adversarial loss: 0.408266\n",
      "epoch 29; iter: 0; batch classifier loss: 0.261883; batch adversarial loss: 0.383411\n",
      "epoch 30; iter: 0; batch classifier loss: 0.286685; batch adversarial loss: 0.405722\n",
      "epoch 31; iter: 0; batch classifier loss: 0.318661; batch adversarial loss: 0.373426\n",
      "epoch 32; iter: 0; batch classifier loss: 0.263816; batch adversarial loss: 0.391107\n",
      "epoch 33; iter: 0; batch classifier loss: 0.316764; batch adversarial loss: 0.466036\n",
      "epoch 34; iter: 0; batch classifier loss: 0.251995; batch adversarial loss: 0.336429\n",
      "epoch 35; iter: 0; batch classifier loss: 0.315566; batch adversarial loss: 0.436278\n",
      "epoch 36; iter: 0; batch classifier loss: 0.261841; batch adversarial loss: 0.372272\n",
      "epoch 37; iter: 0; batch classifier loss: 0.226031; batch adversarial loss: 0.367801\n",
      "epoch 38; iter: 0; batch classifier loss: 0.231721; batch adversarial loss: 0.416198\n",
      "epoch 39; iter: 0; batch classifier loss: 0.201211; batch adversarial loss: 0.349276\n",
      "epoch 40; iter: 0; batch classifier loss: 0.224509; batch adversarial loss: 0.431712\n",
      "epoch 41; iter: 0; batch classifier loss: 0.214196; batch adversarial loss: 0.390708\n",
      "epoch 42; iter: 0; batch classifier loss: 0.177266; batch adversarial loss: 0.486773\n",
      "epoch 43; iter: 0; batch classifier loss: 0.198534; batch adversarial loss: 0.389907\n",
      "epoch 44; iter: 0; batch classifier loss: 0.160808; batch adversarial loss: 0.316095\n",
      "epoch 45; iter: 0; batch classifier loss: 0.201489; batch adversarial loss: 0.434327\n",
      "epoch 46; iter: 0; batch classifier loss: 0.178393; batch adversarial loss: 0.345253\n",
      "epoch 47; iter: 0; batch classifier loss: 0.121388; batch adversarial loss: 0.404522\n",
      "epoch 48; iter: 0; batch classifier loss: 0.130619; batch adversarial loss: 0.413475\n",
      "epoch 49; iter: 0; batch classifier loss: 0.163331; batch adversarial loss: 0.463445\n",
      "epoch 50; iter: 0; batch classifier loss: 0.127293; batch adversarial loss: 0.455890\n",
      "epoch 51; iter: 0; batch classifier loss: 0.149717; batch adversarial loss: 0.388389\n",
      "epoch 52; iter: 0; batch classifier loss: 0.122219; batch adversarial loss: 0.353541\n",
      "epoch 53; iter: 0; batch classifier loss: 0.153283; batch adversarial loss: 0.416559\n",
      "epoch 54; iter: 0; batch classifier loss: 0.142053; batch adversarial loss: 0.465348\n",
      "epoch 55; iter: 0; batch classifier loss: 0.121226; batch adversarial loss: 0.450660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.139287; batch adversarial loss: 0.461884\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095287; batch adversarial loss: 0.352361\n",
      "epoch 58; iter: 0; batch classifier loss: 0.122346; batch adversarial loss: 0.471924\n",
      "epoch 59; iter: 0; batch classifier loss: 0.149499; batch adversarial loss: 0.381771\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118501; batch adversarial loss: 0.333205\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074532; batch adversarial loss: 0.357738\n",
      "epoch 62; iter: 0; batch classifier loss: 0.105611; batch adversarial loss: 0.366199\n",
      "epoch 63; iter: 0; batch classifier loss: 0.119166; batch adversarial loss: 0.390279\n",
      "epoch 64; iter: 0; batch classifier loss: 0.087939; batch adversarial loss: 0.384805\n",
      "epoch 65; iter: 0; batch classifier loss: 0.142302; batch adversarial loss: 0.422325\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062658; batch adversarial loss: 0.396135\n",
      "epoch 67; iter: 0; batch classifier loss: 0.093077; batch adversarial loss: 0.410371\n",
      "epoch 68; iter: 0; batch classifier loss: 0.113901; batch adversarial loss: 0.384869\n",
      "epoch 69; iter: 0; batch classifier loss: 0.054774; batch adversarial loss: 0.386731\n",
      "epoch 70; iter: 0; batch classifier loss: 0.093548; batch adversarial loss: 0.455268\n",
      "epoch 71; iter: 0; batch classifier loss: 0.094066; batch adversarial loss: 0.397296\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064628; batch adversarial loss: 0.386614\n",
      "epoch 73; iter: 0; batch classifier loss: 0.082928; batch adversarial loss: 0.438307\n",
      "epoch 74; iter: 0; batch classifier loss: 0.055858; batch adversarial loss: 0.441088\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083196; batch adversarial loss: 0.398899\n",
      "epoch 76; iter: 0; batch classifier loss: 0.089900; batch adversarial loss: 0.315329\n",
      "epoch 77; iter: 0; batch classifier loss: 0.058891; batch adversarial loss: 0.369929\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072723; batch adversarial loss: 0.393073\n",
      "epoch 79; iter: 0; batch classifier loss: 0.096489; batch adversarial loss: 0.370476\n",
      "epoch 80; iter: 0; batch classifier loss: 0.118024; batch adversarial loss: 0.440801\n",
      "epoch 81; iter: 0; batch classifier loss: 0.044330; batch adversarial loss: 0.445965\n",
      "epoch 82; iter: 0; batch classifier loss: 0.081212; batch adversarial loss: 0.481024\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079214; batch adversarial loss: 0.482493\n",
      "epoch 84; iter: 0; batch classifier loss: 0.110078; batch adversarial loss: 0.406210\n",
      "epoch 85; iter: 0; batch classifier loss: 0.097591; batch adversarial loss: 0.407108\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063181; batch adversarial loss: 0.390913\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059921; batch adversarial loss: 0.333458\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054753; batch adversarial loss: 0.352673\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074761; batch adversarial loss: 0.341560\n",
      "epoch 90; iter: 0; batch classifier loss: 0.086670; batch adversarial loss: 0.404664\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043603; batch adversarial loss: 0.476632\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066193; batch adversarial loss: 0.436764\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079125; batch adversarial loss: 0.305719\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066828; batch adversarial loss: 0.434733\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087835; batch adversarial loss: 0.418884\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066557; batch adversarial loss: 0.397093\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075774; batch adversarial loss: 0.420743\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051841; batch adversarial loss: 0.441406\n",
      "epoch 99; iter: 0; batch classifier loss: 0.103655; batch adversarial loss: 0.484922\n",
      "epoch 100; iter: 0; batch classifier loss: 0.071404; batch adversarial loss: 0.497715\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056891; batch adversarial loss: 0.444099\n",
      "epoch 102; iter: 0; batch classifier loss: 0.121967; batch adversarial loss: 0.422060\n",
      "epoch 103; iter: 0; batch classifier loss: 0.081680; batch adversarial loss: 0.447647\n",
      "epoch 104; iter: 0; batch classifier loss: 0.080444; batch adversarial loss: 0.402624\n",
      "epoch 105; iter: 0; batch classifier loss: 0.094199; batch adversarial loss: 0.380178\n",
      "epoch 106; iter: 0; batch classifier loss: 0.075907; batch adversarial loss: 0.344687\n",
      "epoch 107; iter: 0; batch classifier loss: 0.068020; batch adversarial loss: 0.401461\n",
      "epoch 108; iter: 0; batch classifier loss: 0.087024; batch adversarial loss: 0.399174\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045531; batch adversarial loss: 0.436158\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057156; batch adversarial loss: 0.521986\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066111; batch adversarial loss: 0.436572\n",
      "epoch 112; iter: 0; batch classifier loss: 0.072145; batch adversarial loss: 0.386691\n",
      "epoch 113; iter: 0; batch classifier loss: 0.073012; batch adversarial loss: 0.457325\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068476; batch adversarial loss: 0.421678\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053877; batch adversarial loss: 0.399186\n",
      "epoch 116; iter: 0; batch classifier loss: 0.076924; batch adversarial loss: 0.385911\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042222; batch adversarial loss: 0.390112\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059131; batch adversarial loss: 0.485539\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065747; batch adversarial loss: 0.354015\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043435; batch adversarial loss: 0.403899\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054477; batch adversarial loss: 0.462841\n",
      "epoch 122; iter: 0; batch classifier loss: 0.077119; batch adversarial loss: 0.435179\n",
      "epoch 123; iter: 0; batch classifier loss: 0.069463; batch adversarial loss: 0.382247\n",
      "epoch 124; iter: 0; batch classifier loss: 0.064994; batch adversarial loss: 0.423272\n",
      "epoch 125; iter: 0; batch classifier loss: 0.059312; batch adversarial loss: 0.445196\n",
      "epoch 126; iter: 0; batch classifier loss: 0.060740; batch adversarial loss: 0.409746\n",
      "epoch 127; iter: 0; batch classifier loss: 0.058390; batch adversarial loss: 0.412821\n",
      "epoch 128; iter: 0; batch classifier loss: 0.050603; batch adversarial loss: 0.468228\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037357; batch adversarial loss: 0.358372\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032622; batch adversarial loss: 0.459896\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046407; batch adversarial loss: 0.396424\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027951; batch adversarial loss: 0.502759\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055336; batch adversarial loss: 0.541987\n",
      "epoch 134; iter: 0; batch classifier loss: 0.041608; batch adversarial loss: 0.414291\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046323; batch adversarial loss: 0.539340\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033433; batch adversarial loss: 0.460324\n",
      "epoch 137; iter: 0; batch classifier loss: 0.058344; batch adversarial loss: 0.399842\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030894; batch adversarial loss: 0.458233\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034872; batch adversarial loss: 0.447639\n",
      "epoch 140; iter: 0; batch classifier loss: 0.043514; batch adversarial loss: 0.428544\n",
      "epoch 141; iter: 0; batch classifier loss: 0.086205; batch adversarial loss: 0.458711\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031350; batch adversarial loss: 0.433028\n",
      "epoch 143; iter: 0; batch classifier loss: 0.044591; batch adversarial loss: 0.410048\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018850; batch adversarial loss: 0.409739\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039708; batch adversarial loss: 0.403736\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039033; batch adversarial loss: 0.397271\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024600; batch adversarial loss: 0.357138\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025857; batch adversarial loss: 0.441561\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025465; batch adversarial loss: 0.357872\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029350; batch adversarial loss: 0.462880\n",
      "epoch 151; iter: 0; batch classifier loss: 0.053207; batch adversarial loss: 0.357887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.027965; batch adversarial loss: 0.485280\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030014; batch adversarial loss: 0.376265\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035571; batch adversarial loss: 0.440643\n",
      "epoch 155; iter: 0; batch classifier loss: 0.073343; batch adversarial loss: 0.463034\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032660; batch adversarial loss: 0.468090\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033780; batch adversarial loss: 0.432231\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038736; batch adversarial loss: 0.437625\n",
      "epoch 159; iter: 0; batch classifier loss: 0.057901; batch adversarial loss: 0.642649\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027452; batch adversarial loss: 0.499438\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035778; batch adversarial loss: 0.449398\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033850; batch adversarial loss: 0.429039\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019138; batch adversarial loss: 0.363342\n",
      "epoch 164; iter: 0; batch classifier loss: 0.123179; batch adversarial loss: 0.688654\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044791; batch adversarial loss: 0.411845\n",
      "epoch 166; iter: 0; batch classifier loss: 0.076067; batch adversarial loss: 0.602749\n",
      "epoch 167; iter: 0; batch classifier loss: 0.050784; batch adversarial loss: 0.475634\n",
      "epoch 168; iter: 0; batch classifier loss: 0.052057; batch adversarial loss: 0.471864\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037055; batch adversarial loss: 0.527197\n",
      "epoch 170; iter: 0; batch classifier loss: 0.124956; batch adversarial loss: 0.679526\n",
      "epoch 171; iter: 0; batch classifier loss: 0.072985; batch adversarial loss: 0.460046\n",
      "epoch 172; iter: 0; batch classifier loss: 0.083481; batch adversarial loss: 0.629639\n",
      "epoch 173; iter: 0; batch classifier loss: 0.107066; batch adversarial loss: 0.631310\n",
      "epoch 174; iter: 0; batch classifier loss: 0.080954; batch adversarial loss: 0.364566\n",
      "epoch 175; iter: 0; batch classifier loss: 0.127839; batch adversarial loss: 0.592527\n",
      "epoch 176; iter: 0; batch classifier loss: 0.170966; batch adversarial loss: 0.624387\n",
      "epoch 177; iter: 0; batch classifier loss: 0.102227; batch adversarial loss: 0.498119\n",
      "epoch 178; iter: 0; batch classifier loss: 0.156277; batch adversarial loss: 0.732565\n",
      "epoch 179; iter: 0; batch classifier loss: 0.208939; batch adversarial loss: 0.733614\n",
      "epoch 180; iter: 0; batch classifier loss: 0.228041; batch adversarial loss: 0.734835\n",
      "epoch 181; iter: 0; batch classifier loss: 0.098026; batch adversarial loss: 0.570663\n",
      "epoch 182; iter: 0; batch classifier loss: 0.179540; batch adversarial loss: 0.666025\n",
      "epoch 183; iter: 0; batch classifier loss: 0.186309; batch adversarial loss: 0.701857\n",
      "epoch 184; iter: 0; batch classifier loss: 0.114184; batch adversarial loss: 0.558147\n",
      "epoch 185; iter: 0; batch classifier loss: 0.120130; batch adversarial loss: 0.626421\n",
      "epoch 186; iter: 0; batch classifier loss: 0.163764; batch adversarial loss: 0.604153\n",
      "epoch 187; iter: 0; batch classifier loss: 0.069835; batch adversarial loss: 0.480161\n",
      "epoch 188; iter: 0; batch classifier loss: 0.130685; batch adversarial loss: 0.500019\n",
      "epoch 189; iter: 0; batch classifier loss: 0.151152; batch adversarial loss: 0.648787\n",
      "epoch 190; iter: 0; batch classifier loss: 0.128352; batch adversarial loss: 0.569432\n",
      "epoch 191; iter: 0; batch classifier loss: 0.122331; batch adversarial loss: 0.564018\n",
      "epoch 192; iter: 0; batch classifier loss: 0.090726; batch adversarial loss: 0.444475\n",
      "epoch 193; iter: 0; batch classifier loss: 0.175690; batch adversarial loss: 0.560676\n",
      "epoch 194; iter: 0; batch classifier loss: 0.141979; batch adversarial loss: 0.530741\n",
      "epoch 195; iter: 0; batch classifier loss: 0.228986; batch adversarial loss: 0.740271\n",
      "epoch 196; iter: 0; batch classifier loss: 0.190481; batch adversarial loss: 0.619423\n",
      "epoch 197; iter: 0; batch classifier loss: 0.129109; batch adversarial loss: 0.613488\n",
      "epoch 198; iter: 0; batch classifier loss: 0.153190; batch adversarial loss: 0.620093\n",
      "epoch 199; iter: 0; batch classifier loss: 0.165592; batch adversarial loss: 0.562127\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723350; batch adversarial loss: 0.582761\n",
      "epoch 1; iter: 0; batch classifier loss: 0.480050; batch adversarial loss: 0.596214\n",
      "epoch 2; iter: 0; batch classifier loss: 0.378977; batch adversarial loss: 0.580076\n",
      "epoch 3; iter: 0; batch classifier loss: 0.388021; batch adversarial loss: 0.592980\n",
      "epoch 4; iter: 0; batch classifier loss: 0.468022; batch adversarial loss: 0.545099\n",
      "epoch 5; iter: 0; batch classifier loss: 0.337803; batch adversarial loss: 0.519819\n",
      "epoch 6; iter: 0; batch classifier loss: 0.335680; batch adversarial loss: 0.576091\n",
      "epoch 7; iter: 0; batch classifier loss: 0.399295; batch adversarial loss: 0.556304\n",
      "epoch 8; iter: 0; batch classifier loss: 0.288404; batch adversarial loss: 0.555889\n",
      "epoch 9; iter: 0; batch classifier loss: 0.354826; batch adversarial loss: 0.529413\n",
      "epoch 10; iter: 0; batch classifier loss: 0.390825; batch adversarial loss: 0.576235\n",
      "epoch 11; iter: 0; batch classifier loss: 0.482797; batch adversarial loss: 0.570150\n",
      "epoch 12; iter: 0; batch classifier loss: 0.570890; batch adversarial loss: 0.564691\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501352; batch adversarial loss: 0.546167\n",
      "epoch 14; iter: 0; batch classifier loss: 0.434444; batch adversarial loss: 0.499715\n",
      "epoch 15; iter: 0; batch classifier loss: 0.312285; batch adversarial loss: 0.490250\n",
      "epoch 16; iter: 0; batch classifier loss: 0.303302; batch adversarial loss: 0.499067\n",
      "epoch 17; iter: 0; batch classifier loss: 0.304391; batch adversarial loss: 0.492069\n",
      "epoch 18; iter: 0; batch classifier loss: 0.248535; batch adversarial loss: 0.450118\n",
      "epoch 19; iter: 0; batch classifier loss: 0.238641; batch adversarial loss: 0.473838\n",
      "epoch 20; iter: 0; batch classifier loss: 0.176936; batch adversarial loss: 0.480437\n",
      "epoch 21; iter: 0; batch classifier loss: 0.266922; batch adversarial loss: 0.385726\n",
      "epoch 22; iter: 0; batch classifier loss: 0.269047; batch adversarial loss: 0.483311\n",
      "epoch 23; iter: 0; batch classifier loss: 0.263348; batch adversarial loss: 0.491961\n",
      "epoch 24; iter: 0; batch classifier loss: 0.207375; batch adversarial loss: 0.451895\n",
      "epoch 25; iter: 0; batch classifier loss: 0.164933; batch adversarial loss: 0.470381\n",
      "epoch 26; iter: 0; batch classifier loss: 0.253519; batch adversarial loss: 0.406248\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162126; batch adversarial loss: 0.470233\n",
      "epoch 28; iter: 0; batch classifier loss: 0.134920; batch adversarial loss: 0.498921\n",
      "epoch 29; iter: 0; batch classifier loss: 0.155484; batch adversarial loss: 0.493598\n",
      "epoch 30; iter: 0; batch classifier loss: 0.214412; batch adversarial loss: 0.539347\n",
      "epoch 31; iter: 0; batch classifier loss: 0.177592; batch adversarial loss: 0.397679\n",
      "epoch 32; iter: 0; batch classifier loss: 0.148591; batch adversarial loss: 0.552300\n",
      "epoch 33; iter: 0; batch classifier loss: 0.207388; batch adversarial loss: 0.453561\n",
      "epoch 34; iter: 0; batch classifier loss: 0.137341; batch adversarial loss: 0.458835\n",
      "epoch 35; iter: 0; batch classifier loss: 0.117478; batch adversarial loss: 0.460586\n",
      "epoch 36; iter: 0; batch classifier loss: 0.194821; batch adversarial loss: 0.451250\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166001; batch adversarial loss: 0.478525\n",
      "epoch 38; iter: 0; batch classifier loss: 0.183070; batch adversarial loss: 0.542201\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129112; batch adversarial loss: 0.498454\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154116; batch adversarial loss: 0.417990\n",
      "epoch 41; iter: 0; batch classifier loss: 0.150854; batch adversarial loss: 0.412970\n",
      "epoch 42; iter: 0; batch classifier loss: 0.165564; batch adversarial loss: 0.489890\n",
      "epoch 43; iter: 0; batch classifier loss: 0.187569; batch adversarial loss: 0.444551\n",
      "epoch 44; iter: 0; batch classifier loss: 0.213284; batch adversarial loss: 0.482801\n",
      "epoch 45; iter: 0; batch classifier loss: 0.202115; batch adversarial loss: 0.401096\n",
      "epoch 46; iter: 0; batch classifier loss: 0.144502; batch adversarial loss: 0.399196\n",
      "epoch 47; iter: 0; batch classifier loss: 0.134032; batch adversarial loss: 0.456674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.170098; batch adversarial loss: 0.520989\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114952; batch adversarial loss: 0.449848\n",
      "epoch 50; iter: 0; batch classifier loss: 0.148060; batch adversarial loss: 0.510094\n",
      "epoch 51; iter: 0; batch classifier loss: 0.135962; batch adversarial loss: 0.523150\n",
      "epoch 52; iter: 0; batch classifier loss: 0.188015; batch adversarial loss: 0.454643\n",
      "epoch 53; iter: 0; batch classifier loss: 0.142487; batch adversarial loss: 0.517034\n",
      "epoch 54; iter: 0; batch classifier loss: 0.252227; batch adversarial loss: 0.486838\n",
      "epoch 55; iter: 0; batch classifier loss: 0.208003; batch adversarial loss: 0.514172\n",
      "epoch 56; iter: 0; batch classifier loss: 0.136046; batch adversarial loss: 0.453016\n",
      "epoch 57; iter: 0; batch classifier loss: 0.158330; batch adversarial loss: 0.447317\n",
      "epoch 58; iter: 0; batch classifier loss: 0.134009; batch adversarial loss: 0.455928\n",
      "epoch 59; iter: 0; batch classifier loss: 0.130531; batch adversarial loss: 0.521729\n",
      "epoch 60; iter: 0; batch classifier loss: 0.154094; batch adversarial loss: 0.439531\n",
      "epoch 61; iter: 0; batch classifier loss: 0.145340; batch adversarial loss: 0.522097\n",
      "epoch 62; iter: 0; batch classifier loss: 0.140405; batch adversarial loss: 0.528669\n",
      "epoch 63; iter: 0; batch classifier loss: 0.193373; batch adversarial loss: 0.458916\n",
      "epoch 64; iter: 0; batch classifier loss: 0.203487; batch adversarial loss: 0.433648\n",
      "epoch 65; iter: 0; batch classifier loss: 0.161700; batch adversarial loss: 0.539861\n",
      "epoch 66; iter: 0; batch classifier loss: 0.165625; batch adversarial loss: 0.452119\n",
      "epoch 67; iter: 0; batch classifier loss: 0.112644; batch adversarial loss: 0.483478\n",
      "epoch 68; iter: 0; batch classifier loss: 0.194057; batch adversarial loss: 0.441468\n",
      "epoch 69; iter: 0; batch classifier loss: 0.130608; batch adversarial loss: 0.377698\n",
      "epoch 70; iter: 0; batch classifier loss: 0.211047; batch adversarial loss: 0.430710\n",
      "epoch 71; iter: 0; batch classifier loss: 0.123304; batch adversarial loss: 0.513041\n",
      "epoch 72; iter: 0; batch classifier loss: 0.207499; batch adversarial loss: 0.368590\n",
      "epoch 73; iter: 0; batch classifier loss: 0.156093; batch adversarial loss: 0.453491\n",
      "epoch 74; iter: 0; batch classifier loss: 0.147360; batch adversarial loss: 0.410830\n",
      "epoch 75; iter: 0; batch classifier loss: 0.198945; batch adversarial loss: 0.488187\n",
      "epoch 76; iter: 0; batch classifier loss: 0.138721; batch adversarial loss: 0.463282\n",
      "epoch 77; iter: 0; batch classifier loss: 0.204773; batch adversarial loss: 0.398867\n",
      "epoch 78; iter: 0; batch classifier loss: 0.168119; batch adversarial loss: 0.435696\n",
      "epoch 79; iter: 0; batch classifier loss: 0.147068; batch adversarial loss: 0.403832\n",
      "epoch 80; iter: 0; batch classifier loss: 0.148030; batch adversarial loss: 0.486493\n",
      "epoch 81; iter: 0; batch classifier loss: 0.168436; batch adversarial loss: 0.505131\n",
      "epoch 82; iter: 0; batch classifier loss: 0.134706; batch adversarial loss: 0.363057\n",
      "epoch 83; iter: 0; batch classifier loss: 0.141503; batch adversarial loss: 0.445197\n",
      "epoch 84; iter: 0; batch classifier loss: 0.138004; batch adversarial loss: 0.416906\n",
      "epoch 85; iter: 0; batch classifier loss: 0.123558; batch adversarial loss: 0.446964\n",
      "epoch 86; iter: 0; batch classifier loss: 0.132335; batch adversarial loss: 0.515514\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078119; batch adversarial loss: 0.419637\n",
      "epoch 88; iter: 0; batch classifier loss: 0.074241; batch adversarial loss: 0.377757\n",
      "epoch 89; iter: 0; batch classifier loss: 0.088674; batch adversarial loss: 0.513379\n",
      "epoch 90; iter: 0; batch classifier loss: 0.112595; batch adversarial loss: 0.477493\n",
      "epoch 91; iter: 0; batch classifier loss: 0.148038; batch adversarial loss: 0.369409\n",
      "epoch 92; iter: 0; batch classifier loss: 0.092796; batch adversarial loss: 0.540932\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078827; batch adversarial loss: 0.459832\n",
      "epoch 94; iter: 0; batch classifier loss: 0.113155; batch adversarial loss: 0.470027\n",
      "epoch 95; iter: 0; batch classifier loss: 0.150208; batch adversarial loss: 0.507705\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068773; batch adversarial loss: 0.512078\n",
      "epoch 97; iter: 0; batch classifier loss: 0.058869; batch adversarial loss: 0.403417\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063460; batch adversarial loss: 0.457296\n",
      "epoch 99; iter: 0; batch classifier loss: 0.116995; batch adversarial loss: 0.478793\n",
      "epoch 100; iter: 0; batch classifier loss: 0.166214; batch adversarial loss: 0.574414\n",
      "epoch 101; iter: 0; batch classifier loss: 0.060784; batch adversarial loss: 0.396883\n",
      "epoch 102; iter: 0; batch classifier loss: 0.076012; batch adversarial loss: 0.486488\n",
      "epoch 103; iter: 0; batch classifier loss: 0.067984; batch adversarial loss: 0.432609\n",
      "epoch 104; iter: 0; batch classifier loss: 0.096531; batch adversarial loss: 0.425113\n",
      "epoch 105; iter: 0; batch classifier loss: 0.083998; batch adversarial loss: 0.467794\n",
      "epoch 106; iter: 0; batch classifier loss: 0.086043; batch adversarial loss: 0.508811\n",
      "epoch 107; iter: 0; batch classifier loss: 0.097884; batch adversarial loss: 0.451494\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057879; batch adversarial loss: 0.434895\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061335; batch adversarial loss: 0.510110\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065761; batch adversarial loss: 0.467517\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061891; batch adversarial loss: 0.555869\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040045; batch adversarial loss: 0.558696\n",
      "epoch 113; iter: 0; batch classifier loss: 0.065430; batch adversarial loss: 0.469076\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047510; batch adversarial loss: 0.436424\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056143; batch adversarial loss: 0.440957\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035997; batch adversarial loss: 0.421079\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050184; batch adversarial loss: 0.430150\n",
      "epoch 118; iter: 0; batch classifier loss: 0.067621; batch adversarial loss: 0.443980\n",
      "epoch 119; iter: 0; batch classifier loss: 0.101402; batch adversarial loss: 0.374520\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032231; batch adversarial loss: 0.477132\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048186; batch adversarial loss: 0.524094\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038815; batch adversarial loss: 0.449765\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032618; batch adversarial loss: 0.439544\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042923; batch adversarial loss: 0.401028\n",
      "epoch 125; iter: 0; batch classifier loss: 0.059699; batch adversarial loss: 0.397929\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047665; batch adversarial loss: 0.418312\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048927; batch adversarial loss: 0.408977\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021272; batch adversarial loss: 0.486254\n",
      "epoch 129; iter: 0; batch classifier loss: 0.065970; batch adversarial loss: 0.495195\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056067; batch adversarial loss: 0.459328\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026299; batch adversarial loss: 0.496890\n",
      "epoch 132; iter: 0; batch classifier loss: 0.072224; batch adversarial loss: 0.466056\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052574; batch adversarial loss: 0.436158\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028627; batch adversarial loss: 0.404956\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023628; batch adversarial loss: 0.461937\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047471; batch adversarial loss: 0.443237\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036642; batch adversarial loss: 0.446883\n",
      "epoch 138; iter: 0; batch classifier loss: 0.055612; batch adversarial loss: 0.495355\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051729; batch adversarial loss: 0.451175\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040613; batch adversarial loss: 0.467688\n",
      "epoch 141; iter: 0; batch classifier loss: 0.083210; batch adversarial loss: 0.507207\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024394; batch adversarial loss: 0.450469\n",
      "epoch 143; iter: 0; batch classifier loss: 0.090671; batch adversarial loss: 0.362958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.054371; batch adversarial loss: 0.443729\n",
      "epoch 145; iter: 0; batch classifier loss: 0.056163; batch adversarial loss: 0.516295\n",
      "epoch 146; iter: 0; batch classifier loss: 0.058598; batch adversarial loss: 0.487144\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029830; batch adversarial loss: 0.396883\n",
      "epoch 148; iter: 0; batch classifier loss: 0.053414; batch adversarial loss: 0.460960\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044680; batch adversarial loss: 0.477396\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023972; batch adversarial loss: 0.443659\n",
      "epoch 151; iter: 0; batch classifier loss: 0.087677; batch adversarial loss: 0.510472\n",
      "epoch 152; iter: 0; batch classifier loss: 0.054761; batch adversarial loss: 0.404606\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017625; batch adversarial loss: 0.433603\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034272; batch adversarial loss: 0.422983\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014529; batch adversarial loss: 0.547053\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018765; batch adversarial loss: 0.417057\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021593; batch adversarial loss: 0.432132\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033206; batch adversarial loss: 0.469989\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030168; batch adversarial loss: 0.427469\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015314; batch adversarial loss: 0.505847\n",
      "epoch 161; iter: 0; batch classifier loss: 0.052149; batch adversarial loss: 0.418012\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032204; batch adversarial loss: 0.451628\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017061; batch adversarial loss: 0.511718\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015510; batch adversarial loss: 0.466941\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009726; batch adversarial loss: 0.399141\n",
      "epoch 166; iter: 0; batch classifier loss: 0.039152; batch adversarial loss: 0.434536\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030722; batch adversarial loss: 0.488319\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034028; batch adversarial loss: 0.403269\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028913; batch adversarial loss: 0.463739\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033363; batch adversarial loss: 0.444015\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030714; batch adversarial loss: 0.453266\n",
      "epoch 172; iter: 0; batch classifier loss: 0.037276; batch adversarial loss: 0.408992\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035074; batch adversarial loss: 0.455069\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021421; batch adversarial loss: 0.411360\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032578; batch adversarial loss: 0.458030\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035842; batch adversarial loss: 0.467261\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028965; batch adversarial loss: 0.434483\n",
      "epoch 178; iter: 0; batch classifier loss: 0.068526; batch adversarial loss: 0.518274\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020201; batch adversarial loss: 0.367511\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022373; batch adversarial loss: 0.533753\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022551; batch adversarial loss: 0.463700\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042236; batch adversarial loss: 0.493592\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017856; batch adversarial loss: 0.414289\n",
      "epoch 184; iter: 0; batch classifier loss: 0.042481; batch adversarial loss: 0.359571\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023412; batch adversarial loss: 0.456791\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012857; batch adversarial loss: 0.441739\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022020; batch adversarial loss: 0.481263\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025812; batch adversarial loss: 0.480535\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024699; batch adversarial loss: 0.493982\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038319; batch adversarial loss: 0.500480\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011542; batch adversarial loss: 0.482877\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029311; batch adversarial loss: 0.445251\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021878; batch adversarial loss: 0.494275\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008934; batch adversarial loss: 0.436236\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023143; batch adversarial loss: 0.476686\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015502; batch adversarial loss: 0.452837\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018061; batch adversarial loss: 0.499319\n",
      "epoch 198; iter: 0; batch classifier loss: 0.036666; batch adversarial loss: 0.504450\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015582; batch adversarial loss: 0.440949\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711760; batch adversarial loss: 0.797228\n",
      "epoch 1; iter: 0; batch classifier loss: 0.400153; batch adversarial loss: 0.740348\n",
      "epoch 2; iter: 0; batch classifier loss: 0.443375; batch adversarial loss: 0.687759\n",
      "epoch 3; iter: 0; batch classifier loss: 0.473439; batch adversarial loss: 0.649234\n",
      "epoch 4; iter: 0; batch classifier loss: 0.353561; batch adversarial loss: 0.623274\n",
      "epoch 5; iter: 0; batch classifier loss: 0.392830; batch adversarial loss: 0.604141\n",
      "epoch 6; iter: 0; batch classifier loss: 0.422765; batch adversarial loss: 0.587505\n",
      "epoch 7; iter: 0; batch classifier loss: 0.292545; batch adversarial loss: 0.555889\n",
      "epoch 8; iter: 0; batch classifier loss: 0.328241; batch adversarial loss: 0.571125\n",
      "epoch 9; iter: 0; batch classifier loss: 0.389520; batch adversarial loss: 0.539664\n",
      "epoch 10; iter: 0; batch classifier loss: 0.408725; batch adversarial loss: 0.512836\n",
      "epoch 11; iter: 0; batch classifier loss: 0.428019; batch adversarial loss: 0.538785\n",
      "epoch 12; iter: 0; batch classifier loss: 0.333385; batch adversarial loss: 0.549408\n",
      "epoch 13; iter: 0; batch classifier loss: 0.407187; batch adversarial loss: 0.513266\n",
      "epoch 14; iter: 0; batch classifier loss: 0.360057; batch adversarial loss: 0.526241\n",
      "epoch 15; iter: 0; batch classifier loss: 0.370862; batch adversarial loss: 0.533481\n",
      "epoch 16; iter: 0; batch classifier loss: 0.328242; batch adversarial loss: 0.481285\n",
      "epoch 17; iter: 0; batch classifier loss: 0.281030; batch adversarial loss: 0.478190\n",
      "epoch 18; iter: 0; batch classifier loss: 0.353473; batch adversarial loss: 0.475268\n",
      "epoch 19; iter: 0; batch classifier loss: 0.308440; batch adversarial loss: 0.471733\n",
      "epoch 20; iter: 0; batch classifier loss: 0.289393; batch adversarial loss: 0.459654\n",
      "epoch 21; iter: 0; batch classifier loss: 0.259750; batch adversarial loss: 0.500574\n",
      "epoch 22; iter: 0; batch classifier loss: 0.288386; batch adversarial loss: 0.502364\n",
      "epoch 23; iter: 0; batch classifier loss: 0.272669; batch adversarial loss: 0.503377\n",
      "epoch 24; iter: 0; batch classifier loss: 0.197360; batch adversarial loss: 0.506591\n",
      "epoch 25; iter: 0; batch classifier loss: 0.238951; batch adversarial loss: 0.556525\n",
      "epoch 26; iter: 0; batch classifier loss: 0.303200; batch adversarial loss: 0.480934\n",
      "epoch 27; iter: 0; batch classifier loss: 0.193528; batch adversarial loss: 0.471781\n",
      "epoch 28; iter: 0; batch classifier loss: 0.194216; batch adversarial loss: 0.470009\n",
      "epoch 29; iter: 0; batch classifier loss: 0.173047; batch adversarial loss: 0.477070\n",
      "epoch 30; iter: 0; batch classifier loss: 0.207000; batch adversarial loss: 0.470981\n",
      "epoch 31; iter: 0; batch classifier loss: 0.249911; batch adversarial loss: 0.475048\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126535; batch adversarial loss: 0.554526\n",
      "epoch 33; iter: 0; batch classifier loss: 0.263518; batch adversarial loss: 0.574975\n",
      "epoch 34; iter: 0; batch classifier loss: 0.173518; batch adversarial loss: 0.481739\n",
      "epoch 35; iter: 0; batch classifier loss: 0.198898; batch adversarial loss: 0.456392\n",
      "epoch 36; iter: 0; batch classifier loss: 0.194696; batch adversarial loss: 0.442904\n",
      "epoch 37; iter: 0; batch classifier loss: 0.256946; batch adversarial loss: 0.397288\n",
      "epoch 38; iter: 0; batch classifier loss: 0.211883; batch adversarial loss: 0.459517\n",
      "epoch 39; iter: 0; batch classifier loss: 0.175722; batch adversarial loss: 0.463687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.197373; batch adversarial loss: 0.502725\n",
      "epoch 41; iter: 0; batch classifier loss: 0.177927; batch adversarial loss: 0.463426\n",
      "epoch 42; iter: 0; batch classifier loss: 0.169582; batch adversarial loss: 0.454710\n",
      "epoch 43; iter: 0; batch classifier loss: 0.169434; batch adversarial loss: 0.435606\n",
      "epoch 44; iter: 0; batch classifier loss: 0.198658; batch adversarial loss: 0.447263\n",
      "epoch 45; iter: 0; batch classifier loss: 0.161026; batch adversarial loss: 0.427223\n",
      "epoch 46; iter: 0; batch classifier loss: 0.160872; batch adversarial loss: 0.563398\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119255; batch adversarial loss: 0.471916\n",
      "epoch 48; iter: 0; batch classifier loss: 0.186317; batch adversarial loss: 0.446435\n",
      "epoch 49; iter: 0; batch classifier loss: 0.185052; batch adversarial loss: 0.416178\n",
      "epoch 50; iter: 0; batch classifier loss: 0.147314; batch adversarial loss: 0.424276\n",
      "epoch 51; iter: 0; batch classifier loss: 0.107674; batch adversarial loss: 0.501740\n",
      "epoch 52; iter: 0; batch classifier loss: 0.134415; batch adversarial loss: 0.481346\n",
      "epoch 53; iter: 0; batch classifier loss: 0.178960; batch adversarial loss: 0.506882\n",
      "epoch 54; iter: 0; batch classifier loss: 0.119775; batch adversarial loss: 0.484656\n",
      "epoch 55; iter: 0; batch classifier loss: 0.152487; batch adversarial loss: 0.384206\n",
      "epoch 56; iter: 0; batch classifier loss: 0.105150; batch adversarial loss: 0.547075\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106667; batch adversarial loss: 0.440606\n",
      "epoch 58; iter: 0; batch classifier loss: 0.149402; batch adversarial loss: 0.512497\n",
      "epoch 59; iter: 0; batch classifier loss: 0.108478; batch adversarial loss: 0.521973\n",
      "epoch 60; iter: 0; batch classifier loss: 0.089973; batch adversarial loss: 0.469445\n",
      "epoch 61; iter: 0; batch classifier loss: 0.062663; batch adversarial loss: 0.388092\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078833; batch adversarial loss: 0.489639\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088729; batch adversarial loss: 0.573096\n",
      "epoch 64; iter: 0; batch classifier loss: 0.161162; batch adversarial loss: 0.407895\n",
      "epoch 65; iter: 0; batch classifier loss: 0.165535; batch adversarial loss: 0.424874\n",
      "epoch 66; iter: 0; batch classifier loss: 0.055789; batch adversarial loss: 0.469330\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082195; batch adversarial loss: 0.479504\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071711; batch adversarial loss: 0.439194\n",
      "epoch 69; iter: 0; batch classifier loss: 0.108826; batch adversarial loss: 0.407927\n",
      "epoch 70; iter: 0; batch classifier loss: 0.121358; batch adversarial loss: 0.511938\n",
      "epoch 71; iter: 0; batch classifier loss: 0.053050; batch adversarial loss: 0.525433\n",
      "epoch 72; iter: 0; batch classifier loss: 0.115701; batch adversarial loss: 0.472595\n",
      "epoch 73; iter: 0; batch classifier loss: 0.125032; batch adversarial loss: 0.447066\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102888; batch adversarial loss: 0.515726\n",
      "epoch 75; iter: 0; batch classifier loss: 0.056516; batch adversarial loss: 0.429114\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066877; batch adversarial loss: 0.484539\n",
      "epoch 77; iter: 0; batch classifier loss: 0.041169; batch adversarial loss: 0.497426\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064072; batch adversarial loss: 0.443736\n",
      "epoch 79; iter: 0; batch classifier loss: 0.087265; batch adversarial loss: 0.418722\n",
      "epoch 80; iter: 0; batch classifier loss: 0.038450; batch adversarial loss: 0.430872\n",
      "epoch 81; iter: 0; batch classifier loss: 0.037542; batch adversarial loss: 0.442856\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052134; batch adversarial loss: 0.518841\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086365; batch adversarial loss: 0.509385\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056066; batch adversarial loss: 0.480534\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084590; batch adversarial loss: 0.463808\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051197; batch adversarial loss: 0.420747\n",
      "epoch 87; iter: 0; batch classifier loss: 0.039749; batch adversarial loss: 0.474310\n",
      "epoch 88; iter: 0; batch classifier loss: 0.045813; batch adversarial loss: 0.460449\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063340; batch adversarial loss: 0.442057\n",
      "epoch 90; iter: 0; batch classifier loss: 0.022487; batch adversarial loss: 0.538829\n",
      "epoch 91; iter: 0; batch classifier loss: 0.035659; batch adversarial loss: 0.497488\n",
      "epoch 92; iter: 0; batch classifier loss: 0.034868; batch adversarial loss: 0.636297\n",
      "epoch 93; iter: 0; batch classifier loss: 0.040680; batch adversarial loss: 0.562051\n",
      "epoch 94; iter: 0; batch classifier loss: 0.032935; batch adversarial loss: 0.490708\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038365; batch adversarial loss: 0.430443\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041193; batch adversarial loss: 0.441317\n",
      "epoch 97; iter: 0; batch classifier loss: 0.083277; batch adversarial loss: 0.461200\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045949; batch adversarial loss: 0.577656\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042805; batch adversarial loss: 0.444993\n",
      "epoch 100; iter: 0; batch classifier loss: 0.083795; batch adversarial loss: 0.350769\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047984; batch adversarial loss: 0.395814\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041165; batch adversarial loss: 0.455265\n",
      "epoch 103; iter: 0; batch classifier loss: 0.025258; batch adversarial loss: 0.438810\n",
      "epoch 104; iter: 0; batch classifier loss: 0.023581; batch adversarial loss: 0.467417\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053704; batch adversarial loss: 0.517989\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032815; batch adversarial loss: 0.424291\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056444; batch adversarial loss: 0.425513\n",
      "epoch 108; iter: 0; batch classifier loss: 0.075825; batch adversarial loss: 0.440479\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032957; batch adversarial loss: 0.409319\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025723; batch adversarial loss: 0.513172\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036059; batch adversarial loss: 0.459523\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035148; batch adversarial loss: 0.521919\n",
      "epoch 113; iter: 0; batch classifier loss: 0.016961; batch adversarial loss: 0.537754\n",
      "epoch 114; iter: 0; batch classifier loss: 0.021269; batch adversarial loss: 0.349959\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021185; batch adversarial loss: 0.468651\n",
      "epoch 116; iter: 0; batch classifier loss: 0.047540; batch adversarial loss: 0.470060\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049676; batch adversarial loss: 0.453980\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028519; batch adversarial loss: 0.448439\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019202; batch adversarial loss: 0.542688\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032140; batch adversarial loss: 0.440182\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025672; batch adversarial loss: 0.407617\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032178; batch adversarial loss: 0.496847\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027247; batch adversarial loss: 0.423089\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023938; batch adversarial loss: 0.411594\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025901; batch adversarial loss: 0.396929\n",
      "epoch 126; iter: 0; batch classifier loss: 0.010267; batch adversarial loss: 0.402252\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031857; batch adversarial loss: 0.470366\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035657; batch adversarial loss: 0.546120\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031816; batch adversarial loss: 0.517448\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018998; batch adversarial loss: 0.484026\n",
      "epoch 131; iter: 0; batch classifier loss: 0.016982; batch adversarial loss: 0.532635\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049157; batch adversarial loss: 0.419575\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018384; batch adversarial loss: 0.452459\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053226; batch adversarial loss: 0.538772\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021651; batch adversarial loss: 0.596807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.035725; batch adversarial loss: 0.507458\n",
      "epoch 137; iter: 0; batch classifier loss: 0.070841; batch adversarial loss: 0.465543\n",
      "epoch 138; iter: 0; batch classifier loss: 0.015394; batch adversarial loss: 0.388858\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023049; batch adversarial loss: 0.533978\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033211; batch adversarial loss: 0.449909\n",
      "epoch 141; iter: 0; batch classifier loss: 0.014324; batch adversarial loss: 0.500702\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028966; batch adversarial loss: 0.443958\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024255; batch adversarial loss: 0.496734\n",
      "epoch 144; iter: 0; batch classifier loss: 0.006302; batch adversarial loss: 0.508575\n",
      "epoch 145; iter: 0; batch classifier loss: 0.053228; batch adversarial loss: 0.453767\n",
      "epoch 146; iter: 0; batch classifier loss: 0.058244; batch adversarial loss: 0.530495\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016168; batch adversarial loss: 0.526508\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016272; batch adversarial loss: 0.422200\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019013; batch adversarial loss: 0.436877\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013535; batch adversarial loss: 0.446066\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009098; batch adversarial loss: 0.401645\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022888; batch adversarial loss: 0.502673\n",
      "epoch 153; iter: 0; batch classifier loss: 0.006330; batch adversarial loss: 0.402673\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017756; batch adversarial loss: 0.506373\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017635; batch adversarial loss: 0.405585\n",
      "epoch 156; iter: 0; batch classifier loss: 0.058440; batch adversarial loss: 0.452366\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021713; batch adversarial loss: 0.418314\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032511; batch adversarial loss: 0.548989\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019719; batch adversarial loss: 0.519011\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018109; batch adversarial loss: 0.493306\n",
      "epoch 161; iter: 0; batch classifier loss: 0.006050; batch adversarial loss: 0.492670\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023477; batch adversarial loss: 0.456590\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015327; batch adversarial loss: 0.449846\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017428; batch adversarial loss: 0.506197\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021610; batch adversarial loss: 0.413650\n",
      "epoch 166; iter: 0; batch classifier loss: 0.049575; batch adversarial loss: 0.514995\n",
      "epoch 167; iter: 0; batch classifier loss: 0.040016; batch adversarial loss: 0.484298\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012936; batch adversarial loss: 0.385671\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023035; batch adversarial loss: 0.403678\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029601; batch adversarial loss: 0.396753\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029913; batch adversarial loss: 0.566946\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010505; batch adversarial loss: 0.431427\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021785; batch adversarial loss: 0.442723\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029955; batch adversarial loss: 0.493886\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014587; batch adversarial loss: 0.449948\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018649; batch adversarial loss: 0.344482\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019538; batch adversarial loss: 0.510658\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009131; batch adversarial loss: 0.442867\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024622; batch adversarial loss: 0.451594\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019113; batch adversarial loss: 0.510829\n",
      "epoch 181; iter: 0; batch classifier loss: 0.067047; batch adversarial loss: 0.486103\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008204; batch adversarial loss: 0.447243\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019039; batch adversarial loss: 0.450012\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017388; batch adversarial loss: 0.437760\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013328; batch adversarial loss: 0.449982\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012213; batch adversarial loss: 0.390797\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027298; batch adversarial loss: 0.454697\n",
      "epoch 188; iter: 0; batch classifier loss: 0.047713; batch adversarial loss: 0.493860\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030294; batch adversarial loss: 0.341560\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028732; batch adversarial loss: 0.468667\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022170; batch adversarial loss: 0.345941\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023113; batch adversarial loss: 0.430188\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021558; batch adversarial loss: 0.470074\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008160; batch adversarial loss: 0.380253\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011074; batch adversarial loss: 0.462683\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037389; batch adversarial loss: 0.407196\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012019; batch adversarial loss: 0.444512\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017809; batch adversarial loss: 0.452237\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018361; batch adversarial loss: 0.511892\n",
      "epoch 0; iter: 0; batch classifier loss: 0.753159; batch adversarial loss: 0.743573\n",
      "epoch 1; iter: 0; batch classifier loss: 0.504408; batch adversarial loss: 0.678712\n",
      "epoch 2; iter: 0; batch classifier loss: 0.412225; batch adversarial loss: 0.640980\n",
      "epoch 3; iter: 0; batch classifier loss: 0.406180; batch adversarial loss: 0.629795\n",
      "epoch 4; iter: 0; batch classifier loss: 0.329448; batch adversarial loss: 0.594325\n",
      "epoch 5; iter: 0; batch classifier loss: 0.420750; batch adversarial loss: 0.597323\n",
      "epoch 6; iter: 0; batch classifier loss: 0.355342; batch adversarial loss: 0.587862\n",
      "epoch 7; iter: 0; batch classifier loss: 0.419549; batch adversarial loss: 0.567930\n",
      "epoch 8; iter: 0; batch classifier loss: 0.351202; batch adversarial loss: 0.565400\n",
      "epoch 9; iter: 0; batch classifier loss: 0.446336; batch adversarial loss: 0.559835\n",
      "epoch 10; iter: 0; batch classifier loss: 0.473055; batch adversarial loss: 0.533522\n",
      "epoch 11; iter: 0; batch classifier loss: 0.494273; batch adversarial loss: 0.524383\n",
      "epoch 12; iter: 0; batch classifier loss: 0.372056; batch adversarial loss: 0.507778\n",
      "epoch 13; iter: 0; batch classifier loss: 0.338046; batch adversarial loss: 0.526061\n",
      "epoch 14; iter: 0; batch classifier loss: 0.304543; batch adversarial loss: 0.563636\n",
      "epoch 15; iter: 0; batch classifier loss: 0.387798; batch adversarial loss: 0.488224\n",
      "epoch 16; iter: 0; batch classifier loss: 0.306480; batch adversarial loss: 0.511569\n",
      "epoch 17; iter: 0; batch classifier loss: 0.374248; batch adversarial loss: 0.407860\n",
      "epoch 18; iter: 0; batch classifier loss: 0.344453; batch adversarial loss: 0.465182\n",
      "epoch 19; iter: 0; batch classifier loss: 0.245769; batch adversarial loss: 0.502933\n",
      "epoch 20; iter: 0; batch classifier loss: 0.298797; batch adversarial loss: 0.456461\n",
      "epoch 21; iter: 0; batch classifier loss: 0.269348; batch adversarial loss: 0.458458\n",
      "epoch 22; iter: 0; batch classifier loss: 0.272541; batch adversarial loss: 0.479831\n",
      "epoch 23; iter: 0; batch classifier loss: 0.208819; batch adversarial loss: 0.470066\n",
      "epoch 24; iter: 0; batch classifier loss: 0.274328; batch adversarial loss: 0.437764\n",
      "epoch 25; iter: 0; batch classifier loss: 0.246052; batch adversarial loss: 0.478207\n",
      "epoch 26; iter: 0; batch classifier loss: 0.260728; batch adversarial loss: 0.501522\n",
      "epoch 27; iter: 0; batch classifier loss: 0.291849; batch adversarial loss: 0.528457\n",
      "epoch 28; iter: 0; batch classifier loss: 0.223268; batch adversarial loss: 0.468082\n",
      "epoch 29; iter: 0; batch classifier loss: 0.232603; batch adversarial loss: 0.480878\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205332; batch adversarial loss: 0.514015\n",
      "epoch 31; iter: 0; batch classifier loss: 0.183111; batch adversarial loss: 0.494548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.236699; batch adversarial loss: 0.493789\n",
      "epoch 33; iter: 0; batch classifier loss: 0.223618; batch adversarial loss: 0.378054\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233506; batch adversarial loss: 0.564546\n",
      "epoch 35; iter: 0; batch classifier loss: 0.198539; batch adversarial loss: 0.445354\n",
      "epoch 36; iter: 0; batch classifier loss: 0.191521; batch adversarial loss: 0.483157\n",
      "epoch 37; iter: 0; batch classifier loss: 0.185468; batch adversarial loss: 0.525856\n",
      "epoch 38; iter: 0; batch classifier loss: 0.270600; batch adversarial loss: 0.427610\n",
      "epoch 39; iter: 0; batch classifier loss: 0.195459; batch adversarial loss: 0.481516\n",
      "epoch 40; iter: 0; batch classifier loss: 0.173224; batch adversarial loss: 0.451399\n",
      "epoch 41; iter: 0; batch classifier loss: 0.205166; batch adversarial loss: 0.471124\n",
      "epoch 42; iter: 0; batch classifier loss: 0.227257; batch adversarial loss: 0.491246\n",
      "epoch 43; iter: 0; batch classifier loss: 0.173611; batch adversarial loss: 0.402649\n",
      "epoch 44; iter: 0; batch classifier loss: 0.194220; batch adversarial loss: 0.439271\n",
      "epoch 45; iter: 0; batch classifier loss: 0.231587; batch adversarial loss: 0.455669\n",
      "epoch 46; iter: 0; batch classifier loss: 0.188910; batch adversarial loss: 0.443785\n",
      "epoch 47; iter: 0; batch classifier loss: 0.188881; batch adversarial loss: 0.509657\n",
      "epoch 48; iter: 0; batch classifier loss: 0.186999; batch adversarial loss: 0.531031\n",
      "epoch 49; iter: 0; batch classifier loss: 0.210331; batch adversarial loss: 0.435382\n",
      "epoch 50; iter: 0; batch classifier loss: 0.155049; batch adversarial loss: 0.400242\n",
      "epoch 51; iter: 0; batch classifier loss: 0.169488; batch adversarial loss: 0.528526\n",
      "epoch 52; iter: 0; batch classifier loss: 0.182991; batch adversarial loss: 0.463903\n",
      "epoch 53; iter: 0; batch classifier loss: 0.159435; batch adversarial loss: 0.492889\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103965; batch adversarial loss: 0.512710\n",
      "epoch 55; iter: 0; batch classifier loss: 0.137342; batch adversarial loss: 0.532484\n",
      "epoch 56; iter: 0; batch classifier loss: 0.154761; batch adversarial loss: 0.436722\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072682; batch adversarial loss: 0.510360\n",
      "epoch 58; iter: 0; batch classifier loss: 0.106469; batch adversarial loss: 0.442806\n",
      "epoch 59; iter: 0; batch classifier loss: 0.121658; batch adversarial loss: 0.437574\n",
      "epoch 60; iter: 0; batch classifier loss: 0.116773; batch adversarial loss: 0.479532\n",
      "epoch 61; iter: 0; batch classifier loss: 0.134328; batch adversarial loss: 0.485081\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120815; batch adversarial loss: 0.472633\n",
      "epoch 63; iter: 0; batch classifier loss: 0.094747; batch adversarial loss: 0.519435\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073883; batch adversarial loss: 0.532963\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092185; batch adversarial loss: 0.495593\n",
      "epoch 66; iter: 0; batch classifier loss: 0.114157; batch adversarial loss: 0.396252\n",
      "epoch 67; iter: 0; batch classifier loss: 0.058991; batch adversarial loss: 0.475088\n",
      "epoch 68; iter: 0; batch classifier loss: 0.050008; batch adversarial loss: 0.449072\n",
      "epoch 69; iter: 0; batch classifier loss: 0.080840; batch adversarial loss: 0.443585\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067104; batch adversarial loss: 0.522816\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104728; batch adversarial loss: 0.391594\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062119; batch adversarial loss: 0.449428\n",
      "epoch 73; iter: 0; batch classifier loss: 0.061506; batch adversarial loss: 0.496898\n",
      "epoch 74; iter: 0; batch classifier loss: 0.085370; batch adversarial loss: 0.439621\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073963; batch adversarial loss: 0.436055\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063569; batch adversarial loss: 0.340403\n",
      "epoch 77; iter: 0; batch classifier loss: 0.077588; batch adversarial loss: 0.432944\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071686; batch adversarial loss: 0.440461\n",
      "epoch 79; iter: 0; batch classifier loss: 0.117875; batch adversarial loss: 0.391923\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056986; batch adversarial loss: 0.422085\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084895; batch adversarial loss: 0.466369\n",
      "epoch 82; iter: 0; batch classifier loss: 0.078725; batch adversarial loss: 0.466932\n",
      "epoch 83; iter: 0; batch classifier loss: 0.042219; batch adversarial loss: 0.485078\n",
      "epoch 84; iter: 0; batch classifier loss: 0.033884; batch adversarial loss: 0.429704\n",
      "epoch 85; iter: 0; batch classifier loss: 0.028852; batch adversarial loss: 0.549584\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040625; batch adversarial loss: 0.464878\n",
      "epoch 87; iter: 0; batch classifier loss: 0.037950; batch adversarial loss: 0.468196\n",
      "epoch 88; iter: 0; batch classifier loss: 0.068627; batch adversarial loss: 0.468310\n",
      "epoch 89; iter: 0; batch classifier loss: 0.039134; batch adversarial loss: 0.443357\n",
      "epoch 90; iter: 0; batch classifier loss: 0.032610; batch adversarial loss: 0.496272\n",
      "epoch 91; iter: 0; batch classifier loss: 0.042911; batch adversarial loss: 0.493784\n",
      "epoch 92; iter: 0; batch classifier loss: 0.037700; batch adversarial loss: 0.520069\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043438; batch adversarial loss: 0.434252\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068152; batch adversarial loss: 0.484134\n",
      "epoch 95; iter: 0; batch classifier loss: 0.041588; batch adversarial loss: 0.428432\n",
      "epoch 96; iter: 0; batch classifier loss: 0.023212; batch adversarial loss: 0.407449\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046769; batch adversarial loss: 0.438214\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039233; batch adversarial loss: 0.359420\n",
      "epoch 99; iter: 0; batch classifier loss: 0.028366; batch adversarial loss: 0.405282\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062731; batch adversarial loss: 0.419771\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044372; batch adversarial loss: 0.413399\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057452; batch adversarial loss: 0.399731\n",
      "epoch 103; iter: 0; batch classifier loss: 0.031476; batch adversarial loss: 0.400264\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038558; batch adversarial loss: 0.419444\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076846; batch adversarial loss: 0.428714\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044977; batch adversarial loss: 0.502623\n",
      "epoch 107; iter: 0; batch classifier loss: 0.021826; batch adversarial loss: 0.550111\n",
      "epoch 108; iter: 0; batch classifier loss: 0.061569; batch adversarial loss: 0.443281\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034584; batch adversarial loss: 0.498446\n",
      "epoch 110; iter: 0; batch classifier loss: 0.071740; batch adversarial loss: 0.493832\n",
      "epoch 111; iter: 0; batch classifier loss: 0.063716; batch adversarial loss: 0.459412\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026871; batch adversarial loss: 0.484251\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041495; batch adversarial loss: 0.409290\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027910; batch adversarial loss: 0.495469\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057002; batch adversarial loss: 0.376244\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052228; batch adversarial loss: 0.506996\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029228; batch adversarial loss: 0.485817\n",
      "epoch 118; iter: 0; batch classifier loss: 0.013625; batch adversarial loss: 0.491778\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031985; batch adversarial loss: 0.430610\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027054; batch adversarial loss: 0.488433\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042828; batch adversarial loss: 0.476582\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028185; batch adversarial loss: 0.523137\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017773; batch adversarial loss: 0.498389\n",
      "epoch 124; iter: 0; batch classifier loss: 0.071432; batch adversarial loss: 0.509242\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020105; batch adversarial loss: 0.501248\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026394; batch adversarial loss: 0.468016\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034138; batch adversarial loss: 0.413995\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045852; batch adversarial loss: 0.417935\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034181; batch adversarial loss: 0.483387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.049163; batch adversarial loss: 0.388372\n",
      "epoch 131; iter: 0; batch classifier loss: 0.016864; batch adversarial loss: 0.566594\n",
      "epoch 132; iter: 0; batch classifier loss: 0.052091; batch adversarial loss: 0.505213\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029927; batch adversarial loss: 0.490590\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023421; batch adversarial loss: 0.475327\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046949; batch adversarial loss: 0.451675\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050988; batch adversarial loss: 0.524343\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023211; batch adversarial loss: 0.400436\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034242; batch adversarial loss: 0.383914\n",
      "epoch 139; iter: 0; batch classifier loss: 0.052739; batch adversarial loss: 0.397549\n",
      "epoch 140; iter: 0; batch classifier loss: 0.015002; batch adversarial loss: 0.485854\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017134; batch adversarial loss: 0.485394\n",
      "epoch 142; iter: 0; batch classifier loss: 0.046291; batch adversarial loss: 0.431248\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051694; batch adversarial loss: 0.475961\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040237; batch adversarial loss: 0.446418\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012019; batch adversarial loss: 0.510266\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037742; batch adversarial loss: 0.434328\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013138; batch adversarial loss: 0.496079\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029144; batch adversarial loss: 0.495060\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044932; batch adversarial loss: 0.472896\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017446; batch adversarial loss: 0.445487\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013138; batch adversarial loss: 0.556681\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011429; batch adversarial loss: 0.444654\n",
      "epoch 153; iter: 0; batch classifier loss: 0.055281; batch adversarial loss: 0.517222\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018529; batch adversarial loss: 0.501197\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030181; batch adversarial loss: 0.468954\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032343; batch adversarial loss: 0.500626\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025230; batch adversarial loss: 0.462812\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029167; batch adversarial loss: 0.500803\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030445; batch adversarial loss: 0.530224\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019297; batch adversarial loss: 0.457867\n",
      "epoch 161; iter: 0; batch classifier loss: 0.005942; batch adversarial loss: 0.585557\n",
      "epoch 162; iter: 0; batch classifier loss: 0.044708; batch adversarial loss: 0.457886\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022599; batch adversarial loss: 0.422986\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012217; batch adversarial loss: 0.422432\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014044; batch adversarial loss: 0.423572\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026777; batch adversarial loss: 0.480770\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030014; batch adversarial loss: 0.411437\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008652; batch adversarial loss: 0.468185\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008539; batch adversarial loss: 0.575762\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028626; batch adversarial loss: 0.471015\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033926; batch adversarial loss: 0.486842\n",
      "epoch 172; iter: 0; batch classifier loss: 0.050037; batch adversarial loss: 0.488191\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021312; batch adversarial loss: 0.454754\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007116; batch adversarial loss: 0.593400\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024099; batch adversarial loss: 0.465758\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008485; batch adversarial loss: 0.379602\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017299; batch adversarial loss: 0.498552\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037248; batch adversarial loss: 0.397606\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006562; batch adversarial loss: 0.404261\n",
      "epoch 180; iter: 0; batch classifier loss: 0.045851; batch adversarial loss: 0.482667\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010941; batch adversarial loss: 0.432198\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017670; batch adversarial loss: 0.450406\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005671; batch adversarial loss: 0.457983\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007714; batch adversarial loss: 0.408611\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017313; batch adversarial loss: 0.485438\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026814; batch adversarial loss: 0.478814\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007319; batch adversarial loss: 0.474317\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027139; batch adversarial loss: 0.404414\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016246; batch adversarial loss: 0.419304\n",
      "epoch 190; iter: 0; batch classifier loss: 0.003713; batch adversarial loss: 0.539189\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028140; batch adversarial loss: 0.490161\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016156; batch adversarial loss: 0.437237\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007305; batch adversarial loss: 0.548651\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023046; batch adversarial loss: 0.517387\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010427; batch adversarial loss: 0.418980\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015582; batch adversarial loss: 0.517074\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014012; batch adversarial loss: 0.402252\n",
      "epoch 198; iter: 0; batch classifier loss: 0.042849; batch adversarial loss: 0.509126\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028630; batch adversarial loss: 0.413959\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667273; batch adversarial loss: 0.822188\n",
      "epoch 1; iter: 0; batch classifier loss: 0.376864; batch adversarial loss: 0.766476\n",
      "epoch 2; iter: 0; batch classifier loss: 0.307873; batch adversarial loss: 0.753615\n",
      "epoch 3; iter: 0; batch classifier loss: 0.285226; batch adversarial loss: 0.706889\n",
      "epoch 4; iter: 0; batch classifier loss: 0.398289; batch adversarial loss: 0.677197\n",
      "epoch 5; iter: 0; batch classifier loss: 0.323704; batch adversarial loss: 0.660050\n",
      "epoch 6; iter: 0; batch classifier loss: 0.274135; batch adversarial loss: 0.628350\n",
      "epoch 7; iter: 0; batch classifier loss: 0.270954; batch adversarial loss: 0.590347\n",
      "epoch 8; iter: 0; batch classifier loss: 0.275733; batch adversarial loss: 0.584191\n",
      "epoch 9; iter: 0; batch classifier loss: 0.284416; batch adversarial loss: 0.564265\n",
      "epoch 10; iter: 0; batch classifier loss: 0.298261; batch adversarial loss: 0.538238\n",
      "epoch 11; iter: 0; batch classifier loss: 0.293121; batch adversarial loss: 0.493288\n",
      "epoch 12; iter: 0; batch classifier loss: 0.293288; batch adversarial loss: 0.473671\n",
      "epoch 13; iter: 0; batch classifier loss: 0.243609; batch adversarial loss: 0.459194\n",
      "epoch 14; iter: 0; batch classifier loss: 0.213525; batch adversarial loss: 0.420894\n",
      "epoch 15; iter: 0; batch classifier loss: 0.304665; batch adversarial loss: 0.444681\n",
      "epoch 16; iter: 0; batch classifier loss: 0.286655; batch adversarial loss: 0.422972\n",
      "epoch 17; iter: 0; batch classifier loss: 0.226789; batch adversarial loss: 0.478354\n",
      "epoch 18; iter: 0; batch classifier loss: 0.270387; batch adversarial loss: 0.350139\n",
      "epoch 19; iter: 0; batch classifier loss: 0.311523; batch adversarial loss: 0.437053\n",
      "epoch 20; iter: 0; batch classifier loss: 0.284426; batch adversarial loss: 0.400681\n",
      "epoch 21; iter: 0; batch classifier loss: 0.211999; batch adversarial loss: 0.403981\n",
      "epoch 22; iter: 0; batch classifier loss: 0.255283; batch adversarial loss: 0.442165\n",
      "epoch 23; iter: 0; batch classifier loss: 0.236386; batch adversarial loss: 0.426083\n",
      "epoch 24; iter: 0; batch classifier loss: 0.204570; batch adversarial loss: 0.401735\n",
      "epoch 25; iter: 0; batch classifier loss: 0.228596; batch adversarial loss: 0.411074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.173808; batch adversarial loss: 0.397711\n",
      "epoch 27; iter: 0; batch classifier loss: 0.135401; batch adversarial loss: 0.373493\n",
      "epoch 28; iter: 0; batch classifier loss: 0.149271; batch adversarial loss: 0.397454\n",
      "epoch 29; iter: 0; batch classifier loss: 0.155951; batch adversarial loss: 0.311746\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167167; batch adversarial loss: 0.387449\n",
      "epoch 31; iter: 0; batch classifier loss: 0.239398; batch adversarial loss: 0.426693\n",
      "epoch 32; iter: 0; batch classifier loss: 0.144510; batch adversarial loss: 0.460576\n",
      "epoch 33; iter: 0; batch classifier loss: 0.166482; batch adversarial loss: 0.361481\n",
      "epoch 34; iter: 0; batch classifier loss: 0.178613; batch adversarial loss: 0.393806\n",
      "epoch 35; iter: 0; batch classifier loss: 0.093206; batch adversarial loss: 0.428159\n",
      "epoch 36; iter: 0; batch classifier loss: 0.139082; batch adversarial loss: 0.391115\n",
      "epoch 37; iter: 0; batch classifier loss: 0.174290; batch adversarial loss: 0.357237\n",
      "epoch 38; iter: 0; batch classifier loss: 0.139907; batch adversarial loss: 0.412904\n",
      "epoch 39; iter: 0; batch classifier loss: 0.111773; batch adversarial loss: 0.401776\n",
      "epoch 40; iter: 0; batch classifier loss: 0.137098; batch adversarial loss: 0.467355\n",
      "epoch 41; iter: 0; batch classifier loss: 0.152725; batch adversarial loss: 0.413524\n",
      "epoch 42; iter: 0; batch classifier loss: 0.134990; batch adversarial loss: 0.427166\n",
      "epoch 43; iter: 0; batch classifier loss: 0.140796; batch adversarial loss: 0.390861\n",
      "epoch 44; iter: 0; batch classifier loss: 0.158006; batch adversarial loss: 0.387055\n",
      "epoch 45; iter: 0; batch classifier loss: 0.087111; batch adversarial loss: 0.325031\n",
      "epoch 46; iter: 0; batch classifier loss: 0.149900; batch adversarial loss: 0.459486\n",
      "epoch 47; iter: 0; batch classifier loss: 0.097314; batch adversarial loss: 0.451234\n",
      "epoch 48; iter: 0; batch classifier loss: 0.140236; batch adversarial loss: 0.338067\n",
      "epoch 49; iter: 0; batch classifier loss: 0.131569; batch adversarial loss: 0.499214\n",
      "epoch 50; iter: 0; batch classifier loss: 0.142193; batch adversarial loss: 0.360537\n",
      "epoch 51; iter: 0; batch classifier loss: 0.141100; batch adversarial loss: 0.405692\n",
      "epoch 52; iter: 0; batch classifier loss: 0.110263; batch adversarial loss: 0.459887\n",
      "epoch 53; iter: 0; batch classifier loss: 0.142998; batch adversarial loss: 0.522358\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122398; batch adversarial loss: 0.446872\n",
      "epoch 55; iter: 0; batch classifier loss: 0.136436; batch adversarial loss: 0.435158\n",
      "epoch 56; iter: 0; batch classifier loss: 0.108130; batch adversarial loss: 0.440563\n",
      "epoch 57; iter: 0; batch classifier loss: 0.080202; batch adversarial loss: 0.439114\n",
      "epoch 58; iter: 0; batch classifier loss: 0.065096; batch adversarial loss: 0.436524\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072377; batch adversarial loss: 0.390485\n",
      "epoch 60; iter: 0; batch classifier loss: 0.075524; batch adversarial loss: 0.415106\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078801; batch adversarial loss: 0.423633\n",
      "epoch 62; iter: 0; batch classifier loss: 0.072484; batch adversarial loss: 0.405865\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103342; batch adversarial loss: 0.409447\n",
      "epoch 64; iter: 0; batch classifier loss: 0.096666; batch adversarial loss: 0.430608\n",
      "epoch 65; iter: 0; batch classifier loss: 0.111584; batch adversarial loss: 0.507642\n",
      "epoch 66; iter: 0; batch classifier loss: 0.101636; batch adversarial loss: 0.471544\n",
      "epoch 67; iter: 0; batch classifier loss: 0.086232; batch adversarial loss: 0.305668\n",
      "epoch 68; iter: 0; batch classifier loss: 0.083658; batch adversarial loss: 0.427245\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103342; batch adversarial loss: 0.439976\n",
      "epoch 70; iter: 0; batch classifier loss: 0.083304; batch adversarial loss: 0.395885\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092418; batch adversarial loss: 0.399573\n",
      "epoch 72; iter: 0; batch classifier loss: 0.094703; batch adversarial loss: 0.415802\n",
      "epoch 73; iter: 0; batch classifier loss: 0.106981; batch adversarial loss: 0.456528\n",
      "epoch 74; iter: 0; batch classifier loss: 0.119082; batch adversarial loss: 0.533911\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075280; batch adversarial loss: 0.440178\n",
      "epoch 76; iter: 0; batch classifier loss: 0.095190; batch adversarial loss: 0.420175\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108849; batch adversarial loss: 0.458749\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066758; batch adversarial loss: 0.391721\n",
      "epoch 79; iter: 0; batch classifier loss: 0.056224; batch adversarial loss: 0.381525\n",
      "epoch 80; iter: 0; batch classifier loss: 0.093301; batch adversarial loss: 0.407188\n",
      "epoch 81; iter: 0; batch classifier loss: 0.078789; batch adversarial loss: 0.416062\n",
      "epoch 82; iter: 0; batch classifier loss: 0.077526; batch adversarial loss: 0.374124\n",
      "epoch 83; iter: 0; batch classifier loss: 0.092245; batch adversarial loss: 0.466676\n",
      "epoch 84; iter: 0; batch classifier loss: 0.098686; batch adversarial loss: 0.408523\n",
      "epoch 85; iter: 0; batch classifier loss: 0.071819; batch adversarial loss: 0.389551\n",
      "epoch 86; iter: 0; batch classifier loss: 0.092076; batch adversarial loss: 0.399632\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046285; batch adversarial loss: 0.516163\n",
      "epoch 88; iter: 0; batch classifier loss: 0.096802; batch adversarial loss: 0.383741\n",
      "epoch 89; iter: 0; batch classifier loss: 0.062231; batch adversarial loss: 0.446821\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057260; batch adversarial loss: 0.424688\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071560; batch adversarial loss: 0.445201\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060968; batch adversarial loss: 0.462286\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062741; batch adversarial loss: 0.528408\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081045; batch adversarial loss: 0.389284\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038563; batch adversarial loss: 0.416350\n",
      "epoch 96; iter: 0; batch classifier loss: 0.086360; batch adversarial loss: 0.482562\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052258; batch adversarial loss: 0.484679\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058836; batch adversarial loss: 0.392664\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085521; batch adversarial loss: 0.457830\n",
      "epoch 100; iter: 0; batch classifier loss: 0.094610; batch adversarial loss: 0.321779\n",
      "epoch 101; iter: 0; batch classifier loss: 0.091336; batch adversarial loss: 0.418618\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066100; batch adversarial loss: 0.516886\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061132; batch adversarial loss: 0.415057\n",
      "epoch 104; iter: 0; batch classifier loss: 0.105597; batch adversarial loss: 0.333658\n",
      "epoch 105; iter: 0; batch classifier loss: 0.067348; batch adversarial loss: 0.385084\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058511; batch adversarial loss: 0.478608\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055033; batch adversarial loss: 0.443885\n",
      "epoch 108; iter: 0; batch classifier loss: 0.079396; batch adversarial loss: 0.533373\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049256; batch adversarial loss: 0.467704\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053479; batch adversarial loss: 0.418782\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044419; batch adversarial loss: 0.388792\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056479; batch adversarial loss: 0.400619\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029926; batch adversarial loss: 0.331752\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052525; batch adversarial loss: 0.441869\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038543; batch adversarial loss: 0.403638\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021482; batch adversarial loss: 0.383216\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041970; batch adversarial loss: 0.406318\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048648; batch adversarial loss: 0.452369\n",
      "epoch 119; iter: 0; batch classifier loss: 0.091768; batch adversarial loss: 0.421023\n",
      "epoch 120; iter: 0; batch classifier loss: 0.023992; batch adversarial loss: 0.490605\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052782; batch adversarial loss: 0.410565\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039188; batch adversarial loss: 0.495247\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067845; batch adversarial loss: 0.369769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.042583; batch adversarial loss: 0.418604\n",
      "epoch 125; iter: 0; batch classifier loss: 0.085636; batch adversarial loss: 0.458894\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023405; batch adversarial loss: 0.533499\n",
      "epoch 127; iter: 0; batch classifier loss: 0.018377; batch adversarial loss: 0.481746\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047473; batch adversarial loss: 0.491225\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048846; batch adversarial loss: 0.422755\n",
      "epoch 130; iter: 0; batch classifier loss: 0.068443; batch adversarial loss: 0.551356\n",
      "epoch 131; iter: 0; batch classifier loss: 0.012893; batch adversarial loss: 0.489112\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035206; batch adversarial loss: 0.419588\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041698; batch adversarial loss: 0.615171\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033162; batch adversarial loss: 0.400939\n",
      "epoch 135; iter: 0; batch classifier loss: 0.094999; batch adversarial loss: 0.507960\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049676; batch adversarial loss: 0.406585\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041172; batch adversarial loss: 0.518333\n",
      "epoch 138; iter: 0; batch classifier loss: 0.101191; batch adversarial loss: 0.677717\n",
      "epoch 139; iter: 0; batch classifier loss: 0.089941; batch adversarial loss: 0.629495\n",
      "epoch 140; iter: 0; batch classifier loss: 0.116607; batch adversarial loss: 0.563088\n",
      "epoch 141; iter: 0; batch classifier loss: 0.054778; batch adversarial loss: 0.537264\n",
      "epoch 142; iter: 0; batch classifier loss: 0.128934; batch adversarial loss: 0.535547\n",
      "epoch 143; iter: 0; batch classifier loss: 0.052952; batch adversarial loss: 0.483061\n",
      "epoch 144; iter: 0; batch classifier loss: 0.094330; batch adversarial loss: 0.509445\n",
      "epoch 145; iter: 0; batch classifier loss: 0.169592; batch adversarial loss: 0.724292\n",
      "epoch 146; iter: 0; batch classifier loss: 0.128869; batch adversarial loss: 0.649573\n",
      "epoch 147; iter: 0; batch classifier loss: 0.132736; batch adversarial loss: 0.616951\n",
      "epoch 148; iter: 0; batch classifier loss: 0.193707; batch adversarial loss: 0.842197\n",
      "epoch 149; iter: 0; batch classifier loss: 0.159820; batch adversarial loss: 0.569158\n",
      "epoch 150; iter: 0; batch classifier loss: 0.185300; batch adversarial loss: 0.670532\n",
      "epoch 151; iter: 0; batch classifier loss: 0.130693; batch adversarial loss: 0.414890\n",
      "epoch 152; iter: 0; batch classifier loss: 0.219207; batch adversarial loss: 0.767594\n",
      "epoch 153; iter: 0; batch classifier loss: 0.111209; batch adversarial loss: 0.529611\n",
      "epoch 154; iter: 0; batch classifier loss: 0.139603; batch adversarial loss: 0.599384\n",
      "epoch 155; iter: 0; batch classifier loss: 0.153527; batch adversarial loss: 0.639473\n",
      "epoch 156; iter: 0; batch classifier loss: 0.213944; batch adversarial loss: 0.749069\n",
      "epoch 157; iter: 0; batch classifier loss: 0.166038; batch adversarial loss: 0.595410\n",
      "epoch 158; iter: 0; batch classifier loss: 0.063714; batch adversarial loss: 0.478317\n",
      "epoch 159; iter: 0; batch classifier loss: 0.182695; batch adversarial loss: 0.660588\n",
      "epoch 160; iter: 0; batch classifier loss: 0.158306; batch adversarial loss: 0.517192\n",
      "epoch 161; iter: 0; batch classifier loss: 0.167950; batch adversarial loss: 0.609278\n",
      "epoch 162; iter: 0; batch classifier loss: 0.045064; batch adversarial loss: 0.369818\n",
      "epoch 163; iter: 0; batch classifier loss: 0.103556; batch adversarial loss: 0.557686\n",
      "epoch 164; iter: 0; batch classifier loss: 0.091814; batch adversarial loss: 0.496984\n",
      "epoch 165; iter: 0; batch classifier loss: 0.145212; batch adversarial loss: 0.525739\n",
      "epoch 166; iter: 0; batch classifier loss: 0.144574; batch adversarial loss: 0.498253\n",
      "epoch 167; iter: 0; batch classifier loss: 0.112617; batch adversarial loss: 0.394707\n",
      "epoch 168; iter: 0; batch classifier loss: 0.170375; batch adversarial loss: 0.453953\n",
      "epoch 169; iter: 0; batch classifier loss: 0.103282; batch adversarial loss: 0.427186\n",
      "epoch 170; iter: 0; batch classifier loss: 0.075314; batch adversarial loss: 0.467071\n",
      "epoch 171; iter: 0; batch classifier loss: 0.119274; batch adversarial loss: 0.498510\n",
      "epoch 172; iter: 0; batch classifier loss: 0.123879; batch adversarial loss: 0.472717\n",
      "epoch 173; iter: 0; batch classifier loss: 0.112792; batch adversarial loss: 0.462179\n",
      "epoch 174; iter: 0; batch classifier loss: 0.116256; batch adversarial loss: 0.512136\n",
      "epoch 175; iter: 0; batch classifier loss: 0.113798; batch adversarial loss: 0.433499\n",
      "epoch 176; iter: 0; batch classifier loss: 0.099840; batch adversarial loss: 0.480469\n",
      "epoch 177; iter: 0; batch classifier loss: 0.135153; batch adversarial loss: 0.532230\n",
      "epoch 178; iter: 0; batch classifier loss: 0.098758; batch adversarial loss: 0.432439\n",
      "epoch 179; iter: 0; batch classifier loss: 0.182121; batch adversarial loss: 0.526691\n",
      "epoch 180; iter: 0; batch classifier loss: 0.080078; batch adversarial loss: 0.455581\n",
      "epoch 181; iter: 0; batch classifier loss: 0.079237; batch adversarial loss: 0.465991\n",
      "epoch 182; iter: 0; batch classifier loss: 0.120934; batch adversarial loss: 0.513361\n",
      "epoch 183; iter: 0; batch classifier loss: 0.164993; batch adversarial loss: 0.460534\n",
      "epoch 184; iter: 0; batch classifier loss: 0.143522; batch adversarial loss: 0.433440\n",
      "epoch 185; iter: 0; batch classifier loss: 0.066199; batch adversarial loss: 0.506500\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015002; batch adversarial loss: 0.384062\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030389; batch adversarial loss: 0.408266\n",
      "epoch 188; iter: 0; batch classifier loss: 0.051553; batch adversarial loss: 0.393689\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021172; batch adversarial loss: 0.416352\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038037; batch adversarial loss: 0.470980\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037361; batch adversarial loss: 0.487561\n",
      "epoch 192; iter: 0; batch classifier loss: 0.051795; batch adversarial loss: 0.521289\n",
      "epoch 193; iter: 0; batch classifier loss: 0.039094; batch adversarial loss: 0.465506\n",
      "epoch 194; iter: 0; batch classifier loss: 0.054569; batch adversarial loss: 0.456729\n",
      "epoch 195; iter: 0; batch classifier loss: 0.074018; batch adversarial loss: 0.423049\n",
      "epoch 196; iter: 0; batch classifier loss: 0.055313; batch adversarial loss: 0.450116\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034846; batch adversarial loss: 0.515468\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031205; batch adversarial loss: 0.470170\n",
      "epoch 199; iter: 0; batch classifier loss: 0.084446; batch adversarial loss: 0.572057\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684465; batch adversarial loss: 0.808492\n",
      "epoch 1; iter: 0; batch classifier loss: 0.494988; batch adversarial loss: 0.783000\n",
      "epoch 2; iter: 0; batch classifier loss: 0.712550; batch adversarial loss: 0.793684\n",
      "epoch 3; iter: 0; batch classifier loss: 0.826718; batch adversarial loss: 0.732547\n",
      "epoch 4; iter: 0; batch classifier loss: 0.739208; batch adversarial loss: 0.666235\n",
      "epoch 5; iter: 0; batch classifier loss: 0.523967; batch adversarial loss: 0.596597\n",
      "epoch 6; iter: 0; batch classifier loss: 0.416240; batch adversarial loss: 0.569352\n",
      "epoch 7; iter: 0; batch classifier loss: 0.390790; batch adversarial loss: 0.561632\n",
      "epoch 8; iter: 0; batch classifier loss: 0.366736; batch adversarial loss: 0.577444\n",
      "epoch 9; iter: 0; batch classifier loss: 0.376282; batch adversarial loss: 0.547467\n",
      "epoch 10; iter: 0; batch classifier loss: 0.340762; batch adversarial loss: 0.529944\n",
      "epoch 11; iter: 0; batch classifier loss: 0.297029; batch adversarial loss: 0.540496\n",
      "epoch 12; iter: 0; batch classifier loss: 0.308104; batch adversarial loss: 0.509161\n",
      "epoch 13; iter: 0; batch classifier loss: 0.326394; batch adversarial loss: 0.555792\n",
      "epoch 14; iter: 0; batch classifier loss: 0.344885; batch adversarial loss: 0.488062\n",
      "epoch 15; iter: 0; batch classifier loss: 0.355878; batch adversarial loss: 0.481773\n",
      "epoch 16; iter: 0; batch classifier loss: 0.257886; batch adversarial loss: 0.499252\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265073; batch adversarial loss: 0.543492\n",
      "epoch 18; iter: 0; batch classifier loss: 0.283444; batch adversarial loss: 0.527959\n",
      "epoch 19; iter: 0; batch classifier loss: 0.273852; batch adversarial loss: 0.508021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.279501; batch adversarial loss: 0.469676\n",
      "epoch 21; iter: 0; batch classifier loss: 0.344043; batch adversarial loss: 0.486937\n",
      "epoch 22; iter: 0; batch classifier loss: 0.184123; batch adversarial loss: 0.444982\n",
      "epoch 23; iter: 0; batch classifier loss: 0.282943; batch adversarial loss: 0.486036\n",
      "epoch 24; iter: 0; batch classifier loss: 0.238986; batch adversarial loss: 0.487152\n",
      "epoch 25; iter: 0; batch classifier loss: 0.300333; batch adversarial loss: 0.382139\n",
      "epoch 26; iter: 0; batch classifier loss: 0.213462; batch adversarial loss: 0.466918\n",
      "epoch 27; iter: 0; batch classifier loss: 0.265803; batch adversarial loss: 0.498210\n",
      "epoch 28; iter: 0; batch classifier loss: 0.199991; batch adversarial loss: 0.473559\n",
      "epoch 29; iter: 0; batch classifier loss: 0.255754; batch adversarial loss: 0.486480\n",
      "epoch 30; iter: 0; batch classifier loss: 0.283882; batch adversarial loss: 0.408946\n",
      "epoch 31; iter: 0; batch classifier loss: 0.272726; batch adversarial loss: 0.420079\n",
      "epoch 32; iter: 0; batch classifier loss: 0.213471; batch adversarial loss: 0.480269\n",
      "epoch 33; iter: 0; batch classifier loss: 0.177442; batch adversarial loss: 0.528871\n",
      "epoch 34; iter: 0; batch classifier loss: 0.159129; batch adversarial loss: 0.562020\n",
      "epoch 35; iter: 0; batch classifier loss: 0.244689; batch adversarial loss: 0.508019\n",
      "epoch 36; iter: 0; batch classifier loss: 0.217405; batch adversarial loss: 0.456058\n",
      "epoch 37; iter: 0; batch classifier loss: 0.232554; batch adversarial loss: 0.479707\n",
      "epoch 38; iter: 0; batch classifier loss: 0.200413; batch adversarial loss: 0.524314\n",
      "epoch 39; iter: 0; batch classifier loss: 0.191118; batch adversarial loss: 0.501752\n",
      "epoch 40; iter: 0; batch classifier loss: 0.210106; batch adversarial loss: 0.483816\n",
      "epoch 41; iter: 0; batch classifier loss: 0.168652; batch adversarial loss: 0.428832\n",
      "epoch 42; iter: 0; batch classifier loss: 0.219262; batch adversarial loss: 0.485745\n",
      "epoch 43; iter: 0; batch classifier loss: 0.206575; batch adversarial loss: 0.456946\n",
      "epoch 44; iter: 0; batch classifier loss: 0.180886; batch adversarial loss: 0.397099\n",
      "epoch 45; iter: 0; batch classifier loss: 0.166107; batch adversarial loss: 0.478141\n",
      "epoch 46; iter: 0; batch classifier loss: 0.149927; batch adversarial loss: 0.469996\n",
      "epoch 47; iter: 0; batch classifier loss: 0.166502; batch adversarial loss: 0.471951\n",
      "epoch 48; iter: 0; batch classifier loss: 0.161577; batch adversarial loss: 0.399709\n",
      "epoch 49; iter: 0; batch classifier loss: 0.205362; batch adversarial loss: 0.414181\n",
      "epoch 50; iter: 0; batch classifier loss: 0.175394; batch adversarial loss: 0.481923\n",
      "epoch 51; iter: 0; batch classifier loss: 0.157709; batch adversarial loss: 0.456443\n",
      "epoch 52; iter: 0; batch classifier loss: 0.144286; batch adversarial loss: 0.395860\n",
      "epoch 53; iter: 0; batch classifier loss: 0.143080; batch adversarial loss: 0.461629\n",
      "epoch 54; iter: 0; batch classifier loss: 0.188082; batch adversarial loss: 0.441107\n",
      "epoch 55; iter: 0; batch classifier loss: 0.158608; batch adversarial loss: 0.510482\n",
      "epoch 56; iter: 0; batch classifier loss: 0.116931; batch adversarial loss: 0.395923\n",
      "epoch 57; iter: 0; batch classifier loss: 0.141677; batch adversarial loss: 0.338252\n",
      "epoch 58; iter: 0; batch classifier loss: 0.169990; batch adversarial loss: 0.516690\n",
      "epoch 59; iter: 0; batch classifier loss: 0.143951; batch adversarial loss: 0.411913\n",
      "epoch 60; iter: 0; batch classifier loss: 0.178000; batch adversarial loss: 0.449910\n",
      "epoch 61; iter: 0; batch classifier loss: 0.163337; batch adversarial loss: 0.361610\n",
      "epoch 62; iter: 0; batch classifier loss: 0.115290; batch adversarial loss: 0.402555\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128207; batch adversarial loss: 0.458994\n",
      "epoch 64; iter: 0; batch classifier loss: 0.157357; batch adversarial loss: 0.479896\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107644; batch adversarial loss: 0.412944\n",
      "epoch 66; iter: 0; batch classifier loss: 0.118281; batch adversarial loss: 0.630167\n",
      "epoch 67; iter: 0; batch classifier loss: 0.118369; batch adversarial loss: 0.505231\n",
      "epoch 68; iter: 0; batch classifier loss: 0.098752; batch adversarial loss: 0.508608\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081638; batch adversarial loss: 0.444210\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110369; batch adversarial loss: 0.382593\n",
      "epoch 71; iter: 0; batch classifier loss: 0.125845; batch adversarial loss: 0.503728\n",
      "epoch 72; iter: 0; batch classifier loss: 0.176621; batch adversarial loss: 0.434463\n",
      "epoch 73; iter: 0; batch classifier loss: 0.108570; batch adversarial loss: 0.485219\n",
      "epoch 74; iter: 0; batch classifier loss: 0.124881; batch adversarial loss: 0.396058\n",
      "epoch 75; iter: 0; batch classifier loss: 0.102207; batch adversarial loss: 0.518703\n",
      "epoch 76; iter: 0; batch classifier loss: 0.093402; batch adversarial loss: 0.524204\n",
      "epoch 77; iter: 0; batch classifier loss: 0.160178; batch adversarial loss: 0.413316\n",
      "epoch 78; iter: 0; batch classifier loss: 0.143024; batch adversarial loss: 0.406561\n",
      "epoch 79; iter: 0; batch classifier loss: 0.130769; batch adversarial loss: 0.409574\n",
      "epoch 80; iter: 0; batch classifier loss: 0.145631; batch adversarial loss: 0.462487\n",
      "epoch 81; iter: 0; batch classifier loss: 0.109877; batch adversarial loss: 0.488794\n",
      "epoch 82; iter: 0; batch classifier loss: 0.115058; batch adversarial loss: 0.448742\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094852; batch adversarial loss: 0.404738\n",
      "epoch 84; iter: 0; batch classifier loss: 0.097114; batch adversarial loss: 0.398119\n",
      "epoch 85; iter: 0; batch classifier loss: 0.081707; batch adversarial loss: 0.428947\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061775; batch adversarial loss: 0.423563\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079952; batch adversarial loss: 0.567512\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057989; batch adversarial loss: 0.462290\n",
      "epoch 89; iter: 0; batch classifier loss: 0.121903; batch adversarial loss: 0.449635\n",
      "epoch 90; iter: 0; batch classifier loss: 0.076286; batch adversarial loss: 0.403916\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083516; batch adversarial loss: 0.392523\n",
      "epoch 92; iter: 0; batch classifier loss: 0.035687; batch adversarial loss: 0.478170\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061803; batch adversarial loss: 0.384416\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039615; batch adversarial loss: 0.451946\n",
      "epoch 95; iter: 0; batch classifier loss: 0.062719; batch adversarial loss: 0.519575\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068888; batch adversarial loss: 0.446365\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054942; batch adversarial loss: 0.339665\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039969; batch adversarial loss: 0.461914\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065054; batch adversarial loss: 0.423998\n",
      "epoch 100; iter: 0; batch classifier loss: 0.072330; batch adversarial loss: 0.488922\n",
      "epoch 101; iter: 0; batch classifier loss: 0.035199; batch adversarial loss: 0.439805\n",
      "epoch 102; iter: 0; batch classifier loss: 0.072517; batch adversarial loss: 0.505728\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058421; batch adversarial loss: 0.496856\n",
      "epoch 104; iter: 0; batch classifier loss: 0.032559; batch adversarial loss: 0.494643\n",
      "epoch 105; iter: 0; batch classifier loss: 0.071478; batch adversarial loss: 0.450172\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052479; batch adversarial loss: 0.462518\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034265; batch adversarial loss: 0.479094\n",
      "epoch 108; iter: 0; batch classifier loss: 0.025724; batch adversarial loss: 0.485535\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046892; batch adversarial loss: 0.425433\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023136; batch adversarial loss: 0.437123\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031904; batch adversarial loss: 0.440892\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052466; batch adversarial loss: 0.559658\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028942; batch adversarial loss: 0.449697\n",
      "epoch 114; iter: 0; batch classifier loss: 0.020799; batch adversarial loss: 0.442214\n",
      "epoch 115; iter: 0; batch classifier loss: 0.061694; batch adversarial loss: 0.434476\n",
      "epoch 116; iter: 0; batch classifier loss: 0.031753; batch adversarial loss: 0.447155\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033962; batch adversarial loss: 0.440349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.044369; batch adversarial loss: 0.411111\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025160; batch adversarial loss: 0.417020\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053854; batch adversarial loss: 0.488419\n",
      "epoch 121; iter: 0; batch classifier loss: 0.061418; batch adversarial loss: 0.526650\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033643; batch adversarial loss: 0.538477\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020300; batch adversarial loss: 0.429814\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037923; batch adversarial loss: 0.420848\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036546; batch adversarial loss: 0.427429\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049335; batch adversarial loss: 0.444108\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026504; batch adversarial loss: 0.549333\n",
      "epoch 128; iter: 0; batch classifier loss: 0.007627; batch adversarial loss: 0.449460\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037396; batch adversarial loss: 0.556032\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050111; batch adversarial loss: 0.417263\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036328; batch adversarial loss: 0.567322\n",
      "epoch 132; iter: 0; batch classifier loss: 0.017098; batch adversarial loss: 0.417832\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015415; batch adversarial loss: 0.511291\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015931; batch adversarial loss: 0.467825\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020267; batch adversarial loss: 0.412053\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016535; batch adversarial loss: 0.421281\n",
      "epoch 137; iter: 0; batch classifier loss: 0.013219; batch adversarial loss: 0.443076\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035398; batch adversarial loss: 0.455819\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013378; batch adversarial loss: 0.437983\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025926; batch adversarial loss: 0.514924\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021658; batch adversarial loss: 0.356071\n",
      "epoch 142; iter: 0; batch classifier loss: 0.010592; batch adversarial loss: 0.491791\n",
      "epoch 143; iter: 0; batch classifier loss: 0.012044; batch adversarial loss: 0.417557\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013443; batch adversarial loss: 0.494382\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035910; batch adversarial loss: 0.459917\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040651; batch adversarial loss: 0.383538\n",
      "epoch 147; iter: 0; batch classifier loss: 0.009422; batch adversarial loss: 0.438702\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014549; batch adversarial loss: 0.460181\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024246; batch adversarial loss: 0.506185\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024667; batch adversarial loss: 0.525255\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015216; batch adversarial loss: 0.411862\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039754; batch adversarial loss: 0.435717\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018545; batch adversarial loss: 0.398051\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023272; batch adversarial loss: 0.315154\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018605; batch adversarial loss: 0.432128\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021496; batch adversarial loss: 0.421526\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014034; batch adversarial loss: 0.447419\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023774; batch adversarial loss: 0.513328\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016096; batch adversarial loss: 0.419045\n",
      "epoch 160; iter: 0; batch classifier loss: 0.011689; batch adversarial loss: 0.430962\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028252; batch adversarial loss: 0.466372\n",
      "epoch 162; iter: 0; batch classifier loss: 0.006739; batch adversarial loss: 0.493038\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032268; batch adversarial loss: 0.504592\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011579; batch adversarial loss: 0.496873\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015852; batch adversarial loss: 0.488765\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035255; batch adversarial loss: 0.453180\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025130; batch adversarial loss: 0.472257\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028177; batch adversarial loss: 0.426112\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013928; batch adversarial loss: 0.456422\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036013; batch adversarial loss: 0.406780\n",
      "epoch 171; iter: 0; batch classifier loss: 0.003664; batch adversarial loss: 0.655637\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024172; batch adversarial loss: 0.476100\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034362; batch adversarial loss: 0.439288\n",
      "epoch 174; iter: 0; batch classifier loss: 0.047297; batch adversarial loss: 0.418733\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017484; batch adversarial loss: 0.503314\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024461; batch adversarial loss: 0.416053\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015011; batch adversarial loss: 0.438650\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021496; batch adversarial loss: 0.573411\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024406; batch adversarial loss: 0.410176\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011942; batch adversarial loss: 0.467716\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014834; batch adversarial loss: 0.542759\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025698; batch adversarial loss: 0.521169\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012056; batch adversarial loss: 0.508862\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022656; batch adversarial loss: 0.383700\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009253; batch adversarial loss: 0.475148\n",
      "epoch 186; iter: 0; batch classifier loss: 0.004658; batch adversarial loss: 0.406061\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015687; batch adversarial loss: 0.464794\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010268; batch adversarial loss: 0.402437\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014986; batch adversarial loss: 0.453821\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029015; batch adversarial loss: 0.554925\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010219; batch adversarial loss: 0.509378\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009791; batch adversarial loss: 0.327871\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023126; batch adversarial loss: 0.390358\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022114; batch adversarial loss: 0.504828\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030155; batch adversarial loss: 0.485358\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015979; batch adversarial loss: 0.579124\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033134; batch adversarial loss: 0.420415\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011333; batch adversarial loss: 0.482829\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016000; batch adversarial loss: 0.373151\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674094; batch adversarial loss: 0.540803\n",
      "epoch 1; iter: 0; batch classifier loss: 0.533842; batch adversarial loss: 0.651820\n",
      "epoch 2; iter: 0; batch classifier loss: 0.457975; batch adversarial loss: 0.587077\n",
      "epoch 3; iter: 0; batch classifier loss: 0.379233; batch adversarial loss: 0.610126\n",
      "epoch 4; iter: 0; batch classifier loss: 0.394481; batch adversarial loss: 0.602449\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387739; batch adversarial loss: 0.571202\n",
      "epoch 6; iter: 0; batch classifier loss: 0.344278; batch adversarial loss: 0.562313\n",
      "epoch 7; iter: 0; batch classifier loss: 0.376840; batch adversarial loss: 0.536096\n",
      "epoch 8; iter: 0; batch classifier loss: 0.375242; batch adversarial loss: 0.586068\n",
      "epoch 9; iter: 0; batch classifier loss: 0.364954; batch adversarial loss: 0.565258\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358293; batch adversarial loss: 0.503875\n",
      "epoch 11; iter: 0; batch classifier loss: 0.437853; batch adversarial loss: 0.518698\n",
      "epoch 12; iter: 0; batch classifier loss: 0.484151; batch adversarial loss: 0.595107\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486156; batch adversarial loss: 0.516597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.547634; batch adversarial loss: 0.441364\n",
      "epoch 15; iter: 0; batch classifier loss: 0.580386; batch adversarial loss: 0.536279\n",
      "epoch 16; iter: 0; batch classifier loss: 0.424152; batch adversarial loss: 0.550475\n",
      "epoch 17; iter: 0; batch classifier loss: 0.325622; batch adversarial loss: 0.490765\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251937; batch adversarial loss: 0.500578\n",
      "epoch 19; iter: 0; batch classifier loss: 0.231490; batch adversarial loss: 0.485735\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222763; batch adversarial loss: 0.507918\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234097; batch adversarial loss: 0.512361\n",
      "epoch 22; iter: 0; batch classifier loss: 0.250320; batch adversarial loss: 0.553681\n",
      "epoch 23; iter: 0; batch classifier loss: 0.234126; batch adversarial loss: 0.373177\n",
      "epoch 24; iter: 0; batch classifier loss: 0.249728; batch adversarial loss: 0.450321\n",
      "epoch 25; iter: 0; batch classifier loss: 0.208765; batch adversarial loss: 0.403022\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187906; batch adversarial loss: 0.421446\n",
      "epoch 27; iter: 0; batch classifier loss: 0.123338; batch adversarial loss: 0.373333\n",
      "epoch 28; iter: 0; batch classifier loss: 0.131923; batch adversarial loss: 0.533775\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179032; batch adversarial loss: 0.405128\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144962; batch adversarial loss: 0.490362\n",
      "epoch 31; iter: 0; batch classifier loss: 0.149573; batch adversarial loss: 0.478070\n",
      "epoch 32; iter: 0; batch classifier loss: 0.134034; batch adversarial loss: 0.494041\n",
      "epoch 33; iter: 0; batch classifier loss: 0.132497; batch adversarial loss: 0.485503\n",
      "epoch 34; iter: 0; batch classifier loss: 0.166790; batch adversarial loss: 0.475260\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151436; batch adversarial loss: 0.451898\n",
      "epoch 36; iter: 0; batch classifier loss: 0.112438; batch adversarial loss: 0.520960\n",
      "epoch 37; iter: 0; batch classifier loss: 0.137741; batch adversarial loss: 0.429992\n",
      "epoch 38; iter: 0; batch classifier loss: 0.133886; batch adversarial loss: 0.425774\n",
      "epoch 39; iter: 0; batch classifier loss: 0.102867; batch adversarial loss: 0.452392\n",
      "epoch 40; iter: 0; batch classifier loss: 0.123620; batch adversarial loss: 0.529989\n",
      "epoch 41; iter: 0; batch classifier loss: 0.157217; batch adversarial loss: 0.438456\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117607; batch adversarial loss: 0.468684\n",
      "epoch 43; iter: 0; batch classifier loss: 0.151898; batch adversarial loss: 0.411678\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123257; batch adversarial loss: 0.433162\n",
      "epoch 45; iter: 0; batch classifier loss: 0.126857; batch adversarial loss: 0.445414\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116054; batch adversarial loss: 0.513506\n",
      "epoch 47; iter: 0; batch classifier loss: 0.155200; batch adversarial loss: 0.498925\n",
      "epoch 48; iter: 0; batch classifier loss: 0.117232; batch adversarial loss: 0.482860\n",
      "epoch 49; iter: 0; batch classifier loss: 0.125945; batch adversarial loss: 0.451524\n",
      "epoch 50; iter: 0; batch classifier loss: 0.127221; batch adversarial loss: 0.423945\n",
      "epoch 51; iter: 0; batch classifier loss: 0.162557; batch adversarial loss: 0.355570\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103659; batch adversarial loss: 0.505987\n",
      "epoch 53; iter: 0; batch classifier loss: 0.087559; batch adversarial loss: 0.435018\n",
      "epoch 54; iter: 0; batch classifier loss: 0.153010; batch adversarial loss: 0.542563\n",
      "epoch 55; iter: 0; batch classifier loss: 0.192217; batch adversarial loss: 0.385105\n",
      "epoch 56; iter: 0; batch classifier loss: 0.165411; batch adversarial loss: 0.453924\n",
      "epoch 57; iter: 0; batch classifier loss: 0.171578; batch adversarial loss: 0.394676\n",
      "epoch 58; iter: 0; batch classifier loss: 0.116412; batch adversarial loss: 0.491885\n",
      "epoch 59; iter: 0; batch classifier loss: 0.103321; batch adversarial loss: 0.410385\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118911; batch adversarial loss: 0.472838\n",
      "epoch 61; iter: 0; batch classifier loss: 0.181132; batch adversarial loss: 0.447223\n",
      "epoch 62; iter: 0; batch classifier loss: 0.158089; batch adversarial loss: 0.457606\n",
      "epoch 63; iter: 0; batch classifier loss: 0.123506; batch adversarial loss: 0.447486\n",
      "epoch 64; iter: 0; batch classifier loss: 0.134691; batch adversarial loss: 0.504801\n",
      "epoch 65; iter: 0; batch classifier loss: 0.198550; batch adversarial loss: 0.540622\n",
      "epoch 66; iter: 0; batch classifier loss: 0.193359; batch adversarial loss: 0.444359\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130227; batch adversarial loss: 0.510108\n",
      "epoch 68; iter: 0; batch classifier loss: 0.120941; batch adversarial loss: 0.428153\n",
      "epoch 69; iter: 0; batch classifier loss: 0.106567; batch adversarial loss: 0.442527\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110326; batch adversarial loss: 0.477003\n",
      "epoch 71; iter: 0; batch classifier loss: 0.138130; batch adversarial loss: 0.493137\n",
      "epoch 72; iter: 0; batch classifier loss: 0.218994; batch adversarial loss: 0.384256\n",
      "epoch 73; iter: 0; batch classifier loss: 0.153392; batch adversarial loss: 0.518859\n",
      "epoch 74; iter: 0; batch classifier loss: 0.126640; batch adversarial loss: 0.419197\n",
      "epoch 75; iter: 0; batch classifier loss: 0.150586; batch adversarial loss: 0.424754\n",
      "epoch 76; iter: 0; batch classifier loss: 0.140586; batch adversarial loss: 0.508439\n",
      "epoch 77; iter: 0; batch classifier loss: 0.138718; batch adversarial loss: 0.409694\n",
      "epoch 78; iter: 0; batch classifier loss: 0.172331; batch adversarial loss: 0.458157\n",
      "epoch 79; iter: 0; batch classifier loss: 0.212039; batch adversarial loss: 0.391908\n",
      "epoch 80; iter: 0; batch classifier loss: 0.168192; batch adversarial loss: 0.357910\n",
      "epoch 81; iter: 0; batch classifier loss: 0.121547; batch adversarial loss: 0.433793\n",
      "epoch 82; iter: 0; batch classifier loss: 0.131360; batch adversarial loss: 0.460899\n",
      "epoch 83; iter: 0; batch classifier loss: 0.168452; batch adversarial loss: 0.442114\n",
      "epoch 84; iter: 0; batch classifier loss: 0.251525; batch adversarial loss: 0.456501\n",
      "epoch 85; iter: 0; batch classifier loss: 0.217694; batch adversarial loss: 0.385073\n",
      "epoch 86; iter: 0; batch classifier loss: 0.133478; batch adversarial loss: 0.451161\n",
      "epoch 87; iter: 0; batch classifier loss: 0.156033; batch adversarial loss: 0.440188\n",
      "epoch 88; iter: 0; batch classifier loss: 0.159757; batch adversarial loss: 0.456436\n",
      "epoch 89; iter: 0; batch classifier loss: 0.101342; batch adversarial loss: 0.431420\n",
      "epoch 90; iter: 0; batch classifier loss: 0.230224; batch adversarial loss: 0.645563\n",
      "epoch 91; iter: 0; batch classifier loss: 0.260386; batch adversarial loss: 0.507391\n",
      "epoch 92; iter: 0; batch classifier loss: 0.217866; batch adversarial loss: 0.445401\n",
      "epoch 93; iter: 0; batch classifier loss: 0.185064; batch adversarial loss: 0.396722\n",
      "epoch 94; iter: 0; batch classifier loss: 0.171576; batch adversarial loss: 0.495779\n",
      "epoch 95; iter: 0; batch classifier loss: 0.192840; batch adversarial loss: 0.507344\n",
      "epoch 96; iter: 0; batch classifier loss: 0.219276; batch adversarial loss: 0.372694\n",
      "epoch 97; iter: 0; batch classifier loss: 0.200607; batch adversarial loss: 0.485477\n",
      "epoch 98; iter: 0; batch classifier loss: 0.154262; batch adversarial loss: 0.470102\n",
      "epoch 99; iter: 0; batch classifier loss: 0.197094; batch adversarial loss: 0.395887\n",
      "epoch 100; iter: 0; batch classifier loss: 0.213913; batch adversarial loss: 0.485523\n",
      "epoch 101; iter: 0; batch classifier loss: 0.180322; batch adversarial loss: 0.410401\n",
      "epoch 102; iter: 0; batch classifier loss: 0.178449; batch adversarial loss: 0.410158\n",
      "epoch 103; iter: 0; batch classifier loss: 0.211972; batch adversarial loss: 0.495770\n",
      "epoch 104; iter: 0; batch classifier loss: 0.170686; batch adversarial loss: 0.558803\n",
      "epoch 105; iter: 0; batch classifier loss: 0.168255; batch adversarial loss: 0.396342\n",
      "epoch 106; iter: 0; batch classifier loss: 0.218258; batch adversarial loss: 0.384618\n",
      "epoch 107; iter: 0; batch classifier loss: 0.164793; batch adversarial loss: 0.483484\n",
      "epoch 108; iter: 0; batch classifier loss: 0.191501; batch adversarial loss: 0.446660\n",
      "epoch 109; iter: 0; batch classifier loss: 0.167474; batch adversarial loss: 0.508421\n",
      "epoch 110; iter: 0; batch classifier loss: 0.190779; batch adversarial loss: 0.471462\n",
      "epoch 111; iter: 0; batch classifier loss: 0.141291; batch adversarial loss: 0.396305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.197162; batch adversarial loss: 0.433673\n",
      "epoch 113; iter: 0; batch classifier loss: 0.119004; batch adversarial loss: 0.434331\n",
      "epoch 114; iter: 0; batch classifier loss: 0.177624; batch adversarial loss: 0.397638\n",
      "epoch 115; iter: 0; batch classifier loss: 0.196767; batch adversarial loss: 0.358978\n",
      "epoch 116; iter: 0; batch classifier loss: 0.167129; batch adversarial loss: 0.445318\n",
      "epoch 117; iter: 0; batch classifier loss: 0.240937; batch adversarial loss: 0.382822\n",
      "epoch 118; iter: 0; batch classifier loss: 0.192968; batch adversarial loss: 0.470603\n",
      "epoch 119; iter: 0; batch classifier loss: 0.208762; batch adversarial loss: 0.482641\n",
      "epoch 120; iter: 0; batch classifier loss: 0.208169; batch adversarial loss: 0.396419\n",
      "epoch 121; iter: 0; batch classifier loss: 0.154508; batch adversarial loss: 0.471721\n",
      "epoch 122; iter: 0; batch classifier loss: 0.177588; batch adversarial loss: 0.421698\n",
      "epoch 123; iter: 0; batch classifier loss: 0.229109; batch adversarial loss: 0.458470\n",
      "epoch 124; iter: 0; batch classifier loss: 0.168225; batch adversarial loss: 0.496131\n",
      "epoch 125; iter: 0; batch classifier loss: 0.179893; batch adversarial loss: 0.446029\n",
      "epoch 126; iter: 0; batch classifier loss: 0.148872; batch adversarial loss: 0.421120\n",
      "epoch 127; iter: 0; batch classifier loss: 0.140898; batch adversarial loss: 0.533378\n",
      "epoch 128; iter: 0; batch classifier loss: 0.189978; batch adversarial loss: 0.446684\n",
      "epoch 129; iter: 0; batch classifier loss: 0.172759; batch adversarial loss: 0.434614\n",
      "epoch 130; iter: 0; batch classifier loss: 0.177503; batch adversarial loss: 0.495541\n",
      "epoch 131; iter: 0; batch classifier loss: 0.258357; batch adversarial loss: 0.434145\n",
      "epoch 132; iter: 0; batch classifier loss: 0.201140; batch adversarial loss: 0.396285\n",
      "epoch 133; iter: 0; batch classifier loss: 0.121808; batch adversarial loss: 0.395918\n",
      "epoch 134; iter: 0; batch classifier loss: 0.215391; batch adversarial loss: 0.534317\n",
      "epoch 135; iter: 0; batch classifier loss: 0.245138; batch adversarial loss: 0.434210\n",
      "epoch 136; iter: 0; batch classifier loss: 0.187556; batch adversarial loss: 0.421446\n",
      "epoch 137; iter: 0; batch classifier loss: 0.174759; batch adversarial loss: 0.496450\n",
      "epoch 138; iter: 0; batch classifier loss: 0.147119; batch adversarial loss: 0.445990\n",
      "epoch 139; iter: 0; batch classifier loss: 0.166397; batch adversarial loss: 0.433574\n",
      "epoch 140; iter: 0; batch classifier loss: 0.147104; batch adversarial loss: 0.533768\n",
      "epoch 141; iter: 0; batch classifier loss: 0.205679; batch adversarial loss: 0.420317\n",
      "epoch 142; iter: 0; batch classifier loss: 0.170710; batch adversarial loss: 0.508534\n",
      "epoch 143; iter: 0; batch classifier loss: 0.112446; batch adversarial loss: 0.447360\n",
      "epoch 144; iter: 0; batch classifier loss: 0.208871; batch adversarial loss: 0.470746\n",
      "epoch 145; iter: 0; batch classifier loss: 0.132537; batch adversarial loss: 0.421666\n",
      "epoch 146; iter: 0; batch classifier loss: 0.152624; batch adversarial loss: 0.496440\n",
      "epoch 147; iter: 0; batch classifier loss: 0.188288; batch adversarial loss: 0.483685\n",
      "epoch 148; iter: 0; batch classifier loss: 0.187280; batch adversarial loss: 0.521332\n",
      "epoch 149; iter: 0; batch classifier loss: 0.246850; batch adversarial loss: 0.483513\n",
      "epoch 150; iter: 0; batch classifier loss: 0.147162; batch adversarial loss: 0.596005\n",
      "epoch 151; iter: 0; batch classifier loss: 0.169226; batch adversarial loss: 0.396887\n",
      "epoch 152; iter: 0; batch classifier loss: 0.175183; batch adversarial loss: 0.421859\n",
      "epoch 153; iter: 0; batch classifier loss: 0.208146; batch adversarial loss: 0.595725\n",
      "epoch 154; iter: 0; batch classifier loss: 0.135895; batch adversarial loss: 0.571109\n",
      "epoch 155; iter: 0; batch classifier loss: 0.158408; batch adversarial loss: 0.458629\n",
      "epoch 156; iter: 0; batch classifier loss: 0.204277; batch adversarial loss: 0.409172\n",
      "epoch 157; iter: 0; batch classifier loss: 0.153599; batch adversarial loss: 0.421435\n",
      "epoch 158; iter: 0; batch classifier loss: 0.179632; batch adversarial loss: 0.484124\n",
      "epoch 159; iter: 0; batch classifier loss: 0.200394; batch adversarial loss: 0.433727\n",
      "epoch 160; iter: 0; batch classifier loss: 0.171653; batch adversarial loss: 0.497061\n",
      "epoch 161; iter: 0; batch classifier loss: 0.126984; batch adversarial loss: 0.483250\n",
      "epoch 162; iter: 0; batch classifier loss: 0.191918; batch adversarial loss: 0.471112\n",
      "epoch 163; iter: 0; batch classifier loss: 0.208098; batch adversarial loss: 0.420504\n",
      "epoch 164; iter: 0; batch classifier loss: 0.208924; batch adversarial loss: 0.397096\n",
      "epoch 165; iter: 0; batch classifier loss: 0.131016; batch adversarial loss: 0.521514\n",
      "epoch 166; iter: 0; batch classifier loss: 0.177998; batch adversarial loss: 0.396938\n",
      "epoch 167; iter: 0; batch classifier loss: 0.149454; batch adversarial loss: 0.483414\n",
      "epoch 168; iter: 0; batch classifier loss: 0.126161; batch adversarial loss: 0.483755\n",
      "epoch 169; iter: 0; batch classifier loss: 0.144128; batch adversarial loss: 0.458154\n",
      "epoch 170; iter: 0; batch classifier loss: 0.162453; batch adversarial loss: 0.497249\n",
      "epoch 171; iter: 0; batch classifier loss: 0.123679; batch adversarial loss: 0.521113\n",
      "epoch 172; iter: 0; batch classifier loss: 0.163915; batch adversarial loss: 0.444662\n",
      "epoch 173; iter: 0; batch classifier loss: 0.187103; batch adversarial loss: 0.433143\n",
      "epoch 174; iter: 0; batch classifier loss: 0.139300; batch adversarial loss: 0.458459\n",
      "epoch 175; iter: 0; batch classifier loss: 0.121364; batch adversarial loss: 0.483730\n",
      "epoch 176; iter: 0; batch classifier loss: 0.092849; batch adversarial loss: 0.500875\n",
      "epoch 177; iter: 0; batch classifier loss: 0.133036; batch adversarial loss: 0.407855\n",
      "epoch 178; iter: 0; batch classifier loss: 0.114031; batch adversarial loss: 0.429514\n",
      "epoch 179; iter: 0; batch classifier loss: 0.061195; batch adversarial loss: 0.476356\n",
      "epoch 180; iter: 0; batch classifier loss: 0.074946; batch adversarial loss: 0.382027\n",
      "epoch 181; iter: 0; batch classifier loss: 0.067307; batch adversarial loss: 0.429897\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028979; batch adversarial loss: 0.481648\n",
      "epoch 183; iter: 0; batch classifier loss: 0.043212; batch adversarial loss: 0.424883\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040593; batch adversarial loss: 0.566167\n",
      "epoch 185; iter: 0; batch classifier loss: 0.075450; batch adversarial loss: 0.397365\n",
      "epoch 186; iter: 0; batch classifier loss: 0.042662; batch adversarial loss: 0.377180\n",
      "epoch 187; iter: 0; batch classifier loss: 0.043239; batch adversarial loss: 0.402945\n",
      "epoch 188; iter: 0; batch classifier loss: 0.052331; batch adversarial loss: 0.472074\n",
      "epoch 189; iter: 0; batch classifier loss: 0.047211; batch adversarial loss: 0.414783\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021169; batch adversarial loss: 0.474577\n",
      "epoch 191; iter: 0; batch classifier loss: 0.052701; batch adversarial loss: 0.480768\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019498; batch adversarial loss: 0.505845\n",
      "epoch 193; iter: 0; batch classifier loss: 0.033258; batch adversarial loss: 0.393271\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030753; batch adversarial loss: 0.426134\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034319; batch adversarial loss: 0.411580\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032950; batch adversarial loss: 0.453185\n",
      "epoch 197; iter: 0; batch classifier loss: 0.058697; batch adversarial loss: 0.404568\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018508; batch adversarial loss: 0.457802\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026723; batch adversarial loss: 0.521034\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717237; batch adversarial loss: 0.724020\n",
      "epoch 1; iter: 0; batch classifier loss: 0.507585; batch adversarial loss: 0.664648\n",
      "epoch 2; iter: 0; batch classifier loss: 0.438444; batch adversarial loss: 0.630545\n",
      "epoch 3; iter: 0; batch classifier loss: 0.414475; batch adversarial loss: 0.619973\n",
      "epoch 4; iter: 0; batch classifier loss: 0.454843; batch adversarial loss: 0.621109\n",
      "epoch 5; iter: 0; batch classifier loss: 0.470581; batch adversarial loss: 0.581267\n",
      "epoch 6; iter: 0; batch classifier loss: 0.354813; batch adversarial loss: 0.581576\n",
      "epoch 7; iter: 0; batch classifier loss: 0.361028; batch adversarial loss: 0.545780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.383810; batch adversarial loss: 0.539061\n",
      "epoch 9; iter: 0; batch classifier loss: 0.345026; batch adversarial loss: 0.570588\n",
      "epoch 10; iter: 0; batch classifier loss: 0.370465; batch adversarial loss: 0.568133\n",
      "epoch 11; iter: 0; batch classifier loss: 0.276999; batch adversarial loss: 0.580089\n",
      "epoch 12; iter: 0; batch classifier loss: 0.325584; batch adversarial loss: 0.530625\n",
      "epoch 13; iter: 0; batch classifier loss: 0.367677; batch adversarial loss: 0.498547\n",
      "epoch 14; iter: 0; batch classifier loss: 0.411112; batch adversarial loss: 0.492011\n",
      "epoch 15; iter: 0; batch classifier loss: 0.297401; batch adversarial loss: 0.485476\n",
      "epoch 16; iter: 0; batch classifier loss: 0.326505; batch adversarial loss: 0.470144\n",
      "epoch 17; iter: 0; batch classifier loss: 0.332824; batch adversarial loss: 0.556683\n",
      "epoch 18; iter: 0; batch classifier loss: 0.348407; batch adversarial loss: 0.537676\n",
      "epoch 19; iter: 0; batch classifier loss: 0.305304; batch adversarial loss: 0.445729\n",
      "epoch 20; iter: 0; batch classifier loss: 0.311062; batch adversarial loss: 0.535568\n",
      "epoch 21; iter: 0; batch classifier loss: 0.294200; batch adversarial loss: 0.519997\n",
      "epoch 22; iter: 0; batch classifier loss: 0.293885; batch adversarial loss: 0.501512\n",
      "epoch 23; iter: 0; batch classifier loss: 0.297568; batch adversarial loss: 0.431790\n",
      "epoch 24; iter: 0; batch classifier loss: 0.267917; batch adversarial loss: 0.477310\n",
      "epoch 25; iter: 0; batch classifier loss: 0.320454; batch adversarial loss: 0.429940\n",
      "epoch 26; iter: 0; batch classifier loss: 0.238429; batch adversarial loss: 0.432872\n",
      "epoch 27; iter: 0; batch classifier loss: 0.207446; batch adversarial loss: 0.409726\n",
      "epoch 28; iter: 0; batch classifier loss: 0.265635; batch adversarial loss: 0.502716\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220297; batch adversarial loss: 0.377647\n",
      "epoch 30; iter: 0; batch classifier loss: 0.234025; batch adversarial loss: 0.492787\n",
      "epoch 31; iter: 0; batch classifier loss: 0.212632; batch adversarial loss: 0.518724\n",
      "epoch 32; iter: 0; batch classifier loss: 0.190863; batch adversarial loss: 0.504793\n",
      "epoch 33; iter: 0; batch classifier loss: 0.234461; batch adversarial loss: 0.453346\n",
      "epoch 34; iter: 0; batch classifier loss: 0.209170; batch adversarial loss: 0.510961\n",
      "epoch 35; iter: 0; batch classifier loss: 0.224609; batch adversarial loss: 0.483262\n",
      "epoch 36; iter: 0; batch classifier loss: 0.258945; batch adversarial loss: 0.434207\n",
      "epoch 37; iter: 0; batch classifier loss: 0.226778; batch adversarial loss: 0.492723\n",
      "epoch 38; iter: 0; batch classifier loss: 0.199525; batch adversarial loss: 0.481541\n",
      "epoch 39; iter: 0; batch classifier loss: 0.284063; batch adversarial loss: 0.510173\n",
      "epoch 40; iter: 0; batch classifier loss: 0.277841; batch adversarial loss: 0.450619\n",
      "epoch 41; iter: 0; batch classifier loss: 0.243923; batch adversarial loss: 0.403670\n",
      "epoch 42; iter: 0; batch classifier loss: 0.255349; batch adversarial loss: 0.493475\n",
      "epoch 43; iter: 0; batch classifier loss: 0.212702; batch adversarial loss: 0.472909\n",
      "epoch 44; iter: 0; batch classifier loss: 0.222173; batch adversarial loss: 0.495145\n",
      "epoch 45; iter: 0; batch classifier loss: 0.234208; batch adversarial loss: 0.412866\n",
      "epoch 46; iter: 0; batch classifier loss: 0.152130; batch adversarial loss: 0.470899\n",
      "epoch 47; iter: 0; batch classifier loss: 0.127146; batch adversarial loss: 0.529828\n",
      "epoch 48; iter: 0; batch classifier loss: 0.131006; batch adversarial loss: 0.577354\n",
      "epoch 49; iter: 0; batch classifier loss: 0.219998; batch adversarial loss: 0.410383\n",
      "epoch 50; iter: 0; batch classifier loss: 0.169737; batch adversarial loss: 0.459992\n",
      "epoch 51; iter: 0; batch classifier loss: 0.205140; batch adversarial loss: 0.470456\n",
      "epoch 52; iter: 0; batch classifier loss: 0.229898; batch adversarial loss: 0.410843\n",
      "epoch 53; iter: 0; batch classifier loss: 0.127316; batch adversarial loss: 0.433979\n",
      "epoch 54; iter: 0; batch classifier loss: 0.100035; batch adversarial loss: 0.594711\n",
      "epoch 55; iter: 0; batch classifier loss: 0.233776; batch adversarial loss: 0.436999\n",
      "epoch 56; iter: 0; batch classifier loss: 0.146304; batch adversarial loss: 0.471668\n",
      "epoch 57; iter: 0; batch classifier loss: 0.264431; batch adversarial loss: 0.411951\n",
      "epoch 58; iter: 0; batch classifier loss: 0.187202; batch adversarial loss: 0.483913\n",
      "epoch 59; iter: 0; batch classifier loss: 0.117988; batch adversarial loss: 0.459085\n",
      "epoch 60; iter: 0; batch classifier loss: 0.110808; batch adversarial loss: 0.433996\n",
      "epoch 61; iter: 0; batch classifier loss: 0.202068; batch adversarial loss: 0.494879\n",
      "epoch 62; iter: 0; batch classifier loss: 0.134466; batch adversarial loss: 0.505620\n",
      "epoch 63; iter: 0; batch classifier loss: 0.175735; batch adversarial loss: 0.420421\n",
      "epoch 64; iter: 0; batch classifier loss: 0.183304; batch adversarial loss: 0.385968\n",
      "epoch 65; iter: 0; batch classifier loss: 0.120201; batch adversarial loss: 0.520370\n",
      "epoch 66; iter: 0; batch classifier loss: 0.121389; batch adversarial loss: 0.458068\n",
      "epoch 67; iter: 0; batch classifier loss: 0.124205; batch adversarial loss: 0.397436\n",
      "epoch 68; iter: 0; batch classifier loss: 0.232267; batch adversarial loss: 0.421321\n",
      "epoch 69; iter: 0; batch classifier loss: 0.192666; batch adversarial loss: 0.384914\n",
      "epoch 70; iter: 0; batch classifier loss: 0.203363; batch adversarial loss: 0.496284\n",
      "epoch 71; iter: 0; batch classifier loss: 0.182817; batch adversarial loss: 0.409847\n",
      "epoch 72; iter: 0; batch classifier loss: 0.193667; batch adversarial loss: 0.434373\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101068; batch adversarial loss: 0.446217\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064046; batch adversarial loss: 0.407217\n",
      "epoch 75; iter: 0; batch classifier loss: 0.050328; batch adversarial loss: 0.496761\n",
      "epoch 76; iter: 0; batch classifier loss: 0.115176; batch adversarial loss: 0.393562\n",
      "epoch 77; iter: 0; batch classifier loss: 0.040635; batch adversarial loss: 0.413199\n",
      "epoch 78; iter: 0; batch classifier loss: 0.041711; batch adversarial loss: 0.496719\n",
      "epoch 79; iter: 0; batch classifier loss: 0.086808; batch adversarial loss: 0.492859\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075141; batch adversarial loss: 0.458058\n",
      "epoch 81; iter: 0; batch classifier loss: 0.044556; batch adversarial loss: 0.426007\n",
      "epoch 82; iter: 0; batch classifier loss: 0.070246; batch adversarial loss: 0.513677\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056279; batch adversarial loss: 0.437811\n",
      "epoch 84; iter: 0; batch classifier loss: 0.044472; batch adversarial loss: 0.433343\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065519; batch adversarial loss: 0.441616\n",
      "epoch 86; iter: 0; batch classifier loss: 0.099189; batch adversarial loss: 0.473076\n",
      "epoch 87; iter: 0; batch classifier loss: 0.084399; batch adversarial loss: 0.441570\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069678; batch adversarial loss: 0.454047\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068770; batch adversarial loss: 0.456954\n",
      "epoch 90; iter: 0; batch classifier loss: 0.080679; batch adversarial loss: 0.391519\n",
      "epoch 91; iter: 0; batch classifier loss: 0.101591; batch adversarial loss: 0.509877\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064248; batch adversarial loss: 0.505786\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064581; batch adversarial loss: 0.511172\n",
      "epoch 94; iter: 0; batch classifier loss: 0.110013; batch adversarial loss: 0.495230\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051766; batch adversarial loss: 0.443691\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041745; batch adversarial loss: 0.390311\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076435; batch adversarial loss: 0.422714\n",
      "epoch 98; iter: 0; batch classifier loss: 0.071661; batch adversarial loss: 0.507919\n",
      "epoch 99; iter: 0; batch classifier loss: 0.087872; batch adversarial loss: 0.366833\n",
      "epoch 100; iter: 0; batch classifier loss: 0.073580; batch adversarial loss: 0.420745\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061249; batch adversarial loss: 0.484988\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054497; batch adversarial loss: 0.487560\n",
      "epoch 103; iter: 0; batch classifier loss: 0.067910; batch adversarial loss: 0.463133\n",
      "epoch 104; iter: 0; batch classifier loss: 0.084932; batch adversarial loss: 0.516255\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041848; batch adversarial loss: 0.481249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.093778; batch adversarial loss: 0.511377\n",
      "epoch 107; iter: 0; batch classifier loss: 0.042319; batch adversarial loss: 0.418909\n",
      "epoch 108; iter: 0; batch classifier loss: 0.095647; batch adversarial loss: 0.451470\n",
      "epoch 109; iter: 0; batch classifier loss: 0.078934; batch adversarial loss: 0.494871\n",
      "epoch 110; iter: 0; batch classifier loss: 0.086220; batch adversarial loss: 0.343655\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050616; batch adversarial loss: 0.440695\n",
      "epoch 112; iter: 0; batch classifier loss: 0.058236; batch adversarial loss: 0.428156\n",
      "epoch 113; iter: 0; batch classifier loss: 0.077891; batch adversarial loss: 0.502648\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044016; batch adversarial loss: 0.378001\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062120; batch adversarial loss: 0.439689\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068849; batch adversarial loss: 0.419074\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067430; batch adversarial loss: 0.476442\n",
      "epoch 118; iter: 0; batch classifier loss: 0.076304; batch adversarial loss: 0.474770\n",
      "epoch 119; iter: 0; batch classifier loss: 0.064756; batch adversarial loss: 0.562541\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074140; batch adversarial loss: 0.404992\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046054; batch adversarial loss: 0.451995\n",
      "epoch 122; iter: 0; batch classifier loss: 0.071905; batch adversarial loss: 0.390873\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055854; batch adversarial loss: 0.621280\n",
      "epoch 124; iter: 0; batch classifier loss: 0.061892; batch adversarial loss: 0.439109\n",
      "epoch 125; iter: 0; batch classifier loss: 0.070079; batch adversarial loss: 0.353114\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044910; batch adversarial loss: 0.394041\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035407; batch adversarial loss: 0.388997\n",
      "epoch 128; iter: 0; batch classifier loss: 0.069469; batch adversarial loss: 0.370064\n",
      "epoch 129; iter: 0; batch classifier loss: 0.074815; batch adversarial loss: 0.376173\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059862; batch adversarial loss: 0.412296\n",
      "epoch 131; iter: 0; batch classifier loss: 0.056840; batch adversarial loss: 0.441915\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049599; batch adversarial loss: 0.408042\n",
      "epoch 133; iter: 0; batch classifier loss: 0.076437; batch adversarial loss: 0.450874\n",
      "epoch 134; iter: 0; batch classifier loss: 0.081527; batch adversarial loss: 0.419157\n",
      "epoch 135; iter: 0; batch classifier loss: 0.062184; batch adversarial loss: 0.478063\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056201; batch adversarial loss: 0.449464\n",
      "epoch 137; iter: 0; batch classifier loss: 0.057858; batch adversarial loss: 0.383163\n",
      "epoch 138; iter: 0; batch classifier loss: 0.043150; batch adversarial loss: 0.384866\n",
      "epoch 139; iter: 0; batch classifier loss: 0.060945; batch adversarial loss: 0.395539\n",
      "epoch 140; iter: 0; batch classifier loss: 0.066157; batch adversarial loss: 0.487118\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043190; batch adversarial loss: 0.472775\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041034; batch adversarial loss: 0.409742\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036099; batch adversarial loss: 0.394194\n",
      "epoch 144; iter: 0; batch classifier loss: 0.051043; batch adversarial loss: 0.491592\n",
      "epoch 145; iter: 0; batch classifier loss: 0.086532; batch adversarial loss: 0.493301\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051743; batch adversarial loss: 0.430151\n",
      "epoch 147; iter: 0; batch classifier loss: 0.049287; batch adversarial loss: 0.451964\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049606; batch adversarial loss: 0.427583\n",
      "epoch 149; iter: 0; batch classifier loss: 0.083618; batch adversarial loss: 0.447795\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054167; batch adversarial loss: 0.505317\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039864; batch adversarial loss: 0.415275\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040060; batch adversarial loss: 0.352854\n",
      "epoch 153; iter: 0; batch classifier loss: 0.050880; batch adversarial loss: 0.372782\n",
      "epoch 154; iter: 0; batch classifier loss: 0.042354; batch adversarial loss: 0.420507\n",
      "epoch 155; iter: 0; batch classifier loss: 0.060609; batch adversarial loss: 0.452329\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024663; batch adversarial loss: 0.421450\n",
      "epoch 157; iter: 0; batch classifier loss: 0.068219; batch adversarial loss: 0.469987\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048121; batch adversarial loss: 0.373792\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036269; batch adversarial loss: 0.407639\n",
      "epoch 160; iter: 0; batch classifier loss: 0.060478; batch adversarial loss: 0.506736\n",
      "epoch 161; iter: 0; batch classifier loss: 0.098951; batch adversarial loss: 0.450708\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029317; batch adversarial loss: 0.477974\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042596; batch adversarial loss: 0.471945\n",
      "epoch 164; iter: 0; batch classifier loss: 0.069423; batch adversarial loss: 0.395439\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021706; batch adversarial loss: 0.471130\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034234; batch adversarial loss: 0.426587\n",
      "epoch 167; iter: 0; batch classifier loss: 0.046066; batch adversarial loss: 0.360107\n",
      "epoch 168; iter: 0; batch classifier loss: 0.060638; batch adversarial loss: 0.395159\n",
      "epoch 169; iter: 0; batch classifier loss: 0.053655; batch adversarial loss: 0.335280\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018036; batch adversarial loss: 0.359903\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027266; batch adversarial loss: 0.435503\n",
      "epoch 172; iter: 0; batch classifier loss: 0.059324; batch adversarial loss: 0.364550\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028770; batch adversarial loss: 0.372518\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019725; batch adversarial loss: 0.479620\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036721; batch adversarial loss: 0.365614\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039508; batch adversarial loss: 0.436054\n",
      "epoch 177; iter: 0; batch classifier loss: 0.035997; batch adversarial loss: 0.395854\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024819; batch adversarial loss: 0.534033\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013742; batch adversarial loss: 0.411335\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019650; batch adversarial loss: 0.443378\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034172; batch adversarial loss: 0.438836\n",
      "epoch 182; iter: 0; batch classifier loss: 0.035346; batch adversarial loss: 0.411650\n",
      "epoch 183; iter: 0; batch classifier loss: 0.044697; batch adversarial loss: 0.418774\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040148; batch adversarial loss: 0.371804\n",
      "epoch 185; iter: 0; batch classifier loss: 0.030886; batch adversarial loss: 0.424054\n",
      "epoch 186; iter: 0; batch classifier loss: 0.038738; batch adversarial loss: 0.393569\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020849; batch adversarial loss: 0.429288\n",
      "epoch 188; iter: 0; batch classifier loss: 0.036403; batch adversarial loss: 0.512093\n",
      "epoch 189; iter: 0; batch classifier loss: 0.057398; batch adversarial loss: 0.474901\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027720; batch adversarial loss: 0.468717\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019146; batch adversarial loss: 0.455793\n",
      "epoch 192; iter: 0; batch classifier loss: 0.047903; batch adversarial loss: 0.382770\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020060; batch adversarial loss: 0.430641\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022595; batch adversarial loss: 0.425475\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031202; batch adversarial loss: 0.436438\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028896; batch adversarial loss: 0.409225\n",
      "epoch 197; iter: 0; batch classifier loss: 0.030324; batch adversarial loss: 0.367268\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019103; batch adversarial loss: 0.383082\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026689; batch adversarial loss: 0.338241\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717218; batch adversarial loss: 0.923247\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556881; batch adversarial loss: 0.851175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.708857; batch adversarial loss: 0.870191\n",
      "epoch 3; iter: 0; batch classifier loss: 0.846328; batch adversarial loss: 0.797289\n",
      "epoch 4; iter: 0; batch classifier loss: 0.979974; batch adversarial loss: 0.725138\n",
      "epoch 5; iter: 0; batch classifier loss: 0.805290; batch adversarial loss: 0.675284\n",
      "epoch 6; iter: 0; batch classifier loss: 0.836435; batch adversarial loss: 0.592328\n",
      "epoch 7; iter: 0; batch classifier loss: 0.436994; batch adversarial loss: 0.589724\n",
      "epoch 8; iter: 0; batch classifier loss: 0.372065; batch adversarial loss: 0.566795\n",
      "epoch 9; iter: 0; batch classifier loss: 0.347448; batch adversarial loss: 0.519167\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386512; batch adversarial loss: 0.528462\n",
      "epoch 11; iter: 0; batch classifier loss: 0.306957; batch adversarial loss: 0.531351\n",
      "epoch 12; iter: 0; batch classifier loss: 0.376232; batch adversarial loss: 0.518403\n",
      "epoch 13; iter: 0; batch classifier loss: 0.333552; batch adversarial loss: 0.493838\n",
      "epoch 14; iter: 0; batch classifier loss: 0.349827; batch adversarial loss: 0.522609\n",
      "epoch 15; iter: 0; batch classifier loss: 0.279903; batch adversarial loss: 0.493822\n",
      "epoch 16; iter: 0; batch classifier loss: 0.361370; batch adversarial loss: 0.530328\n",
      "epoch 17; iter: 0; batch classifier loss: 0.281292; batch adversarial loss: 0.474930\n",
      "epoch 18; iter: 0; batch classifier loss: 0.318545; batch adversarial loss: 0.480067\n",
      "epoch 19; iter: 0; batch classifier loss: 0.327192; batch adversarial loss: 0.484707\n",
      "epoch 20; iter: 0; batch classifier loss: 0.289126; batch adversarial loss: 0.480415\n",
      "epoch 21; iter: 0; batch classifier loss: 0.323970; batch adversarial loss: 0.523389\n",
      "epoch 22; iter: 0; batch classifier loss: 0.299052; batch adversarial loss: 0.532134\n",
      "epoch 23; iter: 0; batch classifier loss: 0.332183; batch adversarial loss: 0.437495\n",
      "epoch 24; iter: 0; batch classifier loss: 0.256780; batch adversarial loss: 0.516162\n",
      "epoch 25; iter: 0; batch classifier loss: 0.355368; batch adversarial loss: 0.441719\n",
      "epoch 26; iter: 0; batch classifier loss: 0.250907; batch adversarial loss: 0.372195\n",
      "epoch 27; iter: 0; batch classifier loss: 0.278060; batch adversarial loss: 0.427980\n",
      "epoch 28; iter: 0; batch classifier loss: 0.193264; batch adversarial loss: 0.475003\n",
      "epoch 29; iter: 0; batch classifier loss: 0.295219; batch adversarial loss: 0.481020\n",
      "epoch 30; iter: 0; batch classifier loss: 0.265892; batch adversarial loss: 0.473597\n",
      "epoch 31; iter: 0; batch classifier loss: 0.254178; batch adversarial loss: 0.447313\n",
      "epoch 32; iter: 0; batch classifier loss: 0.237256; batch adversarial loss: 0.430436\n",
      "epoch 33; iter: 0; batch classifier loss: 0.268909; batch adversarial loss: 0.488876\n",
      "epoch 34; iter: 0; batch classifier loss: 0.237358; batch adversarial loss: 0.460813\n",
      "epoch 35; iter: 0; batch classifier loss: 0.263815; batch adversarial loss: 0.424385\n",
      "epoch 36; iter: 0; batch classifier loss: 0.276961; batch adversarial loss: 0.466362\n",
      "epoch 37; iter: 0; batch classifier loss: 0.202945; batch adversarial loss: 0.426753\n",
      "epoch 38; iter: 0; batch classifier loss: 0.207131; batch adversarial loss: 0.398802\n",
      "epoch 39; iter: 0; batch classifier loss: 0.182195; batch adversarial loss: 0.484191\n",
      "epoch 40; iter: 0; batch classifier loss: 0.193463; batch adversarial loss: 0.473010\n",
      "epoch 41; iter: 0; batch classifier loss: 0.188271; batch adversarial loss: 0.542101\n",
      "epoch 42; iter: 0; batch classifier loss: 0.221137; batch adversarial loss: 0.364561\n",
      "epoch 43; iter: 0; batch classifier loss: 0.172631; batch adversarial loss: 0.430701\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119406; batch adversarial loss: 0.416740\n",
      "epoch 45; iter: 0; batch classifier loss: 0.176352; batch adversarial loss: 0.370241\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114762; batch adversarial loss: 0.539540\n",
      "epoch 47; iter: 0; batch classifier loss: 0.111011; batch adversarial loss: 0.463193\n",
      "epoch 48; iter: 0; batch classifier loss: 0.143075; batch adversarial loss: 0.414414\n",
      "epoch 49; iter: 0; batch classifier loss: 0.131692; batch adversarial loss: 0.527936\n",
      "epoch 50; iter: 0; batch classifier loss: 0.131452; batch adversarial loss: 0.442267\n",
      "epoch 51; iter: 0; batch classifier loss: 0.101492; batch adversarial loss: 0.433255\n",
      "epoch 52; iter: 0; batch classifier loss: 0.122409; batch adversarial loss: 0.519470\n",
      "epoch 53; iter: 0; batch classifier loss: 0.161663; batch adversarial loss: 0.398378\n",
      "epoch 54; iter: 0; batch classifier loss: 0.107395; batch adversarial loss: 0.609368\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101022; batch adversarial loss: 0.402237\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099958; batch adversarial loss: 0.454414\n",
      "epoch 57; iter: 0; batch classifier loss: 0.096168; batch adversarial loss: 0.435792\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093881; batch adversarial loss: 0.425408\n",
      "epoch 59; iter: 0; batch classifier loss: 0.091285; batch adversarial loss: 0.426344\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097034; batch adversarial loss: 0.405277\n",
      "epoch 61; iter: 0; batch classifier loss: 0.148070; batch adversarial loss: 0.438931\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089640; batch adversarial loss: 0.406245\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079852; batch adversarial loss: 0.498493\n",
      "epoch 64; iter: 0; batch classifier loss: 0.069167; batch adversarial loss: 0.427892\n",
      "epoch 65; iter: 0; batch classifier loss: 0.060899; batch adversarial loss: 0.513472\n",
      "epoch 66; iter: 0; batch classifier loss: 0.064007; batch adversarial loss: 0.369505\n",
      "epoch 67; iter: 0; batch classifier loss: 0.081616; batch adversarial loss: 0.521991\n",
      "epoch 68; iter: 0; batch classifier loss: 0.099224; batch adversarial loss: 0.447334\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081405; batch adversarial loss: 0.363986\n",
      "epoch 70; iter: 0; batch classifier loss: 0.055244; batch adversarial loss: 0.429935\n",
      "epoch 71; iter: 0; batch classifier loss: 0.094118; batch adversarial loss: 0.455157\n",
      "epoch 72; iter: 0; batch classifier loss: 0.053641; batch adversarial loss: 0.419612\n",
      "epoch 73; iter: 0; batch classifier loss: 0.073583; batch adversarial loss: 0.444218\n",
      "epoch 74; iter: 0; batch classifier loss: 0.096104; batch adversarial loss: 0.525956\n",
      "epoch 75; iter: 0; batch classifier loss: 0.064911; batch adversarial loss: 0.446577\n",
      "epoch 76; iter: 0; batch classifier loss: 0.098291; batch adversarial loss: 0.464480\n",
      "epoch 77; iter: 0; batch classifier loss: 0.052990; batch adversarial loss: 0.440864\n",
      "epoch 78; iter: 0; batch classifier loss: 0.067954; batch adversarial loss: 0.455495\n",
      "epoch 79; iter: 0; batch classifier loss: 0.047929; batch adversarial loss: 0.629608\n",
      "epoch 80; iter: 0; batch classifier loss: 0.032603; batch adversarial loss: 0.439823\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073208; batch adversarial loss: 0.331294\n",
      "epoch 82; iter: 0; batch classifier loss: 0.069530; batch adversarial loss: 0.383485\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054403; batch adversarial loss: 0.463498\n",
      "epoch 84; iter: 0; batch classifier loss: 0.081650; batch adversarial loss: 0.433459\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060238; batch adversarial loss: 0.440317\n",
      "epoch 86; iter: 0; batch classifier loss: 0.041160; batch adversarial loss: 0.447336\n",
      "epoch 87; iter: 0; batch classifier loss: 0.051254; batch adversarial loss: 0.398641\n",
      "epoch 88; iter: 0; batch classifier loss: 0.037063; batch adversarial loss: 0.483574\n",
      "epoch 89; iter: 0; batch classifier loss: 0.041326; batch adversarial loss: 0.431648\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045894; batch adversarial loss: 0.416087\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052912; batch adversarial loss: 0.556884\n",
      "epoch 92; iter: 0; batch classifier loss: 0.056050; batch adversarial loss: 0.496054\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047642; batch adversarial loss: 0.407766\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058371; batch adversarial loss: 0.371968\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044258; batch adversarial loss: 0.497159\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065503; batch adversarial loss: 0.517140\n",
      "epoch 97; iter: 0; batch classifier loss: 0.058786; batch adversarial loss: 0.506816\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050193; batch adversarial loss: 0.491960\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038797; batch adversarial loss: 0.536057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.066561; batch adversarial loss: 0.517954\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041900; batch adversarial loss: 0.442362\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046451; batch adversarial loss: 0.332756\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063616; batch adversarial loss: 0.445605\n",
      "epoch 104; iter: 0; batch classifier loss: 0.032729; batch adversarial loss: 0.284156\n",
      "epoch 105; iter: 0; batch classifier loss: 0.072159; batch adversarial loss: 0.406703\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047520; batch adversarial loss: 0.481820\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039967; batch adversarial loss: 0.422390\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067413; batch adversarial loss: 0.344254\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032964; batch adversarial loss: 0.453900\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025047; batch adversarial loss: 0.467414\n",
      "epoch 111; iter: 0; batch classifier loss: 0.023454; batch adversarial loss: 0.385439\n",
      "epoch 112; iter: 0; batch classifier loss: 0.022380; batch adversarial loss: 0.474234\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027499; batch adversarial loss: 0.441279\n",
      "epoch 114; iter: 0; batch classifier loss: 0.022716; batch adversarial loss: 0.525186\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042697; batch adversarial loss: 0.515246\n",
      "epoch 116; iter: 0; batch classifier loss: 0.020016; batch adversarial loss: 0.448586\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025323; batch adversarial loss: 0.500853\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043174; batch adversarial loss: 0.363885\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026615; batch adversarial loss: 0.458921\n",
      "epoch 120; iter: 0; batch classifier loss: 0.023402; batch adversarial loss: 0.524168\n",
      "epoch 121; iter: 0; batch classifier loss: 0.015320; batch adversarial loss: 0.581752\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045661; batch adversarial loss: 0.510604\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033037; batch adversarial loss: 0.521949\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022558; batch adversarial loss: 0.517018\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033476; batch adversarial loss: 0.473066\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027264; batch adversarial loss: 0.450846\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050987; batch adversarial loss: 0.402893\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027519; batch adversarial loss: 0.413115\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020272; batch adversarial loss: 0.444128\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030046; batch adversarial loss: 0.448062\n",
      "epoch 131; iter: 0; batch classifier loss: 0.016366; batch adversarial loss: 0.429684\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046323; batch adversarial loss: 0.375133\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036876; batch adversarial loss: 0.410899\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040685; batch adversarial loss: 0.516106\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028975; batch adversarial loss: 0.488671\n",
      "epoch 136; iter: 0; batch classifier loss: 0.045011; batch adversarial loss: 0.449795\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012950; batch adversarial loss: 0.531307\n",
      "epoch 138; iter: 0; batch classifier loss: 0.012200; batch adversarial loss: 0.427372\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018547; batch adversarial loss: 0.360229\n",
      "epoch 140; iter: 0; batch classifier loss: 0.009514; batch adversarial loss: 0.430143\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025634; batch adversarial loss: 0.464980\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014432; batch adversarial loss: 0.511449\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041254; batch adversarial loss: 0.585928\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024888; batch adversarial loss: 0.522149\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020891; batch adversarial loss: 0.438845\n",
      "epoch 146; iter: 0; batch classifier loss: 0.007626; batch adversarial loss: 0.426524\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014644; batch adversarial loss: 0.467624\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018086; batch adversarial loss: 0.411901\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023164; batch adversarial loss: 0.396011\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022115; batch adversarial loss: 0.461406\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008018; batch adversarial loss: 0.463685\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021599; batch adversarial loss: 0.457490\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008388; batch adversarial loss: 0.506285\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012297; batch adversarial loss: 0.413798\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038722; batch adversarial loss: 0.466925\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017549; batch adversarial loss: 0.461529\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011162; batch adversarial loss: 0.528008\n",
      "epoch 158; iter: 0; batch classifier loss: 0.039433; batch adversarial loss: 0.377363\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024154; batch adversarial loss: 0.352310\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012698; batch adversarial loss: 0.558143\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022759; batch adversarial loss: 0.489587\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015525; batch adversarial loss: 0.388428\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028838; batch adversarial loss: 0.429943\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009513; batch adversarial loss: 0.492561\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048914; batch adversarial loss: 0.362464\n",
      "epoch 166; iter: 0; batch classifier loss: 0.057189; batch adversarial loss: 0.421778\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014432; batch adversarial loss: 0.352222\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008535; batch adversarial loss: 0.420672\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026973; batch adversarial loss: 0.485635\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017621; batch adversarial loss: 0.457871\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019988; batch adversarial loss: 0.469760\n",
      "epoch 172; iter: 0; batch classifier loss: 0.041576; batch adversarial loss: 0.406919\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025222; batch adversarial loss: 0.522748\n",
      "epoch 174; iter: 0; batch classifier loss: 0.004601; batch adversarial loss: 0.409764\n",
      "epoch 175; iter: 0; batch classifier loss: 0.003528; batch adversarial loss: 0.440904\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021323; batch adversarial loss: 0.515290\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006283; batch adversarial loss: 0.507343\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033116; batch adversarial loss: 0.490125\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011258; batch adversarial loss: 0.497703\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019172; batch adversarial loss: 0.439832\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008794; batch adversarial loss: 0.427856\n",
      "epoch 182; iter: 0; batch classifier loss: 0.005822; batch adversarial loss: 0.412846\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019030; batch adversarial loss: 0.366182\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016812; batch adversarial loss: 0.363934\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015048; batch adversarial loss: 0.486020\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011905; batch adversarial loss: 0.456381\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007076; batch adversarial loss: 0.414047\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011414; batch adversarial loss: 0.507744\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010513; batch adversarial loss: 0.435316\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008698; batch adversarial loss: 0.489024\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012533; batch adversarial loss: 0.536265\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012550; batch adversarial loss: 0.440549\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007034; batch adversarial loss: 0.449018\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006627; batch adversarial loss: 0.436122\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006666; batch adversarial loss: 0.454589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.013076; batch adversarial loss: 0.483289\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010335; batch adversarial loss: 0.508005\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009020; batch adversarial loss: 0.446431\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009878; batch adversarial loss: 0.453307\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680718; batch adversarial loss: 0.615480\n",
      "epoch 1; iter: 0; batch classifier loss: 0.475809; batch adversarial loss: 0.623155\n",
      "epoch 2; iter: 0; batch classifier loss: 0.465087; batch adversarial loss: 0.533446\n",
      "epoch 3; iter: 0; batch classifier loss: 0.455589; batch adversarial loss: 0.608460\n",
      "epoch 4; iter: 0; batch classifier loss: 0.416657; batch adversarial loss: 0.597793\n",
      "epoch 5; iter: 0; batch classifier loss: 0.324603; batch adversarial loss: 0.648459\n",
      "epoch 6; iter: 0; batch classifier loss: 0.324933; batch adversarial loss: 0.608521\n",
      "epoch 7; iter: 0; batch classifier loss: 0.471941; batch adversarial loss: 0.610309\n",
      "epoch 8; iter: 0; batch classifier loss: 0.654641; batch adversarial loss: 0.558503\n",
      "epoch 9; iter: 0; batch classifier loss: 0.555358; batch adversarial loss: 0.578596\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518192; batch adversarial loss: 0.524206\n",
      "epoch 11; iter: 0; batch classifier loss: 0.396895; batch adversarial loss: 0.527868\n",
      "epoch 12; iter: 0; batch classifier loss: 0.314506; batch adversarial loss: 0.509506\n",
      "epoch 13; iter: 0; batch classifier loss: 0.248534; batch adversarial loss: 0.464753\n",
      "epoch 14; iter: 0; batch classifier loss: 0.322398; batch adversarial loss: 0.469086\n",
      "epoch 15; iter: 0; batch classifier loss: 0.250410; batch adversarial loss: 0.491379\n",
      "epoch 16; iter: 0; batch classifier loss: 0.256268; batch adversarial loss: 0.487268\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221751; batch adversarial loss: 0.471334\n",
      "epoch 18; iter: 0; batch classifier loss: 0.212876; batch adversarial loss: 0.474490\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223077; batch adversarial loss: 0.511576\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220188; batch adversarial loss: 0.481727\n",
      "epoch 21; iter: 0; batch classifier loss: 0.220554; batch adversarial loss: 0.462798\n",
      "epoch 22; iter: 0; batch classifier loss: 0.121898; batch adversarial loss: 0.460902\n",
      "epoch 23; iter: 0; batch classifier loss: 0.204510; batch adversarial loss: 0.501800\n",
      "epoch 24; iter: 0; batch classifier loss: 0.198331; batch adversarial loss: 0.423985\n",
      "epoch 25; iter: 0; batch classifier loss: 0.194296; batch adversarial loss: 0.462618\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180458; batch adversarial loss: 0.489244\n",
      "epoch 27; iter: 0; batch classifier loss: 0.194877; batch adversarial loss: 0.496147\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160722; batch adversarial loss: 0.545798\n",
      "epoch 29; iter: 0; batch classifier loss: 0.137150; batch adversarial loss: 0.451297\n",
      "epoch 30; iter: 0; batch classifier loss: 0.164334; batch adversarial loss: 0.417762\n",
      "epoch 31; iter: 0; batch classifier loss: 0.119387; batch adversarial loss: 0.457223\n",
      "epoch 32; iter: 0; batch classifier loss: 0.170546; batch adversarial loss: 0.469253\n",
      "epoch 33; iter: 0; batch classifier loss: 0.142133; batch adversarial loss: 0.359703\n",
      "epoch 34; iter: 0; batch classifier loss: 0.185659; batch adversarial loss: 0.332097\n",
      "epoch 35; iter: 0; batch classifier loss: 0.141727; batch adversarial loss: 0.378797\n",
      "epoch 36; iter: 0; batch classifier loss: 0.180337; batch adversarial loss: 0.431150\n",
      "epoch 37; iter: 0; batch classifier loss: 0.179127; batch adversarial loss: 0.453883\n",
      "epoch 38; iter: 0; batch classifier loss: 0.116809; batch adversarial loss: 0.380879\n",
      "epoch 39; iter: 0; batch classifier loss: 0.105141; batch adversarial loss: 0.541193\n",
      "epoch 40; iter: 0; batch classifier loss: 0.199463; batch adversarial loss: 0.383832\n",
      "epoch 41; iter: 0; batch classifier loss: 0.166055; batch adversarial loss: 0.491809\n",
      "epoch 42; iter: 0; batch classifier loss: 0.151751; batch adversarial loss: 0.444339\n",
      "epoch 43; iter: 0; batch classifier loss: 0.175487; batch adversarial loss: 0.364852\n",
      "epoch 44; iter: 0; batch classifier loss: 0.122206; batch adversarial loss: 0.452120\n",
      "epoch 45; iter: 0; batch classifier loss: 0.146846; batch adversarial loss: 0.351821\n",
      "epoch 46; iter: 0; batch classifier loss: 0.168338; batch adversarial loss: 0.446644\n",
      "epoch 47; iter: 0; batch classifier loss: 0.187962; batch adversarial loss: 0.481932\n",
      "epoch 48; iter: 0; batch classifier loss: 0.253296; batch adversarial loss: 0.516401\n",
      "epoch 49; iter: 0; batch classifier loss: 0.104883; batch adversarial loss: 0.482706\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108363; batch adversarial loss: 0.523264\n",
      "epoch 51; iter: 0; batch classifier loss: 0.208120; batch adversarial loss: 0.326075\n",
      "epoch 52; iter: 0; batch classifier loss: 0.202439; batch adversarial loss: 0.436262\n",
      "epoch 53; iter: 0; batch classifier loss: 0.150586; batch adversarial loss: 0.518713\n",
      "epoch 54; iter: 0; batch classifier loss: 0.213111; batch adversarial loss: 0.435639\n",
      "epoch 55; iter: 0; batch classifier loss: 0.146504; batch adversarial loss: 0.523689\n",
      "epoch 56; iter: 0; batch classifier loss: 0.145618; batch adversarial loss: 0.374123\n",
      "epoch 57; iter: 0; batch classifier loss: 0.208794; batch adversarial loss: 0.469400\n",
      "epoch 58; iter: 0; batch classifier loss: 0.188959; batch adversarial loss: 0.437566\n",
      "epoch 59; iter: 0; batch classifier loss: 0.178142; batch adversarial loss: 0.494310\n",
      "epoch 60; iter: 0; batch classifier loss: 0.131861; batch adversarial loss: 0.521344\n",
      "epoch 61; iter: 0; batch classifier loss: 0.203232; batch adversarial loss: 0.484310\n",
      "epoch 62; iter: 0; batch classifier loss: 0.179930; batch adversarial loss: 0.568802\n",
      "epoch 63; iter: 0; batch classifier loss: 0.174897; batch adversarial loss: 0.383916\n",
      "epoch 64; iter: 0; batch classifier loss: 0.258887; batch adversarial loss: 0.397809\n",
      "epoch 65; iter: 0; batch classifier loss: 0.193076; batch adversarial loss: 0.397079\n",
      "epoch 66; iter: 0; batch classifier loss: 0.191064; batch adversarial loss: 0.446592\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087465; batch adversarial loss: 0.432760\n",
      "epoch 68; iter: 0; batch classifier loss: 0.102936; batch adversarial loss: 0.435850\n",
      "epoch 69; iter: 0; batch classifier loss: 0.041266; batch adversarial loss: 0.536896\n",
      "epoch 70; iter: 0; batch classifier loss: 0.060427; batch adversarial loss: 0.420096\n",
      "epoch 71; iter: 0; batch classifier loss: 0.047543; batch adversarial loss: 0.504912\n",
      "epoch 72; iter: 0; batch classifier loss: 0.112932; batch adversarial loss: 0.402231\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085468; batch adversarial loss: 0.379914\n",
      "epoch 74; iter: 0; batch classifier loss: 0.048535; batch adversarial loss: 0.376976\n",
      "epoch 75; iter: 0; batch classifier loss: 0.080661; batch adversarial loss: 0.474903\n",
      "epoch 76; iter: 0; batch classifier loss: 0.087193; batch adversarial loss: 0.458000\n",
      "epoch 77; iter: 0; batch classifier loss: 0.136718; batch adversarial loss: 0.548132\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071069; batch adversarial loss: 0.493290\n",
      "epoch 79; iter: 0; batch classifier loss: 0.066097; batch adversarial loss: 0.467587\n",
      "epoch 80; iter: 0; batch classifier loss: 0.051820; batch adversarial loss: 0.459246\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065460; batch adversarial loss: 0.478551\n",
      "epoch 82; iter: 0; batch classifier loss: 0.134044; batch adversarial loss: 0.392134\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094097; batch adversarial loss: 0.533334\n",
      "epoch 84; iter: 0; batch classifier loss: 0.097875; batch adversarial loss: 0.441769\n",
      "epoch 85; iter: 0; batch classifier loss: 0.063381; batch adversarial loss: 0.478870\n",
      "epoch 86; iter: 0; batch classifier loss: 0.115705; batch adversarial loss: 0.527197\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072297; batch adversarial loss: 0.434535\n",
      "epoch 88; iter: 0; batch classifier loss: 0.082648; batch adversarial loss: 0.489533\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098692; batch adversarial loss: 0.502974\n",
      "epoch 90; iter: 0; batch classifier loss: 0.124665; batch adversarial loss: 0.487315\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066612; batch adversarial loss: 0.416831\n",
      "epoch 92; iter: 0; batch classifier loss: 0.083722; batch adversarial loss: 0.504215\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064159; batch adversarial loss: 0.430389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.043088; batch adversarial loss: 0.456886\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055535; batch adversarial loss: 0.336045\n",
      "epoch 96; iter: 0; batch classifier loss: 0.050522; batch adversarial loss: 0.552913\n",
      "epoch 97; iter: 0; batch classifier loss: 0.103752; batch adversarial loss: 0.416571\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074329; batch adversarial loss: 0.376109\n",
      "epoch 99; iter: 0; batch classifier loss: 0.092320; batch adversarial loss: 0.461625\n",
      "epoch 100; iter: 0; batch classifier loss: 0.087500; batch adversarial loss: 0.365072\n",
      "epoch 101; iter: 0; batch classifier loss: 0.106082; batch adversarial loss: 0.333328\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079095; batch adversarial loss: 0.499782\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064499; batch adversarial loss: 0.355948\n",
      "epoch 104; iter: 0; batch classifier loss: 0.025631; batch adversarial loss: 0.414824\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064766; batch adversarial loss: 0.442259\n",
      "epoch 106; iter: 0; batch classifier loss: 0.079043; batch adversarial loss: 0.496071\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061405; batch adversarial loss: 0.449819\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064352; batch adversarial loss: 0.358067\n",
      "epoch 109; iter: 0; batch classifier loss: 0.102675; batch adversarial loss: 0.481353\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065969; batch adversarial loss: 0.489225\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066870; batch adversarial loss: 0.526891\n",
      "epoch 112; iter: 0; batch classifier loss: 0.071838; batch adversarial loss: 0.484069\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049709; batch adversarial loss: 0.422759\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033477; batch adversarial loss: 0.506983\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052796; batch adversarial loss: 0.430443\n",
      "epoch 116; iter: 0; batch classifier loss: 0.088982; batch adversarial loss: 0.532562\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048160; batch adversarial loss: 0.474347\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053117; batch adversarial loss: 0.398298\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054502; batch adversarial loss: 0.455292\n",
      "epoch 120; iter: 0; batch classifier loss: 0.083517; batch adversarial loss: 0.379283\n",
      "epoch 121; iter: 0; batch classifier loss: 0.062763; batch adversarial loss: 0.548595\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039966; batch adversarial loss: 0.491750\n",
      "epoch 123; iter: 0; batch classifier loss: 0.059303; batch adversarial loss: 0.397438\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036361; batch adversarial loss: 0.358035\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054634; batch adversarial loss: 0.452275\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037884; batch adversarial loss: 0.480978\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041588; batch adversarial loss: 0.509721\n",
      "epoch 128; iter: 0; batch classifier loss: 0.064566; batch adversarial loss: 0.386333\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045442; batch adversarial loss: 0.494952\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016155; batch adversarial loss: 0.451446\n",
      "epoch 131; iter: 0; batch classifier loss: 0.063876; batch adversarial loss: 0.464056\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039252; batch adversarial loss: 0.430639\n",
      "epoch 133; iter: 0; batch classifier loss: 0.059724; batch adversarial loss: 0.369233\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046190; batch adversarial loss: 0.441533\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028226; batch adversarial loss: 0.386968\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041118; batch adversarial loss: 0.455429\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021427; batch adversarial loss: 0.410109\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032280; batch adversarial loss: 0.390362\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031052; batch adversarial loss: 0.439598\n",
      "epoch 140; iter: 0; batch classifier loss: 0.076695; batch adversarial loss: 0.469136\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026806; batch adversarial loss: 0.463337\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040447; batch adversarial loss: 0.400293\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050569; batch adversarial loss: 0.426013\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025382; batch adversarial loss: 0.423460\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021772; batch adversarial loss: 0.438899\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020045; batch adversarial loss: 0.534438\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027441; batch adversarial loss: 0.494579\n",
      "epoch 148; iter: 0; batch classifier loss: 0.047039; batch adversarial loss: 0.442090\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011000; batch adversarial loss: 0.533382\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034953; batch adversarial loss: 0.457002\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013109; batch adversarial loss: 0.378021\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031236; batch adversarial loss: 0.459242\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039703; batch adversarial loss: 0.446465\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013255; batch adversarial loss: 0.460512\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037428; batch adversarial loss: 0.516077\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020619; batch adversarial loss: 0.455324\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021434; batch adversarial loss: 0.456648\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034179; batch adversarial loss: 0.409943\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026811; batch adversarial loss: 0.531303\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027683; batch adversarial loss: 0.455525\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010679; batch adversarial loss: 0.426787\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042407; batch adversarial loss: 0.499079\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013940; batch adversarial loss: 0.434619\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023985; batch adversarial loss: 0.476561\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022229; batch adversarial loss: 0.397474\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037237; batch adversarial loss: 0.371456\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039900; batch adversarial loss: 0.413041\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014831; batch adversarial loss: 0.455550\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014528; batch adversarial loss: 0.454692\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023166; batch adversarial loss: 0.528920\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028833; batch adversarial loss: 0.475826\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020611; batch adversarial loss: 0.411352\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020983; batch adversarial loss: 0.385635\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017991; batch adversarial loss: 0.552279\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014893; batch adversarial loss: 0.483219\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011853; batch adversarial loss: 0.507823\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017692; batch adversarial loss: 0.375787\n",
      "epoch 178; iter: 0; batch classifier loss: 0.046075; batch adversarial loss: 0.427947\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013667; batch adversarial loss: 0.530596\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023645; batch adversarial loss: 0.354982\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020079; batch adversarial loss: 0.431806\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011114; batch adversarial loss: 0.397257\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027534; batch adversarial loss: 0.411457\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028442; batch adversarial loss: 0.417380\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019845; batch adversarial loss: 0.451762\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011390; batch adversarial loss: 0.398836\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025695; batch adversarial loss: 0.475438\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011169; batch adversarial loss: 0.392112\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016794; batch adversarial loss: 0.447245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.033874; batch adversarial loss: 0.390879\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016180; batch adversarial loss: 0.551596\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015362; batch adversarial loss: 0.543307\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014544; batch adversarial loss: 0.499647\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018583; batch adversarial loss: 0.484643\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024967; batch adversarial loss: 0.422049\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006154; batch adversarial loss: 0.520331\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010726; batch adversarial loss: 0.430653\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019662; batch adversarial loss: 0.424468\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013097; batch adversarial loss: 0.410264\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708914; batch adversarial loss: 0.656114\n",
      "epoch 1; iter: 0; batch classifier loss: 0.403254; batch adversarial loss: 0.639911\n",
      "epoch 2; iter: 0; batch classifier loss: 0.475775; batch adversarial loss: 0.585253\n",
      "epoch 3; iter: 0; batch classifier loss: 0.382493; batch adversarial loss: 0.569399\n",
      "epoch 4; iter: 0; batch classifier loss: 0.305707; batch adversarial loss: 0.543323\n",
      "epoch 5; iter: 0; batch classifier loss: 0.279807; batch adversarial loss: 0.524711\n",
      "epoch 6; iter: 0; batch classifier loss: 0.300064; batch adversarial loss: 0.518474\n",
      "epoch 7; iter: 0; batch classifier loss: 0.301703; batch adversarial loss: 0.463528\n",
      "epoch 8; iter: 0; batch classifier loss: 0.322552; batch adversarial loss: 0.482644\n",
      "epoch 9; iter: 0; batch classifier loss: 0.264123; batch adversarial loss: 0.464508\n",
      "epoch 10; iter: 0; batch classifier loss: 0.274277; batch adversarial loss: 0.476456\n",
      "epoch 11; iter: 0; batch classifier loss: 0.241293; batch adversarial loss: 0.463866\n",
      "epoch 12; iter: 0; batch classifier loss: 0.229396; batch adversarial loss: 0.551265\n",
      "epoch 13; iter: 0; batch classifier loss: 0.256031; batch adversarial loss: 0.503925\n",
      "epoch 14; iter: 0; batch classifier loss: 0.207774; batch adversarial loss: 0.417886\n",
      "epoch 15; iter: 0; batch classifier loss: 0.252316; batch adversarial loss: 0.541348\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222647; batch adversarial loss: 0.490818\n",
      "epoch 17; iter: 0; batch classifier loss: 0.260018; batch adversarial loss: 0.514094\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237457; batch adversarial loss: 0.490843\n",
      "epoch 19; iter: 0; batch classifier loss: 0.206427; batch adversarial loss: 0.493341\n",
      "epoch 20; iter: 0; batch classifier loss: 0.255421; batch adversarial loss: 0.495737\n",
      "epoch 21; iter: 0; batch classifier loss: 0.266538; batch adversarial loss: 0.590686\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254210; batch adversarial loss: 0.463463\n",
      "epoch 23; iter: 0; batch classifier loss: 0.246899; batch adversarial loss: 0.573549\n",
      "epoch 24; iter: 0; batch classifier loss: 0.221810; batch adversarial loss: 0.488273\n",
      "epoch 25; iter: 0; batch classifier loss: 0.206932; batch adversarial loss: 0.434062\n",
      "epoch 26; iter: 0; batch classifier loss: 0.274706; batch adversarial loss: 0.491455\n",
      "epoch 27; iter: 0; batch classifier loss: 0.325281; batch adversarial loss: 0.570992\n",
      "epoch 28; iter: 0; batch classifier loss: 0.267070; batch adversarial loss: 0.434554\n",
      "epoch 29; iter: 0; batch classifier loss: 0.181906; batch adversarial loss: 0.520904\n",
      "epoch 30; iter: 0; batch classifier loss: 0.158035; batch adversarial loss: 0.386543\n",
      "epoch 31; iter: 0; batch classifier loss: 0.135572; batch adversarial loss: 0.446297\n",
      "epoch 32; iter: 0; batch classifier loss: 0.087015; batch adversarial loss: 0.540726\n",
      "epoch 33; iter: 0; batch classifier loss: 0.177258; batch adversarial loss: 0.419739\n",
      "epoch 34; iter: 0; batch classifier loss: 0.096619; batch adversarial loss: 0.460168\n",
      "epoch 35; iter: 0; batch classifier loss: 0.123124; batch adversarial loss: 0.466769\n",
      "epoch 36; iter: 0; batch classifier loss: 0.133595; batch adversarial loss: 0.344401\n",
      "epoch 37; iter: 0; batch classifier loss: 0.104820; batch adversarial loss: 0.499464\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099756; batch adversarial loss: 0.444394\n",
      "epoch 39; iter: 0; batch classifier loss: 0.094803; batch adversarial loss: 0.471341\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135510; batch adversarial loss: 0.479435\n",
      "epoch 41; iter: 0; batch classifier loss: 0.115265; batch adversarial loss: 0.508654\n",
      "epoch 42; iter: 0; batch classifier loss: 0.090854; batch adversarial loss: 0.440362\n",
      "epoch 43; iter: 0; batch classifier loss: 0.090248; batch adversarial loss: 0.379885\n",
      "epoch 44; iter: 0; batch classifier loss: 0.114582; batch adversarial loss: 0.396285\n",
      "epoch 45; iter: 0; batch classifier loss: 0.122033; batch adversarial loss: 0.507117\n",
      "epoch 46; iter: 0; batch classifier loss: 0.115074; batch adversarial loss: 0.447279\n",
      "epoch 47; iter: 0; batch classifier loss: 0.099908; batch adversarial loss: 0.386291\n",
      "epoch 48; iter: 0; batch classifier loss: 0.107816; batch adversarial loss: 0.504015\n",
      "epoch 49; iter: 0; batch classifier loss: 0.110160; batch adversarial loss: 0.436166\n",
      "epoch 50; iter: 0; batch classifier loss: 0.113649; batch adversarial loss: 0.507667\n",
      "epoch 51; iter: 0; batch classifier loss: 0.103251; batch adversarial loss: 0.508007\n",
      "epoch 52; iter: 0; batch classifier loss: 0.148605; batch adversarial loss: 0.440086\n",
      "epoch 53; iter: 0; batch classifier loss: 0.113417; batch adversarial loss: 0.389197\n",
      "epoch 54; iter: 0; batch classifier loss: 0.117555; batch adversarial loss: 0.469633\n",
      "epoch 55; iter: 0; batch classifier loss: 0.078082; batch adversarial loss: 0.490280\n",
      "epoch 56; iter: 0; batch classifier loss: 0.087658; batch adversarial loss: 0.464204\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110981; batch adversarial loss: 0.419617\n",
      "epoch 58; iter: 0; batch classifier loss: 0.039118; batch adversarial loss: 0.469731\n",
      "epoch 59; iter: 0; batch classifier loss: 0.065812; batch adversarial loss: 0.468905\n",
      "epoch 60; iter: 0; batch classifier loss: 0.110314; batch adversarial loss: 0.465167\n",
      "epoch 61; iter: 0; batch classifier loss: 0.111487; batch adversarial loss: 0.332066\n",
      "epoch 62; iter: 0; batch classifier loss: 0.145489; batch adversarial loss: 0.471687\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078822; batch adversarial loss: 0.458974\n",
      "epoch 64; iter: 0; batch classifier loss: 0.097017; batch adversarial loss: 0.466557\n",
      "epoch 65; iter: 0; batch classifier loss: 0.103553; batch adversarial loss: 0.439000\n",
      "epoch 66; iter: 0; batch classifier loss: 0.069932; batch adversarial loss: 0.484081\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095535; batch adversarial loss: 0.513791\n",
      "epoch 68; iter: 0; batch classifier loss: 0.139498; batch adversarial loss: 0.493567\n",
      "epoch 69; iter: 0; batch classifier loss: 0.123235; batch adversarial loss: 0.386842\n",
      "epoch 70; iter: 0; batch classifier loss: 0.068420; batch adversarial loss: 0.479795\n",
      "epoch 71; iter: 0; batch classifier loss: 0.093850; batch adversarial loss: 0.406741\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097964; batch adversarial loss: 0.526649\n",
      "epoch 73; iter: 0; batch classifier loss: 0.094517; batch adversarial loss: 0.403665\n",
      "epoch 74; iter: 0; batch classifier loss: 0.048656; batch adversarial loss: 0.528915\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076991; batch adversarial loss: 0.536795\n",
      "epoch 76; iter: 0; batch classifier loss: 0.122207; batch adversarial loss: 0.456567\n",
      "epoch 77; iter: 0; batch classifier loss: 0.113871; batch adversarial loss: 0.457211\n",
      "epoch 78; iter: 0; batch classifier loss: 0.139644; batch adversarial loss: 0.469405\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074685; batch adversarial loss: 0.496162\n",
      "epoch 80; iter: 0; batch classifier loss: 0.100988; batch adversarial loss: 0.496418\n",
      "epoch 81; iter: 0; batch classifier loss: 0.110929; batch adversarial loss: 0.406619\n",
      "epoch 82; iter: 0; batch classifier loss: 0.119398; batch adversarial loss: 0.410167\n",
      "epoch 83; iter: 0; batch classifier loss: 0.135609; batch adversarial loss: 0.473002\n",
      "epoch 84; iter: 0; batch classifier loss: 0.092363; batch adversarial loss: 0.403324\n",
      "epoch 85; iter: 0; batch classifier loss: 0.095189; batch adversarial loss: 0.473440\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051140; batch adversarial loss: 0.590259\n",
      "epoch 87; iter: 0; batch classifier loss: 0.101116; batch adversarial loss: 0.484411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.118195; batch adversarial loss: 0.443788\n",
      "epoch 89; iter: 0; batch classifier loss: 0.064612; batch adversarial loss: 0.486800\n",
      "epoch 90; iter: 0; batch classifier loss: 0.083891; batch adversarial loss: 0.441308\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056997; batch adversarial loss: 0.387236\n",
      "epoch 92; iter: 0; batch classifier loss: 0.053339; batch adversarial loss: 0.468396\n",
      "epoch 93; iter: 0; batch classifier loss: 0.136104; batch adversarial loss: 0.475059\n",
      "epoch 94; iter: 0; batch classifier loss: 0.085288; batch adversarial loss: 0.460224\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053893; batch adversarial loss: 0.481842\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058156; batch adversarial loss: 0.401304\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051045; batch adversarial loss: 0.512250\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053681; batch adversarial loss: 0.407131\n",
      "epoch 99; iter: 0; batch classifier loss: 0.122461; batch adversarial loss: 0.430365\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060086; batch adversarial loss: 0.396866\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057148; batch adversarial loss: 0.532986\n",
      "epoch 102; iter: 0; batch classifier loss: 0.081520; batch adversarial loss: 0.425239\n",
      "epoch 103; iter: 0; batch classifier loss: 0.094416; batch adversarial loss: 0.393512\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036131; batch adversarial loss: 0.529775\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047319; batch adversarial loss: 0.490444\n",
      "epoch 106; iter: 0; batch classifier loss: 0.085070; batch adversarial loss: 0.449574\n",
      "epoch 107; iter: 0; batch classifier loss: 0.043669; batch adversarial loss: 0.503354\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052582; batch adversarial loss: 0.582717\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027365; batch adversarial loss: 0.393149\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026944; batch adversarial loss: 0.450407\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030767; batch adversarial loss: 0.479729\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051524; batch adversarial loss: 0.472335\n",
      "epoch 113; iter: 0; batch classifier loss: 0.070299; batch adversarial loss: 0.484666\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062158; batch adversarial loss: 0.567087\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049062; batch adversarial loss: 0.487613\n",
      "epoch 116; iter: 0; batch classifier loss: 0.107927; batch adversarial loss: 0.481726\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056823; batch adversarial loss: 0.461734\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024163; batch adversarial loss: 0.466844\n",
      "epoch 119; iter: 0; batch classifier loss: 0.097934; batch adversarial loss: 0.444932\n",
      "epoch 120; iter: 0; batch classifier loss: 0.052280; batch adversarial loss: 0.450929\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025621; batch adversarial loss: 0.578493\n",
      "epoch 122; iter: 0; batch classifier loss: 0.064318; batch adversarial loss: 0.379662\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028020; batch adversarial loss: 0.415069\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038167; batch adversarial loss: 0.351895\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027606; batch adversarial loss: 0.467918\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039292; batch adversarial loss: 0.505659\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028258; batch adversarial loss: 0.568752\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058896; batch adversarial loss: 0.468515\n",
      "epoch 129; iter: 0; batch classifier loss: 0.070546; batch adversarial loss: 0.388293\n",
      "epoch 130; iter: 0; batch classifier loss: 0.066338; batch adversarial loss: 0.424494\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038686; batch adversarial loss: 0.366790\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036970; batch adversarial loss: 0.508971\n",
      "epoch 133; iter: 0; batch classifier loss: 0.070724; batch adversarial loss: 0.398786\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069739; batch adversarial loss: 0.544569\n",
      "epoch 135; iter: 0; batch classifier loss: 0.008989; batch adversarial loss: 0.428988\n",
      "epoch 136; iter: 0; batch classifier loss: 0.078699; batch adversarial loss: 0.405986\n",
      "epoch 137; iter: 0; batch classifier loss: 0.056051; batch adversarial loss: 0.357953\n",
      "epoch 138; iter: 0; batch classifier loss: 0.052918; batch adversarial loss: 0.368442\n",
      "epoch 139; iter: 0; batch classifier loss: 0.056925; batch adversarial loss: 0.500100\n",
      "epoch 140; iter: 0; batch classifier loss: 0.071767; batch adversarial loss: 0.552978\n",
      "epoch 141; iter: 0; batch classifier loss: 0.054873; batch adversarial loss: 0.439613\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045276; batch adversarial loss: 0.377676\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051597; batch adversarial loss: 0.428337\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037465; batch adversarial loss: 0.468154\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017461; batch adversarial loss: 0.475379\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044898; batch adversarial loss: 0.385007\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017640; batch adversarial loss: 0.493173\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037419; batch adversarial loss: 0.446318\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022757; batch adversarial loss: 0.502776\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024109; batch adversarial loss: 0.429568\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044271; batch adversarial loss: 0.420965\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025389; batch adversarial loss: 0.440963\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039849; batch adversarial loss: 0.499822\n",
      "epoch 154; iter: 0; batch classifier loss: 0.045649; batch adversarial loss: 0.560536\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028469; batch adversarial loss: 0.461637\n",
      "epoch 156; iter: 0; batch classifier loss: 0.075035; batch adversarial loss: 0.463763\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039959; batch adversarial loss: 0.480667\n",
      "epoch 158; iter: 0; batch classifier loss: 0.055332; batch adversarial loss: 0.422902\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022115; batch adversarial loss: 0.376700\n",
      "epoch 160; iter: 0; batch classifier loss: 0.050388; batch adversarial loss: 0.350252\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042488; batch adversarial loss: 0.473600\n",
      "epoch 162; iter: 0; batch classifier loss: 0.081585; batch adversarial loss: 0.476839\n",
      "epoch 163; iter: 0; batch classifier loss: 0.041975; batch adversarial loss: 0.502601\n",
      "epoch 164; iter: 0; batch classifier loss: 0.008913; batch adversarial loss: 0.412284\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032306; batch adversarial loss: 0.449204\n",
      "epoch 166; iter: 0; batch classifier loss: 0.055334; batch adversarial loss: 0.365343\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024386; batch adversarial loss: 0.347553\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031252; batch adversarial loss: 0.391231\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037849; batch adversarial loss: 0.518046\n",
      "epoch 170; iter: 0; batch classifier loss: 0.060576; batch adversarial loss: 0.497203\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040313; batch adversarial loss: 0.410497\n",
      "epoch 172; iter: 0; batch classifier loss: 0.049918; batch adversarial loss: 0.379925\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014614; batch adversarial loss: 0.502257\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019602; batch adversarial loss: 0.438057\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027255; batch adversarial loss: 0.387635\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008809; batch adversarial loss: 0.422588\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012599; batch adversarial loss: 0.578187\n",
      "epoch 178; iter: 0; batch classifier loss: 0.049896; batch adversarial loss: 0.439575\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026098; batch adversarial loss: 0.474311\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032955; batch adversarial loss: 0.432341\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010800; batch adversarial loss: 0.531228\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027772; batch adversarial loss: 0.521335\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033530; batch adversarial loss: 0.495095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.028687; batch adversarial loss: 0.373184\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026419; batch adversarial loss: 0.447420\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009118; batch adversarial loss: 0.444614\n",
      "epoch 187; iter: 0; batch classifier loss: 0.066308; batch adversarial loss: 0.460624\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020311; batch adversarial loss: 0.515005\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016369; batch adversarial loss: 0.470714\n",
      "epoch 190; iter: 0; batch classifier loss: 0.041622; batch adversarial loss: 0.469108\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017254; batch adversarial loss: 0.444563\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022243; batch adversarial loss: 0.412518\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007431; batch adversarial loss: 0.402309\n",
      "epoch 194; iter: 0; batch classifier loss: 0.083734; batch adversarial loss: 0.436304\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030252; batch adversarial loss: 0.484596\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033870; batch adversarial loss: 0.468805\n",
      "epoch 197; iter: 0; batch classifier loss: 0.064075; batch adversarial loss: 0.462207\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012474; batch adversarial loss: 0.453725\n",
      "epoch 199; iter: 0; batch classifier loss: 0.055138; batch adversarial loss: 0.379537\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704715; batch adversarial loss: 0.848161\n",
      "epoch 1; iter: 0; batch classifier loss: 0.487158; batch adversarial loss: 0.822766\n",
      "epoch 2; iter: 0; batch classifier loss: 0.405654; batch adversarial loss: 0.784362\n",
      "epoch 3; iter: 0; batch classifier loss: 0.317449; batch adversarial loss: 0.755077\n",
      "epoch 4; iter: 0; batch classifier loss: 0.290691; batch adversarial loss: 0.676412\n",
      "epoch 5; iter: 0; batch classifier loss: 0.330669; batch adversarial loss: 0.673644\n",
      "epoch 6; iter: 0; batch classifier loss: 0.263698; batch adversarial loss: 0.634935\n",
      "epoch 7; iter: 0; batch classifier loss: 0.266176; batch adversarial loss: 0.597436\n",
      "epoch 8; iter: 0; batch classifier loss: 0.348270; batch adversarial loss: 0.583808\n",
      "epoch 9; iter: 0; batch classifier loss: 0.218441; batch adversarial loss: 0.586847\n",
      "epoch 10; iter: 0; batch classifier loss: 0.213628; batch adversarial loss: 0.589959\n",
      "epoch 11; iter: 0; batch classifier loss: 0.292740; batch adversarial loss: 0.545119\n",
      "epoch 12; iter: 0; batch classifier loss: 0.268640; batch adversarial loss: 0.528464\n",
      "epoch 13; iter: 0; batch classifier loss: 0.273849; batch adversarial loss: 0.459496\n",
      "epoch 14; iter: 0; batch classifier loss: 0.242359; batch adversarial loss: 0.469713\n",
      "epoch 15; iter: 0; batch classifier loss: 0.268544; batch adversarial loss: 0.479836\n",
      "epoch 16; iter: 0; batch classifier loss: 0.258733; batch adversarial loss: 0.472733\n",
      "epoch 17; iter: 0; batch classifier loss: 0.267784; batch adversarial loss: 0.446717\n",
      "epoch 18; iter: 0; batch classifier loss: 0.277441; batch adversarial loss: 0.440816\n",
      "epoch 19; iter: 0; batch classifier loss: 0.206313; batch adversarial loss: 0.408474\n",
      "epoch 20; iter: 0; batch classifier loss: 0.291388; batch adversarial loss: 0.388627\n",
      "epoch 21; iter: 0; batch classifier loss: 0.172029; batch adversarial loss: 0.435387\n",
      "epoch 22; iter: 0; batch classifier loss: 0.216792; batch adversarial loss: 0.430126\n",
      "epoch 23; iter: 0; batch classifier loss: 0.220186; batch adversarial loss: 0.386249\n",
      "epoch 24; iter: 0; batch classifier loss: 0.258639; batch adversarial loss: 0.332344\n",
      "epoch 25; iter: 0; batch classifier loss: 0.194503; batch adversarial loss: 0.352550\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181759; batch adversarial loss: 0.355866\n",
      "epoch 27; iter: 0; batch classifier loss: 0.205536; batch adversarial loss: 0.402846\n",
      "epoch 28; iter: 0; batch classifier loss: 0.202007; batch adversarial loss: 0.352583\n",
      "epoch 29; iter: 0; batch classifier loss: 0.171985; batch adversarial loss: 0.407269\n",
      "epoch 30; iter: 0; batch classifier loss: 0.190730; batch adversarial loss: 0.398934\n",
      "epoch 31; iter: 0; batch classifier loss: 0.180647; batch adversarial loss: 0.402876\n",
      "epoch 32; iter: 0; batch classifier loss: 0.173400; batch adversarial loss: 0.382666\n",
      "epoch 33; iter: 0; batch classifier loss: 0.151040; batch adversarial loss: 0.342572\n",
      "epoch 34; iter: 0; batch classifier loss: 0.170991; batch adversarial loss: 0.458870\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122557; batch adversarial loss: 0.466114\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126852; batch adversarial loss: 0.384897\n",
      "epoch 37; iter: 0; batch classifier loss: 0.138286; batch adversarial loss: 0.478618\n",
      "epoch 38; iter: 0; batch classifier loss: 0.136479; batch adversarial loss: 0.373909\n",
      "epoch 39; iter: 0; batch classifier loss: 0.135822; batch adversarial loss: 0.375962\n",
      "epoch 40; iter: 0; batch classifier loss: 0.160176; batch adversarial loss: 0.394040\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142987; batch adversarial loss: 0.432318\n",
      "epoch 42; iter: 0; batch classifier loss: 0.143233; batch adversarial loss: 0.374514\n",
      "epoch 43; iter: 0; batch classifier loss: 0.093442; batch adversarial loss: 0.441347\n",
      "epoch 44; iter: 0; batch classifier loss: 0.120057; batch adversarial loss: 0.395661\n",
      "epoch 45; iter: 0; batch classifier loss: 0.136693; batch adversarial loss: 0.421600\n",
      "epoch 46; iter: 0; batch classifier loss: 0.087571; batch adversarial loss: 0.467967\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114112; batch adversarial loss: 0.394623\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099748; batch adversarial loss: 0.428464\n",
      "epoch 49; iter: 0; batch classifier loss: 0.132531; batch adversarial loss: 0.469819\n",
      "epoch 50; iter: 0; batch classifier loss: 0.115126; batch adversarial loss: 0.408991\n",
      "epoch 51; iter: 0; batch classifier loss: 0.086641; batch adversarial loss: 0.383046\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096891; batch adversarial loss: 0.375784\n",
      "epoch 53; iter: 0; batch classifier loss: 0.086596; batch adversarial loss: 0.328179\n",
      "epoch 54; iter: 0; batch classifier loss: 0.098047; batch adversarial loss: 0.476214\n",
      "epoch 55; iter: 0; batch classifier loss: 0.066962; batch adversarial loss: 0.486483\n",
      "epoch 56; iter: 0; batch classifier loss: 0.096868; batch adversarial loss: 0.386274\n",
      "epoch 57; iter: 0; batch classifier loss: 0.100894; batch adversarial loss: 0.420979\n",
      "epoch 58; iter: 0; batch classifier loss: 0.108895; batch adversarial loss: 0.385556\n",
      "epoch 59; iter: 0; batch classifier loss: 0.073305; batch adversarial loss: 0.368968\n",
      "epoch 60; iter: 0; batch classifier loss: 0.069942; batch adversarial loss: 0.352660\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099668; batch adversarial loss: 0.462178\n",
      "epoch 62; iter: 0; batch classifier loss: 0.103782; batch adversarial loss: 0.419481\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098308; batch adversarial loss: 0.388732\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106663; batch adversarial loss: 0.452081\n",
      "epoch 65; iter: 0; batch classifier loss: 0.086394; batch adversarial loss: 0.437480\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072352; batch adversarial loss: 0.360607\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110032; batch adversarial loss: 0.348874\n",
      "epoch 68; iter: 0; batch classifier loss: 0.091644; batch adversarial loss: 0.366408\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063273; batch adversarial loss: 0.422954\n",
      "epoch 70; iter: 0; batch classifier loss: 0.111495; batch adversarial loss: 0.477317\n",
      "epoch 71; iter: 0; batch classifier loss: 0.101674; batch adversarial loss: 0.436747\n",
      "epoch 72; iter: 0; batch classifier loss: 0.086038; batch adversarial loss: 0.376551\n",
      "epoch 73; iter: 0; batch classifier loss: 0.099756; batch adversarial loss: 0.446874\n",
      "epoch 74; iter: 0; batch classifier loss: 0.051757; batch adversarial loss: 0.338463\n",
      "epoch 75; iter: 0; batch classifier loss: 0.092049; batch adversarial loss: 0.399337\n",
      "epoch 76; iter: 0; batch classifier loss: 0.051640; batch adversarial loss: 0.454331\n",
      "epoch 77; iter: 0; batch classifier loss: 0.085247; batch adversarial loss: 0.391630\n",
      "epoch 78; iter: 0; batch classifier loss: 0.057535; batch adversarial loss: 0.466869\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082492; batch adversarial loss: 0.397310\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053511; batch adversarial loss: 0.303592\n",
      "epoch 81; iter: 0; batch classifier loss: 0.080848; batch adversarial loss: 0.462223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.085793; batch adversarial loss: 0.358716\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073870; batch adversarial loss: 0.485934\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070469; batch adversarial loss: 0.412136\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061979; batch adversarial loss: 0.464032\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057750; batch adversarial loss: 0.444183\n",
      "epoch 87; iter: 0; batch classifier loss: 0.080180; batch adversarial loss: 0.485228\n",
      "epoch 88; iter: 0; batch classifier loss: 0.047458; batch adversarial loss: 0.366727\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052016; batch adversarial loss: 0.379366\n",
      "epoch 90; iter: 0; batch classifier loss: 0.044715; batch adversarial loss: 0.509337\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070950; batch adversarial loss: 0.379554\n",
      "epoch 92; iter: 0; batch classifier loss: 0.029161; batch adversarial loss: 0.351152\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067551; batch adversarial loss: 0.433183\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036457; batch adversarial loss: 0.468924\n",
      "epoch 95; iter: 0; batch classifier loss: 0.037940; batch adversarial loss: 0.428261\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042750; batch adversarial loss: 0.428200\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059487; batch adversarial loss: 0.583505\n",
      "epoch 98; iter: 0; batch classifier loss: 0.038828; batch adversarial loss: 0.430830\n",
      "epoch 99; iter: 0; batch classifier loss: 0.033128; batch adversarial loss: 0.359262\n",
      "epoch 100; iter: 0; batch classifier loss: 0.033112; batch adversarial loss: 0.425613\n",
      "epoch 101; iter: 0; batch classifier loss: 0.019801; batch adversarial loss: 0.364926\n",
      "epoch 102; iter: 0; batch classifier loss: 0.030367; batch adversarial loss: 0.436655\n",
      "epoch 103; iter: 0; batch classifier loss: 0.021164; batch adversarial loss: 0.529302\n",
      "epoch 104; iter: 0; batch classifier loss: 0.028556; batch adversarial loss: 0.447695\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051014; batch adversarial loss: 0.479519\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053340; batch adversarial loss: 0.370725\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037107; batch adversarial loss: 0.422871\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054508; batch adversarial loss: 0.502955\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029734; batch adversarial loss: 0.547551\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066875; batch adversarial loss: 0.441296\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043955; batch adversarial loss: 0.490516\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027454; batch adversarial loss: 0.439606\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025993; batch adversarial loss: 0.410465\n",
      "epoch 114; iter: 0; batch classifier loss: 0.038832; batch adversarial loss: 0.561789\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038902; batch adversarial loss: 0.478967\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029578; batch adversarial loss: 0.527960\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037042; batch adversarial loss: 0.443899\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046395; batch adversarial loss: 0.513593\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050304; batch adversarial loss: 0.447329\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027718; batch adversarial loss: 0.421849\n",
      "epoch 121; iter: 0; batch classifier loss: 0.013243; batch adversarial loss: 0.475651\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024820; batch adversarial loss: 0.514104\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064407; batch adversarial loss: 0.497890\n",
      "epoch 124; iter: 0; batch classifier loss: 0.018633; batch adversarial loss: 0.537511\n",
      "epoch 125; iter: 0; batch classifier loss: 0.011144; batch adversarial loss: 0.485312\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039984; batch adversarial loss: 0.511491\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041747; batch adversarial loss: 0.576848\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032283; batch adversarial loss: 0.518849\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050070; batch adversarial loss: 0.503283\n",
      "epoch 130; iter: 0; batch classifier loss: 0.078433; batch adversarial loss: 0.567587\n",
      "epoch 131; iter: 0; batch classifier loss: 0.089175; batch adversarial loss: 0.587358\n",
      "epoch 132; iter: 0; batch classifier loss: 0.080275; batch adversarial loss: 0.459318\n",
      "epoch 133; iter: 0; batch classifier loss: 0.147190; batch adversarial loss: 0.724190\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027844; batch adversarial loss: 0.436077\n",
      "epoch 135; iter: 0; batch classifier loss: 0.115276; batch adversarial loss: 0.469170\n",
      "epoch 136; iter: 0; batch classifier loss: 0.132382; batch adversarial loss: 0.651166\n",
      "epoch 137; iter: 0; batch classifier loss: 0.131918; batch adversarial loss: 0.554864\n",
      "epoch 138; iter: 0; batch classifier loss: 0.112321; batch adversarial loss: 0.542478\n",
      "epoch 139; iter: 0; batch classifier loss: 0.141688; batch adversarial loss: 0.604685\n",
      "epoch 140; iter: 0; batch classifier loss: 0.079576; batch adversarial loss: 0.493407\n",
      "epoch 141; iter: 0; batch classifier loss: 0.148677; batch adversarial loss: 0.607966\n",
      "epoch 142; iter: 0; batch classifier loss: 0.107636; batch adversarial loss: 0.580833\n",
      "epoch 143; iter: 0; batch classifier loss: 0.122462; batch adversarial loss: 0.571171\n",
      "epoch 144; iter: 0; batch classifier loss: 0.105579; batch adversarial loss: 0.478432\n",
      "epoch 145; iter: 0; batch classifier loss: 0.109400; batch adversarial loss: 0.550077\n",
      "epoch 146; iter: 0; batch classifier loss: 0.120428; batch adversarial loss: 0.584817\n",
      "epoch 147; iter: 0; batch classifier loss: 0.111940; batch adversarial loss: 0.659073\n",
      "epoch 148; iter: 0; batch classifier loss: 0.114613; batch adversarial loss: 0.557275\n",
      "epoch 149; iter: 0; batch classifier loss: 0.128276; batch adversarial loss: 0.576556\n",
      "epoch 150; iter: 0; batch classifier loss: 0.110819; batch adversarial loss: 0.515706\n",
      "epoch 151; iter: 0; batch classifier loss: 0.124752; batch adversarial loss: 0.503289\n",
      "epoch 152; iter: 0; batch classifier loss: 0.096336; batch adversarial loss: 0.462298\n",
      "epoch 153; iter: 0; batch classifier loss: 0.082356; batch adversarial loss: 0.479634\n",
      "epoch 154; iter: 0; batch classifier loss: 0.091053; batch adversarial loss: 0.474544\n",
      "epoch 155; iter: 0; batch classifier loss: 0.159233; batch adversarial loss: 0.577134\n",
      "epoch 156; iter: 0; batch classifier loss: 0.092222; batch adversarial loss: 0.505468\n",
      "epoch 157; iter: 0; batch classifier loss: 0.096288; batch adversarial loss: 0.548272\n",
      "epoch 158; iter: 0; batch classifier loss: 0.105043; batch adversarial loss: 0.482880\n",
      "epoch 159; iter: 0; batch classifier loss: 0.103385; batch adversarial loss: 0.449342\n",
      "epoch 160; iter: 0; batch classifier loss: 0.137067; batch adversarial loss: 0.538114\n",
      "epoch 161; iter: 0; batch classifier loss: 0.088925; batch adversarial loss: 0.481301\n",
      "epoch 162; iter: 0; batch classifier loss: 0.075775; batch adversarial loss: 0.440403\n",
      "epoch 163; iter: 0; batch classifier loss: 0.121645; batch adversarial loss: 0.513705\n",
      "epoch 164; iter: 0; batch classifier loss: 0.073858; batch adversarial loss: 0.428072\n",
      "epoch 165; iter: 0; batch classifier loss: 0.167187; batch adversarial loss: 0.485989\n",
      "epoch 166; iter: 0; batch classifier loss: 0.129301; batch adversarial loss: 0.513251\n",
      "epoch 167; iter: 0; batch classifier loss: 0.072673; batch adversarial loss: 0.458558\n",
      "epoch 168; iter: 0; batch classifier loss: 0.064702; batch adversarial loss: 0.418798\n",
      "epoch 169; iter: 0; batch classifier loss: 0.052123; batch adversarial loss: 0.367452\n",
      "epoch 170; iter: 0; batch classifier loss: 0.130007; batch adversarial loss: 0.488797\n",
      "epoch 171; iter: 0; batch classifier loss: 0.107799; batch adversarial loss: 0.424430\n",
      "epoch 172; iter: 0; batch classifier loss: 0.102200; batch adversarial loss: 0.481919\n",
      "epoch 173; iter: 0; batch classifier loss: 0.123171; batch adversarial loss: 0.398087\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036678; batch adversarial loss: 0.469292\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039731; batch adversarial loss: 0.419711\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034308; batch adversarial loss: 0.444596\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019158; batch adversarial loss: 0.444562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.032348; batch adversarial loss: 0.494981\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024497; batch adversarial loss: 0.468351\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022107; batch adversarial loss: 0.486782\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035770; batch adversarial loss: 0.562827\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028978; batch adversarial loss: 0.507427\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036489; batch adversarial loss: 0.356664\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025860; batch adversarial loss: 0.585626\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026499; batch adversarial loss: 0.526371\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030669; batch adversarial loss: 0.426002\n",
      "epoch 187; iter: 0; batch classifier loss: 0.068162; batch adversarial loss: 0.443659\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035262; batch adversarial loss: 0.465662\n",
      "epoch 189; iter: 0; batch classifier loss: 0.060208; batch adversarial loss: 0.370379\n",
      "epoch 190; iter: 0; batch classifier loss: 0.042826; batch adversarial loss: 0.375226\n",
      "epoch 191; iter: 0; batch classifier loss: 0.046621; batch adversarial loss: 0.429672\n",
      "epoch 192; iter: 0; batch classifier loss: 0.050463; batch adversarial loss: 0.450525\n",
      "epoch 193; iter: 0; batch classifier loss: 0.041999; batch adversarial loss: 0.420920\n",
      "epoch 194; iter: 0; batch classifier loss: 0.057396; batch adversarial loss: 0.531116\n",
      "epoch 195; iter: 0; batch classifier loss: 0.057847; batch adversarial loss: 0.465891\n",
      "epoch 196; iter: 0; batch classifier loss: 0.059727; batch adversarial loss: 0.498744\n",
      "epoch 197; iter: 0; batch classifier loss: 0.040294; batch adversarial loss: 0.447091\n",
      "epoch 198; iter: 0; batch classifier loss: 0.063013; batch adversarial loss: 0.476668\n",
      "epoch 199; iter: 0; batch classifier loss: 0.051960; batch adversarial loss: 0.395345\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674041; batch adversarial loss: 0.554821\n",
      "epoch 1; iter: 0; batch classifier loss: 0.482407; batch adversarial loss: 0.679780\n",
      "epoch 2; iter: 0; batch classifier loss: 0.374852; batch adversarial loss: 0.540683\n",
      "epoch 3; iter: 0; batch classifier loss: 0.297685; batch adversarial loss: 0.595634\n",
      "epoch 4; iter: 0; batch classifier loss: 0.386952; batch adversarial loss: 0.507588\n",
      "epoch 5; iter: 0; batch classifier loss: 0.379359; batch adversarial loss: 0.531399\n",
      "epoch 6; iter: 0; batch classifier loss: 0.272874; batch adversarial loss: 0.583181\n",
      "epoch 7; iter: 0; batch classifier loss: 0.310888; batch adversarial loss: 0.545072\n",
      "epoch 8; iter: 0; batch classifier loss: 0.283296; batch adversarial loss: 0.514573\n",
      "epoch 9; iter: 0; batch classifier loss: 0.293065; batch adversarial loss: 0.587049\n",
      "epoch 10; iter: 0; batch classifier loss: 0.351247; batch adversarial loss: 0.520373\n",
      "epoch 11; iter: 0; batch classifier loss: 0.324657; batch adversarial loss: 0.545126\n",
      "epoch 12; iter: 0; batch classifier loss: 0.340891; batch adversarial loss: 0.489703\n",
      "epoch 13; iter: 0; batch classifier loss: 0.314261; batch adversarial loss: 0.548170\n",
      "epoch 14; iter: 0; batch classifier loss: 0.325102; batch adversarial loss: 0.500516\n",
      "epoch 15; iter: 0; batch classifier loss: 0.233295; batch adversarial loss: 0.524744\n",
      "epoch 16; iter: 0; batch classifier loss: 0.207107; batch adversarial loss: 0.494212\n",
      "epoch 17; iter: 0; batch classifier loss: 0.191864; batch adversarial loss: 0.454429\n",
      "epoch 18; iter: 0; batch classifier loss: 0.218181; batch adversarial loss: 0.532335\n",
      "epoch 19; iter: 0; batch classifier loss: 0.196290; batch adversarial loss: 0.513236\n",
      "epoch 20; iter: 0; batch classifier loss: 0.298052; batch adversarial loss: 0.435034\n",
      "epoch 21; iter: 0; batch classifier loss: 0.172728; batch adversarial loss: 0.517477\n",
      "epoch 22; iter: 0; batch classifier loss: 0.152803; batch adversarial loss: 0.419655\n",
      "epoch 23; iter: 0; batch classifier loss: 0.167295; batch adversarial loss: 0.497949\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192325; batch adversarial loss: 0.475853\n",
      "epoch 25; iter: 0; batch classifier loss: 0.165553; batch adversarial loss: 0.489562\n",
      "epoch 26; iter: 0; batch classifier loss: 0.136079; batch adversarial loss: 0.432567\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152148; batch adversarial loss: 0.456018\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173926; batch adversarial loss: 0.468827\n",
      "epoch 29; iter: 0; batch classifier loss: 0.157112; batch adversarial loss: 0.555899\n",
      "epoch 30; iter: 0; batch classifier loss: 0.182315; batch adversarial loss: 0.457219\n",
      "epoch 31; iter: 0; batch classifier loss: 0.147077; batch adversarial loss: 0.510889\n",
      "epoch 32; iter: 0; batch classifier loss: 0.158547; batch adversarial loss: 0.484905\n",
      "epoch 33; iter: 0; batch classifier loss: 0.092001; batch adversarial loss: 0.452686\n",
      "epoch 34; iter: 0; batch classifier loss: 0.138214; batch adversarial loss: 0.444327\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153529; batch adversarial loss: 0.427342\n",
      "epoch 36; iter: 0; batch classifier loss: 0.097720; batch adversarial loss: 0.475544\n",
      "epoch 37; iter: 0; batch classifier loss: 0.167860; batch adversarial loss: 0.424359\n",
      "epoch 38; iter: 0; batch classifier loss: 0.088918; batch adversarial loss: 0.545505\n",
      "epoch 39; iter: 0; batch classifier loss: 0.119655; batch adversarial loss: 0.589948\n",
      "epoch 40; iter: 0; batch classifier loss: 0.118751; batch adversarial loss: 0.391369\n",
      "epoch 41; iter: 0; batch classifier loss: 0.093866; batch adversarial loss: 0.458470\n",
      "epoch 42; iter: 0; batch classifier loss: 0.114252; batch adversarial loss: 0.485383\n",
      "epoch 43; iter: 0; batch classifier loss: 0.140090; batch adversarial loss: 0.424752\n",
      "epoch 44; iter: 0; batch classifier loss: 0.166228; batch adversarial loss: 0.456275\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097875; batch adversarial loss: 0.476242\n",
      "epoch 46; iter: 0; batch classifier loss: 0.119309; batch adversarial loss: 0.439076\n",
      "epoch 47; iter: 0; batch classifier loss: 0.133056; batch adversarial loss: 0.529145\n",
      "epoch 48; iter: 0; batch classifier loss: 0.098217; batch adversarial loss: 0.554808\n",
      "epoch 49; iter: 0; batch classifier loss: 0.148874; batch adversarial loss: 0.480223\n",
      "epoch 50; iter: 0; batch classifier loss: 0.113472; batch adversarial loss: 0.419919\n",
      "epoch 51; iter: 0; batch classifier loss: 0.093862; batch adversarial loss: 0.496369\n",
      "epoch 52; iter: 0; batch classifier loss: 0.148252; batch adversarial loss: 0.422147\n",
      "epoch 53; iter: 0; batch classifier loss: 0.168949; batch adversarial loss: 0.440461\n",
      "epoch 54; iter: 0; batch classifier loss: 0.118944; batch adversarial loss: 0.484363\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117297; batch adversarial loss: 0.435282\n",
      "epoch 56; iter: 0; batch classifier loss: 0.100737; batch adversarial loss: 0.545258\n",
      "epoch 57; iter: 0; batch classifier loss: 0.151259; batch adversarial loss: 0.423593\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101728; batch adversarial loss: 0.470957\n",
      "epoch 59; iter: 0; batch classifier loss: 0.110286; batch adversarial loss: 0.462117\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115424; batch adversarial loss: 0.405262\n",
      "epoch 61; iter: 0; batch classifier loss: 0.110895; batch adversarial loss: 0.437919\n",
      "epoch 62; iter: 0; batch classifier loss: 0.121960; batch adversarial loss: 0.512611\n",
      "epoch 63; iter: 0; batch classifier loss: 0.120422; batch adversarial loss: 0.522326\n",
      "epoch 64; iter: 0; batch classifier loss: 0.104474; batch adversarial loss: 0.493429\n",
      "epoch 65; iter: 0; batch classifier loss: 0.099967; batch adversarial loss: 0.491464\n",
      "epoch 66; iter: 0; batch classifier loss: 0.046518; batch adversarial loss: 0.500783\n",
      "epoch 67; iter: 0; batch classifier loss: 0.072137; batch adversarial loss: 0.478540\n",
      "epoch 68; iter: 0; batch classifier loss: 0.103816; batch adversarial loss: 0.408861\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076260; batch adversarial loss: 0.378664\n",
      "epoch 70; iter: 0; batch classifier loss: 0.097803; batch adversarial loss: 0.412659\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078338; batch adversarial loss: 0.442374\n",
      "epoch 72; iter: 0; batch classifier loss: 0.059598; batch adversarial loss: 0.429917\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065644; batch adversarial loss: 0.521894\n",
      "epoch 74; iter: 0; batch classifier loss: 0.099639; batch adversarial loss: 0.462467\n",
      "epoch 75; iter: 0; batch classifier loss: 0.127699; batch adversarial loss: 0.379707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.113135; batch adversarial loss: 0.495269\n",
      "epoch 77; iter: 0; batch classifier loss: 0.085071; batch adversarial loss: 0.410651\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082129; batch adversarial loss: 0.502564\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072513; batch adversarial loss: 0.529692\n",
      "epoch 80; iter: 0; batch classifier loss: 0.116465; batch adversarial loss: 0.463968\n",
      "epoch 81; iter: 0; batch classifier loss: 0.093959; batch adversarial loss: 0.498434\n",
      "epoch 82; iter: 0; batch classifier loss: 0.107196; batch adversarial loss: 0.498325\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062165; batch adversarial loss: 0.485895\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085604; batch adversarial loss: 0.527436\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056161; batch adversarial loss: 0.526582\n",
      "epoch 86; iter: 0; batch classifier loss: 0.098269; batch adversarial loss: 0.479392\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067034; batch adversarial loss: 0.499175\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088263; batch adversarial loss: 0.533478\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048088; batch adversarial loss: 0.544352\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063268; batch adversarial loss: 0.360494\n",
      "epoch 91; iter: 0; batch classifier loss: 0.117093; batch adversarial loss: 0.420090\n",
      "epoch 92; iter: 0; batch classifier loss: 0.089188; batch adversarial loss: 0.544393\n",
      "epoch 93; iter: 0; batch classifier loss: 0.076954; batch adversarial loss: 0.492919\n",
      "epoch 94; iter: 0; batch classifier loss: 0.071792; batch adversarial loss: 0.506283\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045542; batch adversarial loss: 0.483682\n",
      "epoch 96; iter: 0; batch classifier loss: 0.072781; batch adversarial loss: 0.511597\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050761; batch adversarial loss: 0.464697\n",
      "epoch 98; iter: 0; batch classifier loss: 0.060157; batch adversarial loss: 0.322575\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059723; batch adversarial loss: 0.486102\n",
      "epoch 100; iter: 0; batch classifier loss: 0.105918; batch adversarial loss: 0.558759\n",
      "epoch 101; iter: 0; batch classifier loss: 0.105057; batch adversarial loss: 0.378971\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042297; batch adversarial loss: 0.450611\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064713; batch adversarial loss: 0.477056\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039026; batch adversarial loss: 0.463991\n",
      "epoch 105; iter: 0; batch classifier loss: 0.082597; batch adversarial loss: 0.557345\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051904; batch adversarial loss: 0.475205\n",
      "epoch 107; iter: 0; batch classifier loss: 0.092789; batch adversarial loss: 0.432885\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055630; batch adversarial loss: 0.418092\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037111; batch adversarial loss: 0.534429\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030862; batch adversarial loss: 0.409983\n",
      "epoch 111; iter: 0; batch classifier loss: 0.073111; batch adversarial loss: 0.391138\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054539; batch adversarial loss: 0.468179\n",
      "epoch 113; iter: 0; batch classifier loss: 0.015561; batch adversarial loss: 0.444873\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051255; batch adversarial loss: 0.455113\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031255; batch adversarial loss: 0.414986\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041096; batch adversarial loss: 0.469686\n",
      "epoch 117; iter: 0; batch classifier loss: 0.059115; batch adversarial loss: 0.513407\n",
      "epoch 118; iter: 0; batch classifier loss: 0.064164; batch adversarial loss: 0.494651\n",
      "epoch 119; iter: 0; batch classifier loss: 0.086534; batch adversarial loss: 0.415222\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032081; batch adversarial loss: 0.425304\n",
      "epoch 121; iter: 0; batch classifier loss: 0.063877; batch adversarial loss: 0.577508\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026356; batch adversarial loss: 0.431710\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035605; batch adversarial loss: 0.521555\n",
      "epoch 124; iter: 0; batch classifier loss: 0.080305; batch adversarial loss: 0.444548\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029693; batch adversarial loss: 0.465640\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063626; batch adversarial loss: 0.459707\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041761; batch adversarial loss: 0.511259\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030825; batch adversarial loss: 0.450777\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037522; batch adversarial loss: 0.524222\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040008; batch adversarial loss: 0.440252\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019481; batch adversarial loss: 0.523163\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032885; batch adversarial loss: 0.537832\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053243; batch adversarial loss: 0.464181\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052592; batch adversarial loss: 0.551794\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057205; batch adversarial loss: 0.453524\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035270; batch adversarial loss: 0.439380\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040656; batch adversarial loss: 0.525597\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028170; batch adversarial loss: 0.442405\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035648; batch adversarial loss: 0.535380\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033695; batch adversarial loss: 0.476323\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022828; batch adversarial loss: 0.411180\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039925; batch adversarial loss: 0.414999\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030014; batch adversarial loss: 0.458601\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014744; batch adversarial loss: 0.406281\n",
      "epoch 145; iter: 0; batch classifier loss: 0.010860; batch adversarial loss: 0.424040\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031827; batch adversarial loss: 0.424353\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042601; batch adversarial loss: 0.556944\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027833; batch adversarial loss: 0.563245\n",
      "epoch 149; iter: 0; batch classifier loss: 0.045034; batch adversarial loss: 0.401152\n",
      "epoch 150; iter: 0; batch classifier loss: 0.077084; batch adversarial loss: 0.421519\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022816; batch adversarial loss: 0.417629\n",
      "epoch 152; iter: 0; batch classifier loss: 0.052739; batch adversarial loss: 0.474067\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008371; batch adversarial loss: 0.494550\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025626; batch adversarial loss: 0.436514\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046340; batch adversarial loss: 0.406886\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028030; batch adversarial loss: 0.471901\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030856; batch adversarial loss: 0.486216\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038065; batch adversarial loss: 0.522335\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023062; batch adversarial loss: 0.505887\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031244; batch adversarial loss: 0.479803\n",
      "epoch 161; iter: 0; batch classifier loss: 0.053866; batch adversarial loss: 0.433947\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018831; batch adversarial loss: 0.452377\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014329; batch adversarial loss: 0.469939\n",
      "epoch 164; iter: 0; batch classifier loss: 0.058609; batch adversarial loss: 0.470458\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013969; batch adversarial loss: 0.442609\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028451; batch adversarial loss: 0.419943\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012077; batch adversarial loss: 0.446010\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023790; batch adversarial loss: 0.491876\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010365; batch adversarial loss: 0.425616\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029614; batch adversarial loss: 0.432910\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028257; batch adversarial loss: 0.561011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.033581; batch adversarial loss: 0.465294\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033782; batch adversarial loss: 0.517602\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028416; batch adversarial loss: 0.597809\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008001; batch adversarial loss: 0.407768\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031379; batch adversarial loss: 0.512910\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033974; batch adversarial loss: 0.445261\n",
      "epoch 178; iter: 0; batch classifier loss: 0.051219; batch adversarial loss: 0.460928\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034161; batch adversarial loss: 0.436344\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015834; batch adversarial loss: 0.507352\n",
      "epoch 181; iter: 0; batch classifier loss: 0.068457; batch adversarial loss: 0.390523\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020925; batch adversarial loss: 0.471054\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028600; batch adversarial loss: 0.458995\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014387; batch adversarial loss: 0.419392\n",
      "epoch 185; iter: 0; batch classifier loss: 0.058303; batch adversarial loss: 0.520767\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025462; batch adversarial loss: 0.363404\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022320; batch adversarial loss: 0.469136\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033348; batch adversarial loss: 0.455510\n",
      "epoch 189; iter: 0; batch classifier loss: 0.038996; batch adversarial loss: 0.409013\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021042; batch adversarial loss: 0.534751\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017870; batch adversarial loss: 0.479016\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037286; batch adversarial loss: 0.410421\n",
      "epoch 193; iter: 0; batch classifier loss: 0.036951; batch adversarial loss: 0.424677\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024552; batch adversarial loss: 0.486347\n",
      "epoch 195; iter: 0; batch classifier loss: 0.035296; batch adversarial loss: 0.513045\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013075; batch adversarial loss: 0.442089\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018846; batch adversarial loss: 0.482355\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026519; batch adversarial loss: 0.521115\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018914; batch adversarial loss: 0.541403\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685404; batch adversarial loss: 0.610641\n",
      "epoch 1; iter: 0; batch classifier loss: 0.455591; batch adversarial loss: 0.637935\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396365; batch adversarial loss: 0.607001\n",
      "epoch 3; iter: 0; batch classifier loss: 0.448973; batch adversarial loss: 0.624576\n",
      "epoch 4; iter: 0; batch classifier loss: 0.455106; batch adversarial loss: 0.594706\n",
      "epoch 5; iter: 0; batch classifier loss: 0.483773; batch adversarial loss: 0.653445\n",
      "epoch 6; iter: 0; batch classifier loss: 0.432739; batch adversarial loss: 0.555485\n",
      "epoch 7; iter: 0; batch classifier loss: 0.486032; batch adversarial loss: 0.577732\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560735; batch adversarial loss: 0.538146\n",
      "epoch 9; iter: 0; batch classifier loss: 0.440495; batch adversarial loss: 0.549979\n",
      "epoch 10; iter: 0; batch classifier loss: 0.370357; batch adversarial loss: 0.531741\n",
      "epoch 11; iter: 0; batch classifier loss: 0.370735; batch adversarial loss: 0.494540\n",
      "epoch 12; iter: 0; batch classifier loss: 0.291680; batch adversarial loss: 0.514852\n",
      "epoch 13; iter: 0; batch classifier loss: 0.283625; batch adversarial loss: 0.480069\n",
      "epoch 14; iter: 0; batch classifier loss: 0.287875; batch adversarial loss: 0.394834\n",
      "epoch 15; iter: 0; batch classifier loss: 0.237211; batch adversarial loss: 0.540295\n",
      "epoch 16; iter: 0; batch classifier loss: 0.213318; batch adversarial loss: 0.440016\n",
      "epoch 17; iter: 0; batch classifier loss: 0.242715; batch adversarial loss: 0.414433\n",
      "epoch 18; iter: 0; batch classifier loss: 0.257630; batch adversarial loss: 0.507385\n",
      "epoch 19; iter: 0; batch classifier loss: 0.226656; batch adversarial loss: 0.495605\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222063; batch adversarial loss: 0.468783\n",
      "epoch 21; iter: 0; batch classifier loss: 0.286234; batch adversarial loss: 0.473131\n",
      "epoch 22; iter: 0; batch classifier loss: 0.166774; batch adversarial loss: 0.465156\n",
      "epoch 23; iter: 0; batch classifier loss: 0.227949; batch adversarial loss: 0.434715\n",
      "epoch 24; iter: 0; batch classifier loss: 0.193124; batch adversarial loss: 0.425302\n",
      "epoch 25; iter: 0; batch classifier loss: 0.166725; batch adversarial loss: 0.457298\n",
      "epoch 26; iter: 0; batch classifier loss: 0.123266; batch adversarial loss: 0.412163\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178083; batch adversarial loss: 0.595612\n",
      "epoch 28; iter: 0; batch classifier loss: 0.140902; batch adversarial loss: 0.543720\n",
      "epoch 29; iter: 0; batch classifier loss: 0.131217; batch adversarial loss: 0.481808\n",
      "epoch 30; iter: 0; batch classifier loss: 0.186576; batch adversarial loss: 0.520833\n",
      "epoch 31; iter: 0; batch classifier loss: 0.168155; batch adversarial loss: 0.407277\n",
      "epoch 32; iter: 0; batch classifier loss: 0.141878; batch adversarial loss: 0.363139\n",
      "epoch 33; iter: 0; batch classifier loss: 0.135469; batch adversarial loss: 0.382111\n",
      "epoch 34; iter: 0; batch classifier loss: 0.172669; batch adversarial loss: 0.450025\n",
      "epoch 35; iter: 0; batch classifier loss: 0.212874; batch adversarial loss: 0.390888\n",
      "epoch 36; iter: 0; batch classifier loss: 0.131423; batch adversarial loss: 0.445969\n",
      "epoch 37; iter: 0; batch classifier loss: 0.167115; batch adversarial loss: 0.496462\n",
      "epoch 38; iter: 0; batch classifier loss: 0.131740; batch adversarial loss: 0.456048\n",
      "epoch 39; iter: 0; batch classifier loss: 0.151854; batch adversarial loss: 0.496473\n",
      "epoch 40; iter: 0; batch classifier loss: 0.112354; batch adversarial loss: 0.502682\n",
      "epoch 41; iter: 0; batch classifier loss: 0.137224; batch adversarial loss: 0.506515\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113125; batch adversarial loss: 0.379474\n",
      "epoch 43; iter: 0; batch classifier loss: 0.091939; batch adversarial loss: 0.507690\n",
      "epoch 44; iter: 0; batch classifier loss: 0.128525; batch adversarial loss: 0.448603\n",
      "epoch 45; iter: 0; batch classifier loss: 0.100645; batch adversarial loss: 0.476330\n",
      "epoch 46; iter: 0; batch classifier loss: 0.111010; batch adversarial loss: 0.472919\n",
      "epoch 47; iter: 0; batch classifier loss: 0.193642; batch adversarial loss: 0.379982\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082416; batch adversarial loss: 0.476639\n",
      "epoch 49; iter: 0; batch classifier loss: 0.121336; batch adversarial loss: 0.538508\n",
      "epoch 50; iter: 0; batch classifier loss: 0.088766; batch adversarial loss: 0.499408\n",
      "epoch 51; iter: 0; batch classifier loss: 0.159071; batch adversarial loss: 0.417511\n",
      "epoch 52; iter: 0; batch classifier loss: 0.119038; batch adversarial loss: 0.448602\n",
      "epoch 53; iter: 0; batch classifier loss: 0.104982; batch adversarial loss: 0.419490\n",
      "epoch 54; iter: 0; batch classifier loss: 0.113751; batch adversarial loss: 0.514668\n",
      "epoch 55; iter: 0; batch classifier loss: 0.109437; batch adversarial loss: 0.490622\n",
      "epoch 56; iter: 0; batch classifier loss: 0.120317; batch adversarial loss: 0.444973\n",
      "epoch 57; iter: 0; batch classifier loss: 0.117624; batch adversarial loss: 0.472699\n",
      "epoch 58; iter: 0; batch classifier loss: 0.098052; batch adversarial loss: 0.491745\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085619; batch adversarial loss: 0.399290\n",
      "epoch 60; iter: 0; batch classifier loss: 0.162656; batch adversarial loss: 0.481259\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099686; batch adversarial loss: 0.401998\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081333; batch adversarial loss: 0.494573\n",
      "epoch 63; iter: 0; batch classifier loss: 0.057392; batch adversarial loss: 0.463841\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101718; batch adversarial loss: 0.465401\n",
      "epoch 65; iter: 0; batch classifier loss: 0.081761; batch adversarial loss: 0.407681\n",
      "epoch 66; iter: 0; batch classifier loss: 0.102722; batch adversarial loss: 0.507291\n",
      "epoch 67; iter: 0; batch classifier loss: 0.071817; batch adversarial loss: 0.446665\n",
      "epoch 68; iter: 0; batch classifier loss: 0.066295; batch adversarial loss: 0.474341\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063298; batch adversarial loss: 0.507430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.093575; batch adversarial loss: 0.413448\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078603; batch adversarial loss: 0.443738\n",
      "epoch 72; iter: 0; batch classifier loss: 0.067723; batch adversarial loss: 0.438425\n",
      "epoch 73; iter: 0; batch classifier loss: 0.129943; batch adversarial loss: 0.352220\n",
      "epoch 74; iter: 0; batch classifier loss: 0.103674; batch adversarial loss: 0.433213\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059726; batch adversarial loss: 0.428634\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064448; batch adversarial loss: 0.408329\n",
      "epoch 77; iter: 0; batch classifier loss: 0.091513; batch adversarial loss: 0.480042\n",
      "epoch 78; iter: 0; batch classifier loss: 0.109954; batch adversarial loss: 0.446491\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061025; batch adversarial loss: 0.496145\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068756; batch adversarial loss: 0.412864\n",
      "epoch 81; iter: 0; batch classifier loss: 0.045288; batch adversarial loss: 0.437167\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075343; batch adversarial loss: 0.441834\n",
      "epoch 83; iter: 0; batch classifier loss: 0.092162; batch adversarial loss: 0.426003\n",
      "epoch 84; iter: 0; batch classifier loss: 0.053650; batch adversarial loss: 0.399593\n",
      "epoch 85; iter: 0; batch classifier loss: 0.091907; batch adversarial loss: 0.498007\n",
      "epoch 86; iter: 0; batch classifier loss: 0.019006; batch adversarial loss: 0.412801\n",
      "epoch 87; iter: 0; batch classifier loss: 0.077419; batch adversarial loss: 0.481559\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051537; batch adversarial loss: 0.458686\n",
      "epoch 89; iter: 0; batch classifier loss: 0.062389; batch adversarial loss: 0.412380\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067113; batch adversarial loss: 0.469903\n",
      "epoch 91; iter: 0; batch classifier loss: 0.037700; batch adversarial loss: 0.317630\n",
      "epoch 92; iter: 0; batch classifier loss: 0.092802; batch adversarial loss: 0.474623\n",
      "epoch 93; iter: 0; batch classifier loss: 0.095174; batch adversarial loss: 0.417731\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038938; batch adversarial loss: 0.422888\n",
      "epoch 95; iter: 0; batch classifier loss: 0.109923; batch adversarial loss: 0.369026\n",
      "epoch 96; iter: 0; batch classifier loss: 0.085316; batch adversarial loss: 0.499219\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051804; batch adversarial loss: 0.422821\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052286; batch adversarial loss: 0.422699\n",
      "epoch 99; iter: 0; batch classifier loss: 0.080126; batch adversarial loss: 0.544396\n",
      "epoch 100; iter: 0; batch classifier loss: 0.022228; batch adversarial loss: 0.569207\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065432; batch adversarial loss: 0.380791\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047642; batch adversarial loss: 0.381852\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046280; batch adversarial loss: 0.510885\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062127; batch adversarial loss: 0.488354\n",
      "epoch 105; iter: 0; batch classifier loss: 0.070084; batch adversarial loss: 0.374002\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063838; batch adversarial loss: 0.411124\n",
      "epoch 107; iter: 0; batch classifier loss: 0.079646; batch adversarial loss: 0.349210\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033461; batch adversarial loss: 0.355228\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037297; batch adversarial loss: 0.464064\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042452; batch adversarial loss: 0.400667\n",
      "epoch 111; iter: 0; batch classifier loss: 0.038806; batch adversarial loss: 0.442516\n",
      "epoch 112; iter: 0; batch classifier loss: 0.028514; batch adversarial loss: 0.522067\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037976; batch adversarial loss: 0.412301\n",
      "epoch 114; iter: 0; batch classifier loss: 0.038617; batch adversarial loss: 0.387967\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057373; batch adversarial loss: 0.379925\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058505; batch adversarial loss: 0.494722\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061166; batch adversarial loss: 0.434840\n",
      "epoch 118; iter: 0; batch classifier loss: 0.098645; batch adversarial loss: 0.438108\n",
      "epoch 119; iter: 0; batch classifier loss: 0.069770; batch adversarial loss: 0.501508\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057276; batch adversarial loss: 0.395177\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026148; batch adversarial loss: 0.395510\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051540; batch adversarial loss: 0.471196\n",
      "epoch 123; iter: 0; batch classifier loss: 0.058174; batch adversarial loss: 0.451062\n",
      "epoch 124; iter: 0; batch classifier loss: 0.079917; batch adversarial loss: 0.498692\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028618; batch adversarial loss: 0.445293\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046236; batch adversarial loss: 0.463824\n",
      "epoch 127; iter: 0; batch classifier loss: 0.018892; batch adversarial loss: 0.477579\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047717; batch adversarial loss: 0.486602\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051976; batch adversarial loss: 0.378353\n",
      "epoch 130; iter: 0; batch classifier loss: 0.055522; batch adversarial loss: 0.384499\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049178; batch adversarial loss: 0.429804\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025353; batch adversarial loss: 0.481343\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023099; batch adversarial loss: 0.380559\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024794; batch adversarial loss: 0.430839\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060748; batch adversarial loss: 0.408114\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049914; batch adversarial loss: 0.438715\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052742; batch adversarial loss: 0.456072\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024073; batch adversarial loss: 0.440195\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031818; batch adversarial loss: 0.382067\n",
      "epoch 140; iter: 0; batch classifier loss: 0.010091; batch adversarial loss: 0.389822\n",
      "epoch 141; iter: 0; batch classifier loss: 0.060959; batch adversarial loss: 0.336896\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014122; batch adversarial loss: 0.494347\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029275; batch adversarial loss: 0.404980\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033042; batch adversarial loss: 0.455887\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043081; batch adversarial loss: 0.397829\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024930; batch adversarial loss: 0.490348\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041027; batch adversarial loss: 0.428797\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036762; batch adversarial loss: 0.494361\n",
      "epoch 149; iter: 0; batch classifier loss: 0.049098; batch adversarial loss: 0.456346\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034287; batch adversarial loss: 0.413220\n",
      "epoch 151; iter: 0; batch classifier loss: 0.052802; batch adversarial loss: 0.442702\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044119; batch adversarial loss: 0.491162\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021244; batch adversarial loss: 0.416746\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017576; batch adversarial loss: 0.440665\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045435; batch adversarial loss: 0.420601\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035074; batch adversarial loss: 0.359018\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011941; batch adversarial loss: 0.461802\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029342; batch adversarial loss: 0.350178\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031138; batch adversarial loss: 0.439536\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032963; batch adversarial loss: 0.436543\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010335; batch adversarial loss: 0.506201\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046132; batch adversarial loss: 0.394167\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007842; batch adversarial loss: 0.338477\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032865; batch adversarial loss: 0.387771\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018992; batch adversarial loss: 0.482415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.007359; batch adversarial loss: 0.413259\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017263; batch adversarial loss: 0.356536\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033079; batch adversarial loss: 0.364576\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036090; batch adversarial loss: 0.463418\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023626; batch adversarial loss: 0.400747\n",
      "epoch 171; iter: 0; batch classifier loss: 0.060203; batch adversarial loss: 0.406784\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026369; batch adversarial loss: 0.374484\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014250; batch adversarial loss: 0.442391\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025166; batch adversarial loss: 0.478586\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028732; batch adversarial loss: 0.381935\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016621; batch adversarial loss: 0.378783\n",
      "epoch 177; iter: 0; batch classifier loss: 0.062274; batch adversarial loss: 0.419921\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022302; batch adversarial loss: 0.411433\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036144; batch adversarial loss: 0.422741\n",
      "epoch 180; iter: 0; batch classifier loss: 0.036584; batch adversarial loss: 0.426616\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021764; batch adversarial loss: 0.313546\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025995; batch adversarial loss: 0.426801\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022073; batch adversarial loss: 0.436977\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029813; batch adversarial loss: 0.490424\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017294; batch adversarial loss: 0.430386\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028759; batch adversarial loss: 0.381367\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034502; batch adversarial loss: 0.393147\n",
      "epoch 188; iter: 0; batch classifier loss: 0.050877; batch adversarial loss: 0.414550\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020679; batch adversarial loss: 0.475419\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010373; batch adversarial loss: 0.447542\n",
      "epoch 191; iter: 0; batch classifier loss: 0.003207; batch adversarial loss: 0.439758\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033208; batch adversarial loss: 0.394068\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028144; batch adversarial loss: 0.422978\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028470; batch adversarial loss: 0.451811\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029231; batch adversarial loss: 0.458118\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020206; batch adversarial loss: 0.459690\n",
      "epoch 197; iter: 0; batch classifier loss: 0.050175; batch adversarial loss: 0.390433\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010283; batch adversarial loss: 0.297948\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009815; batch adversarial loss: 0.378186\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674607; batch adversarial loss: 0.686277\n",
      "epoch 1; iter: 0; batch classifier loss: 0.431909; batch adversarial loss: 0.652436\n",
      "epoch 2; iter: 0; batch classifier loss: 0.460838; batch adversarial loss: 0.606581\n",
      "epoch 3; iter: 0; batch classifier loss: 0.381831; batch adversarial loss: 0.571877\n",
      "epoch 4; iter: 0; batch classifier loss: 0.343052; batch adversarial loss: 0.556264\n",
      "epoch 5; iter: 0; batch classifier loss: 0.382066; batch adversarial loss: 0.551239\n",
      "epoch 6; iter: 0; batch classifier loss: 0.234677; batch adversarial loss: 0.560751\n",
      "epoch 7; iter: 0; batch classifier loss: 0.304645; batch adversarial loss: 0.552232\n",
      "epoch 8; iter: 0; batch classifier loss: 0.255341; batch adversarial loss: 0.520739\n",
      "epoch 9; iter: 0; batch classifier loss: 0.289290; batch adversarial loss: 0.499961\n",
      "epoch 10; iter: 0; batch classifier loss: 0.284867; batch adversarial loss: 0.534923\n",
      "epoch 11; iter: 0; batch classifier loss: 0.284645; batch adversarial loss: 0.490240\n",
      "epoch 12; iter: 0; batch classifier loss: 0.277682; batch adversarial loss: 0.558670\n",
      "epoch 13; iter: 0; batch classifier loss: 0.191717; batch adversarial loss: 0.500968\n",
      "epoch 14; iter: 0; batch classifier loss: 0.306980; batch adversarial loss: 0.566321\n",
      "epoch 15; iter: 0; batch classifier loss: 0.215171; batch adversarial loss: 0.443247\n",
      "epoch 16; iter: 0; batch classifier loss: 0.272469; batch adversarial loss: 0.475995\n",
      "epoch 17; iter: 0; batch classifier loss: 0.235540; batch adversarial loss: 0.508200\n",
      "epoch 18; iter: 0; batch classifier loss: 0.373906; batch adversarial loss: 0.532449\n",
      "epoch 19; iter: 0; batch classifier loss: 0.426349; batch adversarial loss: 0.530335\n",
      "epoch 20; iter: 0; batch classifier loss: 0.479694; batch adversarial loss: 0.499570\n",
      "epoch 21; iter: 0; batch classifier loss: 0.420732; batch adversarial loss: 0.529048\n",
      "epoch 22; iter: 0; batch classifier loss: 0.378030; batch adversarial loss: 0.589381\n",
      "epoch 23; iter: 0; batch classifier loss: 0.318153; batch adversarial loss: 0.521176\n",
      "epoch 24; iter: 0; batch classifier loss: 0.224584; batch adversarial loss: 0.460795\n",
      "epoch 25; iter: 0; batch classifier loss: 0.163351; batch adversarial loss: 0.400435\n",
      "epoch 26; iter: 0; batch classifier loss: 0.144392; batch adversarial loss: 0.462645\n",
      "epoch 27; iter: 0; batch classifier loss: 0.190198; batch adversarial loss: 0.512115\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173366; batch adversarial loss: 0.364391\n",
      "epoch 29; iter: 0; batch classifier loss: 0.110297; batch adversarial loss: 0.490797\n",
      "epoch 30; iter: 0; batch classifier loss: 0.210613; batch adversarial loss: 0.542410\n",
      "epoch 31; iter: 0; batch classifier loss: 0.164045; batch adversarial loss: 0.494843\n",
      "epoch 32; iter: 0; batch classifier loss: 0.138963; batch adversarial loss: 0.511505\n",
      "epoch 33; iter: 0; batch classifier loss: 0.112246; batch adversarial loss: 0.489421\n",
      "epoch 34; iter: 0; batch classifier loss: 0.171105; batch adversarial loss: 0.503384\n",
      "epoch 35; iter: 0; batch classifier loss: 0.135562; batch adversarial loss: 0.480174\n",
      "epoch 36; iter: 0; batch classifier loss: 0.106346; batch adversarial loss: 0.459005\n",
      "epoch 37; iter: 0; batch classifier loss: 0.127945; batch adversarial loss: 0.529085\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148111; batch adversarial loss: 0.556655\n",
      "epoch 39; iter: 0; batch classifier loss: 0.162346; batch adversarial loss: 0.439397\n",
      "epoch 40; iter: 0; batch classifier loss: 0.122720; batch adversarial loss: 0.471408\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125352; batch adversarial loss: 0.520841\n",
      "epoch 42; iter: 0; batch classifier loss: 0.128958; batch adversarial loss: 0.418409\n",
      "epoch 43; iter: 0; batch classifier loss: 0.100758; batch adversarial loss: 0.501735\n",
      "epoch 44; iter: 0; batch classifier loss: 0.125634; batch adversarial loss: 0.425216\n",
      "epoch 45; iter: 0; batch classifier loss: 0.084196; batch adversarial loss: 0.381994\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112849; batch adversarial loss: 0.539993\n",
      "epoch 47; iter: 0; batch classifier loss: 0.181972; batch adversarial loss: 0.496223\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141133; batch adversarial loss: 0.462623\n",
      "epoch 49; iter: 0; batch classifier loss: 0.142234; batch adversarial loss: 0.498391\n",
      "epoch 50; iter: 0; batch classifier loss: 0.085760; batch adversarial loss: 0.562285\n",
      "epoch 51; iter: 0; batch classifier loss: 0.123269; batch adversarial loss: 0.512928\n",
      "epoch 52; iter: 0; batch classifier loss: 0.122791; batch adversarial loss: 0.444806\n",
      "epoch 53; iter: 0; batch classifier loss: 0.102089; batch adversarial loss: 0.504356\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122635; batch adversarial loss: 0.528614\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101497; batch adversarial loss: 0.415644\n",
      "epoch 56; iter: 0; batch classifier loss: 0.166608; batch adversarial loss: 0.404545\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107524; batch adversarial loss: 0.481920\n",
      "epoch 58; iter: 0; batch classifier loss: 0.154085; batch adversarial loss: 0.452232\n",
      "epoch 59; iter: 0; batch classifier loss: 0.163324; batch adversarial loss: 0.500301\n",
      "epoch 60; iter: 0; batch classifier loss: 0.169470; batch adversarial loss: 0.418737\n",
      "epoch 61; iter: 0; batch classifier loss: 0.155637; batch adversarial loss: 0.437686\n",
      "epoch 62; iter: 0; batch classifier loss: 0.152326; batch adversarial loss: 0.437194\n",
      "epoch 63; iter: 0; batch classifier loss: 0.158553; batch adversarial loss: 0.473679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.086021; batch adversarial loss: 0.521647\n",
      "epoch 65; iter: 0; batch classifier loss: 0.169589; batch adversarial loss: 0.427446\n",
      "epoch 66; iter: 0; batch classifier loss: 0.172441; batch adversarial loss: 0.520117\n",
      "epoch 67; iter: 0; batch classifier loss: 0.083932; batch adversarial loss: 0.442920\n",
      "epoch 68; iter: 0; batch classifier loss: 0.157649; batch adversarial loss: 0.448141\n",
      "epoch 69; iter: 0; batch classifier loss: 0.137786; batch adversarial loss: 0.346332\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090587; batch adversarial loss: 0.467000\n",
      "epoch 71; iter: 0; batch classifier loss: 0.108621; batch adversarial loss: 0.519044\n",
      "epoch 72; iter: 0; batch classifier loss: 0.115731; batch adversarial loss: 0.553286\n",
      "epoch 73; iter: 0; batch classifier loss: 0.118262; batch adversarial loss: 0.440327\n",
      "epoch 74; iter: 0; batch classifier loss: 0.180438; batch adversarial loss: 0.451407\n",
      "epoch 75; iter: 0; batch classifier loss: 0.090298; batch adversarial loss: 0.429656\n",
      "epoch 76; iter: 0; batch classifier loss: 0.124057; batch adversarial loss: 0.487244\n",
      "epoch 77; iter: 0; batch classifier loss: 0.085713; batch adversarial loss: 0.515122\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085109; batch adversarial loss: 0.516044\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061313; batch adversarial loss: 0.448303\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090184; batch adversarial loss: 0.458577\n",
      "epoch 81; iter: 0; batch classifier loss: 0.134891; batch adversarial loss: 0.402912\n",
      "epoch 82; iter: 0; batch classifier loss: 0.115700; batch adversarial loss: 0.445506\n",
      "epoch 83; iter: 0; batch classifier loss: 0.136037; batch adversarial loss: 0.567365\n",
      "epoch 84; iter: 0; batch classifier loss: 0.116495; batch adversarial loss: 0.475206\n",
      "epoch 85; iter: 0; batch classifier loss: 0.149080; batch adversarial loss: 0.478928\n",
      "epoch 86; iter: 0; batch classifier loss: 0.142967; batch adversarial loss: 0.428312\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076741; batch adversarial loss: 0.488585\n",
      "epoch 88; iter: 0; batch classifier loss: 0.110877; batch adversarial loss: 0.496642\n",
      "epoch 89; iter: 0; batch classifier loss: 0.128890; batch adversarial loss: 0.380484\n",
      "epoch 90; iter: 0; batch classifier loss: 0.115611; batch adversarial loss: 0.438346\n",
      "epoch 91; iter: 0; batch classifier loss: 0.139598; batch adversarial loss: 0.371697\n",
      "epoch 92; iter: 0; batch classifier loss: 0.149163; batch adversarial loss: 0.483974\n",
      "epoch 93; iter: 0; batch classifier loss: 0.108091; batch adversarial loss: 0.508858\n",
      "epoch 94; iter: 0; batch classifier loss: 0.092742; batch adversarial loss: 0.381787\n",
      "epoch 95; iter: 0; batch classifier loss: 0.108916; batch adversarial loss: 0.500427\n",
      "epoch 96; iter: 0; batch classifier loss: 0.073840; batch adversarial loss: 0.455038\n",
      "epoch 97; iter: 0; batch classifier loss: 0.100825; batch adversarial loss: 0.499882\n",
      "epoch 98; iter: 0; batch classifier loss: 0.075121; batch adversarial loss: 0.521936\n",
      "epoch 99; iter: 0; batch classifier loss: 0.080633; batch adversarial loss: 0.369205\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066702; batch adversarial loss: 0.497890\n",
      "epoch 101; iter: 0; batch classifier loss: 0.073908; batch adversarial loss: 0.414411\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063766; batch adversarial loss: 0.438435\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050727; batch adversarial loss: 0.420930\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071857; batch adversarial loss: 0.410146\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030904; batch adversarial loss: 0.461184\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049556; batch adversarial loss: 0.451029\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058935; batch adversarial loss: 0.444559\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046031; batch adversarial loss: 0.542827\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041887; batch adversarial loss: 0.465405\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056727; batch adversarial loss: 0.476197\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049742; batch adversarial loss: 0.487332\n",
      "epoch 112; iter: 0; batch classifier loss: 0.098149; batch adversarial loss: 0.431441\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058590; batch adversarial loss: 0.475672\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045480; batch adversarial loss: 0.403158\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054633; batch adversarial loss: 0.421863\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053598; batch adversarial loss: 0.429292\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060899; batch adversarial loss: 0.463383\n",
      "epoch 118; iter: 0; batch classifier loss: 0.071830; batch adversarial loss: 0.548971\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047140; batch adversarial loss: 0.386380\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041234; batch adversarial loss: 0.366705\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039566; batch adversarial loss: 0.427842\n",
      "epoch 122; iter: 0; batch classifier loss: 0.056226; batch adversarial loss: 0.514108\n",
      "epoch 123; iter: 0; batch classifier loss: 0.073584; batch adversarial loss: 0.467537\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042836; batch adversarial loss: 0.510220\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021929; batch adversarial loss: 0.479627\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019221; batch adversarial loss: 0.447585\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021575; batch adversarial loss: 0.484902\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061334; batch adversarial loss: 0.499839\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025019; batch adversarial loss: 0.437014\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021898; batch adversarial loss: 0.511310\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041693; batch adversarial loss: 0.468140\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024181; batch adversarial loss: 0.406242\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026142; batch adversarial loss: 0.435647\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049513; batch adversarial loss: 0.382465\n",
      "epoch 135; iter: 0; batch classifier loss: 0.053284; batch adversarial loss: 0.459415\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034222; batch adversarial loss: 0.460896\n",
      "epoch 137; iter: 0; batch classifier loss: 0.059189; batch adversarial loss: 0.488517\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019053; batch adversarial loss: 0.491227\n",
      "epoch 139; iter: 0; batch classifier loss: 0.008046; batch adversarial loss: 0.470610\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030236; batch adversarial loss: 0.524675\n",
      "epoch 141; iter: 0; batch classifier loss: 0.057273; batch adversarial loss: 0.435501\n",
      "epoch 142; iter: 0; batch classifier loss: 0.047787; batch adversarial loss: 0.389864\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025816; batch adversarial loss: 0.363394\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040039; batch adversarial loss: 0.393684\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023835; batch adversarial loss: 0.449937\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027146; batch adversarial loss: 0.496381\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014906; batch adversarial loss: 0.454960\n",
      "epoch 148; iter: 0; batch classifier loss: 0.071022; batch adversarial loss: 0.376101\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036055; batch adversarial loss: 0.420399\n",
      "epoch 150; iter: 0; batch classifier loss: 0.008058; batch adversarial loss: 0.477171\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020269; batch adversarial loss: 0.389110\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020151; batch adversarial loss: 0.576031\n",
      "epoch 153; iter: 0; batch classifier loss: 0.046795; batch adversarial loss: 0.446785\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037951; batch adversarial loss: 0.502693\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016215; batch adversarial loss: 0.491876\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040512; batch adversarial loss: 0.512167\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021454; batch adversarial loss: 0.484018\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036945; batch adversarial loss: 0.506343\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032107; batch adversarial loss: 0.527019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.017347; batch adversarial loss: 0.444748\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007107; batch adversarial loss: 0.581177\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020407; batch adversarial loss: 0.529282\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032557; batch adversarial loss: 0.469581\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015280; batch adversarial loss: 0.416167\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011462; batch adversarial loss: 0.555946\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028348; batch adversarial loss: 0.483258\n",
      "epoch 167; iter: 0; batch classifier loss: 0.003957; batch adversarial loss: 0.553308\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023082; batch adversarial loss: 0.457489\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019522; batch adversarial loss: 0.430860\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008085; batch adversarial loss: 0.469746\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022727; batch adversarial loss: 0.373058\n",
      "epoch 172; iter: 0; batch classifier loss: 0.069075; batch adversarial loss: 0.558691\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021251; batch adversarial loss: 0.495040\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022694; batch adversarial loss: 0.487101\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008107; batch adversarial loss: 0.436449\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022944; batch adversarial loss: 0.456070\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027864; batch adversarial loss: 0.459040\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026284; batch adversarial loss: 0.427487\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025280; batch adversarial loss: 0.368756\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011714; batch adversarial loss: 0.454330\n",
      "epoch 181; iter: 0; batch classifier loss: 0.040072; batch adversarial loss: 0.382077\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025479; batch adversarial loss: 0.512709\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016049; batch adversarial loss: 0.395454\n",
      "epoch 184; iter: 0; batch classifier loss: 0.054188; batch adversarial loss: 0.483714\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016428; batch adversarial loss: 0.543409\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018382; batch adversarial loss: 0.465713\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010170; batch adversarial loss: 0.528367\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022525; batch adversarial loss: 0.469868\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015615; batch adversarial loss: 0.530363\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033260; batch adversarial loss: 0.538463\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037988; batch adversarial loss: 0.485183\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008582; batch adversarial loss: 0.452069\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022827; batch adversarial loss: 0.499807\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027127; batch adversarial loss: 0.345762\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013845; batch adversarial loss: 0.462943\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020169; batch adversarial loss: 0.434366\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017091; batch adversarial loss: 0.402822\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024223; batch adversarial loss: 0.451756\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023080; batch adversarial loss: 0.413473\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710013; batch adversarial loss: 0.594114\n",
      "epoch 1; iter: 0; batch classifier loss: 0.419218; batch adversarial loss: 0.602840\n",
      "epoch 2; iter: 0; batch classifier loss: 0.353203; batch adversarial loss: 0.594392\n",
      "epoch 3; iter: 0; batch classifier loss: 0.370009; batch adversarial loss: 0.593067\n",
      "epoch 4; iter: 0; batch classifier loss: 0.373149; batch adversarial loss: 0.591116\n",
      "epoch 5; iter: 0; batch classifier loss: 0.373703; batch adversarial loss: 0.573776\n",
      "epoch 6; iter: 0; batch classifier loss: 0.365400; batch adversarial loss: 0.603037\n",
      "epoch 7; iter: 0; batch classifier loss: 0.371044; batch adversarial loss: 0.508925\n",
      "epoch 8; iter: 0; batch classifier loss: 0.376296; batch adversarial loss: 0.497886\n",
      "epoch 9; iter: 0; batch classifier loss: 0.338660; batch adversarial loss: 0.507544\n",
      "epoch 10; iter: 0; batch classifier loss: 0.498563; batch adversarial loss: 0.538601\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522081; batch adversarial loss: 0.570080\n",
      "epoch 12; iter: 0; batch classifier loss: 0.606023; batch adversarial loss: 0.582874\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548319; batch adversarial loss: 0.555912\n",
      "epoch 14; iter: 0; batch classifier loss: 0.408801; batch adversarial loss: 0.521269\n",
      "epoch 15; iter: 0; batch classifier loss: 0.288233; batch adversarial loss: 0.505188\n",
      "epoch 16; iter: 0; batch classifier loss: 0.251506; batch adversarial loss: 0.493323\n",
      "epoch 17; iter: 0; batch classifier loss: 0.259216; batch adversarial loss: 0.511671\n",
      "epoch 18; iter: 0; batch classifier loss: 0.248600; batch adversarial loss: 0.451465\n",
      "epoch 19; iter: 0; batch classifier loss: 0.186306; batch adversarial loss: 0.397121\n",
      "epoch 20; iter: 0; batch classifier loss: 0.169612; batch adversarial loss: 0.441939\n",
      "epoch 21; iter: 0; batch classifier loss: 0.148637; batch adversarial loss: 0.463113\n",
      "epoch 22; iter: 0; batch classifier loss: 0.214752; batch adversarial loss: 0.532015\n",
      "epoch 23; iter: 0; batch classifier loss: 0.187078; batch adversarial loss: 0.490447\n",
      "epoch 24; iter: 0; batch classifier loss: 0.198375; batch adversarial loss: 0.440019\n",
      "epoch 25; iter: 0; batch classifier loss: 0.149313; batch adversarial loss: 0.540478\n",
      "epoch 26; iter: 0; batch classifier loss: 0.155619; batch adversarial loss: 0.511504\n",
      "epoch 27; iter: 0; batch classifier loss: 0.150440; batch adversarial loss: 0.443659\n",
      "epoch 28; iter: 0; batch classifier loss: 0.139933; batch adversarial loss: 0.420613\n",
      "epoch 29; iter: 0; batch classifier loss: 0.138731; batch adversarial loss: 0.419155\n",
      "epoch 30; iter: 0; batch classifier loss: 0.183257; batch adversarial loss: 0.487550\n",
      "epoch 31; iter: 0; batch classifier loss: 0.144614; batch adversarial loss: 0.442526\n",
      "epoch 32; iter: 0; batch classifier loss: 0.147677; batch adversarial loss: 0.494554\n",
      "epoch 33; iter: 0; batch classifier loss: 0.149148; batch adversarial loss: 0.406278\n",
      "epoch 34; iter: 0; batch classifier loss: 0.081767; batch adversarial loss: 0.377733\n",
      "epoch 35; iter: 0; batch classifier loss: 0.103371; batch adversarial loss: 0.446720\n",
      "epoch 36; iter: 0; batch classifier loss: 0.121829; batch adversarial loss: 0.496704\n",
      "epoch 37; iter: 0; batch classifier loss: 0.100479; batch adversarial loss: 0.582750\n",
      "epoch 38; iter: 0; batch classifier loss: 0.135477; batch adversarial loss: 0.404238\n",
      "epoch 39; iter: 0; batch classifier loss: 0.078996; batch adversarial loss: 0.409275\n",
      "epoch 40; iter: 0; batch classifier loss: 0.128262; batch adversarial loss: 0.384512\n",
      "epoch 41; iter: 0; batch classifier loss: 0.127716; batch adversarial loss: 0.454964\n",
      "epoch 42; iter: 0; batch classifier loss: 0.118808; batch adversarial loss: 0.468706\n",
      "epoch 43; iter: 0; batch classifier loss: 0.079934; batch adversarial loss: 0.462088\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118819; batch adversarial loss: 0.426859\n",
      "epoch 45; iter: 0; batch classifier loss: 0.146167; batch adversarial loss: 0.498191\n",
      "epoch 46; iter: 0; batch classifier loss: 0.087407; batch adversarial loss: 0.325601\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113900; batch adversarial loss: 0.517272\n",
      "epoch 48; iter: 0; batch classifier loss: 0.110843; batch adversarial loss: 0.422406\n",
      "epoch 49; iter: 0; batch classifier loss: 0.093624; batch adversarial loss: 0.426522\n",
      "epoch 50; iter: 0; batch classifier loss: 0.090707; batch adversarial loss: 0.487082\n",
      "epoch 51; iter: 0; batch classifier loss: 0.103013; batch adversarial loss: 0.457617\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109050; batch adversarial loss: 0.476853\n",
      "epoch 53; iter: 0; batch classifier loss: 0.147810; batch adversarial loss: 0.520595\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102659; batch adversarial loss: 0.463468\n",
      "epoch 55; iter: 0; batch classifier loss: 0.067839; batch adversarial loss: 0.434004\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101489; batch adversarial loss: 0.436394\n",
      "epoch 57; iter: 0; batch classifier loss: 0.101514; batch adversarial loss: 0.474830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.094813; batch adversarial loss: 0.396544\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090465; batch adversarial loss: 0.408705\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079445; batch adversarial loss: 0.457984\n",
      "epoch 61; iter: 0; batch classifier loss: 0.109012; batch adversarial loss: 0.377523\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078098; batch adversarial loss: 0.523463\n",
      "epoch 63; iter: 0; batch classifier loss: 0.062106; batch adversarial loss: 0.384863\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106114; batch adversarial loss: 0.389290\n",
      "epoch 65; iter: 0; batch classifier loss: 0.066072; batch adversarial loss: 0.500591\n",
      "epoch 66; iter: 0; batch classifier loss: 0.123205; batch adversarial loss: 0.371132\n",
      "epoch 67; iter: 0; batch classifier loss: 0.077535; batch adversarial loss: 0.431426\n",
      "epoch 68; iter: 0; batch classifier loss: 0.106130; batch adversarial loss: 0.348369\n",
      "epoch 69; iter: 0; batch classifier loss: 0.112897; batch adversarial loss: 0.517657\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065186; batch adversarial loss: 0.432226\n",
      "epoch 71; iter: 0; batch classifier loss: 0.134693; batch adversarial loss: 0.382367\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072941; batch adversarial loss: 0.423364\n",
      "epoch 73; iter: 0; batch classifier loss: 0.080135; batch adversarial loss: 0.477866\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067086; batch adversarial loss: 0.433925\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063112; batch adversarial loss: 0.417786\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086927; batch adversarial loss: 0.442904\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065832; batch adversarial loss: 0.450583\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066491; batch adversarial loss: 0.408197\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063398; batch adversarial loss: 0.446351\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061826; batch adversarial loss: 0.463750\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068274; batch adversarial loss: 0.530798\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075273; batch adversarial loss: 0.500910\n",
      "epoch 83; iter: 0; batch classifier loss: 0.106240; batch adversarial loss: 0.415909\n",
      "epoch 84; iter: 0; batch classifier loss: 0.073294; batch adversarial loss: 0.444533\n",
      "epoch 85; iter: 0; batch classifier loss: 0.081085; batch adversarial loss: 0.449831\n",
      "epoch 86; iter: 0; batch classifier loss: 0.120379; batch adversarial loss: 0.448959\n",
      "epoch 87; iter: 0; batch classifier loss: 0.093142; batch adversarial loss: 0.371234\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055123; batch adversarial loss: 0.437117\n",
      "epoch 89; iter: 0; batch classifier loss: 0.079615; batch adversarial loss: 0.506196\n",
      "epoch 90; iter: 0; batch classifier loss: 0.092696; batch adversarial loss: 0.458437\n",
      "epoch 91; iter: 0; batch classifier loss: 0.105552; batch adversarial loss: 0.475300\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051749; batch adversarial loss: 0.391054\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043973; batch adversarial loss: 0.461271\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046492; batch adversarial loss: 0.457724\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056866; batch adversarial loss: 0.386693\n",
      "epoch 96; iter: 0; batch classifier loss: 0.039154; batch adversarial loss: 0.456288\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042639; batch adversarial loss: 0.386748\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042854; batch adversarial loss: 0.519860\n",
      "epoch 99; iter: 0; batch classifier loss: 0.021556; batch adversarial loss: 0.443437\n",
      "epoch 100; iter: 0; batch classifier loss: 0.042853; batch adversarial loss: 0.398975\n",
      "epoch 101; iter: 0; batch classifier loss: 0.033796; batch adversarial loss: 0.470561\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060279; batch adversarial loss: 0.436704\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056030; batch adversarial loss: 0.580909\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039063; batch adversarial loss: 0.496885\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040463; batch adversarial loss: 0.563629\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064443; batch adversarial loss: 0.493774\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069137; batch adversarial loss: 0.520986\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053484; batch adversarial loss: 0.423847\n",
      "epoch 109; iter: 0; batch classifier loss: 0.080598; batch adversarial loss: 0.426944\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041371; batch adversarial loss: 0.556324\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043964; batch adversarial loss: 0.402960\n",
      "epoch 112; iter: 0; batch classifier loss: 0.079160; batch adversarial loss: 0.333226\n",
      "epoch 113; iter: 0; batch classifier loss: 0.018273; batch adversarial loss: 0.446607\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034543; batch adversarial loss: 0.399795\n",
      "epoch 115; iter: 0; batch classifier loss: 0.068402; batch adversarial loss: 0.347984\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026794; batch adversarial loss: 0.430588\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044325; batch adversarial loss: 0.557956\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041737; batch adversarial loss: 0.430946\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031248; batch adversarial loss: 0.393979\n",
      "epoch 120; iter: 0; batch classifier loss: 0.063411; batch adversarial loss: 0.510828\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034930; batch adversarial loss: 0.489789\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021512; batch adversarial loss: 0.528872\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051669; batch adversarial loss: 0.502895\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031524; batch adversarial loss: 0.452098\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021895; batch adversarial loss: 0.404362\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022971; batch adversarial loss: 0.431844\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020007; batch adversarial loss: 0.360248\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027727; batch adversarial loss: 0.469690\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040732; batch adversarial loss: 0.444375\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034786; batch adversarial loss: 0.465913\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030445; batch adversarial loss: 0.461205\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027996; batch adversarial loss: 0.351117\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035088; batch adversarial loss: 0.427660\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035440; batch adversarial loss: 0.418294\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039826; batch adversarial loss: 0.453182\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037623; batch adversarial loss: 0.543858\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020972; batch adversarial loss: 0.460279\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044155; batch adversarial loss: 0.451561\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043271; batch adversarial loss: 0.393042\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048437; batch adversarial loss: 0.469671\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041650; batch adversarial loss: 0.476241\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021260; batch adversarial loss: 0.513444\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050885; batch adversarial loss: 0.460468\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038347; batch adversarial loss: 0.565873\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024218; batch adversarial loss: 0.515267\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026614; batch adversarial loss: 0.478231\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029321; batch adversarial loss: 0.432488\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027701; batch adversarial loss: 0.483051\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025700; batch adversarial loss: 0.437002\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027200; batch adversarial loss: 0.552227\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028152; batch adversarial loss: 0.476092\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013524; batch adversarial loss: 0.445153\n",
      "epoch 153; iter: 0; batch classifier loss: 0.041366; batch adversarial loss: 0.487256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.029134; batch adversarial loss: 0.490104\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049885; batch adversarial loss: 0.461492\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031910; batch adversarial loss: 0.454117\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011277; batch adversarial loss: 0.535572\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016174; batch adversarial loss: 0.473078\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036698; batch adversarial loss: 0.485051\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024751; batch adversarial loss: 0.409640\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026942; batch adversarial loss: 0.380273\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017623; batch adversarial loss: 0.455269\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040018; batch adversarial loss: 0.464896\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024624; batch adversarial loss: 0.523978\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032262; batch adversarial loss: 0.419748\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043597; batch adversarial loss: 0.452757\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013082; batch adversarial loss: 0.384800\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020735; batch adversarial loss: 0.450937\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044676; batch adversarial loss: 0.425346\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012663; batch adversarial loss: 0.498240\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014568; batch adversarial loss: 0.417679\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011025; batch adversarial loss: 0.426470\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030037; batch adversarial loss: 0.488654\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019776; batch adversarial loss: 0.480447\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020414; batch adversarial loss: 0.610289\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010614; batch adversarial loss: 0.494037\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030413; batch adversarial loss: 0.453756\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014885; batch adversarial loss: 0.369054\n",
      "epoch 179; iter: 0; batch classifier loss: 0.054826; batch adversarial loss: 0.452757\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032709; batch adversarial loss: 0.476131\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008779; batch adversarial loss: 0.567255\n",
      "epoch 182; iter: 0; batch classifier loss: 0.039370; batch adversarial loss: 0.494548\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015328; batch adversarial loss: 0.481969\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017966; batch adversarial loss: 0.439586\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016360; batch adversarial loss: 0.474757\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017080; batch adversarial loss: 0.318720\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006050; batch adversarial loss: 0.453124\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028078; batch adversarial loss: 0.425941\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016886; batch adversarial loss: 0.452808\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014193; batch adversarial loss: 0.475003\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008607; batch adversarial loss: 0.554796\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013061; batch adversarial loss: 0.408116\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026457; batch adversarial loss: 0.443008\n",
      "epoch 194; iter: 0; batch classifier loss: 0.057692; batch adversarial loss: 0.455205\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008725; batch adversarial loss: 0.502012\n",
      "epoch 196; iter: 0; batch classifier loss: 0.051037; batch adversarial loss: 0.464024\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022949; batch adversarial loss: 0.425802\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006009; batch adversarial loss: 0.476342\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016908; batch adversarial loss: 0.356020\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674637; batch adversarial loss: 0.727821\n",
      "epoch 1; iter: 0; batch classifier loss: 0.495363; batch adversarial loss: 0.687849\n",
      "epoch 2; iter: 0; batch classifier loss: 0.381440; batch adversarial loss: 0.647911\n",
      "epoch 3; iter: 0; batch classifier loss: 0.319390; batch adversarial loss: 0.626496\n",
      "epoch 4; iter: 0; batch classifier loss: 0.426989; batch adversarial loss: 0.600804\n",
      "epoch 5; iter: 0; batch classifier loss: 0.347427; batch adversarial loss: 0.605752\n",
      "epoch 6; iter: 0; batch classifier loss: 0.285803; batch adversarial loss: 0.567641\n",
      "epoch 7; iter: 0; batch classifier loss: 0.250653; batch adversarial loss: 0.577104\n",
      "epoch 8; iter: 0; batch classifier loss: 0.313138; batch adversarial loss: 0.504232\n",
      "epoch 9; iter: 0; batch classifier loss: 0.256798; batch adversarial loss: 0.472438\n",
      "epoch 10; iter: 0; batch classifier loss: 0.306009; batch adversarial loss: 0.507672\n",
      "epoch 11; iter: 0; batch classifier loss: 0.261947; batch adversarial loss: 0.486861\n",
      "epoch 12; iter: 0; batch classifier loss: 0.240527; batch adversarial loss: 0.574206\n",
      "epoch 13; iter: 0; batch classifier loss: 0.277575; batch adversarial loss: 0.517447\n",
      "epoch 14; iter: 0; batch classifier loss: 0.336890; batch adversarial loss: 0.518390\n",
      "epoch 15; iter: 0; batch classifier loss: 0.438814; batch adversarial loss: 0.455630\n",
      "epoch 16; iter: 0; batch classifier loss: 0.370889; batch adversarial loss: 0.481157\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348100; batch adversarial loss: 0.515448\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221621; batch adversarial loss: 0.491627\n",
      "epoch 19; iter: 0; batch classifier loss: 0.252268; batch adversarial loss: 0.492409\n",
      "epoch 20; iter: 0; batch classifier loss: 0.177878; batch adversarial loss: 0.498262\n",
      "epoch 21; iter: 0; batch classifier loss: 0.206612; batch adversarial loss: 0.424723\n",
      "epoch 22; iter: 0; batch classifier loss: 0.207510; batch adversarial loss: 0.420791\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171972; batch adversarial loss: 0.402779\n",
      "epoch 24; iter: 0; batch classifier loss: 0.172929; batch adversarial loss: 0.486571\n",
      "epoch 25; iter: 0; batch classifier loss: 0.211333; batch adversarial loss: 0.551300\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180765; batch adversarial loss: 0.496830\n",
      "epoch 27; iter: 0; batch classifier loss: 0.137688; batch adversarial loss: 0.504409\n",
      "epoch 28; iter: 0; batch classifier loss: 0.165837; batch adversarial loss: 0.409976\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180873; batch adversarial loss: 0.403310\n",
      "epoch 30; iter: 0; batch classifier loss: 0.177764; batch adversarial loss: 0.382338\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170880; batch adversarial loss: 0.454681\n",
      "epoch 32; iter: 0; batch classifier loss: 0.121390; batch adversarial loss: 0.427118\n",
      "epoch 33; iter: 0; batch classifier loss: 0.177972; batch adversarial loss: 0.491371\n",
      "epoch 34; iter: 0; batch classifier loss: 0.241676; batch adversarial loss: 0.438082\n",
      "epoch 35; iter: 0; batch classifier loss: 0.138653; batch adversarial loss: 0.448908\n",
      "epoch 36; iter: 0; batch classifier loss: 0.159080; batch adversarial loss: 0.411865\n",
      "epoch 37; iter: 0; batch classifier loss: 0.134774; batch adversarial loss: 0.423137\n",
      "epoch 38; iter: 0; batch classifier loss: 0.149098; batch adversarial loss: 0.532526\n",
      "epoch 39; iter: 0; batch classifier loss: 0.121482; batch adversarial loss: 0.475342\n",
      "epoch 40; iter: 0; batch classifier loss: 0.153844; batch adversarial loss: 0.445625\n",
      "epoch 41; iter: 0; batch classifier loss: 0.110699; batch adversarial loss: 0.498910\n",
      "epoch 42; iter: 0; batch classifier loss: 0.141753; batch adversarial loss: 0.523083\n",
      "epoch 43; iter: 0; batch classifier loss: 0.098601; batch adversarial loss: 0.488596\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127316; batch adversarial loss: 0.418778\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103693; batch adversarial loss: 0.379849\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112902; batch adversarial loss: 0.416520\n",
      "epoch 47; iter: 0; batch classifier loss: 0.142160; batch adversarial loss: 0.345955\n",
      "epoch 48; iter: 0; batch classifier loss: 0.084205; batch adversarial loss: 0.443238\n",
      "epoch 49; iter: 0; batch classifier loss: 0.127584; batch adversarial loss: 0.408275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.105631; batch adversarial loss: 0.390893\n",
      "epoch 51; iter: 0; batch classifier loss: 0.079063; batch adversarial loss: 0.312970\n",
      "epoch 52; iter: 0; batch classifier loss: 0.080645; batch adversarial loss: 0.400319\n",
      "epoch 53; iter: 0; batch classifier loss: 0.082286; batch adversarial loss: 0.483048\n",
      "epoch 54; iter: 0; batch classifier loss: 0.104699; batch adversarial loss: 0.476964\n",
      "epoch 55; iter: 0; batch classifier loss: 0.112678; batch adversarial loss: 0.477478\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119112; batch adversarial loss: 0.483416\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095668; batch adversarial loss: 0.538232\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093846; batch adversarial loss: 0.495986\n",
      "epoch 59; iter: 0; batch classifier loss: 0.158841; batch adversarial loss: 0.449552\n",
      "epoch 60; iter: 0; batch classifier loss: 0.127452; batch adversarial loss: 0.441365\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105185; batch adversarial loss: 0.429846\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075805; batch adversarial loss: 0.417344\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070531; batch adversarial loss: 0.479472\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084829; batch adversarial loss: 0.468572\n",
      "epoch 65; iter: 0; batch classifier loss: 0.104223; batch adversarial loss: 0.403566\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070852; batch adversarial loss: 0.500845\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096745; batch adversarial loss: 0.434583\n",
      "epoch 68; iter: 0; batch classifier loss: 0.107606; batch adversarial loss: 0.451303\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065016; batch adversarial loss: 0.426705\n",
      "epoch 70; iter: 0; batch classifier loss: 0.072158; batch adversarial loss: 0.449456\n",
      "epoch 71; iter: 0; batch classifier loss: 0.100194; batch adversarial loss: 0.537715\n",
      "epoch 72; iter: 0; batch classifier loss: 0.110754; batch adversarial loss: 0.425822\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084133; batch adversarial loss: 0.469076\n",
      "epoch 74; iter: 0; batch classifier loss: 0.111587; batch adversarial loss: 0.472151\n",
      "epoch 75; iter: 0; batch classifier loss: 0.084910; batch adversarial loss: 0.409637\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059187; batch adversarial loss: 0.461259\n",
      "epoch 77; iter: 0; batch classifier loss: 0.113436; batch adversarial loss: 0.483003\n",
      "epoch 78; iter: 0; batch classifier loss: 0.069033; batch adversarial loss: 0.500984\n",
      "epoch 79; iter: 0; batch classifier loss: 0.097055; batch adversarial loss: 0.438471\n",
      "epoch 80; iter: 0; batch classifier loss: 0.091127; batch adversarial loss: 0.376889\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069444; batch adversarial loss: 0.453881\n",
      "epoch 82; iter: 0; batch classifier loss: 0.141333; batch adversarial loss: 0.441191\n",
      "epoch 83; iter: 0; batch classifier loss: 0.115566; batch adversarial loss: 0.471354\n",
      "epoch 84; iter: 0; batch classifier loss: 0.096827; batch adversarial loss: 0.423461\n",
      "epoch 85; iter: 0; batch classifier loss: 0.078120; batch adversarial loss: 0.472204\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067171; batch adversarial loss: 0.421664\n",
      "epoch 87; iter: 0; batch classifier loss: 0.092891; batch adversarial loss: 0.469826\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069479; batch adversarial loss: 0.494933\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098142; batch adversarial loss: 0.422814\n",
      "epoch 90; iter: 0; batch classifier loss: 0.090401; batch adversarial loss: 0.442278\n",
      "epoch 91; iter: 0; batch classifier loss: 0.040450; batch adversarial loss: 0.405153\n",
      "epoch 92; iter: 0; batch classifier loss: 0.085869; batch adversarial loss: 0.396343\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055456; batch adversarial loss: 0.388137\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048009; batch adversarial loss: 0.428714\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080705; batch adversarial loss: 0.431679\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056280; batch adversarial loss: 0.462268\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049314; batch adversarial loss: 0.429856\n",
      "epoch 98; iter: 0; batch classifier loss: 0.087730; batch adversarial loss: 0.403191\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042116; batch adversarial loss: 0.474946\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054876; batch adversarial loss: 0.440733\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048038; batch adversarial loss: 0.390260\n",
      "epoch 102; iter: 0; batch classifier loss: 0.040624; batch adversarial loss: 0.452916\n",
      "epoch 103; iter: 0; batch classifier loss: 0.026203; batch adversarial loss: 0.419568\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053104; batch adversarial loss: 0.454117\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048802; batch adversarial loss: 0.491425\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057663; batch adversarial loss: 0.445465\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052498; batch adversarial loss: 0.411800\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057826; batch adversarial loss: 0.443936\n",
      "epoch 109; iter: 0; batch classifier loss: 0.022560; batch adversarial loss: 0.405736\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042969; batch adversarial loss: 0.453720\n",
      "epoch 111; iter: 0; batch classifier loss: 0.013819; batch adversarial loss: 0.456310\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037886; batch adversarial loss: 0.500039\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040745; batch adversarial loss: 0.432846\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042502; batch adversarial loss: 0.374160\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060412; batch adversarial loss: 0.464773\n",
      "epoch 116; iter: 0; batch classifier loss: 0.025124; batch adversarial loss: 0.424641\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042788; batch adversarial loss: 0.376347\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025885; batch adversarial loss: 0.431964\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029151; batch adversarial loss: 0.423825\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042813; batch adversarial loss: 0.322438\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043506; batch adversarial loss: 0.529491\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044695; batch adversarial loss: 0.524771\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029617; batch adversarial loss: 0.511122\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024169; batch adversarial loss: 0.401665\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036819; batch adversarial loss: 0.463503\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020778; batch adversarial loss: 0.530707\n",
      "epoch 127; iter: 0; batch classifier loss: 0.018918; batch adversarial loss: 0.516507\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038363; batch adversarial loss: 0.462230\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016476; batch adversarial loss: 0.465534\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045634; batch adversarial loss: 0.476519\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015201; batch adversarial loss: 0.495112\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027381; batch adversarial loss: 0.405418\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018072; batch adversarial loss: 0.448047\n",
      "epoch 134; iter: 0; batch classifier loss: 0.047979; batch adversarial loss: 0.438388\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038036; batch adversarial loss: 0.481472\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046736; batch adversarial loss: 0.430437\n",
      "epoch 137; iter: 0; batch classifier loss: 0.056166; batch adversarial loss: 0.427447\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027570; batch adversarial loss: 0.629497\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018901; batch adversarial loss: 0.473989\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044738; batch adversarial loss: 0.322033\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037575; batch adversarial loss: 0.474798\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020619; batch adversarial loss: 0.484790\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035258; batch adversarial loss: 0.409941\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018904; batch adversarial loss: 0.537385\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024633; batch adversarial loss: 0.419118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.054909; batch adversarial loss: 0.415671\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023269; batch adversarial loss: 0.538655\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035722; batch adversarial loss: 0.464874\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028861; batch adversarial loss: 0.527562\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017973; batch adversarial loss: 0.503543\n",
      "epoch 151; iter: 0; batch classifier loss: 0.003310; batch adversarial loss: 0.455278\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038813; batch adversarial loss: 0.443823\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029611; batch adversarial loss: 0.447269\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023387; batch adversarial loss: 0.449396\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031955; batch adversarial loss: 0.449103\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031097; batch adversarial loss: 0.416443\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046698; batch adversarial loss: 0.382237\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009529; batch adversarial loss: 0.459718\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014123; batch adversarial loss: 0.378962\n",
      "epoch 160; iter: 0; batch classifier loss: 0.050892; batch adversarial loss: 0.408601\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020368; batch adversarial loss: 0.399888\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028077; batch adversarial loss: 0.567031\n",
      "epoch 163; iter: 0; batch classifier loss: 0.044789; batch adversarial loss: 0.471379\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021779; batch adversarial loss: 0.478062\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027584; batch adversarial loss: 0.446620\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010605; batch adversarial loss: 0.562743\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029506; batch adversarial loss: 0.464851\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017915; batch adversarial loss: 0.491776\n",
      "epoch 169; iter: 0; batch classifier loss: 0.061589; batch adversarial loss: 0.455541\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011821; batch adversarial loss: 0.471211\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009611; batch adversarial loss: 0.420199\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027615; batch adversarial loss: 0.599704\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010597; batch adversarial loss: 0.500479\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020378; batch adversarial loss: 0.367268\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016564; batch adversarial loss: 0.436017\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031639; batch adversarial loss: 0.510846\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033698; batch adversarial loss: 0.452842\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012107; batch adversarial loss: 0.493929\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016114; batch adversarial loss: 0.407264\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040437; batch adversarial loss: 0.526177\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013820; batch adversarial loss: 0.440245\n",
      "epoch 182; iter: 0; batch classifier loss: 0.046564; batch adversarial loss: 0.508025\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021519; batch adversarial loss: 0.462629\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012172; batch adversarial loss: 0.368491\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020699; batch adversarial loss: 0.447150\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015139; batch adversarial loss: 0.467085\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020359; batch adversarial loss: 0.419635\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016475; batch adversarial loss: 0.410829\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009984; batch adversarial loss: 0.368424\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016809; batch adversarial loss: 0.427786\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007893; batch adversarial loss: 0.443069\n",
      "epoch 192; iter: 0; batch classifier loss: 0.038151; batch adversarial loss: 0.429829\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014238; batch adversarial loss: 0.446096\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009813; batch adversarial loss: 0.419679\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014975; batch adversarial loss: 0.457585\n",
      "epoch 196; iter: 0; batch classifier loss: 0.041327; batch adversarial loss: 0.561710\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029606; batch adversarial loss: 0.448350\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021976; batch adversarial loss: 0.381895\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017429; batch adversarial loss: 0.411052\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728612; batch adversarial loss: 0.527717\n",
      "epoch 1; iter: 0; batch classifier loss: 0.401689; batch adversarial loss: 0.610244\n",
      "epoch 2; iter: 0; batch classifier loss: 0.382187; batch adversarial loss: 0.554405\n",
      "epoch 3; iter: 0; batch classifier loss: 0.409364; batch adversarial loss: 0.530942\n",
      "epoch 4; iter: 0; batch classifier loss: 0.293380; batch adversarial loss: 0.555468\n",
      "epoch 5; iter: 0; batch classifier loss: 0.273722; batch adversarial loss: 0.533045\n",
      "epoch 6; iter: 0; batch classifier loss: 0.243952; batch adversarial loss: 0.611389\n",
      "epoch 7; iter: 0; batch classifier loss: 0.247940; batch adversarial loss: 0.625546\n",
      "epoch 8; iter: 0; batch classifier loss: 0.237037; batch adversarial loss: 0.548617\n",
      "epoch 9; iter: 0; batch classifier loss: 0.227605; batch adversarial loss: 0.499782\n",
      "epoch 10; iter: 0; batch classifier loss: 0.216957; batch adversarial loss: 0.567012\n",
      "epoch 11; iter: 0; batch classifier loss: 0.270627; batch adversarial loss: 0.544651\n",
      "epoch 12; iter: 0; batch classifier loss: 0.255407; batch adversarial loss: 0.538718\n",
      "epoch 13; iter: 0; batch classifier loss: 0.204588; batch adversarial loss: 0.559660\n",
      "epoch 14; iter: 0; batch classifier loss: 0.189801; batch adversarial loss: 0.523405\n",
      "epoch 15; iter: 0; batch classifier loss: 0.264444; batch adversarial loss: 0.605331\n",
      "epoch 16; iter: 0; batch classifier loss: 0.176722; batch adversarial loss: 0.498372\n",
      "epoch 17; iter: 0; batch classifier loss: 0.226029; batch adversarial loss: 0.477579\n",
      "epoch 18; iter: 0; batch classifier loss: 0.170807; batch adversarial loss: 0.511975\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247098; batch adversarial loss: 0.549796\n",
      "epoch 20; iter: 0; batch classifier loss: 0.181450; batch adversarial loss: 0.508074\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234364; batch adversarial loss: 0.566698\n",
      "epoch 22; iter: 0; batch classifier loss: 0.258669; batch adversarial loss: 0.581804\n",
      "epoch 23; iter: 0; batch classifier loss: 0.292356; batch adversarial loss: 0.627880\n",
      "epoch 24; iter: 0; batch classifier loss: 0.234041; batch adversarial loss: 0.506860\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209560; batch adversarial loss: 0.483646\n",
      "epoch 26; iter: 0; batch classifier loss: 0.271474; batch adversarial loss: 0.518856\n",
      "epoch 27; iter: 0; batch classifier loss: 0.321715; batch adversarial loss: 0.489893\n",
      "epoch 28; iter: 0; batch classifier loss: 0.355457; batch adversarial loss: 0.468043\n",
      "epoch 29; iter: 0; batch classifier loss: 0.306049; batch adversarial loss: 0.475076\n",
      "epoch 30; iter: 0; batch classifier loss: 0.118667; batch adversarial loss: 0.507135\n",
      "epoch 31; iter: 0; batch classifier loss: 0.090892; batch adversarial loss: 0.469127\n",
      "epoch 32; iter: 0; batch classifier loss: 0.100947; batch adversarial loss: 0.452379\n",
      "epoch 33; iter: 0; batch classifier loss: 0.121139; batch adversarial loss: 0.528267\n",
      "epoch 34; iter: 0; batch classifier loss: 0.126442; batch adversarial loss: 0.389313\n",
      "epoch 35; iter: 0; batch classifier loss: 0.128746; batch adversarial loss: 0.474206\n",
      "epoch 36; iter: 0; batch classifier loss: 0.103817; batch adversarial loss: 0.487335\n",
      "epoch 37; iter: 0; batch classifier loss: 0.101309; batch adversarial loss: 0.362060\n",
      "epoch 38; iter: 0; batch classifier loss: 0.116464; batch adversarial loss: 0.478957\n",
      "epoch 39; iter: 0; batch classifier loss: 0.130493; batch adversarial loss: 0.375354\n",
      "epoch 40; iter: 0; batch classifier loss: 0.073159; batch adversarial loss: 0.506408\n",
      "epoch 41; iter: 0; batch classifier loss: 0.073428; batch adversarial loss: 0.396995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.095270; batch adversarial loss: 0.498689\n",
      "epoch 43; iter: 0; batch classifier loss: 0.095177; batch adversarial loss: 0.434139\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097520; batch adversarial loss: 0.434188\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097128; batch adversarial loss: 0.536004\n",
      "epoch 46; iter: 0; batch classifier loss: 0.065443; batch adversarial loss: 0.509001\n",
      "epoch 47; iter: 0; batch classifier loss: 0.099782; batch adversarial loss: 0.430539\n",
      "epoch 48; iter: 0; batch classifier loss: 0.096894; batch adversarial loss: 0.402045\n",
      "epoch 49; iter: 0; batch classifier loss: 0.037772; batch adversarial loss: 0.569647\n",
      "epoch 50; iter: 0; batch classifier loss: 0.086401; batch adversarial loss: 0.408770\n",
      "epoch 51; iter: 0; batch classifier loss: 0.075269; batch adversarial loss: 0.364632\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089294; batch adversarial loss: 0.498092\n",
      "epoch 53; iter: 0; batch classifier loss: 0.068123; batch adversarial loss: 0.571362\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101406; batch adversarial loss: 0.431780\n",
      "epoch 55; iter: 0; batch classifier loss: 0.085147; batch adversarial loss: 0.515247\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082139; batch adversarial loss: 0.472097\n",
      "epoch 57; iter: 0; batch classifier loss: 0.052547; batch adversarial loss: 0.450505\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090843; batch adversarial loss: 0.389484\n",
      "epoch 59; iter: 0; batch classifier loss: 0.109147; batch adversarial loss: 0.413348\n",
      "epoch 60; iter: 0; batch classifier loss: 0.113596; batch adversarial loss: 0.404884\n",
      "epoch 61; iter: 0; batch classifier loss: 0.079616; batch adversarial loss: 0.426983\n",
      "epoch 62; iter: 0; batch classifier loss: 0.062506; batch adversarial loss: 0.471201\n",
      "epoch 63; iter: 0; batch classifier loss: 0.060940; batch adversarial loss: 0.458521\n",
      "epoch 64; iter: 0; batch classifier loss: 0.086607; batch adversarial loss: 0.471364\n",
      "epoch 65; iter: 0; batch classifier loss: 0.055446; batch adversarial loss: 0.407744\n",
      "epoch 66; iter: 0; batch classifier loss: 0.064586; batch adversarial loss: 0.376500\n",
      "epoch 67; iter: 0; batch classifier loss: 0.115486; batch adversarial loss: 0.395759\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071880; batch adversarial loss: 0.431845\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065760; batch adversarial loss: 0.492672\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098766; batch adversarial loss: 0.480227\n",
      "epoch 71; iter: 0; batch classifier loss: 0.070750; batch adversarial loss: 0.462878\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081141; batch adversarial loss: 0.364299\n",
      "epoch 73; iter: 0; batch classifier loss: 0.078482; batch adversarial loss: 0.475503\n",
      "epoch 74; iter: 0; batch classifier loss: 0.098455; batch adversarial loss: 0.416060\n",
      "epoch 75; iter: 0; batch classifier loss: 0.039145; batch adversarial loss: 0.540787\n",
      "epoch 76; iter: 0; batch classifier loss: 0.111712; batch adversarial loss: 0.476552\n",
      "epoch 77; iter: 0; batch classifier loss: 0.034517; batch adversarial loss: 0.398910\n",
      "epoch 78; iter: 0; batch classifier loss: 0.078173; batch adversarial loss: 0.330074\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099631; batch adversarial loss: 0.438890\n",
      "epoch 80; iter: 0; batch classifier loss: 0.108475; batch adversarial loss: 0.480096\n",
      "epoch 81; iter: 0; batch classifier loss: 0.038830; batch adversarial loss: 0.563841\n",
      "epoch 82; iter: 0; batch classifier loss: 0.118460; batch adversarial loss: 0.430481\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074192; batch adversarial loss: 0.417411\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080449; batch adversarial loss: 0.481615\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045958; batch adversarial loss: 0.452940\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072572; batch adversarial loss: 0.504062\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059165; batch adversarial loss: 0.455106\n",
      "epoch 88; iter: 0; batch classifier loss: 0.060544; batch adversarial loss: 0.442887\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080162; batch adversarial loss: 0.542064\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075879; batch adversarial loss: 0.419035\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045558; batch adversarial loss: 0.484512\n",
      "epoch 92; iter: 0; batch classifier loss: 0.073866; batch adversarial loss: 0.447917\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066919; batch adversarial loss: 0.376989\n",
      "epoch 94; iter: 0; batch classifier loss: 0.099879; batch adversarial loss: 0.390903\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068030; batch adversarial loss: 0.416900\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082106; batch adversarial loss: 0.389163\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064540; batch adversarial loss: 0.475396\n",
      "epoch 98; iter: 0; batch classifier loss: 0.088769; batch adversarial loss: 0.473619\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073239; batch adversarial loss: 0.346672\n",
      "epoch 100; iter: 0; batch classifier loss: 0.080000; batch adversarial loss: 0.456210\n",
      "epoch 101; iter: 0; batch classifier loss: 0.085823; batch adversarial loss: 0.427717\n",
      "epoch 102; iter: 0; batch classifier loss: 0.065772; batch adversarial loss: 0.374217\n",
      "epoch 103; iter: 0; batch classifier loss: 0.018423; batch adversarial loss: 0.510759\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060689; batch adversarial loss: 0.505852\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030393; batch adversarial loss: 0.391607\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061187; batch adversarial loss: 0.381803\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065370; batch adversarial loss: 0.450167\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065736; batch adversarial loss: 0.407888\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051548; batch adversarial loss: 0.439909\n",
      "epoch 110; iter: 0; batch classifier loss: 0.087698; batch adversarial loss: 0.375784\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041333; batch adversarial loss: 0.427893\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059003; batch adversarial loss: 0.492356\n",
      "epoch 113; iter: 0; batch classifier loss: 0.075260; batch adversarial loss: 0.440242\n",
      "epoch 114; iter: 0; batch classifier loss: 0.058662; batch adversarial loss: 0.403879\n",
      "epoch 115; iter: 0; batch classifier loss: 0.017452; batch adversarial loss: 0.430514\n",
      "epoch 116; iter: 0; batch classifier loss: 0.069035; batch adversarial loss: 0.453002\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034992; batch adversarial loss: 0.432685\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045468; batch adversarial loss: 0.352710\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054946; batch adversarial loss: 0.464314\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041620; batch adversarial loss: 0.464603\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042477; batch adversarial loss: 0.483064\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029544; batch adversarial loss: 0.509334\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048217; batch adversarial loss: 0.449062\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059709; batch adversarial loss: 0.332749\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033792; batch adversarial loss: 0.471692\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063332; batch adversarial loss: 0.370140\n",
      "epoch 127; iter: 0; batch classifier loss: 0.015092; batch adversarial loss: 0.374682\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052797; batch adversarial loss: 0.446712\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048658; batch adversarial loss: 0.567595\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036742; batch adversarial loss: 0.484492\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040025; batch adversarial loss: 0.434915\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038165; batch adversarial loss: 0.492010\n",
      "epoch 133; iter: 0; batch classifier loss: 0.062585; batch adversarial loss: 0.475083\n",
      "epoch 134; iter: 0; batch classifier loss: 0.078446; batch adversarial loss: 0.380831\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027864; batch adversarial loss: 0.407916\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049544; batch adversarial loss: 0.434886\n",
      "epoch 137; iter: 0; batch classifier loss: 0.075586; batch adversarial loss: 0.452009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.013818; batch adversarial loss: 0.426843\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030104; batch adversarial loss: 0.516857\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026310; batch adversarial loss: 0.368933\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034306; batch adversarial loss: 0.461239\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020462; batch adversarial loss: 0.451820\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037910; batch adversarial loss: 0.465085\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025096; batch adversarial loss: 0.475258\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039553; batch adversarial loss: 0.504975\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023054; batch adversarial loss: 0.431413\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031914; batch adversarial loss: 0.453400\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013527; batch adversarial loss: 0.450341\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035935; batch adversarial loss: 0.518649\n",
      "epoch 150; iter: 0; batch classifier loss: 0.053125; batch adversarial loss: 0.474671\n",
      "epoch 151; iter: 0; batch classifier loss: 0.056391; batch adversarial loss: 0.455955\n",
      "epoch 152; iter: 0; batch classifier loss: 0.056567; batch adversarial loss: 0.453762\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008082; batch adversarial loss: 0.467248\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023921; batch adversarial loss: 0.501136\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021979; batch adversarial loss: 0.415855\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021239; batch adversarial loss: 0.497649\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031012; batch adversarial loss: 0.426216\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038006; batch adversarial loss: 0.389077\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013975; batch adversarial loss: 0.480662\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044894; batch adversarial loss: 0.524092\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027735; batch adversarial loss: 0.459272\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031302; batch adversarial loss: 0.411242\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027091; batch adversarial loss: 0.454707\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028521; batch adversarial loss: 0.444762\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025287; batch adversarial loss: 0.421807\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040523; batch adversarial loss: 0.416229\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039888; batch adversarial loss: 0.527322\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022915; batch adversarial loss: 0.510458\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009082; batch adversarial loss: 0.419762\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015824; batch adversarial loss: 0.488259\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015632; batch adversarial loss: 0.570700\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012744; batch adversarial loss: 0.521534\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035638; batch adversarial loss: 0.476378\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038426; batch adversarial loss: 0.433094\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040357; batch adversarial loss: 0.391321\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015993; batch adversarial loss: 0.422391\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038374; batch adversarial loss: 0.414055\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018548; batch adversarial loss: 0.476432\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023572; batch adversarial loss: 0.425068\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021681; batch adversarial loss: 0.351456\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022451; batch adversarial loss: 0.425862\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028003; batch adversarial loss: 0.505849\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031556; batch adversarial loss: 0.434645\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034535; batch adversarial loss: 0.433580\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018736; batch adversarial loss: 0.389274\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015336; batch adversarial loss: 0.409512\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012642; batch adversarial loss: 0.517674\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040349; batch adversarial loss: 0.495646\n",
      "epoch 189; iter: 0; batch classifier loss: 0.053656; batch adversarial loss: 0.513749\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025223; batch adversarial loss: 0.422378\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033294; batch adversarial loss: 0.470278\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021024; batch adversarial loss: 0.442656\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025836; batch adversarial loss: 0.537435\n",
      "epoch 194; iter: 0; batch classifier loss: 0.047661; batch adversarial loss: 0.431533\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016405; batch adversarial loss: 0.547332\n",
      "epoch 196; iter: 0; batch classifier loss: 0.039170; batch adversarial loss: 0.531491\n",
      "epoch 197; iter: 0; batch classifier loss: 0.040461; batch adversarial loss: 0.462848\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012142; batch adversarial loss: 0.382192\n",
      "epoch 199; iter: 0; batch classifier loss: 0.038166; batch adversarial loss: 0.468261\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679008; batch adversarial loss: 0.590591\n",
      "epoch 1; iter: 0; batch classifier loss: 0.508733; batch adversarial loss: 0.630624\n",
      "epoch 2; iter: 0; batch classifier loss: 0.412074; batch adversarial loss: 0.633141\n",
      "epoch 3; iter: 0; batch classifier loss: 0.426336; batch adversarial loss: 0.680092\n",
      "epoch 4; iter: 0; batch classifier loss: 0.401457; batch adversarial loss: 0.639276\n",
      "epoch 5; iter: 0; batch classifier loss: 0.534645; batch adversarial loss: 0.590602\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584391; batch adversarial loss: 0.610761\n",
      "epoch 7; iter: 0; batch classifier loss: 0.513451; batch adversarial loss: 0.612210\n",
      "epoch 8; iter: 0; batch classifier loss: 0.595767; batch adversarial loss: 0.586595\n",
      "epoch 9; iter: 0; batch classifier loss: 0.464662; batch adversarial loss: 0.552802\n",
      "epoch 10; iter: 0; batch classifier loss: 0.363408; batch adversarial loss: 0.524781\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371130; batch adversarial loss: 0.555444\n",
      "epoch 12; iter: 0; batch classifier loss: 0.339258; batch adversarial loss: 0.591594\n",
      "epoch 13; iter: 0; batch classifier loss: 0.274107; batch adversarial loss: 0.493516\n",
      "epoch 14; iter: 0; batch classifier loss: 0.262192; batch adversarial loss: 0.542547\n",
      "epoch 15; iter: 0; batch classifier loss: 0.301084; batch adversarial loss: 0.480837\n",
      "epoch 16; iter: 0; batch classifier loss: 0.287279; batch adversarial loss: 0.433338\n",
      "epoch 17; iter: 0; batch classifier loss: 0.288989; batch adversarial loss: 0.479665\n",
      "epoch 18; iter: 0; batch classifier loss: 0.285737; batch adversarial loss: 0.410293\n",
      "epoch 19; iter: 0; batch classifier loss: 0.254928; batch adversarial loss: 0.464572\n",
      "epoch 20; iter: 0; batch classifier loss: 0.236408; batch adversarial loss: 0.450754\n",
      "epoch 21; iter: 0; batch classifier loss: 0.270748; batch adversarial loss: 0.528741\n",
      "epoch 22; iter: 0; batch classifier loss: 0.203707; batch adversarial loss: 0.486071\n",
      "epoch 23; iter: 0; batch classifier loss: 0.268707; batch adversarial loss: 0.468542\n",
      "epoch 24; iter: 0; batch classifier loss: 0.197598; batch adversarial loss: 0.460953\n",
      "epoch 25; iter: 0; batch classifier loss: 0.147569; batch adversarial loss: 0.501759\n",
      "epoch 26; iter: 0; batch classifier loss: 0.166986; batch adversarial loss: 0.454244\n",
      "epoch 27; iter: 0; batch classifier loss: 0.194202; batch adversarial loss: 0.476352\n",
      "epoch 28; iter: 0; batch classifier loss: 0.172615; batch adversarial loss: 0.464085\n",
      "epoch 29; iter: 0; batch classifier loss: 0.167217; batch adversarial loss: 0.480810\n",
      "epoch 30; iter: 0; batch classifier loss: 0.170754; batch adversarial loss: 0.482725\n",
      "epoch 31; iter: 0; batch classifier loss: 0.199665; batch adversarial loss: 0.508913\n",
      "epoch 32; iter: 0; batch classifier loss: 0.168429; batch adversarial loss: 0.440675\n",
      "epoch 33; iter: 0; batch classifier loss: 0.241945; batch adversarial loss: 0.467417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.173839; batch adversarial loss: 0.520390\n",
      "epoch 35; iter: 0; batch classifier loss: 0.173078; batch adversarial loss: 0.466960\n",
      "epoch 36; iter: 0; batch classifier loss: 0.153214; batch adversarial loss: 0.503501\n",
      "epoch 37; iter: 0; batch classifier loss: 0.182071; batch adversarial loss: 0.456145\n",
      "epoch 38; iter: 0; batch classifier loss: 0.105738; batch adversarial loss: 0.454632\n",
      "epoch 39; iter: 0; batch classifier loss: 0.116652; batch adversarial loss: 0.501732\n",
      "epoch 40; iter: 0; batch classifier loss: 0.139640; batch adversarial loss: 0.588333\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106723; batch adversarial loss: 0.421598\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115486; batch adversarial loss: 0.425657\n",
      "epoch 43; iter: 0; batch classifier loss: 0.162328; batch adversarial loss: 0.439902\n",
      "epoch 44; iter: 0; batch classifier loss: 0.144998; batch adversarial loss: 0.476248\n",
      "epoch 45; iter: 0; batch classifier loss: 0.129399; batch adversarial loss: 0.482192\n",
      "epoch 46; iter: 0; batch classifier loss: 0.148455; batch adversarial loss: 0.402274\n",
      "epoch 47; iter: 0; batch classifier loss: 0.148452; batch adversarial loss: 0.484529\n",
      "epoch 48; iter: 0; batch classifier loss: 0.182428; batch adversarial loss: 0.511926\n",
      "epoch 49; iter: 0; batch classifier loss: 0.140838; batch adversarial loss: 0.554993\n",
      "epoch 50; iter: 0; batch classifier loss: 0.145307; batch adversarial loss: 0.484121\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109583; batch adversarial loss: 0.510682\n",
      "epoch 52; iter: 0; batch classifier loss: 0.146822; batch adversarial loss: 0.390518\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122036; batch adversarial loss: 0.534672\n",
      "epoch 54; iter: 0; batch classifier loss: 0.186370; batch adversarial loss: 0.504058\n",
      "epoch 55; iter: 0; batch classifier loss: 0.180983; batch adversarial loss: 0.434025\n",
      "epoch 56; iter: 0; batch classifier loss: 0.122500; batch adversarial loss: 0.513238\n",
      "epoch 57; iter: 0; batch classifier loss: 0.162802; batch adversarial loss: 0.526156\n",
      "epoch 58; iter: 0; batch classifier loss: 0.170425; batch adversarial loss: 0.541516\n",
      "epoch 59; iter: 0; batch classifier loss: 0.177944; batch adversarial loss: 0.466417\n",
      "epoch 60; iter: 0; batch classifier loss: 0.166403; batch adversarial loss: 0.424503\n",
      "epoch 61; iter: 0; batch classifier loss: 0.198267; batch adversarial loss: 0.447302\n",
      "epoch 62; iter: 0; batch classifier loss: 0.146359; batch adversarial loss: 0.487227\n",
      "epoch 63; iter: 0; batch classifier loss: 0.152818; batch adversarial loss: 0.447054\n",
      "epoch 64; iter: 0; batch classifier loss: 0.088676; batch adversarial loss: 0.452004\n",
      "epoch 65; iter: 0; batch classifier loss: 0.146900; batch adversarial loss: 0.505113\n",
      "epoch 66; iter: 0; batch classifier loss: 0.173338; batch adversarial loss: 0.582896\n",
      "epoch 67; iter: 0; batch classifier loss: 0.145227; batch adversarial loss: 0.542388\n",
      "epoch 68; iter: 0; batch classifier loss: 0.189010; batch adversarial loss: 0.330492\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095882; batch adversarial loss: 0.556631\n",
      "epoch 70; iter: 0; batch classifier loss: 0.138678; batch adversarial loss: 0.438643\n",
      "epoch 71; iter: 0; batch classifier loss: 0.101122; batch adversarial loss: 0.427874\n",
      "epoch 72; iter: 0; batch classifier loss: 0.184721; batch adversarial loss: 0.528589\n",
      "epoch 73; iter: 0; batch classifier loss: 0.137802; batch adversarial loss: 0.409476\n",
      "epoch 74; iter: 0; batch classifier loss: 0.190525; batch adversarial loss: 0.471242\n",
      "epoch 75; iter: 0; batch classifier loss: 0.132522; batch adversarial loss: 0.497826\n",
      "epoch 76; iter: 0; batch classifier loss: 0.167918; batch adversarial loss: 0.593014\n",
      "epoch 77; iter: 0; batch classifier loss: 0.105017; batch adversarial loss: 0.400257\n",
      "epoch 78; iter: 0; batch classifier loss: 0.147703; batch adversarial loss: 0.454628\n",
      "epoch 79; iter: 0; batch classifier loss: 0.180508; batch adversarial loss: 0.446850\n",
      "epoch 80; iter: 0; batch classifier loss: 0.166079; batch adversarial loss: 0.387932\n",
      "epoch 81; iter: 0; batch classifier loss: 0.133637; batch adversarial loss: 0.458940\n",
      "epoch 82; iter: 0; batch classifier loss: 0.101243; batch adversarial loss: 0.505898\n",
      "epoch 83; iter: 0; batch classifier loss: 0.099724; batch adversarial loss: 0.475670\n",
      "epoch 84; iter: 0; batch classifier loss: 0.136608; batch adversarial loss: 0.474398\n",
      "epoch 85; iter: 0; batch classifier loss: 0.165721; batch adversarial loss: 0.486044\n",
      "epoch 86; iter: 0; batch classifier loss: 0.180652; batch adversarial loss: 0.483828\n",
      "epoch 87; iter: 0; batch classifier loss: 0.092469; batch adversarial loss: 0.444263\n",
      "epoch 88; iter: 0; batch classifier loss: 0.113398; batch adversarial loss: 0.519851\n",
      "epoch 89; iter: 0; batch classifier loss: 0.120983; batch adversarial loss: 0.363317\n",
      "epoch 90; iter: 0; batch classifier loss: 0.126223; batch adversarial loss: 0.503287\n",
      "epoch 91; iter: 0; batch classifier loss: 0.143735; batch adversarial loss: 0.420598\n",
      "epoch 92; iter: 0; batch classifier loss: 0.150087; batch adversarial loss: 0.477541\n",
      "epoch 93; iter: 0; batch classifier loss: 0.159043; batch adversarial loss: 0.433265\n",
      "epoch 94; iter: 0; batch classifier loss: 0.093868; batch adversarial loss: 0.464447\n",
      "epoch 95; iter: 0; batch classifier loss: 0.124946; batch adversarial loss: 0.480955\n",
      "epoch 96; iter: 0; batch classifier loss: 0.069264; batch adversarial loss: 0.498547\n",
      "epoch 97; iter: 0; batch classifier loss: 0.093812; batch adversarial loss: 0.431395\n",
      "epoch 98; iter: 0; batch classifier loss: 0.071258; batch adversarial loss: 0.494539\n",
      "epoch 99; iter: 0; batch classifier loss: 0.101116; batch adversarial loss: 0.516739\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036116; batch adversarial loss: 0.599477\n",
      "epoch 101; iter: 0; batch classifier loss: 0.091456; batch adversarial loss: 0.527111\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071380; batch adversarial loss: 0.465668\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078739; batch adversarial loss: 0.544611\n",
      "epoch 104; iter: 0; batch classifier loss: 0.094394; batch adversarial loss: 0.491579\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076501; batch adversarial loss: 0.371850\n",
      "epoch 106; iter: 0; batch classifier loss: 0.095568; batch adversarial loss: 0.580185\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069048; batch adversarial loss: 0.436227\n",
      "epoch 108; iter: 0; batch classifier loss: 0.126567; batch adversarial loss: 0.493197\n",
      "epoch 109; iter: 0; batch classifier loss: 0.076616; batch adversarial loss: 0.439401\n",
      "epoch 110; iter: 0; batch classifier loss: 0.091611; batch adversarial loss: 0.507276\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042715; batch adversarial loss: 0.572659\n",
      "epoch 112; iter: 0; batch classifier loss: 0.106947; batch adversarial loss: 0.408148\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043102; batch adversarial loss: 0.341398\n",
      "epoch 114; iter: 0; batch classifier loss: 0.067856; batch adversarial loss: 0.535392\n",
      "epoch 115; iter: 0; batch classifier loss: 0.094450; batch adversarial loss: 0.462805\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041858; batch adversarial loss: 0.561699\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047050; batch adversarial loss: 0.487525\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029781; batch adversarial loss: 0.449975\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038403; batch adversarial loss: 0.496196\n",
      "epoch 120; iter: 0; batch classifier loss: 0.071134; batch adversarial loss: 0.448395\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050506; batch adversarial loss: 0.575525\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066494; batch adversarial loss: 0.402040\n",
      "epoch 123; iter: 0; batch classifier loss: 0.059387; batch adversarial loss: 0.481795\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033315; batch adversarial loss: 0.493925\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024695; batch adversarial loss: 0.522954\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032066; batch adversarial loss: 0.419434\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027004; batch adversarial loss: 0.548426\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043897; batch adversarial loss: 0.461252\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024613; batch adversarial loss: 0.491440\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017335; batch adversarial loss: 0.429584\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018411; batch adversarial loss: 0.452325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.020522; batch adversarial loss: 0.474828\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021654; batch adversarial loss: 0.430809\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039403; batch adversarial loss: 0.469808\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050285; batch adversarial loss: 0.413268\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026729; batch adversarial loss: 0.396005\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049338; batch adversarial loss: 0.555103\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014127; batch adversarial loss: 0.524225\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031862; batch adversarial loss: 0.329252\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045874; batch adversarial loss: 0.544292\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030988; batch adversarial loss: 0.475735\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022662; batch adversarial loss: 0.496740\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051037; batch adversarial loss: 0.493258\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017074; batch adversarial loss: 0.521433\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033368; batch adversarial loss: 0.433959\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038241; batch adversarial loss: 0.479417\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035420; batch adversarial loss: 0.467018\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017242; batch adversarial loss: 0.471125\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035425; batch adversarial loss: 0.400939\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040583; batch adversarial loss: 0.442115\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014635; batch adversarial loss: 0.497092\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031942; batch adversarial loss: 0.397260\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018047; batch adversarial loss: 0.525385\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028403; batch adversarial loss: 0.509614\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021836; batch adversarial loss: 0.430282\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022065; batch adversarial loss: 0.525223\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010242; batch adversarial loss: 0.503122\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042162; batch adversarial loss: 0.487432\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026646; batch adversarial loss: 0.395021\n",
      "epoch 160; iter: 0; batch classifier loss: 0.005584; batch adversarial loss: 0.398349\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033134; batch adversarial loss: 0.479113\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034530; batch adversarial loss: 0.439256\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012061; batch adversarial loss: 0.519766\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031850; batch adversarial loss: 0.534374\n",
      "epoch 165; iter: 0; batch classifier loss: 0.006508; batch adversarial loss: 0.524810\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022241; batch adversarial loss: 0.502657\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041125; batch adversarial loss: 0.470964\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007393; batch adversarial loss: 0.485208\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025803; batch adversarial loss: 0.422259\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010468; batch adversarial loss: 0.425069\n",
      "epoch 171; iter: 0; batch classifier loss: 0.002893; batch adversarial loss: 0.482401\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012633; batch adversarial loss: 0.422255\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010546; batch adversarial loss: 0.463149\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019568; batch adversarial loss: 0.498032\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035856; batch adversarial loss: 0.428536\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011260; batch adversarial loss: 0.456452\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026711; batch adversarial loss: 0.472568\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022415; batch adversarial loss: 0.479595\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028368; batch adversarial loss: 0.437265\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027962; batch adversarial loss: 0.414495\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023351; batch adversarial loss: 0.520123\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020851; batch adversarial loss: 0.502294\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010609; batch adversarial loss: 0.450401\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019293; batch adversarial loss: 0.462301\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017473; batch adversarial loss: 0.426280\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009908; batch adversarial loss: 0.406766\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009370; batch adversarial loss: 0.626307\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010519; batch adversarial loss: 0.459554\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009084; batch adversarial loss: 0.431342\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018388; batch adversarial loss: 0.394145\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011267; batch adversarial loss: 0.484940\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028044; batch adversarial loss: 0.498101\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012478; batch adversarial loss: 0.472183\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021735; batch adversarial loss: 0.362308\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018525; batch adversarial loss: 0.448142\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015249; batch adversarial loss: 0.464372\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013035; batch adversarial loss: 0.475131\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013997; batch adversarial loss: 0.457211\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011405; batch adversarial loss: 0.466147\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699761; batch adversarial loss: 0.575990\n",
      "epoch 1; iter: 0; batch classifier loss: 0.490057; batch adversarial loss: 0.568056\n",
      "epoch 2; iter: 0; batch classifier loss: 0.404091; batch adversarial loss: 0.565752\n",
      "epoch 3; iter: 0; batch classifier loss: 0.409846; batch adversarial loss: 0.596338\n",
      "epoch 4; iter: 0; batch classifier loss: 0.342359; batch adversarial loss: 0.564144\n",
      "epoch 5; iter: 0; batch classifier loss: 0.351613; batch adversarial loss: 0.618068\n",
      "epoch 6; iter: 0; batch classifier loss: 0.477161; batch adversarial loss: 0.594192\n",
      "epoch 7; iter: 0; batch classifier loss: 0.388182; batch adversarial loss: 0.588206\n",
      "epoch 8; iter: 0; batch classifier loss: 0.372878; batch adversarial loss: 0.605980\n",
      "epoch 9; iter: 0; batch classifier loss: 0.449556; batch adversarial loss: 0.576421\n",
      "epoch 10; iter: 0; batch classifier loss: 0.482499; batch adversarial loss: 0.571195\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553860; batch adversarial loss: 0.563313\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536034; batch adversarial loss: 0.528082\n",
      "epoch 13; iter: 0; batch classifier loss: 0.362622; batch adversarial loss: 0.473995\n",
      "epoch 14; iter: 0; batch classifier loss: 0.411180; batch adversarial loss: 0.571136\n",
      "epoch 15; iter: 0; batch classifier loss: 0.267470; batch adversarial loss: 0.465895\n",
      "epoch 16; iter: 0; batch classifier loss: 0.332291; batch adversarial loss: 0.557778\n",
      "epoch 17; iter: 0; batch classifier loss: 0.263552; batch adversarial loss: 0.516243\n",
      "epoch 18; iter: 0; batch classifier loss: 0.229550; batch adversarial loss: 0.452310\n",
      "epoch 19; iter: 0; batch classifier loss: 0.191459; batch adversarial loss: 0.529387\n",
      "epoch 20; iter: 0; batch classifier loss: 0.261910; batch adversarial loss: 0.420177\n",
      "epoch 21; iter: 0; batch classifier loss: 0.215080; batch adversarial loss: 0.439248\n",
      "epoch 22; iter: 0; batch classifier loss: 0.207492; batch adversarial loss: 0.467194\n",
      "epoch 23; iter: 0; batch classifier loss: 0.243764; batch adversarial loss: 0.408050\n",
      "epoch 24; iter: 0; batch classifier loss: 0.229910; batch adversarial loss: 0.489194\n",
      "epoch 25; iter: 0; batch classifier loss: 0.262047; batch adversarial loss: 0.460888\n",
      "epoch 26; iter: 0; batch classifier loss: 0.168111; batch adversarial loss: 0.519782\n",
      "epoch 27; iter: 0; batch classifier loss: 0.205206; batch adversarial loss: 0.524639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.133838; batch adversarial loss: 0.470612\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170213; batch adversarial loss: 0.467497\n",
      "epoch 30; iter: 0; batch classifier loss: 0.141005; batch adversarial loss: 0.436906\n",
      "epoch 31; iter: 0; batch classifier loss: 0.199476; batch adversarial loss: 0.445641\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140643; batch adversarial loss: 0.428363\n",
      "epoch 33; iter: 0; batch classifier loss: 0.131391; batch adversarial loss: 0.526150\n",
      "epoch 34; iter: 0; batch classifier loss: 0.153241; batch adversarial loss: 0.404282\n",
      "epoch 35; iter: 0; batch classifier loss: 0.106833; batch adversarial loss: 0.540200\n",
      "epoch 36; iter: 0; batch classifier loss: 0.138277; batch adversarial loss: 0.461891\n",
      "epoch 37; iter: 0; batch classifier loss: 0.150869; batch adversarial loss: 0.486848\n",
      "epoch 38; iter: 0; batch classifier loss: 0.130136; batch adversarial loss: 0.493993\n",
      "epoch 39; iter: 0; batch classifier loss: 0.096239; batch adversarial loss: 0.425928\n",
      "epoch 40; iter: 0; batch classifier loss: 0.126733; batch adversarial loss: 0.439418\n",
      "epoch 41; iter: 0; batch classifier loss: 0.157905; batch adversarial loss: 0.368246\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131012; batch adversarial loss: 0.463885\n",
      "epoch 43; iter: 0; batch classifier loss: 0.144805; batch adversarial loss: 0.489038\n",
      "epoch 44; iter: 0; batch classifier loss: 0.151746; batch adversarial loss: 0.359957\n",
      "epoch 45; iter: 0; batch classifier loss: 0.179592; batch adversarial loss: 0.396129\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103321; batch adversarial loss: 0.472082\n",
      "epoch 47; iter: 0; batch classifier loss: 0.109913; batch adversarial loss: 0.393059\n",
      "epoch 48; iter: 0; batch classifier loss: 0.088234; batch adversarial loss: 0.566864\n",
      "epoch 49; iter: 0; batch classifier loss: 0.062864; batch adversarial loss: 0.471292\n",
      "epoch 50; iter: 0; batch classifier loss: 0.141366; batch adversarial loss: 0.433030\n",
      "epoch 51; iter: 0; batch classifier loss: 0.148351; batch adversarial loss: 0.562222\n",
      "epoch 52; iter: 0; batch classifier loss: 0.102126; batch adversarial loss: 0.447174\n",
      "epoch 53; iter: 0; batch classifier loss: 0.148567; batch adversarial loss: 0.433538\n",
      "epoch 54; iter: 0; batch classifier loss: 0.142614; batch adversarial loss: 0.492839\n",
      "epoch 55; iter: 0; batch classifier loss: 0.182609; batch adversarial loss: 0.442851\n",
      "epoch 56; iter: 0; batch classifier loss: 0.086603; batch adversarial loss: 0.407828\n",
      "epoch 57; iter: 0; batch classifier loss: 0.130820; batch adversarial loss: 0.447939\n",
      "epoch 58; iter: 0; batch classifier loss: 0.100231; batch adversarial loss: 0.456287\n",
      "epoch 59; iter: 0; batch classifier loss: 0.112603; batch adversarial loss: 0.484560\n",
      "epoch 60; iter: 0; batch classifier loss: 0.158358; batch adversarial loss: 0.543839\n",
      "epoch 61; iter: 0; batch classifier loss: 0.129456; batch adversarial loss: 0.519442\n",
      "epoch 62; iter: 0; batch classifier loss: 0.138049; batch adversarial loss: 0.463235\n",
      "epoch 63; iter: 0; batch classifier loss: 0.163203; batch adversarial loss: 0.378286\n",
      "epoch 64; iter: 0; batch classifier loss: 0.159967; batch adversarial loss: 0.356523\n",
      "epoch 65; iter: 0; batch classifier loss: 0.130747; batch adversarial loss: 0.497243\n",
      "epoch 66; iter: 0; batch classifier loss: 0.135620; batch adversarial loss: 0.419474\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101227; batch adversarial loss: 0.421151\n",
      "epoch 68; iter: 0; batch classifier loss: 0.100928; batch adversarial loss: 0.417184\n",
      "epoch 69; iter: 0; batch classifier loss: 0.099524; batch adversarial loss: 0.453425\n",
      "epoch 70; iter: 0; batch classifier loss: 0.156049; batch adversarial loss: 0.521133\n",
      "epoch 71; iter: 0; batch classifier loss: 0.172141; batch adversarial loss: 0.463866\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085722; batch adversarial loss: 0.461116\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085873; batch adversarial loss: 0.358231\n",
      "epoch 74; iter: 0; batch classifier loss: 0.114934; batch adversarial loss: 0.379329\n",
      "epoch 75; iter: 0; batch classifier loss: 0.122582; batch adversarial loss: 0.451216\n",
      "epoch 76; iter: 0; batch classifier loss: 0.095934; batch adversarial loss: 0.504167\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087344; batch adversarial loss: 0.408666\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074631; batch adversarial loss: 0.348064\n",
      "epoch 79; iter: 0; batch classifier loss: 0.097420; batch adversarial loss: 0.530249\n",
      "epoch 80; iter: 0; batch classifier loss: 0.136494; batch adversarial loss: 0.381927\n",
      "epoch 81; iter: 0; batch classifier loss: 0.072453; batch adversarial loss: 0.431969\n",
      "epoch 82; iter: 0; batch classifier loss: 0.119821; batch adversarial loss: 0.467397\n",
      "epoch 83; iter: 0; batch classifier loss: 0.098357; batch adversarial loss: 0.571696\n",
      "epoch 84; iter: 0; batch classifier loss: 0.122162; batch adversarial loss: 0.458145\n",
      "epoch 85; iter: 0; batch classifier loss: 0.149068; batch adversarial loss: 0.454541\n",
      "epoch 86; iter: 0; batch classifier loss: 0.146371; batch adversarial loss: 0.427065\n",
      "epoch 87; iter: 0; batch classifier loss: 0.089139; batch adversarial loss: 0.432948\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075544; batch adversarial loss: 0.357527\n",
      "epoch 89; iter: 0; batch classifier loss: 0.095428; batch adversarial loss: 0.439470\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075587; batch adversarial loss: 0.406732\n",
      "epoch 91; iter: 0; batch classifier loss: 0.105236; batch adversarial loss: 0.524289\n",
      "epoch 92; iter: 0; batch classifier loss: 0.115683; batch adversarial loss: 0.474867\n",
      "epoch 93; iter: 0; batch classifier loss: 0.102156; batch adversarial loss: 0.505487\n",
      "epoch 94; iter: 0; batch classifier loss: 0.096336; batch adversarial loss: 0.404071\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071342; batch adversarial loss: 0.379978\n",
      "epoch 96; iter: 0; batch classifier loss: 0.103233; batch adversarial loss: 0.519172\n",
      "epoch 97; iter: 0; batch classifier loss: 0.078790; batch adversarial loss: 0.425344\n",
      "epoch 98; iter: 0; batch classifier loss: 0.090409; batch adversarial loss: 0.460218\n",
      "epoch 99; iter: 0; batch classifier loss: 0.083358; batch adversarial loss: 0.521488\n",
      "epoch 100; iter: 0; batch classifier loss: 0.089170; batch adversarial loss: 0.366741\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041367; batch adversarial loss: 0.556977\n",
      "epoch 102; iter: 0; batch classifier loss: 0.040540; batch adversarial loss: 0.419751\n",
      "epoch 103; iter: 0; batch classifier loss: 0.127187; batch adversarial loss: 0.355207\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047792; batch adversarial loss: 0.508104\n",
      "epoch 105; iter: 0; batch classifier loss: 0.068368; batch adversarial loss: 0.380667\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054171; batch adversarial loss: 0.426257\n",
      "epoch 107; iter: 0; batch classifier loss: 0.096744; batch adversarial loss: 0.377319\n",
      "epoch 108; iter: 0; batch classifier loss: 0.072924; batch adversarial loss: 0.415083\n",
      "epoch 109; iter: 0; batch classifier loss: 0.096492; batch adversarial loss: 0.337684\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059113; batch adversarial loss: 0.380464\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066815; batch adversarial loss: 0.420466\n",
      "epoch 112; iter: 0; batch classifier loss: 0.076796; batch adversarial loss: 0.440650\n",
      "epoch 113; iter: 0; batch classifier loss: 0.109198; batch adversarial loss: 0.412341\n",
      "epoch 114; iter: 0; batch classifier loss: 0.095959; batch adversarial loss: 0.408534\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043883; batch adversarial loss: 0.470281\n",
      "epoch 116; iter: 0; batch classifier loss: 0.071835; batch adversarial loss: 0.475853\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032596; batch adversarial loss: 0.457853\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048064; batch adversarial loss: 0.477829\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050327; batch adversarial loss: 0.534296\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062300; batch adversarial loss: 0.432628\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025444; batch adversarial loss: 0.510026\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036232; batch adversarial loss: 0.503402\n",
      "epoch 123; iter: 0; batch classifier loss: 0.056360; batch adversarial loss: 0.422912\n",
      "epoch 124; iter: 0; batch classifier loss: 0.053184; batch adversarial loss: 0.443243\n",
      "epoch 125; iter: 0; batch classifier loss: 0.075429; batch adversarial loss: 0.436672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.017404; batch adversarial loss: 0.499632\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060959; batch adversarial loss: 0.485200\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034990; batch adversarial loss: 0.546386\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038285; batch adversarial loss: 0.522344\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033263; batch adversarial loss: 0.402073\n",
      "epoch 131; iter: 0; batch classifier loss: 0.014608; batch adversarial loss: 0.451041\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039688; batch adversarial loss: 0.464513\n",
      "epoch 133; iter: 0; batch classifier loss: 0.047935; batch adversarial loss: 0.488035\n",
      "epoch 134; iter: 0; batch classifier loss: 0.078646; batch adversarial loss: 0.486492\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060904; batch adversarial loss: 0.499267\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021837; batch adversarial loss: 0.439046\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040474; batch adversarial loss: 0.463724\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038993; batch adversarial loss: 0.403127\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014296; batch adversarial loss: 0.441324\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023715; batch adversarial loss: 0.384280\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036252; batch adversarial loss: 0.396401\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035113; batch adversarial loss: 0.497682\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041575; batch adversarial loss: 0.361037\n",
      "epoch 144; iter: 0; batch classifier loss: 0.054094; batch adversarial loss: 0.449107\n",
      "epoch 145; iter: 0; batch classifier loss: 0.054347; batch adversarial loss: 0.432543\n",
      "epoch 146; iter: 0; batch classifier loss: 0.036964; batch adversarial loss: 0.372941\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031869; batch adversarial loss: 0.481646\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026016; batch adversarial loss: 0.490786\n",
      "epoch 149; iter: 0; batch classifier loss: 0.050927; batch adversarial loss: 0.453863\n",
      "epoch 150; iter: 0; batch classifier loss: 0.046943; batch adversarial loss: 0.454915\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030064; batch adversarial loss: 0.480663\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029943; batch adversarial loss: 0.489941\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024040; batch adversarial loss: 0.370020\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033234; batch adversarial loss: 0.463223\n",
      "epoch 155; iter: 0; batch classifier loss: 0.008714; batch adversarial loss: 0.487841\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030986; batch adversarial loss: 0.491298\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022178; batch adversarial loss: 0.498647\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047040; batch adversarial loss: 0.439404\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022314; batch adversarial loss: 0.485256\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024196; batch adversarial loss: 0.498022\n",
      "epoch 161; iter: 0; batch classifier loss: 0.046074; batch adversarial loss: 0.451312\n",
      "epoch 162; iter: 0; batch classifier loss: 0.045306; batch adversarial loss: 0.426726\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023974; batch adversarial loss: 0.486824\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010117; batch adversarial loss: 0.478035\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032237; batch adversarial loss: 0.519639\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017921; batch adversarial loss: 0.384875\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029386; batch adversarial loss: 0.524286\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029595; batch adversarial loss: 0.423660\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024740; batch adversarial loss: 0.467815\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022055; batch adversarial loss: 0.456470\n",
      "epoch 171; iter: 0; batch classifier loss: 0.045847; batch adversarial loss: 0.449752\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036002; batch adversarial loss: 0.504735\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040045; batch adversarial loss: 0.588932\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012337; batch adversarial loss: 0.349165\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025598; batch adversarial loss: 0.470794\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021697; batch adversarial loss: 0.513222\n",
      "epoch 177; iter: 0; batch classifier loss: 0.035351; batch adversarial loss: 0.323407\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009264; batch adversarial loss: 0.416353\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015149; batch adversarial loss: 0.482703\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012484; batch adversarial loss: 0.428545\n",
      "epoch 181; iter: 0; batch classifier loss: 0.044578; batch adversarial loss: 0.426817\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011446; batch adversarial loss: 0.457555\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019413; batch adversarial loss: 0.404189\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017637; batch adversarial loss: 0.407285\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020579; batch adversarial loss: 0.456295\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018289; batch adversarial loss: 0.423691\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019530; batch adversarial loss: 0.447004\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006578; batch adversarial loss: 0.481091\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017168; batch adversarial loss: 0.415227\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012221; batch adversarial loss: 0.420619\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017361; batch adversarial loss: 0.396699\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010481; batch adversarial loss: 0.365678\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028545; batch adversarial loss: 0.438660\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019072; batch adversarial loss: 0.481267\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016963; batch adversarial loss: 0.414362\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013931; batch adversarial loss: 0.355769\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014905; batch adversarial loss: 0.479365\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028112; batch adversarial loss: 0.520017\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011992; batch adversarial loss: 0.490765\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700286; batch adversarial loss: 0.594762\n",
      "epoch 1; iter: 0; batch classifier loss: 0.395860; batch adversarial loss: 0.599707\n",
      "epoch 2; iter: 0; batch classifier loss: 0.321779; batch adversarial loss: 0.577863\n",
      "epoch 3; iter: 0; batch classifier loss: 0.379526; batch adversarial loss: 0.579423\n",
      "epoch 4; iter: 0; batch classifier loss: 0.374604; batch adversarial loss: 0.570600\n",
      "epoch 5; iter: 0; batch classifier loss: 0.266725; batch adversarial loss: 0.561549\n",
      "epoch 6; iter: 0; batch classifier loss: 0.349120; batch adversarial loss: 0.490867\n",
      "epoch 7; iter: 0; batch classifier loss: 0.291818; batch adversarial loss: 0.553695\n",
      "epoch 8; iter: 0; batch classifier loss: 0.233441; batch adversarial loss: 0.526445\n",
      "epoch 9; iter: 0; batch classifier loss: 0.245296; batch adversarial loss: 0.525875\n",
      "epoch 10; iter: 0; batch classifier loss: 0.319116; batch adversarial loss: 0.632068\n",
      "epoch 11; iter: 0; batch classifier loss: 0.367925; batch adversarial loss: 0.571607\n",
      "epoch 12; iter: 0; batch classifier loss: 0.300202; batch adversarial loss: 0.451335\n",
      "epoch 13; iter: 0; batch classifier loss: 0.438812; batch adversarial loss: 0.611957\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478961; batch adversarial loss: 0.541523\n",
      "epoch 15; iter: 0; batch classifier loss: 0.550895; batch adversarial loss: 0.479628\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519601; batch adversarial loss: 0.521252\n",
      "epoch 17; iter: 0; batch classifier loss: 0.400864; batch adversarial loss: 0.517741\n",
      "epoch 18; iter: 0; batch classifier loss: 0.319042; batch adversarial loss: 0.447019\n",
      "epoch 19; iter: 0; batch classifier loss: 0.273442; batch adversarial loss: 0.452343\n",
      "epoch 20; iter: 0; batch classifier loss: 0.216529; batch adversarial loss: 0.490142\n",
      "epoch 21; iter: 0; batch classifier loss: 0.246858; batch adversarial loss: 0.430007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.196855; batch adversarial loss: 0.511412\n",
      "epoch 23; iter: 0; batch classifier loss: 0.238170; batch adversarial loss: 0.436974\n",
      "epoch 24; iter: 0; batch classifier loss: 0.157911; batch adversarial loss: 0.453929\n",
      "epoch 25; iter: 0; batch classifier loss: 0.222180; batch adversarial loss: 0.405134\n",
      "epoch 26; iter: 0; batch classifier loss: 0.169535; batch adversarial loss: 0.417755\n",
      "epoch 27; iter: 0; batch classifier loss: 0.219891; batch adversarial loss: 0.473518\n",
      "epoch 28; iter: 0; batch classifier loss: 0.181150; batch adversarial loss: 0.439125\n",
      "epoch 29; iter: 0; batch classifier loss: 0.211674; batch adversarial loss: 0.398745\n",
      "epoch 30; iter: 0; batch classifier loss: 0.154358; batch adversarial loss: 0.467489\n",
      "epoch 31; iter: 0; batch classifier loss: 0.129875; batch adversarial loss: 0.509081\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172013; batch adversarial loss: 0.485261\n",
      "epoch 33; iter: 0; batch classifier loss: 0.147610; batch adversarial loss: 0.459321\n",
      "epoch 34; iter: 0; batch classifier loss: 0.183012; batch adversarial loss: 0.398172\n",
      "epoch 35; iter: 0; batch classifier loss: 0.169971; batch adversarial loss: 0.387035\n",
      "epoch 36; iter: 0; batch classifier loss: 0.125943; batch adversarial loss: 0.423392\n",
      "epoch 37; iter: 0; batch classifier loss: 0.118693; batch adversarial loss: 0.423593\n",
      "epoch 38; iter: 0; batch classifier loss: 0.101909; batch adversarial loss: 0.536805\n",
      "epoch 39; iter: 0; batch classifier loss: 0.134075; batch adversarial loss: 0.483776\n",
      "epoch 40; iter: 0; batch classifier loss: 0.168143; batch adversarial loss: 0.554604\n",
      "epoch 41; iter: 0; batch classifier loss: 0.118015; batch adversarial loss: 0.506696\n",
      "epoch 42; iter: 0; batch classifier loss: 0.129801; batch adversarial loss: 0.473266\n",
      "epoch 43; iter: 0; batch classifier loss: 0.124616; batch adversarial loss: 0.551093\n",
      "epoch 44; iter: 0; batch classifier loss: 0.104945; batch adversarial loss: 0.452493\n",
      "epoch 45; iter: 0; batch classifier loss: 0.182464; batch adversarial loss: 0.491118\n",
      "epoch 46; iter: 0; batch classifier loss: 0.096986; batch adversarial loss: 0.477611\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106942; batch adversarial loss: 0.427836\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125649; batch adversarial loss: 0.441705\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099773; batch adversarial loss: 0.468185\n",
      "epoch 50; iter: 0; batch classifier loss: 0.092610; batch adversarial loss: 0.412304\n",
      "epoch 51; iter: 0; batch classifier loss: 0.165300; batch adversarial loss: 0.460254\n",
      "epoch 52; iter: 0; batch classifier loss: 0.158294; batch adversarial loss: 0.500422\n",
      "epoch 53; iter: 0; batch classifier loss: 0.137011; batch adversarial loss: 0.504490\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101285; batch adversarial loss: 0.444532\n",
      "epoch 55; iter: 0; batch classifier loss: 0.134342; batch adversarial loss: 0.378897\n",
      "epoch 56; iter: 0; batch classifier loss: 0.126871; batch adversarial loss: 0.479016\n",
      "epoch 57; iter: 0; batch classifier loss: 0.190406; batch adversarial loss: 0.433662\n",
      "epoch 58; iter: 0; batch classifier loss: 0.133498; batch adversarial loss: 0.535096\n",
      "epoch 59; iter: 0; batch classifier loss: 0.179590; batch adversarial loss: 0.511632\n",
      "epoch 60; iter: 0; batch classifier loss: 0.161435; batch adversarial loss: 0.454014\n",
      "epoch 61; iter: 0; batch classifier loss: 0.118917; batch adversarial loss: 0.451705\n",
      "epoch 62; iter: 0; batch classifier loss: 0.139475; batch adversarial loss: 0.473308\n",
      "epoch 63; iter: 0; batch classifier loss: 0.185841; batch adversarial loss: 0.446614\n",
      "epoch 64; iter: 0; batch classifier loss: 0.110813; batch adversarial loss: 0.521464\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122821; batch adversarial loss: 0.457006\n",
      "epoch 66; iter: 0; batch classifier loss: 0.102021; batch adversarial loss: 0.478047\n",
      "epoch 67; iter: 0; batch classifier loss: 0.162986; batch adversarial loss: 0.456193\n",
      "epoch 68; iter: 0; batch classifier loss: 0.140669; batch adversarial loss: 0.475287\n",
      "epoch 69; iter: 0; batch classifier loss: 0.166615; batch adversarial loss: 0.407748\n",
      "epoch 70; iter: 0; batch classifier loss: 0.096064; batch adversarial loss: 0.414010\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104080; batch adversarial loss: 0.395391\n",
      "epoch 72; iter: 0; batch classifier loss: 0.138929; batch adversarial loss: 0.489749\n",
      "epoch 73; iter: 0; batch classifier loss: 0.178394; batch adversarial loss: 0.433208\n",
      "epoch 74; iter: 0; batch classifier loss: 0.099795; batch adversarial loss: 0.385806\n",
      "epoch 75; iter: 0; batch classifier loss: 0.121474; batch adversarial loss: 0.527929\n",
      "epoch 76; iter: 0; batch classifier loss: 0.078961; batch adversarial loss: 0.473949\n",
      "epoch 77; iter: 0; batch classifier loss: 0.128960; batch adversarial loss: 0.467904\n",
      "epoch 78; iter: 0; batch classifier loss: 0.130807; batch adversarial loss: 0.449917\n",
      "epoch 79; iter: 0; batch classifier loss: 0.110207; batch adversarial loss: 0.423379\n",
      "epoch 80; iter: 0; batch classifier loss: 0.128958; batch adversarial loss: 0.474732\n",
      "epoch 81; iter: 0; batch classifier loss: 0.133765; batch adversarial loss: 0.432947\n",
      "epoch 82; iter: 0; batch classifier loss: 0.149677; batch adversarial loss: 0.398890\n",
      "epoch 83; iter: 0; batch classifier loss: 0.162591; batch adversarial loss: 0.401132\n",
      "epoch 84; iter: 0; batch classifier loss: 0.202818; batch adversarial loss: 0.407102\n",
      "epoch 85; iter: 0; batch classifier loss: 0.128840; batch adversarial loss: 0.469546\n",
      "epoch 86; iter: 0; batch classifier loss: 0.186564; batch adversarial loss: 0.484365\n",
      "epoch 87; iter: 0; batch classifier loss: 0.139094; batch adversarial loss: 0.445987\n",
      "epoch 88; iter: 0; batch classifier loss: 0.102925; batch adversarial loss: 0.494150\n",
      "epoch 89; iter: 0; batch classifier loss: 0.149424; batch adversarial loss: 0.409116\n",
      "epoch 90; iter: 0; batch classifier loss: 0.106042; batch adversarial loss: 0.480531\n",
      "epoch 91; iter: 0; batch classifier loss: 0.118727; batch adversarial loss: 0.372189\n",
      "epoch 92; iter: 0; batch classifier loss: 0.150515; batch adversarial loss: 0.421723\n",
      "epoch 93; iter: 0; batch classifier loss: 0.138189; batch adversarial loss: 0.437161\n",
      "epoch 94; iter: 0; batch classifier loss: 0.167938; batch adversarial loss: 0.463008\n",
      "epoch 95; iter: 0; batch classifier loss: 0.166356; batch adversarial loss: 0.520393\n",
      "epoch 96; iter: 0; batch classifier loss: 0.155485; batch adversarial loss: 0.423681\n",
      "epoch 97; iter: 0; batch classifier loss: 0.123867; batch adversarial loss: 0.450783\n",
      "epoch 98; iter: 0; batch classifier loss: 0.142850; batch adversarial loss: 0.457771\n",
      "epoch 99; iter: 0; batch classifier loss: 0.166054; batch adversarial loss: 0.505649\n",
      "epoch 100; iter: 0; batch classifier loss: 0.107344; batch adversarial loss: 0.492266\n",
      "epoch 101; iter: 0; batch classifier loss: 0.092361; batch adversarial loss: 0.466439\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078151; batch adversarial loss: 0.404155\n",
      "epoch 103; iter: 0; batch classifier loss: 0.121862; batch adversarial loss: 0.419722\n",
      "epoch 104; iter: 0; batch classifier loss: 0.103399; batch adversarial loss: 0.465349\n",
      "epoch 105; iter: 0; batch classifier loss: 0.081695; batch adversarial loss: 0.491909\n",
      "epoch 106; iter: 0; batch classifier loss: 0.115376; batch adversarial loss: 0.522869\n",
      "epoch 107; iter: 0; batch classifier loss: 0.084013; batch adversarial loss: 0.393511\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063962; batch adversarial loss: 0.329162\n",
      "epoch 109; iter: 0; batch classifier loss: 0.081347; batch adversarial loss: 0.441659\n",
      "epoch 110; iter: 0; batch classifier loss: 0.112052; batch adversarial loss: 0.479543\n",
      "epoch 111; iter: 0; batch classifier loss: 0.104946; batch adversarial loss: 0.400770\n",
      "epoch 112; iter: 0; batch classifier loss: 0.085527; batch adversarial loss: 0.550530\n",
      "epoch 113; iter: 0; batch classifier loss: 0.070455; batch adversarial loss: 0.412516\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049584; batch adversarial loss: 0.527072\n",
      "epoch 115; iter: 0; batch classifier loss: 0.086564; batch adversarial loss: 0.437110\n",
      "epoch 116; iter: 0; batch classifier loss: 0.096695; batch adversarial loss: 0.462179\n",
      "epoch 117; iter: 0; batch classifier loss: 0.082110; batch adversarial loss: 0.488538\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054989; batch adversarial loss: 0.399802\n",
      "epoch 119; iter: 0; batch classifier loss: 0.075497; batch adversarial loss: 0.438214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.055598; batch adversarial loss: 0.508066\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068964; batch adversarial loss: 0.483550\n",
      "epoch 122; iter: 0; batch classifier loss: 0.058813; batch adversarial loss: 0.505382\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055660; batch adversarial loss: 0.494058\n",
      "epoch 124; iter: 0; batch classifier loss: 0.062545; batch adversarial loss: 0.485677\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041622; batch adversarial loss: 0.509386\n",
      "epoch 126; iter: 0; batch classifier loss: 0.064134; batch adversarial loss: 0.516591\n",
      "epoch 127; iter: 0; batch classifier loss: 0.057130; batch adversarial loss: 0.483394\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029283; batch adversarial loss: 0.484408\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052447; batch adversarial loss: 0.492237\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045000; batch adversarial loss: 0.419726\n",
      "epoch 131; iter: 0; batch classifier loss: 0.066884; batch adversarial loss: 0.367576\n",
      "epoch 132; iter: 0; batch classifier loss: 0.065223; batch adversarial loss: 0.561630\n",
      "epoch 133; iter: 0; batch classifier loss: 0.056361; batch adversarial loss: 0.422991\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021102; batch adversarial loss: 0.562746\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049118; batch adversarial loss: 0.474344\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032525; batch adversarial loss: 0.436439\n",
      "epoch 137; iter: 0; batch classifier loss: 0.055617; batch adversarial loss: 0.465031\n",
      "epoch 138; iter: 0; batch classifier loss: 0.015781; batch adversarial loss: 0.555307\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022953; batch adversarial loss: 0.488989\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030988; batch adversarial loss: 0.465338\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018595; batch adversarial loss: 0.449619\n",
      "epoch 142; iter: 0; batch classifier loss: 0.047738; batch adversarial loss: 0.457415\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035858; batch adversarial loss: 0.473039\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020030; batch adversarial loss: 0.469243\n",
      "epoch 145; iter: 0; batch classifier loss: 0.060496; batch adversarial loss: 0.534015\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025908; batch adversarial loss: 0.510680\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042401; batch adversarial loss: 0.486515\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036044; batch adversarial loss: 0.390770\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012696; batch adversarial loss: 0.484554\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038238; batch adversarial loss: 0.485564\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023384; batch adversarial loss: 0.365878\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030022; batch adversarial loss: 0.430081\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024041; batch adversarial loss: 0.466539\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011548; batch adversarial loss: 0.460163\n",
      "epoch 155; iter: 0; batch classifier loss: 0.056642; batch adversarial loss: 0.527549\n",
      "epoch 156; iter: 0; batch classifier loss: 0.058923; batch adversarial loss: 0.488624\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020779; batch adversarial loss: 0.508775\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012409; batch adversarial loss: 0.464604\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013215; batch adversarial loss: 0.500453\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012525; batch adversarial loss: 0.469383\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013734; batch adversarial loss: 0.458854\n",
      "epoch 162; iter: 0; batch classifier loss: 0.044316; batch adversarial loss: 0.414075\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021242; batch adversarial loss: 0.580300\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032504; batch adversarial loss: 0.518990\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042543; batch adversarial loss: 0.397078\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036263; batch adversarial loss: 0.463590\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018460; batch adversarial loss: 0.428536\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013631; batch adversarial loss: 0.423686\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037193; batch adversarial loss: 0.417349\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007075; batch adversarial loss: 0.449695\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020314; batch adversarial loss: 0.482652\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018000; batch adversarial loss: 0.386477\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022184; batch adversarial loss: 0.486961\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015451; batch adversarial loss: 0.456499\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024866; batch adversarial loss: 0.485631\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022511; batch adversarial loss: 0.458841\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012696; batch adversarial loss: 0.440256\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015556; batch adversarial loss: 0.412372\n",
      "epoch 179; iter: 0; batch classifier loss: 0.052840; batch adversarial loss: 0.507905\n",
      "epoch 180; iter: 0; batch classifier loss: 0.036210; batch adversarial loss: 0.466389\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013983; batch adversarial loss: 0.447199\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013949; batch adversarial loss: 0.486316\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021405; batch adversarial loss: 0.432484\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010362; batch adversarial loss: 0.462159\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019095; batch adversarial loss: 0.426248\n",
      "epoch 186; iter: 0; batch classifier loss: 0.042914; batch adversarial loss: 0.405206\n",
      "epoch 187; iter: 0; batch classifier loss: 0.004707; batch adversarial loss: 0.459327\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028848; batch adversarial loss: 0.393944\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025780; batch adversarial loss: 0.450166\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025392; batch adversarial loss: 0.556822\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030755; batch adversarial loss: 0.364267\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007106; batch adversarial loss: 0.419755\n",
      "epoch 193; iter: 0; batch classifier loss: 0.038043; batch adversarial loss: 0.378722\n",
      "epoch 194; iter: 0; batch classifier loss: 0.055704; batch adversarial loss: 0.389008\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005071; batch adversarial loss: 0.394518\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033107; batch adversarial loss: 0.535193\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026838; batch adversarial loss: 0.562798\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026879; batch adversarial loss: 0.452356\n",
      "epoch 199; iter: 0; batch classifier loss: 0.052949; batch adversarial loss: 0.411323\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678784; batch adversarial loss: 0.710778\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489818; batch adversarial loss: 0.665164\n",
      "epoch 2; iter: 0; batch classifier loss: 0.486347; batch adversarial loss: 0.637536\n",
      "epoch 3; iter: 0; batch classifier loss: 0.391496; batch adversarial loss: 0.611700\n",
      "epoch 4; iter: 0; batch classifier loss: 0.434372; batch adversarial loss: 0.602590\n",
      "epoch 5; iter: 0; batch classifier loss: 0.474484; batch adversarial loss: 0.596199\n",
      "epoch 6; iter: 0; batch classifier loss: 0.438207; batch adversarial loss: 0.581774\n",
      "epoch 7; iter: 0; batch classifier loss: 0.468445; batch adversarial loss: 0.567808\n",
      "epoch 8; iter: 0; batch classifier loss: 0.442977; batch adversarial loss: 0.563906\n",
      "epoch 9; iter: 0; batch classifier loss: 0.445381; batch adversarial loss: 0.558000\n",
      "epoch 10; iter: 0; batch classifier loss: 0.380002; batch adversarial loss: 0.541816\n",
      "epoch 11; iter: 0; batch classifier loss: 0.400731; batch adversarial loss: 0.528667\n",
      "epoch 12; iter: 0; batch classifier loss: 0.397616; batch adversarial loss: 0.493373\n",
      "epoch 13; iter: 0; batch classifier loss: 0.431713; batch adversarial loss: 0.517952\n",
      "epoch 14; iter: 0; batch classifier loss: 0.319379; batch adversarial loss: 0.519730\n",
      "epoch 15; iter: 0; batch classifier loss: 0.356117; batch adversarial loss: 0.493142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.338557; batch adversarial loss: 0.467214\n",
      "epoch 17; iter: 0; batch classifier loss: 0.268088; batch adversarial loss: 0.497071\n",
      "epoch 18; iter: 0; batch classifier loss: 0.323044; batch adversarial loss: 0.429004\n",
      "epoch 19; iter: 0; batch classifier loss: 0.322900; batch adversarial loss: 0.448602\n",
      "epoch 20; iter: 0; batch classifier loss: 0.349929; batch adversarial loss: 0.449837\n",
      "epoch 21; iter: 0; batch classifier loss: 0.338733; batch adversarial loss: 0.489383\n",
      "epoch 22; iter: 0; batch classifier loss: 0.231554; batch adversarial loss: 0.405941\n",
      "epoch 23; iter: 0; batch classifier loss: 0.358318; batch adversarial loss: 0.428694\n",
      "epoch 24; iter: 0; batch classifier loss: 0.339919; batch adversarial loss: 0.464353\n",
      "epoch 25; iter: 0; batch classifier loss: 0.265855; batch adversarial loss: 0.487382\n",
      "epoch 26; iter: 0; batch classifier loss: 0.325031; batch adversarial loss: 0.426725\n",
      "epoch 27; iter: 0; batch classifier loss: 0.232981; batch adversarial loss: 0.509299\n",
      "epoch 28; iter: 0; batch classifier loss: 0.198029; batch adversarial loss: 0.421136\n",
      "epoch 29; iter: 0; batch classifier loss: 0.253434; batch adversarial loss: 0.536736\n",
      "epoch 30; iter: 0; batch classifier loss: 0.237396; batch adversarial loss: 0.459751\n",
      "epoch 31; iter: 0; batch classifier loss: 0.207456; batch adversarial loss: 0.427321\n",
      "epoch 32; iter: 0; batch classifier loss: 0.257875; batch adversarial loss: 0.477939\n",
      "epoch 33; iter: 0; batch classifier loss: 0.217936; batch adversarial loss: 0.509307\n",
      "epoch 34; iter: 0; batch classifier loss: 0.190458; batch adversarial loss: 0.398392\n",
      "epoch 35; iter: 0; batch classifier loss: 0.247011; batch adversarial loss: 0.485672\n",
      "epoch 36; iter: 0; batch classifier loss: 0.151928; batch adversarial loss: 0.518357\n",
      "epoch 37; iter: 0; batch classifier loss: 0.170300; batch adversarial loss: 0.430611\n",
      "epoch 38; iter: 0; batch classifier loss: 0.343852; batch adversarial loss: 0.467703\n",
      "epoch 39; iter: 0; batch classifier loss: 0.198690; batch adversarial loss: 0.449354\n",
      "epoch 40; iter: 0; batch classifier loss: 0.194494; batch adversarial loss: 0.523552\n",
      "epoch 41; iter: 0; batch classifier loss: 0.231337; batch adversarial loss: 0.422546\n",
      "epoch 42; iter: 0; batch classifier loss: 0.147682; batch adversarial loss: 0.477490\n",
      "epoch 43; iter: 0; batch classifier loss: 0.244235; batch adversarial loss: 0.492436\n",
      "epoch 44; iter: 0; batch classifier loss: 0.162636; batch adversarial loss: 0.461282\n",
      "epoch 45; iter: 0; batch classifier loss: 0.146644; batch adversarial loss: 0.482721\n",
      "epoch 46; iter: 0; batch classifier loss: 0.188012; batch adversarial loss: 0.494204\n",
      "epoch 47; iter: 0; batch classifier loss: 0.206885; batch adversarial loss: 0.435601\n",
      "epoch 48; iter: 0; batch classifier loss: 0.217191; batch adversarial loss: 0.391674\n",
      "epoch 49; iter: 0; batch classifier loss: 0.204529; batch adversarial loss: 0.384339\n",
      "epoch 50; iter: 0; batch classifier loss: 0.260690; batch adversarial loss: 0.427487\n",
      "epoch 51; iter: 0; batch classifier loss: 0.233066; batch adversarial loss: 0.481761\n",
      "epoch 52; iter: 0; batch classifier loss: 0.182614; batch adversarial loss: 0.449497\n",
      "epoch 53; iter: 0; batch classifier loss: 0.216294; batch adversarial loss: 0.410642\n",
      "epoch 54; iter: 0; batch classifier loss: 0.196217; batch adversarial loss: 0.408963\n",
      "epoch 55; iter: 0; batch classifier loss: 0.239954; batch adversarial loss: 0.532355\n",
      "epoch 56; iter: 0; batch classifier loss: 0.184781; batch adversarial loss: 0.447626\n",
      "epoch 57; iter: 0; batch classifier loss: 0.253714; batch adversarial loss: 0.471150\n",
      "epoch 58; iter: 0; batch classifier loss: 0.162553; batch adversarial loss: 0.459903\n",
      "epoch 59; iter: 0; batch classifier loss: 0.139467; batch adversarial loss: 0.603592\n",
      "epoch 60; iter: 0; batch classifier loss: 0.251862; batch adversarial loss: 0.458773\n",
      "epoch 61; iter: 0; batch classifier loss: 0.191315; batch adversarial loss: 0.423273\n",
      "epoch 62; iter: 0; batch classifier loss: 0.115078; batch adversarial loss: 0.445140\n",
      "epoch 63; iter: 0; batch classifier loss: 0.123219; batch adversarial loss: 0.472487\n",
      "epoch 64; iter: 0; batch classifier loss: 0.087152; batch adversarial loss: 0.538919\n",
      "epoch 65; iter: 0; batch classifier loss: 0.123767; batch adversarial loss: 0.405330\n",
      "epoch 66; iter: 0; batch classifier loss: 0.069003; batch adversarial loss: 0.453952\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073557; batch adversarial loss: 0.476835\n",
      "epoch 68; iter: 0; batch classifier loss: 0.119911; batch adversarial loss: 0.457769\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095899; batch adversarial loss: 0.405573\n",
      "epoch 70; iter: 0; batch classifier loss: 0.108800; batch adversarial loss: 0.442148\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084055; batch adversarial loss: 0.475674\n",
      "epoch 72; iter: 0; batch classifier loss: 0.050824; batch adversarial loss: 0.478335\n",
      "epoch 73; iter: 0; batch classifier loss: 0.064945; batch adversarial loss: 0.330786\n",
      "epoch 74; iter: 0; batch classifier loss: 0.074316; batch adversarial loss: 0.372412\n",
      "epoch 75; iter: 0; batch classifier loss: 0.057142; batch adversarial loss: 0.476528\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060547; batch adversarial loss: 0.452328\n",
      "epoch 77; iter: 0; batch classifier loss: 0.057274; batch adversarial loss: 0.467517\n",
      "epoch 78; iter: 0; batch classifier loss: 0.108928; batch adversarial loss: 0.378622\n",
      "epoch 79; iter: 0; batch classifier loss: 0.050819; batch adversarial loss: 0.512943\n",
      "epoch 80; iter: 0; batch classifier loss: 0.086669; batch adversarial loss: 0.441783\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067033; batch adversarial loss: 0.480237\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074211; batch adversarial loss: 0.475905\n",
      "epoch 83; iter: 0; batch classifier loss: 0.087033; batch adversarial loss: 0.471751\n",
      "epoch 84; iter: 0; batch classifier loss: 0.049188; batch adversarial loss: 0.457241\n",
      "epoch 85; iter: 0; batch classifier loss: 0.110094; batch adversarial loss: 0.457626\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054744; batch adversarial loss: 0.522514\n",
      "epoch 87; iter: 0; batch classifier loss: 0.061084; batch adversarial loss: 0.448132\n",
      "epoch 88; iter: 0; batch classifier loss: 0.074276; batch adversarial loss: 0.501239\n",
      "epoch 89; iter: 0; batch classifier loss: 0.029005; batch adversarial loss: 0.426697\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042344; batch adversarial loss: 0.419332\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075120; batch adversarial loss: 0.434442\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071447; batch adversarial loss: 0.437120\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071583; batch adversarial loss: 0.479364\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048310; batch adversarial loss: 0.431977\n",
      "epoch 95; iter: 0; batch classifier loss: 0.062224; batch adversarial loss: 0.443164\n",
      "epoch 96; iter: 0; batch classifier loss: 0.031024; batch adversarial loss: 0.452809\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043480; batch adversarial loss: 0.443279\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054151; batch adversarial loss: 0.380924\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040927; batch adversarial loss: 0.490525\n",
      "epoch 100; iter: 0; batch classifier loss: 0.079820; batch adversarial loss: 0.451059\n",
      "epoch 101; iter: 0; batch classifier loss: 0.059005; batch adversarial loss: 0.524352\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047155; batch adversarial loss: 0.471380\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037464; batch adversarial loss: 0.481275\n",
      "epoch 104; iter: 0; batch classifier loss: 0.064869; batch adversarial loss: 0.412035\n",
      "epoch 105; iter: 0; batch classifier loss: 0.081538; batch adversarial loss: 0.489926\n",
      "epoch 106; iter: 0; batch classifier loss: 0.080782; batch adversarial loss: 0.453293\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049497; batch adversarial loss: 0.408430\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040045; batch adversarial loss: 0.408742\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039107; batch adversarial loss: 0.507486\n",
      "epoch 110; iter: 0; batch classifier loss: 0.070662; batch adversarial loss: 0.435339\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069330; batch adversarial loss: 0.507302\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044386; batch adversarial loss: 0.546552\n",
      "epoch 113; iter: 0; batch classifier loss: 0.022845; batch adversarial loss: 0.476855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.038853; batch adversarial loss: 0.434140\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065492; batch adversarial loss: 0.426410\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029868; batch adversarial loss: 0.389713\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029808; batch adversarial loss: 0.441094\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035413; batch adversarial loss: 0.557635\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027340; batch adversarial loss: 0.509179\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039082; batch adversarial loss: 0.383378\n",
      "epoch 121; iter: 0; batch classifier loss: 0.022608; batch adversarial loss: 0.495327\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039358; batch adversarial loss: 0.400102\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038395; batch adversarial loss: 0.450082\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030627; batch adversarial loss: 0.478575\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017158; batch adversarial loss: 0.429432\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030615; batch adversarial loss: 0.486754\n",
      "epoch 127; iter: 0; batch classifier loss: 0.011400; batch adversarial loss: 0.453150\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041094; batch adversarial loss: 0.469292\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024032; batch adversarial loss: 0.425414\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027188; batch adversarial loss: 0.477920\n",
      "epoch 131; iter: 0; batch classifier loss: 0.013269; batch adversarial loss: 0.448476\n",
      "epoch 132; iter: 0; batch classifier loss: 0.071827; batch adversarial loss: 0.525521\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032925; batch adversarial loss: 0.462437\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029445; batch adversarial loss: 0.528449\n",
      "epoch 135; iter: 0; batch classifier loss: 0.054083; batch adversarial loss: 0.359928\n",
      "epoch 136; iter: 0; batch classifier loss: 0.012847; batch adversarial loss: 0.456585\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049240; batch adversarial loss: 0.416920\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025588; batch adversarial loss: 0.430059\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031467; batch adversarial loss: 0.442841\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028405; batch adversarial loss: 0.487638\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019687; batch adversarial loss: 0.486461\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022768; batch adversarial loss: 0.444369\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021312; batch adversarial loss: 0.373473\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017566; batch adversarial loss: 0.398840\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020360; batch adversarial loss: 0.433153\n",
      "epoch 146; iter: 0; batch classifier loss: 0.064937; batch adversarial loss: 0.481972\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037279; batch adversarial loss: 0.479513\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024081; batch adversarial loss: 0.438800\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038885; batch adversarial loss: 0.521684\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024612; batch adversarial loss: 0.492185\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030049; batch adversarial loss: 0.402831\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010878; batch adversarial loss: 0.484840\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040827; batch adversarial loss: 0.487993\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010777; batch adversarial loss: 0.425595\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032388; batch adversarial loss: 0.507107\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024289; batch adversarial loss: 0.407103\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022787; batch adversarial loss: 0.438650\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018922; batch adversarial loss: 0.469123\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025384; batch adversarial loss: 0.352405\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022404; batch adversarial loss: 0.414829\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038693; batch adversarial loss: 0.502816\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013787; batch adversarial loss: 0.481433\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027594; batch adversarial loss: 0.432966\n",
      "epoch 164; iter: 0; batch classifier loss: 0.005846; batch adversarial loss: 0.530488\n",
      "epoch 165; iter: 0; batch classifier loss: 0.052707; batch adversarial loss: 0.436299\n",
      "epoch 166; iter: 0; batch classifier loss: 0.008572; batch adversarial loss: 0.432841\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007189; batch adversarial loss: 0.413274\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015761; batch adversarial loss: 0.428599\n",
      "epoch 169; iter: 0; batch classifier loss: 0.050848; batch adversarial loss: 0.506178\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023019; batch adversarial loss: 0.524546\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019578; batch adversarial loss: 0.430000\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040263; batch adversarial loss: 0.451433\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038212; batch adversarial loss: 0.398094\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020969; batch adversarial loss: 0.425361\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040443; batch adversarial loss: 0.465250\n",
      "epoch 176; iter: 0; batch classifier loss: 0.047159; batch adversarial loss: 0.543078\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024938; batch adversarial loss: 0.446682\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011605; batch adversarial loss: 0.382448\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043490; batch adversarial loss: 0.423023\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012438; batch adversarial loss: 0.373639\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033229; batch adversarial loss: 0.511115\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011343; batch adversarial loss: 0.411153\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020111; batch adversarial loss: 0.548365\n",
      "epoch 184; iter: 0; batch classifier loss: 0.082154; batch adversarial loss: 0.498701\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019660; batch adversarial loss: 0.453547\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006841; batch adversarial loss: 0.497917\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020078; batch adversarial loss: 0.427300\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014188; batch adversarial loss: 0.455134\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018017; batch adversarial loss: 0.484579\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006922; batch adversarial loss: 0.443324\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015700; batch adversarial loss: 0.447179\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022395; batch adversarial loss: 0.372514\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014723; batch adversarial loss: 0.390523\n",
      "epoch 194; iter: 0; batch classifier loss: 0.050527; batch adversarial loss: 0.459931\n",
      "epoch 195; iter: 0; batch classifier loss: 0.038102; batch adversarial loss: 0.384984\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021535; batch adversarial loss: 0.469984\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026319; batch adversarial loss: 0.508989\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017976; batch adversarial loss: 0.469935\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008172; batch adversarial loss: 0.437289\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680706; batch adversarial loss: 0.570640\n",
      "epoch 1; iter: 0; batch classifier loss: 0.395575; batch adversarial loss: 0.632969\n",
      "epoch 2; iter: 0; batch classifier loss: 0.430785; batch adversarial loss: 0.650847\n",
      "epoch 3; iter: 0; batch classifier loss: 0.330101; batch adversarial loss: 0.587214\n",
      "epoch 4; iter: 0; batch classifier loss: 0.346641; batch adversarial loss: 0.549366\n",
      "epoch 5; iter: 0; batch classifier loss: 0.372745; batch adversarial loss: 0.555396\n",
      "epoch 6; iter: 0; batch classifier loss: 0.280837; batch adversarial loss: 0.536861\n",
      "epoch 7; iter: 0; batch classifier loss: 0.335346; batch adversarial loss: 0.493388\n",
      "epoch 8; iter: 0; batch classifier loss: 0.225459; batch adversarial loss: 0.479143\n",
      "epoch 9; iter: 0; batch classifier loss: 0.304297; batch adversarial loss: 0.576445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.233415; batch adversarial loss: 0.489192\n",
      "epoch 11; iter: 0; batch classifier loss: 0.237526; batch adversarial loss: 0.557071\n",
      "epoch 12; iter: 0; batch classifier loss: 0.197094; batch adversarial loss: 0.512701\n",
      "epoch 13; iter: 0; batch classifier loss: 0.199160; batch adversarial loss: 0.532838\n",
      "epoch 14; iter: 0; batch classifier loss: 0.204246; batch adversarial loss: 0.515516\n",
      "epoch 15; iter: 0; batch classifier loss: 0.231340; batch adversarial loss: 0.474058\n",
      "epoch 16; iter: 0; batch classifier loss: 0.245398; batch adversarial loss: 0.565173\n",
      "epoch 17; iter: 0; batch classifier loss: 0.244409; batch adversarial loss: 0.478866\n",
      "epoch 18; iter: 0; batch classifier loss: 0.277512; batch adversarial loss: 0.522067\n",
      "epoch 19; iter: 0; batch classifier loss: 0.360648; batch adversarial loss: 0.560499\n",
      "epoch 20; iter: 0; batch classifier loss: 0.227061; batch adversarial loss: 0.483062\n",
      "epoch 21; iter: 0; batch classifier loss: 0.274442; batch adversarial loss: 0.437096\n",
      "epoch 22; iter: 0; batch classifier loss: 0.349945; batch adversarial loss: 0.471741\n",
      "epoch 23; iter: 0; batch classifier loss: 0.346683; batch adversarial loss: 0.462527\n",
      "epoch 24; iter: 0; batch classifier loss: 0.208524; batch adversarial loss: 0.470248\n",
      "epoch 25; iter: 0; batch classifier loss: 0.181428; batch adversarial loss: 0.488725\n",
      "epoch 26; iter: 0; batch classifier loss: 0.174219; batch adversarial loss: 0.444512\n",
      "epoch 27; iter: 0; batch classifier loss: 0.166268; batch adversarial loss: 0.481954\n",
      "epoch 28; iter: 0; batch classifier loss: 0.113471; batch adversarial loss: 0.474263\n",
      "epoch 29; iter: 0; batch classifier loss: 0.101437; batch adversarial loss: 0.568504\n",
      "epoch 30; iter: 0; batch classifier loss: 0.109131; batch adversarial loss: 0.492670\n",
      "epoch 31; iter: 0; batch classifier loss: 0.165288; batch adversarial loss: 0.473433\n",
      "epoch 32; iter: 0; batch classifier loss: 0.101708; batch adversarial loss: 0.532281\n",
      "epoch 33; iter: 0; batch classifier loss: 0.131133; batch adversarial loss: 0.463979\n",
      "epoch 34; iter: 0; batch classifier loss: 0.124898; batch adversarial loss: 0.355713\n",
      "epoch 35; iter: 0; batch classifier loss: 0.128060; batch adversarial loss: 0.468708\n",
      "epoch 36; iter: 0; batch classifier loss: 0.054404; batch adversarial loss: 0.518835\n",
      "epoch 37; iter: 0; batch classifier loss: 0.129367; batch adversarial loss: 0.517085\n",
      "epoch 38; iter: 0; batch classifier loss: 0.113505; batch adversarial loss: 0.477286\n",
      "epoch 39; iter: 0; batch classifier loss: 0.120236; batch adversarial loss: 0.476886\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154396; batch adversarial loss: 0.402521\n",
      "epoch 41; iter: 0; batch classifier loss: 0.084767; batch adversarial loss: 0.475178\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088754; batch adversarial loss: 0.504892\n",
      "epoch 43; iter: 0; batch classifier loss: 0.095832; batch adversarial loss: 0.501396\n",
      "epoch 44; iter: 0; batch classifier loss: 0.117777; batch adversarial loss: 0.430111\n",
      "epoch 45; iter: 0; batch classifier loss: 0.111187; batch adversarial loss: 0.474805\n",
      "epoch 46; iter: 0; batch classifier loss: 0.085053; batch adversarial loss: 0.516762\n",
      "epoch 47; iter: 0; batch classifier loss: 0.116408; batch adversarial loss: 0.490086\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125544; batch adversarial loss: 0.537912\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101937; batch adversarial loss: 0.446964\n",
      "epoch 50; iter: 0; batch classifier loss: 0.081254; batch adversarial loss: 0.513729\n",
      "epoch 51; iter: 0; batch classifier loss: 0.072111; batch adversarial loss: 0.492021\n",
      "epoch 52; iter: 0; batch classifier loss: 0.084878; batch adversarial loss: 0.491156\n",
      "epoch 53; iter: 0; batch classifier loss: 0.117291; batch adversarial loss: 0.522283\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101985; batch adversarial loss: 0.446194\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101812; batch adversarial loss: 0.469162\n",
      "epoch 56; iter: 0; batch classifier loss: 0.129039; batch adversarial loss: 0.416350\n",
      "epoch 57; iter: 0; batch classifier loss: 0.104061; batch adversarial loss: 0.494615\n",
      "epoch 58; iter: 0; batch classifier loss: 0.100647; batch adversarial loss: 0.494790\n",
      "epoch 59; iter: 0; batch classifier loss: 0.119301; batch adversarial loss: 0.472928\n",
      "epoch 60; iter: 0; batch classifier loss: 0.063306; batch adversarial loss: 0.505266\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080402; batch adversarial loss: 0.484421\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082672; batch adversarial loss: 0.496656\n",
      "epoch 63; iter: 0; batch classifier loss: 0.138602; batch adversarial loss: 0.386839\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106376; batch adversarial loss: 0.454682\n",
      "epoch 65; iter: 0; batch classifier loss: 0.100301; batch adversarial loss: 0.426997\n",
      "epoch 66; iter: 0; batch classifier loss: 0.119220; batch adversarial loss: 0.444823\n",
      "epoch 67; iter: 0; batch classifier loss: 0.164729; batch adversarial loss: 0.427069\n",
      "epoch 68; iter: 0; batch classifier loss: 0.127457; batch adversarial loss: 0.484972\n",
      "epoch 69; iter: 0; batch classifier loss: 0.139248; batch adversarial loss: 0.528071\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144277; batch adversarial loss: 0.457416\n",
      "epoch 71; iter: 0; batch classifier loss: 0.135258; batch adversarial loss: 0.481791\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087157; batch adversarial loss: 0.451157\n",
      "epoch 73; iter: 0; batch classifier loss: 0.135118; batch adversarial loss: 0.384883\n",
      "epoch 74; iter: 0; batch classifier loss: 0.116270; batch adversarial loss: 0.467575\n",
      "epoch 75; iter: 0; batch classifier loss: 0.123924; batch adversarial loss: 0.388700\n",
      "epoch 76; iter: 0; batch classifier loss: 0.148134; batch adversarial loss: 0.476178\n",
      "epoch 77; iter: 0; batch classifier loss: 0.113520; batch adversarial loss: 0.462651\n",
      "epoch 78; iter: 0; batch classifier loss: 0.109792; batch adversarial loss: 0.494230\n",
      "epoch 79; iter: 0; batch classifier loss: 0.160898; batch adversarial loss: 0.476109\n",
      "epoch 80; iter: 0; batch classifier loss: 0.110061; batch adversarial loss: 0.441079\n",
      "epoch 81; iter: 0; batch classifier loss: 0.099223; batch adversarial loss: 0.489730\n",
      "epoch 82; iter: 0; batch classifier loss: 0.217962; batch adversarial loss: 0.373383\n",
      "epoch 83; iter: 0; batch classifier loss: 0.120925; batch adversarial loss: 0.424116\n",
      "epoch 84; iter: 0; batch classifier loss: 0.096632; batch adversarial loss: 0.420017\n",
      "epoch 85; iter: 0; batch classifier loss: 0.115153; batch adversarial loss: 0.455010\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073698; batch adversarial loss: 0.446621\n",
      "epoch 87; iter: 0; batch classifier loss: 0.112648; batch adversarial loss: 0.467138\n",
      "epoch 88; iter: 0; batch classifier loss: 0.116525; batch adversarial loss: 0.463999\n",
      "epoch 89; iter: 0; batch classifier loss: 0.097562; batch adversarial loss: 0.468424\n",
      "epoch 90; iter: 0; batch classifier loss: 0.089108; batch adversarial loss: 0.532168\n",
      "epoch 91; iter: 0; batch classifier loss: 0.099688; batch adversarial loss: 0.486969\n",
      "epoch 92; iter: 0; batch classifier loss: 0.083541; batch adversarial loss: 0.486746\n",
      "epoch 93; iter: 0; batch classifier loss: 0.135877; batch adversarial loss: 0.448758\n",
      "epoch 94; iter: 0; batch classifier loss: 0.118387; batch adversarial loss: 0.449457\n",
      "epoch 95; iter: 0; batch classifier loss: 0.112119; batch adversarial loss: 0.439300\n",
      "epoch 96; iter: 0; batch classifier loss: 0.137824; batch adversarial loss: 0.403997\n",
      "epoch 97; iter: 0; batch classifier loss: 0.146283; batch adversarial loss: 0.365412\n",
      "epoch 98; iter: 0; batch classifier loss: 0.111998; batch adversarial loss: 0.421234\n",
      "epoch 99; iter: 0; batch classifier loss: 0.143113; batch adversarial loss: 0.434806\n",
      "epoch 100; iter: 0; batch classifier loss: 0.131561; batch adversarial loss: 0.489946\n",
      "epoch 101; iter: 0; batch classifier loss: 0.098676; batch adversarial loss: 0.491465\n",
      "epoch 102; iter: 0; batch classifier loss: 0.105056; batch adversarial loss: 0.524247\n",
      "epoch 103; iter: 0; batch classifier loss: 0.109412; batch adversarial loss: 0.441345\n",
      "epoch 104; iter: 0; batch classifier loss: 0.117276; batch adversarial loss: 0.495715\n",
      "epoch 105; iter: 0; batch classifier loss: 0.122547; batch adversarial loss: 0.520270\n",
      "epoch 106; iter: 0; batch classifier loss: 0.107021; batch adversarial loss: 0.376599\n",
      "epoch 107; iter: 0; batch classifier loss: 0.111200; batch adversarial loss: 0.460664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.107563; batch adversarial loss: 0.366456\n",
      "epoch 109; iter: 0; batch classifier loss: 0.116237; batch adversarial loss: 0.453485\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067643; batch adversarial loss: 0.430164\n",
      "epoch 111; iter: 0; batch classifier loss: 0.089157; batch adversarial loss: 0.444614\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046904; batch adversarial loss: 0.487400\n",
      "epoch 113; iter: 0; batch classifier loss: 0.076636; batch adversarial loss: 0.477096\n",
      "epoch 114; iter: 0; batch classifier loss: 0.115856; batch adversarial loss: 0.455256\n",
      "epoch 115; iter: 0; batch classifier loss: 0.122003; batch adversarial loss: 0.426787\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054106; batch adversarial loss: 0.486807\n",
      "epoch 117; iter: 0; batch classifier loss: 0.105894; batch adversarial loss: 0.436344\n",
      "epoch 118; iter: 0; batch classifier loss: 0.089471; batch adversarial loss: 0.411568\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073009; batch adversarial loss: 0.563617\n",
      "epoch 120; iter: 0; batch classifier loss: 0.067413; batch adversarial loss: 0.462670\n",
      "epoch 121; iter: 0; batch classifier loss: 0.138761; batch adversarial loss: 0.432245\n",
      "epoch 122; iter: 0; batch classifier loss: 0.092883; batch adversarial loss: 0.583556\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052524; batch adversarial loss: 0.464553\n",
      "epoch 124; iter: 0; batch classifier loss: 0.074874; batch adversarial loss: 0.368437\n",
      "epoch 125; iter: 0; batch classifier loss: 0.100733; batch adversarial loss: 0.429115\n",
      "epoch 126; iter: 0; batch classifier loss: 0.059547; batch adversarial loss: 0.583371\n",
      "epoch 127; iter: 0; batch classifier loss: 0.105740; batch adversarial loss: 0.458264\n",
      "epoch 128; iter: 0; batch classifier loss: 0.079696; batch adversarial loss: 0.375271\n",
      "epoch 129; iter: 0; batch classifier loss: 0.103239; batch adversarial loss: 0.474386\n",
      "epoch 130; iter: 0; batch classifier loss: 0.054284; batch adversarial loss: 0.455459\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044008; batch adversarial loss: 0.413113\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032987; batch adversarial loss: 0.451410\n",
      "epoch 133; iter: 0; batch classifier loss: 0.070047; batch adversarial loss: 0.350149\n",
      "epoch 134; iter: 0; batch classifier loss: 0.056406; batch adversarial loss: 0.387894\n",
      "epoch 135; iter: 0; batch classifier loss: 0.065476; batch adversarial loss: 0.477883\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025595; batch adversarial loss: 0.479250\n",
      "epoch 137; iter: 0; batch classifier loss: 0.056389; batch adversarial loss: 0.429686\n",
      "epoch 138; iter: 0; batch classifier loss: 0.059234; batch adversarial loss: 0.407164\n",
      "epoch 139; iter: 0; batch classifier loss: 0.059861; batch adversarial loss: 0.417297\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036439; batch adversarial loss: 0.515006\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029375; batch adversarial loss: 0.423470\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048345; batch adversarial loss: 0.442720\n",
      "epoch 143; iter: 0; batch classifier loss: 0.055251; batch adversarial loss: 0.399896\n",
      "epoch 144; iter: 0; batch classifier loss: 0.051181; batch adversarial loss: 0.423315\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034479; batch adversarial loss: 0.438060\n",
      "epoch 146; iter: 0; batch classifier loss: 0.064701; batch adversarial loss: 0.455170\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030994; batch adversarial loss: 0.419005\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035697; batch adversarial loss: 0.361719\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051620; batch adversarial loss: 0.583681\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052450; batch adversarial loss: 0.494704\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016813; batch adversarial loss: 0.476374\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027694; batch adversarial loss: 0.493848\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031455; batch adversarial loss: 0.382507\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017591; batch adversarial loss: 0.512248\n",
      "epoch 155; iter: 0; batch classifier loss: 0.075724; batch adversarial loss: 0.484923\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021666; batch adversarial loss: 0.523820\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018499; batch adversarial loss: 0.461157\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038722; batch adversarial loss: 0.541345\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045692; batch adversarial loss: 0.363207\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015050; batch adversarial loss: 0.494172\n",
      "epoch 161; iter: 0; batch classifier loss: 0.050939; batch adversarial loss: 0.490044\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016898; batch adversarial loss: 0.484949\n",
      "epoch 163; iter: 0; batch classifier loss: 0.046640; batch adversarial loss: 0.522655\n",
      "epoch 164; iter: 0; batch classifier loss: 0.068635; batch adversarial loss: 0.425111\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016342; batch adversarial loss: 0.486021\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043534; batch adversarial loss: 0.517211\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035758; batch adversarial loss: 0.447915\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022214; batch adversarial loss: 0.389968\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016618; batch adversarial loss: 0.550236\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033508; batch adversarial loss: 0.448633\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024778; batch adversarial loss: 0.379564\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030718; batch adversarial loss: 0.524557\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029498; batch adversarial loss: 0.469258\n",
      "epoch 174; iter: 0; batch classifier loss: 0.048902; batch adversarial loss: 0.454922\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026781; batch adversarial loss: 0.457683\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018439; batch adversarial loss: 0.465118\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028094; batch adversarial loss: 0.486618\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027566; batch adversarial loss: 0.445574\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040082; batch adversarial loss: 0.490760\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015388; batch adversarial loss: 0.498595\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033666; batch adversarial loss: 0.504402\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014432; batch adversarial loss: 0.493592\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026459; batch adversarial loss: 0.466960\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018931; batch adversarial loss: 0.449436\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042948; batch adversarial loss: 0.489204\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008140; batch adversarial loss: 0.412680\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019313; batch adversarial loss: 0.559342\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010390; batch adversarial loss: 0.400318\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018611; batch adversarial loss: 0.533944\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020308; batch adversarial loss: 0.516976\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012460; batch adversarial loss: 0.413506\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011889; batch adversarial loss: 0.426643\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011172; batch adversarial loss: 0.445028\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018181; batch adversarial loss: 0.440833\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016464; batch adversarial loss: 0.517336\n",
      "epoch 196; iter: 0; batch classifier loss: 0.038249; batch adversarial loss: 0.480071\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011253; batch adversarial loss: 0.423767\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014627; batch adversarial loss: 0.478914\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026093; batch adversarial loss: 0.579698\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685163; batch adversarial loss: 0.721406\n",
      "epoch 1; iter: 0; batch classifier loss: 0.500043; batch adversarial loss: 0.686029\n",
      "epoch 2; iter: 0; batch classifier loss: 0.424363; batch adversarial loss: 0.639295\n",
      "epoch 3; iter: 0; batch classifier loss: 0.402646; batch adversarial loss: 0.589244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.290345; batch adversarial loss: 0.562757\n",
      "epoch 5; iter: 0; batch classifier loss: 0.323313; batch adversarial loss: 0.520997\n",
      "epoch 6; iter: 0; batch classifier loss: 0.402746; batch adversarial loss: 0.526103\n",
      "epoch 7; iter: 0; batch classifier loss: 0.291871; batch adversarial loss: 0.488901\n",
      "epoch 8; iter: 0; batch classifier loss: 0.330550; batch adversarial loss: 0.528756\n",
      "epoch 9; iter: 0; batch classifier loss: 0.201254; batch adversarial loss: 0.481071\n",
      "epoch 10; iter: 0; batch classifier loss: 0.213434; batch adversarial loss: 0.497570\n",
      "epoch 11; iter: 0; batch classifier loss: 0.220871; batch adversarial loss: 0.488003\n",
      "epoch 12; iter: 0; batch classifier loss: 0.216143; batch adversarial loss: 0.530777\n",
      "epoch 13; iter: 0; batch classifier loss: 0.209343; batch adversarial loss: 0.409098\n",
      "epoch 14; iter: 0; batch classifier loss: 0.159417; batch adversarial loss: 0.534033\n",
      "epoch 15; iter: 0; batch classifier loss: 0.204819; batch adversarial loss: 0.467287\n",
      "epoch 16; iter: 0; batch classifier loss: 0.164127; batch adversarial loss: 0.379224\n",
      "epoch 17; iter: 0; batch classifier loss: 0.186877; batch adversarial loss: 0.529183\n",
      "epoch 18; iter: 0; batch classifier loss: 0.202685; batch adversarial loss: 0.465974\n",
      "epoch 19; iter: 0; batch classifier loss: 0.143831; batch adversarial loss: 0.448414\n",
      "epoch 20; iter: 0; batch classifier loss: 0.201504; batch adversarial loss: 0.418319\n",
      "epoch 21; iter: 0; batch classifier loss: 0.220741; batch adversarial loss: 0.541380\n",
      "epoch 22; iter: 0; batch classifier loss: 0.144425; batch adversarial loss: 0.459629\n",
      "epoch 23; iter: 0; batch classifier loss: 0.129322; batch adversarial loss: 0.512926\n",
      "epoch 24; iter: 0; batch classifier loss: 0.093544; batch adversarial loss: 0.463056\n",
      "epoch 25; iter: 0; batch classifier loss: 0.128189; batch adversarial loss: 0.453275\n",
      "epoch 26; iter: 0; batch classifier loss: 0.161169; batch adversarial loss: 0.427322\n",
      "epoch 27; iter: 0; batch classifier loss: 0.247957; batch adversarial loss: 0.471474\n",
      "epoch 28; iter: 0; batch classifier loss: 0.222171; batch adversarial loss: 0.505359\n",
      "epoch 29; iter: 0; batch classifier loss: 0.219558; batch adversarial loss: 0.479328\n",
      "epoch 30; iter: 0; batch classifier loss: 0.214477; batch adversarial loss: 0.466854\n",
      "epoch 31; iter: 0; batch classifier loss: 0.371563; batch adversarial loss: 0.489404\n",
      "epoch 32; iter: 0; batch classifier loss: 0.218023; batch adversarial loss: 0.425276\n",
      "epoch 33; iter: 0; batch classifier loss: 0.174856; batch adversarial loss: 0.488569\n",
      "epoch 34; iter: 0; batch classifier loss: 0.095393; batch adversarial loss: 0.449483\n",
      "epoch 35; iter: 0; batch classifier loss: 0.117496; batch adversarial loss: 0.403436\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109846; batch adversarial loss: 0.415801\n",
      "epoch 37; iter: 0; batch classifier loss: 0.101483; batch adversarial loss: 0.473801\n",
      "epoch 38; iter: 0; batch classifier loss: 0.108392; batch adversarial loss: 0.411585\n",
      "epoch 39; iter: 0; batch classifier loss: 0.091498; batch adversarial loss: 0.427159\n",
      "epoch 40; iter: 0; batch classifier loss: 0.122759; batch adversarial loss: 0.552885\n",
      "epoch 41; iter: 0; batch classifier loss: 0.082397; batch adversarial loss: 0.590533\n",
      "epoch 42; iter: 0; batch classifier loss: 0.104870; batch adversarial loss: 0.414958\n",
      "epoch 43; iter: 0; batch classifier loss: 0.121918; batch adversarial loss: 0.369617\n",
      "epoch 44; iter: 0; batch classifier loss: 0.075019; batch adversarial loss: 0.499744\n",
      "epoch 45; iter: 0; batch classifier loss: 0.094616; batch adversarial loss: 0.429839\n",
      "epoch 46; iter: 0; batch classifier loss: 0.105675; batch adversarial loss: 0.435297\n",
      "epoch 47; iter: 0; batch classifier loss: 0.080858; batch adversarial loss: 0.418933\n",
      "epoch 48; iter: 0; batch classifier loss: 0.149996; batch adversarial loss: 0.537476\n",
      "epoch 49; iter: 0; batch classifier loss: 0.072097; batch adversarial loss: 0.379549\n",
      "epoch 50; iter: 0; batch classifier loss: 0.044843; batch adversarial loss: 0.404276\n",
      "epoch 51; iter: 0; batch classifier loss: 0.084393; batch adversarial loss: 0.480963\n",
      "epoch 52; iter: 0; batch classifier loss: 0.061614; batch adversarial loss: 0.471915\n",
      "epoch 53; iter: 0; batch classifier loss: 0.107128; batch adversarial loss: 0.484518\n",
      "epoch 54; iter: 0; batch classifier loss: 0.093086; batch adversarial loss: 0.516172\n",
      "epoch 55; iter: 0; batch classifier loss: 0.108551; batch adversarial loss: 0.415471\n",
      "epoch 56; iter: 0; batch classifier loss: 0.062924; batch adversarial loss: 0.373053\n",
      "epoch 57; iter: 0; batch classifier loss: 0.059037; batch adversarial loss: 0.514926\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101450; batch adversarial loss: 0.409596\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082990; batch adversarial loss: 0.404982\n",
      "epoch 60; iter: 0; batch classifier loss: 0.062322; batch adversarial loss: 0.341968\n",
      "epoch 61; iter: 0; batch classifier loss: 0.073315; batch adversarial loss: 0.514661\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098329; batch adversarial loss: 0.375606\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099951; batch adversarial loss: 0.369466\n",
      "epoch 64; iter: 0; batch classifier loss: 0.091467; batch adversarial loss: 0.432185\n",
      "epoch 65; iter: 0; batch classifier loss: 0.068930; batch adversarial loss: 0.407681\n",
      "epoch 66; iter: 0; batch classifier loss: 0.071774; batch adversarial loss: 0.440071\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095596; batch adversarial loss: 0.412906\n",
      "epoch 68; iter: 0; batch classifier loss: 0.074856; batch adversarial loss: 0.376766\n",
      "epoch 69; iter: 0; batch classifier loss: 0.086189; batch adversarial loss: 0.414640\n",
      "epoch 70; iter: 0; batch classifier loss: 0.036132; batch adversarial loss: 0.460770\n",
      "epoch 71; iter: 0; batch classifier loss: 0.051800; batch adversarial loss: 0.462718\n",
      "epoch 72; iter: 0; batch classifier loss: 0.140997; batch adversarial loss: 0.458602\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068264; batch adversarial loss: 0.423570\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064745; batch adversarial loss: 0.363393\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067004; batch adversarial loss: 0.499435\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046951; batch adversarial loss: 0.447260\n",
      "epoch 77; iter: 0; batch classifier loss: 0.133491; batch adversarial loss: 0.367642\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054097; batch adversarial loss: 0.450636\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055382; batch adversarial loss: 0.456781\n",
      "epoch 80; iter: 0; batch classifier loss: 0.111945; batch adversarial loss: 0.401829\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050523; batch adversarial loss: 0.425454\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066806; batch adversarial loss: 0.330252\n",
      "epoch 83; iter: 0; batch classifier loss: 0.057903; batch adversarial loss: 0.348513\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068108; batch adversarial loss: 0.494625\n",
      "epoch 85; iter: 0; batch classifier loss: 0.042109; batch adversarial loss: 0.393194\n",
      "epoch 86; iter: 0; batch classifier loss: 0.059049; batch adversarial loss: 0.515767\n",
      "epoch 87; iter: 0; batch classifier loss: 0.107559; batch adversarial loss: 0.422940\n",
      "epoch 88; iter: 0; batch classifier loss: 0.047378; batch adversarial loss: 0.525969\n",
      "epoch 89; iter: 0; batch classifier loss: 0.079158; batch adversarial loss: 0.344392\n",
      "epoch 90; iter: 0; batch classifier loss: 0.035899; batch adversarial loss: 0.437957\n",
      "epoch 91; iter: 0; batch classifier loss: 0.094094; batch adversarial loss: 0.470426\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062413; batch adversarial loss: 0.434108\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065614; batch adversarial loss: 0.474451\n",
      "epoch 94; iter: 0; batch classifier loss: 0.057951; batch adversarial loss: 0.427960\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080324; batch adversarial loss: 0.392651\n",
      "epoch 96; iter: 0; batch classifier loss: 0.100381; batch adversarial loss: 0.342839\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071809; batch adversarial loss: 0.404160\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048615; batch adversarial loss: 0.490295\n",
      "epoch 99; iter: 0; batch classifier loss: 0.060737; batch adversarial loss: 0.402394\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054574; batch adversarial loss: 0.444255\n",
      "epoch 101; iter: 0; batch classifier loss: 0.067554; batch adversarial loss: 0.435629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.036345; batch adversarial loss: 0.413588\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045064; batch adversarial loss: 0.433115\n",
      "epoch 104; iter: 0; batch classifier loss: 0.049766; batch adversarial loss: 0.457546\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029791; batch adversarial loss: 0.467616\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032881; batch adversarial loss: 0.521315\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032518; batch adversarial loss: 0.481765\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048364; batch adversarial loss: 0.457174\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036224; batch adversarial loss: 0.463609\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037533; batch adversarial loss: 0.430663\n",
      "epoch 111; iter: 0; batch classifier loss: 0.083283; batch adversarial loss: 0.413560\n",
      "epoch 112; iter: 0; batch classifier loss: 0.076425; batch adversarial loss: 0.442796\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038457; batch adversarial loss: 0.577073\n",
      "epoch 114; iter: 0; batch classifier loss: 0.091567; batch adversarial loss: 0.423939\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042489; batch adversarial loss: 0.413644\n",
      "epoch 116; iter: 0; batch classifier loss: 0.086359; batch adversarial loss: 0.392071\n",
      "epoch 117; iter: 0; batch classifier loss: 0.059233; batch adversarial loss: 0.467288\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063879; batch adversarial loss: 0.443817\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052992; batch adversarial loss: 0.428263\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053479; batch adversarial loss: 0.557648\n",
      "epoch 121; iter: 0; batch classifier loss: 0.078947; batch adversarial loss: 0.486676\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017690; batch adversarial loss: 0.495505\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026169; batch adversarial loss: 0.452089\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067519; batch adversarial loss: 0.361520\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052261; batch adversarial loss: 0.405387\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050638; batch adversarial loss: 0.415713\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044762; batch adversarial loss: 0.456715\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034555; batch adversarial loss: 0.427794\n",
      "epoch 129; iter: 0; batch classifier loss: 0.049226; batch adversarial loss: 0.527964\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038776; batch adversarial loss: 0.413124\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032438; batch adversarial loss: 0.405309\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034060; batch adversarial loss: 0.420283\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034896; batch adversarial loss: 0.547524\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021369; batch adversarial loss: 0.409681\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046450; batch adversarial loss: 0.446295\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038874; batch adversarial loss: 0.410551\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038907; batch adversarial loss: 0.427391\n",
      "epoch 138; iter: 0; batch classifier loss: 0.062956; batch adversarial loss: 0.488130\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044065; batch adversarial loss: 0.415002\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026720; batch adversarial loss: 0.431755\n",
      "epoch 141; iter: 0; batch classifier loss: 0.091954; batch adversarial loss: 0.342750\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033061; batch adversarial loss: 0.470047\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030746; batch adversarial loss: 0.506619\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018224; batch adversarial loss: 0.411163\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022231; batch adversarial loss: 0.486500\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025497; batch adversarial loss: 0.459488\n",
      "epoch 147; iter: 0; batch classifier loss: 0.009202; batch adversarial loss: 0.450366\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025164; batch adversarial loss: 0.443555\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029488; batch adversarial loss: 0.456856\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016101; batch adversarial loss: 0.437613\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008044; batch adversarial loss: 0.447356\n",
      "epoch 152; iter: 0; batch classifier loss: 0.009782; batch adversarial loss: 0.405055\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026309; batch adversarial loss: 0.455732\n",
      "epoch 154; iter: 0; batch classifier loss: 0.047415; batch adversarial loss: 0.490700\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027623; batch adversarial loss: 0.449199\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023987; batch adversarial loss: 0.438944\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020761; batch adversarial loss: 0.407044\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047032; batch adversarial loss: 0.488372\n",
      "epoch 159; iter: 0; batch classifier loss: 0.050807; batch adversarial loss: 0.561057\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031053; batch adversarial loss: 0.445786\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019442; batch adversarial loss: 0.451137\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039914; batch adversarial loss: 0.516974\n",
      "epoch 163; iter: 0; batch classifier loss: 0.059244; batch adversarial loss: 0.404427\n",
      "epoch 164; iter: 0; batch classifier loss: 0.005869; batch adversarial loss: 0.402110\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038787; batch adversarial loss: 0.449206\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016700; batch adversarial loss: 0.446963\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041840; batch adversarial loss: 0.388042\n",
      "epoch 168; iter: 0; batch classifier loss: 0.044464; batch adversarial loss: 0.396118\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017019; batch adversarial loss: 0.501737\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017394; batch adversarial loss: 0.413125\n",
      "epoch 171; iter: 0; batch classifier loss: 0.061969; batch adversarial loss: 0.412954\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030018; batch adversarial loss: 0.347434\n",
      "epoch 173; iter: 0; batch classifier loss: 0.048863; batch adversarial loss: 0.322915\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014209; batch adversarial loss: 0.444295\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029031; batch adversarial loss: 0.504990\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023098; batch adversarial loss: 0.434234\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032119; batch adversarial loss: 0.554683\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040417; batch adversarial loss: 0.345370\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009629; batch adversarial loss: 0.295188\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011710; batch adversarial loss: 0.532286\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015151; batch adversarial loss: 0.417352\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016667; batch adversarial loss: 0.492049\n",
      "epoch 183; iter: 0; batch classifier loss: 0.038692; batch adversarial loss: 0.439696\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009605; batch adversarial loss: 0.491485\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037181; batch adversarial loss: 0.457980\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025387; batch adversarial loss: 0.400908\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040108; batch adversarial loss: 0.435376\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021133; batch adversarial loss: 0.509581\n",
      "epoch 189; iter: 0; batch classifier loss: 0.050725; batch adversarial loss: 0.470658\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032323; batch adversarial loss: 0.520187\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007781; batch adversarial loss: 0.412686\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037815; batch adversarial loss: 0.436783\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015371; batch adversarial loss: 0.426558\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008975; batch adversarial loss: 0.446699\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029959; batch adversarial loss: 0.370926\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009879; batch adversarial loss: 0.533241\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012560; batch adversarial loss: 0.395876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.029868; batch adversarial loss: 0.418332\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035299; batch adversarial loss: 0.462355\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705905; batch adversarial loss: 0.804342\n",
      "epoch 1; iter: 0; batch classifier loss: 0.546724; batch adversarial loss: 0.790103\n",
      "epoch 2; iter: 0; batch classifier loss: 0.679058; batch adversarial loss: 0.760704\n",
      "epoch 3; iter: 0; batch classifier loss: 0.738323; batch adversarial loss: 0.694617\n",
      "epoch 4; iter: 0; batch classifier loss: 0.639860; batch adversarial loss: 0.641923\n",
      "epoch 5; iter: 0; batch classifier loss: 0.462732; batch adversarial loss: 0.577788\n",
      "epoch 6; iter: 0; batch classifier loss: 0.427074; batch adversarial loss: 0.579103\n",
      "epoch 7; iter: 0; batch classifier loss: 0.368157; batch adversarial loss: 0.559124\n",
      "epoch 8; iter: 0; batch classifier loss: 0.353343; batch adversarial loss: 0.546988\n",
      "epoch 9; iter: 0; batch classifier loss: 0.298278; batch adversarial loss: 0.590192\n",
      "epoch 10; iter: 0; batch classifier loss: 0.357500; batch adversarial loss: 0.563882\n",
      "epoch 11; iter: 0; batch classifier loss: 0.317431; batch adversarial loss: 0.575143\n",
      "epoch 12; iter: 0; batch classifier loss: 0.317856; batch adversarial loss: 0.530285\n",
      "epoch 13; iter: 0; batch classifier loss: 0.310547; batch adversarial loss: 0.515702\n",
      "epoch 14; iter: 0; batch classifier loss: 0.331300; batch adversarial loss: 0.512626\n",
      "epoch 15; iter: 0; batch classifier loss: 0.272885; batch adversarial loss: 0.578047\n",
      "epoch 16; iter: 0; batch classifier loss: 0.241170; batch adversarial loss: 0.526425\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265238; batch adversarial loss: 0.541592\n",
      "epoch 18; iter: 0; batch classifier loss: 0.314610; batch adversarial loss: 0.510840\n",
      "epoch 19; iter: 0; batch classifier loss: 0.344061; batch adversarial loss: 0.435140\n",
      "epoch 20; iter: 0; batch classifier loss: 0.230781; batch adversarial loss: 0.446349\n",
      "epoch 21; iter: 0; batch classifier loss: 0.302659; batch adversarial loss: 0.501802\n",
      "epoch 22; iter: 0; batch classifier loss: 0.279950; batch adversarial loss: 0.506510\n",
      "epoch 23; iter: 0; batch classifier loss: 0.358205; batch adversarial loss: 0.534978\n",
      "epoch 24; iter: 0; batch classifier loss: 0.268875; batch adversarial loss: 0.527235\n",
      "epoch 25; iter: 0; batch classifier loss: 0.231559; batch adversarial loss: 0.441038\n",
      "epoch 26; iter: 0; batch classifier loss: 0.218011; batch adversarial loss: 0.516546\n",
      "epoch 27; iter: 0; batch classifier loss: 0.223092; batch adversarial loss: 0.432431\n",
      "epoch 28; iter: 0; batch classifier loss: 0.221613; batch adversarial loss: 0.540363\n",
      "epoch 29; iter: 0; batch classifier loss: 0.212183; batch adversarial loss: 0.433249\n",
      "epoch 30; iter: 0; batch classifier loss: 0.196812; batch adversarial loss: 0.595306\n",
      "epoch 31; iter: 0; batch classifier loss: 0.163922; batch adversarial loss: 0.483270\n",
      "epoch 32; iter: 0; batch classifier loss: 0.221844; batch adversarial loss: 0.495805\n",
      "epoch 33; iter: 0; batch classifier loss: 0.242800; batch adversarial loss: 0.450842\n",
      "epoch 34; iter: 0; batch classifier loss: 0.173828; batch adversarial loss: 0.550291\n",
      "epoch 35; iter: 0; batch classifier loss: 0.195474; batch adversarial loss: 0.506823\n",
      "epoch 36; iter: 0; batch classifier loss: 0.209161; batch adversarial loss: 0.489860\n",
      "epoch 37; iter: 0; batch classifier loss: 0.185448; batch adversarial loss: 0.431927\n",
      "epoch 38; iter: 0; batch classifier loss: 0.154994; batch adversarial loss: 0.455674\n",
      "epoch 39; iter: 0; batch classifier loss: 0.218365; batch adversarial loss: 0.462209\n",
      "epoch 40; iter: 0; batch classifier loss: 0.212480; batch adversarial loss: 0.411610\n",
      "epoch 41; iter: 0; batch classifier loss: 0.189590; batch adversarial loss: 0.513807\n",
      "epoch 42; iter: 0; batch classifier loss: 0.155712; batch adversarial loss: 0.459628\n",
      "epoch 43; iter: 0; batch classifier loss: 0.257183; batch adversarial loss: 0.471894\n",
      "epoch 44; iter: 0; batch classifier loss: 0.188674; batch adversarial loss: 0.538749\n",
      "epoch 45; iter: 0; batch classifier loss: 0.172144; batch adversarial loss: 0.473897\n",
      "epoch 46; iter: 0; batch classifier loss: 0.149528; batch adversarial loss: 0.489135\n",
      "epoch 47; iter: 0; batch classifier loss: 0.235274; batch adversarial loss: 0.505661\n",
      "epoch 48; iter: 0; batch classifier loss: 0.182942; batch adversarial loss: 0.434552\n",
      "epoch 49; iter: 0; batch classifier loss: 0.218998; batch adversarial loss: 0.432346\n",
      "epoch 50; iter: 0; batch classifier loss: 0.121676; batch adversarial loss: 0.457663\n",
      "epoch 51; iter: 0; batch classifier loss: 0.222774; batch adversarial loss: 0.505199\n",
      "epoch 52; iter: 0; batch classifier loss: 0.191699; batch adversarial loss: 0.457137\n",
      "epoch 53; iter: 0; batch classifier loss: 0.229916; batch adversarial loss: 0.472844\n",
      "epoch 54; iter: 0; batch classifier loss: 0.153153; batch adversarial loss: 0.401216\n",
      "epoch 55; iter: 0; batch classifier loss: 0.222786; batch adversarial loss: 0.411589\n",
      "epoch 56; iter: 0; batch classifier loss: 0.152140; batch adversarial loss: 0.436361\n",
      "epoch 57; iter: 0; batch classifier loss: 0.160485; batch adversarial loss: 0.424764\n",
      "epoch 58; iter: 0; batch classifier loss: 0.171857; batch adversarial loss: 0.462457\n",
      "epoch 59; iter: 0; batch classifier loss: 0.181068; batch adversarial loss: 0.508362\n",
      "epoch 60; iter: 0; batch classifier loss: 0.169748; batch adversarial loss: 0.506456\n",
      "epoch 61; iter: 0; batch classifier loss: 0.175576; batch adversarial loss: 0.423829\n",
      "epoch 62; iter: 0; batch classifier loss: 0.193333; batch adversarial loss: 0.423777\n",
      "epoch 63; iter: 0; batch classifier loss: 0.174663; batch adversarial loss: 0.471173\n",
      "epoch 64; iter: 0; batch classifier loss: 0.137919; batch adversarial loss: 0.436539\n",
      "epoch 65; iter: 0; batch classifier loss: 0.204717; batch adversarial loss: 0.447304\n",
      "epoch 66; iter: 0; batch classifier loss: 0.130874; batch adversarial loss: 0.494332\n",
      "epoch 67; iter: 0; batch classifier loss: 0.151557; batch adversarial loss: 0.374920\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096906; batch adversarial loss: 0.540811\n",
      "epoch 69; iter: 0; batch classifier loss: 0.096135; batch adversarial loss: 0.411272\n",
      "epoch 70; iter: 0; batch classifier loss: 0.166035; batch adversarial loss: 0.543111\n",
      "epoch 71; iter: 0; batch classifier loss: 0.146317; batch adversarial loss: 0.519077\n",
      "epoch 72; iter: 0; batch classifier loss: 0.210334; batch adversarial loss: 0.364036\n",
      "epoch 73; iter: 0; batch classifier loss: 0.175330; batch adversarial loss: 0.484049\n",
      "epoch 74; iter: 0; batch classifier loss: 0.137444; batch adversarial loss: 0.471620\n",
      "epoch 75; iter: 0; batch classifier loss: 0.146005; batch adversarial loss: 0.530080\n",
      "epoch 76; iter: 0; batch classifier loss: 0.153474; batch adversarial loss: 0.495079\n",
      "epoch 77; iter: 0; batch classifier loss: 0.272367; batch adversarial loss: 0.352654\n",
      "epoch 78; iter: 0; batch classifier loss: 0.169421; batch adversarial loss: 0.446842\n",
      "epoch 79; iter: 0; batch classifier loss: 0.069181; batch adversarial loss: 0.540813\n",
      "epoch 80; iter: 0; batch classifier loss: 0.096825; batch adversarial loss: 0.478489\n",
      "epoch 81; iter: 0; batch classifier loss: 0.103690; batch adversarial loss: 0.434021\n",
      "epoch 82; iter: 0; batch classifier loss: 0.103895; batch adversarial loss: 0.530196\n",
      "epoch 83; iter: 0; batch classifier loss: 0.202933; batch adversarial loss: 0.447955\n",
      "epoch 84; iter: 0; batch classifier loss: 0.125556; batch adversarial loss: 0.514452\n",
      "epoch 85; iter: 0; batch classifier loss: 0.109132; batch adversarial loss: 0.448476\n",
      "epoch 86; iter: 0; batch classifier loss: 0.087240; batch adversarial loss: 0.479181\n",
      "epoch 87; iter: 0; batch classifier loss: 0.134714; batch adversarial loss: 0.479138\n",
      "epoch 88; iter: 0; batch classifier loss: 0.103833; batch adversarial loss: 0.445608\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068465; batch adversarial loss: 0.481421\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068216; batch adversarial loss: 0.502851\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066793; batch adversarial loss: 0.484820\n",
      "epoch 92; iter: 0; batch classifier loss: 0.103379; batch adversarial loss: 0.487236\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077865; batch adversarial loss: 0.447614\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077212; batch adversarial loss: 0.551203\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060212; batch adversarial loss: 0.488899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.154047; batch adversarial loss: 0.357945\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059046; batch adversarial loss: 0.412475\n",
      "epoch 98; iter: 0; batch classifier loss: 0.081213; batch adversarial loss: 0.402450\n",
      "epoch 99; iter: 0; batch classifier loss: 0.066049; batch adversarial loss: 0.431558\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051035; batch adversarial loss: 0.447187\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051983; batch adversarial loss: 0.565904\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059880; batch adversarial loss: 0.520408\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066767; batch adversarial loss: 0.480156\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057907; batch adversarial loss: 0.438814\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052335; batch adversarial loss: 0.554366\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064449; batch adversarial loss: 0.479538\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053801; batch adversarial loss: 0.475103\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038018; batch adversarial loss: 0.400694\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033419; batch adversarial loss: 0.489538\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051202; batch adversarial loss: 0.463278\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054304; batch adversarial loss: 0.486197\n",
      "epoch 112; iter: 0; batch classifier loss: 0.073706; batch adversarial loss: 0.396977\n",
      "epoch 113; iter: 0; batch classifier loss: 0.011722; batch adversarial loss: 0.426454\n",
      "epoch 114; iter: 0; batch classifier loss: 0.055678; batch adversarial loss: 0.343917\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038178; batch adversarial loss: 0.525324\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033148; batch adversarial loss: 0.540136\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049088; batch adversarial loss: 0.416497\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037132; batch adversarial loss: 0.428949\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035017; batch adversarial loss: 0.458556\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036627; batch adversarial loss: 0.412386\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054913; batch adversarial loss: 0.404997\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031217; batch adversarial loss: 0.492092\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020819; batch adversarial loss: 0.513659\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019404; batch adversarial loss: 0.440862\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046383; batch adversarial loss: 0.475558\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047178; batch adversarial loss: 0.506361\n",
      "epoch 127; iter: 0; batch classifier loss: 0.016865; batch adversarial loss: 0.467677\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026669; batch adversarial loss: 0.394920\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019593; batch adversarial loss: 0.357407\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023003; batch adversarial loss: 0.467739\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018029; batch adversarial loss: 0.506230\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037182; batch adversarial loss: 0.343234\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042163; batch adversarial loss: 0.459232\n",
      "epoch 134; iter: 0; batch classifier loss: 0.066375; batch adversarial loss: 0.482067\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024815; batch adversarial loss: 0.439065\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023409; batch adversarial loss: 0.495159\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034039; batch adversarial loss: 0.514659\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048670; batch adversarial loss: 0.470207\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033565; batch adversarial loss: 0.538327\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028475; batch adversarial loss: 0.431203\n",
      "epoch 141; iter: 0; batch classifier loss: 0.010777; batch adversarial loss: 0.393232\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026609; batch adversarial loss: 0.398342\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033449; batch adversarial loss: 0.428970\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020693; batch adversarial loss: 0.492738\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012140; batch adversarial loss: 0.495681\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022452; batch adversarial loss: 0.507299\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024259; batch adversarial loss: 0.550987\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031168; batch adversarial loss: 0.432310\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029814; batch adversarial loss: 0.407777\n",
      "epoch 150; iter: 0; batch classifier loss: 0.008814; batch adversarial loss: 0.457774\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012477; batch adversarial loss: 0.465152\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025487; batch adversarial loss: 0.437748\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008376; batch adversarial loss: 0.504512\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024336; batch adversarial loss: 0.487427\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022886; batch adversarial loss: 0.582442\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027540; batch adversarial loss: 0.473143\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010877; batch adversarial loss: 0.469646\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019717; batch adversarial loss: 0.452474\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037181; batch adversarial loss: 0.465997\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007544; batch adversarial loss: 0.470805\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028986; batch adversarial loss: 0.410522\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031280; batch adversarial loss: 0.441510\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022143; batch adversarial loss: 0.443750\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015390; batch adversarial loss: 0.397601\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015601; batch adversarial loss: 0.443936\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022166; batch adversarial loss: 0.437273\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006836; batch adversarial loss: 0.460825\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007283; batch adversarial loss: 0.541338\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006879; batch adversarial loss: 0.448004\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029857; batch adversarial loss: 0.440959\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027060; batch adversarial loss: 0.476802\n",
      "epoch 172; iter: 0; batch classifier loss: 0.037246; batch adversarial loss: 0.489041\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034222; batch adversarial loss: 0.511000\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025844; batch adversarial loss: 0.488069\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019424; batch adversarial loss: 0.486766\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011569; batch adversarial loss: 0.417763\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006107; batch adversarial loss: 0.406720\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009661; batch adversarial loss: 0.518868\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008605; batch adversarial loss: 0.430501\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029617; batch adversarial loss: 0.435041\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022032; batch adversarial loss: 0.443118\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015180; batch adversarial loss: 0.483384\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033413; batch adversarial loss: 0.558283\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026733; batch adversarial loss: 0.491059\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015227; batch adversarial loss: 0.465610\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015334; batch adversarial loss: 0.449856\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014998; batch adversarial loss: 0.484968\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017744; batch adversarial loss: 0.444504\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036947; batch adversarial loss: 0.376333\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011582; batch adversarial loss: 0.555885\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032255; batch adversarial loss: 0.462235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.039203; batch adversarial loss: 0.415655\n",
      "epoch 193; iter: 0; batch classifier loss: 0.033271; batch adversarial loss: 0.364488\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008221; batch adversarial loss: 0.386869\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025733; batch adversarial loss: 0.451207\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025812; batch adversarial loss: 0.463743\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014783; batch adversarial loss: 0.477407\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007389; batch adversarial loss: 0.442947\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012360; batch adversarial loss: 0.425525\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701709; batch adversarial loss: 0.635964\n",
      "epoch 1; iter: 0; batch classifier loss: 0.463077; batch adversarial loss: 0.647586\n",
      "epoch 2; iter: 0; batch classifier loss: 0.378339; batch adversarial loss: 0.623452\n",
      "epoch 3; iter: 0; batch classifier loss: 0.472250; batch adversarial loss: 0.612385\n",
      "epoch 4; iter: 0; batch classifier loss: 0.412319; batch adversarial loss: 0.605797\n",
      "epoch 5; iter: 0; batch classifier loss: 0.494771; batch adversarial loss: 0.596576\n",
      "epoch 6; iter: 0; batch classifier loss: 0.380235; batch adversarial loss: 0.565768\n",
      "epoch 7; iter: 0; batch classifier loss: 0.458471; batch adversarial loss: 0.598856\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562383; batch adversarial loss: 0.513433\n",
      "epoch 9; iter: 0; batch classifier loss: 0.495670; batch adversarial loss: 0.534837\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472430; batch adversarial loss: 0.534442\n",
      "epoch 11; iter: 0; batch classifier loss: 0.365133; batch adversarial loss: 0.525490\n",
      "epoch 12; iter: 0; batch classifier loss: 0.343232; batch adversarial loss: 0.489841\n",
      "epoch 13; iter: 0; batch classifier loss: 0.316009; batch adversarial loss: 0.545173\n",
      "epoch 14; iter: 0; batch classifier loss: 0.319526; batch adversarial loss: 0.521484\n",
      "epoch 15; iter: 0; batch classifier loss: 0.306806; batch adversarial loss: 0.483110\n",
      "epoch 16; iter: 0; batch classifier loss: 0.380091; batch adversarial loss: 0.461407\n",
      "epoch 17; iter: 0; batch classifier loss: 0.286636; batch adversarial loss: 0.477148\n",
      "epoch 18; iter: 0; batch classifier loss: 0.300894; batch adversarial loss: 0.488794\n",
      "epoch 19; iter: 0; batch classifier loss: 0.269339; batch adversarial loss: 0.471139\n",
      "epoch 20; iter: 0; batch classifier loss: 0.306645; batch adversarial loss: 0.492289\n",
      "epoch 21; iter: 0; batch classifier loss: 0.264789; batch adversarial loss: 0.565365\n",
      "epoch 22; iter: 0; batch classifier loss: 0.235810; batch adversarial loss: 0.360782\n",
      "epoch 23; iter: 0; batch classifier loss: 0.255509; batch adversarial loss: 0.462702\n",
      "epoch 24; iter: 0; batch classifier loss: 0.237553; batch adversarial loss: 0.533063\n",
      "epoch 25; iter: 0; batch classifier loss: 0.188482; batch adversarial loss: 0.443448\n",
      "epoch 26; iter: 0; batch classifier loss: 0.201718; batch adversarial loss: 0.525652\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181236; batch adversarial loss: 0.480196\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179130; batch adversarial loss: 0.504095\n",
      "epoch 29; iter: 0; batch classifier loss: 0.169307; batch adversarial loss: 0.529291\n",
      "epoch 30; iter: 0; batch classifier loss: 0.238609; batch adversarial loss: 0.435393\n",
      "epoch 31; iter: 0; batch classifier loss: 0.203127; batch adversarial loss: 0.432078\n",
      "epoch 32; iter: 0; batch classifier loss: 0.177253; batch adversarial loss: 0.486422\n",
      "epoch 33; iter: 0; batch classifier loss: 0.160400; batch adversarial loss: 0.402265\n",
      "epoch 34; iter: 0; batch classifier loss: 0.167499; batch adversarial loss: 0.479777\n",
      "epoch 35; iter: 0; batch classifier loss: 0.168262; batch adversarial loss: 0.513662\n",
      "epoch 36; iter: 0; batch classifier loss: 0.201867; batch adversarial loss: 0.542211\n",
      "epoch 37; iter: 0; batch classifier loss: 0.178311; batch adversarial loss: 0.429642\n",
      "epoch 38; iter: 0; batch classifier loss: 0.136345; batch adversarial loss: 0.482590\n",
      "epoch 39; iter: 0; batch classifier loss: 0.163056; batch adversarial loss: 0.429862\n",
      "epoch 40; iter: 0; batch classifier loss: 0.170008; batch adversarial loss: 0.464343\n",
      "epoch 41; iter: 0; batch classifier loss: 0.192524; batch adversarial loss: 0.399383\n",
      "epoch 42; iter: 0; batch classifier loss: 0.195075; batch adversarial loss: 0.451921\n",
      "epoch 43; iter: 0; batch classifier loss: 0.194398; batch adversarial loss: 0.528965\n",
      "epoch 44; iter: 0; batch classifier loss: 0.151613; batch adversarial loss: 0.554872\n",
      "epoch 45; iter: 0; batch classifier loss: 0.143863; batch adversarial loss: 0.521998\n",
      "epoch 46; iter: 0; batch classifier loss: 0.185572; batch adversarial loss: 0.476739\n",
      "epoch 47; iter: 0; batch classifier loss: 0.177879; batch adversarial loss: 0.451507\n",
      "epoch 48; iter: 0; batch classifier loss: 0.130618; batch adversarial loss: 0.537781\n",
      "epoch 49; iter: 0; batch classifier loss: 0.148233; batch adversarial loss: 0.567248\n",
      "epoch 50; iter: 0; batch classifier loss: 0.189480; batch adversarial loss: 0.454380\n",
      "epoch 51; iter: 0; batch classifier loss: 0.147210; batch adversarial loss: 0.444206\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161869; batch adversarial loss: 0.545573\n",
      "epoch 53; iter: 0; batch classifier loss: 0.138804; batch adversarial loss: 0.403048\n",
      "epoch 54; iter: 0; batch classifier loss: 0.174886; batch adversarial loss: 0.428126\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125583; batch adversarial loss: 0.494986\n",
      "epoch 56; iter: 0; batch classifier loss: 0.148367; batch adversarial loss: 0.420068\n",
      "epoch 57; iter: 0; batch classifier loss: 0.164295; batch adversarial loss: 0.557763\n",
      "epoch 58; iter: 0; batch classifier loss: 0.096081; batch adversarial loss: 0.501623\n",
      "epoch 59; iter: 0; batch classifier loss: 0.158772; batch adversarial loss: 0.503060\n",
      "epoch 60; iter: 0; batch classifier loss: 0.100021; batch adversarial loss: 0.472804\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088311; batch adversarial loss: 0.585812\n",
      "epoch 62; iter: 0; batch classifier loss: 0.145694; batch adversarial loss: 0.500681\n",
      "epoch 63; iter: 0; batch classifier loss: 0.117722; batch adversarial loss: 0.525526\n",
      "epoch 64; iter: 0; batch classifier loss: 0.169099; batch adversarial loss: 0.366662\n",
      "epoch 65; iter: 0; batch classifier loss: 0.198020; batch adversarial loss: 0.378838\n",
      "epoch 66; iter: 0; batch classifier loss: 0.150746; batch adversarial loss: 0.509588\n",
      "epoch 67; iter: 0; batch classifier loss: 0.132952; batch adversarial loss: 0.484944\n",
      "epoch 68; iter: 0; batch classifier loss: 0.086705; batch adversarial loss: 0.513824\n",
      "epoch 69; iter: 0; batch classifier loss: 0.141868; batch adversarial loss: 0.475178\n",
      "epoch 70; iter: 0; batch classifier loss: 0.108186; batch adversarial loss: 0.410000\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084718; batch adversarial loss: 0.506739\n",
      "epoch 72; iter: 0; batch classifier loss: 0.140605; batch adversarial loss: 0.491622\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101717; batch adversarial loss: 0.394130\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101814; batch adversarial loss: 0.475420\n",
      "epoch 75; iter: 0; batch classifier loss: 0.115811; batch adversarial loss: 0.417486\n",
      "epoch 76; iter: 0; batch classifier loss: 0.116681; batch adversarial loss: 0.541370\n",
      "epoch 77; iter: 0; batch classifier loss: 0.154980; batch adversarial loss: 0.574630\n",
      "epoch 78; iter: 0; batch classifier loss: 0.156362; batch adversarial loss: 0.458657\n",
      "epoch 79; iter: 0; batch classifier loss: 0.086109; batch adversarial loss: 0.445512\n",
      "epoch 80; iter: 0; batch classifier loss: 0.141853; batch adversarial loss: 0.335666\n",
      "epoch 81; iter: 0; batch classifier loss: 0.135193; batch adversarial loss: 0.385430\n",
      "epoch 82; iter: 0; batch classifier loss: 0.082821; batch adversarial loss: 0.513389\n",
      "epoch 83; iter: 0; batch classifier loss: 0.107578; batch adversarial loss: 0.416408\n",
      "epoch 84; iter: 0; batch classifier loss: 0.098206; batch adversarial loss: 0.428017\n",
      "epoch 85; iter: 0; batch classifier loss: 0.118849; batch adversarial loss: 0.434653\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068729; batch adversarial loss: 0.563399\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071629; batch adversarial loss: 0.460412\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075512; batch adversarial loss: 0.433075\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056778; batch adversarial loss: 0.449581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.043199; batch adversarial loss: 0.474756\n",
      "epoch 91; iter: 0; batch classifier loss: 0.091532; batch adversarial loss: 0.429441\n",
      "epoch 92; iter: 0; batch classifier loss: 0.087638; batch adversarial loss: 0.390030\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067535; batch adversarial loss: 0.468631\n",
      "epoch 94; iter: 0; batch classifier loss: 0.095156; batch adversarial loss: 0.533331\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087458; batch adversarial loss: 0.428475\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068445; batch adversarial loss: 0.537544\n",
      "epoch 97; iter: 0; batch classifier loss: 0.126835; batch adversarial loss: 0.372993\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059842; batch adversarial loss: 0.481290\n",
      "epoch 99; iter: 0; batch classifier loss: 0.081572; batch adversarial loss: 0.419236\n",
      "epoch 100; iter: 0; batch classifier loss: 0.078102; batch adversarial loss: 0.487727\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053070; batch adversarial loss: 0.500703\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071466; batch adversarial loss: 0.484133\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072202; batch adversarial loss: 0.454669\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038873; batch adversarial loss: 0.417385\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045620; batch adversarial loss: 0.471178\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042853; batch adversarial loss: 0.449782\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069575; batch adversarial loss: 0.535480\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052098; batch adversarial loss: 0.540724\n",
      "epoch 109; iter: 0; batch classifier loss: 0.069881; batch adversarial loss: 0.493486\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042406; batch adversarial loss: 0.471292\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049411; batch adversarial loss: 0.455530\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044004; batch adversarial loss: 0.531326\n",
      "epoch 113; iter: 0; batch classifier loss: 0.068713; batch adversarial loss: 0.561344\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049039; batch adversarial loss: 0.486683\n",
      "epoch 115; iter: 0; batch classifier loss: 0.073905; batch adversarial loss: 0.433168\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035482; batch adversarial loss: 0.451243\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042926; batch adversarial loss: 0.547663\n",
      "epoch 118; iter: 0; batch classifier loss: 0.021643; batch adversarial loss: 0.486637\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047610; batch adversarial loss: 0.467514\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025822; batch adversarial loss: 0.447735\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036911; batch adversarial loss: 0.441965\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028365; batch adversarial loss: 0.445662\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025072; batch adversarial loss: 0.491644\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040353; batch adversarial loss: 0.448531\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035710; batch adversarial loss: 0.417717\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021881; batch adversarial loss: 0.452476\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042491; batch adversarial loss: 0.487322\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027871; batch adversarial loss: 0.415367\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018231; batch adversarial loss: 0.476102\n",
      "epoch 130; iter: 0; batch classifier loss: 0.053696; batch adversarial loss: 0.552887\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023744; batch adversarial loss: 0.451578\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051540; batch adversarial loss: 0.462881\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024235; batch adversarial loss: 0.419376\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029375; batch adversarial loss: 0.512523\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013217; batch adversarial loss: 0.535081\n",
      "epoch 136; iter: 0; batch classifier loss: 0.066060; batch adversarial loss: 0.456635\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035366; batch adversarial loss: 0.488096\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045893; batch adversarial loss: 0.497414\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017031; batch adversarial loss: 0.544383\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045142; batch adversarial loss: 0.522248\n",
      "epoch 141; iter: 0; batch classifier loss: 0.055765; batch adversarial loss: 0.424084\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045504; batch adversarial loss: 0.433241\n",
      "epoch 143; iter: 0; batch classifier loss: 0.058813; batch adversarial loss: 0.437328\n",
      "epoch 144; iter: 0; batch classifier loss: 0.056150; batch adversarial loss: 0.508341\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041892; batch adversarial loss: 0.486055\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031170; batch adversarial loss: 0.508859\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020344; batch adversarial loss: 0.451503\n",
      "epoch 148; iter: 0; batch classifier loss: 0.050521; batch adversarial loss: 0.393468\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017594; batch adversarial loss: 0.460924\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026983; batch adversarial loss: 0.426271\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030186; batch adversarial loss: 0.406795\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017747; batch adversarial loss: 0.430718\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036451; batch adversarial loss: 0.478169\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017379; batch adversarial loss: 0.441605\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021392; batch adversarial loss: 0.519461\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018873; batch adversarial loss: 0.457923\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038903; batch adversarial loss: 0.409541\n",
      "epoch 158; iter: 0; batch classifier loss: 0.051213; batch adversarial loss: 0.461752\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033527; batch adversarial loss: 0.463802\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017437; batch adversarial loss: 0.486757\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022960; batch adversarial loss: 0.515038\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007806; batch adversarial loss: 0.473847\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029210; batch adversarial loss: 0.351177\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028592; batch adversarial loss: 0.438028\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027573; batch adversarial loss: 0.522975\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037710; batch adversarial loss: 0.494164\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029768; batch adversarial loss: 0.499457\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025148; batch adversarial loss: 0.478456\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040970; batch adversarial loss: 0.437190\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016253; batch adversarial loss: 0.434706\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015214; batch adversarial loss: 0.431831\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012427; batch adversarial loss: 0.455615\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014005; batch adversarial loss: 0.426421\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023486; batch adversarial loss: 0.368077\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027830; batch adversarial loss: 0.380913\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011418; batch adversarial loss: 0.415011\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013348; batch adversarial loss: 0.406727\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015036; batch adversarial loss: 0.433955\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032933; batch adversarial loss: 0.373997\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030231; batch adversarial loss: 0.458649\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011451; batch adversarial loss: 0.428760\n",
      "epoch 182; iter: 0; batch classifier loss: 0.065374; batch adversarial loss: 0.387321\n",
      "epoch 183; iter: 0; batch classifier loss: 0.003577; batch adversarial loss: 0.493811\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022763; batch adversarial loss: 0.482690\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016119; batch adversarial loss: 0.516916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.017775; batch adversarial loss: 0.473007\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025480; batch adversarial loss: 0.442879\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009053; batch adversarial loss: 0.401230\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009066; batch adversarial loss: 0.427397\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023456; batch adversarial loss: 0.477450\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031007; batch adversarial loss: 0.434838\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025783; batch adversarial loss: 0.328386\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034792; batch adversarial loss: 0.462032\n",
      "epoch 194; iter: 0; batch classifier loss: 0.043401; batch adversarial loss: 0.469435\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021292; batch adversarial loss: 0.443581\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012820; batch adversarial loss: 0.434714\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011477; batch adversarial loss: 0.565135\n",
      "epoch 198; iter: 0; batch classifier loss: 0.035628; batch adversarial loss: 0.380608\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006388; batch adversarial loss: 0.558545\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707970; batch adversarial loss: 0.707201\n",
      "epoch 1; iter: 0; batch classifier loss: 0.514138; batch adversarial loss: 0.668557\n",
      "epoch 2; iter: 0; batch classifier loss: 0.434551; batch adversarial loss: 0.643322\n",
      "epoch 3; iter: 0; batch classifier loss: 0.482706; batch adversarial loss: 0.623533\n",
      "epoch 4; iter: 0; batch classifier loss: 0.465638; batch adversarial loss: 0.626383\n",
      "epoch 5; iter: 0; batch classifier loss: 0.473598; batch adversarial loss: 0.587516\n",
      "epoch 6; iter: 0; batch classifier loss: 0.441588; batch adversarial loss: 0.558538\n",
      "epoch 7; iter: 0; batch classifier loss: 0.402000; batch adversarial loss: 0.560652\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521030; batch adversarial loss: 0.519777\n",
      "epoch 9; iter: 0; batch classifier loss: 0.439179; batch adversarial loss: 0.532384\n",
      "epoch 10; iter: 0; batch classifier loss: 0.369422; batch adversarial loss: 0.525637\n",
      "epoch 11; iter: 0; batch classifier loss: 0.380068; batch adversarial loss: 0.505033\n",
      "epoch 12; iter: 0; batch classifier loss: 0.442157; batch adversarial loss: 0.533824\n",
      "epoch 13; iter: 0; batch classifier loss: 0.445654; batch adversarial loss: 0.551472\n",
      "epoch 14; iter: 0; batch classifier loss: 0.382180; batch adversarial loss: 0.517195\n",
      "epoch 15; iter: 0; batch classifier loss: 0.339851; batch adversarial loss: 0.487886\n",
      "epoch 16; iter: 0; batch classifier loss: 0.357102; batch adversarial loss: 0.502792\n",
      "epoch 17; iter: 0; batch classifier loss: 0.322458; batch adversarial loss: 0.499149\n",
      "epoch 18; iter: 0; batch classifier loss: 0.285668; batch adversarial loss: 0.563226\n",
      "epoch 19; iter: 0; batch classifier loss: 0.309713; batch adversarial loss: 0.430689\n",
      "epoch 20; iter: 0; batch classifier loss: 0.279334; batch adversarial loss: 0.440441\n",
      "epoch 21; iter: 0; batch classifier loss: 0.230084; batch adversarial loss: 0.531748\n",
      "epoch 22; iter: 0; batch classifier loss: 0.278717; batch adversarial loss: 0.464382\n",
      "epoch 23; iter: 0; batch classifier loss: 0.269170; batch adversarial loss: 0.592520\n",
      "epoch 24; iter: 0; batch classifier loss: 0.220523; batch adversarial loss: 0.497779\n",
      "epoch 25; iter: 0; batch classifier loss: 0.251555; batch adversarial loss: 0.442014\n",
      "epoch 26; iter: 0; batch classifier loss: 0.240165; batch adversarial loss: 0.549819\n",
      "epoch 27; iter: 0; batch classifier loss: 0.215053; batch adversarial loss: 0.554890\n",
      "epoch 28; iter: 0; batch classifier loss: 0.266668; batch adversarial loss: 0.478929\n",
      "epoch 29; iter: 0; batch classifier loss: 0.245969; batch adversarial loss: 0.503420\n",
      "epoch 30; iter: 0; batch classifier loss: 0.223266; batch adversarial loss: 0.480261\n",
      "epoch 31; iter: 0; batch classifier loss: 0.242111; batch adversarial loss: 0.418048\n",
      "epoch 32; iter: 0; batch classifier loss: 0.228035; batch adversarial loss: 0.455978\n",
      "epoch 33; iter: 0; batch classifier loss: 0.172810; batch adversarial loss: 0.505880\n",
      "epoch 34; iter: 0; batch classifier loss: 0.279190; batch adversarial loss: 0.490885\n",
      "epoch 35; iter: 0; batch classifier loss: 0.258310; batch adversarial loss: 0.464888\n",
      "epoch 36; iter: 0; batch classifier loss: 0.255259; batch adversarial loss: 0.412073\n",
      "epoch 37; iter: 0; batch classifier loss: 0.226051; batch adversarial loss: 0.502590\n",
      "epoch 38; iter: 0; batch classifier loss: 0.286600; batch adversarial loss: 0.498955\n",
      "epoch 39; iter: 0; batch classifier loss: 0.177775; batch adversarial loss: 0.506113\n",
      "epoch 40; iter: 0; batch classifier loss: 0.235654; batch adversarial loss: 0.497229\n",
      "epoch 41; iter: 0; batch classifier loss: 0.325918; batch adversarial loss: 0.384147\n",
      "epoch 42; iter: 0; batch classifier loss: 0.205043; batch adversarial loss: 0.435831\n",
      "epoch 43; iter: 0; batch classifier loss: 0.253834; batch adversarial loss: 0.492274\n",
      "epoch 44; iter: 0; batch classifier loss: 0.216770; batch adversarial loss: 0.459936\n",
      "epoch 45; iter: 0; batch classifier loss: 0.253327; batch adversarial loss: 0.327882\n",
      "epoch 46; iter: 0; batch classifier loss: 0.169159; batch adversarial loss: 0.474500\n",
      "epoch 47; iter: 0; batch classifier loss: 0.204624; batch adversarial loss: 0.470440\n",
      "epoch 48; iter: 0; batch classifier loss: 0.221916; batch adversarial loss: 0.340836\n",
      "epoch 49; iter: 0; batch classifier loss: 0.256729; batch adversarial loss: 0.448035\n",
      "epoch 50; iter: 0; batch classifier loss: 0.174175; batch adversarial loss: 0.484402\n",
      "epoch 51; iter: 0; batch classifier loss: 0.211603; batch adversarial loss: 0.447664\n",
      "epoch 52; iter: 0; batch classifier loss: 0.210521; batch adversarial loss: 0.554399\n",
      "epoch 53; iter: 0; batch classifier loss: 0.206095; batch adversarial loss: 0.446997\n",
      "epoch 54; iter: 0; batch classifier loss: 0.119767; batch adversarial loss: 0.420906\n",
      "epoch 55; iter: 0; batch classifier loss: 0.134674; batch adversarial loss: 0.483079\n",
      "epoch 56; iter: 0; batch classifier loss: 0.120246; batch adversarial loss: 0.431775\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082710; batch adversarial loss: 0.381181\n",
      "epoch 58; iter: 0; batch classifier loss: 0.081749; batch adversarial loss: 0.395051\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067803; batch adversarial loss: 0.485231\n",
      "epoch 60; iter: 0; batch classifier loss: 0.242309; batch adversarial loss: 0.456772\n",
      "epoch 61; iter: 0; batch classifier loss: 0.186891; batch adversarial loss: 0.497640\n",
      "epoch 62; iter: 0; batch classifier loss: 0.140722; batch adversarial loss: 0.383753\n",
      "epoch 63; iter: 0; batch classifier loss: 0.147054; batch adversarial loss: 0.513546\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099591; batch adversarial loss: 0.376516\n",
      "epoch 65; iter: 0; batch classifier loss: 0.084912; batch adversarial loss: 0.388468\n",
      "epoch 66; iter: 0; batch classifier loss: 0.116714; batch adversarial loss: 0.480646\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107218; batch adversarial loss: 0.489665\n",
      "epoch 68; iter: 0; batch classifier loss: 0.124679; batch adversarial loss: 0.382305\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075643; batch adversarial loss: 0.491218\n",
      "epoch 70; iter: 0; batch classifier loss: 0.120201; batch adversarial loss: 0.406752\n",
      "epoch 71; iter: 0; batch classifier loss: 0.145578; batch adversarial loss: 0.423226\n",
      "epoch 72; iter: 0; batch classifier loss: 0.108313; batch adversarial loss: 0.390643\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084166; batch adversarial loss: 0.592500\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089647; batch adversarial loss: 0.510416\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096688; batch adversarial loss: 0.418004\n",
      "epoch 76; iter: 0; batch classifier loss: 0.074690; batch adversarial loss: 0.444863\n",
      "epoch 77; iter: 0; batch classifier loss: 0.072149; batch adversarial loss: 0.553244\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071463; batch adversarial loss: 0.385545\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067653; batch adversarial loss: 0.603703\n",
      "epoch 80; iter: 0; batch classifier loss: 0.121322; batch adversarial loss: 0.413932\n",
      "epoch 81; iter: 0; batch classifier loss: 0.113167; batch adversarial loss: 0.351295\n",
      "epoch 82; iter: 0; batch classifier loss: 0.068071; batch adversarial loss: 0.459110\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059887; batch adversarial loss: 0.408000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.087315; batch adversarial loss: 0.473643\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068303; batch adversarial loss: 0.550584\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040340; batch adversarial loss: 0.407586\n",
      "epoch 87; iter: 0; batch classifier loss: 0.034143; batch adversarial loss: 0.461605\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057568; batch adversarial loss: 0.481656\n",
      "epoch 89; iter: 0; batch classifier loss: 0.072878; batch adversarial loss: 0.379184\n",
      "epoch 90; iter: 0; batch classifier loss: 0.082315; batch adversarial loss: 0.502384\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081969; batch adversarial loss: 0.362619\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062047; batch adversarial loss: 0.491346\n",
      "epoch 93; iter: 0; batch classifier loss: 0.045634; batch adversarial loss: 0.410779\n",
      "epoch 94; iter: 0; batch classifier loss: 0.065944; batch adversarial loss: 0.277566\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043315; batch adversarial loss: 0.463712\n",
      "epoch 96; iter: 0; batch classifier loss: 0.093108; batch adversarial loss: 0.387421\n",
      "epoch 97; iter: 0; batch classifier loss: 0.024711; batch adversarial loss: 0.408184\n",
      "epoch 98; iter: 0; batch classifier loss: 0.028901; batch adversarial loss: 0.495630\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054743; batch adversarial loss: 0.473959\n",
      "epoch 100; iter: 0; batch classifier loss: 0.033336; batch adversarial loss: 0.521006\n",
      "epoch 101; iter: 0; batch classifier loss: 0.025893; batch adversarial loss: 0.460566\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050789; batch adversarial loss: 0.347774\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045190; batch adversarial loss: 0.461841\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050261; batch adversarial loss: 0.388217\n",
      "epoch 105; iter: 0; batch classifier loss: 0.069233; batch adversarial loss: 0.508241\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036003; batch adversarial loss: 0.579237\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041669; batch adversarial loss: 0.406074\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041493; batch adversarial loss: 0.411525\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060685; batch adversarial loss: 0.398521\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030639; batch adversarial loss: 0.443743\n",
      "epoch 111; iter: 0; batch classifier loss: 0.038290; batch adversarial loss: 0.405800\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040796; batch adversarial loss: 0.364610\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043090; batch adversarial loss: 0.537648\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033795; batch adversarial loss: 0.423719\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034425; batch adversarial loss: 0.415616\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055471; batch adversarial loss: 0.474264\n",
      "epoch 117; iter: 0; batch classifier loss: 0.063769; batch adversarial loss: 0.464368\n",
      "epoch 118; iter: 0; batch classifier loss: 0.006931; batch adversarial loss: 0.453172\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051441; batch adversarial loss: 0.552799\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032639; batch adversarial loss: 0.502713\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018480; batch adversarial loss: 0.496166\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015931; batch adversarial loss: 0.365886\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045535; batch adversarial loss: 0.463084\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059519; batch adversarial loss: 0.435259\n",
      "epoch 125; iter: 0; batch classifier loss: 0.097733; batch adversarial loss: 0.493524\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030255; batch adversarial loss: 0.508833\n",
      "epoch 127; iter: 0; batch classifier loss: 0.052684; batch adversarial loss: 0.415119\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043076; batch adversarial loss: 0.520256\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033641; batch adversarial loss: 0.449854\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036447; batch adversarial loss: 0.506346\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027092; batch adversarial loss: 0.422114\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031621; batch adversarial loss: 0.422938\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023043; batch adversarial loss: 0.409744\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035377; batch adversarial loss: 0.464972\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049830; batch adversarial loss: 0.454680\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029755; batch adversarial loss: 0.401962\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029039; batch adversarial loss: 0.415432\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021252; batch adversarial loss: 0.473938\n",
      "epoch 139; iter: 0; batch classifier loss: 0.085400; batch adversarial loss: 0.440394\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024369; batch adversarial loss: 0.462915\n",
      "epoch 141; iter: 0; batch classifier loss: 0.072942; batch adversarial loss: 0.362021\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044028; batch adversarial loss: 0.478964\n",
      "epoch 143; iter: 0; batch classifier loss: 0.049764; batch adversarial loss: 0.528886\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022170; batch adversarial loss: 0.478082\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029080; batch adversarial loss: 0.535561\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042275; batch adversarial loss: 0.346242\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046717; batch adversarial loss: 0.475268\n",
      "epoch 148; iter: 0; batch classifier loss: 0.007496; batch adversarial loss: 0.489910\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022108; batch adversarial loss: 0.424479\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041894; batch adversarial loss: 0.388205\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025812; batch adversarial loss: 0.477400\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030268; batch adversarial loss: 0.463771\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016915; batch adversarial loss: 0.411751\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026817; batch adversarial loss: 0.450626\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009250; batch adversarial loss: 0.440819\n",
      "epoch 156; iter: 0; batch classifier loss: 0.008981; batch adversarial loss: 0.369967\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036137; batch adversarial loss: 0.522705\n",
      "epoch 158; iter: 0; batch classifier loss: 0.046541; batch adversarial loss: 0.336058\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019636; batch adversarial loss: 0.520116\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009844; batch adversarial loss: 0.546643\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011710; batch adversarial loss: 0.484301\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015789; batch adversarial loss: 0.469282\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017280; batch adversarial loss: 0.509771\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017008; batch adversarial loss: 0.510537\n",
      "epoch 165; iter: 0; batch classifier loss: 0.063829; batch adversarial loss: 0.400788\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027282; batch adversarial loss: 0.388580\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019884; batch adversarial loss: 0.445701\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012174; batch adversarial loss: 0.486258\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011355; batch adversarial loss: 0.467496\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029538; batch adversarial loss: 0.313816\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033831; batch adversarial loss: 0.467257\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021244; batch adversarial loss: 0.390475\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009089; batch adversarial loss: 0.352766\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033200; batch adversarial loss: 0.430404\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034179; batch adversarial loss: 0.532276\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019133; batch adversarial loss: 0.473368\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022698; batch adversarial loss: 0.406468\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019142; batch adversarial loss: 0.502412\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007371; batch adversarial loss: 0.507257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.038709; batch adversarial loss: 0.528057\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024313; batch adversarial loss: 0.485207\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032020; batch adversarial loss: 0.317090\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021873; batch adversarial loss: 0.386089\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011813; batch adversarial loss: 0.506121\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029526; batch adversarial loss: 0.506272\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006073; batch adversarial loss: 0.485005\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011591; batch adversarial loss: 0.462305\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012646; batch adversarial loss: 0.424481\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017914; batch adversarial loss: 0.458294\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019335; batch adversarial loss: 0.587052\n",
      "epoch 191; iter: 0; batch classifier loss: 0.048420; batch adversarial loss: 0.438315\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027645; batch adversarial loss: 0.410400\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013328; batch adversarial loss: 0.384074\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012266; batch adversarial loss: 0.431426\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006243; batch adversarial loss: 0.383492\n",
      "epoch 196; iter: 0; batch classifier loss: 0.042144; batch adversarial loss: 0.456172\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014034; batch adversarial loss: 0.403898\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011067; batch adversarial loss: 0.489395\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027343; batch adversarial loss: 0.526794\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683369; batch adversarial loss: 0.639198\n",
      "epoch 1; iter: 0; batch classifier loss: 0.522190; batch adversarial loss: 0.644521\n",
      "epoch 2; iter: 0; batch classifier loss: 0.420836; batch adversarial loss: 0.606155\n",
      "epoch 3; iter: 0; batch classifier loss: 0.483657; batch adversarial loss: 0.634023\n",
      "epoch 4; iter: 0; batch classifier loss: 0.478632; batch adversarial loss: 0.602180\n",
      "epoch 5; iter: 0; batch classifier loss: 0.502364; batch adversarial loss: 0.626723\n",
      "epoch 6; iter: 0; batch classifier loss: 0.406894; batch adversarial loss: 0.560524\n",
      "epoch 7; iter: 0; batch classifier loss: 0.475181; batch adversarial loss: 0.539208\n",
      "epoch 8; iter: 0; batch classifier loss: 0.434129; batch adversarial loss: 0.569735\n",
      "epoch 9; iter: 0; batch classifier loss: 0.461238; batch adversarial loss: 0.557153\n",
      "epoch 10; iter: 0; batch classifier loss: 0.435959; batch adversarial loss: 0.542203\n",
      "epoch 11; iter: 0; batch classifier loss: 0.484408; batch adversarial loss: 0.512599\n",
      "epoch 12; iter: 0; batch classifier loss: 0.369068; batch adversarial loss: 0.480448\n",
      "epoch 13; iter: 0; batch classifier loss: 0.327478; batch adversarial loss: 0.582454\n",
      "epoch 14; iter: 0; batch classifier loss: 0.366431; batch adversarial loss: 0.444534\n",
      "epoch 15; iter: 0; batch classifier loss: 0.309557; batch adversarial loss: 0.577284\n",
      "epoch 16; iter: 0; batch classifier loss: 0.357178; batch adversarial loss: 0.496502\n",
      "epoch 17; iter: 0; batch classifier loss: 0.329542; batch adversarial loss: 0.438974\n",
      "epoch 18; iter: 0; batch classifier loss: 0.325828; batch adversarial loss: 0.503000\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277969; batch adversarial loss: 0.512107\n",
      "epoch 20; iter: 0; batch classifier loss: 0.279264; batch adversarial loss: 0.446686\n",
      "epoch 21; iter: 0; batch classifier loss: 0.283469; batch adversarial loss: 0.512666\n",
      "epoch 22; iter: 0; batch classifier loss: 0.269336; batch adversarial loss: 0.547183\n",
      "epoch 23; iter: 0; batch classifier loss: 0.246781; batch adversarial loss: 0.542121\n",
      "epoch 24; iter: 0; batch classifier loss: 0.316705; batch adversarial loss: 0.493900\n",
      "epoch 25; iter: 0; batch classifier loss: 0.321489; batch adversarial loss: 0.478756\n",
      "epoch 26; iter: 0; batch classifier loss: 0.256821; batch adversarial loss: 0.463099\n",
      "epoch 27; iter: 0; batch classifier loss: 0.272582; batch adversarial loss: 0.468768\n",
      "epoch 28; iter: 0; batch classifier loss: 0.257355; batch adversarial loss: 0.500897\n",
      "epoch 29; iter: 0; batch classifier loss: 0.332225; batch adversarial loss: 0.411107\n",
      "epoch 30; iter: 0; batch classifier loss: 0.259366; batch adversarial loss: 0.415632\n",
      "epoch 31; iter: 0; batch classifier loss: 0.202615; batch adversarial loss: 0.444321\n",
      "epoch 32; iter: 0; batch classifier loss: 0.198369; batch adversarial loss: 0.500148\n",
      "epoch 33; iter: 0; batch classifier loss: 0.315084; batch adversarial loss: 0.421420\n",
      "epoch 34; iter: 0; batch classifier loss: 0.262078; batch adversarial loss: 0.453822\n",
      "epoch 35; iter: 0; batch classifier loss: 0.166745; batch adversarial loss: 0.492041\n",
      "epoch 36; iter: 0; batch classifier loss: 0.249487; batch adversarial loss: 0.492060\n",
      "epoch 37; iter: 0; batch classifier loss: 0.216779; batch adversarial loss: 0.446412\n",
      "epoch 38; iter: 0; batch classifier loss: 0.302171; batch adversarial loss: 0.452318\n",
      "epoch 39; iter: 0; batch classifier loss: 0.295688; batch adversarial loss: 0.494639\n",
      "epoch 40; iter: 0; batch classifier loss: 0.236400; batch adversarial loss: 0.484349\n",
      "epoch 41; iter: 0; batch classifier loss: 0.259126; batch adversarial loss: 0.428379\n",
      "epoch 42; iter: 0; batch classifier loss: 0.189045; batch adversarial loss: 0.472910\n",
      "epoch 43; iter: 0; batch classifier loss: 0.286279; batch adversarial loss: 0.413227\n",
      "epoch 44; iter: 0; batch classifier loss: 0.191618; batch adversarial loss: 0.493970\n",
      "epoch 45; iter: 0; batch classifier loss: 0.135452; batch adversarial loss: 0.470989\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131757; batch adversarial loss: 0.429696\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095961; batch adversarial loss: 0.443693\n",
      "epoch 48; iter: 0; batch classifier loss: 0.111744; batch adversarial loss: 0.480506\n",
      "epoch 49; iter: 0; batch classifier loss: 0.110798; batch adversarial loss: 0.407320\n",
      "epoch 50; iter: 0; batch classifier loss: 0.092282; batch adversarial loss: 0.481355\n",
      "epoch 51; iter: 0; batch classifier loss: 0.072977; batch adversarial loss: 0.534633\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093860; batch adversarial loss: 0.508547\n",
      "epoch 53; iter: 0; batch classifier loss: 0.075220; batch adversarial loss: 0.566122\n",
      "epoch 54; iter: 0; batch classifier loss: 0.063154; batch adversarial loss: 0.464548\n",
      "epoch 55; iter: 0; batch classifier loss: 0.073185; batch adversarial loss: 0.416086\n",
      "epoch 56; iter: 0; batch classifier loss: 0.133192; batch adversarial loss: 0.535117\n",
      "epoch 57; iter: 0; batch classifier loss: 0.129570; batch adversarial loss: 0.357558\n",
      "epoch 58; iter: 0; batch classifier loss: 0.186580; batch adversarial loss: 0.446308\n",
      "epoch 59; iter: 0; batch classifier loss: 0.124226; batch adversarial loss: 0.427565\n",
      "epoch 60; iter: 0; batch classifier loss: 0.130497; batch adversarial loss: 0.354174\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091646; batch adversarial loss: 0.522926\n",
      "epoch 62; iter: 0; batch classifier loss: 0.178864; batch adversarial loss: 0.424411\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178077; batch adversarial loss: 0.459555\n",
      "epoch 64; iter: 0; batch classifier loss: 0.128621; batch adversarial loss: 0.411649\n",
      "epoch 65; iter: 0; batch classifier loss: 0.096670; batch adversarial loss: 0.462802\n",
      "epoch 66; iter: 0; batch classifier loss: 0.115205; batch adversarial loss: 0.523239\n",
      "epoch 67; iter: 0; batch classifier loss: 0.103153; batch adversarial loss: 0.522382\n",
      "epoch 68; iter: 0; batch classifier loss: 0.118726; batch adversarial loss: 0.419473\n",
      "epoch 69; iter: 0; batch classifier loss: 0.141016; batch adversarial loss: 0.380422\n",
      "epoch 70; iter: 0; batch classifier loss: 0.142858; batch adversarial loss: 0.467343\n",
      "epoch 71; iter: 0; batch classifier loss: 0.129135; batch adversarial loss: 0.394367\n",
      "epoch 72; iter: 0; batch classifier loss: 0.157559; batch adversarial loss: 0.451603\n",
      "epoch 73; iter: 0; batch classifier loss: 0.148341; batch adversarial loss: 0.413244\n",
      "epoch 74; iter: 0; batch classifier loss: 0.177106; batch adversarial loss: 0.399781\n",
      "epoch 75; iter: 0; batch classifier loss: 0.122525; batch adversarial loss: 0.457594\n",
      "epoch 76; iter: 0; batch classifier loss: 0.107348; batch adversarial loss: 0.509127\n",
      "epoch 77; iter: 0; batch classifier loss: 0.119166; batch adversarial loss: 0.455133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.120169; batch adversarial loss: 0.482064\n",
      "epoch 79; iter: 0; batch classifier loss: 0.090293; batch adversarial loss: 0.533311\n",
      "epoch 80; iter: 0; batch classifier loss: 0.114351; batch adversarial loss: 0.454924\n",
      "epoch 81; iter: 0; batch classifier loss: 0.140375; batch adversarial loss: 0.477855\n",
      "epoch 82; iter: 0; batch classifier loss: 0.111036; batch adversarial loss: 0.424915\n",
      "epoch 83; iter: 0; batch classifier loss: 0.093751; batch adversarial loss: 0.521174\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077740; batch adversarial loss: 0.521135\n",
      "epoch 85; iter: 0; batch classifier loss: 0.096965; batch adversarial loss: 0.495166\n",
      "epoch 86; iter: 0; batch classifier loss: 0.120769; batch adversarial loss: 0.527502\n",
      "epoch 87; iter: 0; batch classifier loss: 0.105871; batch adversarial loss: 0.492355\n",
      "epoch 88; iter: 0; batch classifier loss: 0.124564; batch adversarial loss: 0.434131\n",
      "epoch 89; iter: 0; batch classifier loss: 0.093363; batch adversarial loss: 0.520152\n",
      "epoch 90; iter: 0; batch classifier loss: 0.134120; batch adversarial loss: 0.443951\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070638; batch adversarial loss: 0.453707\n",
      "epoch 92; iter: 0; batch classifier loss: 0.103149; batch adversarial loss: 0.446728\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071370; batch adversarial loss: 0.493561\n",
      "epoch 94; iter: 0; batch classifier loss: 0.102630; batch adversarial loss: 0.474405\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056418; batch adversarial loss: 0.405257\n",
      "epoch 96; iter: 0; batch classifier loss: 0.099241; batch adversarial loss: 0.416498\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052942; batch adversarial loss: 0.491416\n",
      "epoch 98; iter: 0; batch classifier loss: 0.065258; batch adversarial loss: 0.321485\n",
      "epoch 99; iter: 0; batch classifier loss: 0.101320; batch adversarial loss: 0.538554\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076017; batch adversarial loss: 0.463073\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050790; batch adversarial loss: 0.434482\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048179; batch adversarial loss: 0.455902\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063234; batch adversarial loss: 0.374610\n",
      "epoch 104; iter: 0; batch classifier loss: 0.085355; batch adversarial loss: 0.452816\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075223; batch adversarial loss: 0.420340\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047732; batch adversarial loss: 0.448402\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031531; batch adversarial loss: 0.429869\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028679; batch adversarial loss: 0.425882\n",
      "epoch 109; iter: 0; batch classifier loss: 0.056679; batch adversarial loss: 0.419598\n",
      "epoch 110; iter: 0; batch classifier loss: 0.086796; batch adversarial loss: 0.389983\n",
      "epoch 111; iter: 0; batch classifier loss: 0.056857; batch adversarial loss: 0.452389\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055512; batch adversarial loss: 0.520714\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025166; batch adversarial loss: 0.453697\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030906; batch adversarial loss: 0.493848\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037013; batch adversarial loss: 0.500023\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037817; batch adversarial loss: 0.546078\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035380; batch adversarial loss: 0.395284\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043690; batch adversarial loss: 0.462832\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037829; batch adversarial loss: 0.352309\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045523; batch adversarial loss: 0.410689\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033976; batch adversarial loss: 0.443596\n",
      "epoch 122; iter: 0; batch classifier loss: 0.054194; batch adversarial loss: 0.508139\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039545; batch adversarial loss: 0.386676\n",
      "epoch 124; iter: 0; batch classifier loss: 0.066062; batch adversarial loss: 0.390326\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048885; batch adversarial loss: 0.441141\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039045; batch adversarial loss: 0.527424\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047933; batch adversarial loss: 0.428379\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053360; batch adversarial loss: 0.478470\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030092; batch adversarial loss: 0.531520\n",
      "epoch 130; iter: 0; batch classifier loss: 0.049569; batch adversarial loss: 0.415121\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044105; batch adversarial loss: 0.430799\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033526; batch adversarial loss: 0.462197\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031682; batch adversarial loss: 0.478803\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045114; batch adversarial loss: 0.508885\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029848; batch adversarial loss: 0.467086\n",
      "epoch 136; iter: 0; batch classifier loss: 0.066071; batch adversarial loss: 0.472582\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039520; batch adversarial loss: 0.508170\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017988; batch adversarial loss: 0.508245\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040474; batch adversarial loss: 0.454025\n",
      "epoch 140; iter: 0; batch classifier loss: 0.072636; batch adversarial loss: 0.557479\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018505; batch adversarial loss: 0.432254\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022114; batch adversarial loss: 0.507806\n",
      "epoch 143; iter: 0; batch classifier loss: 0.058911; batch adversarial loss: 0.329414\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040893; batch adversarial loss: 0.544273\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012383; batch adversarial loss: 0.465489\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016138; batch adversarial loss: 0.449822\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033443; batch adversarial loss: 0.496911\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025512; batch adversarial loss: 0.396581\n",
      "epoch 149; iter: 0; batch classifier loss: 0.009969; batch adversarial loss: 0.444481\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014568; batch adversarial loss: 0.438207\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035283; batch adversarial loss: 0.475720\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018794; batch adversarial loss: 0.439746\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036195; batch adversarial loss: 0.403230\n",
      "epoch 154; iter: 0; batch classifier loss: 0.004680; batch adversarial loss: 0.438026\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028134; batch adversarial loss: 0.468271\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044393; batch adversarial loss: 0.413469\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016102; batch adversarial loss: 0.475220\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008751; batch adversarial loss: 0.423253\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012446; batch adversarial loss: 0.394409\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023915; batch adversarial loss: 0.456318\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022305; batch adversarial loss: 0.500791\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024932; batch adversarial loss: 0.474390\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026217; batch adversarial loss: 0.451915\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036671; batch adversarial loss: 0.536391\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035458; batch adversarial loss: 0.416147\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045005; batch adversarial loss: 0.527633\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017829; batch adversarial loss: 0.454127\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011369; batch adversarial loss: 0.430000\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018602; batch adversarial loss: 0.390716\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036855; batch adversarial loss: 0.424784\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018402; batch adversarial loss: 0.415062\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008123; batch adversarial loss: 0.482123\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022920; batch adversarial loss: 0.378926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.017408; batch adversarial loss: 0.416182\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006640; batch adversarial loss: 0.511549\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029703; batch adversarial loss: 0.597892\n",
      "epoch 177; iter: 0; batch classifier loss: 0.035844; batch adversarial loss: 0.405527\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028208; batch adversarial loss: 0.501225\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009432; batch adversarial loss: 0.446958\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040279; batch adversarial loss: 0.443682\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009986; batch adversarial loss: 0.470051\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032569; batch adversarial loss: 0.406386\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024878; batch adversarial loss: 0.428936\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023340; batch adversarial loss: 0.429421\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014300; batch adversarial loss: 0.483086\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016763; batch adversarial loss: 0.418086\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009608; batch adversarial loss: 0.493024\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012088; batch adversarial loss: 0.476349\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015086; batch adversarial loss: 0.427698\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021042; batch adversarial loss: 0.407152\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030115; batch adversarial loss: 0.474980\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024424; batch adversarial loss: 0.495772\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008490; batch adversarial loss: 0.476543\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013410; batch adversarial loss: 0.442834\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015163; batch adversarial loss: 0.453231\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015609; batch adversarial loss: 0.430675\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031074; batch adversarial loss: 0.390913\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041774; batch adversarial loss: 0.433003\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025947; batch adversarial loss: 0.494618\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675174; batch adversarial loss: 0.806152\n",
      "epoch 1; iter: 0; batch classifier loss: 0.542994; batch adversarial loss: 0.792800\n",
      "epoch 2; iter: 0; batch classifier loss: 0.456274; batch adversarial loss: 0.730410\n",
      "epoch 3; iter: 0; batch classifier loss: 0.640571; batch adversarial loss: 0.699021\n",
      "epoch 4; iter: 0; batch classifier loss: 0.664976; batch adversarial loss: 0.649501\n",
      "epoch 5; iter: 0; batch classifier loss: 0.489678; batch adversarial loss: 0.602604\n",
      "epoch 6; iter: 0; batch classifier loss: 0.363557; batch adversarial loss: 0.600224\n",
      "epoch 7; iter: 0; batch classifier loss: 0.410588; batch adversarial loss: 0.578139\n",
      "epoch 8; iter: 0; batch classifier loss: 0.369890; batch adversarial loss: 0.569334\n",
      "epoch 9; iter: 0; batch classifier loss: 0.334392; batch adversarial loss: 0.581847\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386503; batch adversarial loss: 0.518314\n",
      "epoch 11; iter: 0; batch classifier loss: 0.342200; batch adversarial loss: 0.529267\n",
      "epoch 12; iter: 0; batch classifier loss: 0.367962; batch adversarial loss: 0.534524\n",
      "epoch 13; iter: 0; batch classifier loss: 0.362671; batch adversarial loss: 0.517173\n",
      "epoch 14; iter: 0; batch classifier loss: 0.422429; batch adversarial loss: 0.486903\n",
      "epoch 15; iter: 0; batch classifier loss: 0.407827; batch adversarial loss: 0.487856\n",
      "epoch 16; iter: 0; batch classifier loss: 0.358900; batch adversarial loss: 0.532489\n",
      "epoch 17; iter: 0; batch classifier loss: 0.304749; batch adversarial loss: 0.471097\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320682; batch adversarial loss: 0.515980\n",
      "epoch 19; iter: 0; batch classifier loss: 0.301194; batch adversarial loss: 0.509225\n",
      "epoch 20; iter: 0; batch classifier loss: 0.341584; batch adversarial loss: 0.411831\n",
      "epoch 21; iter: 0; batch classifier loss: 0.352872; batch adversarial loss: 0.460807\n",
      "epoch 22; iter: 0; batch classifier loss: 0.338975; batch adversarial loss: 0.493308\n",
      "epoch 23; iter: 0; batch classifier loss: 0.322790; batch adversarial loss: 0.422263\n",
      "epoch 24; iter: 0; batch classifier loss: 0.263075; batch adversarial loss: 0.450132\n",
      "epoch 25; iter: 0; batch classifier loss: 0.340555; batch adversarial loss: 0.496498\n",
      "epoch 26; iter: 0; batch classifier loss: 0.292775; batch adversarial loss: 0.463309\n",
      "epoch 27; iter: 0; batch classifier loss: 0.221241; batch adversarial loss: 0.558837\n",
      "epoch 28; iter: 0; batch classifier loss: 0.313176; batch adversarial loss: 0.433586\n",
      "epoch 29; iter: 0; batch classifier loss: 0.383671; batch adversarial loss: 0.399542\n",
      "epoch 30; iter: 0; batch classifier loss: 0.221746; batch adversarial loss: 0.518924\n",
      "epoch 31; iter: 0; batch classifier loss: 0.270090; batch adversarial loss: 0.410245\n",
      "epoch 32; iter: 0; batch classifier loss: 0.204569; batch adversarial loss: 0.462584\n",
      "epoch 33; iter: 0; batch classifier loss: 0.173379; batch adversarial loss: 0.477850\n",
      "epoch 34; iter: 0; batch classifier loss: 0.208561; batch adversarial loss: 0.470728\n",
      "epoch 35; iter: 0; batch classifier loss: 0.217083; batch adversarial loss: 0.442761\n",
      "epoch 36; iter: 0; batch classifier loss: 0.203340; batch adversarial loss: 0.503597\n",
      "epoch 37; iter: 0; batch classifier loss: 0.251867; batch adversarial loss: 0.475691\n",
      "epoch 38; iter: 0; batch classifier loss: 0.196712; batch adversarial loss: 0.440755\n",
      "epoch 39; iter: 0; batch classifier loss: 0.182525; batch adversarial loss: 0.439440\n",
      "epoch 40; iter: 0; batch classifier loss: 0.289149; batch adversarial loss: 0.484384\n",
      "epoch 41; iter: 0; batch classifier loss: 0.250980; batch adversarial loss: 0.448898\n",
      "epoch 42; iter: 0; batch classifier loss: 0.149625; batch adversarial loss: 0.459404\n",
      "epoch 43; iter: 0; batch classifier loss: 0.202765; batch adversarial loss: 0.525986\n",
      "epoch 44; iter: 0; batch classifier loss: 0.216752; batch adversarial loss: 0.379716\n",
      "epoch 45; iter: 0; batch classifier loss: 0.191153; batch adversarial loss: 0.411416\n",
      "epoch 46; iter: 0; batch classifier loss: 0.213011; batch adversarial loss: 0.402944\n",
      "epoch 47; iter: 0; batch classifier loss: 0.245710; batch adversarial loss: 0.517627\n",
      "epoch 48; iter: 0; batch classifier loss: 0.180976; batch adversarial loss: 0.411463\n",
      "epoch 49; iter: 0; batch classifier loss: 0.157044; batch adversarial loss: 0.433045\n",
      "epoch 50; iter: 0; batch classifier loss: 0.235129; batch adversarial loss: 0.366298\n",
      "epoch 51; iter: 0; batch classifier loss: 0.182739; batch adversarial loss: 0.460230\n",
      "epoch 52; iter: 0; batch classifier loss: 0.222977; batch adversarial loss: 0.446904\n",
      "epoch 53; iter: 0; batch classifier loss: 0.184354; batch adversarial loss: 0.469965\n",
      "epoch 54; iter: 0; batch classifier loss: 0.106220; batch adversarial loss: 0.386951\n",
      "epoch 55; iter: 0; batch classifier loss: 0.193908; batch adversarial loss: 0.446129\n",
      "epoch 56; iter: 0; batch classifier loss: 0.198754; batch adversarial loss: 0.519915\n",
      "epoch 57; iter: 0; batch classifier loss: 0.156962; batch adversarial loss: 0.435028\n",
      "epoch 58; iter: 0; batch classifier loss: 0.178988; batch adversarial loss: 0.385008\n",
      "epoch 59; iter: 0; batch classifier loss: 0.197364; batch adversarial loss: 0.471036\n",
      "epoch 60; iter: 0; batch classifier loss: 0.144797; batch adversarial loss: 0.531875\n",
      "epoch 61; iter: 0; batch classifier loss: 0.212539; batch adversarial loss: 0.446982\n",
      "epoch 62; iter: 0; batch classifier loss: 0.187855; batch adversarial loss: 0.459271\n",
      "epoch 63; iter: 0; batch classifier loss: 0.284434; batch adversarial loss: 0.336565\n",
      "epoch 64; iter: 0; batch classifier loss: 0.133516; batch adversarial loss: 0.482784\n",
      "epoch 65; iter: 0; batch classifier loss: 0.171732; batch adversarial loss: 0.434870\n",
      "epoch 66; iter: 0; batch classifier loss: 0.220257; batch adversarial loss: 0.446509\n",
      "epoch 67; iter: 0; batch classifier loss: 0.175416; batch adversarial loss: 0.471380\n",
      "epoch 68; iter: 0; batch classifier loss: 0.116212; batch adversarial loss: 0.495394\n",
      "epoch 69; iter: 0; batch classifier loss: 0.148857; batch adversarial loss: 0.520163\n",
      "epoch 70; iter: 0; batch classifier loss: 0.146470; batch adversarial loss: 0.583352\n",
      "epoch 71; iter: 0; batch classifier loss: 0.181853; batch adversarial loss: 0.470969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.189373; batch adversarial loss: 0.458109\n",
      "epoch 73; iter: 0; batch classifier loss: 0.166691; batch adversarial loss: 0.434479\n",
      "epoch 74; iter: 0; batch classifier loss: 0.189317; batch adversarial loss: 0.471507\n",
      "epoch 75; iter: 0; batch classifier loss: 0.090402; batch adversarial loss: 0.446592\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081120; batch adversarial loss: 0.434111\n",
      "epoch 77; iter: 0; batch classifier loss: 0.105853; batch adversarial loss: 0.447854\n",
      "epoch 78; iter: 0; batch classifier loss: 0.083310; batch adversarial loss: 0.445737\n",
      "epoch 79; iter: 0; batch classifier loss: 0.100237; batch adversarial loss: 0.444384\n",
      "epoch 80; iter: 0; batch classifier loss: 0.154485; batch adversarial loss: 0.435066\n",
      "epoch 81; iter: 0; batch classifier loss: 0.128255; batch adversarial loss: 0.419845\n",
      "epoch 82; iter: 0; batch classifier loss: 0.123079; batch adversarial loss: 0.445161\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085078; batch adversarial loss: 0.407654\n",
      "epoch 84; iter: 0; batch classifier loss: 0.078119; batch adversarial loss: 0.395477\n",
      "epoch 85; iter: 0; batch classifier loss: 0.099612; batch adversarial loss: 0.466182\n",
      "epoch 86; iter: 0; batch classifier loss: 0.107993; batch adversarial loss: 0.377056\n",
      "epoch 87; iter: 0; batch classifier loss: 0.096083; batch adversarial loss: 0.420031\n",
      "epoch 88; iter: 0; batch classifier loss: 0.087613; batch adversarial loss: 0.499793\n",
      "epoch 89; iter: 0; batch classifier loss: 0.095916; batch adversarial loss: 0.465816\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087467; batch adversarial loss: 0.469289\n",
      "epoch 91; iter: 0; batch classifier loss: 0.094006; batch adversarial loss: 0.535709\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055638; batch adversarial loss: 0.397577\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079984; batch adversarial loss: 0.471232\n",
      "epoch 94; iter: 0; batch classifier loss: 0.093330; batch adversarial loss: 0.431280\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039492; batch adversarial loss: 0.449170\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059326; batch adversarial loss: 0.395107\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071151; batch adversarial loss: 0.481804\n",
      "epoch 98; iter: 0; batch classifier loss: 0.025967; batch adversarial loss: 0.470635\n",
      "epoch 99; iter: 0; batch classifier loss: 0.066545; batch adversarial loss: 0.455769\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046016; batch adversarial loss: 0.439981\n",
      "epoch 101; iter: 0; batch classifier loss: 0.079213; batch adversarial loss: 0.382223\n",
      "epoch 102; iter: 0; batch classifier loss: 0.075575; batch adversarial loss: 0.418659\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050767; batch adversarial loss: 0.512186\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065945; batch adversarial loss: 0.392779\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059057; batch adversarial loss: 0.493253\n",
      "epoch 106; iter: 0; batch classifier loss: 0.028839; batch adversarial loss: 0.600146\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041276; batch adversarial loss: 0.437851\n",
      "epoch 108; iter: 0; batch classifier loss: 0.025093; batch adversarial loss: 0.473032\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036642; batch adversarial loss: 0.435519\n",
      "epoch 110; iter: 0; batch classifier loss: 0.021074; batch adversarial loss: 0.554659\n",
      "epoch 111; iter: 0; batch classifier loss: 0.013429; batch adversarial loss: 0.513048\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042053; batch adversarial loss: 0.479684\n",
      "epoch 113; iter: 0; batch classifier loss: 0.014573; batch adversarial loss: 0.471788\n",
      "epoch 114; iter: 0; batch classifier loss: 0.022452; batch adversarial loss: 0.532693\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029211; batch adversarial loss: 0.453001\n",
      "epoch 116; iter: 0; batch classifier loss: 0.011462; batch adversarial loss: 0.561140\n",
      "epoch 117; iter: 0; batch classifier loss: 0.016919; batch adversarial loss: 0.435077\n",
      "epoch 118; iter: 0; batch classifier loss: 0.017989; batch adversarial loss: 0.405527\n",
      "epoch 119; iter: 0; batch classifier loss: 0.011942; batch adversarial loss: 0.474696\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035496; batch adversarial loss: 0.436674\n",
      "epoch 121; iter: 0; batch classifier loss: 0.020423; batch adversarial loss: 0.426388\n",
      "epoch 122; iter: 0; batch classifier loss: 0.016863; batch adversarial loss: 0.440199\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038478; batch adversarial loss: 0.484784\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033515; batch adversarial loss: 0.394297\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025209; batch adversarial loss: 0.392176\n",
      "epoch 126; iter: 0; batch classifier loss: 0.015334; batch adversarial loss: 0.394205\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034427; batch adversarial loss: 0.407442\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027911; batch adversarial loss: 0.474528\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030867; batch adversarial loss: 0.433917\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035899; batch adversarial loss: 0.407012\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027990; batch adversarial loss: 0.476764\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036637; batch adversarial loss: 0.499720\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023493; batch adversarial loss: 0.399353\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026051; batch adversarial loss: 0.545385\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014158; batch adversarial loss: 0.414340\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024098; batch adversarial loss: 0.467943\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020307; batch adversarial loss: 0.474900\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034694; batch adversarial loss: 0.460042\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016811; batch adversarial loss: 0.443951\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034966; batch adversarial loss: 0.407168\n",
      "epoch 141; iter: 0; batch classifier loss: 0.007790; batch adversarial loss: 0.499985\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013491; batch adversarial loss: 0.471609\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032089; batch adversarial loss: 0.429749\n",
      "epoch 144; iter: 0; batch classifier loss: 0.010494; batch adversarial loss: 0.412733\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016713; batch adversarial loss: 0.533738\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033734; batch adversarial loss: 0.446774\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020336; batch adversarial loss: 0.527298\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017549; batch adversarial loss: 0.348926\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022272; batch adversarial loss: 0.362191\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019541; batch adversarial loss: 0.397844\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015908; batch adversarial loss: 0.537653\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032757; batch adversarial loss: 0.486946\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008416; batch adversarial loss: 0.442146\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017453; batch adversarial loss: 0.434634\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018427; batch adversarial loss: 0.508109\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014507; batch adversarial loss: 0.397470\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020641; batch adversarial loss: 0.441678\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024827; batch adversarial loss: 0.401754\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023382; batch adversarial loss: 0.502265\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007832; batch adversarial loss: 0.349268\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022014; batch adversarial loss: 0.436831\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019198; batch adversarial loss: 0.420675\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037810; batch adversarial loss: 0.377216\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016925; batch adversarial loss: 0.505663\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017782; batch adversarial loss: 0.400134\n",
      "epoch 166; iter: 0; batch classifier loss: 0.006334; batch adversarial loss: 0.378981\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012700; batch adversarial loss: 0.525705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.012691; batch adversarial loss: 0.541512\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011310; batch adversarial loss: 0.402078\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033952; batch adversarial loss: 0.368657\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036096; batch adversarial loss: 0.481823\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010305; batch adversarial loss: 0.497407\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009765; batch adversarial loss: 0.512876\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011890; batch adversarial loss: 0.346775\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016287; batch adversarial loss: 0.463240\n",
      "epoch 176; iter: 0; batch classifier loss: 0.003479; batch adversarial loss: 0.439476\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020172; batch adversarial loss: 0.451746\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009970; batch adversarial loss: 0.448301\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019262; batch adversarial loss: 0.427779\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008300; batch adversarial loss: 0.427309\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008044; batch adversarial loss: 0.521573\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011100; batch adversarial loss: 0.425921\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007705; batch adversarial loss: 0.432131\n",
      "epoch 184; iter: 0; batch classifier loss: 0.005864; batch adversarial loss: 0.489402\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008347; batch adversarial loss: 0.459522\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017401; batch adversarial loss: 0.373263\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006623; batch adversarial loss: 0.412667\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013544; batch adversarial loss: 0.370641\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030670; batch adversarial loss: 0.477830\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004716; batch adversarial loss: 0.552495\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009283; batch adversarial loss: 0.452488\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022915; batch adversarial loss: 0.378280\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014451; batch adversarial loss: 0.426727\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014179; batch adversarial loss: 0.432409\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009027; batch adversarial loss: 0.443851\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009778; batch adversarial loss: 0.383950\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016587; batch adversarial loss: 0.468548\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004777; batch adversarial loss: 0.507031\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014792; batch adversarial loss: 0.480023\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697025; batch adversarial loss: 0.846609\n",
      "epoch 1; iter: 0; batch classifier loss: 0.720266; batch adversarial loss: 0.907217\n",
      "epoch 2; iter: 0; batch classifier loss: 0.872422; batch adversarial loss: 0.902769\n",
      "epoch 3; iter: 0; batch classifier loss: 0.859030; batch adversarial loss: 0.779589\n",
      "epoch 4; iter: 0; batch classifier loss: 0.749721; batch adversarial loss: 0.722820\n",
      "epoch 5; iter: 0; batch classifier loss: 0.680052; batch adversarial loss: 0.693981\n",
      "epoch 6; iter: 0; batch classifier loss: 0.591488; batch adversarial loss: 0.618492\n",
      "epoch 7; iter: 0; batch classifier loss: 0.441643; batch adversarial loss: 0.583407\n",
      "epoch 8; iter: 0; batch classifier loss: 0.318371; batch adversarial loss: 0.530823\n",
      "epoch 9; iter: 0; batch classifier loss: 0.338332; batch adversarial loss: 0.487475\n",
      "epoch 10; iter: 0; batch classifier loss: 0.382884; batch adversarial loss: 0.524157\n",
      "epoch 11; iter: 0; batch classifier loss: 0.289084; batch adversarial loss: 0.499857\n",
      "epoch 12; iter: 0; batch classifier loss: 0.254894; batch adversarial loss: 0.524634\n",
      "epoch 13; iter: 0; batch classifier loss: 0.303670; batch adversarial loss: 0.527120\n",
      "epoch 14; iter: 0; batch classifier loss: 0.270006; batch adversarial loss: 0.513181\n",
      "epoch 15; iter: 0; batch classifier loss: 0.202217; batch adversarial loss: 0.546460\n",
      "epoch 16; iter: 0; batch classifier loss: 0.230326; batch adversarial loss: 0.518042\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225313; batch adversarial loss: 0.448952\n",
      "epoch 18; iter: 0; batch classifier loss: 0.232675; batch adversarial loss: 0.451058\n",
      "epoch 19; iter: 0; batch classifier loss: 0.133043; batch adversarial loss: 0.457683\n",
      "epoch 20; iter: 0; batch classifier loss: 0.227339; batch adversarial loss: 0.442044\n",
      "epoch 21; iter: 0; batch classifier loss: 0.207165; batch adversarial loss: 0.480738\n",
      "epoch 22; iter: 0; batch classifier loss: 0.243456; batch adversarial loss: 0.401213\n",
      "epoch 23; iter: 0; batch classifier loss: 0.192608; batch adversarial loss: 0.365742\n",
      "epoch 24; iter: 0; batch classifier loss: 0.185607; batch adversarial loss: 0.500645\n",
      "epoch 25; iter: 0; batch classifier loss: 0.157707; batch adversarial loss: 0.447095\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187369; batch adversarial loss: 0.523348\n",
      "epoch 27; iter: 0; batch classifier loss: 0.145253; batch adversarial loss: 0.451756\n",
      "epoch 28; iter: 0; batch classifier loss: 0.163379; batch adversarial loss: 0.477652\n",
      "epoch 29; iter: 0; batch classifier loss: 0.141350; batch adversarial loss: 0.538346\n",
      "epoch 30; iter: 0; batch classifier loss: 0.197682; batch adversarial loss: 0.456331\n",
      "epoch 31; iter: 0; batch classifier loss: 0.129011; batch adversarial loss: 0.427638\n",
      "epoch 32; iter: 0; batch classifier loss: 0.179286; batch adversarial loss: 0.484177\n",
      "epoch 33; iter: 0; batch classifier loss: 0.105029; batch adversarial loss: 0.456198\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122709; batch adversarial loss: 0.421747\n",
      "epoch 35; iter: 0; batch classifier loss: 0.101181; batch adversarial loss: 0.473877\n",
      "epoch 36; iter: 0; batch classifier loss: 0.100471; batch adversarial loss: 0.507193\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110894; batch adversarial loss: 0.475634\n",
      "epoch 38; iter: 0; batch classifier loss: 0.125060; batch adversarial loss: 0.521254\n",
      "epoch 39; iter: 0; batch classifier loss: 0.140795; batch adversarial loss: 0.477367\n",
      "epoch 40; iter: 0; batch classifier loss: 0.090214; batch adversarial loss: 0.549471\n",
      "epoch 41; iter: 0; batch classifier loss: 0.100925; batch adversarial loss: 0.500500\n",
      "epoch 42; iter: 0; batch classifier loss: 0.100183; batch adversarial loss: 0.436204\n",
      "epoch 43; iter: 0; batch classifier loss: 0.114964; batch adversarial loss: 0.436397\n",
      "epoch 44; iter: 0; batch classifier loss: 0.109928; batch adversarial loss: 0.475964\n",
      "epoch 45; iter: 0; batch classifier loss: 0.095816; batch adversarial loss: 0.486999\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116536; batch adversarial loss: 0.435594\n",
      "epoch 47; iter: 0; batch classifier loss: 0.067213; batch adversarial loss: 0.487089\n",
      "epoch 48; iter: 0; batch classifier loss: 0.118146; batch adversarial loss: 0.467964\n",
      "epoch 49; iter: 0; batch classifier loss: 0.100611; batch adversarial loss: 0.519449\n",
      "epoch 50; iter: 0; batch classifier loss: 0.146741; batch adversarial loss: 0.411761\n",
      "epoch 51; iter: 0; batch classifier loss: 0.115072; batch adversarial loss: 0.338818\n",
      "epoch 52; iter: 0; batch classifier loss: 0.106132; batch adversarial loss: 0.424487\n",
      "epoch 53; iter: 0; batch classifier loss: 0.066871; batch adversarial loss: 0.477811\n",
      "epoch 54; iter: 0; batch classifier loss: 0.081016; batch adversarial loss: 0.585079\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091475; batch adversarial loss: 0.447228\n",
      "epoch 56; iter: 0; batch classifier loss: 0.077911; batch adversarial loss: 0.484754\n",
      "epoch 57; iter: 0; batch classifier loss: 0.088997; batch adversarial loss: 0.378237\n",
      "epoch 58; iter: 0; batch classifier loss: 0.043427; batch adversarial loss: 0.391846\n",
      "epoch 59; iter: 0; batch classifier loss: 0.165629; batch adversarial loss: 0.374484\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076469; batch adversarial loss: 0.367460\n",
      "epoch 61; iter: 0; batch classifier loss: 0.122861; batch adversarial loss: 0.427384\n",
      "epoch 62; iter: 0; batch classifier loss: 0.102576; batch adversarial loss: 0.401727\n",
      "epoch 63; iter: 0; batch classifier loss: 0.084380; batch adversarial loss: 0.471552\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072078; batch adversarial loss: 0.385883\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087112; batch adversarial loss: 0.545992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.061436; batch adversarial loss: 0.465198\n",
      "epoch 67; iter: 0; batch classifier loss: 0.123166; batch adversarial loss: 0.384863\n",
      "epoch 68; iter: 0; batch classifier loss: 0.069129; batch adversarial loss: 0.454914\n",
      "epoch 69; iter: 0; batch classifier loss: 0.069855; batch adversarial loss: 0.428049\n",
      "epoch 70; iter: 0; batch classifier loss: 0.051304; batch adversarial loss: 0.382477\n",
      "epoch 71; iter: 0; batch classifier loss: 0.047927; batch adversarial loss: 0.438201\n",
      "epoch 72; iter: 0; batch classifier loss: 0.042662; batch adversarial loss: 0.406664\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102330; batch adversarial loss: 0.403821\n",
      "epoch 74; iter: 0; batch classifier loss: 0.127599; batch adversarial loss: 0.408413\n",
      "epoch 75; iter: 0; batch classifier loss: 0.091922; batch adversarial loss: 0.520759\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064017; batch adversarial loss: 0.414465\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104887; batch adversarial loss: 0.397156\n",
      "epoch 78; iter: 0; batch classifier loss: 0.087900; batch adversarial loss: 0.507380\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065126; batch adversarial loss: 0.391971\n",
      "epoch 80; iter: 0; batch classifier loss: 0.103188; batch adversarial loss: 0.484944\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065564; batch adversarial loss: 0.448928\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052883; batch adversarial loss: 0.375338\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062372; batch adversarial loss: 0.399559\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068666; batch adversarial loss: 0.464485\n",
      "epoch 85; iter: 0; batch classifier loss: 0.092377; batch adversarial loss: 0.520811\n",
      "epoch 86; iter: 0; batch classifier loss: 0.024389; batch adversarial loss: 0.488580\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055710; batch adversarial loss: 0.465726\n",
      "epoch 88; iter: 0; batch classifier loss: 0.065532; batch adversarial loss: 0.424913\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048513; batch adversarial loss: 0.449545\n",
      "epoch 90; iter: 0; batch classifier loss: 0.040650; batch adversarial loss: 0.541135\n",
      "epoch 91; iter: 0; batch classifier loss: 0.101768; batch adversarial loss: 0.332454\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043409; batch adversarial loss: 0.479052\n",
      "epoch 93; iter: 0; batch classifier loss: 0.115509; batch adversarial loss: 0.403106\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044916; batch adversarial loss: 0.473418\n",
      "epoch 95; iter: 0; batch classifier loss: 0.086388; batch adversarial loss: 0.468455\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059967; batch adversarial loss: 0.522179\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049405; batch adversarial loss: 0.445659\n",
      "epoch 98; iter: 0; batch classifier loss: 0.094424; batch adversarial loss: 0.472851\n",
      "epoch 99; iter: 0; batch classifier loss: 0.025186; batch adversarial loss: 0.516100\n",
      "epoch 100; iter: 0; batch classifier loss: 0.017215; batch adversarial loss: 0.329837\n",
      "epoch 101; iter: 0; batch classifier loss: 0.012922; batch adversarial loss: 0.490286\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027791; batch adversarial loss: 0.474462\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042704; batch adversarial loss: 0.383583\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057175; batch adversarial loss: 0.466717\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042358; batch adversarial loss: 0.430437\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034983; batch adversarial loss: 0.482698\n",
      "epoch 107; iter: 0; batch classifier loss: 0.060922; batch adversarial loss: 0.470280\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055722; batch adversarial loss: 0.404291\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032568; batch adversarial loss: 0.416301\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057377; batch adversarial loss: 0.490386\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049755; batch adversarial loss: 0.498741\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063806; batch adversarial loss: 0.497130\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059253; batch adversarial loss: 0.489396\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039132; batch adversarial loss: 0.549264\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063979; batch adversarial loss: 0.476403\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032830; batch adversarial loss: 0.478514\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038636; batch adversarial loss: 0.467983\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043178; batch adversarial loss: 0.562165\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038947; batch adversarial loss: 0.450457\n",
      "epoch 120; iter: 0; batch classifier loss: 0.019634; batch adversarial loss: 0.446430\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036297; batch adversarial loss: 0.486971\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043467; batch adversarial loss: 0.420794\n",
      "epoch 123; iter: 0; batch classifier loss: 0.011274; batch adversarial loss: 0.454091\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030544; batch adversarial loss: 0.390469\n",
      "epoch 125; iter: 0; batch classifier loss: 0.007738; batch adversarial loss: 0.472624\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019239; batch adversarial loss: 0.460395\n",
      "epoch 127; iter: 0; batch classifier loss: 0.068834; batch adversarial loss: 0.476266\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039009; batch adversarial loss: 0.456248\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016778; batch adversarial loss: 0.477360\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045219; batch adversarial loss: 0.464441\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034292; batch adversarial loss: 0.508277\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029437; batch adversarial loss: 0.524158\n",
      "epoch 133; iter: 0; batch classifier loss: 0.016856; batch adversarial loss: 0.427048\n",
      "epoch 134; iter: 0; batch classifier loss: 0.014129; batch adversarial loss: 0.477405\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031976; batch adversarial loss: 0.490342\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033717; batch adversarial loss: 0.412307\n",
      "epoch 137; iter: 0; batch classifier loss: 0.069708; batch adversarial loss: 0.417193\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017184; batch adversarial loss: 0.464382\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020132; batch adversarial loss: 0.460560\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033920; batch adversarial loss: 0.424782\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036199; batch adversarial loss: 0.465609\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017444; batch adversarial loss: 0.467666\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020178; batch adversarial loss: 0.473105\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018916; batch adversarial loss: 0.463867\n",
      "epoch 145; iter: 0; batch classifier loss: 0.010992; batch adversarial loss: 0.472369\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029086; batch adversarial loss: 0.503794\n",
      "epoch 147; iter: 0; batch classifier loss: 0.051479; batch adversarial loss: 0.413722\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039373; batch adversarial loss: 0.425927\n",
      "epoch 149; iter: 0; batch classifier loss: 0.007074; batch adversarial loss: 0.463654\n",
      "epoch 150; iter: 0; batch classifier loss: 0.066640; batch adversarial loss: 0.433043\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019662; batch adversarial loss: 0.455337\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024323; batch adversarial loss: 0.463974\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008951; batch adversarial loss: 0.483160\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028558; batch adversarial loss: 0.577271\n",
      "epoch 155; iter: 0; batch classifier loss: 0.070796; batch adversarial loss: 0.469801\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026391; batch adversarial loss: 0.406097\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035364; batch adversarial loss: 0.472694\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026202; batch adversarial loss: 0.475349\n",
      "epoch 159; iter: 0; batch classifier loss: 0.058142; batch adversarial loss: 0.452637\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023051; batch adversarial loss: 0.383785\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027193; batch adversarial loss: 0.429734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.022144; batch adversarial loss: 0.401085\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020204; batch adversarial loss: 0.434447\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029969; batch adversarial loss: 0.454925\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029275; batch adversarial loss: 0.458984\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025916; batch adversarial loss: 0.475764\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011085; batch adversarial loss: 0.601825\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036283; batch adversarial loss: 0.471485\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028561; batch adversarial loss: 0.528607\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023577; batch adversarial loss: 0.435317\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016351; batch adversarial loss: 0.568801\n",
      "epoch 172; iter: 0; batch classifier loss: 0.055053; batch adversarial loss: 0.426804\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025519; batch adversarial loss: 0.485503\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024151; batch adversarial loss: 0.459409\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021156; batch adversarial loss: 0.410691\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023432; batch adversarial loss: 0.532852\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007647; batch adversarial loss: 0.457274\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012481; batch adversarial loss: 0.447891\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036550; batch adversarial loss: 0.472546\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013494; batch adversarial loss: 0.406604\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021001; batch adversarial loss: 0.502721\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013718; batch adversarial loss: 0.424463\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014228; batch adversarial loss: 0.486074\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033078; batch adversarial loss: 0.419866\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008754; batch adversarial loss: 0.506480\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014643; batch adversarial loss: 0.390032\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014182; batch adversarial loss: 0.471240\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027800; batch adversarial loss: 0.416267\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032566; batch adversarial loss: 0.503158\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026593; batch adversarial loss: 0.427140\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014531; batch adversarial loss: 0.349126\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009840; batch adversarial loss: 0.510012\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014613; batch adversarial loss: 0.411781\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020531; batch adversarial loss: 0.550268\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020670; batch adversarial loss: 0.481476\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014093; batch adversarial loss: 0.410622\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009267; batch adversarial loss: 0.407983\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021792; batch adversarial loss: 0.467085\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007028; batch adversarial loss: 0.410579\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673278; batch adversarial loss: 0.587543\n",
      "epoch 1; iter: 0; batch classifier loss: 0.437182; batch adversarial loss: 0.624860\n",
      "epoch 2; iter: 0; batch classifier loss: 0.404884; batch adversarial loss: 0.580385\n",
      "epoch 3; iter: 0; batch classifier loss: 0.446113; batch adversarial loss: 0.625661\n",
      "epoch 4; iter: 0; batch classifier loss: 0.457613; batch adversarial loss: 0.640089\n",
      "epoch 5; iter: 0; batch classifier loss: 0.609766; batch adversarial loss: 0.637210\n",
      "epoch 6; iter: 0; batch classifier loss: 0.627034; batch adversarial loss: 0.568208\n",
      "epoch 7; iter: 0; batch classifier loss: 0.454552; batch adversarial loss: 0.567057\n",
      "epoch 8; iter: 0; batch classifier loss: 0.475224; batch adversarial loss: 0.583866\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499532; batch adversarial loss: 0.529087\n",
      "epoch 10; iter: 0; batch classifier loss: 0.390308; batch adversarial loss: 0.540829\n",
      "epoch 11; iter: 0; batch classifier loss: 0.434149; batch adversarial loss: 0.509022\n",
      "epoch 12; iter: 0; batch classifier loss: 0.357738; batch adversarial loss: 0.551620\n",
      "epoch 13; iter: 0; batch classifier loss: 0.324446; batch adversarial loss: 0.515326\n",
      "epoch 14; iter: 0; batch classifier loss: 0.322262; batch adversarial loss: 0.465022\n",
      "epoch 15; iter: 0; batch classifier loss: 0.265371; batch adversarial loss: 0.481041\n",
      "epoch 16; iter: 0; batch classifier loss: 0.305643; batch adversarial loss: 0.564139\n",
      "epoch 17; iter: 0; batch classifier loss: 0.287708; batch adversarial loss: 0.533169\n",
      "epoch 18; iter: 0; batch classifier loss: 0.275362; batch adversarial loss: 0.543708\n",
      "epoch 19; iter: 0; batch classifier loss: 0.235716; batch adversarial loss: 0.514748\n",
      "epoch 20; iter: 0; batch classifier loss: 0.364376; batch adversarial loss: 0.475035\n",
      "epoch 21; iter: 0; batch classifier loss: 0.291349; batch adversarial loss: 0.440850\n",
      "epoch 22; iter: 0; batch classifier loss: 0.255295; batch adversarial loss: 0.557221\n",
      "epoch 23; iter: 0; batch classifier loss: 0.231389; batch adversarial loss: 0.448889\n",
      "epoch 24; iter: 0; batch classifier loss: 0.239302; batch adversarial loss: 0.422814\n",
      "epoch 25; iter: 0; batch classifier loss: 0.269724; batch adversarial loss: 0.494754\n",
      "epoch 26; iter: 0; batch classifier loss: 0.256473; batch adversarial loss: 0.518237\n",
      "epoch 27; iter: 0; batch classifier loss: 0.255660; batch adversarial loss: 0.507031\n",
      "epoch 28; iter: 0; batch classifier loss: 0.231348; batch adversarial loss: 0.424497\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209841; batch adversarial loss: 0.487638\n",
      "epoch 30; iter: 0; batch classifier loss: 0.286514; batch adversarial loss: 0.539807\n",
      "epoch 31; iter: 0; batch classifier loss: 0.212175; batch adversarial loss: 0.506451\n",
      "epoch 32; iter: 0; batch classifier loss: 0.237308; batch adversarial loss: 0.403667\n",
      "epoch 33; iter: 0; batch classifier loss: 0.226742; batch adversarial loss: 0.389342\n",
      "epoch 34; iter: 0; batch classifier loss: 0.350703; batch adversarial loss: 0.392156\n",
      "epoch 35; iter: 0; batch classifier loss: 0.195531; batch adversarial loss: 0.537071\n",
      "epoch 36; iter: 0; batch classifier loss: 0.244176; batch adversarial loss: 0.423274\n",
      "epoch 37; iter: 0; batch classifier loss: 0.229413; batch adversarial loss: 0.475076\n",
      "epoch 38; iter: 0; batch classifier loss: 0.171825; batch adversarial loss: 0.497541\n",
      "epoch 39; iter: 0; batch classifier loss: 0.266398; batch adversarial loss: 0.392372\n",
      "epoch 40; iter: 0; batch classifier loss: 0.241803; batch adversarial loss: 0.479205\n",
      "epoch 41; iter: 0; batch classifier loss: 0.216396; batch adversarial loss: 0.506266\n",
      "epoch 42; iter: 0; batch classifier loss: 0.180158; batch adversarial loss: 0.487818\n",
      "epoch 43; iter: 0; batch classifier loss: 0.209973; batch adversarial loss: 0.378509\n",
      "epoch 44; iter: 0; batch classifier loss: 0.226613; batch adversarial loss: 0.552136\n",
      "epoch 45; iter: 0; batch classifier loss: 0.233469; batch adversarial loss: 0.459203\n",
      "epoch 46; iter: 0; batch classifier loss: 0.288144; batch adversarial loss: 0.481642\n",
      "epoch 47; iter: 0; batch classifier loss: 0.164760; batch adversarial loss: 0.506129\n",
      "epoch 48; iter: 0; batch classifier loss: 0.236506; batch adversarial loss: 0.471017\n",
      "epoch 49; iter: 0; batch classifier loss: 0.181572; batch adversarial loss: 0.470934\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098330; batch adversarial loss: 0.481403\n",
      "epoch 51; iter: 0; batch classifier loss: 0.134263; batch adversarial loss: 0.404929\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103075; batch adversarial loss: 0.423246\n",
      "epoch 53; iter: 0; batch classifier loss: 0.085565; batch adversarial loss: 0.464484\n",
      "epoch 54; iter: 0; batch classifier loss: 0.067147; batch adversarial loss: 0.482643\n",
      "epoch 55; iter: 0; batch classifier loss: 0.061387; batch adversarial loss: 0.473012\n",
      "epoch 56; iter: 0; batch classifier loss: 0.092758; batch adversarial loss: 0.440243\n",
      "epoch 57; iter: 0; batch classifier loss: 0.127381; batch adversarial loss: 0.535645\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072031; batch adversarial loss: 0.437084\n",
      "epoch 59; iter: 0; batch classifier loss: 0.108717; batch adversarial loss: 0.477445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.149688; batch adversarial loss: 0.506555\n",
      "epoch 61; iter: 0; batch classifier loss: 0.121359; batch adversarial loss: 0.480992\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089400; batch adversarial loss: 0.506280\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100871; batch adversarial loss: 0.389681\n",
      "epoch 64; iter: 0; batch classifier loss: 0.071990; batch adversarial loss: 0.419447\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092455; batch adversarial loss: 0.436028\n",
      "epoch 66; iter: 0; batch classifier loss: 0.094234; batch adversarial loss: 0.428289\n",
      "epoch 67; iter: 0; batch classifier loss: 0.090149; batch adversarial loss: 0.442000\n",
      "epoch 68; iter: 0; batch classifier loss: 0.085450; batch adversarial loss: 0.330026\n",
      "epoch 69; iter: 0; batch classifier loss: 0.105917; batch adversarial loss: 0.371344\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073481; batch adversarial loss: 0.354019\n",
      "epoch 71; iter: 0; batch classifier loss: 0.031171; batch adversarial loss: 0.426929\n",
      "epoch 72; iter: 0; batch classifier loss: 0.068336; batch adversarial loss: 0.464908\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076981; batch adversarial loss: 0.483082\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076424; batch adversarial loss: 0.455846\n",
      "epoch 75; iter: 0; batch classifier loss: 0.078644; batch adversarial loss: 0.532158\n",
      "epoch 76; iter: 0; batch classifier loss: 0.045556; batch adversarial loss: 0.395552\n",
      "epoch 77; iter: 0; batch classifier loss: 0.058099; batch adversarial loss: 0.476597\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064628; batch adversarial loss: 0.356487\n",
      "epoch 79; iter: 0; batch classifier loss: 0.095184; batch adversarial loss: 0.322801\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043477; batch adversarial loss: 0.394117\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077267; batch adversarial loss: 0.465523\n",
      "epoch 82; iter: 0; batch classifier loss: 0.098385; batch adversarial loss: 0.527405\n",
      "epoch 83; iter: 0; batch classifier loss: 0.097418; batch adversarial loss: 0.537132\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064819; batch adversarial loss: 0.433681\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076785; batch adversarial loss: 0.442436\n",
      "epoch 86; iter: 0; batch classifier loss: 0.085666; batch adversarial loss: 0.390647\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072444; batch adversarial loss: 0.429769\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054242; batch adversarial loss: 0.414625\n",
      "epoch 89; iter: 0; batch classifier loss: 0.085773; batch adversarial loss: 0.464299\n",
      "epoch 90; iter: 0; batch classifier loss: 0.085139; batch adversarial loss: 0.438524\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064951; batch adversarial loss: 0.459388\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044649; batch adversarial loss: 0.343484\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053213; batch adversarial loss: 0.432082\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064891; batch adversarial loss: 0.389647\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054624; batch adversarial loss: 0.373138\n",
      "epoch 96; iter: 0; batch classifier loss: 0.053244; batch adversarial loss: 0.378993\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063778; batch adversarial loss: 0.453925\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048671; batch adversarial loss: 0.427454\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047149; batch adversarial loss: 0.462540\n",
      "epoch 100; iter: 0; batch classifier loss: 0.070388; batch adversarial loss: 0.428488\n",
      "epoch 101; iter: 0; batch classifier loss: 0.078626; batch adversarial loss: 0.435160\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066448; batch adversarial loss: 0.496290\n",
      "epoch 103; iter: 0; batch classifier loss: 0.027309; batch adversarial loss: 0.395689\n",
      "epoch 104; iter: 0; batch classifier loss: 0.075407; batch adversarial loss: 0.503514\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045372; batch adversarial loss: 0.479300\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050342; batch adversarial loss: 0.416914\n",
      "epoch 107; iter: 0; batch classifier loss: 0.084208; batch adversarial loss: 0.470341\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056539; batch adversarial loss: 0.387940\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041887; batch adversarial loss: 0.388278\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048519; batch adversarial loss: 0.420916\n",
      "epoch 111; iter: 0; batch classifier loss: 0.071687; batch adversarial loss: 0.475576\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045333; batch adversarial loss: 0.407371\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053548; batch adversarial loss: 0.430410\n",
      "epoch 114; iter: 0; batch classifier loss: 0.073633; batch adversarial loss: 0.442793\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048408; batch adversarial loss: 0.380079\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046823; batch adversarial loss: 0.423736\n",
      "epoch 117; iter: 0; batch classifier loss: 0.064436; batch adversarial loss: 0.386118\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035332; batch adversarial loss: 0.385693\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070184; batch adversarial loss: 0.468518\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074128; batch adversarial loss: 0.415872\n",
      "epoch 121; iter: 0; batch classifier loss: 0.073432; batch adversarial loss: 0.430737\n",
      "epoch 122; iter: 0; batch classifier loss: 0.072392; batch adversarial loss: 0.411989\n",
      "epoch 123; iter: 0; batch classifier loss: 0.060450; batch adversarial loss: 0.410712\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057748; batch adversarial loss: 0.483674\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046755; batch adversarial loss: 0.435597\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040898; batch adversarial loss: 0.431001\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053659; batch adversarial loss: 0.527173\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036485; batch adversarial loss: 0.427796\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045385; batch adversarial loss: 0.553477\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047922; batch adversarial loss: 0.461324\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048805; batch adversarial loss: 0.481921\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043252; batch adversarial loss: 0.509048\n",
      "epoch 133; iter: 0; batch classifier loss: 0.070996; batch adversarial loss: 0.396940\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037398; batch adversarial loss: 0.522889\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040636; batch adversarial loss: 0.408696\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035347; batch adversarial loss: 0.377842\n",
      "epoch 137; iter: 0; batch classifier loss: 0.075753; batch adversarial loss: 0.407518\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028581; batch adversarial loss: 0.571148\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042677; batch adversarial loss: 0.452790\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047725; batch adversarial loss: 0.448286\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053060; batch adversarial loss: 0.379498\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043277; batch adversarial loss: 0.440161\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046291; batch adversarial loss: 0.379299\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025963; batch adversarial loss: 0.469189\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032447; batch adversarial loss: 0.458174\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031416; batch adversarial loss: 0.492857\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026972; batch adversarial loss: 0.414581\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041020; batch adversarial loss: 0.434265\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034015; batch adversarial loss: 0.406832\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040422; batch adversarial loss: 0.551470\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035854; batch adversarial loss: 0.347352\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039986; batch adversarial loss: 0.453757\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019228; batch adversarial loss: 0.475408\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013496; batch adversarial loss: 0.395268\n",
      "epoch 155; iter: 0; batch classifier loss: 0.043564; batch adversarial loss: 0.423031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.024341; batch adversarial loss: 0.462830\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030809; batch adversarial loss: 0.436270\n",
      "epoch 158; iter: 0; batch classifier loss: 0.041563; batch adversarial loss: 0.463130\n",
      "epoch 159; iter: 0; batch classifier loss: 0.046296; batch adversarial loss: 0.442674\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020098; batch adversarial loss: 0.387703\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040205; batch adversarial loss: 0.415281\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038400; batch adversarial loss: 0.506638\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018681; batch adversarial loss: 0.445961\n",
      "epoch 164; iter: 0; batch classifier loss: 0.046625; batch adversarial loss: 0.485091\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022299; batch adversarial loss: 0.445544\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028650; batch adversarial loss: 0.475071\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035509; batch adversarial loss: 0.497535\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019820; batch adversarial loss: 0.439001\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009746; batch adversarial loss: 0.487841\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014644; batch adversarial loss: 0.511533\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040918; batch adversarial loss: 0.474202\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016038; batch adversarial loss: 0.446941\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028569; batch adversarial loss: 0.437771\n",
      "epoch 174; iter: 0; batch classifier loss: 0.034009; batch adversarial loss: 0.571537\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008447; batch adversarial loss: 0.472885\n",
      "epoch 176; iter: 0; batch classifier loss: 0.006183; batch adversarial loss: 0.482004\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012144; batch adversarial loss: 0.410795\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011332; batch adversarial loss: 0.543546\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007258; batch adversarial loss: 0.374544\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010371; batch adversarial loss: 0.424782\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018077; batch adversarial loss: 0.420921\n",
      "epoch 182; iter: 0; batch classifier loss: 0.059486; batch adversarial loss: 0.568040\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024441; batch adversarial loss: 0.390089\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013710; batch adversarial loss: 0.401226\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024862; batch adversarial loss: 0.436827\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012557; batch adversarial loss: 0.467069\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012995; batch adversarial loss: 0.448276\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007650; batch adversarial loss: 0.336425\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032952; batch adversarial loss: 0.552923\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017920; batch adversarial loss: 0.520625\n",
      "epoch 191; iter: 0; batch classifier loss: 0.064214; batch adversarial loss: 0.557870\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040100; batch adversarial loss: 0.609326\n",
      "epoch 193; iter: 0; batch classifier loss: 0.067330; batch adversarial loss: 0.650130\n",
      "epoch 194; iter: 0; batch classifier loss: 0.043100; batch adversarial loss: 0.439887\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020998; batch adversarial loss: 0.558249\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037214; batch adversarial loss: 0.559647\n",
      "epoch 197; iter: 0; batch classifier loss: 0.050658; batch adversarial loss: 0.448911\n",
      "epoch 198; iter: 0; batch classifier loss: 0.058228; batch adversarial loss: 0.444269\n",
      "epoch 199; iter: 0; batch classifier loss: 0.061246; batch adversarial loss: 0.591476\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677231; batch adversarial loss: 0.553864\n",
      "epoch 1; iter: 0; batch classifier loss: 0.491477; batch adversarial loss: 0.535793\n",
      "epoch 2; iter: 0; batch classifier loss: 0.426245; batch adversarial loss: 0.566455\n",
      "epoch 3; iter: 0; batch classifier loss: 0.363599; batch adversarial loss: 0.591009\n",
      "epoch 4; iter: 0; batch classifier loss: 0.435894; batch adversarial loss: 0.607091\n",
      "epoch 5; iter: 0; batch classifier loss: 0.505519; batch adversarial loss: 0.566853\n",
      "epoch 6; iter: 0; batch classifier loss: 0.446126; batch adversarial loss: 0.581911\n",
      "epoch 7; iter: 0; batch classifier loss: 0.480963; batch adversarial loss: 0.587573\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576244; batch adversarial loss: 0.674528\n",
      "epoch 9; iter: 0; batch classifier loss: 0.614494; batch adversarial loss: 0.551866\n",
      "epoch 10; iter: 0; batch classifier loss: 0.523610; batch adversarial loss: 0.608871\n",
      "epoch 11; iter: 0; batch classifier loss: 0.472168; batch adversarial loss: 0.432860\n",
      "epoch 12; iter: 0; batch classifier loss: 0.402820; batch adversarial loss: 0.432542\n",
      "epoch 13; iter: 0; batch classifier loss: 0.281344; batch adversarial loss: 0.476145\n",
      "epoch 14; iter: 0; batch classifier loss: 0.288487; batch adversarial loss: 0.489851\n",
      "epoch 15; iter: 0; batch classifier loss: 0.233777; batch adversarial loss: 0.517361\n",
      "epoch 16; iter: 0; batch classifier loss: 0.213574; batch adversarial loss: 0.398397\n",
      "epoch 17; iter: 0; batch classifier loss: 0.177517; batch adversarial loss: 0.492316\n",
      "epoch 18; iter: 0; batch classifier loss: 0.181023; batch adversarial loss: 0.459194\n",
      "epoch 19; iter: 0; batch classifier loss: 0.198996; batch adversarial loss: 0.416468\n",
      "epoch 20; iter: 0; batch classifier loss: 0.207457; batch adversarial loss: 0.473125\n",
      "epoch 21; iter: 0; batch classifier loss: 0.238467; batch adversarial loss: 0.396111\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206815; batch adversarial loss: 0.509388\n",
      "epoch 23; iter: 0; batch classifier loss: 0.162029; batch adversarial loss: 0.460320\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199633; batch adversarial loss: 0.397525\n",
      "epoch 25; iter: 0; batch classifier loss: 0.135058; batch adversarial loss: 0.462053\n",
      "epoch 26; iter: 0; batch classifier loss: 0.228898; batch adversarial loss: 0.451674\n",
      "epoch 27; iter: 0; batch classifier loss: 0.127541; batch adversarial loss: 0.551486\n",
      "epoch 28; iter: 0; batch classifier loss: 0.107865; batch adversarial loss: 0.375410\n",
      "epoch 29; iter: 0; batch classifier loss: 0.127219; batch adversarial loss: 0.462596\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130910; batch adversarial loss: 0.465463\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166195; batch adversarial loss: 0.537027\n",
      "epoch 32; iter: 0; batch classifier loss: 0.119296; batch adversarial loss: 0.503424\n",
      "epoch 33; iter: 0; batch classifier loss: 0.106172; batch adversarial loss: 0.518909\n",
      "epoch 34; iter: 0; batch classifier loss: 0.126682; batch adversarial loss: 0.503038\n",
      "epoch 35; iter: 0; batch classifier loss: 0.164711; batch adversarial loss: 0.519716\n",
      "epoch 36; iter: 0; batch classifier loss: 0.143981; batch adversarial loss: 0.367739\n",
      "epoch 37; iter: 0; batch classifier loss: 0.187516; batch adversarial loss: 0.409939\n",
      "epoch 38; iter: 0; batch classifier loss: 0.118820; batch adversarial loss: 0.430923\n",
      "epoch 39; iter: 0; batch classifier loss: 0.092273; batch adversarial loss: 0.465314\n",
      "epoch 40; iter: 0; batch classifier loss: 0.134565; batch adversarial loss: 0.413972\n",
      "epoch 41; iter: 0; batch classifier loss: 0.161422; batch adversarial loss: 0.438317\n",
      "epoch 42; iter: 0; batch classifier loss: 0.084634; batch adversarial loss: 0.511579\n",
      "epoch 43; iter: 0; batch classifier loss: 0.128263; batch adversarial loss: 0.443690\n",
      "epoch 44; iter: 0; batch classifier loss: 0.187178; batch adversarial loss: 0.356703\n",
      "epoch 45; iter: 0; batch classifier loss: 0.130018; batch adversarial loss: 0.408447\n",
      "epoch 46; iter: 0; batch classifier loss: 0.066280; batch adversarial loss: 0.527789\n",
      "epoch 47; iter: 0; batch classifier loss: 0.075730; batch adversarial loss: 0.492288\n",
      "epoch 48; iter: 0; batch classifier loss: 0.118489; batch adversarial loss: 0.379716\n",
      "epoch 49; iter: 0; batch classifier loss: 0.154684; batch adversarial loss: 0.415682\n",
      "epoch 50; iter: 0; batch classifier loss: 0.099351; batch adversarial loss: 0.360373\n",
      "epoch 51; iter: 0; batch classifier loss: 0.095267; batch adversarial loss: 0.490470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.119296; batch adversarial loss: 0.479335\n",
      "epoch 53; iter: 0; batch classifier loss: 0.113469; batch adversarial loss: 0.372568\n",
      "epoch 54; iter: 0; batch classifier loss: 0.082364; batch adversarial loss: 0.494469\n",
      "epoch 55; iter: 0; batch classifier loss: 0.137526; batch adversarial loss: 0.483146\n",
      "epoch 56; iter: 0; batch classifier loss: 0.161361; batch adversarial loss: 0.569168\n",
      "epoch 57; iter: 0; batch classifier loss: 0.133186; batch adversarial loss: 0.423280\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072994; batch adversarial loss: 0.465009\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085943; batch adversarial loss: 0.532050\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101863; batch adversarial loss: 0.515589\n",
      "epoch 61; iter: 0; batch classifier loss: 0.115349; batch adversarial loss: 0.428208\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083561; batch adversarial loss: 0.562535\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104144; batch adversarial loss: 0.523397\n",
      "epoch 64; iter: 0; batch classifier loss: 0.085500; batch adversarial loss: 0.516166\n",
      "epoch 65; iter: 0; batch classifier loss: 0.059727; batch adversarial loss: 0.376873\n",
      "epoch 66; iter: 0; batch classifier loss: 0.108444; batch adversarial loss: 0.443774\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094212; batch adversarial loss: 0.475690\n",
      "epoch 68; iter: 0; batch classifier loss: 0.099747; batch adversarial loss: 0.406146\n",
      "epoch 69; iter: 0; batch classifier loss: 0.066049; batch adversarial loss: 0.483421\n",
      "epoch 70; iter: 0; batch classifier loss: 0.108885; batch adversarial loss: 0.446648\n",
      "epoch 71; iter: 0; batch classifier loss: 0.120508; batch adversarial loss: 0.465860\n",
      "epoch 72; iter: 0; batch classifier loss: 0.106025; batch adversarial loss: 0.452584\n",
      "epoch 73; iter: 0; batch classifier loss: 0.120029; batch adversarial loss: 0.510014\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067852; batch adversarial loss: 0.399300\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068778; batch adversarial loss: 0.507810\n",
      "epoch 76; iter: 0; batch classifier loss: 0.120157; batch adversarial loss: 0.488645\n",
      "epoch 77; iter: 0; batch classifier loss: 0.054279; batch adversarial loss: 0.546089\n",
      "epoch 78; iter: 0; batch classifier loss: 0.101061; batch adversarial loss: 0.429513\n",
      "epoch 79; iter: 0; batch classifier loss: 0.159889; batch adversarial loss: 0.489797\n",
      "epoch 80; iter: 0; batch classifier loss: 0.118774; batch adversarial loss: 0.441461\n",
      "epoch 81; iter: 0; batch classifier loss: 0.088750; batch adversarial loss: 0.410274\n",
      "epoch 82; iter: 0; batch classifier loss: 0.047588; batch adversarial loss: 0.389407\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086956; batch adversarial loss: 0.461202\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062419; batch adversarial loss: 0.508397\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083676; batch adversarial loss: 0.598849\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070008; batch adversarial loss: 0.474053\n",
      "epoch 87; iter: 0; batch classifier loss: 0.086790; batch adversarial loss: 0.435212\n",
      "epoch 88; iter: 0; batch classifier loss: 0.139002; batch adversarial loss: 0.394224\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080170; batch adversarial loss: 0.399118\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057601; batch adversarial loss: 0.508848\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068539; batch adversarial loss: 0.489519\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079739; batch adversarial loss: 0.465673\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058074; batch adversarial loss: 0.402888\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041257; batch adversarial loss: 0.424807\n",
      "epoch 95; iter: 0; batch classifier loss: 0.121259; batch adversarial loss: 0.430317\n",
      "epoch 96; iter: 0; batch classifier loss: 0.018210; batch adversarial loss: 0.465483\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056290; batch adversarial loss: 0.502163\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045128; batch adversarial loss: 0.526000\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085367; batch adversarial loss: 0.390006\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039113; batch adversarial loss: 0.442370\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058014; batch adversarial loss: 0.386416\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050822; batch adversarial loss: 0.586203\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044680; batch adversarial loss: 0.517103\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045896; batch adversarial loss: 0.481197\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052834; batch adversarial loss: 0.478091\n",
      "epoch 106; iter: 0; batch classifier loss: 0.116045; batch adversarial loss: 0.481786\n",
      "epoch 107; iter: 0; batch classifier loss: 0.067871; batch adversarial loss: 0.418176\n",
      "epoch 108; iter: 0; batch classifier loss: 0.072812; batch adversarial loss: 0.416761\n",
      "epoch 109; iter: 0; batch classifier loss: 0.072467; batch adversarial loss: 0.438426\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037461; batch adversarial loss: 0.380535\n",
      "epoch 111; iter: 0; batch classifier loss: 0.073571; batch adversarial loss: 0.349071\n",
      "epoch 112; iter: 0; batch classifier loss: 0.114152; batch adversarial loss: 0.448355\n",
      "epoch 113; iter: 0; batch classifier loss: 0.072998; batch adversarial loss: 0.360245\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042297; batch adversarial loss: 0.574991\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047135; batch adversarial loss: 0.455496\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038485; batch adversarial loss: 0.449705\n",
      "epoch 117; iter: 0; batch classifier loss: 0.057929; batch adversarial loss: 0.463616\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060731; batch adversarial loss: 0.433077\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053688; batch adversarial loss: 0.394609\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042072; batch adversarial loss: 0.553384\n",
      "epoch 121; iter: 0; batch classifier loss: 0.073079; batch adversarial loss: 0.342393\n",
      "epoch 122; iter: 0; batch classifier loss: 0.053528; batch adversarial loss: 0.511670\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050594; batch adversarial loss: 0.441018\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025410; batch adversarial loss: 0.516399\n",
      "epoch 125; iter: 0; batch classifier loss: 0.087526; batch adversarial loss: 0.546415\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038762; batch adversarial loss: 0.559206\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027635; batch adversarial loss: 0.361648\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022580; batch adversarial loss: 0.432557\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052620; batch adversarial loss: 0.421959\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043190; batch adversarial loss: 0.462348\n",
      "epoch 131; iter: 0; batch classifier loss: 0.014321; batch adversarial loss: 0.402959\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037323; batch adversarial loss: 0.443297\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039875; batch adversarial loss: 0.424962\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034246; batch adversarial loss: 0.359986\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025305; batch adversarial loss: 0.464532\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046612; batch adversarial loss: 0.440290\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026889; batch adversarial loss: 0.503615\n",
      "epoch 138; iter: 0; batch classifier loss: 0.010887; batch adversarial loss: 0.402895\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044008; batch adversarial loss: 0.550369\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051726; batch adversarial loss: 0.486690\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024047; batch adversarial loss: 0.377769\n",
      "epoch 142; iter: 0; batch classifier loss: 0.007073; batch adversarial loss: 0.581989\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028444; batch adversarial loss: 0.535986\n",
      "epoch 144; iter: 0; batch classifier loss: 0.042184; batch adversarial loss: 0.373135\n",
      "epoch 145; iter: 0; batch classifier loss: 0.008135; batch adversarial loss: 0.443787\n",
      "epoch 146; iter: 0; batch classifier loss: 0.005694; batch adversarial loss: 0.485320\n",
      "epoch 147; iter: 0; batch classifier loss: 0.101292; batch adversarial loss: 0.457356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.061409; batch adversarial loss: 0.452138\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034593; batch adversarial loss: 0.494293\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017466; batch adversarial loss: 0.471354\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028420; batch adversarial loss: 0.435284\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025328; batch adversarial loss: 0.418468\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025933; batch adversarial loss: 0.374037\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026033; batch adversarial loss: 0.544775\n",
      "epoch 155; iter: 0; batch classifier loss: 0.070411; batch adversarial loss: 0.511375\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023277; batch adversarial loss: 0.511238\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009001; batch adversarial loss: 0.454071\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012992; batch adversarial loss: 0.579889\n",
      "epoch 159; iter: 0; batch classifier loss: 0.008316; batch adversarial loss: 0.441382\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023016; batch adversarial loss: 0.486440\n",
      "epoch 161; iter: 0; batch classifier loss: 0.064206; batch adversarial loss: 0.451488\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039755; batch adversarial loss: 0.376895\n",
      "epoch 163; iter: 0; batch classifier loss: 0.008202; batch adversarial loss: 0.425831\n",
      "epoch 164; iter: 0; batch classifier loss: 0.039421; batch adversarial loss: 0.439166\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033985; batch adversarial loss: 0.546521\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021599; batch adversarial loss: 0.636335\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036770; batch adversarial loss: 0.482216\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009637; batch adversarial loss: 0.400127\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018793; batch adversarial loss: 0.372047\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019888; batch adversarial loss: 0.471867\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022703; batch adversarial loss: 0.483438\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013324; batch adversarial loss: 0.432549\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019267; batch adversarial loss: 0.367114\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030556; batch adversarial loss: 0.442257\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022369; batch adversarial loss: 0.428403\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011260; batch adversarial loss: 0.473320\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020336; batch adversarial loss: 0.367942\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028719; batch adversarial loss: 0.483576\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009618; batch adversarial loss: 0.395115\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013202; batch adversarial loss: 0.432923\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022591; batch adversarial loss: 0.443311\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020169; batch adversarial loss: 0.421959\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014248; batch adversarial loss: 0.479021\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015513; batch adversarial loss: 0.435410\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026288; batch adversarial loss: 0.372724\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007919; batch adversarial loss: 0.545751\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012061; batch adversarial loss: 0.422627\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011762; batch adversarial loss: 0.335055\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017329; batch adversarial loss: 0.496674\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021843; batch adversarial loss: 0.396769\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022262; batch adversarial loss: 0.487309\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020847; batch adversarial loss: 0.477163\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009213; batch adversarial loss: 0.490029\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012963; batch adversarial loss: 0.411190\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021831; batch adversarial loss: 0.492698\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022344; batch adversarial loss: 0.409368\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037427; batch adversarial loss: 0.443668\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013539; batch adversarial loss: 0.492566\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022089; batch adversarial loss: 0.504045\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713601; batch adversarial loss: 0.534111\n",
      "epoch 1; iter: 0; batch classifier loss: 0.393963; batch adversarial loss: 0.645176\n",
      "epoch 2; iter: 0; batch classifier loss: 0.464948; batch adversarial loss: 0.565756\n",
      "epoch 3; iter: 0; batch classifier loss: 0.365768; batch adversarial loss: 0.535489\n",
      "epoch 4; iter: 0; batch classifier loss: 0.419471; batch adversarial loss: 0.567046\n",
      "epoch 5; iter: 0; batch classifier loss: 0.327206; batch adversarial loss: 0.559470\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315959; batch adversarial loss: 0.594879\n",
      "epoch 7; iter: 0; batch classifier loss: 0.246544; batch adversarial loss: 0.531186\n",
      "epoch 8; iter: 0; batch classifier loss: 0.344867; batch adversarial loss: 0.573561\n",
      "epoch 9; iter: 0; batch classifier loss: 0.347095; batch adversarial loss: 0.577063\n",
      "epoch 10; iter: 0; batch classifier loss: 0.428482; batch adversarial loss: 0.485983\n",
      "epoch 11; iter: 0; batch classifier loss: 0.457182; batch adversarial loss: 0.554131\n",
      "epoch 12; iter: 0; batch classifier loss: 0.485029; batch adversarial loss: 0.590617\n",
      "epoch 13; iter: 0; batch classifier loss: 0.558583; batch adversarial loss: 0.505833\n",
      "epoch 14; iter: 0; batch classifier loss: 0.741535; batch adversarial loss: 0.581822\n",
      "epoch 15; iter: 0; batch classifier loss: 0.504023; batch adversarial loss: 0.490657\n",
      "epoch 16; iter: 0; batch classifier loss: 0.304363; batch adversarial loss: 0.473591\n",
      "epoch 17; iter: 0; batch classifier loss: 0.324559; batch adversarial loss: 0.562854\n",
      "epoch 18; iter: 0; batch classifier loss: 0.303762; batch adversarial loss: 0.512781\n",
      "epoch 19; iter: 0; batch classifier loss: 0.225833; batch adversarial loss: 0.414830\n",
      "epoch 20; iter: 0; batch classifier loss: 0.324399; batch adversarial loss: 0.539217\n",
      "epoch 21; iter: 0; batch classifier loss: 0.250758; batch adversarial loss: 0.451912\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189153; batch adversarial loss: 0.479872\n",
      "epoch 23; iter: 0; batch classifier loss: 0.194075; batch adversarial loss: 0.479936\n",
      "epoch 24; iter: 0; batch classifier loss: 0.191041; batch adversarial loss: 0.472461\n",
      "epoch 25; iter: 0; batch classifier loss: 0.184371; batch adversarial loss: 0.456276\n",
      "epoch 26; iter: 0; batch classifier loss: 0.195212; batch adversarial loss: 0.543957\n",
      "epoch 27; iter: 0; batch classifier loss: 0.155456; batch adversarial loss: 0.478910\n",
      "epoch 28; iter: 0; batch classifier loss: 0.176876; batch adversarial loss: 0.476275\n",
      "epoch 29; iter: 0; batch classifier loss: 0.147300; batch adversarial loss: 0.524327\n",
      "epoch 30; iter: 0; batch classifier loss: 0.174624; batch adversarial loss: 0.443978\n",
      "epoch 31; iter: 0; batch classifier loss: 0.184936; batch adversarial loss: 0.541090\n",
      "epoch 32; iter: 0; batch classifier loss: 0.156028; batch adversarial loss: 0.477527\n",
      "epoch 33; iter: 0; batch classifier loss: 0.202320; batch adversarial loss: 0.469913\n",
      "epoch 34; iter: 0; batch classifier loss: 0.217195; batch adversarial loss: 0.468079\n",
      "epoch 35; iter: 0; batch classifier loss: 0.156369; batch adversarial loss: 0.370636\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187088; batch adversarial loss: 0.347354\n",
      "epoch 37; iter: 0; batch classifier loss: 0.128564; batch adversarial loss: 0.615752\n",
      "epoch 38; iter: 0; batch classifier loss: 0.141037; batch adversarial loss: 0.475464\n",
      "epoch 39; iter: 0; batch classifier loss: 0.177882; batch adversarial loss: 0.437891\n",
      "epoch 40; iter: 0; batch classifier loss: 0.193003; batch adversarial loss: 0.434002\n",
      "epoch 41; iter: 0; batch classifier loss: 0.165238; batch adversarial loss: 0.464795\n",
      "epoch 42; iter: 0; batch classifier loss: 0.158920; batch adversarial loss: 0.469980\n",
      "epoch 43; iter: 0; batch classifier loss: 0.148479; batch adversarial loss: 0.426756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.190412; batch adversarial loss: 0.539711\n",
      "epoch 45; iter: 0; batch classifier loss: 0.199359; batch adversarial loss: 0.485059\n",
      "epoch 46; iter: 0; batch classifier loss: 0.123594; batch adversarial loss: 0.472862\n",
      "epoch 47; iter: 0; batch classifier loss: 0.102306; batch adversarial loss: 0.567659\n",
      "epoch 48; iter: 0; batch classifier loss: 0.180708; batch adversarial loss: 0.421934\n",
      "epoch 49; iter: 0; batch classifier loss: 0.212799; batch adversarial loss: 0.491824\n",
      "epoch 50; iter: 0; batch classifier loss: 0.182608; batch adversarial loss: 0.392945\n",
      "epoch 51; iter: 0; batch classifier loss: 0.200971; batch adversarial loss: 0.426680\n",
      "epoch 52; iter: 0; batch classifier loss: 0.172325; batch adversarial loss: 0.325342\n",
      "epoch 53; iter: 0; batch classifier loss: 0.168123; batch adversarial loss: 0.497943\n",
      "epoch 54; iter: 0; batch classifier loss: 0.183829; batch adversarial loss: 0.494869\n",
      "epoch 55; iter: 0; batch classifier loss: 0.177880; batch adversarial loss: 0.421891\n",
      "epoch 56; iter: 0; batch classifier loss: 0.140373; batch adversarial loss: 0.430825\n",
      "epoch 57; iter: 0; batch classifier loss: 0.250870; batch adversarial loss: 0.369353\n",
      "epoch 58; iter: 0; batch classifier loss: 0.126813; batch adversarial loss: 0.454303\n",
      "epoch 59; iter: 0; batch classifier loss: 0.130108; batch adversarial loss: 0.387517\n",
      "epoch 60; iter: 0; batch classifier loss: 0.153562; batch adversarial loss: 0.537540\n",
      "epoch 61; iter: 0; batch classifier loss: 0.247876; batch adversarial loss: 0.446617\n",
      "epoch 62; iter: 0; batch classifier loss: 0.169524; batch adversarial loss: 0.395992\n",
      "epoch 63; iter: 0; batch classifier loss: 0.255286; batch adversarial loss: 0.412049\n",
      "epoch 64; iter: 0; batch classifier loss: 0.188712; batch adversarial loss: 0.501555\n",
      "epoch 65; iter: 0; batch classifier loss: 0.220023; batch adversarial loss: 0.456473\n",
      "epoch 66; iter: 0; batch classifier loss: 0.186540; batch adversarial loss: 0.484246\n",
      "epoch 67; iter: 0; batch classifier loss: 0.186605; batch adversarial loss: 0.448778\n",
      "epoch 68; iter: 0; batch classifier loss: 0.127086; batch adversarial loss: 0.445957\n",
      "epoch 69; iter: 0; batch classifier loss: 0.205114; batch adversarial loss: 0.473054\n",
      "epoch 70; iter: 0; batch classifier loss: 0.209289; batch adversarial loss: 0.564027\n",
      "epoch 71; iter: 0; batch classifier loss: 0.233975; batch adversarial loss: 0.532123\n",
      "epoch 72; iter: 0; batch classifier loss: 0.187551; batch adversarial loss: 0.410503\n",
      "epoch 73; iter: 0; batch classifier loss: 0.198741; batch adversarial loss: 0.487655\n",
      "epoch 74; iter: 0; batch classifier loss: 0.135127; batch adversarial loss: 0.455617\n",
      "epoch 75; iter: 0; batch classifier loss: 0.199180; batch adversarial loss: 0.396660\n",
      "epoch 76; iter: 0; batch classifier loss: 0.166774; batch adversarial loss: 0.458641\n",
      "epoch 77; iter: 0; batch classifier loss: 0.252871; batch adversarial loss: 0.399400\n",
      "epoch 78; iter: 0; batch classifier loss: 0.204119; batch adversarial loss: 0.435011\n",
      "epoch 79; iter: 0; batch classifier loss: 0.184431; batch adversarial loss: 0.520961\n",
      "epoch 80; iter: 0; batch classifier loss: 0.273915; batch adversarial loss: 0.383935\n",
      "epoch 81; iter: 0; batch classifier loss: 0.169518; batch adversarial loss: 0.457367\n",
      "epoch 82; iter: 0; batch classifier loss: 0.241319; batch adversarial loss: 0.481994\n",
      "epoch 83; iter: 0; batch classifier loss: 0.283845; batch adversarial loss: 0.422472\n",
      "epoch 84; iter: 0; batch classifier loss: 0.203741; batch adversarial loss: 0.384872\n",
      "epoch 85; iter: 0; batch classifier loss: 0.154150; batch adversarial loss: 0.409407\n",
      "epoch 86; iter: 0; batch classifier loss: 0.224690; batch adversarial loss: 0.336261\n",
      "epoch 87; iter: 0; batch classifier loss: 0.227200; batch adversarial loss: 0.496104\n",
      "epoch 88; iter: 0; batch classifier loss: 0.157505; batch adversarial loss: 0.397626\n",
      "epoch 89; iter: 0; batch classifier loss: 0.242339; batch adversarial loss: 0.446485\n",
      "epoch 90; iter: 0; batch classifier loss: 0.089438; batch adversarial loss: 0.470864\n",
      "epoch 91; iter: 0; batch classifier loss: 0.086780; batch adversarial loss: 0.407603\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069018; batch adversarial loss: 0.457501\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069415; batch adversarial loss: 0.380099\n",
      "epoch 94; iter: 0; batch classifier loss: 0.080156; batch adversarial loss: 0.419093\n",
      "epoch 95; iter: 0; batch classifier loss: 0.138074; batch adversarial loss: 0.517678\n",
      "epoch 96; iter: 0; batch classifier loss: 0.106079; batch adversarial loss: 0.352559\n",
      "epoch 97; iter: 0; batch classifier loss: 0.107282; batch adversarial loss: 0.433195\n",
      "epoch 98; iter: 0; batch classifier loss: 0.094945; batch adversarial loss: 0.496158\n",
      "epoch 99; iter: 0; batch classifier loss: 0.114029; batch adversarial loss: 0.462453\n",
      "epoch 100; iter: 0; batch classifier loss: 0.095577; batch adversarial loss: 0.458739\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083706; batch adversarial loss: 0.407703\n",
      "epoch 102; iter: 0; batch classifier loss: 0.073045; batch adversarial loss: 0.390268\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054030; batch adversarial loss: 0.549411\n",
      "epoch 104; iter: 0; batch classifier loss: 0.093354; batch adversarial loss: 0.416874\n",
      "epoch 105; iter: 0; batch classifier loss: 0.097433; batch adversarial loss: 0.399546\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052097; batch adversarial loss: 0.448622\n",
      "epoch 107; iter: 0; batch classifier loss: 0.067552; batch adversarial loss: 0.450814\n",
      "epoch 108; iter: 0; batch classifier loss: 0.082086; batch adversarial loss: 0.495724\n",
      "epoch 109; iter: 0; batch classifier loss: 0.103692; batch adversarial loss: 0.503546\n",
      "epoch 110; iter: 0; batch classifier loss: 0.082649; batch adversarial loss: 0.365662\n",
      "epoch 111; iter: 0; batch classifier loss: 0.065953; batch adversarial loss: 0.488633\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056408; batch adversarial loss: 0.499536\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035657; batch adversarial loss: 0.550537\n",
      "epoch 114; iter: 0; batch classifier loss: 0.073066; batch adversarial loss: 0.433016\n",
      "epoch 115; iter: 0; batch classifier loss: 0.074967; batch adversarial loss: 0.350824\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046544; batch adversarial loss: 0.376314\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056363; batch adversarial loss: 0.424941\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040050; batch adversarial loss: 0.476985\n",
      "epoch 119; iter: 0; batch classifier loss: 0.090509; batch adversarial loss: 0.500826\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053909; batch adversarial loss: 0.411671\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037774; batch adversarial loss: 0.454170\n",
      "epoch 122; iter: 0; batch classifier loss: 0.054726; batch adversarial loss: 0.412442\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067607; batch adversarial loss: 0.347392\n",
      "epoch 124; iter: 0; batch classifier loss: 0.071499; batch adversarial loss: 0.403234\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054427; batch adversarial loss: 0.485149\n",
      "epoch 126; iter: 0; batch classifier loss: 0.061109; batch adversarial loss: 0.431315\n",
      "epoch 127; iter: 0; batch classifier loss: 0.071106; batch adversarial loss: 0.494707\n",
      "epoch 128; iter: 0; batch classifier loss: 0.057350; batch adversarial loss: 0.397589\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022773; batch adversarial loss: 0.388790\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046789; batch adversarial loss: 0.449506\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034826; batch adversarial loss: 0.568002\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043416; batch adversarial loss: 0.474766\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024234; batch adversarial loss: 0.541718\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033728; batch adversarial loss: 0.443053\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023302; batch adversarial loss: 0.405084\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020735; batch adversarial loss: 0.464317\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036680; batch adversarial loss: 0.470055\n",
      "epoch 138; iter: 0; batch classifier loss: 0.059897; batch adversarial loss: 0.367305\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049161; batch adversarial loss: 0.335413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.024638; batch adversarial loss: 0.419237\n",
      "epoch 141; iter: 0; batch classifier loss: 0.051318; batch adversarial loss: 0.488443\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041050; batch adversarial loss: 0.458220\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022883; batch adversarial loss: 0.518504\n",
      "epoch 144; iter: 0; batch classifier loss: 0.066725; batch adversarial loss: 0.437318\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021363; batch adversarial loss: 0.475384\n",
      "epoch 146; iter: 0; batch classifier loss: 0.056699; batch adversarial loss: 0.504079\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021160; batch adversarial loss: 0.417611\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018836; batch adversarial loss: 0.459145\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019901; batch adversarial loss: 0.403467\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041773; batch adversarial loss: 0.543171\n",
      "epoch 151; iter: 0; batch classifier loss: 0.052451; batch adversarial loss: 0.377463\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036735; batch adversarial loss: 0.486991\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048366; batch adversarial loss: 0.471345\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028594; batch adversarial loss: 0.383223\n",
      "epoch 155; iter: 0; batch classifier loss: 0.047242; batch adversarial loss: 0.427465\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035137; batch adversarial loss: 0.464286\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026656; batch adversarial loss: 0.563294\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030759; batch adversarial loss: 0.533064\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039001; batch adversarial loss: 0.467652\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031492; batch adversarial loss: 0.434451\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020044; batch adversarial loss: 0.410273\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032532; batch adversarial loss: 0.408374\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045427; batch adversarial loss: 0.389960\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038645; batch adversarial loss: 0.406919\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011015; batch adversarial loss: 0.541743\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027597; batch adversarial loss: 0.468161\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016687; batch adversarial loss: 0.501465\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020537; batch adversarial loss: 0.518075\n",
      "epoch 169; iter: 0; batch classifier loss: 0.072472; batch adversarial loss: 0.457783\n",
      "epoch 170; iter: 0; batch classifier loss: 0.051646; batch adversarial loss: 0.456109\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010736; batch adversarial loss: 0.460892\n",
      "epoch 172; iter: 0; batch classifier loss: 0.046575; batch adversarial loss: 0.438302\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019677; batch adversarial loss: 0.401862\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008041; batch adversarial loss: 0.466790\n",
      "epoch 175; iter: 0; batch classifier loss: 0.044908; batch adversarial loss: 0.488998\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027159; batch adversarial loss: 0.432980\n",
      "epoch 177; iter: 0; batch classifier loss: 0.047133; batch adversarial loss: 0.464998\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026578; batch adversarial loss: 0.440303\n",
      "epoch 179; iter: 0; batch classifier loss: 0.042922; batch adversarial loss: 0.459114\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037802; batch adversarial loss: 0.384890\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012195; batch adversarial loss: 0.448780\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017543; batch adversarial loss: 0.526141\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016656; batch adversarial loss: 0.379168\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024205; batch adversarial loss: 0.348950\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033818; batch adversarial loss: 0.506372\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015128; batch adversarial loss: 0.435065\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015858; batch adversarial loss: 0.343783\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041971; batch adversarial loss: 0.431592\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017383; batch adversarial loss: 0.426322\n",
      "epoch 190; iter: 0; batch classifier loss: 0.003946; batch adversarial loss: 0.511782\n",
      "epoch 191; iter: 0; batch classifier loss: 0.051561; batch adversarial loss: 0.498984\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033860; batch adversarial loss: 0.429404\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010667; batch adversarial loss: 0.506528\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017290; batch adversarial loss: 0.466393\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031940; batch adversarial loss: 0.423242\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028315; batch adversarial loss: 0.420264\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020047; batch adversarial loss: 0.428524\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025547; batch adversarial loss: 0.407655\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008764; batch adversarial loss: 0.493082\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699065; batch adversarial loss: 0.541749\n",
      "epoch 1; iter: 0; batch classifier loss: 0.440534; batch adversarial loss: 0.626846\n",
      "epoch 2; iter: 0; batch classifier loss: 0.393856; batch adversarial loss: 0.561593\n",
      "epoch 3; iter: 0; batch classifier loss: 0.364666; batch adversarial loss: 0.591276\n",
      "epoch 4; iter: 0; batch classifier loss: 0.398146; batch adversarial loss: 0.621577\n",
      "epoch 5; iter: 0; batch classifier loss: 0.357234; batch adversarial loss: 0.574063\n",
      "epoch 6; iter: 0; batch classifier loss: 0.347130; batch adversarial loss: 0.572696\n",
      "epoch 7; iter: 0; batch classifier loss: 0.365989; batch adversarial loss: 0.551003\n",
      "epoch 8; iter: 0; batch classifier loss: 0.361165; batch adversarial loss: 0.594305\n",
      "epoch 9; iter: 0; batch classifier loss: 0.323018; batch adversarial loss: 0.556666\n",
      "epoch 10; iter: 0; batch classifier loss: 0.388282; batch adversarial loss: 0.545075\n",
      "epoch 11; iter: 0; batch classifier loss: 0.341510; batch adversarial loss: 0.539340\n",
      "epoch 12; iter: 0; batch classifier loss: 0.375223; batch adversarial loss: 0.526251\n",
      "epoch 13; iter: 0; batch classifier loss: 0.398462; batch adversarial loss: 0.522510\n",
      "epoch 14; iter: 0; batch classifier loss: 0.474826; batch adversarial loss: 0.474707\n",
      "epoch 15; iter: 0; batch classifier loss: 0.624702; batch adversarial loss: 0.511939\n",
      "epoch 16; iter: 0; batch classifier loss: 0.639621; batch adversarial loss: 0.468577\n",
      "epoch 17; iter: 0; batch classifier loss: 0.326505; batch adversarial loss: 0.432049\n",
      "epoch 18; iter: 0; batch classifier loss: 0.312245; batch adversarial loss: 0.429641\n",
      "epoch 19; iter: 0; batch classifier loss: 0.241776; batch adversarial loss: 0.434400\n",
      "epoch 20; iter: 0; batch classifier loss: 0.214000; batch adversarial loss: 0.418510\n",
      "epoch 21; iter: 0; batch classifier loss: 0.224389; batch adversarial loss: 0.468659\n",
      "epoch 22; iter: 0; batch classifier loss: 0.171276; batch adversarial loss: 0.523766\n",
      "epoch 23; iter: 0; batch classifier loss: 0.180290; batch adversarial loss: 0.477122\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192318; batch adversarial loss: 0.437019\n",
      "epoch 25; iter: 0; batch classifier loss: 0.166232; batch adversarial loss: 0.507300\n",
      "epoch 26; iter: 0; batch classifier loss: 0.168211; batch adversarial loss: 0.381745\n",
      "epoch 27; iter: 0; batch classifier loss: 0.219441; batch adversarial loss: 0.361787\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185998; batch adversarial loss: 0.430874\n",
      "epoch 29; iter: 0; batch classifier loss: 0.191353; batch adversarial loss: 0.424523\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151757; batch adversarial loss: 0.513138\n",
      "epoch 31; iter: 0; batch classifier loss: 0.150950; batch adversarial loss: 0.423008\n",
      "epoch 32; iter: 0; batch classifier loss: 0.173365; batch adversarial loss: 0.462066\n",
      "epoch 33; iter: 0; batch classifier loss: 0.176233; batch adversarial loss: 0.371070\n",
      "epoch 34; iter: 0; batch classifier loss: 0.165251; batch adversarial loss: 0.573965\n",
      "epoch 35; iter: 0; batch classifier loss: 0.213553; batch adversarial loss: 0.359119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.218093; batch adversarial loss: 0.368319\n",
      "epoch 37; iter: 0; batch classifier loss: 0.096904; batch adversarial loss: 0.412579\n",
      "epoch 38; iter: 0; batch classifier loss: 0.124023; batch adversarial loss: 0.507603\n",
      "epoch 39; iter: 0; batch classifier loss: 0.146272; batch adversarial loss: 0.486590\n",
      "epoch 40; iter: 0; batch classifier loss: 0.105568; batch adversarial loss: 0.435399\n",
      "epoch 41; iter: 0; batch classifier loss: 0.118714; batch adversarial loss: 0.425862\n",
      "epoch 42; iter: 0; batch classifier loss: 0.114667; batch adversarial loss: 0.431549\n",
      "epoch 43; iter: 0; batch classifier loss: 0.168275; batch adversarial loss: 0.450107\n",
      "epoch 44; iter: 0; batch classifier loss: 0.149371; batch adversarial loss: 0.526047\n",
      "epoch 45; iter: 0; batch classifier loss: 0.119554; batch adversarial loss: 0.431563\n",
      "epoch 46; iter: 0; batch classifier loss: 0.144992; batch adversarial loss: 0.435288\n",
      "epoch 47; iter: 0; batch classifier loss: 0.170725; batch adversarial loss: 0.391235\n",
      "epoch 48; iter: 0; batch classifier loss: 0.098292; batch adversarial loss: 0.480145\n",
      "epoch 49; iter: 0; batch classifier loss: 0.085766; batch adversarial loss: 0.467928\n",
      "epoch 50; iter: 0; batch classifier loss: 0.135663; batch adversarial loss: 0.473465\n",
      "epoch 51; iter: 0; batch classifier loss: 0.118951; batch adversarial loss: 0.476266\n",
      "epoch 52; iter: 0; batch classifier loss: 0.137835; batch adversarial loss: 0.534971\n",
      "epoch 53; iter: 0; batch classifier loss: 0.129826; batch adversarial loss: 0.388700\n",
      "epoch 54; iter: 0; batch classifier loss: 0.159709; batch adversarial loss: 0.455783\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117425; batch adversarial loss: 0.501675\n",
      "epoch 56; iter: 0; batch classifier loss: 0.128854; batch adversarial loss: 0.416349\n",
      "epoch 57; iter: 0; batch classifier loss: 0.136628; batch adversarial loss: 0.521567\n",
      "epoch 58; iter: 0; batch classifier loss: 0.102387; batch adversarial loss: 0.369682\n",
      "epoch 59; iter: 0; batch classifier loss: 0.104802; batch adversarial loss: 0.364000\n",
      "epoch 60; iter: 0; batch classifier loss: 0.098181; batch adversarial loss: 0.576944\n",
      "epoch 61; iter: 0; batch classifier loss: 0.115128; batch adversarial loss: 0.467930\n",
      "epoch 62; iter: 0; batch classifier loss: 0.072757; batch adversarial loss: 0.534190\n",
      "epoch 63; iter: 0; batch classifier loss: 0.121168; batch adversarial loss: 0.452150\n",
      "epoch 64; iter: 0; batch classifier loss: 0.147964; batch adversarial loss: 0.441206\n",
      "epoch 65; iter: 0; batch classifier loss: 0.142803; batch adversarial loss: 0.390904\n",
      "epoch 66; iter: 0; batch classifier loss: 0.128820; batch adversarial loss: 0.449819\n",
      "epoch 67; iter: 0; batch classifier loss: 0.164299; batch adversarial loss: 0.327474\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059466; batch adversarial loss: 0.459378\n",
      "epoch 69; iter: 0; batch classifier loss: 0.100914; batch adversarial loss: 0.458597\n",
      "epoch 70; iter: 0; batch classifier loss: 0.071769; batch adversarial loss: 0.447631\n",
      "epoch 71; iter: 0; batch classifier loss: 0.159943; batch adversarial loss: 0.456219\n",
      "epoch 72; iter: 0; batch classifier loss: 0.170096; batch adversarial loss: 0.481043\n",
      "epoch 73; iter: 0; batch classifier loss: 0.140842; batch adversarial loss: 0.521971\n",
      "epoch 74; iter: 0; batch classifier loss: 0.083594; batch adversarial loss: 0.419017\n",
      "epoch 75; iter: 0; batch classifier loss: 0.138413; batch adversarial loss: 0.518293\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103524; batch adversarial loss: 0.444337\n",
      "epoch 77; iter: 0; batch classifier loss: 0.081334; batch adversarial loss: 0.470551\n",
      "epoch 78; iter: 0; batch classifier loss: 0.096439; batch adversarial loss: 0.445344\n",
      "epoch 79; iter: 0; batch classifier loss: 0.118617; batch adversarial loss: 0.500798\n",
      "epoch 80; iter: 0; batch classifier loss: 0.099482; batch adversarial loss: 0.399808\n",
      "epoch 81; iter: 0; batch classifier loss: 0.142705; batch adversarial loss: 0.482432\n",
      "epoch 82; iter: 0; batch classifier loss: 0.107841; batch adversarial loss: 0.449736\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081068; batch adversarial loss: 0.465397\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080650; batch adversarial loss: 0.479089\n",
      "epoch 85; iter: 0; batch classifier loss: 0.094614; batch adversarial loss: 0.398477\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067846; batch adversarial loss: 0.555109\n",
      "epoch 87; iter: 0; batch classifier loss: 0.074410; batch adversarial loss: 0.474447\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070888; batch adversarial loss: 0.461092\n",
      "epoch 89; iter: 0; batch classifier loss: 0.094752; batch adversarial loss: 0.534333\n",
      "epoch 90; iter: 0; batch classifier loss: 0.090726; batch adversarial loss: 0.374283\n",
      "epoch 91; iter: 0; batch classifier loss: 0.102590; batch adversarial loss: 0.485922\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060329; batch adversarial loss: 0.477082\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072512; batch adversarial loss: 0.386895\n",
      "epoch 94; iter: 0; batch classifier loss: 0.069266; batch adversarial loss: 0.461317\n",
      "epoch 95; iter: 0; batch classifier loss: 0.089408; batch adversarial loss: 0.426870\n",
      "epoch 96; iter: 0; batch classifier loss: 0.097772; batch adversarial loss: 0.418029\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053070; batch adversarial loss: 0.448486\n",
      "epoch 98; iter: 0; batch classifier loss: 0.037778; batch adversarial loss: 0.449327\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061646; batch adversarial loss: 0.448439\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053485; batch adversarial loss: 0.448116\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054978; batch adversarial loss: 0.428004\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078518; batch adversarial loss: 0.511319\n",
      "epoch 103; iter: 0; batch classifier loss: 0.028005; batch adversarial loss: 0.479996\n",
      "epoch 104; iter: 0; batch classifier loss: 0.090557; batch adversarial loss: 0.433767\n",
      "epoch 105; iter: 0; batch classifier loss: 0.078161; batch adversarial loss: 0.554656\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068859; batch adversarial loss: 0.499819\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037920; batch adversarial loss: 0.490585\n",
      "epoch 108; iter: 0; batch classifier loss: 0.083962; batch adversarial loss: 0.416437\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053660; batch adversarial loss: 0.429420\n",
      "epoch 110; iter: 0; batch classifier loss: 0.029769; batch adversarial loss: 0.454696\n",
      "epoch 111; iter: 0; batch classifier loss: 0.072534; batch adversarial loss: 0.509395\n",
      "epoch 112; iter: 0; batch classifier loss: 0.084231; batch adversarial loss: 0.348852\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046039; batch adversarial loss: 0.386298\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054828; batch adversarial loss: 0.406109\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063574; batch adversarial loss: 0.559918\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046174; batch adversarial loss: 0.430408\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043845; batch adversarial loss: 0.470579\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030823; batch adversarial loss: 0.424418\n",
      "epoch 119; iter: 0; batch classifier loss: 0.028503; batch adversarial loss: 0.397557\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028711; batch adversarial loss: 0.448667\n",
      "epoch 121; iter: 0; batch classifier loss: 0.076670; batch adversarial loss: 0.445176\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050934; batch adversarial loss: 0.373951\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029757; batch adversarial loss: 0.384393\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036003; batch adversarial loss: 0.410379\n",
      "epoch 125; iter: 0; batch classifier loss: 0.012387; batch adversarial loss: 0.462980\n",
      "epoch 126; iter: 0; batch classifier loss: 0.073697; batch adversarial loss: 0.386034\n",
      "epoch 127; iter: 0; batch classifier loss: 0.080542; batch adversarial loss: 0.409429\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058065; batch adversarial loss: 0.470648\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046708; batch adversarial loss: 0.432260\n",
      "epoch 130; iter: 0; batch classifier loss: 0.094504; batch adversarial loss: 0.380186\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038439; batch adversarial loss: 0.509355\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026441; batch adversarial loss: 0.420243\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036013; batch adversarial loss: 0.429934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.040463; batch adversarial loss: 0.433966\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047256; batch adversarial loss: 0.483887\n",
      "epoch 136; iter: 0; batch classifier loss: 0.070082; batch adversarial loss: 0.429912\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045139; batch adversarial loss: 0.403836\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029392; batch adversarial loss: 0.489615\n",
      "epoch 139; iter: 0; batch classifier loss: 0.066018; batch adversarial loss: 0.450943\n",
      "epoch 140; iter: 0; batch classifier loss: 0.087101; batch adversarial loss: 0.460468\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036411; batch adversarial loss: 0.467538\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036660; batch adversarial loss: 0.519000\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043391; batch adversarial loss: 0.423086\n",
      "epoch 144; iter: 0; batch classifier loss: 0.042613; batch adversarial loss: 0.398787\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045493; batch adversarial loss: 0.457633\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037903; batch adversarial loss: 0.432995\n",
      "epoch 147; iter: 0; batch classifier loss: 0.055211; batch adversarial loss: 0.410694\n",
      "epoch 148; iter: 0; batch classifier loss: 0.010117; batch adversarial loss: 0.401245\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011608; batch adversarial loss: 0.503878\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025213; batch adversarial loss: 0.351278\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022007; batch adversarial loss: 0.509741\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033738; batch adversarial loss: 0.443946\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027186; batch adversarial loss: 0.419174\n",
      "epoch 154; iter: 0; batch classifier loss: 0.072721; batch adversarial loss: 0.487896\n",
      "epoch 155; iter: 0; batch classifier loss: 0.078780; batch adversarial loss: 0.381192\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019173; batch adversarial loss: 0.462433\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038614; batch adversarial loss: 0.498678\n",
      "epoch 158; iter: 0; batch classifier loss: 0.065821; batch adversarial loss: 0.450959\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045842; batch adversarial loss: 0.439958\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016551; batch adversarial loss: 0.475290\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025748; batch adversarial loss: 0.375166\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031828; batch adversarial loss: 0.425782\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035966; batch adversarial loss: 0.456062\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032559; batch adversarial loss: 0.479969\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018301; batch adversarial loss: 0.487662\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022011; batch adversarial loss: 0.504964\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012681; batch adversarial loss: 0.429021\n",
      "epoch 168; iter: 0; batch classifier loss: 0.044599; batch adversarial loss: 0.458875\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012354; batch adversarial loss: 0.475669\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022150; batch adversarial loss: 0.510969\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005113; batch adversarial loss: 0.387671\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026725; batch adversarial loss: 0.380511\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007884; batch adversarial loss: 0.356617\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026071; batch adversarial loss: 0.500621\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029072; batch adversarial loss: 0.376789\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010827; batch adversarial loss: 0.516731\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027625; batch adversarial loss: 0.418274\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010102; batch adversarial loss: 0.385127\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018962; batch adversarial loss: 0.409495\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017924; batch adversarial loss: 0.478683\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021111; batch adversarial loss: 0.418697\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018974; batch adversarial loss: 0.483608\n",
      "epoch 183; iter: 0; batch classifier loss: 0.043657; batch adversarial loss: 0.359569\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021853; batch adversarial loss: 0.448566\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026463; batch adversarial loss: 0.473867\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033917; batch adversarial loss: 0.416969\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005803; batch adversarial loss: 0.466037\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041424; batch adversarial loss: 0.460280\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033425; batch adversarial loss: 0.449509\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031267; batch adversarial loss: 0.401756\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019241; batch adversarial loss: 0.367755\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022081; batch adversarial loss: 0.414865\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025452; batch adversarial loss: 0.598754\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006224; batch adversarial loss: 0.518041\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013393; batch adversarial loss: 0.507416\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007305; batch adversarial loss: 0.421375\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012891; batch adversarial loss: 0.431886\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031319; batch adversarial loss: 0.411349\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019841; batch adversarial loss: 0.398088\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690681; batch adversarial loss: 0.657823\n",
      "epoch 1; iter: 0; batch classifier loss: 0.560712; batch adversarial loss: 0.631833\n",
      "epoch 2; iter: 0; batch classifier loss: 0.389193; batch adversarial loss: 0.658141\n",
      "epoch 3; iter: 0; batch classifier loss: 0.420471; batch adversarial loss: 0.629112\n",
      "epoch 4; iter: 0; batch classifier loss: 0.360880; batch adversarial loss: 0.589298\n",
      "epoch 5; iter: 0; batch classifier loss: 0.331367; batch adversarial loss: 0.601495\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331430; batch adversarial loss: 0.536113\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306359; batch adversarial loss: 0.531167\n",
      "epoch 8; iter: 0; batch classifier loss: 0.227252; batch adversarial loss: 0.515298\n",
      "epoch 9; iter: 0; batch classifier loss: 0.285360; batch adversarial loss: 0.514029\n",
      "epoch 10; iter: 0; batch classifier loss: 0.245957; batch adversarial loss: 0.537482\n",
      "epoch 11; iter: 0; batch classifier loss: 0.257568; batch adversarial loss: 0.478625\n",
      "epoch 12; iter: 0; batch classifier loss: 0.327744; batch adversarial loss: 0.468913\n",
      "epoch 13; iter: 0; batch classifier loss: 0.282763; batch adversarial loss: 0.640218\n",
      "epoch 14; iter: 0; batch classifier loss: 0.307070; batch adversarial loss: 0.418138\n",
      "epoch 15; iter: 0; batch classifier loss: 0.298239; batch adversarial loss: 0.573321\n",
      "epoch 16; iter: 0; batch classifier loss: 0.217063; batch adversarial loss: 0.463241\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221016; batch adversarial loss: 0.537835\n",
      "epoch 18; iter: 0; batch classifier loss: 0.249641; batch adversarial loss: 0.562050\n",
      "epoch 19; iter: 0; batch classifier loss: 0.186475; batch adversarial loss: 0.493800\n",
      "epoch 20; iter: 0; batch classifier loss: 0.179213; batch adversarial loss: 0.505764\n",
      "epoch 21; iter: 0; batch classifier loss: 0.161653; batch adversarial loss: 0.445859\n",
      "epoch 22; iter: 0; batch classifier loss: 0.244435; batch adversarial loss: 0.416323\n",
      "epoch 23; iter: 0; batch classifier loss: 0.182033; batch adversarial loss: 0.536228\n",
      "epoch 24; iter: 0; batch classifier loss: 0.204225; batch adversarial loss: 0.537617\n",
      "epoch 25; iter: 0; batch classifier loss: 0.130526; batch adversarial loss: 0.503231\n",
      "epoch 26; iter: 0; batch classifier loss: 0.121387; batch adversarial loss: 0.491421\n",
      "epoch 27; iter: 0; batch classifier loss: 0.116742; batch adversarial loss: 0.473569\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169626; batch adversarial loss: 0.470996\n",
      "epoch 29; iter: 0; batch classifier loss: 0.160827; batch adversarial loss: 0.453182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.145488; batch adversarial loss: 0.462759\n",
      "epoch 31; iter: 0; batch classifier loss: 0.160619; batch adversarial loss: 0.457154\n",
      "epoch 32; iter: 0; batch classifier loss: 0.125053; batch adversarial loss: 0.477335\n",
      "epoch 33; iter: 0; batch classifier loss: 0.129646; batch adversarial loss: 0.519267\n",
      "epoch 34; iter: 0; batch classifier loss: 0.175035; batch adversarial loss: 0.423343\n",
      "epoch 35; iter: 0; batch classifier loss: 0.165770; batch adversarial loss: 0.484673\n",
      "epoch 36; iter: 0; batch classifier loss: 0.088783; batch adversarial loss: 0.500463\n",
      "epoch 37; iter: 0; batch classifier loss: 0.146590; batch adversarial loss: 0.451596\n",
      "epoch 38; iter: 0; batch classifier loss: 0.131435; batch adversarial loss: 0.435445\n",
      "epoch 39; iter: 0; batch classifier loss: 0.160750; batch adversarial loss: 0.444951\n",
      "epoch 40; iter: 0; batch classifier loss: 0.097752; batch adversarial loss: 0.459637\n",
      "epoch 41; iter: 0; batch classifier loss: 0.141697; batch adversarial loss: 0.489650\n",
      "epoch 42; iter: 0; batch classifier loss: 0.124900; batch adversarial loss: 0.450587\n",
      "epoch 43; iter: 0; batch classifier loss: 0.176908; batch adversarial loss: 0.563997\n",
      "epoch 44; iter: 0; batch classifier loss: 0.179642; batch adversarial loss: 0.446518\n",
      "epoch 45; iter: 0; batch classifier loss: 0.118097; batch adversarial loss: 0.509831\n",
      "epoch 46; iter: 0; batch classifier loss: 0.115357; batch adversarial loss: 0.464624\n",
      "epoch 47; iter: 0; batch classifier loss: 0.128057; batch adversarial loss: 0.478240\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099168; batch adversarial loss: 0.484702\n",
      "epoch 49; iter: 0; batch classifier loss: 0.090450; batch adversarial loss: 0.448096\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111729; batch adversarial loss: 0.544900\n",
      "epoch 51; iter: 0; batch classifier loss: 0.138030; batch adversarial loss: 0.489520\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093147; batch adversarial loss: 0.387308\n",
      "epoch 53; iter: 0; batch classifier loss: 0.106824; batch adversarial loss: 0.386876\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090575; batch adversarial loss: 0.450725\n",
      "epoch 55; iter: 0; batch classifier loss: 0.141778; batch adversarial loss: 0.483120\n",
      "epoch 56; iter: 0; batch classifier loss: 0.107808; batch adversarial loss: 0.451756\n",
      "epoch 57; iter: 0; batch classifier loss: 0.128125; batch adversarial loss: 0.431112\n",
      "epoch 58; iter: 0; batch classifier loss: 0.076390; batch adversarial loss: 0.450686\n",
      "epoch 59; iter: 0; batch classifier loss: 0.124649; batch adversarial loss: 0.534396\n",
      "epoch 60; iter: 0; batch classifier loss: 0.125391; batch adversarial loss: 0.443438\n",
      "epoch 61; iter: 0; batch classifier loss: 0.098921; batch adversarial loss: 0.461132\n",
      "epoch 62; iter: 0; batch classifier loss: 0.152474; batch adversarial loss: 0.479481\n",
      "epoch 63; iter: 0; batch classifier loss: 0.054439; batch adversarial loss: 0.479666\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101361; batch adversarial loss: 0.417906\n",
      "epoch 65; iter: 0; batch classifier loss: 0.101171; batch adversarial loss: 0.471659\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070987; batch adversarial loss: 0.497625\n",
      "epoch 67; iter: 0; batch classifier loss: 0.108603; batch adversarial loss: 0.481614\n",
      "epoch 68; iter: 0; batch classifier loss: 0.150816; batch adversarial loss: 0.453178\n",
      "epoch 69; iter: 0; batch classifier loss: 0.110878; batch adversarial loss: 0.474234\n",
      "epoch 70; iter: 0; batch classifier loss: 0.083693; batch adversarial loss: 0.418123\n",
      "epoch 71; iter: 0; batch classifier loss: 0.070222; batch adversarial loss: 0.436852\n",
      "epoch 72; iter: 0; batch classifier loss: 0.086973; batch adversarial loss: 0.502285\n",
      "epoch 73; iter: 0; batch classifier loss: 0.050122; batch adversarial loss: 0.494439\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075745; batch adversarial loss: 0.433279\n",
      "epoch 75; iter: 0; batch classifier loss: 0.058597; batch adversarial loss: 0.500351\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072575; batch adversarial loss: 0.342629\n",
      "epoch 77; iter: 0; batch classifier loss: 0.072061; batch adversarial loss: 0.353393\n",
      "epoch 78; iter: 0; batch classifier loss: 0.048721; batch adversarial loss: 0.396814\n",
      "epoch 79; iter: 0; batch classifier loss: 0.047715; batch adversarial loss: 0.424007\n",
      "epoch 80; iter: 0; batch classifier loss: 0.069847; batch adversarial loss: 0.448763\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055930; batch adversarial loss: 0.439977\n",
      "epoch 82; iter: 0; batch classifier loss: 0.082939; batch adversarial loss: 0.512055\n",
      "epoch 83; iter: 0; batch classifier loss: 0.060069; batch adversarial loss: 0.407239\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046412; batch adversarial loss: 0.469239\n",
      "epoch 85; iter: 0; batch classifier loss: 0.054745; batch adversarial loss: 0.511491\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058110; batch adversarial loss: 0.448018\n",
      "epoch 87; iter: 0; batch classifier loss: 0.084189; batch adversarial loss: 0.431506\n",
      "epoch 88; iter: 0; batch classifier loss: 0.100170; batch adversarial loss: 0.433171\n",
      "epoch 89; iter: 0; batch classifier loss: 0.028082; batch adversarial loss: 0.418064\n",
      "epoch 90; iter: 0; batch classifier loss: 0.086759; batch adversarial loss: 0.477997\n",
      "epoch 91; iter: 0; batch classifier loss: 0.069217; batch adversarial loss: 0.517851\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041725; batch adversarial loss: 0.416022\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052603; batch adversarial loss: 0.473741\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061867; batch adversarial loss: 0.339082\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077350; batch adversarial loss: 0.511899\n",
      "epoch 96; iter: 0; batch classifier loss: 0.021449; batch adversarial loss: 0.530563\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065515; batch adversarial loss: 0.342718\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063946; batch adversarial loss: 0.569610\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045737; batch adversarial loss: 0.418084\n",
      "epoch 100; iter: 0; batch classifier loss: 0.052334; batch adversarial loss: 0.489137\n",
      "epoch 101; iter: 0; batch classifier loss: 0.034582; batch adversarial loss: 0.484274\n",
      "epoch 102; iter: 0; batch classifier loss: 0.023293; batch adversarial loss: 0.509742\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040825; batch adversarial loss: 0.516766\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058283; batch adversarial loss: 0.464231\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043666; batch adversarial loss: 0.450220\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034746; batch adversarial loss: 0.513273\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055930; batch adversarial loss: 0.506937\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031165; batch adversarial loss: 0.516818\n",
      "epoch 109; iter: 0; batch classifier loss: 0.022151; batch adversarial loss: 0.431175\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052555; batch adversarial loss: 0.482110\n",
      "epoch 111; iter: 0; batch classifier loss: 0.019083; batch adversarial loss: 0.419029\n",
      "epoch 112; iter: 0; batch classifier loss: 0.019967; batch adversarial loss: 0.464860\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053902; batch adversarial loss: 0.434478\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051824; batch adversarial loss: 0.504692\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032635; batch adversarial loss: 0.475074\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043280; batch adversarial loss: 0.416018\n",
      "epoch 117; iter: 0; batch classifier loss: 0.080308; batch adversarial loss: 0.456452\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033878; batch adversarial loss: 0.441727\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020546; batch adversarial loss: 0.432277\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045066; batch adversarial loss: 0.568092\n",
      "epoch 121; iter: 0; batch classifier loss: 0.013081; batch adversarial loss: 0.480036\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031665; batch adversarial loss: 0.417429\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041146; batch adversarial loss: 0.428543\n",
      "epoch 124; iter: 0; batch classifier loss: 0.061761; batch adversarial loss: 0.418708\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029513; batch adversarial loss: 0.444187\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029001; batch adversarial loss: 0.494123\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032034; batch adversarial loss: 0.365224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.022249; batch adversarial loss: 0.479558\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059231; batch adversarial loss: 0.460551\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039802; batch adversarial loss: 0.426536\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041995; batch adversarial loss: 0.391162\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028175; batch adversarial loss: 0.471428\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020886; batch adversarial loss: 0.456546\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024460; batch adversarial loss: 0.430765\n",
      "epoch 135; iter: 0; batch classifier loss: 0.009999; batch adversarial loss: 0.458431\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017522; batch adversarial loss: 0.428360\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015484; batch adversarial loss: 0.446019\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045439; batch adversarial loss: 0.449416\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023269; batch adversarial loss: 0.457315\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034041; batch adversarial loss: 0.426977\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043492; batch adversarial loss: 0.473270\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028185; batch adversarial loss: 0.593836\n",
      "epoch 143; iter: 0; batch classifier loss: 0.088857; batch adversarial loss: 0.454454\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014544; batch adversarial loss: 0.541828\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031366; batch adversarial loss: 0.434071\n",
      "epoch 146; iter: 0; batch classifier loss: 0.056852; batch adversarial loss: 0.531532\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021546; batch adversarial loss: 0.362904\n",
      "epoch 148; iter: 0; batch classifier loss: 0.058322; batch adversarial loss: 0.481423\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030727; batch adversarial loss: 0.434582\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043297; batch adversarial loss: 0.573586\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034509; batch adversarial loss: 0.488347\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020000; batch adversarial loss: 0.488438\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028131; batch adversarial loss: 0.432481\n",
      "epoch 154; iter: 0; batch classifier loss: 0.042761; batch adversarial loss: 0.398665\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021391; batch adversarial loss: 0.424648\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032596; batch adversarial loss: 0.387231\n",
      "epoch 157; iter: 0; batch classifier loss: 0.074646; batch adversarial loss: 0.465024\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033025; batch adversarial loss: 0.398180\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029633; batch adversarial loss: 0.373030\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031384; batch adversarial loss: 0.440378\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033484; batch adversarial loss: 0.498525\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021801; batch adversarial loss: 0.510527\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045650; batch adversarial loss: 0.399386\n",
      "epoch 164; iter: 0; batch classifier loss: 0.003224; batch adversarial loss: 0.425520\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008563; batch adversarial loss: 0.506133\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031736; batch adversarial loss: 0.481365\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012032; batch adversarial loss: 0.444146\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017018; batch adversarial loss: 0.446057\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022896; batch adversarial loss: 0.490583\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018758; batch adversarial loss: 0.397646\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029601; batch adversarial loss: 0.507926\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012888; batch adversarial loss: 0.479015\n",
      "epoch 173; iter: 0; batch classifier loss: 0.048789; batch adversarial loss: 0.456494\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008342; batch adversarial loss: 0.493422\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010185; batch adversarial loss: 0.558359\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018845; batch adversarial loss: 0.368708\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026697; batch adversarial loss: 0.526152\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023888; batch adversarial loss: 0.483276\n",
      "epoch 179; iter: 0; batch classifier loss: 0.048010; batch adversarial loss: 0.574908\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018244; batch adversarial loss: 0.503618\n",
      "epoch 181; iter: 0; batch classifier loss: 0.040626; batch adversarial loss: 0.533343\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014693; batch adversarial loss: 0.445149\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019778; batch adversarial loss: 0.499644\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013295; batch adversarial loss: 0.499747\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025792; batch adversarial loss: 0.550374\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018154; batch adversarial loss: 0.506507\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024236; batch adversarial loss: 0.442997\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012816; batch adversarial loss: 0.347100\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013632; batch adversarial loss: 0.480740\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007086; batch adversarial loss: 0.523182\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011164; batch adversarial loss: 0.439175\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010930; batch adversarial loss: 0.492953\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008000; batch adversarial loss: 0.503898\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009420; batch adversarial loss: 0.430648\n",
      "epoch 195; iter: 0; batch classifier loss: 0.043870; batch adversarial loss: 0.529091\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008272; batch adversarial loss: 0.532451\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015463; batch adversarial loss: 0.416019\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020467; batch adversarial loss: 0.431732\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017078; batch adversarial loss: 0.431019\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704913; batch adversarial loss: 0.803401\n",
      "epoch 1; iter: 0; batch classifier loss: 0.560818; batch adversarial loss: 0.770036\n",
      "epoch 2; iter: 0; batch classifier loss: 0.577176; batch adversarial loss: 0.717402\n",
      "epoch 3; iter: 0; batch classifier loss: 0.677405; batch adversarial loss: 0.666484\n",
      "epoch 4; iter: 0; batch classifier loss: 0.499945; batch adversarial loss: 0.603730\n",
      "epoch 5; iter: 0; batch classifier loss: 0.526634; batch adversarial loss: 0.581166\n",
      "epoch 6; iter: 0; batch classifier loss: 0.421422; batch adversarial loss: 0.550003\n",
      "epoch 7; iter: 0; batch classifier loss: 0.432005; batch adversarial loss: 0.534470\n",
      "epoch 8; iter: 0; batch classifier loss: 0.438503; batch adversarial loss: 0.530762\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363641; batch adversarial loss: 0.518070\n",
      "epoch 10; iter: 0; batch classifier loss: 0.406632; batch adversarial loss: 0.572922\n",
      "epoch 11; iter: 0; batch classifier loss: 0.358265; batch adversarial loss: 0.549992\n",
      "epoch 12; iter: 0; batch classifier loss: 0.356329; batch adversarial loss: 0.555257\n",
      "epoch 13; iter: 0; batch classifier loss: 0.358770; batch adversarial loss: 0.517581\n",
      "epoch 14; iter: 0; batch classifier loss: 0.303705; batch adversarial loss: 0.528028\n",
      "epoch 15; iter: 0; batch classifier loss: 0.401705; batch adversarial loss: 0.497408\n",
      "epoch 16; iter: 0; batch classifier loss: 0.338638; batch adversarial loss: 0.478287\n",
      "epoch 17; iter: 0; batch classifier loss: 0.341174; batch adversarial loss: 0.514188\n",
      "epoch 18; iter: 0; batch classifier loss: 0.373494; batch adversarial loss: 0.522770\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438147; batch adversarial loss: 0.485084\n",
      "epoch 20; iter: 0; batch classifier loss: 0.404071; batch adversarial loss: 0.450308\n",
      "epoch 21; iter: 0; batch classifier loss: 0.305810; batch adversarial loss: 0.486403\n",
      "epoch 22; iter: 0; batch classifier loss: 0.296661; batch adversarial loss: 0.477698\n",
      "epoch 23; iter: 0; batch classifier loss: 0.281846; batch adversarial loss: 0.515876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.352091; batch adversarial loss: 0.441650\n",
      "epoch 25; iter: 0; batch classifier loss: 0.256302; batch adversarial loss: 0.511552\n",
      "epoch 26; iter: 0; batch classifier loss: 0.310075; batch adversarial loss: 0.585997\n",
      "epoch 27; iter: 0; batch classifier loss: 0.340550; batch adversarial loss: 0.490987\n",
      "epoch 28; iter: 0; batch classifier loss: 0.243794; batch adversarial loss: 0.507073\n",
      "epoch 29; iter: 0; batch classifier loss: 0.334982; batch adversarial loss: 0.446284\n",
      "epoch 30; iter: 0; batch classifier loss: 0.207917; batch adversarial loss: 0.569700\n",
      "epoch 31; iter: 0; batch classifier loss: 0.317249; batch adversarial loss: 0.439845\n",
      "epoch 32; iter: 0; batch classifier loss: 0.283630; batch adversarial loss: 0.536128\n",
      "epoch 33; iter: 0; batch classifier loss: 0.204778; batch adversarial loss: 0.464260\n",
      "epoch 34; iter: 0; batch classifier loss: 0.239811; batch adversarial loss: 0.506583\n",
      "epoch 35; iter: 0; batch classifier loss: 0.223257; batch adversarial loss: 0.542198\n",
      "epoch 36; iter: 0; batch classifier loss: 0.283356; batch adversarial loss: 0.414129\n",
      "epoch 37; iter: 0; batch classifier loss: 0.257687; batch adversarial loss: 0.446557\n",
      "epoch 38; iter: 0; batch classifier loss: 0.230366; batch adversarial loss: 0.477028\n",
      "epoch 39; iter: 0; batch classifier loss: 0.229990; batch adversarial loss: 0.486972\n",
      "epoch 40; iter: 0; batch classifier loss: 0.204773; batch adversarial loss: 0.440334\n",
      "epoch 41; iter: 0; batch classifier loss: 0.222465; batch adversarial loss: 0.542245\n",
      "epoch 42; iter: 0; batch classifier loss: 0.208336; batch adversarial loss: 0.443997\n",
      "epoch 43; iter: 0; batch classifier loss: 0.199205; batch adversarial loss: 0.523451\n",
      "epoch 44; iter: 0; batch classifier loss: 0.248838; batch adversarial loss: 0.475060\n",
      "epoch 45; iter: 0; batch classifier loss: 0.224374; batch adversarial loss: 0.451955\n",
      "epoch 46; iter: 0; batch classifier loss: 0.261510; batch adversarial loss: 0.400274\n",
      "epoch 47; iter: 0; batch classifier loss: 0.216497; batch adversarial loss: 0.486189\n",
      "epoch 48; iter: 0; batch classifier loss: 0.246733; batch adversarial loss: 0.459658\n",
      "epoch 49; iter: 0; batch classifier loss: 0.260951; batch adversarial loss: 0.348039\n",
      "epoch 50; iter: 0; batch classifier loss: 0.170203; batch adversarial loss: 0.335808\n",
      "epoch 51; iter: 0; batch classifier loss: 0.251073; batch adversarial loss: 0.385666\n",
      "epoch 52; iter: 0; batch classifier loss: 0.197288; batch adversarial loss: 0.435354\n",
      "epoch 53; iter: 0; batch classifier loss: 0.224328; batch adversarial loss: 0.504115\n",
      "epoch 54; iter: 0; batch classifier loss: 0.196945; batch adversarial loss: 0.540696\n",
      "epoch 55; iter: 0; batch classifier loss: 0.255243; batch adversarial loss: 0.434107\n",
      "epoch 56; iter: 0; batch classifier loss: 0.181203; batch adversarial loss: 0.474214\n",
      "epoch 57; iter: 0; batch classifier loss: 0.190057; batch adversarial loss: 0.521169\n",
      "epoch 58; iter: 0; batch classifier loss: 0.188457; batch adversarial loss: 0.520495\n",
      "epoch 59; iter: 0; batch classifier loss: 0.218251; batch adversarial loss: 0.456489\n",
      "epoch 60; iter: 0; batch classifier loss: 0.247278; batch adversarial loss: 0.445518\n",
      "epoch 61; iter: 0; batch classifier loss: 0.205089; batch adversarial loss: 0.334722\n",
      "epoch 62; iter: 0; batch classifier loss: 0.152380; batch adversarial loss: 0.468147\n",
      "epoch 63; iter: 0; batch classifier loss: 0.231093; batch adversarial loss: 0.396318\n",
      "epoch 64; iter: 0; batch classifier loss: 0.216334; batch adversarial loss: 0.497175\n",
      "epoch 65; iter: 0; batch classifier loss: 0.218181; batch adversarial loss: 0.462094\n",
      "epoch 66; iter: 0; batch classifier loss: 0.221066; batch adversarial loss: 0.484349\n",
      "epoch 67; iter: 0; batch classifier loss: 0.148057; batch adversarial loss: 0.460909\n",
      "epoch 68; iter: 0; batch classifier loss: 0.169136; batch adversarial loss: 0.445594\n",
      "epoch 69; iter: 0; batch classifier loss: 0.199786; batch adversarial loss: 0.446473\n",
      "epoch 70; iter: 0; batch classifier loss: 0.251369; batch adversarial loss: 0.434587\n",
      "epoch 71; iter: 0; batch classifier loss: 0.215611; batch adversarial loss: 0.383738\n",
      "epoch 72; iter: 0; batch classifier loss: 0.173021; batch adversarial loss: 0.446069\n",
      "epoch 73; iter: 0; batch classifier loss: 0.214193; batch adversarial loss: 0.383941\n",
      "epoch 74; iter: 0; batch classifier loss: 0.271142; batch adversarial loss: 0.408515\n",
      "epoch 75; iter: 0; batch classifier loss: 0.166972; batch adversarial loss: 0.409339\n",
      "epoch 76; iter: 0; batch classifier loss: 0.163218; batch adversarial loss: 0.445988\n",
      "epoch 77; iter: 0; batch classifier loss: 0.150064; batch adversarial loss: 0.458176\n",
      "epoch 78; iter: 0; batch classifier loss: 0.210976; batch adversarial loss: 0.445012\n",
      "epoch 79; iter: 0; batch classifier loss: 0.204639; batch adversarial loss: 0.334062\n",
      "epoch 80; iter: 0; batch classifier loss: 0.221529; batch adversarial loss: 0.396957\n",
      "epoch 81; iter: 0; batch classifier loss: 0.166764; batch adversarial loss: 0.408802\n",
      "epoch 82; iter: 0; batch classifier loss: 0.138120; batch adversarial loss: 0.408791\n",
      "epoch 83; iter: 0; batch classifier loss: 0.184831; batch adversarial loss: 0.497751\n",
      "epoch 84; iter: 0; batch classifier loss: 0.233887; batch adversarial loss: 0.458408\n",
      "epoch 85; iter: 0; batch classifier loss: 0.204069; batch adversarial loss: 0.483913\n",
      "epoch 86; iter: 0; batch classifier loss: 0.142096; batch adversarial loss: 0.435474\n",
      "epoch 87; iter: 0; batch classifier loss: 0.207663; batch adversarial loss: 0.409580\n",
      "epoch 88; iter: 0; batch classifier loss: 0.201758; batch adversarial loss: 0.383911\n",
      "epoch 89; iter: 0; batch classifier loss: 0.202143; batch adversarial loss: 0.508579\n",
      "epoch 90; iter: 0; batch classifier loss: 0.128510; batch adversarial loss: 0.484218\n",
      "epoch 91; iter: 0; batch classifier loss: 0.130343; batch adversarial loss: 0.471963\n",
      "epoch 92; iter: 0; batch classifier loss: 0.182648; batch adversarial loss: 0.330469\n",
      "epoch 93; iter: 0; batch classifier loss: 0.157106; batch adversarial loss: 0.346565\n",
      "epoch 94; iter: 0; batch classifier loss: 0.186008; batch adversarial loss: 0.434038\n",
      "epoch 95; iter: 0; batch classifier loss: 0.168757; batch adversarial loss: 0.432795\n",
      "epoch 96; iter: 0; batch classifier loss: 0.149133; batch adversarial loss: 0.388399\n",
      "epoch 97; iter: 0; batch classifier loss: 0.172754; batch adversarial loss: 0.472142\n",
      "epoch 98; iter: 0; batch classifier loss: 0.134220; batch adversarial loss: 0.470291\n",
      "epoch 99; iter: 0; batch classifier loss: 0.084234; batch adversarial loss: 0.524411\n",
      "epoch 100; iter: 0; batch classifier loss: 0.101761; batch adversarial loss: 0.410944\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070278; batch adversarial loss: 0.407526\n",
      "epoch 102; iter: 0; batch classifier loss: 0.077653; batch adversarial loss: 0.445805\n",
      "epoch 103; iter: 0; batch classifier loss: 0.111419; batch adversarial loss: 0.432825\n",
      "epoch 104; iter: 0; batch classifier loss: 0.087999; batch adversarial loss: 0.486553\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061582; batch adversarial loss: 0.395927\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061732; batch adversarial loss: 0.422605\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049924; batch adversarial loss: 0.459290\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059256; batch adversarial loss: 0.395161\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051486; batch adversarial loss: 0.381965\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046039; batch adversarial loss: 0.463263\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035617; batch adversarial loss: 0.464457\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037790; batch adversarial loss: 0.482239\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035605; batch adversarial loss: 0.493213\n",
      "epoch 114; iter: 0; batch classifier loss: 0.038563; batch adversarial loss: 0.467852\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028238; batch adversarial loss: 0.425241\n",
      "epoch 116; iter: 0; batch classifier loss: 0.023734; batch adversarial loss: 0.461641\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030914; batch adversarial loss: 0.453940\n",
      "epoch 118; iter: 0; batch classifier loss: 0.027840; batch adversarial loss: 0.455321\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036393; batch adversarial loss: 0.365466\n",
      "epoch 120; iter: 0; batch classifier loss: 0.052482; batch adversarial loss: 0.362156\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025613; batch adversarial loss: 0.437302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.031309; batch adversarial loss: 0.373661\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014540; batch adversarial loss: 0.444292\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055934; batch adversarial loss: 0.429883\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038932; batch adversarial loss: 0.488053\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028198; batch adversarial loss: 0.384980\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060893; batch adversarial loss: 0.348557\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039050; batch adversarial loss: 0.492211\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028565; batch adversarial loss: 0.422616\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028469; batch adversarial loss: 0.421754\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019847; batch adversarial loss: 0.384563\n",
      "epoch 132; iter: 0; batch classifier loss: 0.012379; batch adversarial loss: 0.435304\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022282; batch adversarial loss: 0.463130\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015853; batch adversarial loss: 0.454383\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023328; batch adversarial loss: 0.411475\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042093; batch adversarial loss: 0.382657\n",
      "epoch 137; iter: 0; batch classifier loss: 0.055493; batch adversarial loss: 0.492901\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011606; batch adversarial loss: 0.477705\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035340; batch adversarial loss: 0.335296\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023712; batch adversarial loss: 0.425635\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033004; batch adversarial loss: 0.467352\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023637; batch adversarial loss: 0.529171\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018743; batch adversarial loss: 0.537639\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013500; batch adversarial loss: 0.448864\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028092; batch adversarial loss: 0.517439\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021115; batch adversarial loss: 0.484588\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034314; batch adversarial loss: 0.442973\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033243; batch adversarial loss: 0.342564\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012946; batch adversarial loss: 0.544854\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029232; batch adversarial loss: 0.466663\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015864; batch adversarial loss: 0.439678\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033626; batch adversarial loss: 0.406081\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021771; batch adversarial loss: 0.454372\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019304; batch adversarial loss: 0.430822\n",
      "epoch 155; iter: 0; batch classifier loss: 0.006803; batch adversarial loss: 0.482256\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041359; batch adversarial loss: 0.470045\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016500; batch adversarial loss: 0.409130\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018664; batch adversarial loss: 0.641036\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012469; batch adversarial loss: 0.387493\n",
      "epoch 160; iter: 0; batch classifier loss: 0.011453; batch adversarial loss: 0.408823\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028758; batch adversarial loss: 0.527181\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025345; batch adversarial loss: 0.484221\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007596; batch adversarial loss: 0.560771\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013981; batch adversarial loss: 0.400229\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010500; batch adversarial loss: 0.402714\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016923; batch adversarial loss: 0.518147\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016513; batch adversarial loss: 0.419781\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017243; batch adversarial loss: 0.329949\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009350; batch adversarial loss: 0.427267\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031959; batch adversarial loss: 0.551106\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017286; batch adversarial loss: 0.407606\n",
      "epoch 172; iter: 0; batch classifier loss: 0.039375; batch adversarial loss: 0.433917\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016038; batch adversarial loss: 0.492379\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018308; batch adversarial loss: 0.425225\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034809; batch adversarial loss: 0.536712\n",
      "epoch 176; iter: 0; batch classifier loss: 0.049851; batch adversarial loss: 0.416515\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013809; batch adversarial loss: 0.461294\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014229; batch adversarial loss: 0.408105\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027689; batch adversarial loss: 0.411204\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028988; batch adversarial loss: 0.473072\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016946; batch adversarial loss: 0.328351\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042210; batch adversarial loss: 0.506763\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020605; batch adversarial loss: 0.408874\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016784; batch adversarial loss: 0.451436\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010375; batch adversarial loss: 0.410135\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015486; batch adversarial loss: 0.539407\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016501; batch adversarial loss: 0.534207\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015114; batch adversarial loss: 0.420933\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010832; batch adversarial loss: 0.498107\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014412; batch adversarial loss: 0.389333\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017740; batch adversarial loss: 0.540083\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013139; batch adversarial loss: 0.436573\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031202; batch adversarial loss: 0.421717\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024374; batch adversarial loss: 0.335453\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006727; batch adversarial loss: 0.532432\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024952; batch adversarial loss: 0.531902\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011902; batch adversarial loss: 0.492826\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027154; batch adversarial loss: 0.417073\n",
      "epoch 199; iter: 0; batch classifier loss: 0.041230; batch adversarial loss: 0.394814\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675954; batch adversarial loss: 0.800470\n",
      "epoch 1; iter: 0; batch classifier loss: 0.509419; batch adversarial loss: 0.754691\n",
      "epoch 2; iter: 0; batch classifier loss: 0.324859; batch adversarial loss: 0.752569\n",
      "epoch 3; iter: 0; batch classifier loss: 0.292702; batch adversarial loss: 0.680399\n",
      "epoch 4; iter: 0; batch classifier loss: 0.355851; batch adversarial loss: 0.668885\n",
      "epoch 5; iter: 0; batch classifier loss: 0.329302; batch adversarial loss: 0.656773\n",
      "epoch 6; iter: 0; batch classifier loss: 0.396796; batch adversarial loss: 0.631819\n",
      "epoch 7; iter: 0; batch classifier loss: 0.382006; batch adversarial loss: 0.592548\n",
      "epoch 8; iter: 0; batch classifier loss: 0.306514; batch adversarial loss: 0.568798\n",
      "epoch 9; iter: 0; batch classifier loss: 0.234548; batch adversarial loss: 0.551652\n",
      "epoch 10; iter: 0; batch classifier loss: 0.293682; batch adversarial loss: 0.513712\n",
      "epoch 11; iter: 0; batch classifier loss: 0.236870; batch adversarial loss: 0.539307\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251550; batch adversarial loss: 0.478577\n",
      "epoch 13; iter: 0; batch classifier loss: 0.263839; batch adversarial loss: 0.453546\n",
      "epoch 14; iter: 0; batch classifier loss: 0.218800; batch adversarial loss: 0.496218\n",
      "epoch 15; iter: 0; batch classifier loss: 0.174330; batch adversarial loss: 0.520682\n",
      "epoch 16; iter: 0; batch classifier loss: 0.182903; batch adversarial loss: 0.477239\n",
      "epoch 17; iter: 0; batch classifier loss: 0.148627; batch adversarial loss: 0.452093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.176956; batch adversarial loss: 0.409325\n",
      "epoch 19; iter: 0; batch classifier loss: 0.179368; batch adversarial loss: 0.460809\n",
      "epoch 20; iter: 0; batch classifier loss: 0.254723; batch adversarial loss: 0.449988\n",
      "epoch 21; iter: 0; batch classifier loss: 0.235246; batch adversarial loss: 0.489751\n",
      "epoch 22; iter: 0; batch classifier loss: 0.183482; batch adversarial loss: 0.374003\n",
      "epoch 23; iter: 0; batch classifier loss: 0.193183; batch adversarial loss: 0.437165\n",
      "epoch 24; iter: 0; batch classifier loss: 0.155528; batch adversarial loss: 0.499490\n",
      "epoch 25; iter: 0; batch classifier loss: 0.192421; batch adversarial loss: 0.484106\n",
      "epoch 26; iter: 0; batch classifier loss: 0.161644; batch adversarial loss: 0.399357\n",
      "epoch 27; iter: 0; batch classifier loss: 0.195262; batch adversarial loss: 0.391298\n",
      "epoch 28; iter: 0; batch classifier loss: 0.187303; batch adversarial loss: 0.526718\n",
      "epoch 29; iter: 0; batch classifier loss: 0.168104; batch adversarial loss: 0.402037\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138996; batch adversarial loss: 0.422155\n",
      "epoch 31; iter: 0; batch classifier loss: 0.126041; batch adversarial loss: 0.450193\n",
      "epoch 32; iter: 0; batch classifier loss: 0.147182; batch adversarial loss: 0.451938\n",
      "epoch 33; iter: 0; batch classifier loss: 0.155865; batch adversarial loss: 0.446379\n",
      "epoch 34; iter: 0; batch classifier loss: 0.141833; batch adversarial loss: 0.421847\n",
      "epoch 35; iter: 0; batch classifier loss: 0.131769; batch adversarial loss: 0.365257\n",
      "epoch 36; iter: 0; batch classifier loss: 0.193745; batch adversarial loss: 0.392237\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153584; batch adversarial loss: 0.453610\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099434; batch adversarial loss: 0.535241\n",
      "epoch 39; iter: 0; batch classifier loss: 0.134343; batch adversarial loss: 0.388767\n",
      "epoch 40; iter: 0; batch classifier loss: 0.143951; batch adversarial loss: 0.486919\n",
      "epoch 41; iter: 0; batch classifier loss: 0.132303; batch adversarial loss: 0.513671\n",
      "epoch 42; iter: 0; batch classifier loss: 0.160332; batch adversarial loss: 0.449079\n",
      "epoch 43; iter: 0; batch classifier loss: 0.083979; batch adversarial loss: 0.369241\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118367; batch adversarial loss: 0.405767\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124416; batch adversarial loss: 0.388754\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117077; batch adversarial loss: 0.445932\n",
      "epoch 47; iter: 0; batch classifier loss: 0.147810; batch adversarial loss: 0.499214\n",
      "epoch 48; iter: 0; batch classifier loss: 0.109804; batch adversarial loss: 0.463588\n",
      "epoch 49; iter: 0; batch classifier loss: 0.115459; batch adversarial loss: 0.337837\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087710; batch adversarial loss: 0.420618\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122979; batch adversarial loss: 0.434292\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099555; batch adversarial loss: 0.403554\n",
      "epoch 53; iter: 0; batch classifier loss: 0.080245; batch adversarial loss: 0.330807\n",
      "epoch 54; iter: 0; batch classifier loss: 0.084328; batch adversarial loss: 0.425749\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122748; batch adversarial loss: 0.418144\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083688; batch adversarial loss: 0.428680\n",
      "epoch 57; iter: 0; batch classifier loss: 0.097961; batch adversarial loss: 0.395721\n",
      "epoch 58; iter: 0; batch classifier loss: 0.056244; batch adversarial loss: 0.445973\n",
      "epoch 59; iter: 0; batch classifier loss: 0.064209; batch adversarial loss: 0.524972\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081457; batch adversarial loss: 0.453616\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078207; batch adversarial loss: 0.426522\n",
      "epoch 62; iter: 0; batch classifier loss: 0.070369; batch adversarial loss: 0.460235\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089970; batch adversarial loss: 0.519964\n",
      "epoch 64; iter: 0; batch classifier loss: 0.086027; batch adversarial loss: 0.399722\n",
      "epoch 65; iter: 0; batch classifier loss: 0.143590; batch adversarial loss: 0.454261\n",
      "epoch 66; iter: 0; batch classifier loss: 0.064688; batch adversarial loss: 0.375092\n",
      "epoch 67; iter: 0; batch classifier loss: 0.099455; batch adversarial loss: 0.504742\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060533; batch adversarial loss: 0.484129\n",
      "epoch 69; iter: 0; batch classifier loss: 0.058156; batch adversarial loss: 0.451864\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098141; batch adversarial loss: 0.437670\n",
      "epoch 71; iter: 0; batch classifier loss: 0.054814; batch adversarial loss: 0.381232\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054076; batch adversarial loss: 0.502164\n",
      "epoch 73; iter: 0; batch classifier loss: 0.064864; batch adversarial loss: 0.445032\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076137; batch adversarial loss: 0.423627\n",
      "epoch 75; iter: 0; batch classifier loss: 0.062866; batch adversarial loss: 0.333021\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065586; batch adversarial loss: 0.425655\n",
      "epoch 77; iter: 0; batch classifier loss: 0.078233; batch adversarial loss: 0.438765\n",
      "epoch 78; iter: 0; batch classifier loss: 0.060724; batch adversarial loss: 0.383404\n",
      "epoch 79; iter: 0; batch classifier loss: 0.119548; batch adversarial loss: 0.359711\n",
      "epoch 80; iter: 0; batch classifier loss: 0.057466; batch adversarial loss: 0.345256\n",
      "epoch 81; iter: 0; batch classifier loss: 0.033977; batch adversarial loss: 0.434703\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060785; batch adversarial loss: 0.459994\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056207; batch adversarial loss: 0.594421\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051794; batch adversarial loss: 0.362512\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090293; batch adversarial loss: 0.454003\n",
      "epoch 86; iter: 0; batch classifier loss: 0.031405; batch adversarial loss: 0.449670\n",
      "epoch 87; iter: 0; batch classifier loss: 0.026415; batch adversarial loss: 0.479871\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051645; batch adversarial loss: 0.396705\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051663; batch adversarial loss: 0.463453\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055593; batch adversarial loss: 0.393416\n",
      "epoch 91; iter: 0; batch classifier loss: 0.029995; batch adversarial loss: 0.410269\n",
      "epoch 92; iter: 0; batch classifier loss: 0.033684; batch adversarial loss: 0.408774\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060830; batch adversarial loss: 0.447548\n",
      "epoch 94; iter: 0; batch classifier loss: 0.034273; batch adversarial loss: 0.489826\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064212; batch adversarial loss: 0.412922\n",
      "epoch 96; iter: 0; batch classifier loss: 0.040893; batch adversarial loss: 0.480538\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044659; batch adversarial loss: 0.426013\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053379; batch adversarial loss: 0.476216\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074565; batch adversarial loss: 0.460869\n",
      "epoch 100; iter: 0; batch classifier loss: 0.040076; batch adversarial loss: 0.437423\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049681; batch adversarial loss: 0.486553\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036036; batch adversarial loss: 0.428887\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037249; batch adversarial loss: 0.550158\n",
      "epoch 104; iter: 0; batch classifier loss: 0.022075; batch adversarial loss: 0.472215\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034683; batch adversarial loss: 0.385438\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031844; batch adversarial loss: 0.459288\n",
      "epoch 107; iter: 0; batch classifier loss: 0.021733; batch adversarial loss: 0.379946\n",
      "epoch 108; iter: 0; batch classifier loss: 0.013635; batch adversarial loss: 0.429035\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027374; batch adversarial loss: 0.576171\n",
      "epoch 110; iter: 0; batch classifier loss: 0.014284; batch adversarial loss: 0.367735\n",
      "epoch 111; iter: 0; batch classifier loss: 0.026741; batch adversarial loss: 0.466240\n",
      "epoch 112; iter: 0; batch classifier loss: 0.021616; batch adversarial loss: 0.494298\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044981; batch adversarial loss: 0.586709\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040731; batch adversarial loss: 0.434968\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057901; batch adversarial loss: 0.526209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.047512; batch adversarial loss: 0.466008\n",
      "epoch 117; iter: 0; batch classifier loss: 0.059074; batch adversarial loss: 0.515726\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069669; batch adversarial loss: 0.466718\n",
      "epoch 119; iter: 0; batch classifier loss: 0.077570; batch adversarial loss: 0.710536\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057186; batch adversarial loss: 0.477083\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068656; batch adversarial loss: 0.508125\n",
      "epoch 122; iter: 0; batch classifier loss: 0.131161; batch adversarial loss: 0.715678\n",
      "epoch 123; iter: 0; batch classifier loss: 0.150432; batch adversarial loss: 0.662355\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031785; batch adversarial loss: 0.411489\n",
      "epoch 125; iter: 0; batch classifier loss: 0.095397; batch adversarial loss: 0.680330\n",
      "epoch 126; iter: 0; batch classifier loss: 0.084621; batch adversarial loss: 0.444366\n",
      "epoch 127; iter: 0; batch classifier loss: 0.169620; batch adversarial loss: 0.610115\n",
      "epoch 128; iter: 0; batch classifier loss: 0.097588; batch adversarial loss: 0.539865\n",
      "epoch 129; iter: 0; batch classifier loss: 0.108671; batch adversarial loss: 0.582664\n",
      "epoch 130; iter: 0; batch classifier loss: 0.090770; batch adversarial loss: 0.507739\n",
      "epoch 131; iter: 0; batch classifier loss: 0.292654; batch adversarial loss: 0.810489\n",
      "epoch 132; iter: 0; batch classifier loss: 0.152663; batch adversarial loss: 0.607285\n",
      "epoch 133; iter: 0; batch classifier loss: 0.129502; batch adversarial loss: 0.624036\n",
      "epoch 134; iter: 0; batch classifier loss: 0.157770; batch adversarial loss: 0.530112\n",
      "epoch 135; iter: 0; batch classifier loss: 0.107503; batch adversarial loss: 0.561109\n",
      "epoch 136; iter: 0; batch classifier loss: 0.152834; batch adversarial loss: 0.565010\n",
      "epoch 137; iter: 0; batch classifier loss: 0.137552; batch adversarial loss: 0.559789\n",
      "epoch 138; iter: 0; batch classifier loss: 0.113479; batch adversarial loss: 0.511797\n",
      "epoch 139; iter: 0; batch classifier loss: 0.138921; batch adversarial loss: 0.591858\n",
      "epoch 140; iter: 0; batch classifier loss: 0.208227; batch adversarial loss: 0.709323\n",
      "epoch 141; iter: 0; batch classifier loss: 0.146150; batch adversarial loss: 0.553905\n",
      "epoch 142; iter: 0; batch classifier loss: 0.057735; batch adversarial loss: 0.485936\n",
      "epoch 143; iter: 0; batch classifier loss: 0.123760; batch adversarial loss: 0.432966\n",
      "epoch 144; iter: 0; batch classifier loss: 0.110904; batch adversarial loss: 0.499561\n",
      "epoch 145; iter: 0; batch classifier loss: 0.107622; batch adversarial loss: 0.408230\n",
      "epoch 146; iter: 0; batch classifier loss: 0.131119; batch adversarial loss: 0.524777\n",
      "epoch 147; iter: 0; batch classifier loss: 0.185415; batch adversarial loss: 0.617975\n",
      "epoch 148; iter: 0; batch classifier loss: 0.101637; batch adversarial loss: 0.476970\n",
      "epoch 149; iter: 0; batch classifier loss: 0.155444; batch adversarial loss: 0.489756\n",
      "epoch 150; iter: 0; batch classifier loss: 0.115387; batch adversarial loss: 0.476736\n",
      "epoch 151; iter: 0; batch classifier loss: 0.152277; batch adversarial loss: 0.564982\n",
      "epoch 152; iter: 0; batch classifier loss: 0.163677; batch adversarial loss: 0.459049\n",
      "epoch 153; iter: 0; batch classifier loss: 0.096606; batch adversarial loss: 0.531026\n",
      "epoch 154; iter: 0; batch classifier loss: 0.081035; batch adversarial loss: 0.482069\n",
      "epoch 155; iter: 0; batch classifier loss: 0.145786; batch adversarial loss: 0.517717\n",
      "epoch 156; iter: 0; batch classifier loss: 0.087943; batch adversarial loss: 0.434168\n",
      "epoch 157; iter: 0; batch classifier loss: 0.142321; batch adversarial loss: 0.431869\n",
      "epoch 158; iter: 0; batch classifier loss: 0.118696; batch adversarial loss: 0.468980\n",
      "epoch 159; iter: 0; batch classifier loss: 0.091276; batch adversarial loss: 0.416771\n",
      "epoch 160; iter: 0; batch classifier loss: 0.122798; batch adversarial loss: 0.508348\n",
      "epoch 161; iter: 0; batch classifier loss: 0.100811; batch adversarial loss: 0.445655\n",
      "epoch 162; iter: 0; batch classifier loss: 0.109063; batch adversarial loss: 0.432697\n",
      "epoch 163; iter: 0; batch classifier loss: 0.059618; batch adversarial loss: 0.516729\n",
      "epoch 164; iter: 0; batch classifier loss: 0.054714; batch adversarial loss: 0.435714\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033543; batch adversarial loss: 0.493938\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037343; batch adversarial loss: 0.473897\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029984; batch adversarial loss: 0.469708\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032518; batch adversarial loss: 0.441214\n",
      "epoch 169; iter: 0; batch classifier loss: 0.051262; batch adversarial loss: 0.555537\n",
      "epoch 170; iter: 0; batch classifier loss: 0.055247; batch adversarial loss: 0.487652\n",
      "epoch 171; iter: 0; batch classifier loss: 0.067780; batch adversarial loss: 0.438995\n",
      "epoch 172; iter: 0; batch classifier loss: 0.049786; batch adversarial loss: 0.433029\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025297; batch adversarial loss: 0.460343\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036413; batch adversarial loss: 0.457359\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040945; batch adversarial loss: 0.498000\n",
      "epoch 176; iter: 0; batch classifier loss: 0.061883; batch adversarial loss: 0.405467\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033586; batch adversarial loss: 0.401767\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030053; batch adversarial loss: 0.558605\n",
      "epoch 179; iter: 0; batch classifier loss: 0.052190; batch adversarial loss: 0.575183\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037228; batch adversarial loss: 0.380363\n",
      "epoch 181; iter: 0; batch classifier loss: 0.045571; batch adversarial loss: 0.490261\n",
      "epoch 182; iter: 0; batch classifier loss: 0.058771; batch adversarial loss: 0.457053\n",
      "epoch 183; iter: 0; batch classifier loss: 0.067227; batch adversarial loss: 0.467596\n",
      "epoch 184; iter: 0; batch classifier loss: 0.059288; batch adversarial loss: 0.532721\n",
      "epoch 185; iter: 0; batch classifier loss: 0.069351; batch adversarial loss: 0.469339\n",
      "epoch 186; iter: 0; batch classifier loss: 0.058828; batch adversarial loss: 0.451228\n",
      "epoch 187; iter: 0; batch classifier loss: 0.064213; batch adversarial loss: 0.488743\n",
      "epoch 188; iter: 0; batch classifier loss: 0.078686; batch adversarial loss: 0.475404\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032432; batch adversarial loss: 0.421697\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040076; batch adversarial loss: 0.600304\n",
      "epoch 191; iter: 0; batch classifier loss: 0.040182; batch adversarial loss: 0.489934\n",
      "epoch 192; iter: 0; batch classifier loss: 0.097292; batch adversarial loss: 0.438082\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030746; batch adversarial loss: 0.455238\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041376; batch adversarial loss: 0.416641\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018126; batch adversarial loss: 0.480702\n",
      "epoch 196; iter: 0; batch classifier loss: 0.069599; batch adversarial loss: 0.476747\n",
      "epoch 197; iter: 0; batch classifier loss: 0.078987; batch adversarial loss: 0.464325\n",
      "epoch 198; iter: 0; batch classifier loss: 0.100955; batch adversarial loss: 0.489593\n",
      "epoch 199; iter: 0; batch classifier loss: 0.048838; batch adversarial loss: 0.407011\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708625; batch adversarial loss: 0.727843\n",
      "epoch 1; iter: 0; batch classifier loss: 0.471528; batch adversarial loss: 0.676520\n",
      "epoch 2; iter: 0; batch classifier loss: 0.437763; batch adversarial loss: 0.653499\n",
      "epoch 3; iter: 0; batch classifier loss: 0.344597; batch adversarial loss: 0.623530\n",
      "epoch 4; iter: 0; batch classifier loss: 0.362825; batch adversarial loss: 0.603832\n",
      "epoch 5; iter: 0; batch classifier loss: 0.333862; batch adversarial loss: 0.573627\n",
      "epoch 6; iter: 0; batch classifier loss: 0.371911; batch adversarial loss: 0.596820\n",
      "epoch 7; iter: 0; batch classifier loss: 0.322952; batch adversarial loss: 0.551334\n",
      "epoch 8; iter: 0; batch classifier loss: 0.431857; batch adversarial loss: 0.616133\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545068; batch adversarial loss: 0.524930\n",
      "epoch 10; iter: 0; batch classifier loss: 0.433880; batch adversarial loss: 0.535681\n",
      "epoch 11; iter: 0; batch classifier loss: 0.465590; batch adversarial loss: 0.572612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.360358; batch adversarial loss: 0.527105\n",
      "epoch 13; iter: 0; batch classifier loss: 0.419542; batch adversarial loss: 0.536616\n",
      "epoch 14; iter: 0; batch classifier loss: 0.442084; batch adversarial loss: 0.550134\n",
      "epoch 15; iter: 0; batch classifier loss: 0.351690; batch adversarial loss: 0.502542\n",
      "epoch 16; iter: 0; batch classifier loss: 0.426472; batch adversarial loss: 0.527392\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377385; batch adversarial loss: 0.480191\n",
      "epoch 18; iter: 0; batch classifier loss: 0.290139; batch adversarial loss: 0.480006\n",
      "epoch 19; iter: 0; batch classifier loss: 0.361042; batch adversarial loss: 0.459979\n",
      "epoch 20; iter: 0; batch classifier loss: 0.321850; batch adversarial loss: 0.448832\n",
      "epoch 21; iter: 0; batch classifier loss: 0.293544; batch adversarial loss: 0.501597\n",
      "epoch 22; iter: 0; batch classifier loss: 0.291884; batch adversarial loss: 0.472311\n",
      "epoch 23; iter: 0; batch classifier loss: 0.233745; batch adversarial loss: 0.495962\n",
      "epoch 24; iter: 0; batch classifier loss: 0.340292; batch adversarial loss: 0.462128\n",
      "epoch 25; iter: 0; batch classifier loss: 0.256204; batch adversarial loss: 0.507493\n",
      "epoch 26; iter: 0; batch classifier loss: 0.247479; batch adversarial loss: 0.427258\n",
      "epoch 27; iter: 0; batch classifier loss: 0.304105; batch adversarial loss: 0.446969\n",
      "epoch 28; iter: 0; batch classifier loss: 0.277842; batch adversarial loss: 0.461482\n",
      "epoch 29; iter: 0; batch classifier loss: 0.266987; batch adversarial loss: 0.511505\n",
      "epoch 30; iter: 0; batch classifier loss: 0.318916; batch adversarial loss: 0.402787\n",
      "epoch 31; iter: 0; batch classifier loss: 0.233886; batch adversarial loss: 0.412062\n",
      "epoch 32; iter: 0; batch classifier loss: 0.293669; batch adversarial loss: 0.458967\n",
      "epoch 33; iter: 0; batch classifier loss: 0.261606; batch adversarial loss: 0.430378\n",
      "epoch 34; iter: 0; batch classifier loss: 0.260023; batch adversarial loss: 0.390694\n",
      "epoch 35; iter: 0; batch classifier loss: 0.290409; batch adversarial loss: 0.422049\n",
      "epoch 36; iter: 0; batch classifier loss: 0.244746; batch adversarial loss: 0.443178\n",
      "epoch 37; iter: 0; batch classifier loss: 0.180992; batch adversarial loss: 0.475171\n",
      "epoch 38; iter: 0; batch classifier loss: 0.263490; batch adversarial loss: 0.416870\n",
      "epoch 39; iter: 0; batch classifier loss: 0.271665; batch adversarial loss: 0.462800\n",
      "epoch 40; iter: 0; batch classifier loss: 0.293974; batch adversarial loss: 0.452018\n",
      "epoch 41; iter: 0; batch classifier loss: 0.211326; batch adversarial loss: 0.439625\n",
      "epoch 42; iter: 0; batch classifier loss: 0.296975; batch adversarial loss: 0.440154\n",
      "epoch 43; iter: 0; batch classifier loss: 0.255350; batch adversarial loss: 0.424269\n",
      "epoch 44; iter: 0; batch classifier loss: 0.259474; batch adversarial loss: 0.434190\n",
      "epoch 45; iter: 0; batch classifier loss: 0.274389; batch adversarial loss: 0.423180\n",
      "epoch 46; iter: 0; batch classifier loss: 0.210114; batch adversarial loss: 0.495161\n",
      "epoch 47; iter: 0; batch classifier loss: 0.281731; batch adversarial loss: 0.461237\n",
      "epoch 48; iter: 0; batch classifier loss: 0.199963; batch adversarial loss: 0.399575\n",
      "epoch 49; iter: 0; batch classifier loss: 0.212738; batch adversarial loss: 0.532996\n",
      "epoch 50; iter: 0; batch classifier loss: 0.227915; batch adversarial loss: 0.399218\n",
      "epoch 51; iter: 0; batch classifier loss: 0.279433; batch adversarial loss: 0.411475\n",
      "epoch 52; iter: 0; batch classifier loss: 0.183088; batch adversarial loss: 0.529428\n",
      "epoch 53; iter: 0; batch classifier loss: 0.256379; batch adversarial loss: 0.459578\n",
      "epoch 54; iter: 0; batch classifier loss: 0.157477; batch adversarial loss: 0.422866\n",
      "epoch 55; iter: 0; batch classifier loss: 0.151120; batch adversarial loss: 0.459166\n",
      "epoch 56; iter: 0; batch classifier loss: 0.235436; batch adversarial loss: 0.554571\n",
      "epoch 57; iter: 0; batch classifier loss: 0.146591; batch adversarial loss: 0.542280\n",
      "epoch 58; iter: 0; batch classifier loss: 0.226750; batch adversarial loss: 0.363283\n",
      "epoch 59; iter: 0; batch classifier loss: 0.235722; batch adversarial loss: 0.496210\n",
      "epoch 60; iter: 0; batch classifier loss: 0.135604; batch adversarial loss: 0.446313\n",
      "epoch 61; iter: 0; batch classifier loss: 0.218398; batch adversarial loss: 0.385795\n",
      "epoch 62; iter: 0; batch classifier loss: 0.302873; batch adversarial loss: 0.520884\n",
      "epoch 63; iter: 0; batch classifier loss: 0.134620; batch adversarial loss: 0.457588\n",
      "epoch 64; iter: 0; batch classifier loss: 0.158729; batch adversarial loss: 0.423135\n",
      "epoch 65; iter: 0; batch classifier loss: 0.240820; batch adversarial loss: 0.530859\n",
      "epoch 66; iter: 0; batch classifier loss: 0.218762; batch adversarial loss: 0.447054\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171665; batch adversarial loss: 0.422381\n",
      "epoch 68; iter: 0; batch classifier loss: 0.245706; batch adversarial loss: 0.374183\n",
      "epoch 69; iter: 0; batch classifier loss: 0.278560; batch adversarial loss: 0.508945\n",
      "epoch 70; iter: 0; batch classifier loss: 0.181979; batch adversarial loss: 0.495390\n",
      "epoch 71; iter: 0; batch classifier loss: 0.214271; batch adversarial loss: 0.471362\n",
      "epoch 72; iter: 0; batch classifier loss: 0.170765; batch adversarial loss: 0.507342\n",
      "epoch 73; iter: 0; batch classifier loss: 0.117020; batch adversarial loss: 0.482384\n",
      "epoch 74; iter: 0; batch classifier loss: 0.119540; batch adversarial loss: 0.436852\n",
      "epoch 75; iter: 0; batch classifier loss: 0.101918; batch adversarial loss: 0.533197\n",
      "epoch 76; iter: 0; batch classifier loss: 0.280661; batch adversarial loss: 0.496040\n",
      "epoch 77; iter: 0; batch classifier loss: 0.141409; batch adversarial loss: 0.506314\n",
      "epoch 78; iter: 0; batch classifier loss: 0.146671; batch adversarial loss: 0.507242\n",
      "epoch 79; iter: 0; batch classifier loss: 0.146159; batch adversarial loss: 0.409163\n",
      "epoch 80; iter: 0; batch classifier loss: 0.283965; batch adversarial loss: 0.397370\n",
      "epoch 81; iter: 0; batch classifier loss: 0.269793; batch adversarial loss: 0.532781\n",
      "epoch 82; iter: 0; batch classifier loss: 0.181339; batch adversarial loss: 0.483257\n",
      "epoch 83; iter: 0; batch classifier loss: 0.190624; batch adversarial loss: 0.496161\n",
      "epoch 84; iter: 0; batch classifier loss: 0.213767; batch adversarial loss: 0.471116\n",
      "epoch 85; iter: 0; batch classifier loss: 0.218897; batch adversarial loss: 0.506625\n",
      "epoch 86; iter: 0; batch classifier loss: 0.234040; batch adversarial loss: 0.459029\n",
      "epoch 87; iter: 0; batch classifier loss: 0.220619; batch adversarial loss: 0.471050\n",
      "epoch 88; iter: 0; batch classifier loss: 0.211249; batch adversarial loss: 0.422390\n",
      "epoch 89; iter: 0; batch classifier loss: 0.203939; batch adversarial loss: 0.445048\n",
      "epoch 90; iter: 0; batch classifier loss: 0.169081; batch adversarial loss: 0.482772\n",
      "epoch 91; iter: 0; batch classifier loss: 0.255131; batch adversarial loss: 0.421653\n",
      "epoch 92; iter: 0; batch classifier loss: 0.224860; batch adversarial loss: 0.436030\n",
      "epoch 93; iter: 0; batch classifier loss: 0.173853; batch adversarial loss: 0.494341\n",
      "epoch 94; iter: 0; batch classifier loss: 0.184589; batch adversarial loss: 0.495472\n",
      "epoch 95; iter: 0; batch classifier loss: 0.166922; batch adversarial loss: 0.592857\n",
      "epoch 96; iter: 0; batch classifier loss: 0.270368; batch adversarial loss: 0.471018\n",
      "epoch 97; iter: 0; batch classifier loss: 0.150141; batch adversarial loss: 0.483380\n",
      "epoch 98; iter: 0; batch classifier loss: 0.119040; batch adversarial loss: 0.494534\n",
      "epoch 99; iter: 0; batch classifier loss: 0.096744; batch adversarial loss: 0.455690\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045559; batch adversarial loss: 0.504505\n",
      "epoch 101; iter: 0; batch classifier loss: 0.032185; batch adversarial loss: 0.455206\n",
      "epoch 102; iter: 0; batch classifier loss: 0.075028; batch adversarial loss: 0.527182\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049027; batch adversarial loss: 0.566176\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044597; batch adversarial loss: 0.405990\n",
      "epoch 105; iter: 0; batch classifier loss: 0.039292; batch adversarial loss: 0.482030\n",
      "epoch 106; iter: 0; batch classifier loss: 0.066829; batch adversarial loss: 0.458867\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048183; batch adversarial loss: 0.392344\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077423; batch adversarial loss: 0.441378\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062025; batch adversarial loss: 0.359455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.032228; batch adversarial loss: 0.355641\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060577; batch adversarial loss: 0.453879\n",
      "epoch 112; iter: 0; batch classifier loss: 0.072570; batch adversarial loss: 0.492893\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044279; batch adversarial loss: 0.394441\n",
      "epoch 114; iter: 0; batch classifier loss: 0.106431; batch adversarial loss: 0.357201\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049862; batch adversarial loss: 0.437152\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059772; batch adversarial loss: 0.504477\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047931; batch adversarial loss: 0.400137\n",
      "epoch 118; iter: 0; batch classifier loss: 0.084517; batch adversarial loss: 0.447064\n",
      "epoch 119; iter: 0; batch classifier loss: 0.090497; batch adversarial loss: 0.403928\n",
      "epoch 120; iter: 0; batch classifier loss: 0.065678; batch adversarial loss: 0.434037\n",
      "epoch 121; iter: 0; batch classifier loss: 0.056294; batch adversarial loss: 0.450026\n",
      "epoch 122; iter: 0; batch classifier loss: 0.081086; batch adversarial loss: 0.475336\n",
      "epoch 123; iter: 0; batch classifier loss: 0.060663; batch adversarial loss: 0.440227\n",
      "epoch 124; iter: 0; batch classifier loss: 0.061380; batch adversarial loss: 0.403517\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042287; batch adversarial loss: 0.448514\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027040; batch adversarial loss: 0.444205\n",
      "epoch 127; iter: 0; batch classifier loss: 0.069519; batch adversarial loss: 0.374190\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042249; batch adversarial loss: 0.413157\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048385; batch adversarial loss: 0.358541\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036885; batch adversarial loss: 0.416800\n",
      "epoch 131; iter: 0; batch classifier loss: 0.057180; batch adversarial loss: 0.389564\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032405; batch adversarial loss: 0.451931\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048184; batch adversarial loss: 0.448667\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033981; batch adversarial loss: 0.459176\n",
      "epoch 135; iter: 0; batch classifier loss: 0.076509; batch adversarial loss: 0.495518\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028364; batch adversarial loss: 0.418972\n",
      "epoch 137; iter: 0; batch classifier loss: 0.059350; batch adversarial loss: 0.398342\n",
      "epoch 138; iter: 0; batch classifier loss: 0.083948; batch adversarial loss: 0.430668\n",
      "epoch 139; iter: 0; batch classifier loss: 0.068032; batch adversarial loss: 0.495957\n",
      "epoch 140; iter: 0; batch classifier loss: 0.064839; batch adversarial loss: 0.382648\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050316; batch adversarial loss: 0.416053\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028136; batch adversarial loss: 0.428259\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042504; batch adversarial loss: 0.388421\n",
      "epoch 144; iter: 0; batch classifier loss: 0.065699; batch adversarial loss: 0.393432\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031375; batch adversarial loss: 0.440517\n",
      "epoch 146; iter: 0; batch classifier loss: 0.081531; batch adversarial loss: 0.539513\n",
      "epoch 147; iter: 0; batch classifier loss: 0.071856; batch adversarial loss: 0.462199\n",
      "epoch 148; iter: 0; batch classifier loss: 0.059997; batch adversarial loss: 0.473861\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040154; batch adversarial loss: 0.397266\n",
      "epoch 150; iter: 0; batch classifier loss: 0.061292; batch adversarial loss: 0.350940\n",
      "epoch 151; iter: 0; batch classifier loss: 0.046401; batch adversarial loss: 0.523294\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044925; batch adversarial loss: 0.423728\n",
      "epoch 153; iter: 0; batch classifier loss: 0.092050; batch adversarial loss: 0.433173\n",
      "epoch 154; iter: 0; batch classifier loss: 0.047364; batch adversarial loss: 0.463874\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040305; batch adversarial loss: 0.463903\n",
      "epoch 156; iter: 0; batch classifier loss: 0.071251; batch adversarial loss: 0.496445\n",
      "epoch 157; iter: 0; batch classifier loss: 0.054641; batch adversarial loss: 0.533882\n",
      "epoch 158; iter: 0; batch classifier loss: 0.050720; batch adversarial loss: 0.439543\n",
      "epoch 159; iter: 0; batch classifier loss: 0.063338; batch adversarial loss: 0.436928\n",
      "epoch 160; iter: 0; batch classifier loss: 0.043125; batch adversarial loss: 0.465871\n",
      "epoch 161; iter: 0; batch classifier loss: 0.045840; batch adversarial loss: 0.448480\n",
      "epoch 162; iter: 0; batch classifier loss: 0.092209; batch adversarial loss: 0.484920\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039120; batch adversarial loss: 0.387743\n",
      "epoch 164; iter: 0; batch classifier loss: 0.048421; batch adversarial loss: 0.355959\n",
      "epoch 165; iter: 0; batch classifier loss: 0.054529; batch adversarial loss: 0.384078\n",
      "epoch 166; iter: 0; batch classifier loss: 0.042891; batch adversarial loss: 0.366716\n",
      "epoch 167; iter: 0; batch classifier loss: 0.043757; batch adversarial loss: 0.430736\n",
      "epoch 168; iter: 0; batch classifier loss: 0.061690; batch adversarial loss: 0.433171\n",
      "epoch 169; iter: 0; batch classifier loss: 0.065186; batch adversarial loss: 0.596663\n",
      "epoch 170; iter: 0; batch classifier loss: 0.073398; batch adversarial loss: 0.401894\n",
      "epoch 171; iter: 0; batch classifier loss: 0.059734; batch adversarial loss: 0.431688\n",
      "epoch 172; iter: 0; batch classifier loss: 0.106650; batch adversarial loss: 0.479297\n",
      "epoch 173; iter: 0; batch classifier loss: 0.061664; batch adversarial loss: 0.475096\n",
      "epoch 174; iter: 0; batch classifier loss: 0.059372; batch adversarial loss: 0.480739\n",
      "epoch 175; iter: 0; batch classifier loss: 0.054896; batch adversarial loss: 0.360030\n",
      "epoch 176; iter: 0; batch classifier loss: 0.055310; batch adversarial loss: 0.447095\n",
      "epoch 177; iter: 0; batch classifier loss: 0.039638; batch adversarial loss: 0.477552\n",
      "epoch 178; iter: 0; batch classifier loss: 0.047587; batch adversarial loss: 0.494150\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044493; batch adversarial loss: 0.500213\n",
      "epoch 180; iter: 0; batch classifier loss: 0.059746; batch adversarial loss: 0.399270\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038867; batch adversarial loss: 0.334098\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029566; batch adversarial loss: 0.446712\n",
      "epoch 183; iter: 0; batch classifier loss: 0.037519; batch adversarial loss: 0.427959\n",
      "epoch 184; iter: 0; batch classifier loss: 0.048530; batch adversarial loss: 0.418775\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026434; batch adversarial loss: 0.483057\n",
      "epoch 186; iter: 0; batch classifier loss: 0.047424; batch adversarial loss: 0.452549\n",
      "epoch 187; iter: 0; batch classifier loss: 0.051420; batch adversarial loss: 0.403931\n",
      "epoch 188; iter: 0; batch classifier loss: 0.077878; batch adversarial loss: 0.418829\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026330; batch adversarial loss: 0.426706\n",
      "epoch 190; iter: 0; batch classifier loss: 0.053189; batch adversarial loss: 0.369818\n",
      "epoch 191; iter: 0; batch classifier loss: 0.053219; batch adversarial loss: 0.474304\n",
      "epoch 192; iter: 0; batch classifier loss: 0.045811; batch adversarial loss: 0.410121\n",
      "epoch 193; iter: 0; batch classifier loss: 0.044357; batch adversarial loss: 0.473261\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033170; batch adversarial loss: 0.366892\n",
      "epoch 195; iter: 0; batch classifier loss: 0.051414; batch adversarial loss: 0.455922\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032837; batch adversarial loss: 0.449986\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031313; batch adversarial loss: 0.413228\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025728; batch adversarial loss: 0.454410\n",
      "epoch 199; iter: 0; batch classifier loss: 0.045962; batch adversarial loss: 0.400842\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683228; batch adversarial loss: 0.868164\n",
      "epoch 1; iter: 0; batch classifier loss: 0.474819; batch adversarial loss: 0.914467\n",
      "epoch 2; iter: 0; batch classifier loss: 0.677393; batch adversarial loss: 0.872949\n",
      "epoch 3; iter: 0; batch classifier loss: 0.830077; batch adversarial loss: 0.832923\n",
      "epoch 4; iter: 0; batch classifier loss: 0.911938; batch adversarial loss: 0.761816\n",
      "epoch 5; iter: 0; batch classifier loss: 0.763136; batch adversarial loss: 0.696157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.947487; batch adversarial loss: 0.610359\n",
      "epoch 7; iter: 0; batch classifier loss: 0.816934; batch adversarial loss: 0.601896\n",
      "epoch 8; iter: 0; batch classifier loss: 0.343494; batch adversarial loss: 0.553743\n",
      "epoch 9; iter: 0; batch classifier loss: 0.354365; batch adversarial loss: 0.564726\n",
      "epoch 10; iter: 0; batch classifier loss: 0.293466; batch adversarial loss: 0.504609\n",
      "epoch 11; iter: 0; batch classifier loss: 0.266396; batch adversarial loss: 0.554519\n",
      "epoch 12; iter: 0; batch classifier loss: 0.308749; batch adversarial loss: 0.524914\n",
      "epoch 13; iter: 0; batch classifier loss: 0.266894; batch adversarial loss: 0.533953\n",
      "epoch 14; iter: 0; batch classifier loss: 0.384679; batch adversarial loss: 0.497079\n",
      "epoch 15; iter: 0; batch classifier loss: 0.292210; batch adversarial loss: 0.553795\n",
      "epoch 16; iter: 0; batch classifier loss: 0.353673; batch adversarial loss: 0.555128\n",
      "epoch 17; iter: 0; batch classifier loss: 0.321639; batch adversarial loss: 0.530478\n",
      "epoch 18; iter: 0; batch classifier loss: 0.292036; batch adversarial loss: 0.517016\n",
      "epoch 19; iter: 0; batch classifier loss: 0.337199; batch adversarial loss: 0.496890\n",
      "epoch 20; iter: 0; batch classifier loss: 0.291755; batch adversarial loss: 0.512595\n",
      "epoch 21; iter: 0; batch classifier loss: 0.363936; batch adversarial loss: 0.503092\n",
      "epoch 22; iter: 0; batch classifier loss: 0.282461; batch adversarial loss: 0.544153\n",
      "epoch 23; iter: 0; batch classifier loss: 0.268500; batch adversarial loss: 0.587466\n",
      "epoch 24; iter: 0; batch classifier loss: 0.247931; batch adversarial loss: 0.509920\n",
      "epoch 25; iter: 0; batch classifier loss: 0.234424; batch adversarial loss: 0.485547\n",
      "epoch 26; iter: 0; batch classifier loss: 0.288645; batch adversarial loss: 0.508695\n",
      "epoch 27; iter: 0; batch classifier loss: 0.245294; batch adversarial loss: 0.435853\n",
      "epoch 28; iter: 0; batch classifier loss: 0.314863; batch adversarial loss: 0.417316\n",
      "epoch 29; iter: 0; batch classifier loss: 0.175272; batch adversarial loss: 0.577228\n",
      "epoch 30; iter: 0; batch classifier loss: 0.225670; batch adversarial loss: 0.569205\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170891; batch adversarial loss: 0.506617\n",
      "epoch 32; iter: 0; batch classifier loss: 0.182049; batch adversarial loss: 0.459534\n",
      "epoch 33; iter: 0; batch classifier loss: 0.205137; batch adversarial loss: 0.404648\n",
      "epoch 34; iter: 0; batch classifier loss: 0.253963; batch adversarial loss: 0.401596\n",
      "epoch 35; iter: 0; batch classifier loss: 0.210434; batch adversarial loss: 0.457155\n",
      "epoch 36; iter: 0; batch classifier loss: 0.175278; batch adversarial loss: 0.497942\n",
      "epoch 37; iter: 0; batch classifier loss: 0.191233; batch adversarial loss: 0.436947\n",
      "epoch 38; iter: 0; batch classifier loss: 0.149164; batch adversarial loss: 0.469805\n",
      "epoch 39; iter: 0; batch classifier loss: 0.193039; batch adversarial loss: 0.492216\n",
      "epoch 40; iter: 0; batch classifier loss: 0.153811; batch adversarial loss: 0.442766\n",
      "epoch 41; iter: 0; batch classifier loss: 0.178605; batch adversarial loss: 0.476779\n",
      "epoch 42; iter: 0; batch classifier loss: 0.196313; batch adversarial loss: 0.548250\n",
      "epoch 43; iter: 0; batch classifier loss: 0.151976; batch adversarial loss: 0.406467\n",
      "epoch 44; iter: 0; batch classifier loss: 0.238882; batch adversarial loss: 0.470656\n",
      "epoch 45; iter: 0; batch classifier loss: 0.153916; batch adversarial loss: 0.480318\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112491; batch adversarial loss: 0.483229\n",
      "epoch 47; iter: 0; batch classifier loss: 0.177007; batch adversarial loss: 0.484858\n",
      "epoch 48; iter: 0; batch classifier loss: 0.207638; batch adversarial loss: 0.490501\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099871; batch adversarial loss: 0.488998\n",
      "epoch 50; iter: 0; batch classifier loss: 0.118701; batch adversarial loss: 0.475571\n",
      "epoch 51; iter: 0; batch classifier loss: 0.160671; batch adversarial loss: 0.411741\n",
      "epoch 52; iter: 0; batch classifier loss: 0.141061; batch adversarial loss: 0.436613\n",
      "epoch 53; iter: 0; batch classifier loss: 0.073015; batch adversarial loss: 0.448000\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079425; batch adversarial loss: 0.393073\n",
      "epoch 55; iter: 0; batch classifier loss: 0.159843; batch adversarial loss: 0.404043\n",
      "epoch 56; iter: 0; batch classifier loss: 0.085850; batch adversarial loss: 0.428239\n",
      "epoch 57; iter: 0; batch classifier loss: 0.119007; batch adversarial loss: 0.407769\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091110; batch adversarial loss: 0.385013\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087121; batch adversarial loss: 0.470328\n",
      "epoch 60; iter: 0; batch classifier loss: 0.085197; batch adversarial loss: 0.420571\n",
      "epoch 61; iter: 0; batch classifier loss: 0.095240; batch adversarial loss: 0.430904\n",
      "epoch 62; iter: 0; batch classifier loss: 0.132955; batch adversarial loss: 0.292366\n",
      "epoch 63; iter: 0; batch classifier loss: 0.065137; batch adversarial loss: 0.503964\n",
      "epoch 64; iter: 0; batch classifier loss: 0.058494; batch adversarial loss: 0.544401\n",
      "epoch 65; iter: 0; batch classifier loss: 0.111106; batch adversarial loss: 0.432470\n",
      "epoch 66; iter: 0; batch classifier loss: 0.063639; batch adversarial loss: 0.524257\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059447; batch adversarial loss: 0.507550\n",
      "epoch 68; iter: 0; batch classifier loss: 0.083535; batch adversarial loss: 0.467668\n",
      "epoch 69; iter: 0; batch classifier loss: 0.043320; batch adversarial loss: 0.545003\n",
      "epoch 70; iter: 0; batch classifier loss: 0.112156; batch adversarial loss: 0.470302\n",
      "epoch 71; iter: 0; batch classifier loss: 0.038010; batch adversarial loss: 0.514801\n",
      "epoch 72; iter: 0; batch classifier loss: 0.037814; batch adversarial loss: 0.503607\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085227; batch adversarial loss: 0.426452\n",
      "epoch 74; iter: 0; batch classifier loss: 0.040409; batch adversarial loss: 0.380776\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079695; batch adversarial loss: 0.460407\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063347; batch adversarial loss: 0.470708\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067373; batch adversarial loss: 0.443176\n",
      "epoch 78; iter: 0; batch classifier loss: 0.052235; batch adversarial loss: 0.373039\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076908; batch adversarial loss: 0.408194\n",
      "epoch 80; iter: 0; batch classifier loss: 0.058449; batch adversarial loss: 0.451174\n",
      "epoch 81; iter: 0; batch classifier loss: 0.072357; batch adversarial loss: 0.456931\n",
      "epoch 82; iter: 0; batch classifier loss: 0.054331; batch adversarial loss: 0.381494\n",
      "epoch 83; iter: 0; batch classifier loss: 0.097250; batch adversarial loss: 0.456768\n",
      "epoch 84; iter: 0; batch classifier loss: 0.033682; batch adversarial loss: 0.553863\n",
      "epoch 85; iter: 0; batch classifier loss: 0.033540; batch adversarial loss: 0.487274\n",
      "epoch 86; iter: 0; batch classifier loss: 0.029681; batch adversarial loss: 0.375447\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072864; batch adversarial loss: 0.480444\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042222; batch adversarial loss: 0.476586\n",
      "epoch 89; iter: 0; batch classifier loss: 0.028649; batch adversarial loss: 0.402597\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056885; batch adversarial loss: 0.407222\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062995; batch adversarial loss: 0.452713\n",
      "epoch 92; iter: 0; batch classifier loss: 0.061179; batch adversarial loss: 0.478868\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055766; batch adversarial loss: 0.456235\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077280; batch adversarial loss: 0.394493\n",
      "epoch 95; iter: 0; batch classifier loss: 0.029749; batch adversarial loss: 0.454151\n",
      "epoch 96; iter: 0; batch classifier loss: 0.053574; batch adversarial loss: 0.423248\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065406; batch adversarial loss: 0.415909\n",
      "epoch 98; iter: 0; batch classifier loss: 0.100740; batch adversarial loss: 0.497115\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037650; batch adversarial loss: 0.521903\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039893; batch adversarial loss: 0.456913\n",
      "epoch 101; iter: 0; batch classifier loss: 0.013525; batch adversarial loss: 0.444984\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044659; batch adversarial loss: 0.507493\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054029; batch adversarial loss: 0.427846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.016881; batch adversarial loss: 0.409389\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030363; batch adversarial loss: 0.466558\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040581; batch adversarial loss: 0.503427\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040307; batch adversarial loss: 0.448105\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057190; batch adversarial loss: 0.363084\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030277; batch adversarial loss: 0.453012\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040007; batch adversarial loss: 0.476849\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053600; batch adversarial loss: 0.551369\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038124; batch adversarial loss: 0.438864\n",
      "epoch 113; iter: 0; batch classifier loss: 0.009517; batch adversarial loss: 0.558016\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049208; batch adversarial loss: 0.500172\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021744; batch adversarial loss: 0.371325\n",
      "epoch 116; iter: 0; batch classifier loss: 0.017370; batch adversarial loss: 0.535958\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027847; batch adversarial loss: 0.430486\n",
      "epoch 118; iter: 0; batch classifier loss: 0.016871; batch adversarial loss: 0.555280\n",
      "epoch 119; iter: 0; batch classifier loss: 0.024852; batch adversarial loss: 0.501624\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027274; batch adversarial loss: 0.423307\n",
      "epoch 121; iter: 0; batch classifier loss: 0.022315; batch adversarial loss: 0.446014\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033298; batch adversarial loss: 0.534455\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027868; batch adversarial loss: 0.480993\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024767; batch adversarial loss: 0.430807\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041851; batch adversarial loss: 0.474335\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019965; batch adversarial loss: 0.394798\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030316; batch adversarial loss: 0.397261\n",
      "epoch 128; iter: 0; batch classifier loss: 0.011429; batch adversarial loss: 0.570648\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016977; batch adversarial loss: 0.466327\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056306; batch adversarial loss: 0.381722\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038591; batch adversarial loss: 0.443828\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049101; batch adversarial loss: 0.502340\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042636; batch adversarial loss: 0.479369\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015645; batch adversarial loss: 0.464247\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019880; batch adversarial loss: 0.589967\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019179; batch adversarial loss: 0.510361\n",
      "epoch 137; iter: 0; batch classifier loss: 0.013471; batch adversarial loss: 0.443341\n",
      "epoch 138; iter: 0; batch classifier loss: 0.009385; batch adversarial loss: 0.526973\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018475; batch adversarial loss: 0.413353\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032806; batch adversarial loss: 0.460017\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048202; batch adversarial loss: 0.454825\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049265; batch adversarial loss: 0.513292\n",
      "epoch 143; iter: 0; batch classifier loss: 0.006763; batch adversarial loss: 0.495513\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017219; batch adversarial loss: 0.417018\n",
      "epoch 145; iter: 0; batch classifier loss: 0.010158; batch adversarial loss: 0.447362\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017865; batch adversarial loss: 0.389675\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011058; batch adversarial loss: 0.442559\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016389; batch adversarial loss: 0.393815\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022821; batch adversarial loss: 0.434060\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027204; batch adversarial loss: 0.449800\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026699; batch adversarial loss: 0.406063\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045121; batch adversarial loss: 0.426924\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040245; batch adversarial loss: 0.513377\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019956; batch adversarial loss: 0.375877\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023231; batch adversarial loss: 0.445441\n",
      "epoch 156; iter: 0; batch classifier loss: 0.003206; batch adversarial loss: 0.420332\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009803; batch adversarial loss: 0.400538\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036597; batch adversarial loss: 0.430372\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011831; batch adversarial loss: 0.427763\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008139; batch adversarial loss: 0.482452\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009636; batch adversarial loss: 0.473723\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024924; batch adversarial loss: 0.459302\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026137; batch adversarial loss: 0.415892\n",
      "epoch 164; iter: 0; batch classifier loss: 0.008317; batch adversarial loss: 0.450341\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013625; batch adversarial loss: 0.392317\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016208; batch adversarial loss: 0.489994\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006188; batch adversarial loss: 0.445477\n",
      "epoch 168; iter: 0; batch classifier loss: 0.001931; batch adversarial loss: 0.457661\n",
      "epoch 169; iter: 0; batch classifier loss: 0.003276; batch adversarial loss: 0.455684\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036624; batch adversarial loss: 0.513534\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011152; batch adversarial loss: 0.360067\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020778; batch adversarial loss: 0.467966\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012073; batch adversarial loss: 0.506956\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006394; batch adversarial loss: 0.401134\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012717; batch adversarial loss: 0.393955\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009606; batch adversarial loss: 0.424022\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007960; batch adversarial loss: 0.431142\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025932; batch adversarial loss: 0.493683\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025225; batch adversarial loss: 0.375235\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016625; batch adversarial loss: 0.479522\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026501; batch adversarial loss: 0.367594\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036300; batch adversarial loss: 0.442193\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014912; batch adversarial loss: 0.499127\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004806; batch adversarial loss: 0.488558\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010778; batch adversarial loss: 0.422835\n",
      "epoch 186; iter: 0; batch classifier loss: 0.001984; batch adversarial loss: 0.491284\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007578; batch adversarial loss: 0.458623\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012044; batch adversarial loss: 0.489387\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014238; batch adversarial loss: 0.412383\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026841; batch adversarial loss: 0.473097\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007660; batch adversarial loss: 0.426025\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023756; batch adversarial loss: 0.444634\n",
      "epoch 193; iter: 0; batch classifier loss: 0.003838; batch adversarial loss: 0.447339\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013310; batch adversarial loss: 0.457972\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020626; batch adversarial loss: 0.420152\n",
      "epoch 196; iter: 0; batch classifier loss: 0.038604; batch adversarial loss: 0.460885\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021626; batch adversarial loss: 0.412235\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025654; batch adversarial loss: 0.478718\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015876; batch adversarial loss: 0.515130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.722404; batch adversarial loss: 0.922815\n",
      "epoch 1; iter: 0; batch classifier loss: 0.505724; batch adversarial loss: 0.934576\n",
      "epoch 2; iter: 0; batch classifier loss: 0.491897; batch adversarial loss: 0.872795\n",
      "epoch 3; iter: 0; batch classifier loss: 0.352173; batch adversarial loss: 0.854377\n",
      "epoch 4; iter: 0; batch classifier loss: 0.291269; batch adversarial loss: 0.772256\n",
      "epoch 5; iter: 0; batch classifier loss: 0.272829; batch adversarial loss: 0.785278\n",
      "epoch 6; iter: 0; batch classifier loss: 0.231423; batch adversarial loss: 0.709152\n",
      "epoch 7; iter: 0; batch classifier loss: 0.265840; batch adversarial loss: 0.658854\n",
      "epoch 8; iter: 0; batch classifier loss: 0.300732; batch adversarial loss: 0.624496\n",
      "epoch 9; iter: 0; batch classifier loss: 0.231682; batch adversarial loss: 0.622101\n",
      "epoch 10; iter: 0; batch classifier loss: 0.238240; batch adversarial loss: 0.593657\n",
      "epoch 11; iter: 0; batch classifier loss: 0.222120; batch adversarial loss: 0.616310\n",
      "epoch 12; iter: 0; batch classifier loss: 0.191844; batch adversarial loss: 0.552968\n",
      "epoch 13; iter: 0; batch classifier loss: 0.313466; batch adversarial loss: 0.512902\n",
      "epoch 14; iter: 0; batch classifier loss: 0.241357; batch adversarial loss: 0.548277\n",
      "epoch 15; iter: 0; batch classifier loss: 0.211825; batch adversarial loss: 0.579269\n",
      "epoch 16; iter: 0; batch classifier loss: 0.241922; batch adversarial loss: 0.474939\n",
      "epoch 17; iter: 0; batch classifier loss: 0.227861; batch adversarial loss: 0.541270\n",
      "epoch 18; iter: 0; batch classifier loss: 0.240350; batch adversarial loss: 0.485588\n",
      "epoch 19; iter: 0; batch classifier loss: 0.169707; batch adversarial loss: 0.461325\n",
      "epoch 20; iter: 0; batch classifier loss: 0.193588; batch adversarial loss: 0.526649\n",
      "epoch 21; iter: 0; batch classifier loss: 0.196686; batch adversarial loss: 0.512573\n",
      "epoch 22; iter: 0; batch classifier loss: 0.272570; batch adversarial loss: 0.453078\n",
      "epoch 23; iter: 0; batch classifier loss: 0.209805; batch adversarial loss: 0.439218\n",
      "epoch 24; iter: 0; batch classifier loss: 0.248981; batch adversarial loss: 0.477127\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209433; batch adversarial loss: 0.491990\n",
      "epoch 26; iter: 0; batch classifier loss: 0.201323; batch adversarial loss: 0.498058\n",
      "epoch 27; iter: 0; batch classifier loss: 0.225166; batch adversarial loss: 0.465249\n",
      "epoch 28; iter: 0; batch classifier loss: 0.186367; batch adversarial loss: 0.397387\n",
      "epoch 29; iter: 0; batch classifier loss: 0.192056; batch adversarial loss: 0.403889\n",
      "epoch 30; iter: 0; batch classifier loss: 0.170226; batch adversarial loss: 0.419699\n",
      "epoch 31; iter: 0; batch classifier loss: 0.158736; batch adversarial loss: 0.436588\n",
      "epoch 32; iter: 0; batch classifier loss: 0.221481; batch adversarial loss: 0.498125\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128236; batch adversarial loss: 0.386467\n",
      "epoch 34; iter: 0; batch classifier loss: 0.120290; batch adversarial loss: 0.377516\n",
      "epoch 35; iter: 0; batch classifier loss: 0.164263; batch adversarial loss: 0.476318\n",
      "epoch 36; iter: 0; batch classifier loss: 0.148660; batch adversarial loss: 0.499073\n",
      "epoch 37; iter: 0; batch classifier loss: 0.115310; batch adversarial loss: 0.413026\n",
      "epoch 38; iter: 0; batch classifier loss: 0.184991; batch adversarial loss: 0.474075\n",
      "epoch 39; iter: 0; batch classifier loss: 0.144358; batch adversarial loss: 0.404267\n",
      "epoch 40; iter: 0; batch classifier loss: 0.146539; batch adversarial loss: 0.472626\n",
      "epoch 41; iter: 0; batch classifier loss: 0.130014; batch adversarial loss: 0.388407\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113115; batch adversarial loss: 0.389270\n",
      "epoch 43; iter: 0; batch classifier loss: 0.111095; batch adversarial loss: 0.456682\n",
      "epoch 44; iter: 0; batch classifier loss: 0.102985; batch adversarial loss: 0.323150\n",
      "epoch 45; iter: 0; batch classifier loss: 0.115555; batch adversarial loss: 0.484319\n",
      "epoch 46; iter: 0; batch classifier loss: 0.106017; batch adversarial loss: 0.429894\n",
      "epoch 47; iter: 0; batch classifier loss: 0.135989; batch adversarial loss: 0.390424\n",
      "epoch 48; iter: 0; batch classifier loss: 0.112372; batch adversarial loss: 0.431528\n",
      "epoch 49; iter: 0; batch classifier loss: 0.120742; batch adversarial loss: 0.463568\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091620; batch adversarial loss: 0.428011\n",
      "epoch 51; iter: 0; batch classifier loss: 0.114488; batch adversarial loss: 0.432236\n",
      "epoch 52; iter: 0; batch classifier loss: 0.117188; batch adversarial loss: 0.441211\n",
      "epoch 53; iter: 0; batch classifier loss: 0.183217; batch adversarial loss: 0.456727\n",
      "epoch 54; iter: 0; batch classifier loss: 0.076364; batch adversarial loss: 0.424596\n",
      "epoch 55; iter: 0; batch classifier loss: 0.118202; batch adversarial loss: 0.365643\n",
      "epoch 56; iter: 0; batch classifier loss: 0.136196; batch adversarial loss: 0.391926\n",
      "epoch 57; iter: 0; batch classifier loss: 0.134112; batch adversarial loss: 0.370709\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101000; batch adversarial loss: 0.423394\n",
      "epoch 59; iter: 0; batch classifier loss: 0.125041; batch adversarial loss: 0.363756\n",
      "epoch 60; iter: 0; batch classifier loss: 0.143272; batch adversarial loss: 0.481427\n",
      "epoch 61; iter: 0; batch classifier loss: 0.120399; batch adversarial loss: 0.433624\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082788; batch adversarial loss: 0.506566\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089048; batch adversarial loss: 0.478507\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073999; batch adversarial loss: 0.450668\n",
      "epoch 65; iter: 0; batch classifier loss: 0.051368; batch adversarial loss: 0.378149\n",
      "epoch 66; iter: 0; batch classifier loss: 0.103346; batch adversarial loss: 0.343508\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106903; batch adversarial loss: 0.417603\n",
      "epoch 68; iter: 0; batch classifier loss: 0.117139; batch adversarial loss: 0.431035\n",
      "epoch 69; iter: 0; batch classifier loss: 0.091798; batch adversarial loss: 0.512657\n",
      "epoch 70; iter: 0; batch classifier loss: 0.105608; batch adversarial loss: 0.424338\n",
      "epoch 71; iter: 0; batch classifier loss: 0.053520; batch adversarial loss: 0.397190\n",
      "epoch 72; iter: 0; batch classifier loss: 0.150326; batch adversarial loss: 0.409989\n",
      "epoch 73; iter: 0; batch classifier loss: 0.066486; batch adversarial loss: 0.419881\n",
      "epoch 74; iter: 0; batch classifier loss: 0.093000; batch adversarial loss: 0.432019\n",
      "epoch 75; iter: 0; batch classifier loss: 0.107352; batch adversarial loss: 0.474916\n",
      "epoch 76; iter: 0; batch classifier loss: 0.056417; batch adversarial loss: 0.449576\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063103; batch adversarial loss: 0.479911\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085560; batch adversarial loss: 0.455392\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068229; batch adversarial loss: 0.458316\n",
      "epoch 80; iter: 0; batch classifier loss: 0.073532; batch adversarial loss: 0.414191\n",
      "epoch 81; iter: 0; batch classifier loss: 0.026438; batch adversarial loss: 0.383043\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091962; batch adversarial loss: 0.443271\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070486; batch adversarial loss: 0.362312\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085055; batch adversarial loss: 0.433643\n",
      "epoch 85; iter: 0; batch classifier loss: 0.103990; batch adversarial loss: 0.438040\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068378; batch adversarial loss: 0.445466\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057207; batch adversarial loss: 0.480725\n",
      "epoch 88; iter: 0; batch classifier loss: 0.086053; batch adversarial loss: 0.417711\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052646; batch adversarial loss: 0.470797\n",
      "epoch 90; iter: 0; batch classifier loss: 0.093348; batch adversarial loss: 0.415503\n",
      "epoch 91; iter: 0; batch classifier loss: 0.065781; batch adversarial loss: 0.359527\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060339; batch adversarial loss: 0.415709\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065434; batch adversarial loss: 0.423937\n",
      "epoch 94; iter: 0; batch classifier loss: 0.074954; batch adversarial loss: 0.454951\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064645; batch adversarial loss: 0.416108\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046815; batch adversarial loss: 0.480616\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044690; batch adversarial loss: 0.449235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.086151; batch adversarial loss: 0.440251\n",
      "epoch 99; iter: 0; batch classifier loss: 0.084285; batch adversarial loss: 0.511037\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075759; batch adversarial loss: 0.468548\n",
      "epoch 101; iter: 0; batch classifier loss: 0.081571; batch adversarial loss: 0.465298\n",
      "epoch 102; iter: 0; batch classifier loss: 0.082490; batch adversarial loss: 0.466838\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047348; batch adversarial loss: 0.417855\n",
      "epoch 104; iter: 0; batch classifier loss: 0.076864; batch adversarial loss: 0.504663\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060450; batch adversarial loss: 0.443054\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050932; batch adversarial loss: 0.378165\n",
      "epoch 107; iter: 0; batch classifier loss: 0.075338; batch adversarial loss: 0.364513\n",
      "epoch 108; iter: 0; batch classifier loss: 0.087772; batch adversarial loss: 0.411514\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048029; batch adversarial loss: 0.492325\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060000; batch adversarial loss: 0.429818\n",
      "epoch 111; iter: 0; batch classifier loss: 0.161006; batch adversarial loss: 0.462653\n",
      "epoch 112; iter: 0; batch classifier loss: 0.069889; batch adversarial loss: 0.473319\n",
      "epoch 113; iter: 0; batch classifier loss: 0.061939; batch adversarial loss: 0.406894\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047952; batch adversarial loss: 0.371251\n",
      "epoch 115; iter: 0; batch classifier loss: 0.104333; batch adversarial loss: 0.428760\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064613; batch adversarial loss: 0.440950\n",
      "epoch 117; iter: 0; batch classifier loss: 0.064212; batch adversarial loss: 0.453888\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063207; batch adversarial loss: 0.490737\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051694; batch adversarial loss: 0.460658\n",
      "epoch 120; iter: 0; batch classifier loss: 0.091920; batch adversarial loss: 0.442174\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065427; batch adversarial loss: 0.362909\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048042; batch adversarial loss: 0.558965\n",
      "epoch 123; iter: 0; batch classifier loss: 0.069490; batch adversarial loss: 0.406166\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048871; batch adversarial loss: 0.471414\n",
      "epoch 125; iter: 0; batch classifier loss: 0.060433; batch adversarial loss: 0.413848\n",
      "epoch 126; iter: 0; batch classifier loss: 0.086289; batch adversarial loss: 0.391085\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035846; batch adversarial loss: 0.414871\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055300; batch adversarial loss: 0.434522\n",
      "epoch 129; iter: 0; batch classifier loss: 0.044640; batch adversarial loss: 0.336510\n",
      "epoch 130; iter: 0; batch classifier loss: 0.079498; batch adversarial loss: 0.474186\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036904; batch adversarial loss: 0.508196\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040610; batch adversarial loss: 0.393799\n",
      "epoch 133; iter: 0; batch classifier loss: 0.075766; batch adversarial loss: 0.451842\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057392; batch adversarial loss: 0.523491\n",
      "epoch 135; iter: 0; batch classifier loss: 0.056715; batch adversarial loss: 0.444053\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044959; batch adversarial loss: 0.512812\n",
      "epoch 137; iter: 0; batch classifier loss: 0.078631; batch adversarial loss: 0.520886\n",
      "epoch 138; iter: 0; batch classifier loss: 0.084235; batch adversarial loss: 0.458576\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045062; batch adversarial loss: 0.482662\n",
      "epoch 140; iter: 0; batch classifier loss: 0.055369; batch adversarial loss: 0.523660\n",
      "epoch 141; iter: 0; batch classifier loss: 0.063579; batch adversarial loss: 0.453269\n",
      "epoch 142; iter: 0; batch classifier loss: 0.073015; batch adversarial loss: 0.443423\n",
      "epoch 143; iter: 0; batch classifier loss: 0.069578; batch adversarial loss: 0.498399\n",
      "epoch 144; iter: 0; batch classifier loss: 0.057591; batch adversarial loss: 0.503102\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039762; batch adversarial loss: 0.425214\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037000; batch adversarial loss: 0.479921\n",
      "epoch 147; iter: 0; batch classifier loss: 0.065750; batch adversarial loss: 0.440111\n",
      "epoch 148; iter: 0; batch classifier loss: 0.055679; batch adversarial loss: 0.443973\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034723; batch adversarial loss: 0.487002\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035504; batch adversarial loss: 0.512735\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012447; batch adversarial loss: 0.373719\n",
      "epoch 152; iter: 0; batch classifier loss: 0.061643; batch adversarial loss: 0.453709\n",
      "epoch 153; iter: 0; batch classifier loss: 0.060249; batch adversarial loss: 0.434193\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028415; batch adversarial loss: 0.333221\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037681; batch adversarial loss: 0.444899\n",
      "epoch 156; iter: 0; batch classifier loss: 0.091960; batch adversarial loss: 0.442709\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026738; batch adversarial loss: 0.473620\n",
      "epoch 158; iter: 0; batch classifier loss: 0.054223; batch adversarial loss: 0.393398\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025719; batch adversarial loss: 0.447796\n",
      "epoch 160; iter: 0; batch classifier loss: 0.042363; batch adversarial loss: 0.492112\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037947; batch adversarial loss: 0.352207\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028419; batch adversarial loss: 0.535699\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028898; batch adversarial loss: 0.374518\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030388; batch adversarial loss: 0.482959\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041724; batch adversarial loss: 0.480751\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025950; batch adversarial loss: 0.516941\n",
      "epoch 167; iter: 0; batch classifier loss: 0.046137; batch adversarial loss: 0.448968\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028189; batch adversarial loss: 0.409430\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019974; batch adversarial loss: 0.473842\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040189; batch adversarial loss: 0.483440\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025861; batch adversarial loss: 0.430959\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035346; batch adversarial loss: 0.448562\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018731; batch adversarial loss: 0.453741\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019849; batch adversarial loss: 0.428124\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030195; batch adversarial loss: 0.420145\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032311; batch adversarial loss: 0.488535\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046834; batch adversarial loss: 0.444627\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018343; batch adversarial loss: 0.477722\n",
      "epoch 179; iter: 0; batch classifier loss: 0.061229; batch adversarial loss: 0.517298\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037060; batch adversarial loss: 0.510837\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017302; batch adversarial loss: 0.539330\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009466; batch adversarial loss: 0.394426\n",
      "epoch 183; iter: 0; batch classifier loss: 0.040889; batch adversarial loss: 0.512105\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033588; batch adversarial loss: 0.456694\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018594; batch adversarial loss: 0.468028\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031527; batch adversarial loss: 0.517633\n",
      "epoch 187; iter: 0; batch classifier loss: 0.079337; batch adversarial loss: 0.545642\n",
      "epoch 188; iter: 0; batch classifier loss: 0.042953; batch adversarial loss: 0.526224\n",
      "epoch 189; iter: 0; batch classifier loss: 0.084614; batch adversarial loss: 0.568180\n",
      "epoch 190; iter: 0; batch classifier loss: 0.082259; batch adversarial loss: 0.520768\n",
      "epoch 191; iter: 0; batch classifier loss: 0.094351; batch adversarial loss: 0.557902\n",
      "epoch 192; iter: 0; batch classifier loss: 0.125899; batch adversarial loss: 0.625730\n",
      "epoch 193; iter: 0; batch classifier loss: 0.141473; batch adversarial loss: 0.635851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.083296; batch adversarial loss: 0.543980\n",
      "epoch 195; iter: 0; batch classifier loss: 0.107868; batch adversarial loss: 0.663325\n",
      "epoch 196; iter: 0; batch classifier loss: 0.139595; batch adversarial loss: 0.691888\n",
      "epoch 197; iter: 0; batch classifier loss: 0.103873; batch adversarial loss: 0.476922\n",
      "epoch 198; iter: 0; batch classifier loss: 0.155867; batch adversarial loss: 0.661488\n",
      "epoch 199; iter: 0; batch classifier loss: 0.146581; batch adversarial loss: 0.687499\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685784; batch adversarial loss: 0.558634\n",
      "epoch 1; iter: 0; batch classifier loss: 0.478412; batch adversarial loss: 0.598781\n",
      "epoch 2; iter: 0; batch classifier loss: 0.437824; batch adversarial loss: 0.605268\n",
      "epoch 3; iter: 0; batch classifier loss: 0.314411; batch adversarial loss: 0.576242\n",
      "epoch 4; iter: 0; batch classifier loss: 0.432952; batch adversarial loss: 0.569499\n",
      "epoch 5; iter: 0; batch classifier loss: 0.399611; batch adversarial loss: 0.583310\n",
      "epoch 6; iter: 0; batch classifier loss: 0.330989; batch adversarial loss: 0.586741\n",
      "epoch 7; iter: 0; batch classifier loss: 0.349765; batch adversarial loss: 0.577457\n",
      "epoch 8; iter: 0; batch classifier loss: 0.304279; batch adversarial loss: 0.592337\n",
      "epoch 9; iter: 0; batch classifier loss: 0.344096; batch adversarial loss: 0.519784\n",
      "epoch 10; iter: 0; batch classifier loss: 0.367567; batch adversarial loss: 0.527507\n",
      "epoch 11; iter: 0; batch classifier loss: 0.367366; batch adversarial loss: 0.500317\n",
      "epoch 12; iter: 0; batch classifier loss: 0.255892; batch adversarial loss: 0.497583\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340371; batch adversarial loss: 0.552852\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236504; batch adversarial loss: 0.524371\n",
      "epoch 15; iter: 0; batch classifier loss: 0.241092; batch adversarial loss: 0.477542\n",
      "epoch 16; iter: 0; batch classifier loss: 0.240045; batch adversarial loss: 0.427102\n",
      "epoch 17; iter: 0; batch classifier loss: 0.215796; batch adversarial loss: 0.516066\n",
      "epoch 18; iter: 0; batch classifier loss: 0.159176; batch adversarial loss: 0.540681\n",
      "epoch 19; iter: 0; batch classifier loss: 0.222752; batch adversarial loss: 0.473068\n",
      "epoch 20; iter: 0; batch classifier loss: 0.183419; batch adversarial loss: 0.520886\n",
      "epoch 21; iter: 0; batch classifier loss: 0.197258; batch adversarial loss: 0.526231\n",
      "epoch 22; iter: 0; batch classifier loss: 0.186118; batch adversarial loss: 0.485984\n",
      "epoch 23; iter: 0; batch classifier loss: 0.194908; batch adversarial loss: 0.458198\n",
      "epoch 24; iter: 0; batch classifier loss: 0.166588; batch adversarial loss: 0.530078\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179063; batch adversarial loss: 0.459538\n",
      "epoch 26; iter: 0; batch classifier loss: 0.183216; batch adversarial loss: 0.526887\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151543; batch adversarial loss: 0.462256\n",
      "epoch 28; iter: 0; batch classifier loss: 0.208360; batch adversarial loss: 0.504548\n",
      "epoch 29; iter: 0; batch classifier loss: 0.107697; batch adversarial loss: 0.419452\n",
      "epoch 30; iter: 0; batch classifier loss: 0.164923; batch adversarial loss: 0.495117\n",
      "epoch 31; iter: 0; batch classifier loss: 0.160186; batch adversarial loss: 0.442929\n",
      "epoch 32; iter: 0; batch classifier loss: 0.125097; batch adversarial loss: 0.436302\n",
      "epoch 33; iter: 0; batch classifier loss: 0.124894; batch adversarial loss: 0.422578\n",
      "epoch 34; iter: 0; batch classifier loss: 0.158500; batch adversarial loss: 0.489955\n",
      "epoch 35; iter: 0; batch classifier loss: 0.166674; batch adversarial loss: 0.518652\n",
      "epoch 36; iter: 0; batch classifier loss: 0.152506; batch adversarial loss: 0.450252\n",
      "epoch 37; iter: 0; batch classifier loss: 0.098565; batch adversarial loss: 0.541046\n",
      "epoch 38; iter: 0; batch classifier loss: 0.097200; batch adversarial loss: 0.425840\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143466; batch adversarial loss: 0.479165\n",
      "epoch 40; iter: 0; batch classifier loss: 0.157022; batch adversarial loss: 0.399609\n",
      "epoch 41; iter: 0; batch classifier loss: 0.166599; batch adversarial loss: 0.532060\n",
      "epoch 42; iter: 0; batch classifier loss: 0.089958; batch adversarial loss: 0.502653\n",
      "epoch 43; iter: 0; batch classifier loss: 0.125160; batch adversarial loss: 0.496418\n",
      "epoch 44; iter: 0; batch classifier loss: 0.099672; batch adversarial loss: 0.422722\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108840; batch adversarial loss: 0.418253\n",
      "epoch 46; iter: 0; batch classifier loss: 0.080468; batch adversarial loss: 0.480708\n",
      "epoch 47; iter: 0; batch classifier loss: 0.122020; batch adversarial loss: 0.541404\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141888; batch adversarial loss: 0.471030\n",
      "epoch 49; iter: 0; batch classifier loss: 0.126573; batch adversarial loss: 0.417026\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108876; batch adversarial loss: 0.441919\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092416; batch adversarial loss: 0.430005\n",
      "epoch 52; iter: 0; batch classifier loss: 0.130712; batch adversarial loss: 0.494366\n",
      "epoch 53; iter: 0; batch classifier loss: 0.129062; batch adversarial loss: 0.473894\n",
      "epoch 54; iter: 0; batch classifier loss: 0.158087; batch adversarial loss: 0.481306\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098069; batch adversarial loss: 0.460902\n",
      "epoch 56; iter: 0; batch classifier loss: 0.144588; batch adversarial loss: 0.434204\n",
      "epoch 57; iter: 0; batch classifier loss: 0.130290; batch adversarial loss: 0.406881\n",
      "epoch 58; iter: 0; batch classifier loss: 0.128072; batch adversarial loss: 0.406560\n",
      "epoch 59; iter: 0; batch classifier loss: 0.122396; batch adversarial loss: 0.452420\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105272; batch adversarial loss: 0.582530\n",
      "epoch 61; iter: 0; batch classifier loss: 0.100203; batch adversarial loss: 0.499602\n",
      "epoch 62; iter: 0; batch classifier loss: 0.102828; batch adversarial loss: 0.466562\n",
      "epoch 63; iter: 0; batch classifier loss: 0.142110; batch adversarial loss: 0.468227\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083371; batch adversarial loss: 0.540427\n",
      "epoch 65; iter: 0; batch classifier loss: 0.144906; batch adversarial loss: 0.421371\n",
      "epoch 66; iter: 0; batch classifier loss: 0.094882; batch adversarial loss: 0.557328\n",
      "epoch 67; iter: 0; batch classifier loss: 0.145481; batch adversarial loss: 0.599789\n",
      "epoch 68; iter: 0; batch classifier loss: 0.131099; batch adversarial loss: 0.370717\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103700; batch adversarial loss: 0.462216\n",
      "epoch 70; iter: 0; batch classifier loss: 0.155994; batch adversarial loss: 0.474690\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089490; batch adversarial loss: 0.469678\n",
      "epoch 72; iter: 0; batch classifier loss: 0.106789; batch adversarial loss: 0.464920\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065644; batch adversarial loss: 0.495260\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089690; batch adversarial loss: 0.512878\n",
      "epoch 75; iter: 0; batch classifier loss: 0.122129; batch adversarial loss: 0.344085\n",
      "epoch 76; iter: 0; batch classifier loss: 0.114674; batch adversarial loss: 0.478269\n",
      "epoch 77; iter: 0; batch classifier loss: 0.083124; batch adversarial loss: 0.519311\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090254; batch adversarial loss: 0.360205\n",
      "epoch 79; iter: 0; batch classifier loss: 0.132137; batch adversarial loss: 0.516315\n",
      "epoch 80; iter: 0; batch classifier loss: 0.116563; batch adversarial loss: 0.456844\n",
      "epoch 81; iter: 0; batch classifier loss: 0.086153; batch adversarial loss: 0.399021\n",
      "epoch 82; iter: 0; batch classifier loss: 0.116748; batch adversarial loss: 0.460419\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070839; batch adversarial loss: 0.414564\n",
      "epoch 84; iter: 0; batch classifier loss: 0.096749; batch adversarial loss: 0.515296\n",
      "epoch 85; iter: 0; batch classifier loss: 0.150148; batch adversarial loss: 0.451336\n",
      "epoch 86; iter: 0; batch classifier loss: 0.090306; batch adversarial loss: 0.424639\n",
      "epoch 87; iter: 0; batch classifier loss: 0.086482; batch adversarial loss: 0.485848\n",
      "epoch 88; iter: 0; batch classifier loss: 0.111115; batch adversarial loss: 0.493656\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081399; batch adversarial loss: 0.454201\n",
      "epoch 90; iter: 0; batch classifier loss: 0.097205; batch adversarial loss: 0.411762\n",
      "epoch 91; iter: 0; batch classifier loss: 0.115098; batch adversarial loss: 0.575210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.120949; batch adversarial loss: 0.478988\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050505; batch adversarial loss: 0.551002\n",
      "epoch 94; iter: 0; batch classifier loss: 0.122353; batch adversarial loss: 0.450477\n",
      "epoch 95; iter: 0; batch classifier loss: 0.092161; batch adversarial loss: 0.493818\n",
      "epoch 96; iter: 0; batch classifier loss: 0.053579; batch adversarial loss: 0.407782\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077632; batch adversarial loss: 0.370085\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067481; batch adversarial loss: 0.464406\n",
      "epoch 99; iter: 0; batch classifier loss: 0.034298; batch adversarial loss: 0.552674\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064900; batch adversarial loss: 0.495965\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047898; batch adversarial loss: 0.503619\n",
      "epoch 102; iter: 0; batch classifier loss: 0.075383; batch adversarial loss: 0.460044\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056126; batch adversarial loss: 0.442898\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057247; batch adversarial loss: 0.400184\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084361; batch adversarial loss: 0.512599\n",
      "epoch 106; iter: 0; batch classifier loss: 0.048929; batch adversarial loss: 0.426234\n",
      "epoch 107; iter: 0; batch classifier loss: 0.071666; batch adversarial loss: 0.501773\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052096; batch adversarial loss: 0.432056\n",
      "epoch 109; iter: 0; batch classifier loss: 0.091901; batch adversarial loss: 0.474729\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069247; batch adversarial loss: 0.526235\n",
      "epoch 111; iter: 0; batch classifier loss: 0.072825; batch adversarial loss: 0.477433\n",
      "epoch 112; iter: 0; batch classifier loss: 0.068381; batch adversarial loss: 0.329524\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051252; batch adversarial loss: 0.395755\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029938; batch adversarial loss: 0.435015\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043614; batch adversarial loss: 0.492679\n",
      "epoch 116; iter: 0; batch classifier loss: 0.025850; batch adversarial loss: 0.544836\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055819; batch adversarial loss: 0.479697\n",
      "epoch 118; iter: 0; batch classifier loss: 0.072615; batch adversarial loss: 0.422336\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030757; batch adversarial loss: 0.562599\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057986; batch adversarial loss: 0.493317\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035422; batch adversarial loss: 0.456028\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026073; batch adversarial loss: 0.424987\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037671; batch adversarial loss: 0.448789\n",
      "epoch 124; iter: 0; batch classifier loss: 0.060871; batch adversarial loss: 0.436327\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068822; batch adversarial loss: 0.423934\n",
      "epoch 126; iter: 0; batch classifier loss: 0.053098; batch adversarial loss: 0.400733\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032724; batch adversarial loss: 0.509964\n",
      "epoch 128; iter: 0; batch classifier loss: 0.072217; batch adversarial loss: 0.373445\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036540; batch adversarial loss: 0.516385\n",
      "epoch 130; iter: 0; batch classifier loss: 0.095287; batch adversarial loss: 0.491291\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026121; batch adversarial loss: 0.556128\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027238; batch adversarial loss: 0.416564\n",
      "epoch 133; iter: 0; batch classifier loss: 0.011601; batch adversarial loss: 0.481092\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036582; batch adversarial loss: 0.532395\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050521; batch adversarial loss: 0.375379\n",
      "epoch 136; iter: 0; batch classifier loss: 0.053197; batch adversarial loss: 0.494151\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027864; batch adversarial loss: 0.431253\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044546; batch adversarial loss: 0.435644\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038517; batch adversarial loss: 0.492610\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033826; batch adversarial loss: 0.538328\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026784; batch adversarial loss: 0.518400\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037077; batch adversarial loss: 0.526020\n",
      "epoch 143; iter: 0; batch classifier loss: 0.073170; batch adversarial loss: 0.552847\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030482; batch adversarial loss: 0.400071\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031526; batch adversarial loss: 0.451770\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025160; batch adversarial loss: 0.416877\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023907; batch adversarial loss: 0.436852\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026657; batch adversarial loss: 0.495986\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024803; batch adversarial loss: 0.538739\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021951; batch adversarial loss: 0.552365\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017575; batch adversarial loss: 0.356288\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014915; batch adversarial loss: 0.452051\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008905; batch adversarial loss: 0.445216\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037965; batch adversarial loss: 0.441410\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037829; batch adversarial loss: 0.437665\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035899; batch adversarial loss: 0.422282\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032582; batch adversarial loss: 0.454768\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044976; batch adversarial loss: 0.328892\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014392; batch adversarial loss: 0.434427\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026048; batch adversarial loss: 0.449459\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022313; batch adversarial loss: 0.425210\n",
      "epoch 162; iter: 0; batch classifier loss: 0.054100; batch adversarial loss: 0.444004\n",
      "epoch 163; iter: 0; batch classifier loss: 0.052506; batch adversarial loss: 0.436866\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034930; batch adversarial loss: 0.569594\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028738; batch adversarial loss: 0.424642\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029617; batch adversarial loss: 0.372521\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015302; batch adversarial loss: 0.476425\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029679; batch adversarial loss: 0.500235\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020831; batch adversarial loss: 0.455450\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025952; batch adversarial loss: 0.437103\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016668; batch adversarial loss: 0.432007\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014860; batch adversarial loss: 0.503558\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038409; batch adversarial loss: 0.374958\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041759; batch adversarial loss: 0.498063\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031521; batch adversarial loss: 0.459027\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013271; batch adversarial loss: 0.496243\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018861; batch adversarial loss: 0.503849\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036317; batch adversarial loss: 0.429666\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043004; batch adversarial loss: 0.542410\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028709; batch adversarial loss: 0.407380\n",
      "epoch 181; iter: 0; batch classifier loss: 0.042903; batch adversarial loss: 0.505688\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026603; batch adversarial loss: 0.418356\n",
      "epoch 183; iter: 0; batch classifier loss: 0.045322; batch adversarial loss: 0.430500\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006941; batch adversarial loss: 0.460614\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021480; batch adversarial loss: 0.466079\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025848; batch adversarial loss: 0.471514\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030831; batch adversarial loss: 0.429453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.014283; batch adversarial loss: 0.475949\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019558; batch adversarial loss: 0.435541\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034964; batch adversarial loss: 0.473356\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006245; batch adversarial loss: 0.470006\n",
      "epoch 192; iter: 0; batch classifier loss: 0.053279; batch adversarial loss: 0.456079\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012740; batch adversarial loss: 0.459946\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016341; batch adversarial loss: 0.487030\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009602; batch adversarial loss: 0.491527\n",
      "epoch 196; iter: 0; batch classifier loss: 0.041785; batch adversarial loss: 0.540918\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018101; batch adversarial loss: 0.362545\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007880; batch adversarial loss: 0.416964\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015148; batch adversarial loss: 0.446719\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695760; batch adversarial loss: 0.564865\n",
      "epoch 1; iter: 0; batch classifier loss: 0.456690; batch adversarial loss: 0.608445\n",
      "epoch 2; iter: 0; batch classifier loss: 0.442080; batch adversarial loss: 0.575835\n",
      "epoch 3; iter: 0; batch classifier loss: 0.321608; batch adversarial loss: 0.570744\n",
      "epoch 4; iter: 0; batch classifier loss: 0.392163; batch adversarial loss: 0.578318\n",
      "epoch 5; iter: 0; batch classifier loss: 0.320984; batch adversarial loss: 0.499365\n",
      "epoch 6; iter: 0; batch classifier loss: 0.323907; batch adversarial loss: 0.560037\n",
      "epoch 7; iter: 0; batch classifier loss: 0.285017; batch adversarial loss: 0.559153\n",
      "epoch 8; iter: 0; batch classifier loss: 0.263169; batch adversarial loss: 0.477561\n",
      "epoch 9; iter: 0; batch classifier loss: 0.308761; batch adversarial loss: 0.499230\n",
      "epoch 10; iter: 0; batch classifier loss: 0.224001; batch adversarial loss: 0.546836\n",
      "epoch 11; iter: 0; batch classifier loss: 0.251892; batch adversarial loss: 0.494770\n",
      "epoch 12; iter: 0; batch classifier loss: 0.295094; batch adversarial loss: 0.415669\n",
      "epoch 13; iter: 0; batch classifier loss: 0.214826; batch adversarial loss: 0.490416\n",
      "epoch 14; iter: 0; batch classifier loss: 0.188571; batch adversarial loss: 0.566540\n",
      "epoch 15; iter: 0; batch classifier loss: 0.252798; batch adversarial loss: 0.529513\n",
      "epoch 16; iter: 0; batch classifier loss: 0.224414; batch adversarial loss: 0.561376\n",
      "epoch 17; iter: 0; batch classifier loss: 0.215529; batch adversarial loss: 0.454964\n",
      "epoch 18; iter: 0; batch classifier loss: 0.249952; batch adversarial loss: 0.486279\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237275; batch adversarial loss: 0.425428\n",
      "epoch 20; iter: 0; batch classifier loss: 0.293936; batch adversarial loss: 0.435440\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234699; batch adversarial loss: 0.464452\n",
      "epoch 22; iter: 0; batch classifier loss: 0.239902; batch adversarial loss: 0.544855\n",
      "epoch 23; iter: 0; batch classifier loss: 0.321515; batch adversarial loss: 0.496695\n",
      "epoch 24; iter: 0; batch classifier loss: 0.370312; batch adversarial loss: 0.441115\n",
      "epoch 25; iter: 0; batch classifier loss: 0.308468; batch adversarial loss: 0.513040\n",
      "epoch 26; iter: 0; batch classifier loss: 0.285909; batch adversarial loss: 0.456052\n",
      "epoch 27; iter: 0; batch classifier loss: 0.405402; batch adversarial loss: 0.493180\n",
      "epoch 28; iter: 0; batch classifier loss: 0.165584; batch adversarial loss: 0.462148\n",
      "epoch 29; iter: 0; batch classifier loss: 0.137533; batch adversarial loss: 0.589485\n",
      "epoch 30; iter: 0; batch classifier loss: 0.179676; batch adversarial loss: 0.500994\n",
      "epoch 31; iter: 0; batch classifier loss: 0.155264; batch adversarial loss: 0.462495\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154201; batch adversarial loss: 0.412545\n",
      "epoch 33; iter: 0; batch classifier loss: 0.161656; batch adversarial loss: 0.526356\n",
      "epoch 34; iter: 0; batch classifier loss: 0.145856; batch adversarial loss: 0.434655\n",
      "epoch 35; iter: 0; batch classifier loss: 0.109480; batch adversarial loss: 0.439321\n",
      "epoch 36; iter: 0; batch classifier loss: 0.116615; batch adversarial loss: 0.489965\n",
      "epoch 37; iter: 0; batch classifier loss: 0.170493; batch adversarial loss: 0.478850\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107141; batch adversarial loss: 0.404616\n",
      "epoch 39; iter: 0; batch classifier loss: 0.087145; batch adversarial loss: 0.512206\n",
      "epoch 40; iter: 0; batch classifier loss: 0.127741; batch adversarial loss: 0.438880\n",
      "epoch 41; iter: 0; batch classifier loss: 0.093901; batch adversarial loss: 0.442549\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131126; batch adversarial loss: 0.512274\n",
      "epoch 43; iter: 0; batch classifier loss: 0.094584; batch adversarial loss: 0.442408\n",
      "epoch 44; iter: 0; batch classifier loss: 0.089733; batch adversarial loss: 0.460201\n",
      "epoch 45; iter: 0; batch classifier loss: 0.096245; batch adversarial loss: 0.523350\n",
      "epoch 46; iter: 0; batch classifier loss: 0.088227; batch adversarial loss: 0.426227\n",
      "epoch 47; iter: 0; batch classifier loss: 0.099235; batch adversarial loss: 0.464672\n",
      "epoch 48; iter: 0; batch classifier loss: 0.108367; batch adversarial loss: 0.443940\n",
      "epoch 49; iter: 0; batch classifier loss: 0.083517; batch adversarial loss: 0.469548\n",
      "epoch 50; iter: 0; batch classifier loss: 0.080018; batch adversarial loss: 0.452632\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106453; batch adversarial loss: 0.402255\n",
      "epoch 52; iter: 0; batch classifier loss: 0.133360; batch adversarial loss: 0.485771\n",
      "epoch 53; iter: 0; batch classifier loss: 0.087335; batch adversarial loss: 0.379376\n",
      "epoch 54; iter: 0; batch classifier loss: 0.111394; batch adversarial loss: 0.488663\n",
      "epoch 55; iter: 0; batch classifier loss: 0.176280; batch adversarial loss: 0.519011\n",
      "epoch 56; iter: 0; batch classifier loss: 0.074885; batch adversarial loss: 0.456733\n",
      "epoch 57; iter: 0; batch classifier loss: 0.121764; batch adversarial loss: 0.399113\n",
      "epoch 58; iter: 0; batch classifier loss: 0.052095; batch adversarial loss: 0.501722\n",
      "epoch 59; iter: 0; batch classifier loss: 0.120455; batch adversarial loss: 0.477757\n",
      "epoch 60; iter: 0; batch classifier loss: 0.114535; batch adversarial loss: 0.489093\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103575; batch adversarial loss: 0.459648\n",
      "epoch 62; iter: 0; batch classifier loss: 0.142992; batch adversarial loss: 0.494547\n",
      "epoch 63; iter: 0; batch classifier loss: 0.111352; batch adversarial loss: 0.504962\n",
      "epoch 64; iter: 0; batch classifier loss: 0.124352; batch adversarial loss: 0.463896\n",
      "epoch 65; iter: 0; batch classifier loss: 0.102613; batch adversarial loss: 0.428328\n",
      "epoch 66; iter: 0; batch classifier loss: 0.169013; batch adversarial loss: 0.467081\n",
      "epoch 67; iter: 0; batch classifier loss: 0.155449; batch adversarial loss: 0.414630\n",
      "epoch 68; iter: 0; batch classifier loss: 0.186946; batch adversarial loss: 0.390909\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072722; batch adversarial loss: 0.477237\n",
      "epoch 70; iter: 0; batch classifier loss: 0.125126; batch adversarial loss: 0.458650\n",
      "epoch 71; iter: 0; batch classifier loss: 0.141016; batch adversarial loss: 0.451056\n",
      "epoch 72; iter: 0; batch classifier loss: 0.135922; batch adversarial loss: 0.429161\n",
      "epoch 73; iter: 0; batch classifier loss: 0.125105; batch adversarial loss: 0.424046\n",
      "epoch 74; iter: 0; batch classifier loss: 0.127464; batch adversarial loss: 0.426064\n",
      "epoch 75; iter: 0; batch classifier loss: 0.095822; batch adversarial loss: 0.433365\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077810; batch adversarial loss: 0.444399\n",
      "epoch 77; iter: 0; batch classifier loss: 0.147224; batch adversarial loss: 0.528921\n",
      "epoch 78; iter: 0; batch classifier loss: 0.159483; batch adversarial loss: 0.425832\n",
      "epoch 79; iter: 0; batch classifier loss: 0.179725; batch adversarial loss: 0.463292\n",
      "epoch 80; iter: 0; batch classifier loss: 0.130605; batch adversarial loss: 0.439592\n",
      "epoch 81; iter: 0; batch classifier loss: 0.106214; batch adversarial loss: 0.405693\n",
      "epoch 82; iter: 0; batch classifier loss: 0.120048; batch adversarial loss: 0.409528\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086825; batch adversarial loss: 0.506708\n",
      "epoch 84; iter: 0; batch classifier loss: 0.137067; batch adversarial loss: 0.473072\n",
      "epoch 85; iter: 0; batch classifier loss: 0.141507; batch adversarial loss: 0.466567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.122143; batch adversarial loss: 0.444236\n",
      "epoch 87; iter: 0; batch classifier loss: 0.085279; batch adversarial loss: 0.425594\n",
      "epoch 88; iter: 0; batch classifier loss: 0.150491; batch adversarial loss: 0.414995\n",
      "epoch 89; iter: 0; batch classifier loss: 0.110434; batch adversarial loss: 0.437160\n",
      "epoch 90; iter: 0; batch classifier loss: 0.088214; batch adversarial loss: 0.402034\n",
      "epoch 91; iter: 0; batch classifier loss: 0.104017; batch adversarial loss: 0.453422\n",
      "epoch 92; iter: 0; batch classifier loss: 0.113047; batch adversarial loss: 0.486409\n",
      "epoch 93; iter: 0; batch classifier loss: 0.114236; batch adversarial loss: 0.480660\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064401; batch adversarial loss: 0.472489\n",
      "epoch 95; iter: 0; batch classifier loss: 0.062938; batch adversarial loss: 0.502999\n",
      "epoch 96; iter: 0; batch classifier loss: 0.116773; batch adversarial loss: 0.479377\n",
      "epoch 97; iter: 0; batch classifier loss: 0.112469; batch adversarial loss: 0.458655\n",
      "epoch 98; iter: 0; batch classifier loss: 0.104826; batch adversarial loss: 0.490889\n",
      "epoch 99; iter: 0; batch classifier loss: 0.105228; batch adversarial loss: 0.449483\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076974; batch adversarial loss: 0.465440\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071209; batch adversarial loss: 0.440838\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059983; batch adversarial loss: 0.460378\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076034; batch adversarial loss: 0.515822\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071151; batch adversarial loss: 0.410459\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075446; batch adversarial loss: 0.407481\n",
      "epoch 106; iter: 0; batch classifier loss: 0.074720; batch adversarial loss: 0.518761\n",
      "epoch 107; iter: 0; batch classifier loss: 0.101030; batch adversarial loss: 0.423501\n",
      "epoch 108; iter: 0; batch classifier loss: 0.061869; batch adversarial loss: 0.419510\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071840; batch adversarial loss: 0.466090\n",
      "epoch 110; iter: 0; batch classifier loss: 0.088558; batch adversarial loss: 0.450790\n",
      "epoch 111; iter: 0; batch classifier loss: 0.094988; batch adversarial loss: 0.429790\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060573; batch adversarial loss: 0.388723\n",
      "epoch 113; iter: 0; batch classifier loss: 0.081664; batch adversarial loss: 0.420131\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072731; batch adversarial loss: 0.427674\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027107; batch adversarial loss: 0.516597\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055517; batch adversarial loss: 0.499059\n",
      "epoch 117; iter: 0; batch classifier loss: 0.019397; batch adversarial loss: 0.437498\n",
      "epoch 118; iter: 0; batch classifier loss: 0.085241; batch adversarial loss: 0.431602\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046620; batch adversarial loss: 0.545130\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057267; batch adversarial loss: 0.509500\n",
      "epoch 121; iter: 0; batch classifier loss: 0.059491; batch adversarial loss: 0.477439\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046745; batch adversarial loss: 0.464611\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067137; batch adversarial loss: 0.469004\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025529; batch adversarial loss: 0.542433\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061379; batch adversarial loss: 0.481194\n",
      "epoch 126; iter: 0; batch classifier loss: 0.078126; batch adversarial loss: 0.492160\n",
      "epoch 127; iter: 0; batch classifier loss: 0.059232; batch adversarial loss: 0.490648\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063516; batch adversarial loss: 0.435754\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032280; batch adversarial loss: 0.429947\n",
      "epoch 130; iter: 0; batch classifier loss: 0.064824; batch adversarial loss: 0.468606\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020810; batch adversarial loss: 0.451032\n",
      "epoch 132; iter: 0; batch classifier loss: 0.065617; batch adversarial loss: 0.473576\n",
      "epoch 133; iter: 0; batch classifier loss: 0.067520; batch adversarial loss: 0.546118\n",
      "epoch 134; iter: 0; batch classifier loss: 0.012884; batch adversarial loss: 0.442840\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060352; batch adversarial loss: 0.406636\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035578; batch adversarial loss: 0.492673\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029812; batch adversarial loss: 0.466765\n",
      "epoch 138; iter: 0; batch classifier loss: 0.058489; batch adversarial loss: 0.407917\n",
      "epoch 139; iter: 0; batch classifier loss: 0.055742; batch adversarial loss: 0.412861\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022052; batch adversarial loss: 0.479843\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036996; batch adversarial loss: 0.506451\n",
      "epoch 142; iter: 0; batch classifier loss: 0.060334; batch adversarial loss: 0.374664\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038828; batch adversarial loss: 0.364186\n",
      "epoch 144; iter: 0; batch classifier loss: 0.076540; batch adversarial loss: 0.455915\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035432; batch adversarial loss: 0.556820\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041751; batch adversarial loss: 0.513301\n",
      "epoch 147; iter: 0; batch classifier loss: 0.053636; batch adversarial loss: 0.412706\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042660; batch adversarial loss: 0.534385\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027159; batch adversarial loss: 0.379735\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026856; batch adversarial loss: 0.403227\n",
      "epoch 151; iter: 0; batch classifier loss: 0.049161; batch adversarial loss: 0.426174\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026040; batch adversarial loss: 0.484400\n",
      "epoch 153; iter: 0; batch classifier loss: 0.047382; batch adversarial loss: 0.379533\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043692; batch adversarial loss: 0.474659\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036172; batch adversarial loss: 0.431625\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034192; batch adversarial loss: 0.454834\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021367; batch adversarial loss: 0.340951\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019582; batch adversarial loss: 0.473046\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036846; batch adversarial loss: 0.388861\n",
      "epoch 160; iter: 0; batch classifier loss: 0.092037; batch adversarial loss: 0.384637\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039233; batch adversarial loss: 0.416949\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027678; batch adversarial loss: 0.490685\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013312; batch adversarial loss: 0.388896\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043411; batch adversarial loss: 0.449965\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044621; batch adversarial loss: 0.403893\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038117; batch adversarial loss: 0.437732\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036417; batch adversarial loss: 0.380901\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015907; batch adversarial loss: 0.375065\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014101; batch adversarial loss: 0.402006\n",
      "epoch 170; iter: 0; batch classifier loss: 0.053495; batch adversarial loss: 0.527056\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009584; batch adversarial loss: 0.434822\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013975; batch adversarial loss: 0.459386\n",
      "epoch 173; iter: 0; batch classifier loss: 0.049465; batch adversarial loss: 0.389672\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013025; batch adversarial loss: 0.456095\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022627; batch adversarial loss: 0.456629\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026029; batch adversarial loss: 0.358111\n",
      "epoch 177; iter: 0; batch classifier loss: 0.040112; batch adversarial loss: 0.543761\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028056; batch adversarial loss: 0.492367\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024739; batch adversarial loss: 0.445208\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031251; batch adversarial loss: 0.470747\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032587; batch adversarial loss: 0.449555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.027882; batch adversarial loss: 0.386619\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026440; batch adversarial loss: 0.422546\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024854; batch adversarial loss: 0.449949\n",
      "epoch 185; iter: 0; batch classifier loss: 0.057710; batch adversarial loss: 0.522041\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023577; batch adversarial loss: 0.436319\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012754; batch adversarial loss: 0.434424\n",
      "epoch 188; iter: 0; batch classifier loss: 0.036076; batch adversarial loss: 0.532156\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030076; batch adversarial loss: 0.410104\n",
      "epoch 190; iter: 0; batch classifier loss: 0.043376; batch adversarial loss: 0.354019\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011109; batch adversarial loss: 0.463048\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018350; batch adversarial loss: 0.431572\n",
      "epoch 193; iter: 0; batch classifier loss: 0.042316; batch adversarial loss: 0.515346\n",
      "epoch 194; iter: 0; batch classifier loss: 0.043885; batch adversarial loss: 0.434958\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026774; batch adversarial loss: 0.435657\n",
      "epoch 196; iter: 0; batch classifier loss: 0.040626; batch adversarial loss: 0.513175\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012148; batch adversarial loss: 0.444931\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017748; batch adversarial loss: 0.477804\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016080; batch adversarial loss: 0.585804\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686401; batch adversarial loss: 0.571995\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489634; batch adversarial loss: 0.614036\n",
      "epoch 2; iter: 0; batch classifier loss: 0.372663; batch adversarial loss: 0.650959\n",
      "epoch 3; iter: 0; batch classifier loss: 0.496803; batch adversarial loss: 0.574904\n",
      "epoch 4; iter: 0; batch classifier loss: 0.281336; batch adversarial loss: 0.570829\n",
      "epoch 5; iter: 0; batch classifier loss: 0.356096; batch adversarial loss: 0.581949\n",
      "epoch 6; iter: 0; batch classifier loss: 0.317235; batch adversarial loss: 0.514574\n",
      "epoch 7; iter: 0; batch classifier loss: 0.332126; batch adversarial loss: 0.573379\n",
      "epoch 8; iter: 0; batch classifier loss: 0.402768; batch adversarial loss: 0.536601\n",
      "epoch 9; iter: 0; batch classifier loss: 0.261784; batch adversarial loss: 0.493436\n",
      "epoch 10; iter: 0; batch classifier loss: 0.224670; batch adversarial loss: 0.554640\n",
      "epoch 11; iter: 0; batch classifier loss: 0.300524; batch adversarial loss: 0.530179\n",
      "epoch 12; iter: 0; batch classifier loss: 0.256085; batch adversarial loss: 0.513226\n",
      "epoch 13; iter: 0; batch classifier loss: 0.251135; batch adversarial loss: 0.522511\n",
      "epoch 14; iter: 0; batch classifier loss: 0.179417; batch adversarial loss: 0.523840\n",
      "epoch 15; iter: 0; batch classifier loss: 0.185882; batch adversarial loss: 0.559868\n",
      "epoch 16; iter: 0; batch classifier loss: 0.235540; batch adversarial loss: 0.507322\n",
      "epoch 17; iter: 0; batch classifier loss: 0.226681; batch adversarial loss: 0.460900\n",
      "epoch 18; iter: 0; batch classifier loss: 0.254106; batch adversarial loss: 0.484523\n",
      "epoch 19; iter: 0; batch classifier loss: 0.190882; batch adversarial loss: 0.530655\n",
      "epoch 20; iter: 0; batch classifier loss: 0.162517; batch adversarial loss: 0.472713\n",
      "epoch 21; iter: 0; batch classifier loss: 0.183453; batch adversarial loss: 0.484380\n",
      "epoch 22; iter: 0; batch classifier loss: 0.168332; batch adversarial loss: 0.592902\n",
      "epoch 23; iter: 0; batch classifier loss: 0.162196; batch adversarial loss: 0.511820\n",
      "epoch 24; iter: 0; batch classifier loss: 0.167757; batch adversarial loss: 0.435175\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177115; batch adversarial loss: 0.495911\n",
      "epoch 26; iter: 0; batch classifier loss: 0.218082; batch adversarial loss: 0.515281\n",
      "epoch 27; iter: 0; batch classifier loss: 0.179431; batch adversarial loss: 0.480079\n",
      "epoch 28; iter: 0; batch classifier loss: 0.190398; batch adversarial loss: 0.433489\n",
      "epoch 29; iter: 0; batch classifier loss: 0.183457; batch adversarial loss: 0.397751\n",
      "epoch 30; iter: 0; batch classifier loss: 0.199776; batch adversarial loss: 0.371847\n",
      "epoch 31; iter: 0; batch classifier loss: 0.146458; batch adversarial loss: 0.475423\n",
      "epoch 32; iter: 0; batch classifier loss: 0.151921; batch adversarial loss: 0.477814\n",
      "epoch 33; iter: 0; batch classifier loss: 0.173325; batch adversarial loss: 0.391311\n",
      "epoch 34; iter: 0; batch classifier loss: 0.172439; batch adversarial loss: 0.511496\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160153; batch adversarial loss: 0.440602\n",
      "epoch 36; iter: 0; batch classifier loss: 0.122577; batch adversarial loss: 0.502691\n",
      "epoch 37; iter: 0; batch classifier loss: 0.170840; batch adversarial loss: 0.473580\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117804; batch adversarial loss: 0.552074\n",
      "epoch 39; iter: 0; batch classifier loss: 0.190861; batch adversarial loss: 0.453641\n",
      "epoch 40; iter: 0; batch classifier loss: 0.139301; batch adversarial loss: 0.496733\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146403; batch adversarial loss: 0.421445\n",
      "epoch 42; iter: 0; batch classifier loss: 0.126970; batch adversarial loss: 0.478813\n",
      "epoch 43; iter: 0; batch classifier loss: 0.182553; batch adversarial loss: 0.398659\n",
      "epoch 44; iter: 0; batch classifier loss: 0.180037; batch adversarial loss: 0.439970\n",
      "epoch 45; iter: 0; batch classifier loss: 0.201721; batch adversarial loss: 0.422867\n",
      "epoch 46; iter: 0; batch classifier loss: 0.157275; batch adversarial loss: 0.372123\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095869; batch adversarial loss: 0.475081\n",
      "epoch 48; iter: 0; batch classifier loss: 0.154470; batch adversarial loss: 0.445634\n",
      "epoch 49; iter: 0; batch classifier loss: 0.127958; batch adversarial loss: 0.447118\n",
      "epoch 50; iter: 0; batch classifier loss: 0.151555; batch adversarial loss: 0.413133\n",
      "epoch 51; iter: 0; batch classifier loss: 0.158615; batch adversarial loss: 0.539313\n",
      "epoch 52; iter: 0; batch classifier loss: 0.210428; batch adversarial loss: 0.443179\n",
      "epoch 53; iter: 0; batch classifier loss: 0.187779; batch adversarial loss: 0.408863\n",
      "epoch 54; iter: 0; batch classifier loss: 0.182545; batch adversarial loss: 0.483717\n",
      "epoch 55; iter: 0; batch classifier loss: 0.180945; batch adversarial loss: 0.412024\n",
      "epoch 56; iter: 0; batch classifier loss: 0.166008; batch adversarial loss: 0.435867\n",
      "epoch 57; iter: 0; batch classifier loss: 0.204148; batch adversarial loss: 0.470443\n",
      "epoch 58; iter: 0; batch classifier loss: 0.171730; batch adversarial loss: 0.459494\n",
      "epoch 59; iter: 0; batch classifier loss: 0.144939; batch adversarial loss: 0.460495\n",
      "epoch 60; iter: 0; batch classifier loss: 0.166820; batch adversarial loss: 0.433658\n",
      "epoch 61; iter: 0; batch classifier loss: 0.176714; batch adversarial loss: 0.495690\n",
      "epoch 62; iter: 0; batch classifier loss: 0.127578; batch adversarial loss: 0.440008\n",
      "epoch 63; iter: 0; batch classifier loss: 0.167267; batch adversarial loss: 0.484868\n",
      "epoch 64; iter: 0; batch classifier loss: 0.157779; batch adversarial loss: 0.409530\n",
      "epoch 65; iter: 0; batch classifier loss: 0.212430; batch adversarial loss: 0.434893\n",
      "epoch 66; iter: 0; batch classifier loss: 0.201565; batch adversarial loss: 0.459061\n",
      "epoch 67; iter: 0; batch classifier loss: 0.140795; batch adversarial loss: 0.423245\n",
      "epoch 68; iter: 0; batch classifier loss: 0.232745; batch adversarial loss: 0.515319\n",
      "epoch 69; iter: 0; batch classifier loss: 0.233258; batch adversarial loss: 0.446568\n",
      "epoch 70; iter: 0; batch classifier loss: 0.181767; batch adversarial loss: 0.434563\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099910; batch adversarial loss: 0.422488\n",
      "epoch 72; iter: 0; batch classifier loss: 0.149990; batch adversarial loss: 0.385287\n",
      "epoch 73; iter: 0; batch classifier loss: 0.195620; batch adversarial loss: 0.425173\n",
      "epoch 74; iter: 0; batch classifier loss: 0.165957; batch adversarial loss: 0.494009\n",
      "epoch 75; iter: 0; batch classifier loss: 0.228410; batch adversarial loss: 0.447343\n",
      "epoch 76; iter: 0; batch classifier loss: 0.172741; batch adversarial loss: 0.446644\n",
      "epoch 77; iter: 0; batch classifier loss: 0.185793; batch adversarial loss: 0.471730\n",
      "epoch 78; iter: 0; batch classifier loss: 0.225120; batch adversarial loss: 0.483811\n",
      "epoch 79; iter: 0; batch classifier loss: 0.124986; batch adversarial loss: 0.495102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.142295; batch adversarial loss: 0.459375\n",
      "epoch 81; iter: 0; batch classifier loss: 0.102853; batch adversarial loss: 0.422623\n",
      "epoch 82; iter: 0; batch classifier loss: 0.196117; batch adversarial loss: 0.434947\n",
      "epoch 83; iter: 0; batch classifier loss: 0.205770; batch adversarial loss: 0.324148\n",
      "epoch 84; iter: 0; batch classifier loss: 0.186837; batch adversarial loss: 0.493338\n",
      "epoch 85; iter: 0; batch classifier loss: 0.137461; batch adversarial loss: 0.458016\n",
      "epoch 86; iter: 0; batch classifier loss: 0.206108; batch adversarial loss: 0.435120\n",
      "epoch 87; iter: 0; batch classifier loss: 0.124051; batch adversarial loss: 0.385548\n",
      "epoch 88; iter: 0; batch classifier loss: 0.205322; batch adversarial loss: 0.398254\n",
      "epoch 89; iter: 0; batch classifier loss: 0.171707; batch adversarial loss: 0.591962\n",
      "epoch 90; iter: 0; batch classifier loss: 0.154481; batch adversarial loss: 0.496213\n",
      "epoch 91; iter: 0; batch classifier loss: 0.134720; batch adversarial loss: 0.422243\n",
      "epoch 92; iter: 0; batch classifier loss: 0.194633; batch adversarial loss: 0.457986\n",
      "epoch 93; iter: 0; batch classifier loss: 0.170719; batch adversarial loss: 0.469674\n",
      "epoch 94; iter: 0; batch classifier loss: 0.161838; batch adversarial loss: 0.520960\n",
      "epoch 95; iter: 0; batch classifier loss: 0.195523; batch adversarial loss: 0.518933\n",
      "epoch 96; iter: 0; batch classifier loss: 0.201565; batch adversarial loss: 0.496511\n",
      "epoch 97; iter: 0; batch classifier loss: 0.165968; batch adversarial loss: 0.483971\n",
      "epoch 98; iter: 0; batch classifier loss: 0.147244; batch adversarial loss: 0.472547\n",
      "epoch 99; iter: 0; batch classifier loss: 0.143122; batch adversarial loss: 0.422534\n",
      "epoch 100; iter: 0; batch classifier loss: 0.152273; batch adversarial loss: 0.457154\n",
      "epoch 101; iter: 0; batch classifier loss: 0.122990; batch adversarial loss: 0.371565\n",
      "epoch 102; iter: 0; batch classifier loss: 0.173634; batch adversarial loss: 0.459359\n",
      "epoch 103; iter: 0; batch classifier loss: 0.092658; batch adversarial loss: 0.508432\n",
      "epoch 104; iter: 0; batch classifier loss: 0.114697; batch adversarial loss: 0.554336\n",
      "epoch 105; iter: 0; batch classifier loss: 0.185958; batch adversarial loss: 0.497343\n",
      "epoch 106; iter: 0; batch classifier loss: 0.171396; batch adversarial loss: 0.447525\n",
      "epoch 107; iter: 0; batch classifier loss: 0.174086; batch adversarial loss: 0.399712\n",
      "epoch 108; iter: 0; batch classifier loss: 0.173499; batch adversarial loss: 0.493120\n",
      "epoch 109; iter: 0; batch classifier loss: 0.158859; batch adversarial loss: 0.530347\n",
      "epoch 110; iter: 0; batch classifier loss: 0.109685; batch adversarial loss: 0.444967\n",
      "epoch 111; iter: 0; batch classifier loss: 0.116673; batch adversarial loss: 0.398679\n",
      "epoch 112; iter: 0; batch classifier loss: 0.094671; batch adversarial loss: 0.480288\n",
      "epoch 113; iter: 0; batch classifier loss: 0.143632; batch adversarial loss: 0.456071\n",
      "epoch 114; iter: 0; batch classifier loss: 0.132854; batch adversarial loss: 0.489973\n",
      "epoch 115; iter: 0; batch classifier loss: 0.099673; batch adversarial loss: 0.416548\n",
      "epoch 116; iter: 0; batch classifier loss: 0.107111; batch adversarial loss: 0.368359\n",
      "epoch 117; iter: 0; batch classifier loss: 0.089658; batch adversarial loss: 0.510791\n",
      "epoch 118; iter: 0; batch classifier loss: 0.072650; batch adversarial loss: 0.515862\n",
      "epoch 119; iter: 0; batch classifier loss: 0.074806; batch adversarial loss: 0.403127\n",
      "epoch 120; iter: 0; batch classifier loss: 0.075440; batch adversarial loss: 0.431504\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050473; batch adversarial loss: 0.601680\n",
      "epoch 122; iter: 0; batch classifier loss: 0.075372; batch adversarial loss: 0.425199\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067186; batch adversarial loss: 0.496908\n",
      "epoch 124; iter: 0; batch classifier loss: 0.028435; batch adversarial loss: 0.594627\n",
      "epoch 125; iter: 0; batch classifier loss: 0.085416; batch adversarial loss: 0.417869\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044431; batch adversarial loss: 0.432194\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048994; batch adversarial loss: 0.388619\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038393; batch adversarial loss: 0.488580\n",
      "epoch 129; iter: 0; batch classifier loss: 0.083969; batch adversarial loss: 0.414733\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040023; batch adversarial loss: 0.542632\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030377; batch adversarial loss: 0.392763\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047735; batch adversarial loss: 0.453125\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031973; batch adversarial loss: 0.404159\n",
      "epoch 134; iter: 0; batch classifier loss: 0.063800; batch adversarial loss: 0.518872\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029027; batch adversarial loss: 0.511035\n",
      "epoch 136; iter: 0; batch classifier loss: 0.060262; batch adversarial loss: 0.416486\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032023; batch adversarial loss: 0.434198\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030935; batch adversarial loss: 0.425857\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036652; batch adversarial loss: 0.405944\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034427; batch adversarial loss: 0.455280\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033975; batch adversarial loss: 0.499535\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022438; batch adversarial loss: 0.473871\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029891; batch adversarial loss: 0.432100\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048061; batch adversarial loss: 0.416652\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042763; batch adversarial loss: 0.474166\n",
      "epoch 146; iter: 0; batch classifier loss: 0.046049; batch adversarial loss: 0.552203\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050337; batch adversarial loss: 0.439771\n",
      "epoch 148; iter: 0; batch classifier loss: 0.050754; batch adversarial loss: 0.416084\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038071; batch adversarial loss: 0.497668\n",
      "epoch 150; iter: 0; batch classifier loss: 0.049029; batch adversarial loss: 0.405346\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020306; batch adversarial loss: 0.426453\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027230; batch adversarial loss: 0.420121\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021370; batch adversarial loss: 0.543259\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038130; batch adversarial loss: 0.545919\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044493; batch adversarial loss: 0.534814\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016437; batch adversarial loss: 0.412877\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015736; batch adversarial loss: 0.479465\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035030; batch adversarial loss: 0.469129\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038991; batch adversarial loss: 0.454932\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031379; batch adversarial loss: 0.393219\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032663; batch adversarial loss: 0.418297\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010027; batch adversarial loss: 0.432724\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024139; batch adversarial loss: 0.499781\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035542; batch adversarial loss: 0.433025\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033203; batch adversarial loss: 0.433203\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031879; batch adversarial loss: 0.394589\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017725; batch adversarial loss: 0.416818\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012302; batch adversarial loss: 0.405781\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022080; batch adversarial loss: 0.463337\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026608; batch adversarial loss: 0.426588\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012657; batch adversarial loss: 0.428068\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014782; batch adversarial loss: 0.441831\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029726; batch adversarial loss: 0.470455\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012234; batch adversarial loss: 0.389528\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032306; batch adversarial loss: 0.401949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.015833; batch adversarial loss: 0.446939\n",
      "epoch 177; iter: 0; batch classifier loss: 0.040056; batch adversarial loss: 0.439516\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017908; batch adversarial loss: 0.490530\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034510; batch adversarial loss: 0.478260\n",
      "epoch 180; iter: 0; batch classifier loss: 0.005378; batch adversarial loss: 0.586033\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028857; batch adversarial loss: 0.459308\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028232; batch adversarial loss: 0.378821\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015450; batch adversarial loss: 0.475018\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009871; batch adversarial loss: 0.459850\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021201; batch adversarial loss: 0.451533\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020820; batch adversarial loss: 0.453437\n",
      "epoch 187; iter: 0; batch classifier loss: 0.038006; batch adversarial loss: 0.469888\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027551; batch adversarial loss: 0.554395\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014495; batch adversarial loss: 0.368585\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031220; batch adversarial loss: 0.469295\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022855; batch adversarial loss: 0.491217\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022758; batch adversarial loss: 0.414807\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014015; batch adversarial loss: 0.457094\n",
      "epoch 194; iter: 0; batch classifier loss: 0.055489; batch adversarial loss: 0.437508\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023099; batch adversarial loss: 0.340797\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015520; batch adversarial loss: 0.468397\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020299; batch adversarial loss: 0.441724\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022294; batch adversarial loss: 0.406632\n",
      "epoch 199; iter: 0; batch classifier loss: 0.048545; batch adversarial loss: 0.431348\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703505; batch adversarial loss: 0.530041\n",
      "epoch 1; iter: 0; batch classifier loss: 0.432375; batch adversarial loss: 0.589751\n",
      "epoch 2; iter: 0; batch classifier loss: 0.387533; batch adversarial loss: 0.560595\n",
      "epoch 3; iter: 0; batch classifier loss: 0.370082; batch adversarial loss: 0.564219\n",
      "epoch 4; iter: 0; batch classifier loss: 0.466921; batch adversarial loss: 0.583090\n",
      "epoch 5; iter: 0; batch classifier loss: 0.407775; batch adversarial loss: 0.626083\n",
      "epoch 6; iter: 0; batch classifier loss: 0.430881; batch adversarial loss: 0.546372\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529875; batch adversarial loss: 0.562701\n",
      "epoch 8; iter: 0; batch classifier loss: 0.476834; batch adversarial loss: 0.568711\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499310; batch adversarial loss: 0.604252\n",
      "epoch 10; iter: 0; batch classifier loss: 0.667510; batch adversarial loss: 0.570082\n",
      "epoch 11; iter: 0; batch classifier loss: 0.594689; batch adversarial loss: 0.552463\n",
      "epoch 12; iter: 0; batch classifier loss: 0.440329; batch adversarial loss: 0.490526\n",
      "epoch 13; iter: 0; batch classifier loss: 0.349081; batch adversarial loss: 0.462519\n",
      "epoch 14; iter: 0; batch classifier loss: 0.320752; batch adversarial loss: 0.413750\n",
      "epoch 15; iter: 0; batch classifier loss: 0.231182; batch adversarial loss: 0.489024\n",
      "epoch 16; iter: 0; batch classifier loss: 0.325178; batch adversarial loss: 0.464679\n",
      "epoch 17; iter: 0; batch classifier loss: 0.231517; batch adversarial loss: 0.411752\n",
      "epoch 18; iter: 0; batch classifier loss: 0.276201; batch adversarial loss: 0.483643\n",
      "epoch 19; iter: 0; batch classifier loss: 0.243147; batch adversarial loss: 0.493861\n",
      "epoch 20; iter: 0; batch classifier loss: 0.193618; batch adversarial loss: 0.449095\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202486; batch adversarial loss: 0.429749\n",
      "epoch 22; iter: 0; batch classifier loss: 0.167215; batch adversarial loss: 0.458859\n",
      "epoch 23; iter: 0; batch classifier loss: 0.144885; batch adversarial loss: 0.437537\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182161; batch adversarial loss: 0.412417\n",
      "epoch 25; iter: 0; batch classifier loss: 0.138656; batch adversarial loss: 0.453458\n",
      "epoch 26; iter: 0; batch classifier loss: 0.139637; batch adversarial loss: 0.507846\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181060; batch adversarial loss: 0.430314\n",
      "epoch 28; iter: 0; batch classifier loss: 0.149920; batch adversarial loss: 0.419339\n",
      "epoch 29; iter: 0; batch classifier loss: 0.184259; batch adversarial loss: 0.549056\n",
      "epoch 30; iter: 0; batch classifier loss: 0.170361; batch adversarial loss: 0.481292\n",
      "epoch 31; iter: 0; batch classifier loss: 0.194748; batch adversarial loss: 0.472165\n",
      "epoch 32; iter: 0; batch classifier loss: 0.136102; batch adversarial loss: 0.406890\n",
      "epoch 33; iter: 0; batch classifier loss: 0.115385; batch adversarial loss: 0.441748\n",
      "epoch 34; iter: 0; batch classifier loss: 0.163322; batch adversarial loss: 0.464275\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121686; batch adversarial loss: 0.514806\n",
      "epoch 36; iter: 0; batch classifier loss: 0.115868; batch adversarial loss: 0.466468\n",
      "epoch 37; iter: 0; batch classifier loss: 0.162701; batch adversarial loss: 0.563153\n",
      "epoch 38; iter: 0; batch classifier loss: 0.133380; batch adversarial loss: 0.451867\n",
      "epoch 39; iter: 0; batch classifier loss: 0.165911; batch adversarial loss: 0.389805\n",
      "epoch 40; iter: 0; batch classifier loss: 0.109130; batch adversarial loss: 0.459436\n",
      "epoch 41; iter: 0; batch classifier loss: 0.120075; batch adversarial loss: 0.402104\n",
      "epoch 42; iter: 0; batch classifier loss: 0.133153; batch adversarial loss: 0.364081\n",
      "epoch 43; iter: 0; batch classifier loss: 0.094687; batch adversarial loss: 0.392511\n",
      "epoch 44; iter: 0; batch classifier loss: 0.129139; batch adversarial loss: 0.467926\n",
      "epoch 45; iter: 0; batch classifier loss: 0.094168; batch adversarial loss: 0.381756\n",
      "epoch 46; iter: 0; batch classifier loss: 0.073007; batch adversarial loss: 0.428677\n",
      "epoch 47; iter: 0; batch classifier loss: 0.129358; batch adversarial loss: 0.451651\n",
      "epoch 48; iter: 0; batch classifier loss: 0.114446; batch adversarial loss: 0.455025\n",
      "epoch 49; iter: 0; batch classifier loss: 0.112920; batch adversarial loss: 0.473109\n",
      "epoch 50; iter: 0; batch classifier loss: 0.135425; batch adversarial loss: 0.469409\n",
      "epoch 51; iter: 0; batch classifier loss: 0.113684; batch adversarial loss: 0.413325\n",
      "epoch 52; iter: 0; batch classifier loss: 0.131984; batch adversarial loss: 0.508656\n",
      "epoch 53; iter: 0; batch classifier loss: 0.114326; batch adversarial loss: 0.349728\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090081; batch adversarial loss: 0.474119\n",
      "epoch 55; iter: 0; batch classifier loss: 0.069026; batch adversarial loss: 0.423198\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098986; batch adversarial loss: 0.388711\n",
      "epoch 57; iter: 0; batch classifier loss: 0.116945; batch adversarial loss: 0.510814\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101169; batch adversarial loss: 0.375577\n",
      "epoch 59; iter: 0; batch classifier loss: 0.142735; batch adversarial loss: 0.375278\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095286; batch adversarial loss: 0.466785\n",
      "epoch 61; iter: 0; batch classifier loss: 0.081251; batch adversarial loss: 0.517370\n",
      "epoch 62; iter: 0; batch classifier loss: 0.107197; batch adversarial loss: 0.421635\n",
      "epoch 63; iter: 0; batch classifier loss: 0.119435; batch adversarial loss: 0.365782\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072118; batch adversarial loss: 0.433009\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075243; batch adversarial loss: 0.446602\n",
      "epoch 66; iter: 0; batch classifier loss: 0.100600; batch adversarial loss: 0.412125\n",
      "epoch 67; iter: 0; batch classifier loss: 0.205961; batch adversarial loss: 0.463356\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078373; batch adversarial loss: 0.476059\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072395; batch adversarial loss: 0.473204\n",
      "epoch 70; iter: 0; batch classifier loss: 0.097645; batch adversarial loss: 0.420761\n",
      "epoch 71; iter: 0; batch classifier loss: 0.065094; batch adversarial loss: 0.498843\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081458; batch adversarial loss: 0.400988\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075288; batch adversarial loss: 0.435911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.068605; batch adversarial loss: 0.401031\n",
      "epoch 75; iter: 0; batch classifier loss: 0.050248; batch adversarial loss: 0.334521\n",
      "epoch 76; iter: 0; batch classifier loss: 0.048805; batch adversarial loss: 0.412114\n",
      "epoch 77; iter: 0; batch classifier loss: 0.149405; batch adversarial loss: 0.413637\n",
      "epoch 78; iter: 0; batch classifier loss: 0.033581; batch adversarial loss: 0.413313\n",
      "epoch 79; iter: 0; batch classifier loss: 0.120190; batch adversarial loss: 0.386126\n",
      "epoch 80; iter: 0; batch classifier loss: 0.071267; batch adversarial loss: 0.455983\n",
      "epoch 81; iter: 0; batch classifier loss: 0.048374; batch adversarial loss: 0.413455\n",
      "epoch 82; iter: 0; batch classifier loss: 0.047297; batch adversarial loss: 0.448770\n",
      "epoch 83; iter: 0; batch classifier loss: 0.060074; batch adversarial loss: 0.429986\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060984; batch adversarial loss: 0.329647\n",
      "epoch 85; iter: 0; batch classifier loss: 0.082778; batch adversarial loss: 0.442551\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053983; batch adversarial loss: 0.383968\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053459; batch adversarial loss: 0.381901\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056159; batch adversarial loss: 0.487740\n",
      "epoch 89; iter: 0; batch classifier loss: 0.067847; batch adversarial loss: 0.428974\n",
      "epoch 90; iter: 0; batch classifier loss: 0.133814; batch adversarial loss: 0.445774\n",
      "epoch 91; iter: 0; batch classifier loss: 0.097913; batch adversarial loss: 0.417217\n",
      "epoch 92; iter: 0; batch classifier loss: 0.078020; batch adversarial loss: 0.471264\n",
      "epoch 93; iter: 0; batch classifier loss: 0.068823; batch adversarial loss: 0.461640\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079390; batch adversarial loss: 0.430138\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057592; batch adversarial loss: 0.502333\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044130; batch adversarial loss: 0.399129\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044139; batch adversarial loss: 0.463930\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048451; batch adversarial loss: 0.484491\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053713; batch adversarial loss: 0.385496\n",
      "epoch 100; iter: 0; batch classifier loss: 0.081304; batch adversarial loss: 0.488544\n",
      "epoch 101; iter: 0; batch classifier loss: 0.074134; batch adversarial loss: 0.500261\n",
      "epoch 102; iter: 0; batch classifier loss: 0.016071; batch adversarial loss: 0.381767\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064924; batch adversarial loss: 0.341301\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056404; batch adversarial loss: 0.442769\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031897; batch adversarial loss: 0.443518\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047982; batch adversarial loss: 0.346719\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025585; batch adversarial loss: 0.368813\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049412; batch adversarial loss: 0.456310\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053143; batch adversarial loss: 0.428205\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039167; batch adversarial loss: 0.427046\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030926; batch adversarial loss: 0.446536\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063181; batch adversarial loss: 0.397935\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049641; batch adversarial loss: 0.435529\n",
      "epoch 114; iter: 0; batch classifier loss: 0.092951; batch adversarial loss: 0.465003\n",
      "epoch 115; iter: 0; batch classifier loss: 0.072900; batch adversarial loss: 0.413652\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030695; batch adversarial loss: 0.432821\n",
      "epoch 117; iter: 0; batch classifier loss: 0.077526; batch adversarial loss: 0.422873\n",
      "epoch 118; iter: 0; batch classifier loss: 0.015007; batch adversarial loss: 0.417324\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036841; batch adversarial loss: 0.332245\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048297; batch adversarial loss: 0.386046\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052247; batch adversarial loss: 0.447160\n",
      "epoch 122; iter: 0; batch classifier loss: 0.020188; batch adversarial loss: 0.430610\n",
      "epoch 123; iter: 0; batch classifier loss: 0.085517; batch adversarial loss: 0.427431\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059251; batch adversarial loss: 0.379236\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028150; batch adversarial loss: 0.504833\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035959; batch adversarial loss: 0.388383\n",
      "epoch 127; iter: 0; batch classifier loss: 0.012268; batch adversarial loss: 0.404600\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018815; batch adversarial loss: 0.403356\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033540; batch adversarial loss: 0.461618\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045143; batch adversarial loss: 0.471708\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026807; batch adversarial loss: 0.466163\n",
      "epoch 132; iter: 0; batch classifier loss: 0.013938; batch adversarial loss: 0.452844\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040178; batch adversarial loss: 0.389285\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057586; batch adversarial loss: 0.450209\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018396; batch adversarial loss: 0.463771\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043153; batch adversarial loss: 0.383948\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032055; batch adversarial loss: 0.376405\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022033; batch adversarial loss: 0.421683\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049272; batch adversarial loss: 0.439659\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051940; batch adversarial loss: 0.429453\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029653; batch adversarial loss: 0.468763\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036353; batch adversarial loss: 0.488907\n",
      "epoch 143; iter: 0; batch classifier loss: 0.049332; batch adversarial loss: 0.407050\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040197; batch adversarial loss: 0.447922\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034089; batch adversarial loss: 0.436901\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019700; batch adversarial loss: 0.402799\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019055; batch adversarial loss: 0.539066\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017406; batch adversarial loss: 0.407369\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033870; batch adversarial loss: 0.434385\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014061; batch adversarial loss: 0.410137\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042165; batch adversarial loss: 0.418113\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022926; batch adversarial loss: 0.436455\n",
      "epoch 153; iter: 0; batch classifier loss: 0.053595; batch adversarial loss: 0.370112\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037455; batch adversarial loss: 0.545321\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023111; batch adversarial loss: 0.451263\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018589; batch adversarial loss: 0.494255\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019851; batch adversarial loss: 0.477144\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009427; batch adversarial loss: 0.468042\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024265; batch adversarial loss: 0.363031\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044518; batch adversarial loss: 0.478197\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019894; batch adversarial loss: 0.455290\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011053; batch adversarial loss: 0.399761\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033355; batch adversarial loss: 0.451029\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014252; batch adversarial loss: 0.397283\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018281; batch adversarial loss: 0.384446\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024755; batch adversarial loss: 0.419077\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012142; batch adversarial loss: 0.422919\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013631; batch adversarial loss: 0.318949\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026592; batch adversarial loss: 0.465194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.038275; batch adversarial loss: 0.458716\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015655; batch adversarial loss: 0.428953\n",
      "epoch 172; iter: 0; batch classifier loss: 0.048825; batch adversarial loss: 0.403248\n",
      "epoch 173; iter: 0; batch classifier loss: 0.004859; batch adversarial loss: 0.503116\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024487; batch adversarial loss: 0.419780\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023082; batch adversarial loss: 0.432202\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029459; batch adversarial loss: 0.416959\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021614; batch adversarial loss: 0.445416\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033077; batch adversarial loss: 0.391954\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014744; batch adversarial loss: 0.446756\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014145; batch adversarial loss: 0.449754\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009301; batch adversarial loss: 0.422628\n",
      "epoch 182; iter: 0; batch classifier loss: 0.049893; batch adversarial loss: 0.401950\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026876; batch adversarial loss: 0.453988\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016361; batch adversarial loss: 0.347185\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015129; batch adversarial loss: 0.497401\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033404; batch adversarial loss: 0.441088\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031807; batch adversarial loss: 0.452979\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011165; batch adversarial loss: 0.330378\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013387; batch adversarial loss: 0.477076\n",
      "epoch 190; iter: 0; batch classifier loss: 0.045930; batch adversarial loss: 0.499595\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015818; batch adversarial loss: 0.386666\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008125; batch adversarial loss: 0.435579\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021369; batch adversarial loss: 0.476460\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018689; batch adversarial loss: 0.499958\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011002; batch adversarial loss: 0.461609\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029981; batch adversarial loss: 0.456108\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006175; batch adversarial loss: 0.475828\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023837; batch adversarial loss: 0.360151\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009830; batch adversarial loss: 0.451079\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726588; batch adversarial loss: 0.986204\n",
      "epoch 1; iter: 0; batch classifier loss: 0.492117; batch adversarial loss: 1.072773\n",
      "epoch 2; iter: 0; batch classifier loss: 0.441772; batch adversarial loss: 0.991903\n",
      "epoch 3; iter: 0; batch classifier loss: 0.455230; batch adversarial loss: 0.922007\n",
      "epoch 4; iter: 0; batch classifier loss: 0.355519; batch adversarial loss: 0.864647\n",
      "epoch 5; iter: 0; batch classifier loss: 0.280525; batch adversarial loss: 0.802956\n",
      "epoch 6; iter: 0; batch classifier loss: 0.275676; batch adversarial loss: 0.710492\n",
      "epoch 7; iter: 0; batch classifier loss: 0.277668; batch adversarial loss: 0.692932\n",
      "epoch 8; iter: 0; batch classifier loss: 0.340656; batch adversarial loss: 0.639264\n",
      "epoch 9; iter: 0; batch classifier loss: 0.322942; batch adversarial loss: 0.659658\n",
      "epoch 10; iter: 0; batch classifier loss: 0.288737; batch adversarial loss: 0.596121\n",
      "epoch 11; iter: 0; batch classifier loss: 0.281152; batch adversarial loss: 0.582526\n",
      "epoch 12; iter: 0; batch classifier loss: 0.255599; batch adversarial loss: 0.547727\n",
      "epoch 13; iter: 0; batch classifier loss: 0.253229; batch adversarial loss: 0.552607\n",
      "epoch 14; iter: 0; batch classifier loss: 0.278511; batch adversarial loss: 0.526054\n",
      "epoch 15; iter: 0; batch classifier loss: 0.226359; batch adversarial loss: 0.528956\n",
      "epoch 16; iter: 0; batch classifier loss: 0.257995; batch adversarial loss: 0.507517\n",
      "epoch 17; iter: 0; batch classifier loss: 0.203905; batch adversarial loss: 0.484529\n",
      "epoch 18; iter: 0; batch classifier loss: 0.285474; batch adversarial loss: 0.559017\n",
      "epoch 19; iter: 0; batch classifier loss: 0.226421; batch adversarial loss: 0.469290\n",
      "epoch 20; iter: 0; batch classifier loss: 0.184528; batch adversarial loss: 0.515491\n",
      "epoch 21; iter: 0; batch classifier loss: 0.165334; batch adversarial loss: 0.528519\n",
      "epoch 22; iter: 0; batch classifier loss: 0.157203; batch adversarial loss: 0.498806\n",
      "epoch 23; iter: 0; batch classifier loss: 0.147796; batch adversarial loss: 0.423254\n",
      "epoch 24; iter: 0; batch classifier loss: 0.292598; batch adversarial loss: 0.486764\n",
      "epoch 25; iter: 0; batch classifier loss: 0.206598; batch adversarial loss: 0.392186\n",
      "epoch 26; iter: 0; batch classifier loss: 0.272966; batch adversarial loss: 0.421513\n",
      "epoch 27; iter: 0; batch classifier loss: 0.255958; batch adversarial loss: 0.432770\n",
      "epoch 28; iter: 0; batch classifier loss: 0.230258; batch adversarial loss: 0.505994\n",
      "epoch 29; iter: 0; batch classifier loss: 0.215058; batch adversarial loss: 0.375904\n",
      "epoch 30; iter: 0; batch classifier loss: 0.216785; batch adversarial loss: 0.360741\n",
      "epoch 31; iter: 0; batch classifier loss: 0.173565; batch adversarial loss: 0.501528\n",
      "epoch 32; iter: 0; batch classifier loss: 0.233491; batch adversarial loss: 0.384864\n",
      "epoch 33; iter: 0; batch classifier loss: 0.125331; batch adversarial loss: 0.387173\n",
      "epoch 34; iter: 0; batch classifier loss: 0.182509; batch adversarial loss: 0.416175\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142618; batch adversarial loss: 0.377295\n",
      "epoch 36; iter: 0; batch classifier loss: 0.224351; batch adversarial loss: 0.393240\n",
      "epoch 37; iter: 0; batch classifier loss: 0.146615; batch adversarial loss: 0.458573\n",
      "epoch 38; iter: 0; batch classifier loss: 0.155190; batch adversarial loss: 0.373346\n",
      "epoch 39; iter: 0; batch classifier loss: 0.205767; batch adversarial loss: 0.384214\n",
      "epoch 40; iter: 0; batch classifier loss: 0.152325; batch adversarial loss: 0.399459\n",
      "epoch 41; iter: 0; batch classifier loss: 0.140553; batch adversarial loss: 0.415643\n",
      "epoch 42; iter: 0; batch classifier loss: 0.153282; batch adversarial loss: 0.440590\n",
      "epoch 43; iter: 0; batch classifier loss: 0.157007; batch adversarial loss: 0.333980\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123455; batch adversarial loss: 0.397467\n",
      "epoch 45; iter: 0; batch classifier loss: 0.161382; batch adversarial loss: 0.401951\n",
      "epoch 46; iter: 0; batch classifier loss: 0.181563; batch adversarial loss: 0.398689\n",
      "epoch 47; iter: 0; batch classifier loss: 0.150259; batch adversarial loss: 0.365691\n",
      "epoch 48; iter: 0; batch classifier loss: 0.117587; batch adversarial loss: 0.380910\n",
      "epoch 49; iter: 0; batch classifier loss: 0.155924; batch adversarial loss: 0.351666\n",
      "epoch 50; iter: 0; batch classifier loss: 0.118017; batch adversarial loss: 0.391216\n",
      "epoch 51; iter: 0; batch classifier loss: 0.123371; batch adversarial loss: 0.331413\n",
      "epoch 52; iter: 0; batch classifier loss: 0.125160; batch adversarial loss: 0.397812\n",
      "epoch 53; iter: 0; batch classifier loss: 0.125721; batch adversarial loss: 0.386576\n",
      "epoch 54; iter: 0; batch classifier loss: 0.104391; batch adversarial loss: 0.472649\n",
      "epoch 55; iter: 0; batch classifier loss: 0.097959; batch adversarial loss: 0.386623\n",
      "epoch 56; iter: 0; batch classifier loss: 0.121267; batch adversarial loss: 0.385830\n",
      "epoch 57; iter: 0; batch classifier loss: 0.101275; batch adversarial loss: 0.391634\n",
      "epoch 58; iter: 0; batch classifier loss: 0.092723; batch adversarial loss: 0.349860\n",
      "epoch 59; iter: 0; batch classifier loss: 0.086618; batch adversarial loss: 0.383511\n",
      "epoch 60; iter: 0; batch classifier loss: 0.063038; batch adversarial loss: 0.497850\n",
      "epoch 61; iter: 0; batch classifier loss: 0.106455; batch adversarial loss: 0.478009\n",
      "epoch 62; iter: 0; batch classifier loss: 0.066888; batch adversarial loss: 0.388328\n",
      "epoch 63; iter: 0; batch classifier loss: 0.064734; batch adversarial loss: 0.459771\n",
      "epoch 64; iter: 0; batch classifier loss: 0.064406; batch adversarial loss: 0.361849\n",
      "epoch 65; iter: 0; batch classifier loss: 0.098938; batch adversarial loss: 0.455426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.135607; batch adversarial loss: 0.470360\n",
      "epoch 67; iter: 0; batch classifier loss: 0.077953; batch adversarial loss: 0.480844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.075012; batch adversarial loss: 0.422395\n",
      "epoch 69; iter: 0; batch classifier loss: 0.042139; batch adversarial loss: 0.365023\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090417; batch adversarial loss: 0.342930\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073570; batch adversarial loss: 0.370745\n",
      "epoch 72; iter: 0; batch classifier loss: 0.130213; batch adversarial loss: 0.377327\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074617; batch adversarial loss: 0.514466\n",
      "epoch 74; iter: 0; batch classifier loss: 0.048501; batch adversarial loss: 0.477956\n",
      "epoch 75; iter: 0; batch classifier loss: 0.042061; batch adversarial loss: 0.394265\n",
      "epoch 76; iter: 0; batch classifier loss: 0.104056; batch adversarial loss: 0.379533\n",
      "epoch 77; iter: 0; batch classifier loss: 0.107058; batch adversarial loss: 0.432789\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077049; batch adversarial loss: 0.460424\n",
      "epoch 79; iter: 0; batch classifier loss: 0.047476; batch adversarial loss: 0.439837\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056657; batch adversarial loss: 0.320076\n",
      "epoch 81; iter: 0; batch classifier loss: 0.113111; batch adversarial loss: 0.557800\n",
      "epoch 82; iter: 0; batch classifier loss: 0.120373; batch adversarial loss: 0.460128\n",
      "epoch 83; iter: 0; batch classifier loss: 0.087627; batch adversarial loss: 0.368025\n",
      "epoch 84; iter: 0; batch classifier loss: 0.115492; batch adversarial loss: 0.423547\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056385; batch adversarial loss: 0.428571\n",
      "epoch 86; iter: 0; batch classifier loss: 0.034457; batch adversarial loss: 0.399349\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078451; batch adversarial loss: 0.387343\n",
      "epoch 88; iter: 0; batch classifier loss: 0.053935; batch adversarial loss: 0.369082\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068629; batch adversarial loss: 0.372387\n",
      "epoch 90; iter: 0; batch classifier loss: 0.070554; batch adversarial loss: 0.450227\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077952; batch adversarial loss: 0.439028\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058892; batch adversarial loss: 0.417464\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062634; batch adversarial loss: 0.435706\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058871; batch adversarial loss: 0.413158\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083145; batch adversarial loss: 0.435179\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055400; batch adversarial loss: 0.424583\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050875; batch adversarial loss: 0.509302\n",
      "epoch 98; iter: 0; batch classifier loss: 0.080666; batch adversarial loss: 0.313178\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065474; batch adversarial loss: 0.567083\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043599; batch adversarial loss: 0.432403\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046253; batch adversarial loss: 0.443914\n",
      "epoch 102; iter: 0; batch classifier loss: 0.072308; batch adversarial loss: 0.441026\n",
      "epoch 103; iter: 0; batch classifier loss: 0.067552; batch adversarial loss: 0.531433\n",
      "epoch 104; iter: 0; batch classifier loss: 0.079148; batch adversarial loss: 0.529808\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040979; batch adversarial loss: 0.469304\n",
      "epoch 106; iter: 0; batch classifier loss: 0.078132; batch adversarial loss: 0.447569\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047652; batch adversarial loss: 0.422094\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055587; batch adversarial loss: 0.437555\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043884; batch adversarial loss: 0.409013\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046101; batch adversarial loss: 0.387083\n",
      "epoch 111; iter: 0; batch classifier loss: 0.079655; batch adversarial loss: 0.425100\n",
      "epoch 112; iter: 0; batch classifier loss: 0.064853; batch adversarial loss: 0.401710\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042788; batch adversarial loss: 0.348888\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044110; batch adversarial loss: 0.320488\n",
      "epoch 115; iter: 0; batch classifier loss: 0.073522; batch adversarial loss: 0.452273\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064348; batch adversarial loss: 0.429407\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034104; batch adversarial loss: 0.436370\n",
      "epoch 118; iter: 0; batch classifier loss: 0.075215; batch adversarial loss: 0.496467\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051691; batch adversarial loss: 0.419179\n",
      "epoch 120; iter: 0; batch classifier loss: 0.061740; batch adversarial loss: 0.384394\n",
      "epoch 121; iter: 0; batch classifier loss: 0.082437; batch adversarial loss: 0.446103\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045741; batch adversarial loss: 0.404953\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049664; batch adversarial loss: 0.419756\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055590; batch adversarial loss: 0.398298\n",
      "epoch 125; iter: 0; batch classifier loss: 0.075696; batch adversarial loss: 0.410366\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055269; batch adversarial loss: 0.425400\n",
      "epoch 127; iter: 0; batch classifier loss: 0.056962; batch adversarial loss: 0.431133\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042455; batch adversarial loss: 0.476360\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039120; batch adversarial loss: 0.400071\n",
      "epoch 130; iter: 0; batch classifier loss: 0.060932; batch adversarial loss: 0.434977\n",
      "epoch 131; iter: 0; batch classifier loss: 0.057241; batch adversarial loss: 0.472644\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058083; batch adversarial loss: 0.436924\n",
      "epoch 133; iter: 0; batch classifier loss: 0.086673; batch adversarial loss: 0.378838\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034095; batch adversarial loss: 0.469651\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059040; batch adversarial loss: 0.382063\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043575; batch adversarial loss: 0.461358\n",
      "epoch 137; iter: 0; batch classifier loss: 0.050333; batch adversarial loss: 0.397825\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021893; batch adversarial loss: 0.431317\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033163; batch adversarial loss: 0.357245\n",
      "epoch 140; iter: 0; batch classifier loss: 0.058851; batch adversarial loss: 0.331684\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046875; batch adversarial loss: 0.499601\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048691; batch adversarial loss: 0.415032\n",
      "epoch 143; iter: 0; batch classifier loss: 0.047116; batch adversarial loss: 0.352793\n",
      "epoch 144; iter: 0; batch classifier loss: 0.073998; batch adversarial loss: 0.338341\n",
      "epoch 145; iter: 0; batch classifier loss: 0.066389; batch adversarial loss: 0.395711\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035561; batch adversarial loss: 0.434313\n",
      "epoch 147; iter: 0; batch classifier loss: 0.063229; batch adversarial loss: 0.427822\n",
      "epoch 148; iter: 0; batch classifier loss: 0.048580; batch adversarial loss: 0.489897\n",
      "epoch 149; iter: 0; batch classifier loss: 0.045564; batch adversarial loss: 0.483056\n",
      "epoch 150; iter: 0; batch classifier loss: 0.051497; batch adversarial loss: 0.326053\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029494; batch adversarial loss: 0.409219\n",
      "epoch 152; iter: 0; batch classifier loss: 0.046138; batch adversarial loss: 0.383106\n",
      "epoch 153; iter: 0; batch classifier loss: 0.055374; batch adversarial loss: 0.489148\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032144; batch adversarial loss: 0.468710\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026088; batch adversarial loss: 0.383519\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026328; batch adversarial loss: 0.465038\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026903; batch adversarial loss: 0.337222\n",
      "epoch 158; iter: 0; batch classifier loss: 0.063736; batch adversarial loss: 0.431474\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037802; batch adversarial loss: 0.431697\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025519; batch adversarial loss: 0.419614\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024316; batch adversarial loss: 0.457012\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036866; batch adversarial loss: 0.366827\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035374; batch adversarial loss: 0.489321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.036782; batch adversarial loss: 0.397261\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036240; batch adversarial loss: 0.478022\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031280; batch adversarial loss: 0.396717\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036557; batch adversarial loss: 0.440142\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036188; batch adversarial loss: 0.500821\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031712; batch adversarial loss: 0.415755\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034877; batch adversarial loss: 0.409910\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025777; batch adversarial loss: 0.530120\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021319; batch adversarial loss: 0.507254\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020377; batch adversarial loss: 0.416131\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030698; batch adversarial loss: 0.471740\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018686; batch adversarial loss: 0.428370\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024960; batch adversarial loss: 0.423374\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032921; batch adversarial loss: 0.434345\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024466; batch adversarial loss: 0.376341\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043290; batch adversarial loss: 0.452628\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028022; batch adversarial loss: 0.452386\n",
      "epoch 181; iter: 0; batch classifier loss: 0.051961; batch adversarial loss: 0.347018\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011523; batch adversarial loss: 0.404592\n",
      "epoch 183; iter: 0; batch classifier loss: 0.054193; batch adversarial loss: 0.534570\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027534; batch adversarial loss: 0.549718\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025411; batch adversarial loss: 0.511258\n",
      "epoch 186; iter: 0; batch classifier loss: 0.061117; batch adversarial loss: 0.537015\n",
      "epoch 187; iter: 0; batch classifier loss: 0.058500; batch adversarial loss: 0.484228\n",
      "epoch 188; iter: 0; batch classifier loss: 0.063114; batch adversarial loss: 0.540481\n",
      "epoch 189; iter: 0; batch classifier loss: 0.121152; batch adversarial loss: 0.667472\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050138; batch adversarial loss: 0.436341\n",
      "epoch 191; iter: 0; batch classifier loss: 0.106368; batch adversarial loss: 0.546833\n",
      "epoch 192; iter: 0; batch classifier loss: 0.125068; batch adversarial loss: 0.669755\n",
      "epoch 193; iter: 0; batch classifier loss: 0.193546; batch adversarial loss: 0.655293\n",
      "epoch 194; iter: 0; batch classifier loss: 0.153540; batch adversarial loss: 0.707395\n",
      "epoch 195; iter: 0; batch classifier loss: 0.122686; batch adversarial loss: 0.656779\n",
      "epoch 196; iter: 0; batch classifier loss: 0.190127; batch adversarial loss: 0.691611\n",
      "epoch 197; iter: 0; batch classifier loss: 0.123311; batch adversarial loss: 0.572975\n",
      "epoch 198; iter: 0; batch classifier loss: 0.133560; batch adversarial loss: 0.633669\n",
      "epoch 199; iter: 0; batch classifier loss: 0.169201; batch adversarial loss: 0.694462\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690196; batch adversarial loss: 0.575377\n",
      "epoch 1; iter: 0; batch classifier loss: 0.397735; batch adversarial loss: 0.618849\n",
      "epoch 2; iter: 0; batch classifier loss: 0.340363; batch adversarial loss: 0.591321\n",
      "epoch 3; iter: 0; batch classifier loss: 0.387164; batch adversarial loss: 0.586609\n",
      "epoch 4; iter: 0; batch classifier loss: 0.341525; batch adversarial loss: 0.604911\n",
      "epoch 5; iter: 0; batch classifier loss: 0.267255; batch adversarial loss: 0.545630\n",
      "epoch 6; iter: 0; batch classifier loss: 0.372226; batch adversarial loss: 0.488924\n",
      "epoch 7; iter: 0; batch classifier loss: 0.296282; batch adversarial loss: 0.478280\n",
      "epoch 8; iter: 0; batch classifier loss: 0.278765; batch adversarial loss: 0.517270\n",
      "epoch 9; iter: 0; batch classifier loss: 0.250993; batch adversarial loss: 0.513259\n",
      "epoch 10; iter: 0; batch classifier loss: 0.271461; batch adversarial loss: 0.503500\n",
      "epoch 11; iter: 0; batch classifier loss: 0.290149; batch adversarial loss: 0.491296\n",
      "epoch 12; iter: 0; batch classifier loss: 0.298137; batch adversarial loss: 0.535450\n",
      "epoch 13; iter: 0; batch classifier loss: 0.263872; batch adversarial loss: 0.493720\n",
      "epoch 14; iter: 0; batch classifier loss: 0.231354; batch adversarial loss: 0.500803\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302662; batch adversarial loss: 0.500780\n",
      "epoch 16; iter: 0; batch classifier loss: 0.321407; batch adversarial loss: 0.483800\n",
      "epoch 17; iter: 0; batch classifier loss: 0.344205; batch adversarial loss: 0.528366\n",
      "epoch 18; iter: 0; batch classifier loss: 0.307830; batch adversarial loss: 0.466721\n",
      "epoch 19; iter: 0; batch classifier loss: 0.446379; batch adversarial loss: 0.495109\n",
      "epoch 20; iter: 0; batch classifier loss: 0.430178; batch adversarial loss: 0.466433\n",
      "epoch 21; iter: 0; batch classifier loss: 0.352411; batch adversarial loss: 0.469952\n",
      "epoch 22; iter: 0; batch classifier loss: 0.207571; batch adversarial loss: 0.431838\n",
      "epoch 23; iter: 0; batch classifier loss: 0.204085; batch adversarial loss: 0.429924\n",
      "epoch 24; iter: 0; batch classifier loss: 0.208903; batch adversarial loss: 0.427187\n",
      "epoch 25; iter: 0; batch classifier loss: 0.183747; batch adversarial loss: 0.434937\n",
      "epoch 26; iter: 0; batch classifier loss: 0.240657; batch adversarial loss: 0.465760\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151081; batch adversarial loss: 0.404792\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169287; batch adversarial loss: 0.433064\n",
      "epoch 29; iter: 0; batch classifier loss: 0.117488; batch adversarial loss: 0.450388\n",
      "epoch 30; iter: 0; batch classifier loss: 0.106536; batch adversarial loss: 0.525008\n",
      "epoch 31; iter: 0; batch classifier loss: 0.153381; batch adversarial loss: 0.420448\n",
      "epoch 32; iter: 0; batch classifier loss: 0.156954; batch adversarial loss: 0.428335\n",
      "epoch 33; iter: 0; batch classifier loss: 0.108298; batch adversarial loss: 0.488326\n",
      "epoch 34; iter: 0; batch classifier loss: 0.117850; batch adversarial loss: 0.462309\n",
      "epoch 35; iter: 0; batch classifier loss: 0.138371; batch adversarial loss: 0.444688\n",
      "epoch 36; iter: 0; batch classifier loss: 0.080432; batch adversarial loss: 0.508293\n",
      "epoch 37; iter: 0; batch classifier loss: 0.114794; batch adversarial loss: 0.396799\n",
      "epoch 38; iter: 0; batch classifier loss: 0.112681; batch adversarial loss: 0.375922\n",
      "epoch 39; iter: 0; batch classifier loss: 0.121909; batch adversarial loss: 0.423708\n",
      "epoch 40; iter: 0; batch classifier loss: 0.070775; batch adversarial loss: 0.424228\n",
      "epoch 41; iter: 0; batch classifier loss: 0.164888; batch adversarial loss: 0.350393\n",
      "epoch 42; iter: 0; batch classifier loss: 0.144442; batch adversarial loss: 0.364764\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104079; batch adversarial loss: 0.427649\n",
      "epoch 44; iter: 0; batch classifier loss: 0.135767; batch adversarial loss: 0.395559\n",
      "epoch 45; iter: 0; batch classifier loss: 0.076491; batch adversarial loss: 0.402002\n",
      "epoch 46; iter: 0; batch classifier loss: 0.137300; batch adversarial loss: 0.457063\n",
      "epoch 47; iter: 0; batch classifier loss: 0.086929; batch adversarial loss: 0.493236\n",
      "epoch 48; iter: 0; batch classifier loss: 0.142039; batch adversarial loss: 0.525032\n",
      "epoch 49; iter: 0; batch classifier loss: 0.131938; batch adversarial loss: 0.527562\n",
      "epoch 50; iter: 0; batch classifier loss: 0.103425; batch adversarial loss: 0.430811\n",
      "epoch 51; iter: 0; batch classifier loss: 0.112788; batch adversarial loss: 0.493594\n",
      "epoch 52; iter: 0; batch classifier loss: 0.116651; batch adversarial loss: 0.369452\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096869; batch adversarial loss: 0.376092\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101510; batch adversarial loss: 0.381075\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117932; batch adversarial loss: 0.492369\n",
      "epoch 56; iter: 0; batch classifier loss: 0.074504; batch adversarial loss: 0.355493\n",
      "epoch 57; iter: 0; batch classifier loss: 0.081063; batch adversarial loss: 0.347036\n",
      "epoch 58; iter: 0; batch classifier loss: 0.083781; batch adversarial loss: 0.397512\n",
      "epoch 59; iter: 0; batch classifier loss: 0.120044; batch adversarial loss: 0.412181\n",
      "epoch 60; iter: 0; batch classifier loss: 0.092597; batch adversarial loss: 0.376401\n",
      "epoch 61; iter: 0; batch classifier loss: 0.060413; batch adversarial loss: 0.543609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.120305; batch adversarial loss: 0.476978\n",
      "epoch 63; iter: 0; batch classifier loss: 0.081998; batch adversarial loss: 0.489253\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083596; batch adversarial loss: 0.471100\n",
      "epoch 65; iter: 0; batch classifier loss: 0.098444; batch adversarial loss: 0.466101\n",
      "epoch 66; iter: 0; batch classifier loss: 0.098347; batch adversarial loss: 0.442664\n",
      "epoch 67; iter: 0; batch classifier loss: 0.062351; batch adversarial loss: 0.585266\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109261; batch adversarial loss: 0.492475\n",
      "epoch 69; iter: 0; batch classifier loss: 0.077090; batch adversarial loss: 0.449400\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110462; batch adversarial loss: 0.486086\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082529; batch adversarial loss: 0.512181\n",
      "epoch 72; iter: 0; batch classifier loss: 0.067612; batch adversarial loss: 0.400133\n",
      "epoch 73; iter: 0; batch classifier loss: 0.109836; batch adversarial loss: 0.487290\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082915; batch adversarial loss: 0.454534\n",
      "epoch 75; iter: 0; batch classifier loss: 0.086858; batch adversarial loss: 0.489513\n",
      "epoch 76; iter: 0; batch classifier loss: 0.124898; batch adversarial loss: 0.393104\n",
      "epoch 77; iter: 0; batch classifier loss: 0.086096; batch adversarial loss: 0.395260\n",
      "epoch 78; iter: 0; batch classifier loss: 0.053555; batch adversarial loss: 0.490901\n",
      "epoch 79; iter: 0; batch classifier loss: 0.079292; batch adversarial loss: 0.445026\n",
      "epoch 80; iter: 0; batch classifier loss: 0.103451; batch adversarial loss: 0.522604\n",
      "epoch 81; iter: 0; batch classifier loss: 0.112764; batch adversarial loss: 0.409269\n",
      "epoch 82; iter: 0; batch classifier loss: 0.096336; batch adversarial loss: 0.342457\n",
      "epoch 83; iter: 0; batch classifier loss: 0.107042; batch adversarial loss: 0.502895\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080113; batch adversarial loss: 0.436408\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090392; batch adversarial loss: 0.476588\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057592; batch adversarial loss: 0.456415\n",
      "epoch 87; iter: 0; batch classifier loss: 0.091509; batch adversarial loss: 0.461335\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075576; batch adversarial loss: 0.475748\n",
      "epoch 89; iter: 0; batch classifier loss: 0.061956; batch adversarial loss: 0.390863\n",
      "epoch 90; iter: 0; batch classifier loss: 0.080603; batch adversarial loss: 0.446545\n",
      "epoch 91; iter: 0; batch classifier loss: 0.087781; batch adversarial loss: 0.445435\n",
      "epoch 92; iter: 0; batch classifier loss: 0.106672; batch adversarial loss: 0.392041\n",
      "epoch 93; iter: 0; batch classifier loss: 0.057249; batch adversarial loss: 0.341964\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079428; batch adversarial loss: 0.413061\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079232; batch adversarial loss: 0.369711\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065066; batch adversarial loss: 0.461978\n",
      "epoch 97; iter: 0; batch classifier loss: 0.093152; batch adversarial loss: 0.463521\n",
      "epoch 98; iter: 0; batch classifier loss: 0.083180; batch adversarial loss: 0.392293\n",
      "epoch 99; iter: 0; batch classifier loss: 0.080191; batch adversarial loss: 0.438526\n",
      "epoch 100; iter: 0; batch classifier loss: 0.122260; batch adversarial loss: 0.478096\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058690; batch adversarial loss: 0.480248\n",
      "epoch 102; iter: 0; batch classifier loss: 0.094023; batch adversarial loss: 0.505861\n",
      "epoch 103; iter: 0; batch classifier loss: 0.097006; batch adversarial loss: 0.392198\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044496; batch adversarial loss: 0.554649\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028092; batch adversarial loss: 0.381881\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060534; batch adversarial loss: 0.484462\n",
      "epoch 107; iter: 0; batch classifier loss: 0.078336; batch adversarial loss: 0.466528\n",
      "epoch 108; iter: 0; batch classifier loss: 0.108613; batch adversarial loss: 0.408453\n",
      "epoch 109; iter: 0; batch classifier loss: 0.074070; batch adversarial loss: 0.448922\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060491; batch adversarial loss: 0.453313\n",
      "epoch 111; iter: 0; batch classifier loss: 0.072660; batch adversarial loss: 0.405166\n",
      "epoch 112; iter: 0; batch classifier loss: 0.072194; batch adversarial loss: 0.424706\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071149; batch adversarial loss: 0.421590\n",
      "epoch 114; iter: 0; batch classifier loss: 0.088512; batch adversarial loss: 0.484446\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053694; batch adversarial loss: 0.377390\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051834; batch adversarial loss: 0.461341\n",
      "epoch 117; iter: 0; batch classifier loss: 0.077971; batch adversarial loss: 0.449747\n",
      "epoch 118; iter: 0; batch classifier loss: 0.016030; batch adversarial loss: 0.514994\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047294; batch adversarial loss: 0.470325\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039726; batch adversarial loss: 0.399024\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041317; batch adversarial loss: 0.468997\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044673; batch adversarial loss: 0.391501\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067622; batch adversarial loss: 0.395171\n",
      "epoch 124; iter: 0; batch classifier loss: 0.084168; batch adversarial loss: 0.511572\n",
      "epoch 125; iter: 0; batch classifier loss: 0.082498; batch adversarial loss: 0.339601\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030165; batch adversarial loss: 0.484257\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044665; batch adversarial loss: 0.357612\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044120; batch adversarial loss: 0.394690\n",
      "epoch 129; iter: 0; batch classifier loss: 0.063958; batch adversarial loss: 0.409334\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028833; batch adversarial loss: 0.536698\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035164; batch adversarial loss: 0.406408\n",
      "epoch 132; iter: 0; batch classifier loss: 0.052822; batch adversarial loss: 0.459057\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053942; batch adversarial loss: 0.457104\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038525; batch adversarial loss: 0.440761\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044374; batch adversarial loss: 0.412951\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032421; batch adversarial loss: 0.454553\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046818; batch adversarial loss: 0.454343\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037511; batch adversarial loss: 0.384735\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044834; batch adversarial loss: 0.358442\n",
      "epoch 140; iter: 0; batch classifier loss: 0.059726; batch adversarial loss: 0.430022\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049656; batch adversarial loss: 0.540359\n",
      "epoch 142; iter: 0; batch classifier loss: 0.072378; batch adversarial loss: 0.452776\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034074; batch adversarial loss: 0.505435\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019268; batch adversarial loss: 0.455723\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018295; batch adversarial loss: 0.352211\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022084; batch adversarial loss: 0.429667\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037990; batch adversarial loss: 0.424013\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033065; batch adversarial loss: 0.438749\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022016; batch adversarial loss: 0.458088\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023918; batch adversarial loss: 0.502583\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029751; batch adversarial loss: 0.427233\n",
      "epoch 152; iter: 0; batch classifier loss: 0.060984; batch adversarial loss: 0.669218\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017078; batch adversarial loss: 0.404208\n",
      "epoch 154; iter: 0; batch classifier loss: 0.047531; batch adversarial loss: 0.387909\n",
      "epoch 155; iter: 0; batch classifier loss: 0.062809; batch adversarial loss: 0.468377\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021627; batch adversarial loss: 0.483177\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040802; batch adversarial loss: 0.488831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.035922; batch adversarial loss: 0.465295\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045930; batch adversarial loss: 0.423494\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037428; batch adversarial loss: 0.391860\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034927; batch adversarial loss: 0.439942\n",
      "epoch 162; iter: 0; batch classifier loss: 0.057512; batch adversarial loss: 0.385488\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028868; batch adversarial loss: 0.360834\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030111; batch adversarial loss: 0.352172\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023075; batch adversarial loss: 0.426764\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026214; batch adversarial loss: 0.405837\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022523; batch adversarial loss: 0.443315\n",
      "epoch 168; iter: 0; batch classifier loss: 0.074457; batch adversarial loss: 0.489577\n",
      "epoch 169; iter: 0; batch classifier loss: 0.062495; batch adversarial loss: 0.441032\n",
      "epoch 170; iter: 0; batch classifier loss: 0.046989; batch adversarial loss: 0.457758\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011148; batch adversarial loss: 0.465880\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016059; batch adversarial loss: 0.435412\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042346; batch adversarial loss: 0.375874\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038080; batch adversarial loss: 0.444575\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012112; batch adversarial loss: 0.478681\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022708; batch adversarial loss: 0.468427\n",
      "epoch 177; iter: 0; batch classifier loss: 0.047437; batch adversarial loss: 0.473775\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017883; batch adversarial loss: 0.512724\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025392; batch adversarial loss: 0.526859\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021692; batch adversarial loss: 0.457131\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024209; batch adversarial loss: 0.417534\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036962; batch adversarial loss: 0.425384\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017774; batch adversarial loss: 0.421644\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030186; batch adversarial loss: 0.431972\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038193; batch adversarial loss: 0.413462\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016148; batch adversarial loss: 0.402891\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018939; batch adversarial loss: 0.516018\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006861; batch adversarial loss: 0.471039\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025962; batch adversarial loss: 0.516353\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013728; batch adversarial loss: 0.509685\n",
      "epoch 191; iter: 0; batch classifier loss: 0.051200; batch adversarial loss: 0.440556\n",
      "epoch 192; iter: 0; batch classifier loss: 0.055228; batch adversarial loss: 0.406208\n",
      "epoch 193; iter: 0; batch classifier loss: 0.048121; batch adversarial loss: 0.447864\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017796; batch adversarial loss: 0.539582\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030612; batch adversarial loss: 0.401182\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018731; batch adversarial loss: 0.384123\n",
      "epoch 197; iter: 0; batch classifier loss: 0.040535; batch adversarial loss: 0.475374\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018134; batch adversarial loss: 0.475347\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009011; batch adversarial loss: 0.462479\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691913; batch adversarial loss: 0.618391\n",
      "epoch 1; iter: 0; batch classifier loss: 0.450771; batch adversarial loss: 0.593611\n",
      "epoch 2; iter: 0; batch classifier loss: 0.364634; batch adversarial loss: 0.583427\n",
      "epoch 3; iter: 0; batch classifier loss: 0.283828; batch adversarial loss: 0.592501\n",
      "epoch 4; iter: 0; batch classifier loss: 0.284481; batch adversarial loss: 0.557323\n",
      "epoch 5; iter: 0; batch classifier loss: 0.286140; batch adversarial loss: 0.540854\n",
      "epoch 6; iter: 0; batch classifier loss: 0.305563; batch adversarial loss: 0.571742\n",
      "epoch 7; iter: 0; batch classifier loss: 0.305586; batch adversarial loss: 0.634128\n",
      "epoch 8; iter: 0; batch classifier loss: 0.230320; batch adversarial loss: 0.495472\n",
      "epoch 9; iter: 0; batch classifier loss: 0.257212; batch adversarial loss: 0.481943\n",
      "epoch 10; iter: 0; batch classifier loss: 0.363824; batch adversarial loss: 0.575598\n",
      "epoch 11; iter: 0; batch classifier loss: 0.278315; batch adversarial loss: 0.595410\n",
      "epoch 12; iter: 0; batch classifier loss: 0.303667; batch adversarial loss: 0.646872\n",
      "epoch 13; iter: 0; batch classifier loss: 0.262821; batch adversarial loss: 0.475603\n",
      "epoch 14; iter: 0; batch classifier loss: 0.202288; batch adversarial loss: 0.543148\n",
      "epoch 15; iter: 0; batch classifier loss: 0.223401; batch adversarial loss: 0.495559\n",
      "epoch 16; iter: 0; batch classifier loss: 0.248148; batch adversarial loss: 0.537825\n",
      "epoch 17; iter: 0; batch classifier loss: 0.288993; batch adversarial loss: 0.611503\n",
      "epoch 18; iter: 0; batch classifier loss: 0.233742; batch adversarial loss: 0.537547\n",
      "epoch 19; iter: 0; batch classifier loss: 0.212811; batch adversarial loss: 0.483643\n",
      "epoch 20; iter: 0; batch classifier loss: 0.278732; batch adversarial loss: 0.513701\n",
      "epoch 21; iter: 0; batch classifier loss: 0.295886; batch adversarial loss: 0.483206\n",
      "epoch 22; iter: 0; batch classifier loss: 0.228982; batch adversarial loss: 0.427331\n",
      "epoch 23; iter: 0; batch classifier loss: 0.268005; batch adversarial loss: 0.450338\n",
      "epoch 24; iter: 0; batch classifier loss: 0.276355; batch adversarial loss: 0.490960\n",
      "epoch 25; iter: 0; batch classifier loss: 0.311598; batch adversarial loss: 0.509256\n",
      "epoch 26; iter: 0; batch classifier loss: 0.334947; batch adversarial loss: 0.551239\n",
      "epoch 27; iter: 0; batch classifier loss: 0.349847; batch adversarial loss: 0.457704\n",
      "epoch 28; iter: 0; batch classifier loss: 0.150860; batch adversarial loss: 0.535921\n",
      "epoch 29; iter: 0; batch classifier loss: 0.122805; batch adversarial loss: 0.575553\n",
      "epoch 30; iter: 0; batch classifier loss: 0.128091; batch adversarial loss: 0.456688\n",
      "epoch 31; iter: 0; batch classifier loss: 0.158416; batch adversarial loss: 0.512621\n",
      "epoch 32; iter: 0; batch classifier loss: 0.173015; batch adversarial loss: 0.429500\n",
      "epoch 33; iter: 0; batch classifier loss: 0.106849; batch adversarial loss: 0.493289\n",
      "epoch 34; iter: 0; batch classifier loss: 0.137190; batch adversarial loss: 0.516798\n",
      "epoch 35; iter: 0; batch classifier loss: 0.102862; batch adversarial loss: 0.467568\n",
      "epoch 36; iter: 0; batch classifier loss: 0.094129; batch adversarial loss: 0.483138\n",
      "epoch 37; iter: 0; batch classifier loss: 0.119442; batch adversarial loss: 0.512403\n",
      "epoch 38; iter: 0; batch classifier loss: 0.094671; batch adversarial loss: 0.505365\n",
      "epoch 39; iter: 0; batch classifier loss: 0.087425; batch adversarial loss: 0.553466\n",
      "epoch 40; iter: 0; batch classifier loss: 0.081183; batch adversarial loss: 0.397677\n",
      "epoch 41; iter: 0; batch classifier loss: 0.092371; batch adversarial loss: 0.517101\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110832; batch adversarial loss: 0.496570\n",
      "epoch 43; iter: 0; batch classifier loss: 0.113906; batch adversarial loss: 0.544611\n",
      "epoch 44; iter: 0; batch classifier loss: 0.067726; batch adversarial loss: 0.529089\n",
      "epoch 45; iter: 0; batch classifier loss: 0.138776; batch adversarial loss: 0.357082\n",
      "epoch 46; iter: 0; batch classifier loss: 0.145130; batch adversarial loss: 0.470427\n",
      "epoch 47; iter: 0; batch classifier loss: 0.079274; batch adversarial loss: 0.431175\n",
      "epoch 48; iter: 0; batch classifier loss: 0.101580; batch adversarial loss: 0.450914\n",
      "epoch 49; iter: 0; batch classifier loss: 0.103954; batch adversarial loss: 0.528435\n",
      "epoch 50; iter: 0; batch classifier loss: 0.080327; batch adversarial loss: 0.466239\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096619; batch adversarial loss: 0.481631\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082664; batch adversarial loss: 0.477436\n",
      "epoch 53; iter: 0; batch classifier loss: 0.101626; batch adversarial loss: 0.447501\n",
      "epoch 54; iter: 0; batch classifier loss: 0.072071; batch adversarial loss: 0.456647\n",
      "epoch 55; iter: 0; batch classifier loss: 0.109211; batch adversarial loss: 0.432957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.060830; batch adversarial loss: 0.449759\n",
      "epoch 57; iter: 0; batch classifier loss: 0.121432; batch adversarial loss: 0.430070\n",
      "epoch 58; iter: 0; batch classifier loss: 0.095673; batch adversarial loss: 0.477179\n",
      "epoch 59; iter: 0; batch classifier loss: 0.107902; batch adversarial loss: 0.427661\n",
      "epoch 60; iter: 0; batch classifier loss: 0.067838; batch adversarial loss: 0.495572\n",
      "epoch 61; iter: 0; batch classifier loss: 0.059558; batch adversarial loss: 0.468197\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090124; batch adversarial loss: 0.433279\n",
      "epoch 63; iter: 0; batch classifier loss: 0.064707; batch adversarial loss: 0.484756\n",
      "epoch 64; iter: 0; batch classifier loss: 0.060074; batch adversarial loss: 0.498082\n",
      "epoch 65; iter: 0; batch classifier loss: 0.081705; batch adversarial loss: 0.500835\n",
      "epoch 66; iter: 0; batch classifier loss: 0.061395; batch adversarial loss: 0.564596\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098504; batch adversarial loss: 0.538724\n",
      "epoch 68; iter: 0; batch classifier loss: 0.069400; batch adversarial loss: 0.443981\n",
      "epoch 69; iter: 0; batch classifier loss: 0.034050; batch adversarial loss: 0.440417\n",
      "epoch 70; iter: 0; batch classifier loss: 0.051997; batch adversarial loss: 0.400847\n",
      "epoch 71; iter: 0; batch classifier loss: 0.085392; batch adversarial loss: 0.500024\n",
      "epoch 72; iter: 0; batch classifier loss: 0.108144; batch adversarial loss: 0.520525\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090729; batch adversarial loss: 0.417471\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066478; batch adversarial loss: 0.524816\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063312; batch adversarial loss: 0.435903\n",
      "epoch 76; iter: 0; batch classifier loss: 0.053856; batch adversarial loss: 0.498510\n",
      "epoch 77; iter: 0; batch classifier loss: 0.083990; batch adversarial loss: 0.442025\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064358; batch adversarial loss: 0.459396\n",
      "epoch 79; iter: 0; batch classifier loss: 0.108617; batch adversarial loss: 0.428719\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084162; batch adversarial loss: 0.509618\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076514; batch adversarial loss: 0.511599\n",
      "epoch 82; iter: 0; batch classifier loss: 0.079350; batch adversarial loss: 0.556151\n",
      "epoch 83; iter: 0; batch classifier loss: 0.043119; batch adversarial loss: 0.385644\n",
      "epoch 84; iter: 0; batch classifier loss: 0.073464; batch adversarial loss: 0.352497\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075075; batch adversarial loss: 0.565036\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052870; batch adversarial loss: 0.388424\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062761; batch adversarial loss: 0.488477\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063048; batch adversarial loss: 0.484248\n",
      "epoch 89; iter: 0; batch classifier loss: 0.067052; batch adversarial loss: 0.382729\n",
      "epoch 90; iter: 0; batch classifier loss: 0.077342; batch adversarial loss: 0.383705\n",
      "epoch 91; iter: 0; batch classifier loss: 0.072009; batch adversarial loss: 0.412708\n",
      "epoch 92; iter: 0; batch classifier loss: 0.031070; batch adversarial loss: 0.482366\n",
      "epoch 93; iter: 0; batch classifier loss: 0.094719; batch adversarial loss: 0.453913\n",
      "epoch 94; iter: 0; batch classifier loss: 0.093995; batch adversarial loss: 0.459954\n",
      "epoch 95; iter: 0; batch classifier loss: 0.078768; batch adversarial loss: 0.516790\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047885; batch adversarial loss: 0.491477\n",
      "epoch 97; iter: 0; batch classifier loss: 0.030307; batch adversarial loss: 0.414916\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062627; batch adversarial loss: 0.573435\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049940; batch adversarial loss: 0.480755\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049811; batch adversarial loss: 0.409686\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070359; batch adversarial loss: 0.525105\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052830; batch adversarial loss: 0.466554\n",
      "epoch 103; iter: 0; batch classifier loss: 0.080665; batch adversarial loss: 0.506405\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044158; batch adversarial loss: 0.448930\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055170; batch adversarial loss: 0.434986\n",
      "epoch 106; iter: 0; batch classifier loss: 0.115602; batch adversarial loss: 0.410646\n",
      "epoch 107; iter: 0; batch classifier loss: 0.115223; batch adversarial loss: 0.567665\n",
      "epoch 108; iter: 0; batch classifier loss: 0.072885; batch adversarial loss: 0.549158\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051487; batch adversarial loss: 0.500434\n",
      "epoch 110; iter: 0; batch classifier loss: 0.083888; batch adversarial loss: 0.491858\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059830; batch adversarial loss: 0.446627\n",
      "epoch 112; iter: 0; batch classifier loss: 0.064886; batch adversarial loss: 0.360719\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059820; batch adversarial loss: 0.450783\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034348; batch adversarial loss: 0.517422\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041012; batch adversarial loss: 0.397166\n",
      "epoch 116; iter: 0; batch classifier loss: 0.079994; batch adversarial loss: 0.445152\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031476; batch adversarial loss: 0.471220\n",
      "epoch 118; iter: 0; batch classifier loss: 0.055872; batch adversarial loss: 0.549467\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043914; batch adversarial loss: 0.495355\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055324; batch adversarial loss: 0.473646\n",
      "epoch 121; iter: 0; batch classifier loss: 0.085546; batch adversarial loss: 0.477076\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034270; batch adversarial loss: 0.512947\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052254; batch adversarial loss: 0.357517\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031068; batch adversarial loss: 0.434043\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041472; batch adversarial loss: 0.486505\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026036; batch adversarial loss: 0.485279\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051226; batch adversarial loss: 0.460955\n",
      "epoch 128; iter: 0; batch classifier loss: 0.071113; batch adversarial loss: 0.501267\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024526; batch adversarial loss: 0.402090\n",
      "epoch 130; iter: 0; batch classifier loss: 0.055195; batch adversarial loss: 0.499210\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031969; batch adversarial loss: 0.487288\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032372; batch adversarial loss: 0.344405\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025849; batch adversarial loss: 0.609699\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042244; batch adversarial loss: 0.436610\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045841; batch adversarial loss: 0.567161\n",
      "epoch 136; iter: 0; batch classifier loss: 0.064229; batch adversarial loss: 0.391439\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036083; batch adversarial loss: 0.390933\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020452; batch adversarial loss: 0.584786\n",
      "epoch 139; iter: 0; batch classifier loss: 0.121145; batch adversarial loss: 0.429820\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022510; batch adversarial loss: 0.450552\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016880; batch adversarial loss: 0.462302\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034065; batch adversarial loss: 0.473841\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027563; batch adversarial loss: 0.405154\n",
      "epoch 144; iter: 0; batch classifier loss: 0.068834; batch adversarial loss: 0.518558\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014337; batch adversarial loss: 0.442749\n",
      "epoch 146; iter: 0; batch classifier loss: 0.079042; batch adversarial loss: 0.468123\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025448; batch adversarial loss: 0.461698\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036712; batch adversarial loss: 0.500663\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046232; batch adversarial loss: 0.472099\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030070; batch adversarial loss: 0.471525\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027839; batch adversarial loss: 0.403056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.023495; batch adversarial loss: 0.472238\n",
      "epoch 153; iter: 0; batch classifier loss: 0.080398; batch adversarial loss: 0.455223\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013441; batch adversarial loss: 0.497781\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014649; batch adversarial loss: 0.447144\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016953; batch adversarial loss: 0.465247\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028423; batch adversarial loss: 0.437573\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008060; batch adversarial loss: 0.514525\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017645; batch adversarial loss: 0.502814\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032410; batch adversarial loss: 0.442400\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018521; batch adversarial loss: 0.491742\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023383; batch adversarial loss: 0.465883\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042921; batch adversarial loss: 0.434777\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011568; batch adversarial loss: 0.434146\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009901; batch adversarial loss: 0.497945\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019909; batch adversarial loss: 0.555894\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042729; batch adversarial loss: 0.404555\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019126; batch adversarial loss: 0.398537\n",
      "epoch 169; iter: 0; batch classifier loss: 0.045615; batch adversarial loss: 0.506520\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011838; batch adversarial loss: 0.508832\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028343; batch adversarial loss: 0.442930\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025392; batch adversarial loss: 0.505018\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031514; batch adversarial loss: 0.479233\n",
      "epoch 174; iter: 0; batch classifier loss: 0.052846; batch adversarial loss: 0.539240\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036216; batch adversarial loss: 0.431130\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035041; batch adversarial loss: 0.443362\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023012; batch adversarial loss: 0.429557\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029147; batch adversarial loss: 0.410313\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027700; batch adversarial loss: 0.485851\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011095; batch adversarial loss: 0.527371\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027831; batch adversarial loss: 0.430435\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009801; batch adversarial loss: 0.537247\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023546; batch adversarial loss: 0.514588\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022718; batch adversarial loss: 0.463798\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017725; batch adversarial loss: 0.522343\n",
      "epoch 186; iter: 0; batch classifier loss: 0.058129; batch adversarial loss: 0.495216\n",
      "epoch 187; iter: 0; batch classifier loss: 0.003476; batch adversarial loss: 0.455515\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014434; batch adversarial loss: 0.515406\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020333; batch adversarial loss: 0.385925\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025583; batch adversarial loss: 0.452208\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025674; batch adversarial loss: 0.482955\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034246; batch adversarial loss: 0.534451\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031864; batch adversarial loss: 0.365812\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006996; batch adversarial loss: 0.454022\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009537; batch adversarial loss: 0.568845\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022627; batch adversarial loss: 0.392108\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025960; batch adversarial loss: 0.366290\n",
      "epoch 198; iter: 0; batch classifier loss: 0.034982; batch adversarial loss: 0.479102\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017031; batch adversarial loss: 0.514723\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722675; batch adversarial loss: 0.982106\n",
      "epoch 1; iter: 0; batch classifier loss: 0.540926; batch adversarial loss: 0.962612\n",
      "epoch 2; iter: 0; batch classifier loss: 0.414803; batch adversarial loss: 0.894436\n",
      "epoch 3; iter: 0; batch classifier loss: 0.312438; batch adversarial loss: 0.835233\n",
      "epoch 4; iter: 0; batch classifier loss: 0.346230; batch adversarial loss: 0.783448\n",
      "epoch 5; iter: 0; batch classifier loss: 0.335397; batch adversarial loss: 0.751157\n",
      "epoch 6; iter: 0; batch classifier loss: 0.397972; batch adversarial loss: 0.682810\n",
      "epoch 7; iter: 0; batch classifier loss: 0.368955; batch adversarial loss: 0.630967\n",
      "epoch 8; iter: 0; batch classifier loss: 0.344394; batch adversarial loss: 0.631579\n",
      "epoch 9; iter: 0; batch classifier loss: 0.317884; batch adversarial loss: 0.614823\n",
      "epoch 10; iter: 0; batch classifier loss: 0.242873; batch adversarial loss: 0.577299\n",
      "epoch 11; iter: 0; batch classifier loss: 0.284964; batch adversarial loss: 0.540179\n",
      "epoch 12; iter: 0; batch classifier loss: 0.288298; batch adversarial loss: 0.564984\n",
      "epoch 13; iter: 0; batch classifier loss: 0.257847; batch adversarial loss: 0.516915\n",
      "epoch 14; iter: 0; batch classifier loss: 0.303251; batch adversarial loss: 0.525040\n",
      "epoch 15; iter: 0; batch classifier loss: 0.227825; batch adversarial loss: 0.528608\n",
      "epoch 16; iter: 0; batch classifier loss: 0.221518; batch adversarial loss: 0.501743\n",
      "epoch 17; iter: 0; batch classifier loss: 0.264857; batch adversarial loss: 0.434027\n",
      "epoch 18; iter: 0; batch classifier loss: 0.210346; batch adversarial loss: 0.514447\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236706; batch adversarial loss: 0.438212\n",
      "epoch 20; iter: 0; batch classifier loss: 0.230964; batch adversarial loss: 0.470040\n",
      "epoch 21; iter: 0; batch classifier loss: 0.248271; batch adversarial loss: 0.436876\n",
      "epoch 22; iter: 0; batch classifier loss: 0.230628; batch adversarial loss: 0.484603\n",
      "epoch 23; iter: 0; batch classifier loss: 0.265311; batch adversarial loss: 0.427480\n",
      "epoch 24; iter: 0; batch classifier loss: 0.215397; batch adversarial loss: 0.459508\n",
      "epoch 25; iter: 0; batch classifier loss: 0.274893; batch adversarial loss: 0.479823\n",
      "epoch 26; iter: 0; batch classifier loss: 0.237079; batch adversarial loss: 0.441330\n",
      "epoch 27; iter: 0; batch classifier loss: 0.208024; batch adversarial loss: 0.413430\n",
      "epoch 28; iter: 0; batch classifier loss: 0.202734; batch adversarial loss: 0.432501\n",
      "epoch 29; iter: 0; batch classifier loss: 0.263866; batch adversarial loss: 0.393550\n",
      "epoch 30; iter: 0; batch classifier loss: 0.272458; batch adversarial loss: 0.405690\n",
      "epoch 31; iter: 0; batch classifier loss: 0.216026; batch adversarial loss: 0.379465\n",
      "epoch 32; iter: 0; batch classifier loss: 0.219484; batch adversarial loss: 0.483081\n",
      "epoch 33; iter: 0; batch classifier loss: 0.203948; batch adversarial loss: 0.359928\n",
      "epoch 34; iter: 0; batch classifier loss: 0.306416; batch adversarial loss: 0.385022\n",
      "epoch 35; iter: 0; batch classifier loss: 0.177808; batch adversarial loss: 0.383054\n",
      "epoch 36; iter: 0; batch classifier loss: 0.206544; batch adversarial loss: 0.424572\n",
      "epoch 37; iter: 0; batch classifier loss: 0.225950; batch adversarial loss: 0.389596\n",
      "epoch 38; iter: 0; batch classifier loss: 0.166679; batch adversarial loss: 0.456168\n",
      "epoch 39; iter: 0; batch classifier loss: 0.199657; batch adversarial loss: 0.439495\n",
      "epoch 40; iter: 0; batch classifier loss: 0.157289; batch adversarial loss: 0.364249\n",
      "epoch 41; iter: 0; batch classifier loss: 0.167099; batch adversarial loss: 0.314829\n",
      "epoch 42; iter: 0; batch classifier loss: 0.266172; batch adversarial loss: 0.418358\n",
      "epoch 43; iter: 0; batch classifier loss: 0.174174; batch adversarial loss: 0.467948\n",
      "epoch 44; iter: 0; batch classifier loss: 0.196836; batch adversarial loss: 0.448872\n",
      "epoch 45; iter: 0; batch classifier loss: 0.148512; batch adversarial loss: 0.438535\n",
      "epoch 46; iter: 0; batch classifier loss: 0.133488; batch adversarial loss: 0.387284\n",
      "epoch 47; iter: 0; batch classifier loss: 0.208799; batch adversarial loss: 0.452720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.158133; batch adversarial loss: 0.400973\n",
      "epoch 49; iter: 0; batch classifier loss: 0.145880; batch adversarial loss: 0.359062\n",
      "epoch 50; iter: 0; batch classifier loss: 0.169295; batch adversarial loss: 0.365694\n",
      "epoch 51; iter: 0; batch classifier loss: 0.101474; batch adversarial loss: 0.424914\n",
      "epoch 52; iter: 0; batch classifier loss: 0.130185; batch adversarial loss: 0.451160\n",
      "epoch 53; iter: 0; batch classifier loss: 0.138699; batch adversarial loss: 0.453983\n",
      "epoch 54; iter: 0; batch classifier loss: 0.172590; batch adversarial loss: 0.459599\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079385; batch adversarial loss: 0.413204\n",
      "epoch 56; iter: 0; batch classifier loss: 0.138911; batch adversarial loss: 0.415052\n",
      "epoch 57; iter: 0; batch classifier loss: 0.121350; batch adversarial loss: 0.464471\n",
      "epoch 58; iter: 0; batch classifier loss: 0.130383; batch adversarial loss: 0.436851\n",
      "epoch 59; iter: 0; batch classifier loss: 0.132063; batch adversarial loss: 0.447860\n",
      "epoch 60; iter: 0; batch classifier loss: 0.102055; batch adversarial loss: 0.386943\n",
      "epoch 61; iter: 0; batch classifier loss: 0.117838; batch adversarial loss: 0.412000\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090308; batch adversarial loss: 0.396234\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103952; batch adversarial loss: 0.380560\n",
      "epoch 64; iter: 0; batch classifier loss: 0.133365; batch adversarial loss: 0.393884\n",
      "epoch 65; iter: 0; batch classifier loss: 0.090584; batch adversarial loss: 0.409063\n",
      "epoch 66; iter: 0; batch classifier loss: 0.122008; batch adversarial loss: 0.448452\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098714; batch adversarial loss: 0.385517\n",
      "epoch 68; iter: 0; batch classifier loss: 0.115917; batch adversarial loss: 0.463799\n",
      "epoch 69; iter: 0; batch classifier loss: 0.100769; batch adversarial loss: 0.404620\n",
      "epoch 70; iter: 0; batch classifier loss: 0.094618; batch adversarial loss: 0.594891\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063412; batch adversarial loss: 0.388201\n",
      "epoch 72; iter: 0; batch classifier loss: 0.091673; batch adversarial loss: 0.416282\n",
      "epoch 73; iter: 0; batch classifier loss: 0.110422; batch adversarial loss: 0.418945\n",
      "epoch 74; iter: 0; batch classifier loss: 0.100127; batch adversarial loss: 0.401947\n",
      "epoch 75; iter: 0; batch classifier loss: 0.074476; batch adversarial loss: 0.442663\n",
      "epoch 76; iter: 0; batch classifier loss: 0.071725; batch adversarial loss: 0.418858\n",
      "epoch 77; iter: 0; batch classifier loss: 0.139365; batch adversarial loss: 0.446144\n",
      "epoch 78; iter: 0; batch classifier loss: 0.101316; batch adversarial loss: 0.438216\n",
      "epoch 79; iter: 0; batch classifier loss: 0.090454; batch adversarial loss: 0.384031\n",
      "epoch 80; iter: 0; batch classifier loss: 0.095168; batch adversarial loss: 0.454459\n",
      "epoch 81; iter: 0; batch classifier loss: 0.078963; batch adversarial loss: 0.424201\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062588; batch adversarial loss: 0.439104\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083370; batch adversarial loss: 0.423539\n",
      "epoch 84; iter: 0; batch classifier loss: 0.098561; batch adversarial loss: 0.400979\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083176; batch adversarial loss: 0.545973\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089339; batch adversarial loss: 0.378399\n",
      "epoch 87; iter: 0; batch classifier loss: 0.085462; batch adversarial loss: 0.394046\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057367; batch adversarial loss: 0.393989\n",
      "epoch 89; iter: 0; batch classifier loss: 0.077063; batch adversarial loss: 0.426679\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054135; batch adversarial loss: 0.391509\n",
      "epoch 91; iter: 0; batch classifier loss: 0.053595; batch adversarial loss: 0.343388\n",
      "epoch 92; iter: 0; batch classifier loss: 0.072767; batch adversarial loss: 0.515113\n",
      "epoch 93; iter: 0; batch classifier loss: 0.087627; batch adversarial loss: 0.500248\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064868; batch adversarial loss: 0.427524\n",
      "epoch 95; iter: 0; batch classifier loss: 0.074854; batch adversarial loss: 0.411026\n",
      "epoch 96; iter: 0; batch classifier loss: 0.094392; batch adversarial loss: 0.422695\n",
      "epoch 97; iter: 0; batch classifier loss: 0.097196; batch adversarial loss: 0.377098\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050422; batch adversarial loss: 0.395138\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046235; batch adversarial loss: 0.471281\n",
      "epoch 100; iter: 0; batch classifier loss: 0.072406; batch adversarial loss: 0.454550\n",
      "epoch 101; iter: 0; batch classifier loss: 0.092520; batch adversarial loss: 0.392485\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067445; batch adversarial loss: 0.443419\n",
      "epoch 103; iter: 0; batch classifier loss: 0.074624; batch adversarial loss: 0.388856\n",
      "epoch 104; iter: 0; batch classifier loss: 0.104654; batch adversarial loss: 0.356160\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043232; batch adversarial loss: 0.404613\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049080; batch adversarial loss: 0.377097\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041061; batch adversarial loss: 0.429093\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065944; batch adversarial loss: 0.450807\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066328; batch adversarial loss: 0.470470\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040635; batch adversarial loss: 0.443034\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069037; batch adversarial loss: 0.469697\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054538; batch adversarial loss: 0.500839\n",
      "epoch 113; iter: 0; batch classifier loss: 0.084932; batch adversarial loss: 0.478956\n",
      "epoch 114; iter: 0; batch classifier loss: 0.066485; batch adversarial loss: 0.404412\n",
      "epoch 115; iter: 0; batch classifier loss: 0.055197; batch adversarial loss: 0.472011\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032910; batch adversarial loss: 0.427434\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053022; batch adversarial loss: 0.403199\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035423; batch adversarial loss: 0.406194\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037794; batch adversarial loss: 0.428682\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053947; batch adversarial loss: 0.443074\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031601; batch adversarial loss: 0.384757\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040945; batch adversarial loss: 0.480086\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048319; batch adversarial loss: 0.423710\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032694; batch adversarial loss: 0.459033\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030904; batch adversarial loss: 0.485258\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037371; batch adversarial loss: 0.360640\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022300; batch adversarial loss: 0.470711\n",
      "epoch 128; iter: 0; batch classifier loss: 0.048408; batch adversarial loss: 0.445762\n",
      "epoch 129; iter: 0; batch classifier loss: 0.053570; batch adversarial loss: 0.512272\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028357; batch adversarial loss: 0.458523\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050990; batch adversarial loss: 0.440523\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058745; batch adversarial loss: 0.449871\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039759; batch adversarial loss: 0.499967\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051838; batch adversarial loss: 0.391662\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051137; batch adversarial loss: 0.348641\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016923; batch adversarial loss: 0.491319\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015153; batch adversarial loss: 0.474022\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029157; batch adversarial loss: 0.497102\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038558; batch adversarial loss: 0.537355\n",
      "epoch 140; iter: 0; batch classifier loss: 0.058027; batch adversarial loss: 0.450271\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026833; batch adversarial loss: 0.479957\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020519; batch adversarial loss: 0.440504\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024152; batch adversarial loss: 0.482239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.059645; batch adversarial loss: 0.706538\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033549; batch adversarial loss: 0.482096\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038188; batch adversarial loss: 0.606437\n",
      "epoch 147; iter: 0; batch classifier loss: 0.080654; batch adversarial loss: 0.537060\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028156; batch adversarial loss: 0.445378\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035366; batch adversarial loss: 0.571228\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037074; batch adversarial loss: 0.536730\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012909; batch adversarial loss: 0.390559\n",
      "epoch 152; iter: 0; batch classifier loss: 0.058144; batch adversarial loss: 0.481500\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048795; batch adversarial loss: 0.534327\n",
      "epoch 154; iter: 0; batch classifier loss: 0.055752; batch adversarial loss: 0.551620\n",
      "epoch 155; iter: 0; batch classifier loss: 0.104847; batch adversarial loss: 0.633568\n",
      "epoch 156; iter: 0; batch classifier loss: 0.095759; batch adversarial loss: 0.634066\n",
      "epoch 157; iter: 0; batch classifier loss: 0.143937; batch adversarial loss: 0.663535\n",
      "epoch 158; iter: 0; batch classifier loss: 0.080696; batch adversarial loss: 0.529529\n",
      "epoch 159; iter: 0; batch classifier loss: 0.089746; batch adversarial loss: 0.608968\n",
      "epoch 160; iter: 0; batch classifier loss: 0.170134; batch adversarial loss: 0.694834\n",
      "epoch 161; iter: 0; batch classifier loss: 0.160546; batch adversarial loss: 0.646914\n",
      "epoch 162; iter: 0; batch classifier loss: 0.154987; batch adversarial loss: 0.564869\n",
      "epoch 163; iter: 0; batch classifier loss: 0.208492; batch adversarial loss: 0.682912\n",
      "epoch 164; iter: 0; batch classifier loss: 0.105936; batch adversarial loss: 0.627237\n",
      "epoch 165; iter: 0; batch classifier loss: 0.115359; batch adversarial loss: 0.563975\n",
      "epoch 166; iter: 0; batch classifier loss: 0.110514; batch adversarial loss: 0.522136\n",
      "epoch 167; iter: 0; batch classifier loss: 0.263391; batch adversarial loss: 0.889595\n",
      "epoch 168; iter: 0; batch classifier loss: 0.182006; batch adversarial loss: 0.649846\n",
      "epoch 169; iter: 0; batch classifier loss: 0.100077; batch adversarial loss: 0.467406\n",
      "epoch 170; iter: 0; batch classifier loss: 0.147559; batch adversarial loss: 0.537781\n",
      "epoch 171; iter: 0; batch classifier loss: 0.219172; batch adversarial loss: 0.647640\n",
      "epoch 172; iter: 0; batch classifier loss: 0.157970; batch adversarial loss: 0.531843\n",
      "epoch 173; iter: 0; batch classifier loss: 0.208239; batch adversarial loss: 0.559615\n",
      "epoch 174; iter: 0; batch classifier loss: 0.122522; batch adversarial loss: 0.488571\n",
      "epoch 175; iter: 0; batch classifier loss: 0.163142; batch adversarial loss: 0.604460\n",
      "epoch 176; iter: 0; batch classifier loss: 0.111941; batch adversarial loss: 0.491277\n",
      "epoch 177; iter: 0; batch classifier loss: 0.101199; batch adversarial loss: 0.450399\n",
      "epoch 178; iter: 0; batch classifier loss: 0.099066; batch adversarial loss: 0.528756\n",
      "epoch 179; iter: 0; batch classifier loss: 0.119345; batch adversarial loss: 0.641840\n",
      "epoch 180; iter: 0; batch classifier loss: 0.107166; batch adversarial loss: 0.452118\n",
      "epoch 181; iter: 0; batch classifier loss: 0.137062; batch adversarial loss: 0.544770\n",
      "epoch 182; iter: 0; batch classifier loss: 0.173595; batch adversarial loss: 0.529885\n",
      "epoch 183; iter: 0; batch classifier loss: 0.092736; batch adversarial loss: 0.522638\n",
      "epoch 184; iter: 0; batch classifier loss: 0.177473; batch adversarial loss: 0.606213\n",
      "epoch 185; iter: 0; batch classifier loss: 0.153507; batch adversarial loss: 0.539762\n",
      "epoch 186; iter: 0; batch classifier loss: 0.156238; batch adversarial loss: 0.616135\n",
      "epoch 187; iter: 0; batch classifier loss: 0.204344; batch adversarial loss: 0.596326\n",
      "epoch 188; iter: 0; batch classifier loss: 0.108780; batch adversarial loss: 0.467766\n",
      "epoch 189; iter: 0; batch classifier loss: 0.115847; batch adversarial loss: 0.515580\n",
      "epoch 190; iter: 0; batch classifier loss: 0.104136; batch adversarial loss: 0.474608\n",
      "epoch 191; iter: 0; batch classifier loss: 0.088464; batch adversarial loss: 0.516680\n",
      "epoch 192; iter: 0; batch classifier loss: 0.060011; batch adversarial loss: 0.497776\n",
      "epoch 193; iter: 0; batch classifier loss: 0.128162; batch adversarial loss: 0.575780\n",
      "epoch 194; iter: 0; batch classifier loss: 0.091286; batch adversarial loss: 0.473980\n",
      "epoch 195; iter: 0; batch classifier loss: 0.117990; batch adversarial loss: 0.484249\n",
      "epoch 196; iter: 0; batch classifier loss: 0.171785; batch adversarial loss: 0.533226\n",
      "epoch 197; iter: 0; batch classifier loss: 0.069963; batch adversarial loss: 0.376763\n",
      "epoch 198; iter: 0; batch classifier loss: 0.068910; batch adversarial loss: 0.401334\n",
      "epoch 199; iter: 0; batch classifier loss: 0.131394; batch adversarial loss: 0.521617\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722035; batch adversarial loss: 1.027417\n",
      "epoch 1; iter: 0; batch classifier loss: 0.609919; batch adversarial loss: 1.087543\n",
      "epoch 2; iter: 0; batch classifier loss: 0.817234; batch adversarial loss: 1.080443\n",
      "epoch 3; iter: 0; batch classifier loss: 0.955175; batch adversarial loss: 0.991174\n",
      "epoch 4; iter: 0; batch classifier loss: 1.014823; batch adversarial loss: 0.881397\n",
      "epoch 5; iter: 0; batch classifier loss: 1.031537; batch adversarial loss: 0.802125\n",
      "epoch 6; iter: 0; batch classifier loss: 0.923396; batch adversarial loss: 0.731822\n",
      "epoch 7; iter: 0; batch classifier loss: 0.997274; batch adversarial loss: 0.689027\n",
      "epoch 8; iter: 0; batch classifier loss: 0.964855; batch adversarial loss: 0.617674\n",
      "epoch 9; iter: 0; batch classifier loss: 0.873466; batch adversarial loss: 0.574778\n",
      "epoch 10; iter: 0; batch classifier loss: 0.438443; batch adversarial loss: 0.545615\n",
      "epoch 11; iter: 0; batch classifier loss: 0.290289; batch adversarial loss: 0.537571\n",
      "epoch 12; iter: 0; batch classifier loss: 0.345563; batch adversarial loss: 0.490993\n",
      "epoch 13; iter: 0; batch classifier loss: 0.274759; batch adversarial loss: 0.527798\n",
      "epoch 14; iter: 0; batch classifier loss: 0.258000; batch adversarial loss: 0.484643\n",
      "epoch 15; iter: 0; batch classifier loss: 0.188416; batch adversarial loss: 0.522671\n",
      "epoch 16; iter: 0; batch classifier loss: 0.211182; batch adversarial loss: 0.481026\n",
      "epoch 17; iter: 0; batch classifier loss: 0.227189; batch adversarial loss: 0.530277\n",
      "epoch 18; iter: 0; batch classifier loss: 0.224641; batch adversarial loss: 0.495498\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223296; batch adversarial loss: 0.505104\n",
      "epoch 20; iter: 0; batch classifier loss: 0.221761; batch adversarial loss: 0.504100\n",
      "epoch 21; iter: 0; batch classifier loss: 0.169008; batch adversarial loss: 0.377818\n",
      "epoch 22; iter: 0; batch classifier loss: 0.144937; batch adversarial loss: 0.544816\n",
      "epoch 23; iter: 0; batch classifier loss: 0.201041; batch adversarial loss: 0.489708\n",
      "epoch 24; iter: 0; batch classifier loss: 0.136885; batch adversarial loss: 0.429383\n",
      "epoch 25; iter: 0; batch classifier loss: 0.176788; batch adversarial loss: 0.498441\n",
      "epoch 26; iter: 0; batch classifier loss: 0.146288; batch adversarial loss: 0.465224\n",
      "epoch 27; iter: 0; batch classifier loss: 0.143098; batch adversarial loss: 0.463035\n",
      "epoch 28; iter: 0; batch classifier loss: 0.170570; batch adversarial loss: 0.455624\n",
      "epoch 29; iter: 0; batch classifier loss: 0.175815; batch adversarial loss: 0.426716\n",
      "epoch 30; iter: 0; batch classifier loss: 0.165874; batch adversarial loss: 0.424789\n",
      "epoch 31; iter: 0; batch classifier loss: 0.233145; batch adversarial loss: 0.459163\n",
      "epoch 32; iter: 0; batch classifier loss: 0.190276; batch adversarial loss: 0.464625\n",
      "epoch 33; iter: 0; batch classifier loss: 0.130357; batch adversarial loss: 0.444551\n",
      "epoch 34; iter: 0; batch classifier loss: 0.224962; batch adversarial loss: 0.482660\n",
      "epoch 35; iter: 0; batch classifier loss: 0.185291; batch adversarial loss: 0.415335\n",
      "epoch 36; iter: 0; batch classifier loss: 0.159615; batch adversarial loss: 0.459975\n",
      "epoch 37; iter: 0; batch classifier loss: 0.141668; batch adversarial loss: 0.498671\n",
      "epoch 38; iter: 0; batch classifier loss: 0.124048; batch adversarial loss: 0.444885\n",
      "epoch 39; iter: 0; batch classifier loss: 0.120736; batch adversarial loss: 0.428146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.159060; batch adversarial loss: 0.479107\n",
      "epoch 41; iter: 0; batch classifier loss: 0.119394; batch adversarial loss: 0.460398\n",
      "epoch 42; iter: 0; batch classifier loss: 0.114737; batch adversarial loss: 0.458584\n",
      "epoch 43; iter: 0; batch classifier loss: 0.102347; batch adversarial loss: 0.374366\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098591; batch adversarial loss: 0.426449\n",
      "epoch 45; iter: 0; batch classifier loss: 0.106660; batch adversarial loss: 0.410966\n",
      "epoch 46; iter: 0; batch classifier loss: 0.107996; batch adversarial loss: 0.379959\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095306; batch adversarial loss: 0.447777\n",
      "epoch 48; iter: 0; batch classifier loss: 0.107876; batch adversarial loss: 0.456819\n",
      "epoch 49; iter: 0; batch classifier loss: 0.125502; batch adversarial loss: 0.439748\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091566; batch adversarial loss: 0.479303\n",
      "epoch 51; iter: 0; batch classifier loss: 0.094656; batch adversarial loss: 0.525458\n",
      "epoch 52; iter: 0; batch classifier loss: 0.076036; batch adversarial loss: 0.473598\n",
      "epoch 53; iter: 0; batch classifier loss: 0.060256; batch adversarial loss: 0.385461\n",
      "epoch 54; iter: 0; batch classifier loss: 0.075687; batch adversarial loss: 0.478066\n",
      "epoch 55; iter: 0; batch classifier loss: 0.065293; batch adversarial loss: 0.446445\n",
      "epoch 56; iter: 0; batch classifier loss: 0.060909; batch adversarial loss: 0.432341\n",
      "epoch 57; iter: 0; batch classifier loss: 0.084948; batch adversarial loss: 0.458286\n",
      "epoch 58; iter: 0; batch classifier loss: 0.062371; batch adversarial loss: 0.473608\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087611; batch adversarial loss: 0.443051\n",
      "epoch 60; iter: 0; batch classifier loss: 0.069890; batch adversarial loss: 0.450419\n",
      "epoch 61; iter: 0; batch classifier loss: 0.048669; batch adversarial loss: 0.447334\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078625; batch adversarial loss: 0.448266\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091273; batch adversarial loss: 0.535484\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068410; batch adversarial loss: 0.539920\n",
      "epoch 65; iter: 0; batch classifier loss: 0.041994; batch adversarial loss: 0.463097\n",
      "epoch 66; iter: 0; batch classifier loss: 0.049324; batch adversarial loss: 0.472224\n",
      "epoch 67; iter: 0; batch classifier loss: 0.055326; batch adversarial loss: 0.492577\n",
      "epoch 68; iter: 0; batch classifier loss: 0.062039; batch adversarial loss: 0.335453\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087067; batch adversarial loss: 0.413315\n",
      "epoch 70; iter: 0; batch classifier loss: 0.047764; batch adversarial loss: 0.422945\n",
      "epoch 71; iter: 0; batch classifier loss: 0.055076; batch adversarial loss: 0.521524\n",
      "epoch 72; iter: 0; batch classifier loss: 0.047756; batch adversarial loss: 0.448665\n",
      "epoch 73; iter: 0; batch classifier loss: 0.048717; batch adversarial loss: 0.420321\n",
      "epoch 74; iter: 0; batch classifier loss: 0.050313; batch adversarial loss: 0.423131\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075127; batch adversarial loss: 0.444741\n",
      "epoch 76; iter: 0; batch classifier loss: 0.044095; batch adversarial loss: 0.462496\n",
      "epoch 77; iter: 0; batch classifier loss: 0.041956; batch adversarial loss: 0.526599\n",
      "epoch 78; iter: 0; batch classifier loss: 0.026334; batch adversarial loss: 0.543308\n",
      "epoch 79; iter: 0; batch classifier loss: 0.042453; batch adversarial loss: 0.364287\n",
      "epoch 80; iter: 0; batch classifier loss: 0.065019; batch adversarial loss: 0.441873\n",
      "epoch 81; iter: 0; batch classifier loss: 0.030055; batch adversarial loss: 0.459566\n",
      "epoch 82; iter: 0; batch classifier loss: 0.044641; batch adversarial loss: 0.388434\n",
      "epoch 83; iter: 0; batch classifier loss: 0.034066; batch adversarial loss: 0.462621\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051395; batch adversarial loss: 0.426239\n",
      "epoch 85; iter: 0; batch classifier loss: 0.015397; batch adversarial loss: 0.509826\n",
      "epoch 86; iter: 0; batch classifier loss: 0.039231; batch adversarial loss: 0.440889\n",
      "epoch 87; iter: 0; batch classifier loss: 0.043349; batch adversarial loss: 0.428582\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073477; batch adversarial loss: 0.482629\n",
      "epoch 89; iter: 0; batch classifier loss: 0.044555; batch adversarial loss: 0.494739\n",
      "epoch 90; iter: 0; batch classifier loss: 0.036557; batch adversarial loss: 0.470937\n",
      "epoch 91; iter: 0; batch classifier loss: 0.040110; batch adversarial loss: 0.457832\n",
      "epoch 92; iter: 0; batch classifier loss: 0.042636; batch adversarial loss: 0.418552\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044279; batch adversarial loss: 0.457939\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033362; batch adversarial loss: 0.405234\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048209; batch adversarial loss: 0.368601\n",
      "epoch 96; iter: 0; batch classifier loss: 0.025640; batch adversarial loss: 0.437998\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047896; batch adversarial loss: 0.596464\n",
      "epoch 98; iter: 0; batch classifier loss: 0.033515; batch adversarial loss: 0.474312\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039836; batch adversarial loss: 0.508475\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039934; batch adversarial loss: 0.413160\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056513; batch adversarial loss: 0.441377\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032505; batch adversarial loss: 0.459698\n",
      "epoch 103; iter: 0; batch classifier loss: 0.030316; batch adversarial loss: 0.443414\n",
      "epoch 104; iter: 0; batch classifier loss: 0.021240; batch adversarial loss: 0.557892\n",
      "epoch 105; iter: 0; batch classifier loss: 0.039953; batch adversarial loss: 0.332009\n",
      "epoch 106; iter: 0; batch classifier loss: 0.020454; batch adversarial loss: 0.416407\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028061; batch adversarial loss: 0.435046\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051223; batch adversarial loss: 0.438832\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049879; batch adversarial loss: 0.494227\n",
      "epoch 110; iter: 0; batch classifier loss: 0.020717; batch adversarial loss: 0.468683\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028055; batch adversarial loss: 0.481067\n",
      "epoch 112; iter: 0; batch classifier loss: 0.081611; batch adversarial loss: 0.398755\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042793; batch adversarial loss: 0.423067\n",
      "epoch 114; iter: 0; batch classifier loss: 0.058846; batch adversarial loss: 0.463992\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034764; batch adversarial loss: 0.509141\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022882; batch adversarial loss: 0.433740\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039002; batch adversarial loss: 0.434748\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024145; batch adversarial loss: 0.519818\n",
      "epoch 119; iter: 0; batch classifier loss: 0.028650; batch adversarial loss: 0.416082\n",
      "epoch 120; iter: 0; batch classifier loss: 0.014714; batch adversarial loss: 0.434761\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025583; batch adversarial loss: 0.388858\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034121; batch adversarial loss: 0.445143\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063697; batch adversarial loss: 0.463811\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035548; batch adversarial loss: 0.402245\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053751; batch adversarial loss: 0.459288\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028680; batch adversarial loss: 0.485654\n",
      "epoch 127; iter: 0; batch classifier loss: 0.014487; batch adversarial loss: 0.494060\n",
      "epoch 128; iter: 0; batch classifier loss: 0.059142; batch adversarial loss: 0.478017\n",
      "epoch 129; iter: 0; batch classifier loss: 0.073614; batch adversarial loss: 0.517096\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023073; batch adversarial loss: 0.507806\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017349; batch adversarial loss: 0.421873\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030622; batch adversarial loss: 0.435067\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021252; batch adversarial loss: 0.556260\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033629; batch adversarial loss: 0.415003\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021782; batch adversarial loss: 0.412559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.029862; batch adversarial loss: 0.411956\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032929; batch adversarial loss: 0.430835\n",
      "epoch 138; iter: 0; batch classifier loss: 0.047008; batch adversarial loss: 0.402015\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019233; batch adversarial loss: 0.589046\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023083; batch adversarial loss: 0.389229\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026381; batch adversarial loss: 0.531908\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045871; batch adversarial loss: 0.476880\n",
      "epoch 143; iter: 0; batch classifier loss: 0.012649; batch adversarial loss: 0.404120\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024779; batch adversarial loss: 0.440421\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025595; batch adversarial loss: 0.471196\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029911; batch adversarial loss: 0.365998\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026689; batch adversarial loss: 0.429351\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021752; batch adversarial loss: 0.446949\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025965; batch adversarial loss: 0.449257\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012350; batch adversarial loss: 0.429447\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048129; batch adversarial loss: 0.430550\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038739; batch adversarial loss: 0.413289\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018301; batch adversarial loss: 0.373980\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010797; batch adversarial loss: 0.474139\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011817; batch adversarial loss: 0.492071\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011868; batch adversarial loss: 0.449677\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013972; batch adversarial loss: 0.413151\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028359; batch adversarial loss: 0.466246\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030772; batch adversarial loss: 0.435953\n",
      "epoch 160; iter: 0; batch classifier loss: 0.042661; batch adversarial loss: 0.497281\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024201; batch adversarial loss: 0.468524\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013625; batch adversarial loss: 0.396101\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007594; batch adversarial loss: 0.409240\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029310; batch adversarial loss: 0.377379\n",
      "epoch 165; iter: 0; batch classifier loss: 0.006586; batch adversarial loss: 0.346944\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017627; batch adversarial loss: 0.525992\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011369; batch adversarial loss: 0.551518\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018272; batch adversarial loss: 0.482716\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007409; batch adversarial loss: 0.447451\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010606; batch adversarial loss: 0.313026\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021868; batch adversarial loss: 0.410979\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007391; batch adversarial loss: 0.485538\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011229; batch adversarial loss: 0.414335\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011528; batch adversarial loss: 0.611565\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020041; batch adversarial loss: 0.405629\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014351; batch adversarial loss: 0.392454\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012929; batch adversarial loss: 0.515636\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028947; batch adversarial loss: 0.493122\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026320; batch adversarial loss: 0.435358\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020403; batch adversarial loss: 0.475303\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027935; batch adversarial loss: 0.415864\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009957; batch adversarial loss: 0.451657\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012542; batch adversarial loss: 0.462575\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026518; batch adversarial loss: 0.424389\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022968; batch adversarial loss: 0.483517\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019881; batch adversarial loss: 0.492773\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023826; batch adversarial loss: 0.413063\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017986; batch adversarial loss: 0.457240\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007424; batch adversarial loss: 0.327208\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005912; batch adversarial loss: 0.426220\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023523; batch adversarial loss: 0.442415\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028046; batch adversarial loss: 0.421534\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023386; batch adversarial loss: 0.395958\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018310; batch adversarial loss: 0.322624\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017897; batch adversarial loss: 0.402707\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025108; batch adversarial loss: 0.439585\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014233; batch adversarial loss: 0.502235\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014214; batch adversarial loss: 0.414325\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022362; batch adversarial loss: 0.408253\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701971; batch adversarial loss: 0.644681\n",
      "epoch 1; iter: 0; batch classifier loss: 0.413385; batch adversarial loss: 0.621356\n",
      "epoch 2; iter: 0; batch classifier loss: 0.345996; batch adversarial loss: 0.618338\n",
      "epoch 3; iter: 0; batch classifier loss: 0.318277; batch adversarial loss: 0.555654\n",
      "epoch 4; iter: 0; batch classifier loss: 0.316140; batch adversarial loss: 0.581837\n",
      "epoch 5; iter: 0; batch classifier loss: 0.278288; batch adversarial loss: 0.538058\n",
      "epoch 6; iter: 0; batch classifier loss: 0.312926; batch adversarial loss: 0.534876\n",
      "epoch 7; iter: 0; batch classifier loss: 0.210383; batch adversarial loss: 0.530031\n",
      "epoch 8; iter: 0; batch classifier loss: 0.276177; batch adversarial loss: 0.532045\n",
      "epoch 9; iter: 0; batch classifier loss: 0.275370; batch adversarial loss: 0.468763\n",
      "epoch 10; iter: 0; batch classifier loss: 0.284841; batch adversarial loss: 0.530446\n",
      "epoch 11; iter: 0; batch classifier loss: 0.267819; batch adversarial loss: 0.530679\n",
      "epoch 12; iter: 0; batch classifier loss: 0.167466; batch adversarial loss: 0.485020\n",
      "epoch 13; iter: 0; batch classifier loss: 0.251075; batch adversarial loss: 0.483074\n",
      "epoch 14; iter: 0; batch classifier loss: 0.144240; batch adversarial loss: 0.469539\n",
      "epoch 15; iter: 0; batch classifier loss: 0.221199; batch adversarial loss: 0.540281\n",
      "epoch 16; iter: 0; batch classifier loss: 0.253340; batch adversarial loss: 0.547726\n",
      "epoch 17; iter: 0; batch classifier loss: 0.245549; batch adversarial loss: 0.557981\n",
      "epoch 18; iter: 0; batch classifier loss: 0.262713; batch adversarial loss: 0.433185\n",
      "epoch 19; iter: 0; batch classifier loss: 0.297860; batch adversarial loss: 0.480655\n",
      "epoch 20; iter: 0; batch classifier loss: 0.276039; batch adversarial loss: 0.499600\n",
      "epoch 21; iter: 0; batch classifier loss: 0.344215; batch adversarial loss: 0.451076\n",
      "epoch 22; iter: 0; batch classifier loss: 0.421023; batch adversarial loss: 0.503907\n",
      "epoch 23; iter: 0; batch classifier loss: 0.390213; batch adversarial loss: 0.512758\n",
      "epoch 24; iter: 0; batch classifier loss: 0.258780; batch adversarial loss: 0.505895\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179129; batch adversarial loss: 0.485562\n",
      "epoch 26; iter: 0; batch classifier loss: 0.215193; batch adversarial loss: 0.462969\n",
      "epoch 27; iter: 0; batch classifier loss: 0.174730; batch adversarial loss: 0.417275\n",
      "epoch 28; iter: 0; batch classifier loss: 0.192912; batch adversarial loss: 0.389801\n",
      "epoch 29; iter: 0; batch classifier loss: 0.192175; batch adversarial loss: 0.479067\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130491; batch adversarial loss: 0.364981\n",
      "epoch 31; iter: 0; batch classifier loss: 0.120366; batch adversarial loss: 0.426681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.137048; batch adversarial loss: 0.400379\n",
      "epoch 33; iter: 0; batch classifier loss: 0.176983; batch adversarial loss: 0.393251\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149894; batch adversarial loss: 0.394259\n",
      "epoch 35; iter: 0; batch classifier loss: 0.112312; batch adversarial loss: 0.441627\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109923; batch adversarial loss: 0.401326\n",
      "epoch 37; iter: 0; batch classifier loss: 0.138521; batch adversarial loss: 0.521494\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115506; batch adversarial loss: 0.454854\n",
      "epoch 39; iter: 0; batch classifier loss: 0.095051; batch adversarial loss: 0.479538\n",
      "epoch 40; iter: 0; batch classifier loss: 0.107857; batch adversarial loss: 0.523909\n",
      "epoch 41; iter: 0; batch classifier loss: 0.100698; batch adversarial loss: 0.382905\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115623; batch adversarial loss: 0.473568\n",
      "epoch 43; iter: 0; batch classifier loss: 0.136449; batch adversarial loss: 0.474870\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127069; batch adversarial loss: 0.421818\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117282; batch adversarial loss: 0.413792\n",
      "epoch 46; iter: 0; batch classifier loss: 0.212059; batch adversarial loss: 0.425371\n",
      "epoch 47; iter: 0; batch classifier loss: 0.128156; batch adversarial loss: 0.401310\n",
      "epoch 48; iter: 0; batch classifier loss: 0.145765; batch adversarial loss: 0.430870\n",
      "epoch 49; iter: 0; batch classifier loss: 0.131478; batch adversarial loss: 0.461092\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096313; batch adversarial loss: 0.488197\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083211; batch adversarial loss: 0.422402\n",
      "epoch 52; iter: 0; batch classifier loss: 0.095567; batch adversarial loss: 0.482664\n",
      "epoch 53; iter: 0; batch classifier loss: 0.108170; batch adversarial loss: 0.475724\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097357; batch adversarial loss: 0.490823\n",
      "epoch 55; iter: 0; batch classifier loss: 0.115759; batch adversarial loss: 0.464067\n",
      "epoch 56; iter: 0; batch classifier loss: 0.078236; batch adversarial loss: 0.403419\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079982; batch adversarial loss: 0.426522\n",
      "epoch 58; iter: 0; batch classifier loss: 0.079197; batch adversarial loss: 0.442823\n",
      "epoch 59; iter: 0; batch classifier loss: 0.098040; batch adversarial loss: 0.490645\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097472; batch adversarial loss: 0.451014\n",
      "epoch 61; iter: 0; batch classifier loss: 0.051399; batch adversarial loss: 0.560310\n",
      "epoch 62; iter: 0; batch classifier loss: 0.131200; batch adversarial loss: 0.410485\n",
      "epoch 63; iter: 0; batch classifier loss: 0.122633; batch adversarial loss: 0.471723\n",
      "epoch 64; iter: 0; batch classifier loss: 0.103356; batch adversarial loss: 0.518178\n",
      "epoch 65; iter: 0; batch classifier loss: 0.103252; batch adversarial loss: 0.477003\n",
      "epoch 66; iter: 0; batch classifier loss: 0.077661; batch adversarial loss: 0.400068\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098183; batch adversarial loss: 0.440628\n",
      "epoch 68; iter: 0; batch classifier loss: 0.136802; batch adversarial loss: 0.383561\n",
      "epoch 69; iter: 0; batch classifier loss: 0.079268; batch adversarial loss: 0.404079\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066950; batch adversarial loss: 0.438457\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073092; batch adversarial loss: 0.534591\n",
      "epoch 72; iter: 0; batch classifier loss: 0.129208; batch adversarial loss: 0.458157\n",
      "epoch 73; iter: 0; batch classifier loss: 0.080847; batch adversarial loss: 0.387036\n",
      "epoch 74; iter: 0; batch classifier loss: 0.155834; batch adversarial loss: 0.363614\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096338; batch adversarial loss: 0.395635\n",
      "epoch 76; iter: 0; batch classifier loss: 0.105958; batch adversarial loss: 0.385690\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064983; batch adversarial loss: 0.451174\n",
      "epoch 78; iter: 0; batch classifier loss: 0.096190; batch adversarial loss: 0.394382\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063916; batch adversarial loss: 0.473573\n",
      "epoch 80; iter: 0; batch classifier loss: 0.047339; batch adversarial loss: 0.393904\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073869; batch adversarial loss: 0.476297\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061752; batch adversarial loss: 0.461377\n",
      "epoch 83; iter: 0; batch classifier loss: 0.119302; batch adversarial loss: 0.434919\n",
      "epoch 84; iter: 0; batch classifier loss: 0.073274; batch adversarial loss: 0.486422\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077381; batch adversarial loss: 0.417704\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063574; batch adversarial loss: 0.532866\n",
      "epoch 87; iter: 0; batch classifier loss: 0.120245; batch adversarial loss: 0.519064\n",
      "epoch 88; iter: 0; batch classifier loss: 0.121173; batch adversarial loss: 0.449910\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063323; batch adversarial loss: 0.406944\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061426; batch adversarial loss: 0.418076\n",
      "epoch 91; iter: 0; batch classifier loss: 0.094728; batch adversarial loss: 0.471913\n",
      "epoch 92; iter: 0; batch classifier loss: 0.080708; batch adversarial loss: 0.546557\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072846; batch adversarial loss: 0.548083\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051496; batch adversarial loss: 0.525773\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073171; batch adversarial loss: 0.536534\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051773; batch adversarial loss: 0.513355\n",
      "epoch 97; iter: 0; batch classifier loss: 0.108844; batch adversarial loss: 0.420998\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045787; batch adversarial loss: 0.434371\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041399; batch adversarial loss: 0.437776\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046789; batch adversarial loss: 0.550990\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054997; batch adversarial loss: 0.464848\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066355; batch adversarial loss: 0.404028\n",
      "epoch 103; iter: 0; batch classifier loss: 0.073090; batch adversarial loss: 0.541871\n",
      "epoch 104; iter: 0; batch classifier loss: 0.070254; batch adversarial loss: 0.457008\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049334; batch adversarial loss: 0.586951\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034034; batch adversarial loss: 0.462243\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052161; batch adversarial loss: 0.458031\n",
      "epoch 108; iter: 0; batch classifier loss: 0.027997; batch adversarial loss: 0.522708\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071315; batch adversarial loss: 0.526900\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042233; batch adversarial loss: 0.448016\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042370; batch adversarial loss: 0.463955\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036105; batch adversarial loss: 0.437315\n",
      "epoch 113; iter: 0; batch classifier loss: 0.022009; batch adversarial loss: 0.392606\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043409; batch adversarial loss: 0.388337\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038959; batch adversarial loss: 0.422697\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057536; batch adversarial loss: 0.400508\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046232; batch adversarial loss: 0.473228\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054122; batch adversarial loss: 0.402188\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046718; batch adversarial loss: 0.382249\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045433; batch adversarial loss: 0.398069\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046844; batch adversarial loss: 0.401359\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038046; batch adversarial loss: 0.441927\n",
      "epoch 123; iter: 0; batch classifier loss: 0.071538; batch adversarial loss: 0.473645\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038240; batch adversarial loss: 0.435841\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026683; batch adversarial loss: 0.475967\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039535; batch adversarial loss: 0.502399\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026323; batch adversarial loss: 0.432520\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054419; batch adversarial loss: 0.496731\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023564; batch adversarial loss: 0.481046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.036172; batch adversarial loss: 0.407929\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031568; batch adversarial loss: 0.369638\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015994; batch adversarial loss: 0.441757\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044922; batch adversarial loss: 0.432232\n",
      "epoch 134; iter: 0; batch classifier loss: 0.007290; batch adversarial loss: 0.433099\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029994; batch adversarial loss: 0.466150\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036169; batch adversarial loss: 0.536273\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024245; batch adversarial loss: 0.466882\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023091; batch adversarial loss: 0.440877\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021497; batch adversarial loss: 0.438348\n",
      "epoch 140; iter: 0; batch classifier loss: 0.011513; batch adversarial loss: 0.473155\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029505; batch adversarial loss: 0.429877\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045490; batch adversarial loss: 0.574923\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017374; batch adversarial loss: 0.501168\n",
      "epoch 144; iter: 0; batch classifier loss: 0.079153; batch adversarial loss: 0.438692\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015490; batch adversarial loss: 0.462374\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037722; batch adversarial loss: 0.476347\n",
      "epoch 147; iter: 0; batch classifier loss: 0.049838; batch adversarial loss: 0.428945\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017931; batch adversarial loss: 0.434840\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027802; batch adversarial loss: 0.424185\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039398; batch adversarial loss: 0.476699\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015115; batch adversarial loss: 0.409800\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021394; batch adversarial loss: 0.423141\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038880; batch adversarial loss: 0.385659\n",
      "epoch 154; iter: 0; batch classifier loss: 0.008394; batch adversarial loss: 0.481311\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018873; batch adversarial loss: 0.453774\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023455; batch adversarial loss: 0.534664\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018980; batch adversarial loss: 0.532007\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042179; batch adversarial loss: 0.477529\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021287; batch adversarial loss: 0.458145\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012652; batch adversarial loss: 0.398759\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010522; batch adversarial loss: 0.495602\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043057; batch adversarial loss: 0.418082\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010388; batch adversarial loss: 0.554810\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019078; batch adversarial loss: 0.398814\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007241; batch adversarial loss: 0.502142\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033764; batch adversarial loss: 0.433669\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010835; batch adversarial loss: 0.373121\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017626; batch adversarial loss: 0.440496\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024201; batch adversarial loss: 0.479288\n",
      "epoch 170; iter: 0; batch classifier loss: 0.006694; batch adversarial loss: 0.447645\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036352; batch adversarial loss: 0.452013\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016094; batch adversarial loss: 0.397309\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019370; batch adversarial loss: 0.425335\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021316; batch adversarial loss: 0.421576\n",
      "epoch 175; iter: 0; batch classifier loss: 0.050284; batch adversarial loss: 0.501457\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027367; batch adversarial loss: 0.375111\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009033; batch adversarial loss: 0.470021\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024323; batch adversarial loss: 0.462411\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043699; batch adversarial loss: 0.350576\n",
      "epoch 180; iter: 0; batch classifier loss: 0.052770; batch adversarial loss: 0.446962\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033074; batch adversarial loss: 0.397037\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017133; batch adversarial loss: 0.475667\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033565; batch adversarial loss: 0.429300\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024495; batch adversarial loss: 0.420769\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013269; batch adversarial loss: 0.437247\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017849; batch adversarial loss: 0.357526\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012252; batch adversarial loss: 0.547423\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004761; batch adversarial loss: 0.555754\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017485; batch adversarial loss: 0.339985\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026035; batch adversarial loss: 0.540656\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026238; batch adversarial loss: 0.536117\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008117; batch adversarial loss: 0.404268\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021931; batch adversarial loss: 0.460953\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032755; batch adversarial loss: 0.449431\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023850; batch adversarial loss: 0.423250\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017124; batch adversarial loss: 0.491034\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018269; batch adversarial loss: 0.443505\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020927; batch adversarial loss: 0.567856\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020692; batch adversarial loss: 0.448913\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714221; batch adversarial loss: 0.660264\n",
      "epoch 1; iter: 0; batch classifier loss: 0.484825; batch adversarial loss: 0.624146\n",
      "epoch 2; iter: 0; batch classifier loss: 0.413187; batch adversarial loss: 0.612956\n",
      "epoch 3; iter: 0; batch classifier loss: 0.396286; batch adversarial loss: 0.616443\n",
      "epoch 4; iter: 0; batch classifier loss: 0.454134; batch adversarial loss: 0.622119\n",
      "epoch 5; iter: 0; batch classifier loss: 0.392513; batch adversarial loss: 0.582173\n",
      "epoch 6; iter: 0; batch classifier loss: 0.430250; batch adversarial loss: 0.569647\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550108; batch adversarial loss: 0.583580\n",
      "epoch 8; iter: 0; batch classifier loss: 0.402774; batch adversarial loss: 0.521253\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539929; batch adversarial loss: 0.505785\n",
      "epoch 10; iter: 0; batch classifier loss: 0.422778; batch adversarial loss: 0.554032\n",
      "epoch 11; iter: 0; batch classifier loss: 0.413033; batch adversarial loss: 0.485579\n",
      "epoch 12; iter: 0; batch classifier loss: 0.328428; batch adversarial loss: 0.510872\n",
      "epoch 13; iter: 0; batch classifier loss: 0.413912; batch adversarial loss: 0.514240\n",
      "epoch 14; iter: 0; batch classifier loss: 0.371439; batch adversarial loss: 0.542700\n",
      "epoch 15; iter: 0; batch classifier loss: 0.294895; batch adversarial loss: 0.503356\n",
      "epoch 16; iter: 0; batch classifier loss: 0.396343; batch adversarial loss: 0.447221\n",
      "epoch 17; iter: 0; batch classifier loss: 0.276168; batch adversarial loss: 0.482864\n",
      "epoch 18; iter: 0; batch classifier loss: 0.282075; batch adversarial loss: 0.532496\n",
      "epoch 19; iter: 0; batch classifier loss: 0.404962; batch adversarial loss: 0.417499\n",
      "epoch 20; iter: 0; batch classifier loss: 0.294550; batch adversarial loss: 0.407244\n",
      "epoch 21; iter: 0; batch classifier loss: 0.239598; batch adversarial loss: 0.471283\n",
      "epoch 22; iter: 0; batch classifier loss: 0.308953; batch adversarial loss: 0.473771\n",
      "epoch 23; iter: 0; batch classifier loss: 0.281957; batch adversarial loss: 0.463958\n",
      "epoch 24; iter: 0; batch classifier loss: 0.276059; batch adversarial loss: 0.497293\n",
      "epoch 25; iter: 0; batch classifier loss: 0.331250; batch adversarial loss: 0.476303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.280066; batch adversarial loss: 0.491091\n",
      "epoch 27; iter: 0; batch classifier loss: 0.199820; batch adversarial loss: 0.441254\n",
      "epoch 28; iter: 0; batch classifier loss: 0.249186; batch adversarial loss: 0.489130\n",
      "epoch 29; iter: 0; batch classifier loss: 0.273706; batch adversarial loss: 0.444148\n",
      "epoch 30; iter: 0; batch classifier loss: 0.238698; batch adversarial loss: 0.465396\n",
      "epoch 31; iter: 0; batch classifier loss: 0.264100; batch adversarial loss: 0.471234\n",
      "epoch 32; iter: 0; batch classifier loss: 0.171716; batch adversarial loss: 0.503480\n",
      "epoch 33; iter: 0; batch classifier loss: 0.276175; batch adversarial loss: 0.482784\n",
      "epoch 34; iter: 0; batch classifier loss: 0.183004; batch adversarial loss: 0.483507\n",
      "epoch 35; iter: 0; batch classifier loss: 0.205173; batch adversarial loss: 0.463144\n",
      "epoch 36; iter: 0; batch classifier loss: 0.188356; batch adversarial loss: 0.537783\n",
      "epoch 37; iter: 0; batch classifier loss: 0.279591; batch adversarial loss: 0.450041\n",
      "epoch 38; iter: 0; batch classifier loss: 0.175603; batch adversarial loss: 0.536770\n",
      "epoch 39; iter: 0; batch classifier loss: 0.213683; batch adversarial loss: 0.553278\n",
      "epoch 40; iter: 0; batch classifier loss: 0.178344; batch adversarial loss: 0.482915\n",
      "epoch 41; iter: 0; batch classifier loss: 0.228831; batch adversarial loss: 0.528690\n",
      "epoch 42; iter: 0; batch classifier loss: 0.197016; batch adversarial loss: 0.484172\n",
      "epoch 43; iter: 0; batch classifier loss: 0.147473; batch adversarial loss: 0.505392\n",
      "epoch 44; iter: 0; batch classifier loss: 0.141125; batch adversarial loss: 0.376698\n",
      "epoch 45; iter: 0; batch classifier loss: 0.144907; batch adversarial loss: 0.493093\n",
      "epoch 46; iter: 0; batch classifier loss: 0.218980; batch adversarial loss: 0.487141\n",
      "epoch 47; iter: 0; batch classifier loss: 0.158991; batch adversarial loss: 0.411417\n",
      "epoch 48; iter: 0; batch classifier loss: 0.159215; batch adversarial loss: 0.469640\n",
      "epoch 49; iter: 0; batch classifier loss: 0.182215; batch adversarial loss: 0.386357\n",
      "epoch 50; iter: 0; batch classifier loss: 0.179079; batch adversarial loss: 0.412585\n",
      "epoch 51; iter: 0; batch classifier loss: 0.161203; batch adversarial loss: 0.482317\n",
      "epoch 52; iter: 0; batch classifier loss: 0.149692; batch adversarial loss: 0.457616\n",
      "epoch 53; iter: 0; batch classifier loss: 0.163836; batch adversarial loss: 0.448250\n",
      "epoch 54; iter: 0; batch classifier loss: 0.145598; batch adversarial loss: 0.447070\n",
      "epoch 55; iter: 0; batch classifier loss: 0.111553; batch adversarial loss: 0.484185\n",
      "epoch 56; iter: 0; batch classifier loss: 0.104046; batch adversarial loss: 0.450207\n",
      "epoch 57; iter: 0; batch classifier loss: 0.141405; batch adversarial loss: 0.471031\n",
      "epoch 58; iter: 0; batch classifier loss: 0.222441; batch adversarial loss: 0.459585\n",
      "epoch 59; iter: 0; batch classifier loss: 0.136286; batch adversarial loss: 0.398507\n",
      "epoch 60; iter: 0; batch classifier loss: 0.175106; batch adversarial loss: 0.480924\n",
      "epoch 61; iter: 0; batch classifier loss: 0.201450; batch adversarial loss: 0.495446\n",
      "epoch 62; iter: 0; batch classifier loss: 0.117334; batch adversarial loss: 0.505611\n",
      "epoch 63; iter: 0; batch classifier loss: 0.201119; batch adversarial loss: 0.421710\n",
      "epoch 64; iter: 0; batch classifier loss: 0.161196; batch adversarial loss: 0.447909\n",
      "epoch 65; iter: 0; batch classifier loss: 0.096165; batch adversarial loss: 0.422825\n",
      "epoch 66; iter: 0; batch classifier loss: 0.093046; batch adversarial loss: 0.409019\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095101; batch adversarial loss: 0.481070\n",
      "epoch 68; iter: 0; batch classifier loss: 0.156747; batch adversarial loss: 0.434630\n",
      "epoch 69; iter: 0; batch classifier loss: 0.108780; batch adversarial loss: 0.518476\n",
      "epoch 70; iter: 0; batch classifier loss: 0.159109; batch adversarial loss: 0.504307\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099820; batch adversarial loss: 0.569711\n",
      "epoch 72; iter: 0; batch classifier loss: 0.129782; batch adversarial loss: 0.504399\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084697; batch adversarial loss: 0.446521\n",
      "epoch 74; iter: 0; batch classifier loss: 0.111311; batch adversarial loss: 0.506807\n",
      "epoch 75; iter: 0; batch classifier loss: 0.105984; batch adversarial loss: 0.444508\n",
      "epoch 76; iter: 0; batch classifier loss: 0.148519; batch adversarial loss: 0.593846\n",
      "epoch 77; iter: 0; batch classifier loss: 0.112947; batch adversarial loss: 0.495151\n",
      "epoch 78; iter: 0; batch classifier loss: 0.091875; batch adversarial loss: 0.482950\n",
      "epoch 79; iter: 0; batch classifier loss: 0.096278; batch adversarial loss: 0.474266\n",
      "epoch 80; iter: 0; batch classifier loss: 0.116936; batch adversarial loss: 0.382356\n",
      "epoch 81; iter: 0; batch classifier loss: 0.143134; batch adversarial loss: 0.385881\n",
      "epoch 82; iter: 0; batch classifier loss: 0.095535; batch adversarial loss: 0.423020\n",
      "epoch 83; iter: 0; batch classifier loss: 0.161414; batch adversarial loss: 0.493191\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079007; batch adversarial loss: 0.509565\n",
      "epoch 85; iter: 0; batch classifier loss: 0.086571; batch adversarial loss: 0.396840\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072001; batch adversarial loss: 0.505492\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082231; batch adversarial loss: 0.468771\n",
      "epoch 88; iter: 0; batch classifier loss: 0.043867; batch adversarial loss: 0.487606\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047308; batch adversarial loss: 0.482443\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050075; batch adversarial loss: 0.503813\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050787; batch adversarial loss: 0.526323\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066273; batch adversarial loss: 0.520835\n",
      "epoch 93; iter: 0; batch classifier loss: 0.027963; batch adversarial loss: 0.498873\n",
      "epoch 94; iter: 0; batch classifier loss: 0.057507; batch adversarial loss: 0.596851\n",
      "epoch 95; iter: 0; batch classifier loss: 0.096156; batch adversarial loss: 0.420204\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064375; batch adversarial loss: 0.497932\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046476; batch adversarial loss: 0.476965\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049973; batch adversarial loss: 0.453262\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057505; batch adversarial loss: 0.420032\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050267; batch adversarial loss: 0.477190\n",
      "epoch 101; iter: 0; batch classifier loss: 0.059692; batch adversarial loss: 0.396208\n",
      "epoch 102; iter: 0; batch classifier loss: 0.045502; batch adversarial loss: 0.503342\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062576; batch adversarial loss: 0.444393\n",
      "epoch 104; iter: 0; batch classifier loss: 0.042826; batch adversarial loss: 0.473206\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035531; batch adversarial loss: 0.489369\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046853; batch adversarial loss: 0.448083\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041449; batch adversarial loss: 0.460852\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048192; batch adversarial loss: 0.489938\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038127; batch adversarial loss: 0.471530\n",
      "epoch 110; iter: 0; batch classifier loss: 0.019409; batch adversarial loss: 0.493652\n",
      "epoch 111; iter: 0; batch classifier loss: 0.074276; batch adversarial loss: 0.537131\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047409; batch adversarial loss: 0.409896\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063987; batch adversarial loss: 0.403664\n",
      "epoch 114; iter: 0; batch classifier loss: 0.024510; batch adversarial loss: 0.485620\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046857; batch adversarial loss: 0.474767\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029491; batch adversarial loss: 0.328040\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028005; batch adversarial loss: 0.435262\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051922; batch adversarial loss: 0.461204\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026277; batch adversarial loss: 0.443785\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062353; batch adversarial loss: 0.449490\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023234; batch adversarial loss: 0.475033\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033791; batch adversarial loss: 0.489517\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029908; batch adversarial loss: 0.480537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.038159; batch adversarial loss: 0.463712\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030464; batch adversarial loss: 0.387816\n",
      "epoch 126; iter: 0; batch classifier loss: 0.016003; batch adversarial loss: 0.400029\n",
      "epoch 127; iter: 0; batch classifier loss: 0.015450; batch adversarial loss: 0.504895\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051621; batch adversarial loss: 0.444561\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021248; batch adversarial loss: 0.487501\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025293; batch adversarial loss: 0.426115\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055097; batch adversarial loss: 0.516605\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022336; batch adversarial loss: 0.559254\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045977; batch adversarial loss: 0.407136\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024312; batch adversarial loss: 0.455643\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022827; batch adversarial loss: 0.473964\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032011; batch adversarial loss: 0.533682\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032398; batch adversarial loss: 0.522513\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028003; batch adversarial loss: 0.469291\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016244; batch adversarial loss: 0.473231\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018649; batch adversarial loss: 0.473828\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050153; batch adversarial loss: 0.434973\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033564; batch adversarial loss: 0.455603\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020341; batch adversarial loss: 0.460894\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016759; batch adversarial loss: 0.557780\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019427; batch adversarial loss: 0.471483\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025313; batch adversarial loss: 0.492945\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016486; batch adversarial loss: 0.457791\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015688; batch adversarial loss: 0.459030\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019570; batch adversarial loss: 0.383805\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024208; batch adversarial loss: 0.452195\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024452; batch adversarial loss: 0.312707\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022932; batch adversarial loss: 0.445593\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013559; batch adversarial loss: 0.513674\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046083; batch adversarial loss: 0.448755\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027861; batch adversarial loss: 0.485823\n",
      "epoch 156; iter: 0; batch classifier loss: 0.007186; batch adversarial loss: 0.468080\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021303; batch adversarial loss: 0.461590\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016761; batch adversarial loss: 0.410502\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021864; batch adversarial loss: 0.406771\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012094; batch adversarial loss: 0.547741\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007212; batch adversarial loss: 0.478419\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019748; batch adversarial loss: 0.484498\n",
      "epoch 163; iter: 0; batch classifier loss: 0.008040; batch adversarial loss: 0.515361\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017058; batch adversarial loss: 0.393725\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034783; batch adversarial loss: 0.418428\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016146; batch adversarial loss: 0.396505\n",
      "epoch 167; iter: 0; batch classifier loss: 0.050331; batch adversarial loss: 0.500735\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007680; batch adversarial loss: 0.434643\n",
      "epoch 169; iter: 0; batch classifier loss: 0.004839; batch adversarial loss: 0.420853\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009320; batch adversarial loss: 0.483619\n",
      "epoch 171; iter: 0; batch classifier loss: 0.002525; batch adversarial loss: 0.477709\n",
      "epoch 172; iter: 0; batch classifier loss: 0.065474; batch adversarial loss: 0.403403\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008073; batch adversarial loss: 0.478797\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012827; batch adversarial loss: 0.474136\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029437; batch adversarial loss: 0.462191\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018620; batch adversarial loss: 0.397273\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034348; batch adversarial loss: 0.460131\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017586; batch adversarial loss: 0.424440\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017863; batch adversarial loss: 0.476948\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011255; batch adversarial loss: 0.511035\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032886; batch adversarial loss: 0.467469\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019807; batch adversarial loss: 0.473531\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006674; batch adversarial loss: 0.401384\n",
      "epoch 184; iter: 0; batch classifier loss: 0.005628; batch adversarial loss: 0.560776\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027223; batch adversarial loss: 0.524087\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016992; batch adversarial loss: 0.494020\n",
      "epoch 187; iter: 0; batch classifier loss: 0.037361; batch adversarial loss: 0.531686\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018000; batch adversarial loss: 0.518844\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034138; batch adversarial loss: 0.507825\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015244; batch adversarial loss: 0.471568\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024375; batch adversarial loss: 0.467752\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019126; batch adversarial loss: 0.492226\n",
      "epoch 193; iter: 0; batch classifier loss: 0.038604; batch adversarial loss: 0.385376\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014186; batch adversarial loss: 0.533160\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016720; batch adversarial loss: 0.409502\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004996; batch adversarial loss: 0.562251\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012518; batch adversarial loss: 0.388922\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003005; batch adversarial loss: 0.535014\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019413; batch adversarial loss: 0.483725\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686935; batch adversarial loss: 0.675074\n",
      "epoch 1; iter: 0; batch classifier loss: 0.437656; batch adversarial loss: 0.642369\n",
      "epoch 2; iter: 0; batch classifier loss: 0.346516; batch adversarial loss: 0.615310\n",
      "epoch 3; iter: 0; batch classifier loss: 0.335631; batch adversarial loss: 0.574720\n",
      "epoch 4; iter: 0; batch classifier loss: 0.277265; batch adversarial loss: 0.559510\n",
      "epoch 5; iter: 0; batch classifier loss: 0.341840; batch adversarial loss: 0.537670\n",
      "epoch 6; iter: 0; batch classifier loss: 0.256400; batch adversarial loss: 0.540343\n",
      "epoch 7; iter: 0; batch classifier loss: 0.268940; batch adversarial loss: 0.486306\n",
      "epoch 8; iter: 0; batch classifier loss: 0.183513; batch adversarial loss: 0.537521\n",
      "epoch 9; iter: 0; batch classifier loss: 0.228884; batch adversarial loss: 0.467101\n",
      "epoch 10; iter: 0; batch classifier loss: 0.263377; batch adversarial loss: 0.511489\n",
      "epoch 11; iter: 0; batch classifier loss: 0.227420; batch adversarial loss: 0.475770\n",
      "epoch 12; iter: 0; batch classifier loss: 0.186507; batch adversarial loss: 0.475284\n",
      "epoch 13; iter: 0; batch classifier loss: 0.180995; batch adversarial loss: 0.454302\n",
      "epoch 14; iter: 0; batch classifier loss: 0.248295; batch adversarial loss: 0.519524\n",
      "epoch 15; iter: 0; batch classifier loss: 0.240040; batch adversarial loss: 0.530745\n",
      "epoch 16; iter: 0; batch classifier loss: 0.202222; batch adversarial loss: 0.426198\n",
      "epoch 17; iter: 0; batch classifier loss: 0.199744; batch adversarial loss: 0.592968\n",
      "epoch 18; iter: 0; batch classifier loss: 0.317961; batch adversarial loss: 0.512196\n",
      "epoch 19; iter: 0; batch classifier loss: 0.244365; batch adversarial loss: 0.532944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.250760; batch adversarial loss: 0.430032\n",
      "epoch 21; iter: 0; batch classifier loss: 0.381729; batch adversarial loss: 0.547097\n",
      "epoch 22; iter: 0; batch classifier loss: 0.432187; batch adversarial loss: 0.462095\n",
      "epoch 23; iter: 0; batch classifier loss: 0.423887; batch adversarial loss: 0.500419\n",
      "epoch 24; iter: 0; batch classifier loss: 0.388186; batch adversarial loss: 0.371269\n",
      "epoch 25; iter: 0; batch classifier loss: 0.259723; batch adversarial loss: 0.486631\n",
      "epoch 26; iter: 0; batch classifier loss: 0.183623; batch adversarial loss: 0.385899\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152063; batch adversarial loss: 0.441047\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166285; batch adversarial loss: 0.516216\n",
      "epoch 29; iter: 0; batch classifier loss: 0.125364; batch adversarial loss: 0.471715\n",
      "epoch 30; iter: 0; batch classifier loss: 0.157406; batch adversarial loss: 0.536704\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170590; batch adversarial loss: 0.438235\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159814; batch adversarial loss: 0.433724\n",
      "epoch 33; iter: 0; batch classifier loss: 0.175092; batch adversarial loss: 0.403165\n",
      "epoch 34; iter: 0; batch classifier loss: 0.117108; batch adversarial loss: 0.515434\n",
      "epoch 35; iter: 0; batch classifier loss: 0.182017; batch adversarial loss: 0.451016\n",
      "epoch 36; iter: 0; batch classifier loss: 0.132836; batch adversarial loss: 0.422925\n",
      "epoch 37; iter: 0; batch classifier loss: 0.123605; batch adversarial loss: 0.501945\n",
      "epoch 38; iter: 0; batch classifier loss: 0.147958; batch adversarial loss: 0.479751\n",
      "epoch 39; iter: 0; batch classifier loss: 0.099129; batch adversarial loss: 0.429890\n",
      "epoch 40; iter: 0; batch classifier loss: 0.126094; batch adversarial loss: 0.409644\n",
      "epoch 41; iter: 0; batch classifier loss: 0.073337; batch adversarial loss: 0.446742\n",
      "epoch 42; iter: 0; batch classifier loss: 0.095116; batch adversarial loss: 0.422715\n",
      "epoch 43; iter: 0; batch classifier loss: 0.095250; batch adversarial loss: 0.445971\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098891; batch adversarial loss: 0.427064\n",
      "epoch 45; iter: 0; batch classifier loss: 0.116526; batch adversarial loss: 0.403850\n",
      "epoch 46; iter: 0; batch classifier loss: 0.119306; batch adversarial loss: 0.479851\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108841; batch adversarial loss: 0.433645\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104277; batch adversarial loss: 0.483059\n",
      "epoch 49; iter: 0; batch classifier loss: 0.076359; batch adversarial loss: 0.411630\n",
      "epoch 50; iter: 0; batch classifier loss: 0.114209; batch adversarial loss: 0.503611\n",
      "epoch 51; iter: 0; batch classifier loss: 0.091951; batch adversarial loss: 0.450554\n",
      "epoch 52; iter: 0; batch classifier loss: 0.068766; batch adversarial loss: 0.497172\n",
      "epoch 53; iter: 0; batch classifier loss: 0.125325; batch adversarial loss: 0.371902\n",
      "epoch 54; iter: 0; batch classifier loss: 0.076035; batch adversarial loss: 0.439480\n",
      "epoch 55; iter: 0; batch classifier loss: 0.118359; batch adversarial loss: 0.428783\n",
      "epoch 56; iter: 0; batch classifier loss: 0.108688; batch adversarial loss: 0.443872\n",
      "epoch 57; iter: 0; batch classifier loss: 0.083632; batch adversarial loss: 0.429004\n",
      "epoch 58; iter: 0; batch classifier loss: 0.095253; batch adversarial loss: 0.472994\n",
      "epoch 59; iter: 0; batch classifier loss: 0.133699; batch adversarial loss: 0.503604\n",
      "epoch 60; iter: 0; batch classifier loss: 0.078648; batch adversarial loss: 0.467257\n",
      "epoch 61; iter: 0; batch classifier loss: 0.102593; batch adversarial loss: 0.341092\n",
      "epoch 62; iter: 0; batch classifier loss: 0.124443; batch adversarial loss: 0.361633\n",
      "epoch 63; iter: 0; batch classifier loss: 0.081462; batch adversarial loss: 0.464609\n",
      "epoch 64; iter: 0; batch classifier loss: 0.095598; batch adversarial loss: 0.414328\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077785; batch adversarial loss: 0.493759\n",
      "epoch 66; iter: 0; batch classifier loss: 0.112571; batch adversarial loss: 0.425420\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095165; batch adversarial loss: 0.417295\n",
      "epoch 68; iter: 0; batch classifier loss: 0.068911; batch adversarial loss: 0.337105\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061324; batch adversarial loss: 0.456030\n",
      "epoch 70; iter: 0; batch classifier loss: 0.102477; batch adversarial loss: 0.516095\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063972; batch adversarial loss: 0.525369\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087620; batch adversarial loss: 0.449225\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081146; batch adversarial loss: 0.446606\n",
      "epoch 74; iter: 0; batch classifier loss: 0.061605; batch adversarial loss: 0.442917\n",
      "epoch 75; iter: 0; batch classifier loss: 0.147159; batch adversarial loss: 0.435277\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049872; batch adversarial loss: 0.536414\n",
      "epoch 77; iter: 0; batch classifier loss: 0.068970; batch adversarial loss: 0.450692\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075841; batch adversarial loss: 0.373242\n",
      "epoch 79; iter: 0; batch classifier loss: 0.051725; batch adversarial loss: 0.490256\n",
      "epoch 80; iter: 0; batch classifier loss: 0.102681; batch adversarial loss: 0.527207\n",
      "epoch 81; iter: 0; batch classifier loss: 0.088901; batch adversarial loss: 0.387607\n",
      "epoch 82; iter: 0; batch classifier loss: 0.077216; batch adversarial loss: 0.441796\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094676; batch adversarial loss: 0.443069\n",
      "epoch 84; iter: 0; batch classifier loss: 0.100986; batch adversarial loss: 0.487070\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070564; batch adversarial loss: 0.480441\n",
      "epoch 86; iter: 0; batch classifier loss: 0.056728; batch adversarial loss: 0.601529\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078346; batch adversarial loss: 0.371690\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051515; batch adversarial loss: 0.337206\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075338; batch adversarial loss: 0.510688\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050842; batch adversarial loss: 0.536801\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045443; batch adversarial loss: 0.473198\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063458; batch adversarial loss: 0.402621\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061963; batch adversarial loss: 0.415737\n",
      "epoch 94; iter: 0; batch classifier loss: 0.065326; batch adversarial loss: 0.419657\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048502; batch adversarial loss: 0.341219\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035694; batch adversarial loss: 0.490913\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064601; batch adversarial loss: 0.509668\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055407; batch adversarial loss: 0.478746\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061773; batch adversarial loss: 0.478358\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057606; batch adversarial loss: 0.538228\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055982; batch adversarial loss: 0.327005\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041635; batch adversarial loss: 0.423049\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059444; batch adversarial loss: 0.465379\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061318; batch adversarial loss: 0.475860\n",
      "epoch 105; iter: 0; batch classifier loss: 0.039296; batch adversarial loss: 0.451340\n",
      "epoch 106; iter: 0; batch classifier loss: 0.072557; batch adversarial loss: 0.469956\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065207; batch adversarial loss: 0.419652\n",
      "epoch 108; iter: 0; batch classifier loss: 0.021093; batch adversarial loss: 0.431042\n",
      "epoch 109; iter: 0; batch classifier loss: 0.018920; batch adversarial loss: 0.389725\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034066; batch adversarial loss: 0.348072\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061853; batch adversarial loss: 0.408509\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040759; batch adversarial loss: 0.431075\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049883; batch adversarial loss: 0.560008\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028858; batch adversarial loss: 0.434155\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052028; batch adversarial loss: 0.404178\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038996; batch adversarial loss: 0.390795\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042461; batch adversarial loss: 0.452336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.036030; batch adversarial loss: 0.482857\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050491; batch adversarial loss: 0.455634\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050843; batch adversarial loss: 0.470329\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034428; batch adversarial loss: 0.473806\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037614; batch adversarial loss: 0.362356\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053269; batch adversarial loss: 0.418347\n",
      "epoch 124; iter: 0; batch classifier loss: 0.065031; batch adversarial loss: 0.439334\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028943; batch adversarial loss: 0.404068\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020596; batch adversarial loss: 0.438724\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021421; batch adversarial loss: 0.447429\n",
      "epoch 128; iter: 0; batch classifier loss: 0.060347; batch adversarial loss: 0.287691\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024577; batch adversarial loss: 0.505400\n",
      "epoch 130; iter: 0; batch classifier loss: 0.055925; batch adversarial loss: 0.419379\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036661; batch adversarial loss: 0.447922\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034733; batch adversarial loss: 0.561973\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045362; batch adversarial loss: 0.386801\n",
      "epoch 134; iter: 0; batch classifier loss: 0.063147; batch adversarial loss: 0.481042\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043921; batch adversarial loss: 0.529292\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032360; batch adversarial loss: 0.496116\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040789; batch adversarial loss: 0.480646\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035330; batch adversarial loss: 0.378815\n",
      "epoch 139; iter: 0; batch classifier loss: 0.047677; batch adversarial loss: 0.485835\n",
      "epoch 140; iter: 0; batch classifier loss: 0.059357; batch adversarial loss: 0.466565\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020014; batch adversarial loss: 0.499772\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049309; batch adversarial loss: 0.425726\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034552; batch adversarial loss: 0.390533\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030447; batch adversarial loss: 0.400652\n",
      "epoch 145; iter: 0; batch classifier loss: 0.057825; batch adversarial loss: 0.466524\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042542; batch adversarial loss: 0.478769\n",
      "epoch 147; iter: 0; batch classifier loss: 0.055402; batch adversarial loss: 0.479384\n",
      "epoch 148; iter: 0; batch classifier loss: 0.050935; batch adversarial loss: 0.489004\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037226; batch adversarial loss: 0.437667\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037897; batch adversarial loss: 0.392215\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010964; batch adversarial loss: 0.451245\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019853; batch adversarial loss: 0.407254\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038915; batch adversarial loss: 0.541428\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028135; batch adversarial loss: 0.487312\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024604; batch adversarial loss: 0.415256\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010192; batch adversarial loss: 0.377739\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034067; batch adversarial loss: 0.446141\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012074; batch adversarial loss: 0.527881\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014690; batch adversarial loss: 0.478841\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036041; batch adversarial loss: 0.509791\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039172; batch adversarial loss: 0.440035\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022115; batch adversarial loss: 0.520981\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013894; batch adversarial loss: 0.383924\n",
      "epoch 164; iter: 0; batch classifier loss: 0.056226; batch adversarial loss: 0.450688\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020622; batch adversarial loss: 0.467892\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021776; batch adversarial loss: 0.434412\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019758; batch adversarial loss: 0.379622\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015649; batch adversarial loss: 0.485610\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038840; batch adversarial loss: 0.504564\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023997; batch adversarial loss: 0.452336\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025024; batch adversarial loss: 0.425395\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009893; batch adversarial loss: 0.429327\n",
      "epoch 173; iter: 0; batch classifier loss: 0.049848; batch adversarial loss: 0.404636\n",
      "epoch 174; iter: 0; batch classifier loss: 0.065634; batch adversarial loss: 0.371637\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032029; batch adversarial loss: 0.533075\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028224; batch adversarial loss: 0.595768\n",
      "epoch 177; iter: 0; batch classifier loss: 0.039365; batch adversarial loss: 0.467384\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028375; batch adversarial loss: 0.495940\n",
      "epoch 179; iter: 0; batch classifier loss: 0.042661; batch adversarial loss: 0.427330\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025535; batch adversarial loss: 0.464346\n",
      "epoch 181; iter: 0; batch classifier loss: 0.062591; batch adversarial loss: 0.462750\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018945; batch adversarial loss: 0.396412\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031736; batch adversarial loss: 0.497915\n",
      "epoch 184; iter: 0; batch classifier loss: 0.041415; batch adversarial loss: 0.400012\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036409; batch adversarial loss: 0.473407\n",
      "epoch 186; iter: 0; batch classifier loss: 0.036675; batch adversarial loss: 0.411738\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021828; batch adversarial loss: 0.437299\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013622; batch adversarial loss: 0.488422\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034810; batch adversarial loss: 0.531689\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019742; batch adversarial loss: 0.437644\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021099; batch adversarial loss: 0.465414\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031325; batch adversarial loss: 0.455706\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006157; batch adversarial loss: 0.559750\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017597; batch adversarial loss: 0.441175\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013257; batch adversarial loss: 0.375844\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016238; batch adversarial loss: 0.495303\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019546; batch adversarial loss: 0.410126\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029378; batch adversarial loss: 0.534045\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008705; batch adversarial loss: 0.460047\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692150; batch adversarial loss: 0.745582\n",
      "epoch 1; iter: 0; batch classifier loss: 0.410501; batch adversarial loss: 0.710622\n",
      "epoch 2; iter: 0; batch classifier loss: 0.415524; batch adversarial loss: 0.677797\n",
      "epoch 3; iter: 0; batch classifier loss: 0.322134; batch adversarial loss: 0.670926\n",
      "epoch 4; iter: 0; batch classifier loss: 0.311518; batch adversarial loss: 0.626961\n",
      "epoch 5; iter: 0; batch classifier loss: 0.354055; batch adversarial loss: 0.573265\n",
      "epoch 6; iter: 0; batch classifier loss: 0.347349; batch adversarial loss: 0.562992\n",
      "epoch 7; iter: 0; batch classifier loss: 0.267470; batch adversarial loss: 0.542415\n",
      "epoch 8; iter: 0; batch classifier loss: 0.399112; batch adversarial loss: 0.507825\n",
      "epoch 9; iter: 0; batch classifier loss: 0.205303; batch adversarial loss: 0.514137\n",
      "epoch 10; iter: 0; batch classifier loss: 0.288837; batch adversarial loss: 0.491938\n",
      "epoch 11; iter: 0; batch classifier loss: 0.230780; batch adversarial loss: 0.476606\n",
      "epoch 12; iter: 0; batch classifier loss: 0.208792; batch adversarial loss: 0.561265\n",
      "epoch 13; iter: 0; batch classifier loss: 0.192551; batch adversarial loss: 0.526467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.162213; batch adversarial loss: 0.538065\n",
      "epoch 15; iter: 0; batch classifier loss: 0.193090; batch adversarial loss: 0.415332\n",
      "epoch 16; iter: 0; batch classifier loss: 0.175700; batch adversarial loss: 0.446739\n",
      "epoch 17; iter: 0; batch classifier loss: 0.171507; batch adversarial loss: 0.481011\n",
      "epoch 18; iter: 0; batch classifier loss: 0.167011; batch adversarial loss: 0.416032\n",
      "epoch 19; iter: 0; batch classifier loss: 0.156853; batch adversarial loss: 0.419001\n",
      "epoch 20; iter: 0; batch classifier loss: 0.151336; batch adversarial loss: 0.511092\n",
      "epoch 21; iter: 0; batch classifier loss: 0.194076; batch adversarial loss: 0.467595\n",
      "epoch 22; iter: 0; batch classifier loss: 0.144798; batch adversarial loss: 0.443783\n",
      "epoch 23; iter: 0; batch classifier loss: 0.153270; batch adversarial loss: 0.395242\n",
      "epoch 24; iter: 0; batch classifier loss: 0.172679; batch adversarial loss: 0.381110\n",
      "epoch 25; iter: 0; batch classifier loss: 0.193359; batch adversarial loss: 0.374242\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181054; batch adversarial loss: 0.399878\n",
      "epoch 27; iter: 0; batch classifier loss: 0.141749; batch adversarial loss: 0.409124\n",
      "epoch 28; iter: 0; batch classifier loss: 0.113386; batch adversarial loss: 0.393432\n",
      "epoch 29; iter: 0; batch classifier loss: 0.195558; batch adversarial loss: 0.492008\n",
      "epoch 30; iter: 0; batch classifier loss: 0.140689; batch adversarial loss: 0.336987\n",
      "epoch 31; iter: 0; batch classifier loss: 0.143418; batch adversarial loss: 0.369002\n",
      "epoch 32; iter: 0; batch classifier loss: 0.135025; batch adversarial loss: 0.390141\n",
      "epoch 33; iter: 0; batch classifier loss: 0.156274; batch adversarial loss: 0.463356\n",
      "epoch 34; iter: 0; batch classifier loss: 0.155595; batch adversarial loss: 0.401815\n",
      "epoch 35; iter: 0; batch classifier loss: 0.136917; batch adversarial loss: 0.403779\n",
      "epoch 36; iter: 0; batch classifier loss: 0.124249; batch adversarial loss: 0.446407\n",
      "epoch 37; iter: 0; batch classifier loss: 0.129234; batch adversarial loss: 0.400612\n",
      "epoch 38; iter: 0; batch classifier loss: 0.144078; batch adversarial loss: 0.391350\n",
      "epoch 39; iter: 0; batch classifier loss: 0.111013; batch adversarial loss: 0.443966\n",
      "epoch 40; iter: 0; batch classifier loss: 0.169370; batch adversarial loss: 0.373377\n",
      "epoch 41; iter: 0; batch classifier loss: 0.118155; batch adversarial loss: 0.359814\n",
      "epoch 42; iter: 0; batch classifier loss: 0.202646; batch adversarial loss: 0.448958\n",
      "epoch 43; iter: 0; batch classifier loss: 0.101698; batch adversarial loss: 0.352273\n",
      "epoch 44; iter: 0; batch classifier loss: 0.131541; batch adversarial loss: 0.419486\n",
      "epoch 45; iter: 0; batch classifier loss: 0.107157; batch adversarial loss: 0.383806\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117562; batch adversarial loss: 0.493305\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096123; batch adversarial loss: 0.403471\n",
      "epoch 48; iter: 0; batch classifier loss: 0.115950; batch adversarial loss: 0.366587\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096491; batch adversarial loss: 0.446267\n",
      "epoch 50; iter: 0; batch classifier loss: 0.116126; batch adversarial loss: 0.336120\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081665; batch adversarial loss: 0.458235\n",
      "epoch 52; iter: 0; batch classifier loss: 0.129552; batch adversarial loss: 0.457612\n",
      "epoch 53; iter: 0; batch classifier loss: 0.074593; batch adversarial loss: 0.435161\n",
      "epoch 54; iter: 0; batch classifier loss: 0.085483; batch adversarial loss: 0.431667\n",
      "epoch 55; iter: 0; batch classifier loss: 0.076789; batch adversarial loss: 0.434731\n",
      "epoch 56; iter: 0; batch classifier loss: 0.085597; batch adversarial loss: 0.372968\n",
      "epoch 57; iter: 0; batch classifier loss: 0.109396; batch adversarial loss: 0.503136\n",
      "epoch 58; iter: 0; batch classifier loss: 0.114681; batch adversarial loss: 0.419865\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105450; batch adversarial loss: 0.447107\n",
      "epoch 60; iter: 0; batch classifier loss: 0.096084; batch adversarial loss: 0.399228\n",
      "epoch 61; iter: 0; batch classifier loss: 0.066518; batch adversarial loss: 0.414923\n",
      "epoch 62; iter: 0; batch classifier loss: 0.076343; batch adversarial loss: 0.354821\n",
      "epoch 63; iter: 0; batch classifier loss: 0.062479; batch adversarial loss: 0.385799\n",
      "epoch 64; iter: 0; batch classifier loss: 0.109640; batch adversarial loss: 0.396299\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087687; batch adversarial loss: 0.475299\n",
      "epoch 66; iter: 0; batch classifier loss: 0.064481; batch adversarial loss: 0.432279\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100312; batch adversarial loss: 0.389503\n",
      "epoch 68; iter: 0; batch classifier loss: 0.107178; batch adversarial loss: 0.430176\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076873; batch adversarial loss: 0.363797\n",
      "epoch 70; iter: 0; batch classifier loss: 0.105490; batch adversarial loss: 0.336583\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079354; batch adversarial loss: 0.440091\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062821; batch adversarial loss: 0.388680\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068224; batch adversarial loss: 0.441766\n",
      "epoch 74; iter: 0; batch classifier loss: 0.060478; batch adversarial loss: 0.443667\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066324; batch adversarial loss: 0.444320\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060226; batch adversarial loss: 0.377481\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063285; batch adversarial loss: 0.366451\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073618; batch adversarial loss: 0.334329\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082831; batch adversarial loss: 0.368334\n",
      "epoch 80; iter: 0; batch classifier loss: 0.051242; batch adversarial loss: 0.404117\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075831; batch adversarial loss: 0.413986\n",
      "epoch 82; iter: 0; batch classifier loss: 0.032471; batch adversarial loss: 0.514778\n",
      "epoch 83; iter: 0; batch classifier loss: 0.053221; batch adversarial loss: 0.533303\n",
      "epoch 84; iter: 0; batch classifier loss: 0.036447; batch adversarial loss: 0.469509\n",
      "epoch 85; iter: 0; batch classifier loss: 0.091816; batch adversarial loss: 0.506706\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058520; batch adversarial loss: 0.423083\n",
      "epoch 87; iter: 0; batch classifier loss: 0.034083; batch adversarial loss: 0.343414\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049344; batch adversarial loss: 0.455098\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035339; batch adversarial loss: 0.429011\n",
      "epoch 90; iter: 0; batch classifier loss: 0.084538; batch adversarial loss: 0.449372\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046815; batch adversarial loss: 0.398093\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074954; batch adversarial loss: 0.432534\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046344; batch adversarial loss: 0.562759\n",
      "epoch 94; iter: 0; batch classifier loss: 0.060489; batch adversarial loss: 0.384496\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054142; batch adversarial loss: 0.376402\n",
      "epoch 96; iter: 0; batch classifier loss: 0.031742; batch adversarial loss: 0.407377\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063319; batch adversarial loss: 0.539352\n",
      "epoch 98; iter: 0; batch classifier loss: 0.093987; batch adversarial loss: 0.467993\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044366; batch adversarial loss: 0.433358\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066201; batch adversarial loss: 0.596561\n",
      "epoch 101; iter: 0; batch classifier loss: 0.088073; batch adversarial loss: 0.513670\n",
      "epoch 102; iter: 0; batch classifier loss: 0.127466; batch adversarial loss: 0.595843\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064048; batch adversarial loss: 0.537732\n",
      "epoch 104; iter: 0; batch classifier loss: 0.120986; batch adversarial loss: 0.592475\n",
      "epoch 105; iter: 0; batch classifier loss: 0.121181; batch adversarial loss: 0.442371\n",
      "epoch 106; iter: 0; batch classifier loss: 0.137253; batch adversarial loss: 0.639309\n",
      "epoch 107; iter: 0; batch classifier loss: 0.133066; batch adversarial loss: 0.634282\n",
      "epoch 108; iter: 0; batch classifier loss: 0.139994; batch adversarial loss: 0.564931\n",
      "epoch 109; iter: 0; batch classifier loss: 0.094732; batch adversarial loss: 0.507116\n",
      "epoch 110; iter: 0; batch classifier loss: 0.140930; batch adversarial loss: 0.585898\n",
      "epoch 111; iter: 0; batch classifier loss: 0.141906; batch adversarial loss: 0.591011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.049167; batch adversarial loss: 0.397337\n",
      "epoch 113; iter: 0; batch classifier loss: 0.106352; batch adversarial loss: 0.482903\n",
      "epoch 114; iter: 0; batch classifier loss: 0.145110; batch adversarial loss: 0.569055\n",
      "epoch 115; iter: 0; batch classifier loss: 0.147559; batch adversarial loss: 0.600861\n",
      "epoch 116; iter: 0; batch classifier loss: 0.163242; batch adversarial loss: 0.632317\n",
      "epoch 117; iter: 0; batch classifier loss: 0.117607; batch adversarial loss: 0.557185\n",
      "epoch 118; iter: 0; batch classifier loss: 0.124801; batch adversarial loss: 0.521433\n",
      "epoch 119; iter: 0; batch classifier loss: 0.130929; batch adversarial loss: 0.551135\n",
      "epoch 120; iter: 0; batch classifier loss: 0.154699; batch adversarial loss: 0.596811\n",
      "epoch 121; iter: 0; batch classifier loss: 0.092211; batch adversarial loss: 0.545194\n",
      "epoch 122; iter: 0; batch classifier loss: 0.115744; batch adversarial loss: 0.483248\n",
      "epoch 123; iter: 0; batch classifier loss: 0.135883; batch adversarial loss: 0.531727\n",
      "epoch 124; iter: 0; batch classifier loss: 0.144708; batch adversarial loss: 0.544781\n",
      "epoch 125; iter: 0; batch classifier loss: 0.123862; batch adversarial loss: 0.452311\n",
      "epoch 126; iter: 0; batch classifier loss: 0.157751; batch adversarial loss: 0.503489\n",
      "epoch 127; iter: 0; batch classifier loss: 0.109630; batch adversarial loss: 0.451956\n",
      "epoch 128; iter: 0; batch classifier loss: 0.094119; batch adversarial loss: 0.471739\n",
      "epoch 129; iter: 0; batch classifier loss: 0.132722; batch adversarial loss: 0.483673\n",
      "epoch 130; iter: 0; batch classifier loss: 0.113353; batch adversarial loss: 0.507801\n",
      "epoch 131; iter: 0; batch classifier loss: 0.143652; batch adversarial loss: 0.491199\n",
      "epoch 132; iter: 0; batch classifier loss: 0.140999; batch adversarial loss: 0.441883\n",
      "epoch 133; iter: 0; batch classifier loss: 0.090723; batch adversarial loss: 0.419264\n",
      "epoch 134; iter: 0; batch classifier loss: 0.121194; batch adversarial loss: 0.455324\n",
      "epoch 135; iter: 0; batch classifier loss: 0.069544; batch adversarial loss: 0.449906\n",
      "epoch 136; iter: 0; batch classifier loss: 0.099211; batch adversarial loss: 0.437797\n",
      "epoch 137; iter: 0; batch classifier loss: 0.096814; batch adversarial loss: 0.459719\n",
      "epoch 138; iter: 0; batch classifier loss: 0.081909; batch adversarial loss: 0.372375\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049254; batch adversarial loss: 0.540704\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034413; batch adversarial loss: 0.469829\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027468; batch adversarial loss: 0.426158\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039179; batch adversarial loss: 0.451627\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027243; batch adversarial loss: 0.429276\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045645; batch adversarial loss: 0.460950\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023862; batch adversarial loss: 0.559372\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023848; batch adversarial loss: 0.475977\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025531; batch adversarial loss: 0.538657\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025236; batch adversarial loss: 0.399450\n",
      "epoch 149; iter: 0; batch classifier loss: 0.058537; batch adversarial loss: 0.327471\n",
      "epoch 150; iter: 0; batch classifier loss: 0.055372; batch adversarial loss: 0.487156\n",
      "epoch 151; iter: 0; batch classifier loss: 0.060964; batch adversarial loss: 0.489561\n",
      "epoch 152; iter: 0; batch classifier loss: 0.067714; batch adversarial loss: 0.453646\n",
      "epoch 153; iter: 0; batch classifier loss: 0.043652; batch adversarial loss: 0.474355\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038393; batch adversarial loss: 0.424647\n",
      "epoch 155; iter: 0; batch classifier loss: 0.078965; batch adversarial loss: 0.490995\n",
      "epoch 156; iter: 0; batch classifier loss: 0.064009; batch adversarial loss: 0.494541\n",
      "epoch 157; iter: 0; batch classifier loss: 0.080481; batch adversarial loss: 0.381312\n",
      "epoch 158; iter: 0; batch classifier loss: 0.072727; batch adversarial loss: 0.535010\n",
      "epoch 159; iter: 0; batch classifier loss: 0.100404; batch adversarial loss: 0.411910\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046111; batch adversarial loss: 0.378597\n",
      "epoch 161; iter: 0; batch classifier loss: 0.047373; batch adversarial loss: 0.439139\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052111; batch adversarial loss: 0.453548\n",
      "epoch 163; iter: 0; batch classifier loss: 0.076013; batch adversarial loss: 0.416795\n",
      "epoch 164; iter: 0; batch classifier loss: 0.143534; batch adversarial loss: 0.457251\n",
      "epoch 165; iter: 0; batch classifier loss: 0.047842; batch adversarial loss: 0.441150\n",
      "epoch 166; iter: 0; batch classifier loss: 0.057088; batch adversarial loss: 0.415774\n",
      "epoch 167; iter: 0; batch classifier loss: 0.062932; batch adversarial loss: 0.509901\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036386; batch adversarial loss: 0.536036\n",
      "epoch 169; iter: 0; batch classifier loss: 0.057425; batch adversarial loss: 0.540040\n",
      "epoch 170; iter: 0; batch classifier loss: 0.109504; batch adversarial loss: 0.428211\n",
      "epoch 171; iter: 0; batch classifier loss: 0.071716; batch adversarial loss: 0.491227\n",
      "epoch 172; iter: 0; batch classifier loss: 0.087138; batch adversarial loss: 0.438170\n",
      "epoch 173; iter: 0; batch classifier loss: 0.077090; batch adversarial loss: 0.478669\n",
      "epoch 174; iter: 0; batch classifier loss: 0.080590; batch adversarial loss: 0.469203\n",
      "epoch 175; iter: 0; batch classifier loss: 0.085555; batch adversarial loss: 0.469103\n",
      "epoch 176; iter: 0; batch classifier loss: 0.087321; batch adversarial loss: 0.459310\n",
      "epoch 177; iter: 0; batch classifier loss: 0.158838; batch adversarial loss: 0.443425\n",
      "epoch 178; iter: 0; batch classifier loss: 0.114674; batch adversarial loss: 0.377611\n",
      "epoch 179; iter: 0; batch classifier loss: 0.088495; batch adversarial loss: 0.447167\n",
      "epoch 180; iter: 0; batch classifier loss: 0.096737; batch adversarial loss: 0.522061\n",
      "epoch 181; iter: 0; batch classifier loss: 0.123376; batch adversarial loss: 0.484206\n",
      "epoch 182; iter: 0; batch classifier loss: 0.095757; batch adversarial loss: 0.464888\n",
      "epoch 183; iter: 0; batch classifier loss: 0.100197; batch adversarial loss: 0.478841\n",
      "epoch 184; iter: 0; batch classifier loss: 0.078844; batch adversarial loss: 0.450278\n",
      "epoch 185; iter: 0; batch classifier loss: 0.059286; batch adversarial loss: 0.370824\n",
      "epoch 186; iter: 0; batch classifier loss: 0.060168; batch adversarial loss: 0.420912\n",
      "epoch 187; iter: 0; batch classifier loss: 0.107645; batch adversarial loss: 0.432602\n",
      "epoch 188; iter: 0; batch classifier loss: 0.095449; batch adversarial loss: 0.393531\n",
      "epoch 189; iter: 0; batch classifier loss: 0.058070; batch adversarial loss: 0.469792\n",
      "epoch 190; iter: 0; batch classifier loss: 0.098743; batch adversarial loss: 0.409106\n",
      "epoch 191; iter: 0; batch classifier loss: 0.072509; batch adversarial loss: 0.458448\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033755; batch adversarial loss: 0.458018\n",
      "epoch 193; iter: 0; batch classifier loss: 0.147913; batch adversarial loss: 0.522018\n",
      "epoch 194; iter: 0; batch classifier loss: 0.045209; batch adversarial loss: 0.509336\n",
      "epoch 195; iter: 0; batch classifier loss: 0.081897; batch adversarial loss: 0.472831\n",
      "epoch 196; iter: 0; batch classifier loss: 0.041855; batch adversarial loss: 0.480769\n",
      "epoch 197; iter: 0; batch classifier loss: 0.046667; batch adversarial loss: 0.456286\n",
      "epoch 198; iter: 0; batch classifier loss: 0.078819; batch adversarial loss: 0.509728\n",
      "epoch 199; iter: 0; batch classifier loss: 0.064740; batch adversarial loss: 0.474212\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709970; batch adversarial loss: 0.684211\n",
      "epoch 1; iter: 0; batch classifier loss: 0.494748; batch adversarial loss: 0.659813\n",
      "epoch 2; iter: 0; batch classifier loss: 0.417639; batch adversarial loss: 0.618886\n",
      "epoch 3; iter: 0; batch classifier loss: 0.329467; batch adversarial loss: 0.585362\n",
      "epoch 4; iter: 0; batch classifier loss: 0.305041; batch adversarial loss: 0.565922\n",
      "epoch 5; iter: 0; batch classifier loss: 0.279242; batch adversarial loss: 0.527663\n",
      "epoch 6; iter: 0; batch classifier loss: 0.267427; batch adversarial loss: 0.539001\n",
      "epoch 7; iter: 0; batch classifier loss: 0.339786; batch adversarial loss: 0.535386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.321594; batch adversarial loss: 0.505530\n",
      "epoch 9; iter: 0; batch classifier loss: 0.284334; batch adversarial loss: 0.505996\n",
      "epoch 10; iter: 0; batch classifier loss: 0.207828; batch adversarial loss: 0.485987\n",
      "epoch 11; iter: 0; batch classifier loss: 0.196069; batch adversarial loss: 0.493760\n",
      "epoch 12; iter: 0; batch classifier loss: 0.224052; batch adversarial loss: 0.468925\n",
      "epoch 13; iter: 0; batch classifier loss: 0.193347; batch adversarial loss: 0.507686\n",
      "epoch 14; iter: 0; batch classifier loss: 0.226672; batch adversarial loss: 0.478600\n",
      "epoch 15; iter: 0; batch classifier loss: 0.220362; batch adversarial loss: 0.512412\n",
      "epoch 16; iter: 0; batch classifier loss: 0.155739; batch adversarial loss: 0.443086\n",
      "epoch 17; iter: 0; batch classifier loss: 0.174882; batch adversarial loss: 0.526025\n",
      "epoch 18; iter: 0; batch classifier loss: 0.169110; batch adversarial loss: 0.566483\n",
      "epoch 19; iter: 0; batch classifier loss: 0.150938; batch adversarial loss: 0.462401\n",
      "epoch 20; iter: 0; batch classifier loss: 0.154324; batch adversarial loss: 0.480552\n",
      "epoch 21; iter: 0; batch classifier loss: 0.198556; batch adversarial loss: 0.440875\n",
      "epoch 22; iter: 0; batch classifier loss: 0.202308; batch adversarial loss: 0.559409\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171430; batch adversarial loss: 0.469720\n",
      "epoch 24; iter: 0; batch classifier loss: 0.178047; batch adversarial loss: 0.509923\n",
      "epoch 25; iter: 0; batch classifier loss: 0.216271; batch adversarial loss: 0.469273\n",
      "epoch 26; iter: 0; batch classifier loss: 0.236994; batch adversarial loss: 0.549933\n",
      "epoch 27; iter: 0; batch classifier loss: 0.262911; batch adversarial loss: 0.464540\n",
      "epoch 28; iter: 0; batch classifier loss: 0.285964; batch adversarial loss: 0.528609\n",
      "epoch 29; iter: 0; batch classifier loss: 0.247326; batch adversarial loss: 0.408609\n",
      "epoch 30; iter: 0; batch classifier loss: 0.396766; batch adversarial loss: 0.514100\n",
      "epoch 31; iter: 0; batch classifier loss: 0.296475; batch adversarial loss: 0.481849\n",
      "epoch 32; iter: 0; batch classifier loss: 0.248181; batch adversarial loss: 0.487559\n",
      "epoch 33; iter: 0; batch classifier loss: 0.194342; batch adversarial loss: 0.478363\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122069; batch adversarial loss: 0.383070\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129444; batch adversarial loss: 0.546047\n",
      "epoch 36; iter: 0; batch classifier loss: 0.130722; batch adversarial loss: 0.459211\n",
      "epoch 37; iter: 0; batch classifier loss: 0.098724; batch adversarial loss: 0.397572\n",
      "epoch 38; iter: 0; batch classifier loss: 0.140204; batch adversarial loss: 0.472800\n",
      "epoch 39; iter: 0; batch classifier loss: 0.163430; batch adversarial loss: 0.442548\n",
      "epoch 40; iter: 0; batch classifier loss: 0.177014; batch adversarial loss: 0.296077\n",
      "epoch 41; iter: 0; batch classifier loss: 0.091411; batch adversarial loss: 0.494742\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120168; batch adversarial loss: 0.410898\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089239; batch adversarial loss: 0.476387\n",
      "epoch 44; iter: 0; batch classifier loss: 0.154841; batch adversarial loss: 0.470367\n",
      "epoch 45; iter: 0; batch classifier loss: 0.107744; batch adversarial loss: 0.447544\n",
      "epoch 46; iter: 0; batch classifier loss: 0.100880; batch adversarial loss: 0.363450\n",
      "epoch 47; iter: 0; batch classifier loss: 0.080048; batch adversarial loss: 0.454447\n",
      "epoch 48; iter: 0; batch classifier loss: 0.095417; batch adversarial loss: 0.406449\n",
      "epoch 49; iter: 0; batch classifier loss: 0.109962; batch adversarial loss: 0.544777\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096432; batch adversarial loss: 0.429063\n",
      "epoch 51; iter: 0; batch classifier loss: 0.080573; batch adversarial loss: 0.475764\n",
      "epoch 52; iter: 0; batch classifier loss: 0.116899; batch adversarial loss: 0.400195\n",
      "epoch 53; iter: 0; batch classifier loss: 0.127549; batch adversarial loss: 0.436277\n",
      "epoch 54; iter: 0; batch classifier loss: 0.094796; batch adversarial loss: 0.416140\n",
      "epoch 55; iter: 0; batch classifier loss: 0.110067; batch adversarial loss: 0.476540\n",
      "epoch 56; iter: 0; batch classifier loss: 0.107949; batch adversarial loss: 0.455888\n",
      "epoch 57; iter: 0; batch classifier loss: 0.101311; batch adversarial loss: 0.509082\n",
      "epoch 58; iter: 0; batch classifier loss: 0.081323; batch adversarial loss: 0.395043\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085691; batch adversarial loss: 0.528740\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104564; batch adversarial loss: 0.469373\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080535; batch adversarial loss: 0.389415\n",
      "epoch 62; iter: 0; batch classifier loss: 0.077440; batch adversarial loss: 0.579582\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098074; batch adversarial loss: 0.539653\n",
      "epoch 64; iter: 0; batch classifier loss: 0.089134; batch adversarial loss: 0.414253\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074685; batch adversarial loss: 0.425431\n",
      "epoch 66; iter: 0; batch classifier loss: 0.076823; batch adversarial loss: 0.400448\n",
      "epoch 67; iter: 0; batch classifier loss: 0.086536; batch adversarial loss: 0.523055\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071345; batch adversarial loss: 0.464461\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075236; batch adversarial loss: 0.502890\n",
      "epoch 70; iter: 0; batch classifier loss: 0.040245; batch adversarial loss: 0.516632\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079814; batch adversarial loss: 0.377016\n",
      "epoch 72; iter: 0; batch classifier loss: 0.096851; batch adversarial loss: 0.543937\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047016; batch adversarial loss: 0.489237\n",
      "epoch 74; iter: 0; batch classifier loss: 0.051125; batch adversarial loss: 0.555799\n",
      "epoch 75; iter: 0; batch classifier loss: 0.103223; batch adversarial loss: 0.394573\n",
      "epoch 76; iter: 0; batch classifier loss: 0.100256; batch adversarial loss: 0.381534\n",
      "epoch 77; iter: 0; batch classifier loss: 0.079185; batch adversarial loss: 0.504797\n",
      "epoch 78; iter: 0; batch classifier loss: 0.092753; batch adversarial loss: 0.426679\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060260; batch adversarial loss: 0.429149\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070528; batch adversarial loss: 0.465711\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061182; batch adversarial loss: 0.387384\n",
      "epoch 82; iter: 0; batch classifier loss: 0.080596; batch adversarial loss: 0.518910\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068539; batch adversarial loss: 0.439950\n",
      "epoch 84; iter: 0; batch classifier loss: 0.061543; batch adversarial loss: 0.423168\n",
      "epoch 85; iter: 0; batch classifier loss: 0.038554; batch adversarial loss: 0.406622\n",
      "epoch 86; iter: 0; batch classifier loss: 0.059925; batch adversarial loss: 0.508199\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042897; batch adversarial loss: 0.473055\n",
      "epoch 88; iter: 0; batch classifier loss: 0.045306; batch adversarial loss: 0.446905\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063474; batch adversarial loss: 0.426764\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052151; batch adversarial loss: 0.510733\n",
      "epoch 91; iter: 0; batch classifier loss: 0.054616; batch adversarial loss: 0.590898\n",
      "epoch 92; iter: 0; batch classifier loss: 0.033389; batch adversarial loss: 0.433781\n",
      "epoch 93; iter: 0; batch classifier loss: 0.075417; batch adversarial loss: 0.505296\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061615; batch adversarial loss: 0.502958\n",
      "epoch 95; iter: 0; batch classifier loss: 0.049704; batch adversarial loss: 0.388569\n",
      "epoch 96; iter: 0; batch classifier loss: 0.092581; batch adversarial loss: 0.383641\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076501; batch adversarial loss: 0.449279\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058928; batch adversarial loss: 0.411790\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065598; batch adversarial loss: 0.457051\n",
      "epoch 100; iter: 0; batch classifier loss: 0.077439; batch adversarial loss: 0.455572\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041443; batch adversarial loss: 0.489719\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055176; batch adversarial loss: 0.412465\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043299; batch adversarial loss: 0.542683\n",
      "epoch 104; iter: 0; batch classifier loss: 0.077269; batch adversarial loss: 0.434565\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035375; batch adversarial loss: 0.501296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.039483; batch adversarial loss: 0.459004\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036572; batch adversarial loss: 0.453578\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028758; batch adversarial loss: 0.523908\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070367; batch adversarial loss: 0.368433\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058860; batch adversarial loss: 0.484993\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044667; batch adversarial loss: 0.392584\n",
      "epoch 112; iter: 0; batch classifier loss: 0.069347; batch adversarial loss: 0.464903\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048393; batch adversarial loss: 0.468639\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041064; batch adversarial loss: 0.425295\n",
      "epoch 115; iter: 0; batch classifier loss: 0.094725; batch adversarial loss: 0.466775\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030171; batch adversarial loss: 0.419302\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031133; batch adversarial loss: 0.519828\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031929; batch adversarial loss: 0.491193\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040857; batch adversarial loss: 0.456024\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028935; batch adversarial loss: 0.460763\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048699; batch adversarial loss: 0.385527\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050063; batch adversarial loss: 0.462501\n",
      "epoch 123; iter: 0; batch classifier loss: 0.072360; batch adversarial loss: 0.479116\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033133; batch adversarial loss: 0.476415\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018579; batch adversarial loss: 0.422023\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017185; batch adversarial loss: 0.469403\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035799; batch adversarial loss: 0.429248\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024069; batch adversarial loss: 0.476114\n",
      "epoch 129; iter: 0; batch classifier loss: 0.063719; batch adversarial loss: 0.406246\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022111; batch adversarial loss: 0.403011\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024522; batch adversarial loss: 0.432683\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050901; batch adversarial loss: 0.490004\n",
      "epoch 133; iter: 0; batch classifier loss: 0.121198; batch adversarial loss: 0.432956\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028138; batch adversarial loss: 0.406595\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047728; batch adversarial loss: 0.427799\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050259; batch adversarial loss: 0.419513\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036945; batch adversarial loss: 0.445213\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028168; batch adversarial loss: 0.474037\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040158; batch adversarial loss: 0.397142\n",
      "epoch 140; iter: 0; batch classifier loss: 0.055519; batch adversarial loss: 0.432594\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022086; batch adversarial loss: 0.427247\n",
      "epoch 142; iter: 0; batch classifier loss: 0.062267; batch adversarial loss: 0.495952\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020378; batch adversarial loss: 0.484156\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037493; batch adversarial loss: 0.385296\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034764; batch adversarial loss: 0.496933\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041122; batch adversarial loss: 0.468419\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032496; batch adversarial loss: 0.453250\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037487; batch adversarial loss: 0.362184\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027261; batch adversarial loss: 0.477760\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026073; batch adversarial loss: 0.478579\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038862; batch adversarial loss: 0.553249\n",
      "epoch 152; iter: 0; batch classifier loss: 0.046319; batch adversarial loss: 0.415598\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014795; batch adversarial loss: 0.416743\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037134; batch adversarial loss: 0.403608\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019326; batch adversarial loss: 0.447857\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040927; batch adversarial loss: 0.509009\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042477; batch adversarial loss: 0.535923\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025966; batch adversarial loss: 0.475533\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033710; batch adversarial loss: 0.499540\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018219; batch adversarial loss: 0.424709\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009374; batch adversarial loss: 0.446338\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031114; batch adversarial loss: 0.418476\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018246; batch adversarial loss: 0.562665\n",
      "epoch 164; iter: 0; batch classifier loss: 0.004620; batch adversarial loss: 0.404611\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018274; batch adversarial loss: 0.475235\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021333; batch adversarial loss: 0.476433\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019124; batch adversarial loss: 0.454842\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026824; batch adversarial loss: 0.414349\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024499; batch adversarial loss: 0.483057\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014931; batch adversarial loss: 0.418972\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012070; batch adversarial loss: 0.429908\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017428; batch adversarial loss: 0.540411\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026261; batch adversarial loss: 0.505464\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009282; batch adversarial loss: 0.516358\n",
      "epoch 175; iter: 0; batch classifier loss: 0.066685; batch adversarial loss: 0.392992\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023271; batch adversarial loss: 0.510093\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020508; batch adversarial loss: 0.445912\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019929; batch adversarial loss: 0.475553\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009358; batch adversarial loss: 0.418189\n",
      "epoch 180; iter: 0; batch classifier loss: 0.042987; batch adversarial loss: 0.538185\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037623; batch adversarial loss: 0.444677\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020523; batch adversarial loss: 0.441816\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026244; batch adversarial loss: 0.388339\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015456; batch adversarial loss: 0.499560\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015287; batch adversarial loss: 0.451838\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009842; batch adversarial loss: 0.476884\n",
      "epoch 187; iter: 0; batch classifier loss: 0.041933; batch adversarial loss: 0.469519\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021363; batch adversarial loss: 0.447182\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037694; batch adversarial loss: 0.477398\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012469; batch adversarial loss: 0.492096\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015396; batch adversarial loss: 0.425023\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032480; batch adversarial loss: 0.393605\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020792; batch adversarial loss: 0.507482\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018574; batch adversarial loss: 0.417710\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030794; batch adversarial loss: 0.463350\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029676; batch adversarial loss: 0.470994\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021222; batch adversarial loss: 0.545975\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008841; batch adversarial loss: 0.397806\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020417; batch adversarial loss: 0.459333\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679272; batch adversarial loss: 0.768112\n",
      "epoch 1; iter: 0; batch classifier loss: 0.412901; batch adversarial loss: 0.750117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.322174; batch adversarial loss: 0.705710\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339260; batch adversarial loss: 0.656099\n",
      "epoch 4; iter: 0; batch classifier loss: 0.373446; batch adversarial loss: 0.629717\n",
      "epoch 5; iter: 0; batch classifier loss: 0.322995; batch adversarial loss: 0.596579\n",
      "epoch 6; iter: 0; batch classifier loss: 0.277478; batch adversarial loss: 0.558923\n",
      "epoch 7; iter: 0; batch classifier loss: 0.202474; batch adversarial loss: 0.554989\n",
      "epoch 8; iter: 0; batch classifier loss: 0.356899; batch adversarial loss: 0.548370\n",
      "epoch 9; iter: 0; batch classifier loss: 0.269043; batch adversarial loss: 0.516315\n",
      "epoch 10; iter: 0; batch classifier loss: 0.287942; batch adversarial loss: 0.508990\n",
      "epoch 11; iter: 0; batch classifier loss: 0.216195; batch adversarial loss: 0.467711\n",
      "epoch 12; iter: 0; batch classifier loss: 0.220215; batch adversarial loss: 0.506138\n",
      "epoch 13; iter: 0; batch classifier loss: 0.243413; batch adversarial loss: 0.490004\n",
      "epoch 14; iter: 0; batch classifier loss: 0.155848; batch adversarial loss: 0.518852\n",
      "epoch 15; iter: 0; batch classifier loss: 0.144532; batch adversarial loss: 0.529064\n",
      "epoch 16; iter: 0; batch classifier loss: 0.266193; batch adversarial loss: 0.521827\n",
      "epoch 17; iter: 0; batch classifier loss: 0.188257; batch adversarial loss: 0.515337\n",
      "epoch 18; iter: 0; batch classifier loss: 0.179136; batch adversarial loss: 0.552382\n",
      "epoch 19; iter: 0; batch classifier loss: 0.260460; batch adversarial loss: 0.491577\n",
      "epoch 20; iter: 0; batch classifier loss: 0.251698; batch adversarial loss: 0.437815\n",
      "epoch 21; iter: 0; batch classifier loss: 0.248200; batch adversarial loss: 0.499903\n",
      "epoch 22; iter: 0; batch classifier loss: 0.320417; batch adversarial loss: 0.465483\n",
      "epoch 23; iter: 0; batch classifier loss: 0.478384; batch adversarial loss: 0.457216\n",
      "epoch 24; iter: 0; batch classifier loss: 0.307382; batch adversarial loss: 0.470049\n",
      "epoch 25; iter: 0; batch classifier loss: 0.233397; batch adversarial loss: 0.483286\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188758; batch adversarial loss: 0.432552\n",
      "epoch 27; iter: 0; batch classifier loss: 0.148096; batch adversarial loss: 0.465111\n",
      "epoch 28; iter: 0; batch classifier loss: 0.108905; batch adversarial loss: 0.440847\n",
      "epoch 29; iter: 0; batch classifier loss: 0.125324; batch adversarial loss: 0.402805\n",
      "epoch 30; iter: 0; batch classifier loss: 0.134046; batch adversarial loss: 0.420511\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178930; batch adversarial loss: 0.497532\n",
      "epoch 32; iter: 0; batch classifier loss: 0.116548; batch adversarial loss: 0.473831\n",
      "epoch 33; iter: 0; batch classifier loss: 0.120586; batch adversarial loss: 0.505686\n",
      "epoch 34; iter: 0; batch classifier loss: 0.143432; batch adversarial loss: 0.459047\n",
      "epoch 35; iter: 0; batch classifier loss: 0.136216; batch adversarial loss: 0.572299\n",
      "epoch 36; iter: 0; batch classifier loss: 0.090704; batch adversarial loss: 0.568088\n",
      "epoch 37; iter: 0; batch classifier loss: 0.195487; batch adversarial loss: 0.527494\n",
      "epoch 38; iter: 0; batch classifier loss: 0.121891; batch adversarial loss: 0.519034\n",
      "epoch 39; iter: 0; batch classifier loss: 0.087582; batch adversarial loss: 0.441753\n",
      "epoch 40; iter: 0; batch classifier loss: 0.125790; batch adversarial loss: 0.472488\n",
      "epoch 41; iter: 0; batch classifier loss: 0.127092; batch adversarial loss: 0.528017\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096679; batch adversarial loss: 0.532537\n",
      "epoch 43; iter: 0; batch classifier loss: 0.134900; batch adversarial loss: 0.483810\n",
      "epoch 44; iter: 0; batch classifier loss: 0.081638; batch adversarial loss: 0.416057\n",
      "epoch 45; iter: 0; batch classifier loss: 0.080957; batch adversarial loss: 0.515625\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112869; batch adversarial loss: 0.443770\n",
      "epoch 47; iter: 0; batch classifier loss: 0.071942; batch adversarial loss: 0.574922\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129167; batch adversarial loss: 0.416070\n",
      "epoch 49; iter: 0; batch classifier loss: 0.152309; batch adversarial loss: 0.580552\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087584; batch adversarial loss: 0.473949\n",
      "epoch 51; iter: 0; batch classifier loss: 0.075676; batch adversarial loss: 0.416001\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109589; batch adversarial loss: 0.402629\n",
      "epoch 53; iter: 0; batch classifier loss: 0.091042; batch adversarial loss: 0.489462\n",
      "epoch 54; iter: 0; batch classifier loss: 0.100127; batch adversarial loss: 0.370577\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091004; batch adversarial loss: 0.435277\n",
      "epoch 56; iter: 0; batch classifier loss: 0.091526; batch adversarial loss: 0.487021\n",
      "epoch 57; iter: 0; batch classifier loss: 0.087788; batch adversarial loss: 0.580661\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072573; batch adversarial loss: 0.500299\n",
      "epoch 59; iter: 0; batch classifier loss: 0.144430; batch adversarial loss: 0.355111\n",
      "epoch 60; iter: 0; batch classifier loss: 0.127208; batch adversarial loss: 0.420915\n",
      "epoch 61; iter: 0; batch classifier loss: 0.227037; batch adversarial loss: 0.458330\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078048; batch adversarial loss: 0.458565\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097160; batch adversarial loss: 0.457845\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099970; batch adversarial loss: 0.480980\n",
      "epoch 65; iter: 0; batch classifier loss: 0.090623; batch adversarial loss: 0.410028\n",
      "epoch 66; iter: 0; batch classifier loss: 0.063672; batch adversarial loss: 0.425968\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110537; batch adversarial loss: 0.488072\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078884; batch adversarial loss: 0.514876\n",
      "epoch 69; iter: 0; batch classifier loss: 0.104538; batch adversarial loss: 0.374379\n",
      "epoch 70; iter: 0; batch classifier loss: 0.099560; batch adversarial loss: 0.469700\n",
      "epoch 71; iter: 0; batch classifier loss: 0.112147; batch adversarial loss: 0.509347\n",
      "epoch 72; iter: 0; batch classifier loss: 0.068622; batch adversarial loss: 0.527259\n",
      "epoch 73; iter: 0; batch classifier loss: 0.131362; batch adversarial loss: 0.543530\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064122; batch adversarial loss: 0.397124\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077038; batch adversarial loss: 0.423372\n",
      "epoch 76; iter: 0; batch classifier loss: 0.104079; batch adversarial loss: 0.419422\n",
      "epoch 77; iter: 0; batch classifier loss: 0.117320; batch adversarial loss: 0.442693\n",
      "epoch 78; iter: 0; batch classifier loss: 0.069157; batch adversarial loss: 0.488920\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076947; batch adversarial loss: 0.426292\n",
      "epoch 80; iter: 0; batch classifier loss: 0.050709; batch adversarial loss: 0.489995\n",
      "epoch 81; iter: 0; batch classifier loss: 0.115749; batch adversarial loss: 0.578218\n",
      "epoch 82; iter: 0; batch classifier loss: 0.132039; batch adversarial loss: 0.516147\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085470; batch adversarial loss: 0.437214\n",
      "epoch 84; iter: 0; batch classifier loss: 0.091253; batch adversarial loss: 0.552414\n",
      "epoch 85; iter: 0; batch classifier loss: 0.036348; batch adversarial loss: 0.494340\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062120; batch adversarial loss: 0.435415\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064070; batch adversarial loss: 0.388405\n",
      "epoch 88; iter: 0; batch classifier loss: 0.053450; batch adversarial loss: 0.517232\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074481; batch adversarial loss: 0.418181\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039759; batch adversarial loss: 0.506075\n",
      "epoch 91; iter: 0; batch classifier loss: 0.088013; batch adversarial loss: 0.438736\n",
      "epoch 92; iter: 0; batch classifier loss: 0.026643; batch adversarial loss: 0.480240\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048664; batch adversarial loss: 0.429843\n",
      "epoch 94; iter: 0; batch classifier loss: 0.029461; batch adversarial loss: 0.491314\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081647; batch adversarial loss: 0.456939\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057426; batch adversarial loss: 0.482277\n",
      "epoch 97; iter: 0; batch classifier loss: 0.040444; batch adversarial loss: 0.567491\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052441; batch adversarial loss: 0.433961\n",
      "epoch 99; iter: 0; batch classifier loss: 0.025994; batch adversarial loss: 0.458084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.051841; batch adversarial loss: 0.375180\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068763; batch adversarial loss: 0.333929\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043147; batch adversarial loss: 0.445238\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057535; batch adversarial loss: 0.421869\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046651; batch adversarial loss: 0.489022\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066218; batch adversarial loss: 0.415479\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052803; batch adversarial loss: 0.412100\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050481; batch adversarial loss: 0.518771\n",
      "epoch 108; iter: 0; batch classifier loss: 0.015081; batch adversarial loss: 0.543073\n",
      "epoch 109; iter: 0; batch classifier loss: 0.025008; batch adversarial loss: 0.419377\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049719; batch adversarial loss: 0.467612\n",
      "epoch 111; iter: 0; batch classifier loss: 0.020640; batch adversarial loss: 0.410700\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024867; batch adversarial loss: 0.612686\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026202; batch adversarial loss: 0.424281\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068953; batch adversarial loss: 0.463105\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042219; batch adversarial loss: 0.515690\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029074; batch adversarial loss: 0.438456\n",
      "epoch 117; iter: 0; batch classifier loss: 0.086260; batch adversarial loss: 0.390992\n",
      "epoch 118; iter: 0; batch classifier loss: 0.020590; batch adversarial loss: 0.584629\n",
      "epoch 119; iter: 0; batch classifier loss: 0.075671; batch adversarial loss: 0.488665\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043335; batch adversarial loss: 0.508836\n",
      "epoch 121; iter: 0; batch classifier loss: 0.079022; batch adversarial loss: 0.464055\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067985; batch adversarial loss: 0.451219\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049613; batch adversarial loss: 0.421286\n",
      "epoch 124; iter: 0; batch classifier loss: 0.017462; batch adversarial loss: 0.448682\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047829; batch adversarial loss: 0.535315\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037256; batch adversarial loss: 0.488291\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028399; batch adversarial loss: 0.463351\n",
      "epoch 128; iter: 0; batch classifier loss: 0.065475; batch adversarial loss: 0.410828\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017186; batch adversarial loss: 0.509929\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047801; batch adversarial loss: 0.461659\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020994; batch adversarial loss: 0.610014\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049742; batch adversarial loss: 0.475305\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038521; batch adversarial loss: 0.475092\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040132; batch adversarial loss: 0.442175\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043225; batch adversarial loss: 0.451360\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016429; batch adversarial loss: 0.450171\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048291; batch adversarial loss: 0.493734\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028437; batch adversarial loss: 0.470676\n",
      "epoch 139; iter: 0; batch classifier loss: 0.084397; batch adversarial loss: 0.415076\n",
      "epoch 140; iter: 0; batch classifier loss: 0.007463; batch adversarial loss: 0.566058\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026815; batch adversarial loss: 0.486443\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037088; batch adversarial loss: 0.544570\n",
      "epoch 143; iter: 0; batch classifier loss: 0.054085; batch adversarial loss: 0.423284\n",
      "epoch 144; iter: 0; batch classifier loss: 0.062409; batch adversarial loss: 0.440436\n",
      "epoch 145; iter: 0; batch classifier loss: 0.049309; batch adversarial loss: 0.385352\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024206; batch adversarial loss: 0.525603\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034448; batch adversarial loss: 0.511044\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013145; batch adversarial loss: 0.403978\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036595; batch adversarial loss: 0.527846\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021770; batch adversarial loss: 0.544180\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035718; batch adversarial loss: 0.447450\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027226; batch adversarial loss: 0.407875\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023811; batch adversarial loss: 0.490181\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025931; batch adversarial loss: 0.414127\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023713; batch adversarial loss: 0.434223\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034008; batch adversarial loss: 0.437524\n",
      "epoch 157; iter: 0; batch classifier loss: 0.064934; batch adversarial loss: 0.497387\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044946; batch adversarial loss: 0.448583\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026875; batch adversarial loss: 0.433044\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012038; batch adversarial loss: 0.414032\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031573; batch adversarial loss: 0.493254\n",
      "epoch 162; iter: 0; batch classifier loss: 0.008592; batch adversarial loss: 0.409278\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027723; batch adversarial loss: 0.543321\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012623; batch adversarial loss: 0.505860\n",
      "epoch 165; iter: 0; batch classifier loss: 0.049453; batch adversarial loss: 0.497477\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045899; batch adversarial loss: 0.445461\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018039; batch adversarial loss: 0.381630\n",
      "epoch 168; iter: 0; batch classifier loss: 0.043139; batch adversarial loss: 0.389064\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037667; batch adversarial loss: 0.489233\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027559; batch adversarial loss: 0.454829\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028267; batch adversarial loss: 0.371463\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032884; batch adversarial loss: 0.494548\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030177; batch adversarial loss: 0.412499\n",
      "epoch 174; iter: 0; batch classifier loss: 0.054616; batch adversarial loss: 0.379623\n",
      "epoch 175; iter: 0; batch classifier loss: 0.068554; batch adversarial loss: 0.520202\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013002; batch adversarial loss: 0.431680\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042842; batch adversarial loss: 0.480038\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010667; batch adversarial loss: 0.517313\n",
      "epoch 179; iter: 0; batch classifier loss: 0.061028; batch adversarial loss: 0.469158\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017255; batch adversarial loss: 0.477687\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025177; batch adversarial loss: 0.394598\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033578; batch adversarial loss: 0.390330\n",
      "epoch 183; iter: 0; batch classifier loss: 0.046130; batch adversarial loss: 0.406957\n",
      "epoch 184; iter: 0; batch classifier loss: 0.047074; batch adversarial loss: 0.516302\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037256; batch adversarial loss: 0.450582\n",
      "epoch 186; iter: 0; batch classifier loss: 0.003601; batch adversarial loss: 0.378467\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033834; batch adversarial loss: 0.484962\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031586; batch adversarial loss: 0.466883\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009056; batch adversarial loss: 0.495663\n",
      "epoch 190; iter: 0; batch classifier loss: 0.041285; batch adversarial loss: 0.457979\n",
      "epoch 191; iter: 0; batch classifier loss: 0.041845; batch adversarial loss: 0.499223\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032856; batch adversarial loss: 0.595424\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024967; batch adversarial loss: 0.428662\n",
      "epoch 194; iter: 0; batch classifier loss: 0.058319; batch adversarial loss: 0.387457\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023209; batch adversarial loss: 0.411575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.019977; batch adversarial loss: 0.385464\n",
      "epoch 197; iter: 0; batch classifier loss: 0.040213; batch adversarial loss: 0.472835\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005603; batch adversarial loss: 0.509353\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014824; batch adversarial loss: 0.520367\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694243; batch adversarial loss: 0.887163\n",
      "epoch 1; iter: 0; batch classifier loss: 0.460419; batch adversarial loss: 0.874286\n",
      "epoch 2; iter: 0; batch classifier loss: 0.544709; batch adversarial loss: 0.819137\n",
      "epoch 3; iter: 0; batch classifier loss: 0.632894; batch adversarial loss: 0.778571\n",
      "epoch 4; iter: 0; batch classifier loss: 0.669397; batch adversarial loss: 0.701923\n",
      "epoch 5; iter: 0; batch classifier loss: 0.611600; batch adversarial loss: 0.648839\n",
      "epoch 6; iter: 0; batch classifier loss: 0.371316; batch adversarial loss: 0.605312\n",
      "epoch 7; iter: 0; batch classifier loss: 0.291216; batch adversarial loss: 0.600787\n",
      "epoch 8; iter: 0; batch classifier loss: 0.302074; batch adversarial loss: 0.552000\n",
      "epoch 9; iter: 0; batch classifier loss: 0.345320; batch adversarial loss: 0.551797\n",
      "epoch 10; iter: 0; batch classifier loss: 0.303657; batch adversarial loss: 0.514580\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362254; batch adversarial loss: 0.506844\n",
      "epoch 12; iter: 0; batch classifier loss: 0.268660; batch adversarial loss: 0.506899\n",
      "epoch 13; iter: 0; batch classifier loss: 0.209469; batch adversarial loss: 0.485117\n",
      "epoch 14; iter: 0; batch classifier loss: 0.203151; batch adversarial loss: 0.473301\n",
      "epoch 15; iter: 0; batch classifier loss: 0.197655; batch adversarial loss: 0.484704\n",
      "epoch 16; iter: 0; batch classifier loss: 0.234625; batch adversarial loss: 0.478098\n",
      "epoch 17; iter: 0; batch classifier loss: 0.213268; batch adversarial loss: 0.488609\n",
      "epoch 18; iter: 0; batch classifier loss: 0.158777; batch adversarial loss: 0.489951\n",
      "epoch 19; iter: 0; batch classifier loss: 0.123767; batch adversarial loss: 0.530900\n",
      "epoch 20; iter: 0; batch classifier loss: 0.206822; batch adversarial loss: 0.486592\n",
      "epoch 21; iter: 0; batch classifier loss: 0.125150; batch adversarial loss: 0.560433\n",
      "epoch 22; iter: 0; batch classifier loss: 0.099795; batch adversarial loss: 0.416714\n",
      "epoch 23; iter: 0; batch classifier loss: 0.161310; batch adversarial loss: 0.489689\n",
      "epoch 24; iter: 0; batch classifier loss: 0.134873; batch adversarial loss: 0.469680\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132757; batch adversarial loss: 0.457655\n",
      "epoch 26; iter: 0; batch classifier loss: 0.127551; batch adversarial loss: 0.411806\n",
      "epoch 27; iter: 0; batch classifier loss: 0.123843; batch adversarial loss: 0.424736\n",
      "epoch 28; iter: 0; batch classifier loss: 0.101541; batch adversarial loss: 0.475977\n",
      "epoch 29; iter: 0; batch classifier loss: 0.104701; batch adversarial loss: 0.503932\n",
      "epoch 30; iter: 0; batch classifier loss: 0.098015; batch adversarial loss: 0.438805\n",
      "epoch 31; iter: 0; batch classifier loss: 0.128789; batch adversarial loss: 0.369903\n",
      "epoch 32; iter: 0; batch classifier loss: 0.106151; batch adversarial loss: 0.437357\n",
      "epoch 33; iter: 0; batch classifier loss: 0.140080; batch adversarial loss: 0.473008\n",
      "epoch 34; iter: 0; batch classifier loss: 0.101248; batch adversarial loss: 0.401456\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121314; batch adversarial loss: 0.467920\n",
      "epoch 36; iter: 0; batch classifier loss: 0.149309; batch adversarial loss: 0.435602\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110378; batch adversarial loss: 0.481540\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127669; batch adversarial loss: 0.475927\n",
      "epoch 39; iter: 0; batch classifier loss: 0.103641; batch adversarial loss: 0.444515\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116034; batch adversarial loss: 0.390901\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125263; batch adversarial loss: 0.528907\n",
      "epoch 42; iter: 0; batch classifier loss: 0.152252; batch adversarial loss: 0.450568\n",
      "epoch 43; iter: 0; batch classifier loss: 0.115884; batch adversarial loss: 0.474170\n",
      "epoch 44; iter: 0; batch classifier loss: 0.128659; batch adversarial loss: 0.451347\n",
      "epoch 45; iter: 0; batch classifier loss: 0.148194; batch adversarial loss: 0.428376\n",
      "epoch 46; iter: 0; batch classifier loss: 0.108904; batch adversarial loss: 0.242286\n",
      "epoch 47; iter: 0; batch classifier loss: 0.123426; batch adversarial loss: 0.484459\n",
      "epoch 48; iter: 0; batch classifier loss: 0.138390; batch adversarial loss: 0.418968\n",
      "epoch 49; iter: 0; batch classifier loss: 0.108775; batch adversarial loss: 0.413141\n",
      "epoch 50; iter: 0; batch classifier loss: 0.056518; batch adversarial loss: 0.354046\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096329; batch adversarial loss: 0.423395\n",
      "epoch 52; iter: 0; batch classifier loss: 0.125373; batch adversarial loss: 0.428260\n",
      "epoch 53; iter: 0; batch classifier loss: 0.106845; batch adversarial loss: 0.537181\n",
      "epoch 54; iter: 0; batch classifier loss: 0.091423; batch adversarial loss: 0.509478\n",
      "epoch 55; iter: 0; batch classifier loss: 0.070428; batch adversarial loss: 0.524429\n",
      "epoch 56; iter: 0; batch classifier loss: 0.060533; batch adversarial loss: 0.488097\n",
      "epoch 57; iter: 0; batch classifier loss: 0.056488; batch adversarial loss: 0.390082\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077234; batch adversarial loss: 0.422866\n",
      "epoch 59; iter: 0; batch classifier loss: 0.121170; batch adversarial loss: 0.436357\n",
      "epoch 60; iter: 0; batch classifier loss: 0.113356; batch adversarial loss: 0.446000\n",
      "epoch 61; iter: 0; batch classifier loss: 0.051832; batch adversarial loss: 0.534209\n",
      "epoch 62; iter: 0; batch classifier loss: 0.157593; batch adversarial loss: 0.453204\n",
      "epoch 63; iter: 0; batch classifier loss: 0.049431; batch adversarial loss: 0.355119\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078516; batch adversarial loss: 0.440818\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107204; batch adversarial loss: 0.457595\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086772; batch adversarial loss: 0.454097\n",
      "epoch 67; iter: 0; batch classifier loss: 0.083407; batch adversarial loss: 0.411434\n",
      "epoch 68; iter: 0; batch classifier loss: 0.055244; batch adversarial loss: 0.476202\n",
      "epoch 69; iter: 0; batch classifier loss: 0.097696; batch adversarial loss: 0.400014\n",
      "epoch 70; iter: 0; batch classifier loss: 0.038616; batch adversarial loss: 0.386549\n",
      "epoch 71; iter: 0; batch classifier loss: 0.057690; batch adversarial loss: 0.444180\n",
      "epoch 72; iter: 0; batch classifier loss: 0.061401; batch adversarial loss: 0.391747\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075230; batch adversarial loss: 0.382865\n",
      "epoch 74; iter: 0; batch classifier loss: 0.110590; batch adversarial loss: 0.469701\n",
      "epoch 75; iter: 0; batch classifier loss: 0.105356; batch adversarial loss: 0.439002\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070111; batch adversarial loss: 0.500892\n",
      "epoch 77; iter: 0; batch classifier loss: 0.038686; batch adversarial loss: 0.406035\n",
      "epoch 78; iter: 0; batch classifier loss: 0.042517; batch adversarial loss: 0.425167\n",
      "epoch 79; iter: 0; batch classifier loss: 0.094116; batch adversarial loss: 0.425745\n",
      "epoch 80; iter: 0; batch classifier loss: 0.093881; batch adversarial loss: 0.541751\n",
      "epoch 81; iter: 0; batch classifier loss: 0.072474; batch adversarial loss: 0.357082\n",
      "epoch 82; iter: 0; batch classifier loss: 0.070613; batch adversarial loss: 0.474876\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081846; batch adversarial loss: 0.376021\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059198; batch adversarial loss: 0.436730\n",
      "epoch 85; iter: 0; batch classifier loss: 0.102749; batch adversarial loss: 0.489847\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058795; batch adversarial loss: 0.471680\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066184; batch adversarial loss: 0.462603\n",
      "epoch 88; iter: 0; batch classifier loss: 0.092924; batch adversarial loss: 0.497131\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078996; batch adversarial loss: 0.546513\n",
      "epoch 90; iter: 0; batch classifier loss: 0.069354; batch adversarial loss: 0.495426\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062351; batch adversarial loss: 0.389772\n",
      "epoch 92; iter: 0; batch classifier loss: 0.039044; batch adversarial loss: 0.411247\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055564; batch adversarial loss: 0.483102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.063785; batch adversarial loss: 0.464518\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051551; batch adversarial loss: 0.395582\n",
      "epoch 96; iter: 0; batch classifier loss: 0.028712; batch adversarial loss: 0.440491\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066103; batch adversarial loss: 0.606947\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046230; batch adversarial loss: 0.466128\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044100; batch adversarial loss: 0.476525\n",
      "epoch 100; iter: 0; batch classifier loss: 0.090497; batch adversarial loss: 0.476766\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049181; batch adversarial loss: 0.593340\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063212; batch adversarial loss: 0.474950\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053887; batch adversarial loss: 0.402122\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035553; batch adversarial loss: 0.433293\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055594; batch adversarial loss: 0.406876\n",
      "epoch 106; iter: 0; batch classifier loss: 0.073684; batch adversarial loss: 0.413556\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061742; batch adversarial loss: 0.377920\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039422; batch adversarial loss: 0.369754\n",
      "epoch 109; iter: 0; batch classifier loss: 0.079729; batch adversarial loss: 0.394610\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065557; batch adversarial loss: 0.448200\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060416; batch adversarial loss: 0.491609\n",
      "epoch 112; iter: 0; batch classifier loss: 0.066701; batch adversarial loss: 0.475900\n",
      "epoch 113; iter: 0; batch classifier loss: 0.080810; batch adversarial loss: 0.447701\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080773; batch adversarial loss: 0.386753\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044988; batch adversarial loss: 0.414693\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056248; batch adversarial loss: 0.396781\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043493; batch adversarial loss: 0.450372\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045794; batch adversarial loss: 0.493422\n",
      "epoch 119; iter: 0; batch classifier loss: 0.075154; batch adversarial loss: 0.433916\n",
      "epoch 120; iter: 0; batch classifier loss: 0.099084; batch adversarial loss: 0.487358\n",
      "epoch 121; iter: 0; batch classifier loss: 0.075576; batch adversarial loss: 0.421243\n",
      "epoch 122; iter: 0; batch classifier loss: 0.070269; batch adversarial loss: 0.510746\n",
      "epoch 123; iter: 0; batch classifier loss: 0.091654; batch adversarial loss: 0.388803\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054565; batch adversarial loss: 0.463405\n",
      "epoch 125; iter: 0; batch classifier loss: 0.064178; batch adversarial loss: 0.461680\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056472; batch adversarial loss: 0.419049\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051969; batch adversarial loss: 0.399448\n",
      "epoch 128; iter: 0; batch classifier loss: 0.075616; batch adversarial loss: 0.441923\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056095; batch adversarial loss: 0.346010\n",
      "epoch 130; iter: 0; batch classifier loss: 0.093571; batch adversarial loss: 0.526847\n",
      "epoch 131; iter: 0; batch classifier loss: 0.063531; batch adversarial loss: 0.389851\n",
      "epoch 132; iter: 0; batch classifier loss: 0.064822; batch adversarial loss: 0.411713\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043282; batch adversarial loss: 0.311283\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069065; batch adversarial loss: 0.443282\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049903; batch adversarial loss: 0.448152\n",
      "epoch 136; iter: 0; batch classifier loss: 0.067128; batch adversarial loss: 0.407175\n",
      "epoch 137; iter: 0; batch classifier loss: 0.087462; batch adversarial loss: 0.510649\n",
      "epoch 138; iter: 0; batch classifier loss: 0.069021; batch adversarial loss: 0.430439\n",
      "epoch 139; iter: 0; batch classifier loss: 0.104042; batch adversarial loss: 0.506919\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046959; batch adversarial loss: 0.355396\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046999; batch adversarial loss: 0.437678\n",
      "epoch 142; iter: 0; batch classifier loss: 0.059825; batch adversarial loss: 0.443816\n",
      "epoch 143; iter: 0; batch classifier loss: 0.070341; batch adversarial loss: 0.475255\n",
      "epoch 144; iter: 0; batch classifier loss: 0.072634; batch adversarial loss: 0.489682\n",
      "epoch 145; iter: 0; batch classifier loss: 0.053319; batch adversarial loss: 0.469683\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052585; batch adversarial loss: 0.352632\n",
      "epoch 147; iter: 0; batch classifier loss: 0.066296; batch adversarial loss: 0.409043\n",
      "epoch 148; iter: 0; batch classifier loss: 0.070398; batch adversarial loss: 0.458066\n",
      "epoch 149; iter: 0; batch classifier loss: 0.067669; batch adversarial loss: 0.532768\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041595; batch adversarial loss: 0.421981\n",
      "epoch 151; iter: 0; batch classifier loss: 0.049874; batch adversarial loss: 0.443116\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039733; batch adversarial loss: 0.455171\n",
      "epoch 153; iter: 0; batch classifier loss: 0.055714; batch adversarial loss: 0.338881\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041116; batch adversarial loss: 0.379201\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046446; batch adversarial loss: 0.360157\n",
      "epoch 156; iter: 0; batch classifier loss: 0.049423; batch adversarial loss: 0.413514\n",
      "epoch 157; iter: 0; batch classifier loss: 0.044425; batch adversarial loss: 0.495610\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029229; batch adversarial loss: 0.429909\n",
      "epoch 159; iter: 0; batch classifier loss: 0.110061; batch adversarial loss: 0.510423\n",
      "epoch 160; iter: 0; batch classifier loss: 0.052745; batch adversarial loss: 0.423303\n",
      "epoch 161; iter: 0; batch classifier loss: 0.069402; batch adversarial loss: 0.432540\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043842; batch adversarial loss: 0.516608\n",
      "epoch 163; iter: 0; batch classifier loss: 0.048479; batch adversarial loss: 0.353371\n",
      "epoch 164; iter: 0; batch classifier loss: 0.041809; batch adversarial loss: 0.479349\n",
      "epoch 165; iter: 0; batch classifier loss: 0.080787; batch adversarial loss: 0.432915\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046857; batch adversarial loss: 0.453391\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042891; batch adversarial loss: 0.535377\n",
      "epoch 168; iter: 0; batch classifier loss: 0.062107; batch adversarial loss: 0.479648\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030999; batch adversarial loss: 0.427412\n",
      "epoch 170; iter: 0; batch classifier loss: 0.079089; batch adversarial loss: 0.349589\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034225; batch adversarial loss: 0.502652\n",
      "epoch 172; iter: 0; batch classifier loss: 0.086787; batch adversarial loss: 0.491419\n",
      "epoch 173; iter: 0; batch classifier loss: 0.050526; batch adversarial loss: 0.348598\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039270; batch adversarial loss: 0.428762\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019067; batch adversarial loss: 0.475333\n",
      "epoch 176; iter: 0; batch classifier loss: 0.065047; batch adversarial loss: 0.383770\n",
      "epoch 177; iter: 0; batch classifier loss: 0.075599; batch adversarial loss: 0.403507\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028218; batch adversarial loss: 0.419531\n",
      "epoch 179; iter: 0; batch classifier loss: 0.071977; batch adversarial loss: 0.496329\n",
      "epoch 180; iter: 0; batch classifier loss: 0.062288; batch adversarial loss: 0.389757\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034611; batch adversarial loss: 0.416144\n",
      "epoch 182; iter: 0; batch classifier loss: 0.046475; batch adversarial loss: 0.434685\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036230; batch adversarial loss: 0.448530\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034398; batch adversarial loss: 0.391532\n",
      "epoch 185; iter: 0; batch classifier loss: 0.039440; batch adversarial loss: 0.412405\n",
      "epoch 186; iter: 0; batch classifier loss: 0.039463; batch adversarial loss: 0.433419\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039839; batch adversarial loss: 0.380771\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029888; batch adversarial loss: 0.374985\n",
      "epoch 189; iter: 0; batch classifier loss: 0.061000; batch adversarial loss: 0.521112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.030794; batch adversarial loss: 0.425122\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032209; batch adversarial loss: 0.475321\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010575; batch adversarial loss: 0.436450\n",
      "epoch 193; iter: 0; batch classifier loss: 0.033328; batch adversarial loss: 0.393859\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035113; batch adversarial loss: 0.405138\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025255; batch adversarial loss: 0.535333\n",
      "epoch 196; iter: 0; batch classifier loss: 0.046907; batch adversarial loss: 0.485469\n",
      "epoch 197; iter: 0; batch classifier loss: 0.046291; batch adversarial loss: 0.452133\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020156; batch adversarial loss: 0.418711\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016998; batch adversarial loss: 0.564282\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704535; batch adversarial loss: 0.943652\n",
      "epoch 1; iter: 0; batch classifier loss: 0.592917; batch adversarial loss: 0.966215\n",
      "epoch 2; iter: 0; batch classifier loss: 0.877778; batch adversarial loss: 1.045522\n",
      "epoch 3; iter: 0; batch classifier loss: 1.004527; batch adversarial loss: 0.960173\n",
      "epoch 4; iter: 0; batch classifier loss: 1.207374; batch adversarial loss: 0.875612\n",
      "epoch 5; iter: 0; batch classifier loss: 1.033498; batch adversarial loss: 0.780800\n",
      "epoch 6; iter: 0; batch classifier loss: 1.122599; batch adversarial loss: 0.720491\n",
      "epoch 7; iter: 0; batch classifier loss: 0.957035; batch adversarial loss: 0.671394\n",
      "epoch 8; iter: 0; batch classifier loss: 0.960949; batch adversarial loss: 0.582726\n",
      "epoch 9; iter: 0; batch classifier loss: 0.715859; batch adversarial loss: 0.564056\n",
      "epoch 10; iter: 0; batch classifier loss: 0.452728; batch adversarial loss: 0.534825\n",
      "epoch 11; iter: 0; batch classifier loss: 0.332553; batch adversarial loss: 0.532922\n",
      "epoch 12; iter: 0; batch classifier loss: 0.281118; batch adversarial loss: 0.534578\n",
      "epoch 13; iter: 0; batch classifier loss: 0.305322; batch adversarial loss: 0.540250\n",
      "epoch 14; iter: 0; batch classifier loss: 0.313701; batch adversarial loss: 0.497877\n",
      "epoch 15; iter: 0; batch classifier loss: 0.392589; batch adversarial loss: 0.516290\n",
      "epoch 16; iter: 0; batch classifier loss: 0.282969; batch adversarial loss: 0.516049\n",
      "epoch 17; iter: 0; batch classifier loss: 0.335840; batch adversarial loss: 0.450784\n",
      "epoch 18; iter: 0; batch classifier loss: 0.310694; batch adversarial loss: 0.493825\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338527; batch adversarial loss: 0.552531\n",
      "epoch 20; iter: 0; batch classifier loss: 0.342313; batch adversarial loss: 0.501169\n",
      "epoch 21; iter: 0; batch classifier loss: 0.293913; batch adversarial loss: 0.429821\n",
      "epoch 22; iter: 0; batch classifier loss: 0.305417; batch adversarial loss: 0.480112\n",
      "epoch 23; iter: 0; batch classifier loss: 0.226940; batch adversarial loss: 0.471148\n",
      "epoch 24; iter: 0; batch classifier loss: 0.232115; batch adversarial loss: 0.488440\n",
      "epoch 25; iter: 0; batch classifier loss: 0.270078; batch adversarial loss: 0.475023\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223874; batch adversarial loss: 0.501619\n",
      "epoch 27; iter: 0; batch classifier loss: 0.304434; batch adversarial loss: 0.474806\n",
      "epoch 28; iter: 0; batch classifier loss: 0.283798; batch adversarial loss: 0.570725\n",
      "epoch 29; iter: 0; batch classifier loss: 0.255754; batch adversarial loss: 0.508564\n",
      "epoch 30; iter: 0; batch classifier loss: 0.272027; batch adversarial loss: 0.457884\n",
      "epoch 31; iter: 0; batch classifier loss: 0.243112; batch adversarial loss: 0.509450\n",
      "epoch 32; iter: 0; batch classifier loss: 0.306278; batch adversarial loss: 0.428346\n",
      "epoch 33; iter: 0; batch classifier loss: 0.278858; batch adversarial loss: 0.456319\n",
      "epoch 34; iter: 0; batch classifier loss: 0.225890; batch adversarial loss: 0.545240\n",
      "epoch 35; iter: 0; batch classifier loss: 0.212762; batch adversarial loss: 0.474226\n",
      "epoch 36; iter: 0; batch classifier loss: 0.242273; batch adversarial loss: 0.405015\n",
      "epoch 37; iter: 0; batch classifier loss: 0.204249; batch adversarial loss: 0.425417\n",
      "epoch 38; iter: 0; batch classifier loss: 0.234091; batch adversarial loss: 0.465214\n",
      "epoch 39; iter: 0; batch classifier loss: 0.171998; batch adversarial loss: 0.461727\n",
      "epoch 40; iter: 0; batch classifier loss: 0.152645; batch adversarial loss: 0.410296\n",
      "epoch 41; iter: 0; batch classifier loss: 0.187400; batch adversarial loss: 0.466263\n",
      "epoch 42; iter: 0; batch classifier loss: 0.212402; batch adversarial loss: 0.457851\n",
      "epoch 43; iter: 0; batch classifier loss: 0.229893; batch adversarial loss: 0.421458\n",
      "epoch 44; iter: 0; batch classifier loss: 0.167252; batch adversarial loss: 0.414962\n",
      "epoch 45; iter: 0; batch classifier loss: 0.246388; batch adversarial loss: 0.442715\n",
      "epoch 46; iter: 0; batch classifier loss: 0.158498; batch adversarial loss: 0.546129\n",
      "epoch 47; iter: 0; batch classifier loss: 0.162125; batch adversarial loss: 0.433132\n",
      "epoch 48; iter: 0; batch classifier loss: 0.157007; batch adversarial loss: 0.507764\n",
      "epoch 49; iter: 0; batch classifier loss: 0.203561; batch adversarial loss: 0.407491\n",
      "epoch 50; iter: 0; batch classifier loss: 0.181108; batch adversarial loss: 0.448543\n",
      "epoch 51; iter: 0; batch classifier loss: 0.198145; batch adversarial loss: 0.481833\n",
      "epoch 52; iter: 0; batch classifier loss: 0.185190; batch adversarial loss: 0.443912\n",
      "epoch 53; iter: 0; batch classifier loss: 0.119934; batch adversarial loss: 0.459548\n",
      "epoch 54; iter: 0; batch classifier loss: 0.167508; batch adversarial loss: 0.429916\n",
      "epoch 55; iter: 0; batch classifier loss: 0.113323; batch adversarial loss: 0.413537\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084594; batch adversarial loss: 0.503228\n",
      "epoch 57; iter: 0; batch classifier loss: 0.182361; batch adversarial loss: 0.381260\n",
      "epoch 58; iter: 0; batch classifier loss: 0.137026; batch adversarial loss: 0.532676\n",
      "epoch 59; iter: 0; batch classifier loss: 0.130608; batch adversarial loss: 0.505286\n",
      "epoch 60; iter: 0; batch classifier loss: 0.112821; batch adversarial loss: 0.539625\n",
      "epoch 61; iter: 0; batch classifier loss: 0.173528; batch adversarial loss: 0.494579\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087478; batch adversarial loss: 0.532098\n",
      "epoch 63; iter: 0; batch classifier loss: 0.113621; batch adversarial loss: 0.378162\n",
      "epoch 64; iter: 0; batch classifier loss: 0.156736; batch adversarial loss: 0.549923\n",
      "epoch 65; iter: 0; batch classifier loss: 0.104345; batch adversarial loss: 0.532412\n",
      "epoch 66; iter: 0; batch classifier loss: 0.127162; batch adversarial loss: 0.464549\n",
      "epoch 67; iter: 0; batch classifier loss: 0.093532; batch adversarial loss: 0.544088\n",
      "epoch 68; iter: 0; batch classifier loss: 0.100091; batch adversarial loss: 0.454695\n",
      "epoch 69; iter: 0; batch classifier loss: 0.106046; batch adversarial loss: 0.508792\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079594; batch adversarial loss: 0.546787\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076627; batch adversarial loss: 0.470921\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087726; batch adversarial loss: 0.485315\n",
      "epoch 73; iter: 0; batch classifier loss: 0.120767; batch adversarial loss: 0.391322\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079454; batch adversarial loss: 0.399295\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083875; batch adversarial loss: 0.563857\n",
      "epoch 76; iter: 0; batch classifier loss: 0.094643; batch adversarial loss: 0.404432\n",
      "epoch 77; iter: 0; batch classifier loss: 0.097628; batch adversarial loss: 0.536084\n",
      "epoch 78; iter: 0; batch classifier loss: 0.086950; batch adversarial loss: 0.411889\n",
      "epoch 79; iter: 0; batch classifier loss: 0.108742; batch adversarial loss: 0.431317\n",
      "epoch 80; iter: 0; batch classifier loss: 0.095248; batch adversarial loss: 0.474336\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067506; batch adversarial loss: 0.355545\n",
      "epoch 82; iter: 0; batch classifier loss: 0.082276; batch adversarial loss: 0.479360\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070540; batch adversarial loss: 0.453084\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067239; batch adversarial loss: 0.453450\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052277; batch adversarial loss: 0.477402\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076171; batch adversarial loss: 0.455975\n",
      "epoch 87; iter: 0; batch classifier loss: 0.093156; batch adversarial loss: 0.501921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.035834; batch adversarial loss: 0.476051\n",
      "epoch 89; iter: 0; batch classifier loss: 0.083200; batch adversarial loss: 0.457838\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060900; batch adversarial loss: 0.507371\n",
      "epoch 91; iter: 0; batch classifier loss: 0.079662; batch adversarial loss: 0.425075\n",
      "epoch 92; iter: 0; batch classifier loss: 0.083852; batch adversarial loss: 0.449506\n",
      "epoch 93; iter: 0; batch classifier loss: 0.073424; batch adversarial loss: 0.496739\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041446; batch adversarial loss: 0.482274\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053832; batch adversarial loss: 0.560087\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051087; batch adversarial loss: 0.370759\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050688; batch adversarial loss: 0.531614\n",
      "epoch 98; iter: 0; batch classifier loss: 0.073754; batch adversarial loss: 0.357106\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067637; batch adversarial loss: 0.400514\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075150; batch adversarial loss: 0.414529\n",
      "epoch 101; iter: 0; batch classifier loss: 0.030565; batch adversarial loss: 0.489188\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036605; batch adversarial loss: 0.525070\n",
      "epoch 103; iter: 0; batch classifier loss: 0.031200; batch adversarial loss: 0.571921\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036469; batch adversarial loss: 0.427219\n",
      "epoch 105; iter: 0; batch classifier loss: 0.090784; batch adversarial loss: 0.429174\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068927; batch adversarial loss: 0.369261\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048265; batch adversarial loss: 0.443810\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064961; batch adversarial loss: 0.545209\n",
      "epoch 109; iter: 0; batch classifier loss: 0.056557; batch adversarial loss: 0.395501\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056250; batch adversarial loss: 0.572798\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028819; batch adversarial loss: 0.464244\n",
      "epoch 112; iter: 0; batch classifier loss: 0.050535; batch adversarial loss: 0.392451\n",
      "epoch 113; iter: 0; batch classifier loss: 0.023433; batch adversarial loss: 0.511279\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053387; batch adversarial loss: 0.477182\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060186; batch adversarial loss: 0.514435\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040709; batch adversarial loss: 0.514780\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020833; batch adversarial loss: 0.475808\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030495; batch adversarial loss: 0.431818\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056709; batch adversarial loss: 0.492149\n",
      "epoch 120; iter: 0; batch classifier loss: 0.021461; batch adversarial loss: 0.431084\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046626; batch adversarial loss: 0.463094\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039902; batch adversarial loss: 0.467041\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027293; batch adversarial loss: 0.485466\n",
      "epoch 124; iter: 0; batch classifier loss: 0.013769; batch adversarial loss: 0.509722\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021138; batch adversarial loss: 0.473317\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024253; batch adversarial loss: 0.418486\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042012; batch adversarial loss: 0.528862\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019516; batch adversarial loss: 0.499578\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026462; batch adversarial loss: 0.446054\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029587; batch adversarial loss: 0.405797\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026253; batch adversarial loss: 0.441557\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023928; batch adversarial loss: 0.391975\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018882; batch adversarial loss: 0.488641\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028603; batch adversarial loss: 0.398510\n",
      "epoch 135; iter: 0; batch classifier loss: 0.048676; batch adversarial loss: 0.385552\n",
      "epoch 136; iter: 0; batch classifier loss: 0.007963; batch adversarial loss: 0.574715\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049787; batch adversarial loss: 0.445700\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011667; batch adversarial loss: 0.491877\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021061; batch adversarial loss: 0.423985\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021901; batch adversarial loss: 0.445835\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044634; batch adversarial loss: 0.462967\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017190; batch adversarial loss: 0.436676\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011013; batch adversarial loss: 0.450828\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037543; batch adversarial loss: 0.423372\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017977; batch adversarial loss: 0.587833\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023076; batch adversarial loss: 0.505551\n",
      "epoch 147; iter: 0; batch classifier loss: 0.064446; batch adversarial loss: 0.502089\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026659; batch adversarial loss: 0.493262\n",
      "epoch 149; iter: 0; batch classifier loss: 0.067369; batch adversarial loss: 0.473142\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021141; batch adversarial loss: 0.466283\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036121; batch adversarial loss: 0.520214\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015559; batch adversarial loss: 0.445048\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023028; batch adversarial loss: 0.352256\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040545; batch adversarial loss: 0.383941\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009270; batch adversarial loss: 0.434054\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025618; batch adversarial loss: 0.388788\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030284; batch adversarial loss: 0.442212\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040278; batch adversarial loss: 0.378389\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031424; batch adversarial loss: 0.409010\n",
      "epoch 160; iter: 0; batch classifier loss: 0.048794; batch adversarial loss: 0.392893\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021733; batch adversarial loss: 0.551952\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029636; batch adversarial loss: 0.491163\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010014; batch adversarial loss: 0.375541\n",
      "epoch 164; iter: 0; batch classifier loss: 0.056834; batch adversarial loss: 0.430331\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010018; batch adversarial loss: 0.451207\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009066; batch adversarial loss: 0.411913\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018367; batch adversarial loss: 0.459942\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018213; batch adversarial loss: 0.393776\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031394; batch adversarial loss: 0.463859\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019443; batch adversarial loss: 0.509078\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007036; batch adversarial loss: 0.476701\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021087; batch adversarial loss: 0.387397\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013438; batch adversarial loss: 0.499581\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014733; batch adversarial loss: 0.465575\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015468; batch adversarial loss: 0.352906\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015539; batch adversarial loss: 0.474329\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030634; batch adversarial loss: 0.406062\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036233; batch adversarial loss: 0.390050\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023628; batch adversarial loss: 0.489218\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024640; batch adversarial loss: 0.471070\n",
      "epoch 181; iter: 0; batch classifier loss: 0.060106; batch adversarial loss: 0.451623\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041554; batch adversarial loss: 0.428968\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014856; batch adversarial loss: 0.379486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.016280; batch adversarial loss: 0.475191\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025840; batch adversarial loss: 0.424983\n",
      "epoch 186; iter: 0; batch classifier loss: 0.004674; batch adversarial loss: 0.492077\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030170; batch adversarial loss: 0.476769\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025027; batch adversarial loss: 0.542189\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009751; batch adversarial loss: 0.498575\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015131; batch adversarial loss: 0.482976\n",
      "epoch 191; iter: 0; batch classifier loss: 0.004150; batch adversarial loss: 0.430109\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024739; batch adversarial loss: 0.458563\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025712; batch adversarial loss: 0.511021\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004407; batch adversarial loss: 0.357642\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031668; batch adversarial loss: 0.470973\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017819; batch adversarial loss: 0.507383\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037655; batch adversarial loss: 0.467065\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015044; batch adversarial loss: 0.364139\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015116; batch adversarial loss: 0.540686\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698075; batch adversarial loss: 0.618112\n",
      "epoch 1; iter: 0; batch classifier loss: 0.409276; batch adversarial loss: 0.622165\n",
      "epoch 2; iter: 0; batch classifier loss: 0.412152; batch adversarial loss: 0.602572\n",
      "epoch 3; iter: 0; batch classifier loss: 0.357329; batch adversarial loss: 0.574956\n",
      "epoch 4; iter: 0; batch classifier loss: 0.388846; batch adversarial loss: 0.599333\n",
      "epoch 5; iter: 0; batch classifier loss: 0.327127; batch adversarial loss: 0.615883\n",
      "epoch 6; iter: 0; batch classifier loss: 0.356749; batch adversarial loss: 0.574177\n",
      "epoch 7; iter: 0; batch classifier loss: 0.469549; batch adversarial loss: 0.568514\n",
      "epoch 8; iter: 0; batch classifier loss: 0.461945; batch adversarial loss: 0.559648\n",
      "epoch 9; iter: 0; batch classifier loss: 0.481690; batch adversarial loss: 0.582575\n",
      "epoch 10; iter: 0; batch classifier loss: 0.579488; batch adversarial loss: 0.554042\n",
      "epoch 11; iter: 0; batch classifier loss: 0.541375; batch adversarial loss: 0.566098\n",
      "epoch 12; iter: 0; batch classifier loss: 0.446684; batch adversarial loss: 0.508612\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373939; batch adversarial loss: 0.520664\n",
      "epoch 14; iter: 0; batch classifier loss: 0.294433; batch adversarial loss: 0.499194\n",
      "epoch 15; iter: 0; batch classifier loss: 0.360036; batch adversarial loss: 0.485219\n",
      "epoch 16; iter: 0; batch classifier loss: 0.224253; batch adversarial loss: 0.430395\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262914; batch adversarial loss: 0.426006\n",
      "epoch 18; iter: 0; batch classifier loss: 0.249353; batch adversarial loss: 0.518233\n",
      "epoch 19; iter: 0; batch classifier loss: 0.220515; batch adversarial loss: 0.487945\n",
      "epoch 20; iter: 0; batch classifier loss: 0.263954; batch adversarial loss: 0.496250\n",
      "epoch 21; iter: 0; batch classifier loss: 0.224704; batch adversarial loss: 0.456087\n",
      "epoch 22; iter: 0; batch classifier loss: 0.215716; batch adversarial loss: 0.521645\n",
      "epoch 23; iter: 0; batch classifier loss: 0.223860; batch adversarial loss: 0.454473\n",
      "epoch 24; iter: 0; batch classifier loss: 0.344372; batch adversarial loss: 0.513829\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209662; batch adversarial loss: 0.411110\n",
      "epoch 26; iter: 0; batch classifier loss: 0.195011; batch adversarial loss: 0.440319\n",
      "epoch 27; iter: 0; batch classifier loss: 0.238266; batch adversarial loss: 0.470691\n",
      "epoch 28; iter: 0; batch classifier loss: 0.154208; batch adversarial loss: 0.479640\n",
      "epoch 29; iter: 0; batch classifier loss: 0.204006; batch adversarial loss: 0.456924\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172001; batch adversarial loss: 0.454503\n",
      "epoch 31; iter: 0; batch classifier loss: 0.149326; batch adversarial loss: 0.481785\n",
      "epoch 32; iter: 0; batch classifier loss: 0.207360; batch adversarial loss: 0.434950\n",
      "epoch 33; iter: 0; batch classifier loss: 0.216342; batch adversarial loss: 0.455594\n",
      "epoch 34; iter: 0; batch classifier loss: 0.201488; batch adversarial loss: 0.395120\n",
      "epoch 35; iter: 0; batch classifier loss: 0.167745; batch adversarial loss: 0.526303\n",
      "epoch 36; iter: 0; batch classifier loss: 0.162117; batch adversarial loss: 0.430807\n",
      "epoch 37; iter: 0; batch classifier loss: 0.174851; batch adversarial loss: 0.546708\n",
      "epoch 38; iter: 0; batch classifier loss: 0.152258; batch adversarial loss: 0.443322\n",
      "epoch 39; iter: 0; batch classifier loss: 0.138702; batch adversarial loss: 0.491092\n",
      "epoch 40; iter: 0; batch classifier loss: 0.158302; batch adversarial loss: 0.496060\n",
      "epoch 41; iter: 0; batch classifier loss: 0.141807; batch adversarial loss: 0.534530\n",
      "epoch 42; iter: 0; batch classifier loss: 0.164901; batch adversarial loss: 0.380291\n",
      "epoch 43; iter: 0; batch classifier loss: 0.109153; batch adversarial loss: 0.507107\n",
      "epoch 44; iter: 0; batch classifier loss: 0.114001; batch adversarial loss: 0.450762\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108782; batch adversarial loss: 0.488614\n",
      "epoch 46; iter: 0; batch classifier loss: 0.136227; batch adversarial loss: 0.474185\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119942; batch adversarial loss: 0.496742\n",
      "epoch 48; iter: 0; batch classifier loss: 0.158535; batch adversarial loss: 0.417263\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099040; batch adversarial loss: 0.430810\n",
      "epoch 50; iter: 0; batch classifier loss: 0.126488; batch adversarial loss: 0.520735\n",
      "epoch 51; iter: 0; batch classifier loss: 0.119201; batch adversarial loss: 0.457895\n",
      "epoch 52; iter: 0; batch classifier loss: 0.130354; batch adversarial loss: 0.405601\n",
      "epoch 53; iter: 0; batch classifier loss: 0.141692; batch adversarial loss: 0.457898\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110976; batch adversarial loss: 0.483662\n",
      "epoch 55; iter: 0; batch classifier loss: 0.161282; batch adversarial loss: 0.446941\n",
      "epoch 56; iter: 0; batch classifier loss: 0.161807; batch adversarial loss: 0.491708\n",
      "epoch 57; iter: 0; batch classifier loss: 0.167965; batch adversarial loss: 0.485191\n",
      "epoch 58; iter: 0; batch classifier loss: 0.126693; batch adversarial loss: 0.419523\n",
      "epoch 59; iter: 0; batch classifier loss: 0.134633; batch adversarial loss: 0.438088\n",
      "epoch 60; iter: 0; batch classifier loss: 0.120995; batch adversarial loss: 0.418476\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099726; batch adversarial loss: 0.477221\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098815; batch adversarial loss: 0.494185\n",
      "epoch 63; iter: 0; batch classifier loss: 0.108236; batch adversarial loss: 0.529932\n",
      "epoch 64; iter: 0; batch classifier loss: 0.124147; batch adversarial loss: 0.458972\n",
      "epoch 65; iter: 0; batch classifier loss: 0.146082; batch adversarial loss: 0.434172\n",
      "epoch 66; iter: 0; batch classifier loss: 0.132291; batch adversarial loss: 0.412677\n",
      "epoch 67; iter: 0; batch classifier loss: 0.140872; batch adversarial loss: 0.483006\n",
      "epoch 68; iter: 0; batch classifier loss: 0.130085; batch adversarial loss: 0.381429\n",
      "epoch 69; iter: 0; batch classifier loss: 0.165672; batch adversarial loss: 0.323334\n",
      "epoch 70; iter: 0; batch classifier loss: 0.106485; batch adversarial loss: 0.507250\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089387; batch adversarial loss: 0.474223\n",
      "epoch 72; iter: 0; batch classifier loss: 0.129733; batch adversarial loss: 0.380017\n",
      "epoch 73; iter: 0; batch classifier loss: 0.130487; batch adversarial loss: 0.409396\n",
      "epoch 74; iter: 0; batch classifier loss: 0.160492; batch adversarial loss: 0.498188\n",
      "epoch 75; iter: 0; batch classifier loss: 0.120423; batch adversarial loss: 0.430164\n",
      "epoch 76; iter: 0; batch classifier loss: 0.091128; batch adversarial loss: 0.430540\n",
      "epoch 77; iter: 0; batch classifier loss: 0.139035; batch adversarial loss: 0.378476\n",
      "epoch 78; iter: 0; batch classifier loss: 0.155392; batch adversarial loss: 0.553280\n",
      "epoch 79; iter: 0; batch classifier loss: 0.096543; batch adversarial loss: 0.577507\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087165; batch adversarial loss: 0.477538\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079468; batch adversarial loss: 0.510779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.142952; batch adversarial loss: 0.286866\n",
      "epoch 83; iter: 0; batch classifier loss: 0.101171; batch adversarial loss: 0.490678\n",
      "epoch 84; iter: 0; batch classifier loss: 0.129273; batch adversarial loss: 0.441775\n",
      "epoch 85; iter: 0; batch classifier loss: 0.105997; batch adversarial loss: 0.422845\n",
      "epoch 86; iter: 0; batch classifier loss: 0.105900; batch adversarial loss: 0.481545\n",
      "epoch 87; iter: 0; batch classifier loss: 0.080272; batch adversarial loss: 0.376422\n",
      "epoch 88; iter: 0; batch classifier loss: 0.106243; batch adversarial loss: 0.406793\n",
      "epoch 89; iter: 0; batch classifier loss: 0.109931; batch adversarial loss: 0.370231\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067692; batch adversarial loss: 0.541450\n",
      "epoch 91; iter: 0; batch classifier loss: 0.119586; batch adversarial loss: 0.393445\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048742; batch adversarial loss: 0.458892\n",
      "epoch 93; iter: 0; batch classifier loss: 0.085991; batch adversarial loss: 0.476079\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066988; batch adversarial loss: 0.405286\n",
      "epoch 95; iter: 0; batch classifier loss: 0.059627; batch adversarial loss: 0.502687\n",
      "epoch 96; iter: 0; batch classifier loss: 0.173528; batch adversarial loss: 0.499192\n",
      "epoch 97; iter: 0; batch classifier loss: 0.094597; batch adversarial loss: 0.395827\n",
      "epoch 98; iter: 0; batch classifier loss: 0.080854; batch adversarial loss: 0.467371\n",
      "epoch 99; iter: 0; batch classifier loss: 0.066669; batch adversarial loss: 0.422809\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045802; batch adversarial loss: 0.493502\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083738; batch adversarial loss: 0.420649\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056032; batch adversarial loss: 0.440146\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063210; batch adversarial loss: 0.528139\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062576; batch adversarial loss: 0.426921\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048665; batch adversarial loss: 0.459640\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040846; batch adversarial loss: 0.497295\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053935; batch adversarial loss: 0.455405\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057777; batch adversarial loss: 0.442650\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059529; batch adversarial loss: 0.415455\n",
      "epoch 110; iter: 0; batch classifier loss: 0.082561; batch adversarial loss: 0.533837\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052158; batch adversarial loss: 0.414583\n",
      "epoch 112; iter: 0; batch classifier loss: 0.077584; batch adversarial loss: 0.401919\n",
      "epoch 113; iter: 0; batch classifier loss: 0.080190; batch adversarial loss: 0.411406\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042369; batch adversarial loss: 0.439699\n",
      "epoch 115; iter: 0; batch classifier loss: 0.069130; batch adversarial loss: 0.487041\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028492; batch adversarial loss: 0.445463\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038505; batch adversarial loss: 0.460208\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029041; batch adversarial loss: 0.483076\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043274; batch adversarial loss: 0.504969\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041685; batch adversarial loss: 0.484223\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054879; batch adversarial loss: 0.542445\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039630; batch adversarial loss: 0.434231\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029850; batch adversarial loss: 0.532009\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031492; batch adversarial loss: 0.448587\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042641; batch adversarial loss: 0.343197\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025046; batch adversarial loss: 0.407567\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022018; batch adversarial loss: 0.531528\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058661; batch adversarial loss: 0.376904\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031724; batch adversarial loss: 0.413531\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022148; batch adversarial loss: 0.437675\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042882; batch adversarial loss: 0.438577\n",
      "epoch 132; iter: 0; batch classifier loss: 0.059796; batch adversarial loss: 0.454662\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051118; batch adversarial loss: 0.303490\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028965; batch adversarial loss: 0.445368\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016021; batch adversarial loss: 0.452030\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054412; batch adversarial loss: 0.499895\n",
      "epoch 137; iter: 0; batch classifier loss: 0.071620; batch adversarial loss: 0.510836\n",
      "epoch 138; iter: 0; batch classifier loss: 0.010831; batch adversarial loss: 0.377079\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038074; batch adversarial loss: 0.347165\n",
      "epoch 140; iter: 0; batch classifier loss: 0.016752; batch adversarial loss: 0.554791\n",
      "epoch 141; iter: 0; batch classifier loss: 0.054299; batch adversarial loss: 0.489998\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019602; batch adversarial loss: 0.516851\n",
      "epoch 143; iter: 0; batch classifier loss: 0.044667; batch adversarial loss: 0.444539\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019574; batch adversarial loss: 0.405421\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029236; batch adversarial loss: 0.343224\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033680; batch adversarial loss: 0.379284\n",
      "epoch 147; iter: 0; batch classifier loss: 0.059398; batch adversarial loss: 0.467003\n",
      "epoch 148; iter: 0; batch classifier loss: 0.055687; batch adversarial loss: 0.420562\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030496; batch adversarial loss: 0.551182\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028156; batch adversarial loss: 0.352703\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032735; batch adversarial loss: 0.420549\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038190; batch adversarial loss: 0.521473\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040173; batch adversarial loss: 0.374171\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039596; batch adversarial loss: 0.384774\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019467; batch adversarial loss: 0.405452\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028101; batch adversarial loss: 0.522931\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018092; batch adversarial loss: 0.413562\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014876; batch adversarial loss: 0.476435\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022380; batch adversarial loss: 0.380568\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020490; batch adversarial loss: 0.505062\n",
      "epoch 161; iter: 0; batch classifier loss: 0.041066; batch adversarial loss: 0.521082\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017643; batch adversarial loss: 0.439047\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022180; batch adversarial loss: 0.476595\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035841; batch adversarial loss: 0.362036\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037401; batch adversarial loss: 0.429314\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010709; batch adversarial loss: 0.516220\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021925; batch adversarial loss: 0.436484\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010628; batch adversarial loss: 0.499184\n",
      "epoch 169; iter: 0; batch classifier loss: 0.041228; batch adversarial loss: 0.477640\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021478; batch adversarial loss: 0.478480\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031127; batch adversarial loss: 0.495734\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021898; batch adversarial loss: 0.371256\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011432; batch adversarial loss: 0.390170\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027962; batch adversarial loss: 0.421566\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020616; batch adversarial loss: 0.538980\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010089; batch adversarial loss: 0.427641\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012193; batch adversarial loss: 0.559075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.011509; batch adversarial loss: 0.450290\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014833; batch adversarial loss: 0.499684\n",
      "epoch 180; iter: 0; batch classifier loss: 0.046509; batch adversarial loss: 0.510214\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010471; batch adversarial loss: 0.467122\n",
      "epoch 182; iter: 0; batch classifier loss: 0.004875; batch adversarial loss: 0.458415\n",
      "epoch 183; iter: 0; batch classifier loss: 0.004879; batch adversarial loss: 0.490123\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029910; batch adversarial loss: 0.427238\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038988; batch adversarial loss: 0.479888\n",
      "epoch 186; iter: 0; batch classifier loss: 0.049530; batch adversarial loss: 0.453100\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018313; batch adversarial loss: 0.453164\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016232; batch adversarial loss: 0.496735\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034516; batch adversarial loss: 0.382646\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009942; batch adversarial loss: 0.434843\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006927; batch adversarial loss: 0.396258\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012050; batch adversarial loss: 0.444735\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020793; batch adversarial loss: 0.519095\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014796; batch adversarial loss: 0.465653\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013059; batch adversarial loss: 0.447362\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016030; batch adversarial loss: 0.432907\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020719; batch adversarial loss: 0.386952\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012404; batch adversarial loss: 0.460203\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020952; batch adversarial loss: 0.479232\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713333; batch adversarial loss: 0.839379\n",
      "epoch 1; iter: 0; batch classifier loss: 0.592970; batch adversarial loss: 0.823850\n",
      "epoch 2; iter: 0; batch classifier loss: 0.788715; batch adversarial loss: 0.811132\n",
      "epoch 3; iter: 0; batch classifier loss: 0.864370; batch adversarial loss: 0.747281\n",
      "epoch 4; iter: 0; batch classifier loss: 0.823866; batch adversarial loss: 0.694202\n",
      "epoch 5; iter: 0; batch classifier loss: 0.568898; batch adversarial loss: 0.577308\n",
      "epoch 6; iter: 0; batch classifier loss: 0.441810; batch adversarial loss: 0.556765\n",
      "epoch 7; iter: 0; batch classifier loss: 0.334197; batch adversarial loss: 0.573372\n",
      "epoch 8; iter: 0; batch classifier loss: 0.302498; batch adversarial loss: 0.562617\n",
      "epoch 9; iter: 0; batch classifier loss: 0.361127; batch adversarial loss: 0.530777\n",
      "epoch 10; iter: 0; batch classifier loss: 0.215414; batch adversarial loss: 0.486373\n",
      "epoch 11; iter: 0; batch classifier loss: 0.281405; batch adversarial loss: 0.544156\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282408; batch adversarial loss: 0.557686\n",
      "epoch 13; iter: 0; batch classifier loss: 0.275326; batch adversarial loss: 0.465365\n",
      "epoch 14; iter: 0; batch classifier loss: 0.188325; batch adversarial loss: 0.473425\n",
      "epoch 15; iter: 0; batch classifier loss: 0.212166; batch adversarial loss: 0.559651\n",
      "epoch 16; iter: 0; batch classifier loss: 0.235920; batch adversarial loss: 0.511908\n",
      "epoch 17; iter: 0; batch classifier loss: 0.211427; batch adversarial loss: 0.519259\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243186; batch adversarial loss: 0.476546\n",
      "epoch 19; iter: 0; batch classifier loss: 0.259068; batch adversarial loss: 0.433801\n",
      "epoch 20; iter: 0; batch classifier loss: 0.251526; batch adversarial loss: 0.512513\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202876; batch adversarial loss: 0.573856\n",
      "epoch 22; iter: 0; batch classifier loss: 0.199841; batch adversarial loss: 0.439553\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171306; batch adversarial loss: 0.500769\n",
      "epoch 24; iter: 0; batch classifier loss: 0.274208; batch adversarial loss: 0.409318\n",
      "epoch 25; iter: 0; batch classifier loss: 0.167797; batch adversarial loss: 0.434458\n",
      "epoch 26; iter: 0; batch classifier loss: 0.184749; batch adversarial loss: 0.484845\n",
      "epoch 27; iter: 0; batch classifier loss: 0.176285; batch adversarial loss: 0.450506\n",
      "epoch 28; iter: 0; batch classifier loss: 0.171131; batch adversarial loss: 0.406127\n",
      "epoch 29; iter: 0; batch classifier loss: 0.096177; batch adversarial loss: 0.412682\n",
      "epoch 30; iter: 0; batch classifier loss: 0.192989; batch adversarial loss: 0.542726\n",
      "epoch 31; iter: 0; batch classifier loss: 0.174839; batch adversarial loss: 0.503938\n",
      "epoch 32; iter: 0; batch classifier loss: 0.205947; batch adversarial loss: 0.461077\n",
      "epoch 33; iter: 0; batch classifier loss: 0.200975; batch adversarial loss: 0.430439\n",
      "epoch 34; iter: 0; batch classifier loss: 0.192697; batch adversarial loss: 0.417177\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161194; batch adversarial loss: 0.515715\n",
      "epoch 36; iter: 0; batch classifier loss: 0.124032; batch adversarial loss: 0.484721\n",
      "epoch 37; iter: 0; batch classifier loss: 0.178157; batch adversarial loss: 0.527241\n",
      "epoch 38; iter: 0; batch classifier loss: 0.155525; batch adversarial loss: 0.402568\n",
      "epoch 39; iter: 0; batch classifier loss: 0.137209; batch adversarial loss: 0.493760\n",
      "epoch 40; iter: 0; batch classifier loss: 0.152259; batch adversarial loss: 0.461289\n",
      "epoch 41; iter: 0; batch classifier loss: 0.188478; batch adversarial loss: 0.483605\n",
      "epoch 42; iter: 0; batch classifier loss: 0.166270; batch adversarial loss: 0.460965\n",
      "epoch 43; iter: 0; batch classifier loss: 0.103875; batch adversarial loss: 0.384383\n",
      "epoch 44; iter: 0; batch classifier loss: 0.155849; batch adversarial loss: 0.407986\n",
      "epoch 45; iter: 0; batch classifier loss: 0.143825; batch adversarial loss: 0.456168\n",
      "epoch 46; iter: 0; batch classifier loss: 0.182552; batch adversarial loss: 0.432621\n",
      "epoch 47; iter: 0; batch classifier loss: 0.139350; batch adversarial loss: 0.534605\n",
      "epoch 48; iter: 0; batch classifier loss: 0.144692; batch adversarial loss: 0.434422\n",
      "epoch 49; iter: 0; batch classifier loss: 0.132877; batch adversarial loss: 0.466637\n",
      "epoch 50; iter: 0; batch classifier loss: 0.120595; batch adversarial loss: 0.449029\n",
      "epoch 51; iter: 0; batch classifier loss: 0.155232; batch adversarial loss: 0.463721\n",
      "epoch 52; iter: 0; batch classifier loss: 0.133825; batch adversarial loss: 0.476930\n",
      "epoch 53; iter: 0; batch classifier loss: 0.136901; batch adversarial loss: 0.476063\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110379; batch adversarial loss: 0.525967\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091908; batch adversarial loss: 0.449176\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101704; batch adversarial loss: 0.437067\n",
      "epoch 57; iter: 0; batch classifier loss: 0.169429; batch adversarial loss: 0.464099\n",
      "epoch 58; iter: 0; batch classifier loss: 0.098598; batch adversarial loss: 0.605869\n",
      "epoch 59; iter: 0; batch classifier loss: 0.134427; batch adversarial loss: 0.482485\n",
      "epoch 60; iter: 0; batch classifier loss: 0.156482; batch adversarial loss: 0.434736\n",
      "epoch 61; iter: 0; batch classifier loss: 0.170081; batch adversarial loss: 0.494077\n",
      "epoch 62; iter: 0; batch classifier loss: 0.158275; batch adversarial loss: 0.424352\n",
      "epoch 63; iter: 0; batch classifier loss: 0.109418; batch adversarial loss: 0.482567\n",
      "epoch 64; iter: 0; batch classifier loss: 0.107064; batch adversarial loss: 0.528657\n",
      "epoch 65; iter: 0; batch classifier loss: 0.159135; batch adversarial loss: 0.453109\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096914; batch adversarial loss: 0.503190\n",
      "epoch 67; iter: 0; batch classifier loss: 0.147686; batch adversarial loss: 0.507599\n",
      "epoch 68; iter: 0; batch classifier loss: 0.134737; batch adversarial loss: 0.422024\n",
      "epoch 69; iter: 0; batch classifier loss: 0.181261; batch adversarial loss: 0.462866\n",
      "epoch 70; iter: 0; batch classifier loss: 0.138455; batch adversarial loss: 0.513198\n",
      "epoch 71; iter: 0; batch classifier loss: 0.107645; batch adversarial loss: 0.606951\n",
      "epoch 72; iter: 0; batch classifier loss: 0.149751; batch adversarial loss: 0.457701\n",
      "epoch 73; iter: 0; batch classifier loss: 0.123864; batch adversarial loss: 0.443390\n",
      "epoch 74; iter: 0; batch classifier loss: 0.150223; batch adversarial loss: 0.501635\n",
      "epoch 75; iter: 0; batch classifier loss: 0.113014; batch adversarial loss: 0.461490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.170980; batch adversarial loss: 0.509968\n",
      "epoch 77; iter: 0; batch classifier loss: 0.103395; batch adversarial loss: 0.565604\n",
      "epoch 78; iter: 0; batch classifier loss: 0.159103; batch adversarial loss: 0.560216\n",
      "epoch 79; iter: 0; batch classifier loss: 0.190334; batch adversarial loss: 0.489004\n",
      "epoch 80; iter: 0; batch classifier loss: 0.108858; batch adversarial loss: 0.470210\n",
      "epoch 81; iter: 0; batch classifier loss: 0.087653; batch adversarial loss: 0.563406\n",
      "epoch 82; iter: 0; batch classifier loss: 0.113320; batch adversarial loss: 0.411843\n",
      "epoch 83; iter: 0; batch classifier loss: 0.132300; batch adversarial loss: 0.517098\n",
      "epoch 84; iter: 0; batch classifier loss: 0.130893; batch adversarial loss: 0.451086\n",
      "epoch 85; iter: 0; batch classifier loss: 0.129317; batch adversarial loss: 0.528302\n",
      "epoch 86; iter: 0; batch classifier loss: 0.193312; batch adversarial loss: 0.403392\n",
      "epoch 87; iter: 0; batch classifier loss: 0.130543; batch adversarial loss: 0.391333\n",
      "epoch 88; iter: 0; batch classifier loss: 0.138876; batch adversarial loss: 0.406335\n",
      "epoch 89; iter: 0; batch classifier loss: 0.135726; batch adversarial loss: 0.463475\n",
      "epoch 90; iter: 0; batch classifier loss: 0.114897; batch adversarial loss: 0.385394\n",
      "epoch 91; iter: 0; batch classifier loss: 0.108031; batch adversarial loss: 0.500514\n",
      "epoch 92; iter: 0; batch classifier loss: 0.152559; batch adversarial loss: 0.473708\n",
      "epoch 93; iter: 0; batch classifier loss: 0.139220; batch adversarial loss: 0.474755\n",
      "epoch 94; iter: 0; batch classifier loss: 0.173701; batch adversarial loss: 0.403371\n",
      "epoch 95; iter: 0; batch classifier loss: 0.153819; batch adversarial loss: 0.483240\n",
      "epoch 96; iter: 0; batch classifier loss: 0.151213; batch adversarial loss: 0.566566\n",
      "epoch 97; iter: 0; batch classifier loss: 0.140343; batch adversarial loss: 0.491847\n",
      "epoch 98; iter: 0; batch classifier loss: 0.224868; batch adversarial loss: 0.414517\n",
      "epoch 99; iter: 0; batch classifier loss: 0.192598; batch adversarial loss: 0.550487\n",
      "epoch 100; iter: 0; batch classifier loss: 0.140285; batch adversarial loss: 0.490632\n",
      "epoch 101; iter: 0; batch classifier loss: 0.228320; batch adversarial loss: 0.431574\n",
      "epoch 102; iter: 0; batch classifier loss: 0.261154; batch adversarial loss: 0.450392\n",
      "epoch 103; iter: 0; batch classifier loss: 0.225023; batch adversarial loss: 0.387523\n",
      "epoch 104; iter: 0; batch classifier loss: 0.149207; batch adversarial loss: 0.458206\n",
      "epoch 105; iter: 0; batch classifier loss: 0.192262; batch adversarial loss: 0.567973\n",
      "epoch 106; iter: 0; batch classifier loss: 0.169855; batch adversarial loss: 0.464051\n",
      "epoch 107; iter: 0; batch classifier loss: 0.234753; batch adversarial loss: 0.468378\n",
      "epoch 108; iter: 0; batch classifier loss: 0.123049; batch adversarial loss: 0.482775\n",
      "epoch 109; iter: 0; batch classifier loss: 0.204014; batch adversarial loss: 0.389834\n",
      "epoch 110; iter: 0; batch classifier loss: 0.181330; batch adversarial loss: 0.374745\n",
      "epoch 111; iter: 0; batch classifier loss: 0.207110; batch adversarial loss: 0.429150\n",
      "epoch 112; iter: 0; batch classifier loss: 0.248217; batch adversarial loss: 0.554444\n",
      "epoch 113; iter: 0; batch classifier loss: 0.271897; batch adversarial loss: 0.328042\n",
      "epoch 114; iter: 0; batch classifier loss: 0.196969; batch adversarial loss: 0.457873\n",
      "epoch 115; iter: 0; batch classifier loss: 0.250271; batch adversarial loss: 0.484601\n",
      "epoch 116; iter: 0; batch classifier loss: 0.249359; batch adversarial loss: 0.468698\n",
      "epoch 117; iter: 0; batch classifier loss: 0.258565; batch adversarial loss: 0.518079\n",
      "epoch 118; iter: 0; batch classifier loss: 0.287229; batch adversarial loss: 0.470427\n",
      "epoch 119; iter: 0; batch classifier loss: 0.222956; batch adversarial loss: 0.447069\n",
      "epoch 120; iter: 0; batch classifier loss: 0.131951; batch adversarial loss: 0.434628\n",
      "epoch 121; iter: 0; batch classifier loss: 0.186313; batch adversarial loss: 0.435252\n",
      "epoch 122; iter: 0; batch classifier loss: 0.193451; batch adversarial loss: 0.434307\n",
      "epoch 123; iter: 0; batch classifier loss: 0.228922; batch adversarial loss: 0.422851\n",
      "epoch 124; iter: 0; batch classifier loss: 0.236275; batch adversarial loss: 0.555077\n",
      "epoch 125; iter: 0; batch classifier loss: 0.100543; batch adversarial loss: 0.422825\n",
      "epoch 126; iter: 0; batch classifier loss: 0.110097; batch adversarial loss: 0.494020\n",
      "epoch 127; iter: 0; batch classifier loss: 0.180120; batch adversarial loss: 0.410491\n",
      "epoch 128; iter: 0; batch classifier loss: 0.215388; batch adversarial loss: 0.520234\n",
      "epoch 129; iter: 0; batch classifier loss: 0.186823; batch adversarial loss: 0.505979\n",
      "epoch 130; iter: 0; batch classifier loss: 0.254528; batch adversarial loss: 0.434633\n",
      "epoch 131; iter: 0; batch classifier loss: 0.220673; batch adversarial loss: 0.530711\n",
      "epoch 132; iter: 0; batch classifier loss: 0.237634; batch adversarial loss: 0.470754\n",
      "epoch 133; iter: 0; batch classifier loss: 0.084995; batch adversarial loss: 0.446404\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045742; batch adversarial loss: 0.401018\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037763; batch adversarial loss: 0.570038\n",
      "epoch 136; iter: 0; batch classifier loss: 0.060599; batch adversarial loss: 0.450396\n",
      "epoch 137; iter: 0; batch classifier loss: 0.056536; batch adversarial loss: 0.426756\n",
      "epoch 138; iter: 0; batch classifier loss: 0.050908; batch adversarial loss: 0.446009\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026654; batch adversarial loss: 0.431700\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038135; batch adversarial loss: 0.447220\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052303; batch adversarial loss: 0.333510\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031733; batch adversarial loss: 0.499044\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025206; batch adversarial loss: 0.436117\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032828; batch adversarial loss: 0.488118\n",
      "epoch 145; iter: 0; batch classifier loss: 0.055585; batch adversarial loss: 0.347454\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051293; batch adversarial loss: 0.471669\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044164; batch adversarial loss: 0.486442\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039680; batch adversarial loss: 0.454404\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051180; batch adversarial loss: 0.466381\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015920; batch adversarial loss: 0.402367\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035719; batch adversarial loss: 0.421108\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018158; batch adversarial loss: 0.568938\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021882; batch adversarial loss: 0.456659\n",
      "epoch 154; iter: 0; batch classifier loss: 0.063157; batch adversarial loss: 0.387828\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042978; batch adversarial loss: 0.429733\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035318; batch adversarial loss: 0.445932\n",
      "epoch 157; iter: 0; batch classifier loss: 0.052262; batch adversarial loss: 0.408027\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033544; batch adversarial loss: 0.433834\n",
      "epoch 159; iter: 0; batch classifier loss: 0.057663; batch adversarial loss: 0.430560\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028472; batch adversarial loss: 0.410238\n",
      "epoch 161; iter: 0; batch classifier loss: 0.074546; batch adversarial loss: 0.466327\n",
      "epoch 162; iter: 0; batch classifier loss: 0.063847; batch adversarial loss: 0.498363\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032468; batch adversarial loss: 0.445970\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036302; batch adversarial loss: 0.415060\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035412; batch adversarial loss: 0.503855\n",
      "epoch 166; iter: 0; batch classifier loss: 0.091899; batch adversarial loss: 0.372181\n",
      "epoch 167; iter: 0; batch classifier loss: 0.094782; batch adversarial loss: 0.479930\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034795; batch adversarial loss: 0.465347\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044626; batch adversarial loss: 0.371314\n",
      "epoch 170; iter: 0; batch classifier loss: 0.079017; batch adversarial loss: 0.456052\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021371; batch adversarial loss: 0.413202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.043076; batch adversarial loss: 0.402781\n",
      "epoch 173; iter: 0; batch classifier loss: 0.063529; batch adversarial loss: 0.472037\n",
      "epoch 174; iter: 0; batch classifier loss: 0.061668; batch adversarial loss: 0.472298\n",
      "epoch 175; iter: 0; batch classifier loss: 0.043957; batch adversarial loss: 0.492042\n",
      "epoch 176; iter: 0; batch classifier loss: 0.084323; batch adversarial loss: 0.421159\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027053; batch adversarial loss: 0.524639\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017524; batch adversarial loss: 0.389536\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038226; batch adversarial loss: 0.380195\n",
      "epoch 180; iter: 0; batch classifier loss: 0.046391; batch adversarial loss: 0.369250\n",
      "epoch 181; iter: 0; batch classifier loss: 0.050572; batch adversarial loss: 0.536747\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030340; batch adversarial loss: 0.428077\n",
      "epoch 183; iter: 0; batch classifier loss: 0.089242; batch adversarial loss: 0.412970\n",
      "epoch 184; iter: 0; batch classifier loss: 0.048681; batch adversarial loss: 0.485930\n",
      "epoch 185; iter: 0; batch classifier loss: 0.060665; batch adversarial loss: 0.418137\n",
      "epoch 186; iter: 0; batch classifier loss: 0.053715; batch adversarial loss: 0.447073\n",
      "epoch 187; iter: 0; batch classifier loss: 0.072666; batch adversarial loss: 0.355099\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026648; batch adversarial loss: 0.391619\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035767; batch adversarial loss: 0.481171\n",
      "epoch 190; iter: 0; batch classifier loss: 0.074812; batch adversarial loss: 0.370207\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031844; batch adversarial loss: 0.388719\n",
      "epoch 192; iter: 0; batch classifier loss: 0.057728; batch adversarial loss: 0.510383\n",
      "epoch 193; iter: 0; batch classifier loss: 0.081541; batch adversarial loss: 0.576200\n",
      "epoch 194; iter: 0; batch classifier loss: 0.047253; batch adversarial loss: 0.541727\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033111; batch adversarial loss: 0.401371\n",
      "epoch 196; iter: 0; batch classifier loss: 0.083661; batch adversarial loss: 0.409183\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039513; batch adversarial loss: 0.458496\n",
      "epoch 198; iter: 0; batch classifier loss: 0.048736; batch adversarial loss: 0.407049\n",
      "epoch 199; iter: 0; batch classifier loss: 0.050311; batch adversarial loss: 0.428411\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697458; batch adversarial loss: 0.794814\n",
      "epoch 1; iter: 0; batch classifier loss: 0.416373; batch adversarial loss: 0.763476\n",
      "epoch 2; iter: 0; batch classifier loss: 0.310499; batch adversarial loss: 0.700999\n",
      "epoch 3; iter: 0; batch classifier loss: 0.318600; batch adversarial loss: 0.665289\n",
      "epoch 4; iter: 0; batch classifier loss: 0.358579; batch adversarial loss: 0.635855\n",
      "epoch 5; iter: 0; batch classifier loss: 0.305398; batch adversarial loss: 0.619885\n",
      "epoch 6; iter: 0; batch classifier loss: 0.339956; batch adversarial loss: 0.582832\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300346; batch adversarial loss: 0.538927\n",
      "epoch 8; iter: 0; batch classifier loss: 0.323217; batch adversarial loss: 0.539619\n",
      "epoch 9; iter: 0; batch classifier loss: 0.304835; batch adversarial loss: 0.505315\n",
      "epoch 10; iter: 0; batch classifier loss: 0.283934; batch adversarial loss: 0.520667\n",
      "epoch 11; iter: 0; batch classifier loss: 0.240525; batch adversarial loss: 0.505653\n",
      "epoch 12; iter: 0; batch classifier loss: 0.208648; batch adversarial loss: 0.512290\n",
      "epoch 13; iter: 0; batch classifier loss: 0.208946; batch adversarial loss: 0.535621\n",
      "epoch 14; iter: 0; batch classifier loss: 0.166473; batch adversarial loss: 0.510316\n",
      "epoch 15; iter: 0; batch classifier loss: 0.133398; batch adversarial loss: 0.492080\n",
      "epoch 16; iter: 0; batch classifier loss: 0.187714; batch adversarial loss: 0.476675\n",
      "epoch 17; iter: 0; batch classifier loss: 0.188113; batch adversarial loss: 0.479027\n",
      "epoch 18; iter: 0; batch classifier loss: 0.157764; batch adversarial loss: 0.440401\n",
      "epoch 19; iter: 0; batch classifier loss: 0.139436; batch adversarial loss: 0.457198\n",
      "epoch 20; iter: 0; batch classifier loss: 0.151047; batch adversarial loss: 0.503378\n",
      "epoch 21; iter: 0; batch classifier loss: 0.170429; batch adversarial loss: 0.416074\n",
      "epoch 22; iter: 0; batch classifier loss: 0.166587; batch adversarial loss: 0.500847\n",
      "epoch 23; iter: 0; batch classifier loss: 0.160124; batch adversarial loss: 0.493206\n",
      "epoch 24; iter: 0; batch classifier loss: 0.179293; batch adversarial loss: 0.434647\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179742; batch adversarial loss: 0.439873\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208088; batch adversarial loss: 0.471659\n",
      "epoch 27; iter: 0; batch classifier loss: 0.274602; batch adversarial loss: 0.522540\n",
      "epoch 28; iter: 0; batch classifier loss: 0.306340; batch adversarial loss: 0.459215\n",
      "epoch 29; iter: 0; batch classifier loss: 0.407224; batch adversarial loss: 0.487688\n",
      "epoch 30; iter: 0; batch classifier loss: 0.331266; batch adversarial loss: 0.416105\n",
      "epoch 31; iter: 0; batch classifier loss: 0.184831; batch adversarial loss: 0.570899\n",
      "epoch 32; iter: 0; batch classifier loss: 0.110531; batch adversarial loss: 0.509171\n",
      "epoch 33; iter: 0; batch classifier loss: 0.139163; batch adversarial loss: 0.493783\n",
      "epoch 34; iter: 0; batch classifier loss: 0.118320; batch adversarial loss: 0.464736\n",
      "epoch 35; iter: 0; batch classifier loss: 0.139734; batch adversarial loss: 0.375528\n",
      "epoch 36; iter: 0; batch classifier loss: 0.106373; batch adversarial loss: 0.390960\n",
      "epoch 37; iter: 0; batch classifier loss: 0.125035; batch adversarial loss: 0.427303\n",
      "epoch 38; iter: 0; batch classifier loss: 0.121109; batch adversarial loss: 0.449339\n",
      "epoch 39; iter: 0; batch classifier loss: 0.112466; batch adversarial loss: 0.441882\n",
      "epoch 40; iter: 0; batch classifier loss: 0.089465; batch adversarial loss: 0.451923\n",
      "epoch 41; iter: 0; batch classifier loss: 0.130447; batch adversarial loss: 0.452115\n",
      "epoch 42; iter: 0; batch classifier loss: 0.076519; batch adversarial loss: 0.484590\n",
      "epoch 43; iter: 0; batch classifier loss: 0.126075; batch adversarial loss: 0.456348\n",
      "epoch 44; iter: 0; batch classifier loss: 0.083328; batch adversarial loss: 0.446124\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103684; batch adversarial loss: 0.422712\n",
      "epoch 46; iter: 0; batch classifier loss: 0.088115; batch adversarial loss: 0.477107\n",
      "epoch 47; iter: 0; batch classifier loss: 0.130198; batch adversarial loss: 0.434307\n",
      "epoch 48; iter: 0; batch classifier loss: 0.079527; batch adversarial loss: 0.508952\n",
      "epoch 49; iter: 0; batch classifier loss: 0.150668; batch adversarial loss: 0.306710\n",
      "epoch 50; iter: 0; batch classifier loss: 0.061576; batch adversarial loss: 0.453365\n",
      "epoch 51; iter: 0; batch classifier loss: 0.166057; batch adversarial loss: 0.427229\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101707; batch adversarial loss: 0.444984\n",
      "epoch 53; iter: 0; batch classifier loss: 0.083820; batch adversarial loss: 0.421350\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080710; batch adversarial loss: 0.426057\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122675; batch adversarial loss: 0.399260\n",
      "epoch 56; iter: 0; batch classifier loss: 0.094416; batch adversarial loss: 0.580091\n",
      "epoch 57; iter: 0; batch classifier loss: 0.057022; batch adversarial loss: 0.411563\n",
      "epoch 58; iter: 0; batch classifier loss: 0.143825; batch adversarial loss: 0.438138\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097542; batch adversarial loss: 0.487337\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065388; batch adversarial loss: 0.429622\n",
      "epoch 61; iter: 0; batch classifier loss: 0.058235; batch adversarial loss: 0.503343\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082391; batch adversarial loss: 0.584864\n",
      "epoch 63; iter: 0; batch classifier loss: 0.107427; batch adversarial loss: 0.381842\n",
      "epoch 64; iter: 0; batch classifier loss: 0.104718; batch adversarial loss: 0.459426\n",
      "epoch 65; iter: 0; batch classifier loss: 0.094436; batch adversarial loss: 0.478642\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068942; batch adversarial loss: 0.319855\n",
      "epoch 67; iter: 0; batch classifier loss: 0.097974; batch adversarial loss: 0.434744\n",
      "epoch 68; iter: 0; batch classifier loss: 0.085367; batch adversarial loss: 0.381668\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087863; batch adversarial loss: 0.395764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.105803; batch adversarial loss: 0.373638\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064394; batch adversarial loss: 0.405791\n",
      "epoch 72; iter: 0; batch classifier loss: 0.115740; batch adversarial loss: 0.479210\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083591; batch adversarial loss: 0.419648\n",
      "epoch 74; iter: 0; batch classifier loss: 0.071759; batch adversarial loss: 0.423942\n",
      "epoch 75; iter: 0; batch classifier loss: 0.112730; batch adversarial loss: 0.363149\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077514; batch adversarial loss: 0.418222\n",
      "epoch 77; iter: 0; batch classifier loss: 0.058874; batch adversarial loss: 0.387148\n",
      "epoch 78; iter: 0; batch classifier loss: 0.038167; batch adversarial loss: 0.472151\n",
      "epoch 79; iter: 0; batch classifier loss: 0.089693; batch adversarial loss: 0.487165\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043250; batch adversarial loss: 0.463345\n",
      "epoch 81; iter: 0; batch classifier loss: 0.056470; batch adversarial loss: 0.478354\n",
      "epoch 82; iter: 0; batch classifier loss: 0.051925; batch adversarial loss: 0.448423\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068154; batch adversarial loss: 0.468198\n",
      "epoch 84; iter: 0; batch classifier loss: 0.049747; batch adversarial loss: 0.451192\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064981; batch adversarial loss: 0.418618\n",
      "epoch 86; iter: 0; batch classifier loss: 0.041475; batch adversarial loss: 0.522214\n",
      "epoch 87; iter: 0; batch classifier loss: 0.069554; batch adversarial loss: 0.450049\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049932; batch adversarial loss: 0.457663\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075270; batch adversarial loss: 0.478723\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075386; batch adversarial loss: 0.526313\n",
      "epoch 91; iter: 0; batch classifier loss: 0.038622; batch adversarial loss: 0.426367\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077790; batch adversarial loss: 0.533322\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052629; batch adversarial loss: 0.469050\n",
      "epoch 94; iter: 0; batch classifier loss: 0.069934; batch adversarial loss: 0.480352\n",
      "epoch 95; iter: 0; batch classifier loss: 0.090833; batch adversarial loss: 0.447083\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059518; batch adversarial loss: 0.634373\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066003; batch adversarial loss: 0.495565\n",
      "epoch 98; iter: 0; batch classifier loss: 0.034036; batch adversarial loss: 0.553220\n",
      "epoch 99; iter: 0; batch classifier loss: 0.072261; batch adversarial loss: 0.476987\n",
      "epoch 100; iter: 0; batch classifier loss: 0.124829; batch adversarial loss: 0.409265\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040327; batch adversarial loss: 0.426886\n",
      "epoch 102; iter: 0; batch classifier loss: 0.094103; batch adversarial loss: 0.438990\n",
      "epoch 103; iter: 0; batch classifier loss: 0.070703; batch adversarial loss: 0.459261\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060092; batch adversarial loss: 0.369326\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047915; batch adversarial loss: 0.418333\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036993; batch adversarial loss: 0.427141\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052110; batch adversarial loss: 0.496545\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073728; batch adversarial loss: 0.479393\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046017; batch adversarial loss: 0.460583\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036716; batch adversarial loss: 0.448971\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029208; batch adversarial loss: 0.541809\n",
      "epoch 112; iter: 0; batch classifier loss: 0.066650; batch adversarial loss: 0.421607\n",
      "epoch 113; iter: 0; batch classifier loss: 0.061016; batch adversarial loss: 0.361686\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040042; batch adversarial loss: 0.418143\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032082; batch adversarial loss: 0.390821\n",
      "epoch 116; iter: 0; batch classifier loss: 0.078805; batch adversarial loss: 0.379266\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049678; batch adversarial loss: 0.449304\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060550; batch adversarial loss: 0.398737\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029210; batch adversarial loss: 0.412288\n",
      "epoch 120; iter: 0; batch classifier loss: 0.090501; batch adversarial loss: 0.447301\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045088; batch adversarial loss: 0.461354\n",
      "epoch 122; iter: 0; batch classifier loss: 0.022950; batch adversarial loss: 0.561987\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063698; batch adversarial loss: 0.457605\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032344; batch adversarial loss: 0.370338\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042897; batch adversarial loss: 0.405395\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037867; batch adversarial loss: 0.381524\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033337; batch adversarial loss: 0.482116\n",
      "epoch 128; iter: 0; batch classifier loss: 0.059469; batch adversarial loss: 0.414536\n",
      "epoch 129; iter: 0; batch classifier loss: 0.077193; batch adversarial loss: 0.482794\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034362; batch adversarial loss: 0.434059\n",
      "epoch 131; iter: 0; batch classifier loss: 0.069080; batch adversarial loss: 0.547724\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039510; batch adversarial loss: 0.459366\n",
      "epoch 133; iter: 0; batch classifier loss: 0.059678; batch adversarial loss: 0.427869\n",
      "epoch 134; iter: 0; batch classifier loss: 0.060748; batch adversarial loss: 0.421798\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041120; batch adversarial loss: 0.468447\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056341; batch adversarial loss: 0.390460\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040869; batch adversarial loss: 0.448667\n",
      "epoch 138; iter: 0; batch classifier loss: 0.063843; batch adversarial loss: 0.475683\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015244; batch adversarial loss: 0.455013\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041709; batch adversarial loss: 0.505828\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052233; batch adversarial loss: 0.449428\n",
      "epoch 142; iter: 0; batch classifier loss: 0.056382; batch adversarial loss: 0.437398\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031554; batch adversarial loss: 0.413463\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030092; batch adversarial loss: 0.387244\n",
      "epoch 145; iter: 0; batch classifier loss: 0.058114; batch adversarial loss: 0.418368\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045076; batch adversarial loss: 0.385442\n",
      "epoch 147; iter: 0; batch classifier loss: 0.054132; batch adversarial loss: 0.500728\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014654; batch adversarial loss: 0.447644\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014100; batch adversarial loss: 0.433353\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023435; batch adversarial loss: 0.417463\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031571; batch adversarial loss: 0.440745\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025384; batch adversarial loss: 0.421959\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027776; batch adversarial loss: 0.488303\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020820; batch adversarial loss: 0.445937\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042446; batch adversarial loss: 0.561396\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032548; batch adversarial loss: 0.448189\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019864; batch adversarial loss: 0.487761\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017450; batch adversarial loss: 0.397208\n",
      "epoch 159; iter: 0; batch classifier loss: 0.060412; batch adversarial loss: 0.381985\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037839; batch adversarial loss: 0.471356\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027344; batch adversarial loss: 0.486103\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030034; batch adversarial loss: 0.373931\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014952; batch adversarial loss: 0.464519\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009659; batch adversarial loss: 0.453901\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035597; batch adversarial loss: 0.513534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.058239; batch adversarial loss: 0.442593\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039012; batch adversarial loss: 0.494568\n",
      "epoch 168; iter: 0; batch classifier loss: 0.053084; batch adversarial loss: 0.511962\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036899; batch adversarial loss: 0.519573\n",
      "epoch 170; iter: 0; batch classifier loss: 0.054240; batch adversarial loss: 0.493871\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047401; batch adversarial loss: 0.398699\n",
      "epoch 172; iter: 0; batch classifier loss: 0.053034; batch adversarial loss: 0.456374\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013020; batch adversarial loss: 0.513114\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030708; batch adversarial loss: 0.484562\n",
      "epoch 175; iter: 0; batch classifier loss: 0.050109; batch adversarial loss: 0.373235\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014055; batch adversarial loss: 0.500434\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017821; batch adversarial loss: 0.554300\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029452; batch adversarial loss: 0.415403\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030669; batch adversarial loss: 0.531126\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040481; batch adversarial loss: 0.421888\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017205; batch adversarial loss: 0.633527\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015305; batch adversarial loss: 0.403872\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033297; batch adversarial loss: 0.314565\n",
      "epoch 184; iter: 0; batch classifier loss: 0.050161; batch adversarial loss: 0.475559\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012662; batch adversarial loss: 0.400636\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040408; batch adversarial loss: 0.445354\n",
      "epoch 187; iter: 0; batch classifier loss: 0.004247; batch adversarial loss: 0.515972\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021603; batch adversarial loss: 0.344711\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027288; batch adversarial loss: 0.438651\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038810; batch adversarial loss: 0.446693\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010270; batch adversarial loss: 0.378317\n",
      "epoch 192; iter: 0; batch classifier loss: 0.042604; batch adversarial loss: 0.476359\n",
      "epoch 193; iter: 0; batch classifier loss: 0.043321; batch adversarial loss: 0.371476\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008467; batch adversarial loss: 0.549424\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026107; batch adversarial loss: 0.434802\n",
      "epoch 196; iter: 0; batch classifier loss: 0.050623; batch adversarial loss: 0.532806\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019757; batch adversarial loss: 0.507260\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006372; batch adversarial loss: 0.514098\n",
      "epoch 199; iter: 0; batch classifier loss: 0.029936; batch adversarial loss: 0.461161\n",
      "epoch 0; iter: 0; batch classifier loss: 0.647081; batch adversarial loss: 0.861586\n",
      "epoch 1; iter: 0; batch classifier loss: 0.454361; batch adversarial loss: 0.898843\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594229; batch adversarial loss: 0.896833\n",
      "epoch 3; iter: 0; batch classifier loss: 0.881176; batch adversarial loss: 0.881269\n",
      "epoch 4; iter: 0; batch classifier loss: 0.993059; batch adversarial loss: 0.786432\n",
      "epoch 5; iter: 0; batch classifier loss: 0.965347; batch adversarial loss: 0.711476\n",
      "epoch 6; iter: 0; batch classifier loss: 1.047510; batch adversarial loss: 0.656837\n",
      "epoch 7; iter: 0; batch classifier loss: 0.740974; batch adversarial loss: 0.617161\n",
      "epoch 8; iter: 0; batch classifier loss: 0.441511; batch adversarial loss: 0.577210\n",
      "epoch 9; iter: 0; batch classifier loss: 0.409969; batch adversarial loss: 0.533926\n",
      "epoch 10; iter: 0; batch classifier loss: 0.302089; batch adversarial loss: 0.540678\n",
      "epoch 11; iter: 0; batch classifier loss: 0.339142; batch adversarial loss: 0.574304\n",
      "epoch 12; iter: 0; batch classifier loss: 0.305981; batch adversarial loss: 0.521219\n",
      "epoch 13; iter: 0; batch classifier loss: 0.323438; batch adversarial loss: 0.541807\n",
      "epoch 14; iter: 0; batch classifier loss: 0.255800; batch adversarial loss: 0.534921\n",
      "epoch 15; iter: 0; batch classifier loss: 0.278743; batch adversarial loss: 0.500312\n",
      "epoch 16; iter: 0; batch classifier loss: 0.304789; batch adversarial loss: 0.450778\n",
      "epoch 17; iter: 0; batch classifier loss: 0.410284; batch adversarial loss: 0.493358\n",
      "epoch 18; iter: 0; batch classifier loss: 0.369875; batch adversarial loss: 0.554307\n",
      "epoch 19; iter: 0; batch classifier loss: 0.427881; batch adversarial loss: 0.502497\n",
      "epoch 20; iter: 0; batch classifier loss: 0.364659; batch adversarial loss: 0.487364\n",
      "epoch 21; iter: 0; batch classifier loss: 0.290095; batch adversarial loss: 0.492348\n",
      "epoch 22; iter: 0; batch classifier loss: 0.288010; batch adversarial loss: 0.475011\n",
      "epoch 23; iter: 0; batch classifier loss: 0.369937; batch adversarial loss: 0.493209\n",
      "epoch 24; iter: 0; batch classifier loss: 0.315949; batch adversarial loss: 0.488153\n",
      "epoch 25; iter: 0; batch classifier loss: 0.375632; batch adversarial loss: 0.485919\n",
      "epoch 26; iter: 0; batch classifier loss: 0.323943; batch adversarial loss: 0.492714\n",
      "epoch 27; iter: 0; batch classifier loss: 0.312972; batch adversarial loss: 0.478836\n",
      "epoch 28; iter: 0; batch classifier loss: 0.326875; batch adversarial loss: 0.498241\n",
      "epoch 29; iter: 0; batch classifier loss: 0.266748; batch adversarial loss: 0.505389\n",
      "epoch 30; iter: 0; batch classifier loss: 0.378202; batch adversarial loss: 0.494411\n",
      "epoch 31; iter: 0; batch classifier loss: 0.261489; batch adversarial loss: 0.469341\n",
      "epoch 32; iter: 0; batch classifier loss: 0.329758; batch adversarial loss: 0.435638\n",
      "epoch 33; iter: 0; batch classifier loss: 0.277725; batch adversarial loss: 0.517467\n",
      "epoch 34; iter: 0; batch classifier loss: 0.288410; batch adversarial loss: 0.433595\n",
      "epoch 35; iter: 0; batch classifier loss: 0.254823; batch adversarial loss: 0.434487\n",
      "epoch 36; iter: 0; batch classifier loss: 0.293376; batch adversarial loss: 0.474047\n",
      "epoch 37; iter: 0; batch classifier loss: 0.288739; batch adversarial loss: 0.518107\n",
      "epoch 38; iter: 0; batch classifier loss: 0.234939; batch adversarial loss: 0.467295\n",
      "epoch 39; iter: 0; batch classifier loss: 0.320946; batch adversarial loss: 0.440841\n",
      "epoch 40; iter: 0; batch classifier loss: 0.186260; batch adversarial loss: 0.475489\n",
      "epoch 41; iter: 0; batch classifier loss: 0.208426; batch adversarial loss: 0.439211\n",
      "epoch 42; iter: 0; batch classifier loss: 0.246348; batch adversarial loss: 0.437637\n",
      "epoch 43; iter: 0; batch classifier loss: 0.264374; batch adversarial loss: 0.451758\n",
      "epoch 44; iter: 0; batch classifier loss: 0.230383; batch adversarial loss: 0.452490\n",
      "epoch 45; iter: 0; batch classifier loss: 0.221093; batch adversarial loss: 0.459012\n",
      "epoch 46; iter: 0; batch classifier loss: 0.236999; batch adversarial loss: 0.452678\n",
      "epoch 47; iter: 0; batch classifier loss: 0.241998; batch adversarial loss: 0.495893\n",
      "epoch 48; iter: 0; batch classifier loss: 0.222735; batch adversarial loss: 0.447796\n",
      "epoch 49; iter: 0; batch classifier loss: 0.177932; batch adversarial loss: 0.576769\n",
      "epoch 50; iter: 0; batch classifier loss: 0.213946; batch adversarial loss: 0.386761\n",
      "epoch 51; iter: 0; batch classifier loss: 0.234021; batch adversarial loss: 0.469774\n",
      "epoch 52; iter: 0; batch classifier loss: 0.227840; batch adversarial loss: 0.386993\n",
      "epoch 53; iter: 0; batch classifier loss: 0.236309; batch adversarial loss: 0.495688\n",
      "epoch 54; iter: 0; batch classifier loss: 0.217116; batch adversarial loss: 0.463303\n",
      "epoch 55; iter: 0; batch classifier loss: 0.238745; batch adversarial loss: 0.437675\n",
      "epoch 56; iter: 0; batch classifier loss: 0.207853; batch adversarial loss: 0.437041\n",
      "epoch 57; iter: 0; batch classifier loss: 0.187790; batch adversarial loss: 0.543494\n",
      "epoch 58; iter: 0; batch classifier loss: 0.161289; batch adversarial loss: 0.506495\n",
      "epoch 59; iter: 0; batch classifier loss: 0.203613; batch adversarial loss: 0.506703\n",
      "epoch 60; iter: 0; batch classifier loss: 0.230690; batch adversarial loss: 0.494200\n",
      "epoch 61; iter: 0; batch classifier loss: 0.198108; batch adversarial loss: 0.509327\n",
      "epoch 62; iter: 0; batch classifier loss: 0.185321; batch adversarial loss: 0.469445\n",
      "epoch 63; iter: 0; batch classifier loss: 0.227888; batch adversarial loss: 0.397654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.171356; batch adversarial loss: 0.508844\n",
      "epoch 65; iter: 0; batch classifier loss: 0.151355; batch adversarial loss: 0.400080\n",
      "epoch 66; iter: 0; batch classifier loss: 0.164727; batch adversarial loss: 0.398200\n",
      "epoch 67; iter: 0; batch classifier loss: 0.220566; batch adversarial loss: 0.398205\n",
      "epoch 68; iter: 0; batch classifier loss: 0.228772; batch adversarial loss: 0.422547\n",
      "epoch 69; iter: 0; batch classifier loss: 0.192403; batch adversarial loss: 0.459526\n",
      "epoch 70; iter: 0; batch classifier loss: 0.200064; batch adversarial loss: 0.471784\n",
      "epoch 71; iter: 0; batch classifier loss: 0.228926; batch adversarial loss: 0.483212\n",
      "epoch 72; iter: 0; batch classifier loss: 0.220617; batch adversarial loss: 0.410543\n",
      "epoch 73; iter: 0; batch classifier loss: 0.233371; batch adversarial loss: 0.398035\n",
      "epoch 74; iter: 0; batch classifier loss: 0.266602; batch adversarial loss: 0.457794\n",
      "epoch 75; iter: 0; batch classifier loss: 0.220729; batch adversarial loss: 0.483795\n",
      "epoch 76; iter: 0; batch classifier loss: 0.236017; batch adversarial loss: 0.446582\n",
      "epoch 77; iter: 0; batch classifier loss: 0.163449; batch adversarial loss: 0.495259\n",
      "epoch 78; iter: 0; batch classifier loss: 0.237332; batch adversarial loss: 0.446766\n",
      "epoch 79; iter: 0; batch classifier loss: 0.217933; batch adversarial loss: 0.446828\n",
      "epoch 80; iter: 0; batch classifier loss: 0.237965; batch adversarial loss: 0.532241\n",
      "epoch 81; iter: 0; batch classifier loss: 0.118399; batch adversarial loss: 0.459634\n",
      "epoch 82; iter: 0; batch classifier loss: 0.196387; batch adversarial loss: 0.483961\n",
      "epoch 83; iter: 0; batch classifier loss: 0.251736; batch adversarial loss: 0.384854\n",
      "epoch 84; iter: 0; batch classifier loss: 0.315897; batch adversarial loss: 0.449678\n",
      "epoch 85; iter: 0; batch classifier loss: 0.176833; batch adversarial loss: 0.469880\n",
      "epoch 86; iter: 0; batch classifier loss: 0.216526; batch adversarial loss: 0.397397\n",
      "epoch 87; iter: 0; batch classifier loss: 0.122271; batch adversarial loss: 0.509396\n",
      "epoch 88; iter: 0; batch classifier loss: 0.162540; batch adversarial loss: 0.518369\n",
      "epoch 89; iter: 0; batch classifier loss: 0.226514; batch adversarial loss: 0.435202\n",
      "epoch 90; iter: 0; batch classifier loss: 0.231622; batch adversarial loss: 0.421904\n",
      "epoch 91; iter: 0; batch classifier loss: 0.157447; batch adversarial loss: 0.507974\n",
      "epoch 92; iter: 0; batch classifier loss: 0.181791; batch adversarial loss: 0.495045\n",
      "epoch 93; iter: 0; batch classifier loss: 0.176029; batch adversarial loss: 0.507137\n",
      "epoch 94; iter: 0; batch classifier loss: 0.197353; batch adversarial loss: 0.397522\n",
      "epoch 95; iter: 0; batch classifier loss: 0.172879; batch adversarial loss: 0.336598\n",
      "epoch 96; iter: 0; batch classifier loss: 0.223634; batch adversarial loss: 0.495802\n",
      "epoch 97; iter: 0; batch classifier loss: 0.190999; batch adversarial loss: 0.494976\n",
      "epoch 98; iter: 0; batch classifier loss: 0.215366; batch adversarial loss: 0.543942\n",
      "epoch 99; iter: 0; batch classifier loss: 0.181705; batch adversarial loss: 0.422127\n",
      "epoch 100; iter: 0; batch classifier loss: 0.212474; batch adversarial loss: 0.519577\n",
      "epoch 101; iter: 0; batch classifier loss: 0.131872; batch adversarial loss: 0.458941\n",
      "epoch 102; iter: 0; batch classifier loss: 0.129984; batch adversarial loss: 0.360949\n",
      "epoch 103; iter: 0; batch classifier loss: 0.135206; batch adversarial loss: 0.519771\n",
      "epoch 104; iter: 0; batch classifier loss: 0.137478; batch adversarial loss: 0.482880\n",
      "epoch 105; iter: 0; batch classifier loss: 0.220736; batch adversarial loss: 0.471249\n",
      "epoch 106; iter: 0; batch classifier loss: 0.139594; batch adversarial loss: 0.373247\n",
      "epoch 107; iter: 0; batch classifier loss: 0.233104; batch adversarial loss: 0.408731\n",
      "epoch 108; iter: 0; batch classifier loss: 0.196517; batch adversarial loss: 0.373737\n",
      "epoch 109; iter: 0; batch classifier loss: 0.139909; batch adversarial loss: 0.483773\n",
      "epoch 110; iter: 0; batch classifier loss: 0.141763; batch adversarial loss: 0.434722\n",
      "epoch 111; iter: 0; batch classifier loss: 0.238297; batch adversarial loss: 0.458553\n",
      "epoch 112; iter: 0; batch classifier loss: 0.247993; batch adversarial loss: 0.568650\n",
      "epoch 113; iter: 0; batch classifier loss: 0.188737; batch adversarial loss: 0.373756\n",
      "epoch 114; iter: 0; batch classifier loss: 0.183283; batch adversarial loss: 0.421915\n",
      "epoch 115; iter: 0; batch classifier loss: 0.173715; batch adversarial loss: 0.484577\n",
      "epoch 116; iter: 0; batch classifier loss: 0.158354; batch adversarial loss: 0.533466\n",
      "epoch 117; iter: 0; batch classifier loss: 0.227081; batch adversarial loss: 0.508232\n",
      "epoch 118; iter: 0; batch classifier loss: 0.164573; batch adversarial loss: 0.483232\n",
      "epoch 119; iter: 0; batch classifier loss: 0.144546; batch adversarial loss: 0.520151\n",
      "epoch 120; iter: 0; batch classifier loss: 0.146536; batch adversarial loss: 0.507060\n",
      "epoch 121; iter: 0; batch classifier loss: 0.205370; batch adversarial loss: 0.385694\n",
      "epoch 122; iter: 0; batch classifier loss: 0.162128; batch adversarial loss: 0.433558\n",
      "epoch 123; iter: 0; batch classifier loss: 0.151535; batch adversarial loss: 0.496153\n",
      "epoch 124; iter: 0; batch classifier loss: 0.194913; batch adversarial loss: 0.456704\n",
      "epoch 125; iter: 0; batch classifier loss: 0.179627; batch adversarial loss: 0.383913\n",
      "epoch 126; iter: 0; batch classifier loss: 0.175825; batch adversarial loss: 0.458593\n",
      "epoch 127; iter: 0; batch classifier loss: 0.153289; batch adversarial loss: 0.409965\n",
      "epoch 128; iter: 0; batch classifier loss: 0.207179; batch adversarial loss: 0.445914\n",
      "epoch 129; iter: 0; batch classifier loss: 0.168764; batch adversarial loss: 0.492681\n",
      "epoch 130; iter: 0; batch classifier loss: 0.137866; batch adversarial loss: 0.580770\n",
      "epoch 131; iter: 0; batch classifier loss: 0.139164; batch adversarial loss: 0.467703\n",
      "epoch 132; iter: 0; batch classifier loss: 0.070252; batch adversarial loss: 0.473846\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051457; batch adversarial loss: 0.418255\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045699; batch adversarial loss: 0.414741\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050916; batch adversarial loss: 0.518551\n",
      "epoch 136; iter: 0; batch classifier loss: 0.052160; batch adversarial loss: 0.390680\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028027; batch adversarial loss: 0.467007\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033145; batch adversarial loss: 0.454983\n",
      "epoch 139; iter: 0; batch classifier loss: 0.052166; batch adversarial loss: 0.502567\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027143; batch adversarial loss: 0.445999\n",
      "epoch 141; iter: 0; batch classifier loss: 0.054851; batch adversarial loss: 0.438977\n",
      "epoch 142; iter: 0; batch classifier loss: 0.015974; batch adversarial loss: 0.453516\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050014; batch adversarial loss: 0.486322\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039732; batch adversarial loss: 0.508996\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020995; batch adversarial loss: 0.362935\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028269; batch adversarial loss: 0.484646\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018947; batch adversarial loss: 0.511537\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020758; batch adversarial loss: 0.558885\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018065; batch adversarial loss: 0.437932\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019359; batch adversarial loss: 0.436849\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025768; batch adversarial loss: 0.507057\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036315; batch adversarial loss: 0.383591\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030813; batch adversarial loss: 0.407140\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017532; batch adversarial loss: 0.383503\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013835; batch adversarial loss: 0.510747\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024117; batch adversarial loss: 0.333152\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028558; batch adversarial loss: 0.415285\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014655; batch adversarial loss: 0.512071\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016114; batch adversarial loss: 0.406184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.045588; batch adversarial loss: 0.429045\n",
      "epoch 161; iter: 0; batch classifier loss: 0.049863; batch adversarial loss: 0.437208\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012313; batch adversarial loss: 0.391111\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007679; batch adversarial loss: 0.598338\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030750; batch adversarial loss: 0.424480\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013074; batch adversarial loss: 0.448055\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031554; batch adversarial loss: 0.457738\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015521; batch adversarial loss: 0.411737\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024570; batch adversarial loss: 0.496222\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028448; batch adversarial loss: 0.383984\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023937; batch adversarial loss: 0.408413\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009130; batch adversarial loss: 0.478725\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014805; batch adversarial loss: 0.402254\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021195; batch adversarial loss: 0.515902\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031802; batch adversarial loss: 0.506349\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024194; batch adversarial loss: 0.419322\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011089; batch adversarial loss: 0.447355\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014048; batch adversarial loss: 0.392538\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015149; batch adversarial loss: 0.534862\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009086; batch adversarial loss: 0.515020\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016681; batch adversarial loss: 0.427603\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012471; batch adversarial loss: 0.394866\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011820; batch adversarial loss: 0.422873\n",
      "epoch 183; iter: 0; batch classifier loss: 0.004025; batch adversarial loss: 0.429865\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020200; batch adversarial loss: 0.407969\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014523; batch adversarial loss: 0.454340\n",
      "epoch 186; iter: 0; batch classifier loss: 0.004049; batch adversarial loss: 0.429039\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008602; batch adversarial loss: 0.433195\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016734; batch adversarial loss: 0.563673\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017764; batch adversarial loss: 0.489627\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025312; batch adversarial loss: 0.420887\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010589; batch adversarial loss: 0.384258\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010134; batch adversarial loss: 0.364335\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029992; batch adversarial loss: 0.443838\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015279; batch adversarial loss: 0.536777\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029512; batch adversarial loss: 0.326308\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014438; batch adversarial loss: 0.463832\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017356; batch adversarial loss: 0.417490\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014599; batch adversarial loss: 0.484750\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014279; batch adversarial loss: 0.454250\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671588; batch adversarial loss: 0.601115\n",
      "epoch 1; iter: 0; batch classifier loss: 0.365662; batch adversarial loss: 0.624918\n",
      "epoch 2; iter: 0; batch classifier loss: 0.429614; batch adversarial loss: 0.636516\n",
      "epoch 3; iter: 0; batch classifier loss: 0.419853; batch adversarial loss: 0.541601\n",
      "epoch 4; iter: 0; batch classifier loss: 0.375989; batch adversarial loss: 0.571652\n",
      "epoch 5; iter: 0; batch classifier loss: 0.398970; batch adversarial loss: 0.575561\n",
      "epoch 6; iter: 0; batch classifier loss: 0.261018; batch adversarial loss: 0.566540\n",
      "epoch 7; iter: 0; batch classifier loss: 0.371710; batch adversarial loss: 0.539478\n",
      "epoch 8; iter: 0; batch classifier loss: 0.343722; batch adversarial loss: 0.564361\n",
      "epoch 9; iter: 0; batch classifier loss: 0.302736; batch adversarial loss: 0.574634\n",
      "epoch 10; iter: 0; batch classifier loss: 0.445079; batch adversarial loss: 0.629825\n",
      "epoch 11; iter: 0; batch classifier loss: 0.527364; batch adversarial loss: 0.582700\n",
      "epoch 12; iter: 0; batch classifier loss: 0.465157; batch adversarial loss: 0.622897\n",
      "epoch 13; iter: 0; batch classifier loss: 0.587000; batch adversarial loss: 0.513372\n",
      "epoch 14; iter: 0; batch classifier loss: 0.442699; batch adversarial loss: 0.542746\n",
      "epoch 15; iter: 0; batch classifier loss: 0.288281; batch adversarial loss: 0.490287\n",
      "epoch 16; iter: 0; batch classifier loss: 0.223677; batch adversarial loss: 0.484341\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262297; batch adversarial loss: 0.495917\n",
      "epoch 18; iter: 0; batch classifier loss: 0.282178; batch adversarial loss: 0.471782\n",
      "epoch 19; iter: 0; batch classifier loss: 0.230367; batch adversarial loss: 0.441558\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222060; batch adversarial loss: 0.523862\n",
      "epoch 21; iter: 0; batch classifier loss: 0.171775; batch adversarial loss: 0.468423\n",
      "epoch 22; iter: 0; batch classifier loss: 0.147460; batch adversarial loss: 0.479599\n",
      "epoch 23; iter: 0; batch classifier loss: 0.202037; batch adversarial loss: 0.405391\n",
      "epoch 24; iter: 0; batch classifier loss: 0.238014; batch adversarial loss: 0.484785\n",
      "epoch 25; iter: 0; batch classifier loss: 0.150482; batch adversarial loss: 0.528076\n",
      "epoch 26; iter: 0; batch classifier loss: 0.167479; batch adversarial loss: 0.499665\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159497; batch adversarial loss: 0.462928\n",
      "epoch 28; iter: 0; batch classifier loss: 0.158085; batch adversarial loss: 0.495992\n",
      "epoch 29; iter: 0; batch classifier loss: 0.119999; batch adversarial loss: 0.550763\n",
      "epoch 30; iter: 0; batch classifier loss: 0.140163; batch adversarial loss: 0.430959\n",
      "epoch 31; iter: 0; batch classifier loss: 0.119644; batch adversarial loss: 0.432152\n",
      "epoch 32; iter: 0; batch classifier loss: 0.129572; batch adversarial loss: 0.541775\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163704; batch adversarial loss: 0.397913\n",
      "epoch 34; iter: 0; batch classifier loss: 0.137508; batch adversarial loss: 0.462439\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140118; batch adversarial loss: 0.496524\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128873; batch adversarial loss: 0.462696\n",
      "epoch 37; iter: 0; batch classifier loss: 0.137140; batch adversarial loss: 0.397334\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115246; batch adversarial loss: 0.493416\n",
      "epoch 39; iter: 0; batch classifier loss: 0.102559; batch adversarial loss: 0.448045\n",
      "epoch 40; iter: 0; batch classifier loss: 0.126655; batch adversarial loss: 0.434171\n",
      "epoch 41; iter: 0; batch classifier loss: 0.070129; batch adversarial loss: 0.448408\n",
      "epoch 42; iter: 0; batch classifier loss: 0.127582; batch adversarial loss: 0.565296\n",
      "epoch 43; iter: 0; batch classifier loss: 0.084351; batch adversarial loss: 0.421581\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112950; batch adversarial loss: 0.549736\n",
      "epoch 45; iter: 0; batch classifier loss: 0.101003; batch adversarial loss: 0.330063\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127116; batch adversarial loss: 0.455624\n",
      "epoch 47; iter: 0; batch classifier loss: 0.138527; batch adversarial loss: 0.478126\n",
      "epoch 48; iter: 0; batch classifier loss: 0.102284; batch adversarial loss: 0.512279\n",
      "epoch 49; iter: 0; batch classifier loss: 0.157770; batch adversarial loss: 0.500546\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096449; batch adversarial loss: 0.554842\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121712; batch adversarial loss: 0.423394\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089182; batch adversarial loss: 0.414645\n",
      "epoch 53; iter: 0; batch classifier loss: 0.099270; batch adversarial loss: 0.520496\n",
      "epoch 54; iter: 0; batch classifier loss: 0.152791; batch adversarial loss: 0.421439\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083599; batch adversarial loss: 0.550106\n",
      "epoch 56; iter: 0; batch classifier loss: 0.147646; batch adversarial loss: 0.452115\n",
      "epoch 57; iter: 0; batch classifier loss: 0.077318; batch adversarial loss: 0.455380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.092187; batch adversarial loss: 0.410436\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088779; batch adversarial loss: 0.404971\n",
      "epoch 60; iter: 0; batch classifier loss: 0.214227; batch adversarial loss: 0.428955\n",
      "epoch 61; iter: 0; batch classifier loss: 0.081182; batch adversarial loss: 0.512853\n",
      "epoch 62; iter: 0; batch classifier loss: 0.117742; batch adversarial loss: 0.430944\n",
      "epoch 63; iter: 0; batch classifier loss: 0.134736; batch adversarial loss: 0.428562\n",
      "epoch 64; iter: 0; batch classifier loss: 0.171841; batch adversarial loss: 0.542725\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065432; batch adversarial loss: 0.517568\n",
      "epoch 66; iter: 0; batch classifier loss: 0.109073; batch adversarial loss: 0.424434\n",
      "epoch 67; iter: 0; batch classifier loss: 0.097031; batch adversarial loss: 0.493407\n",
      "epoch 68; iter: 0; batch classifier loss: 0.112578; batch adversarial loss: 0.438195\n",
      "epoch 69; iter: 0; batch classifier loss: 0.093152; batch adversarial loss: 0.534839\n",
      "epoch 70; iter: 0; batch classifier loss: 0.131630; batch adversarial loss: 0.448966\n",
      "epoch 71; iter: 0; batch classifier loss: 0.095225; batch adversarial loss: 0.456649\n",
      "epoch 72; iter: 0; batch classifier loss: 0.079174; batch adversarial loss: 0.523780\n",
      "epoch 73; iter: 0; batch classifier loss: 0.097164; batch adversarial loss: 0.440672\n",
      "epoch 74; iter: 0; batch classifier loss: 0.105812; batch adversarial loss: 0.461571\n",
      "epoch 75; iter: 0; batch classifier loss: 0.117386; batch adversarial loss: 0.536631\n",
      "epoch 76; iter: 0; batch classifier loss: 0.116837; batch adversarial loss: 0.422436\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055209; batch adversarial loss: 0.465320\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056330; batch adversarial loss: 0.398486\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055260; batch adversarial loss: 0.415078\n",
      "epoch 80; iter: 0; batch classifier loss: 0.159272; batch adversarial loss: 0.451461\n",
      "epoch 81; iter: 0; batch classifier loss: 0.124645; batch adversarial loss: 0.375414\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071087; batch adversarial loss: 0.492836\n",
      "epoch 83; iter: 0; batch classifier loss: 0.118907; batch adversarial loss: 0.439995\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079785; batch adversarial loss: 0.346844\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090446; batch adversarial loss: 0.520450\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083004; batch adversarial loss: 0.472403\n",
      "epoch 87; iter: 0; batch classifier loss: 0.104365; batch adversarial loss: 0.423894\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069610; batch adversarial loss: 0.498909\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057913; batch adversarial loss: 0.401126\n",
      "epoch 90; iter: 0; batch classifier loss: 0.119783; batch adversarial loss: 0.537644\n",
      "epoch 91; iter: 0; batch classifier loss: 0.087331; batch adversarial loss: 0.445754\n",
      "epoch 92; iter: 0; batch classifier loss: 0.075702; batch adversarial loss: 0.474982\n",
      "epoch 93; iter: 0; batch classifier loss: 0.073522; batch adversarial loss: 0.356564\n",
      "epoch 94; iter: 0; batch classifier loss: 0.074048; batch adversarial loss: 0.392929\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044118; batch adversarial loss: 0.471494\n",
      "epoch 96; iter: 0; batch classifier loss: 0.052983; batch adversarial loss: 0.505622\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081446; batch adversarial loss: 0.473048\n",
      "epoch 98; iter: 0; batch classifier loss: 0.037835; batch adversarial loss: 0.521753\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067992; batch adversarial loss: 0.388428\n",
      "epoch 100; iter: 0; batch classifier loss: 0.084917; batch adversarial loss: 0.467229\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054496; batch adversarial loss: 0.452428\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046087; batch adversarial loss: 0.383791\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049556; batch adversarial loss: 0.306703\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037416; batch adversarial loss: 0.470594\n",
      "epoch 105; iter: 0; batch classifier loss: 0.092079; batch adversarial loss: 0.478824\n",
      "epoch 106; iter: 0; batch classifier loss: 0.084152; batch adversarial loss: 0.446249\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059309; batch adversarial loss: 0.399426\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038083; batch adversarial loss: 0.544933\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040600; batch adversarial loss: 0.551054\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036602; batch adversarial loss: 0.426072\n",
      "epoch 111; iter: 0; batch classifier loss: 0.080107; batch adversarial loss: 0.522709\n",
      "epoch 112; iter: 0; batch classifier loss: 0.083723; batch adversarial loss: 0.502356\n",
      "epoch 113; iter: 0; batch classifier loss: 0.022780; batch adversarial loss: 0.405581\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026249; batch adversarial loss: 0.377961\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021416; batch adversarial loss: 0.420420\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040667; batch adversarial loss: 0.497174\n",
      "epoch 117; iter: 0; batch classifier loss: 0.068509; batch adversarial loss: 0.408886\n",
      "epoch 118; iter: 0; batch classifier loss: 0.058636; batch adversarial loss: 0.484955\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025315; batch adversarial loss: 0.481740\n",
      "epoch 120; iter: 0; batch classifier loss: 0.018041; batch adversarial loss: 0.435941\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051095; batch adversarial loss: 0.494920\n",
      "epoch 122; iter: 0; batch classifier loss: 0.047411; batch adversarial loss: 0.452290\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049715; batch adversarial loss: 0.412393\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021452; batch adversarial loss: 0.502501\n",
      "epoch 125; iter: 0; batch classifier loss: 0.072635; batch adversarial loss: 0.509948\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032507; batch adversarial loss: 0.445034\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039766; batch adversarial loss: 0.426957\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043954; batch adversarial loss: 0.395977\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030759; batch adversarial loss: 0.447144\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023735; batch adversarial loss: 0.491816\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031496; batch adversarial loss: 0.436931\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049754; batch adversarial loss: 0.461311\n",
      "epoch 133; iter: 0; batch classifier loss: 0.067446; batch adversarial loss: 0.539766\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020382; batch adversarial loss: 0.485849\n",
      "epoch 135; iter: 0; batch classifier loss: 0.063033; batch adversarial loss: 0.464957\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029667; batch adversarial loss: 0.429311\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043392; batch adversarial loss: 0.461385\n",
      "epoch 138; iter: 0; batch classifier loss: 0.047330; batch adversarial loss: 0.493955\n",
      "epoch 139; iter: 0; batch classifier loss: 0.053281; batch adversarial loss: 0.526562\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024662; batch adversarial loss: 0.488697\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036521; batch adversarial loss: 0.503811\n",
      "epoch 142; iter: 0; batch classifier loss: 0.053618; batch adversarial loss: 0.393996\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025032; batch adversarial loss: 0.516956\n",
      "epoch 144; iter: 0; batch classifier loss: 0.011730; batch adversarial loss: 0.452858\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014519; batch adversarial loss: 0.378892\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038491; batch adversarial loss: 0.415128\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020693; batch adversarial loss: 0.568239\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016896; batch adversarial loss: 0.359675\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042784; batch adversarial loss: 0.442718\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034100; batch adversarial loss: 0.572365\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018817; batch adversarial loss: 0.485408\n",
      "epoch 152; iter: 0; batch classifier loss: 0.047528; batch adversarial loss: 0.474070\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011146; batch adversarial loss: 0.461759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.021392; batch adversarial loss: 0.477909\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019421; batch adversarial loss: 0.466916\n",
      "epoch 156; iter: 0; batch classifier loss: 0.026322; batch adversarial loss: 0.477478\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020728; batch adversarial loss: 0.387172\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026407; batch adversarial loss: 0.524279\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037294; batch adversarial loss: 0.411043\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017824; batch adversarial loss: 0.502161\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025940; batch adversarial loss: 0.485150\n",
      "epoch 162; iter: 0; batch classifier loss: 0.003888; batch adversarial loss: 0.582867\n",
      "epoch 163; iter: 0; batch classifier loss: 0.008342; batch adversarial loss: 0.466497\n",
      "epoch 164; iter: 0; batch classifier loss: 0.045689; batch adversarial loss: 0.448676\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015945; batch adversarial loss: 0.467374\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014425; batch adversarial loss: 0.470713\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034066; batch adversarial loss: 0.385183\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032029; batch adversarial loss: 0.434184\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010583; batch adversarial loss: 0.589609\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029142; batch adversarial loss: 0.483145\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047770; batch adversarial loss: 0.429078\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015264; batch adversarial loss: 0.522651\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023270; batch adversarial loss: 0.438869\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017607; batch adversarial loss: 0.549149\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041760; batch adversarial loss: 0.318368\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025001; batch adversarial loss: 0.479610\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049494; batch adversarial loss: 0.470567\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009120; batch adversarial loss: 0.452008\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006273; batch adversarial loss: 0.422634\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014757; batch adversarial loss: 0.438504\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006997; batch adversarial loss: 0.459634\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013982; batch adversarial loss: 0.438523\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020056; batch adversarial loss: 0.489179\n",
      "epoch 184; iter: 0; batch classifier loss: 0.039076; batch adversarial loss: 0.494033\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014751; batch adversarial loss: 0.498966\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020784; batch adversarial loss: 0.538035\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009356; batch adversarial loss: 0.420045\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014054; batch adversarial loss: 0.448187\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033132; batch adversarial loss: 0.570740\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021855; batch adversarial loss: 0.481765\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007892; batch adversarial loss: 0.528818\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026702; batch adversarial loss: 0.476532\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008103; batch adversarial loss: 0.448153\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019740; batch adversarial loss: 0.476469\n",
      "epoch 195; iter: 0; batch classifier loss: 0.043456; batch adversarial loss: 0.443975\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025550; batch adversarial loss: 0.451669\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028885; batch adversarial loss: 0.449027\n",
      "epoch 198; iter: 0; batch classifier loss: 0.059428; batch adversarial loss: 0.429141\n",
      "epoch 199; iter: 0; batch classifier loss: 0.038127; batch adversarial loss: 0.417466\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714129; batch adversarial loss: 0.610179\n",
      "epoch 1; iter: 0; batch classifier loss: 0.487343; batch adversarial loss: 0.596061\n",
      "epoch 2; iter: 0; batch classifier loss: 0.439061; batch adversarial loss: 0.580546\n",
      "epoch 3; iter: 0; batch classifier loss: 0.352130; batch adversarial loss: 0.574121\n",
      "epoch 4; iter: 0; batch classifier loss: 0.434786; batch adversarial loss: 0.611699\n",
      "epoch 5; iter: 0; batch classifier loss: 0.499029; batch adversarial loss: 0.612882\n",
      "epoch 6; iter: 0; batch classifier loss: 0.498949; batch adversarial loss: 0.600254\n",
      "epoch 7; iter: 0; batch classifier loss: 0.513093; batch adversarial loss: 0.561721\n",
      "epoch 8; iter: 0; batch classifier loss: 0.620752; batch adversarial loss: 0.568037\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534544; batch adversarial loss: 0.529876\n",
      "epoch 10; iter: 0; batch classifier loss: 0.349880; batch adversarial loss: 0.540098\n",
      "epoch 11; iter: 0; batch classifier loss: 0.339096; batch adversarial loss: 0.508247\n",
      "epoch 12; iter: 0; batch classifier loss: 0.323662; batch adversarial loss: 0.461447\n",
      "epoch 13; iter: 0; batch classifier loss: 0.287716; batch adversarial loss: 0.500544\n",
      "epoch 14; iter: 0; batch classifier loss: 0.280629; batch adversarial loss: 0.426362\n",
      "epoch 15; iter: 0; batch classifier loss: 0.293233; batch adversarial loss: 0.467854\n",
      "epoch 16; iter: 0; batch classifier loss: 0.315080; batch adversarial loss: 0.507971\n",
      "epoch 17; iter: 0; batch classifier loss: 0.275735; batch adversarial loss: 0.462103\n",
      "epoch 18; iter: 0; batch classifier loss: 0.248025; batch adversarial loss: 0.492527\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237087; batch adversarial loss: 0.420197\n",
      "epoch 20; iter: 0; batch classifier loss: 0.201745; batch adversarial loss: 0.480143\n",
      "epoch 21; iter: 0; batch classifier loss: 0.245288; batch adversarial loss: 0.474982\n",
      "epoch 22; iter: 0; batch classifier loss: 0.282182; batch adversarial loss: 0.456595\n",
      "epoch 23; iter: 0; batch classifier loss: 0.177008; batch adversarial loss: 0.543565\n",
      "epoch 24; iter: 0; batch classifier loss: 0.232706; batch adversarial loss: 0.506385\n",
      "epoch 25; iter: 0; batch classifier loss: 0.175626; batch adversarial loss: 0.499896\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165730; batch adversarial loss: 0.514159\n",
      "epoch 27; iter: 0; batch classifier loss: 0.161888; batch adversarial loss: 0.484928\n",
      "epoch 28; iter: 0; batch classifier loss: 0.178198; batch adversarial loss: 0.420353\n",
      "epoch 29; iter: 0; batch classifier loss: 0.203758; batch adversarial loss: 0.488836\n",
      "epoch 30; iter: 0; batch classifier loss: 0.131390; batch adversarial loss: 0.445676\n",
      "epoch 31; iter: 0; batch classifier loss: 0.130138; batch adversarial loss: 0.468344\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165167; batch adversarial loss: 0.434474\n",
      "epoch 33; iter: 0; batch classifier loss: 0.199711; batch adversarial loss: 0.539444\n",
      "epoch 34; iter: 0; batch classifier loss: 0.176376; batch adversarial loss: 0.475289\n",
      "epoch 35; iter: 0; batch classifier loss: 0.138812; batch adversarial loss: 0.521934\n",
      "epoch 36; iter: 0; batch classifier loss: 0.227416; batch adversarial loss: 0.532972\n",
      "epoch 37; iter: 0; batch classifier loss: 0.229380; batch adversarial loss: 0.419561\n",
      "epoch 38; iter: 0; batch classifier loss: 0.137864; batch adversarial loss: 0.500761\n",
      "epoch 39; iter: 0; batch classifier loss: 0.209714; batch adversarial loss: 0.424985\n",
      "epoch 40; iter: 0; batch classifier loss: 0.170870; batch adversarial loss: 0.464631\n",
      "epoch 41; iter: 0; batch classifier loss: 0.100987; batch adversarial loss: 0.409954\n",
      "epoch 42; iter: 0; batch classifier loss: 0.112088; batch adversarial loss: 0.521776\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150577; batch adversarial loss: 0.451395\n",
      "epoch 44; iter: 0; batch classifier loss: 0.213593; batch adversarial loss: 0.407186\n",
      "epoch 45; iter: 0; batch classifier loss: 0.168296; batch adversarial loss: 0.471089\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114635; batch adversarial loss: 0.512905\n",
      "epoch 47; iter: 0; batch classifier loss: 0.151133; batch adversarial loss: 0.480990\n",
      "epoch 48; iter: 0; batch classifier loss: 0.119366; batch adversarial loss: 0.453383\n",
      "epoch 49; iter: 0; batch classifier loss: 0.128539; batch adversarial loss: 0.490882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.113372; batch adversarial loss: 0.464831\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109404; batch adversarial loss: 0.469772\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111315; batch adversarial loss: 0.494250\n",
      "epoch 53; iter: 0; batch classifier loss: 0.117476; batch adversarial loss: 0.506194\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114612; batch adversarial loss: 0.370542\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083906; batch adversarial loss: 0.453697\n",
      "epoch 56; iter: 0; batch classifier loss: 0.127167; batch adversarial loss: 0.408074\n",
      "epoch 57; iter: 0; batch classifier loss: 0.215152; batch adversarial loss: 0.393338\n",
      "epoch 58; iter: 0; batch classifier loss: 0.089483; batch adversarial loss: 0.487975\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083540; batch adversarial loss: 0.420693\n",
      "epoch 60; iter: 0; batch classifier loss: 0.098578; batch adversarial loss: 0.426086\n",
      "epoch 61; iter: 0; batch classifier loss: 0.145419; batch adversarial loss: 0.458043\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094309; batch adversarial loss: 0.446407\n",
      "epoch 63; iter: 0; batch classifier loss: 0.102531; batch adversarial loss: 0.478159\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076788; batch adversarial loss: 0.421960\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118291; batch adversarial loss: 0.377013\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073750; batch adversarial loss: 0.448541\n",
      "epoch 67; iter: 0; batch classifier loss: 0.123078; batch adversarial loss: 0.497401\n",
      "epoch 68; iter: 0; batch classifier loss: 0.101602; batch adversarial loss: 0.526615\n",
      "epoch 69; iter: 0; batch classifier loss: 0.074587; batch adversarial loss: 0.421964\n",
      "epoch 70; iter: 0; batch classifier loss: 0.092578; batch adversarial loss: 0.432824\n",
      "epoch 71; iter: 0; batch classifier loss: 0.140442; batch adversarial loss: 0.453907\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074818; batch adversarial loss: 0.410803\n",
      "epoch 73; iter: 0; batch classifier loss: 0.120698; batch adversarial loss: 0.419653\n",
      "epoch 74; iter: 0; batch classifier loss: 0.092822; batch adversarial loss: 0.446754\n",
      "epoch 75; iter: 0; batch classifier loss: 0.138563; batch adversarial loss: 0.399817\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073793; batch adversarial loss: 0.511532\n",
      "epoch 77; iter: 0; batch classifier loss: 0.100532; batch adversarial loss: 0.366530\n",
      "epoch 78; iter: 0; batch classifier loss: 0.115712; batch adversarial loss: 0.404701\n",
      "epoch 79; iter: 0; batch classifier loss: 0.079176; batch adversarial loss: 0.486824\n",
      "epoch 80; iter: 0; batch classifier loss: 0.077423; batch adversarial loss: 0.499790\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083538; batch adversarial loss: 0.417573\n",
      "epoch 82; iter: 0; batch classifier loss: 0.110874; batch adversarial loss: 0.399506\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081522; batch adversarial loss: 0.419337\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051870; batch adversarial loss: 0.473055\n",
      "epoch 85; iter: 0; batch classifier loss: 0.097114; batch adversarial loss: 0.464166\n",
      "epoch 86; iter: 0; batch classifier loss: 0.059514; batch adversarial loss: 0.518920\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062957; batch adversarial loss: 0.415456\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070051; batch adversarial loss: 0.511872\n",
      "epoch 89; iter: 0; batch classifier loss: 0.102914; batch adversarial loss: 0.501626\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051869; batch adversarial loss: 0.454012\n",
      "epoch 91; iter: 0; batch classifier loss: 0.054078; batch adversarial loss: 0.468294\n",
      "epoch 92; iter: 0; batch classifier loss: 0.085019; batch adversarial loss: 0.562618\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036976; batch adversarial loss: 0.427772\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056467; batch adversarial loss: 0.466453\n",
      "epoch 95; iter: 0; batch classifier loss: 0.041509; batch adversarial loss: 0.561794\n",
      "epoch 96; iter: 0; batch classifier loss: 0.073162; batch adversarial loss: 0.526690\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080756; batch adversarial loss: 0.461431\n",
      "epoch 98; iter: 0; batch classifier loss: 0.097397; batch adversarial loss: 0.468652\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056212; batch adversarial loss: 0.414321\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053666; batch adversarial loss: 0.531979\n",
      "epoch 101; iter: 0; batch classifier loss: 0.095308; batch adversarial loss: 0.432377\n",
      "epoch 102; iter: 0; batch classifier loss: 0.061550; batch adversarial loss: 0.420129\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048252; batch adversarial loss: 0.396976\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039061; batch adversarial loss: 0.427320\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042169; batch adversarial loss: 0.556901\n",
      "epoch 106; iter: 0; batch classifier loss: 0.079012; batch adversarial loss: 0.483761\n",
      "epoch 107; iter: 0; batch classifier loss: 0.101772; batch adversarial loss: 0.430971\n",
      "epoch 108; iter: 0; batch classifier loss: 0.075281; batch adversarial loss: 0.375888\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047118; batch adversarial loss: 0.341987\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058909; batch adversarial loss: 0.386982\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042712; batch adversarial loss: 0.484256\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034757; batch adversarial loss: 0.491395\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052677; batch adversarial loss: 0.458413\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057807; batch adversarial loss: 0.449181\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037493; batch adversarial loss: 0.433485\n",
      "epoch 116; iter: 0; batch classifier loss: 0.063085; batch adversarial loss: 0.453358\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046028; batch adversarial loss: 0.475442\n",
      "epoch 118; iter: 0; batch classifier loss: 0.055429; batch adversarial loss: 0.528777\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029164; batch adversarial loss: 0.347210\n",
      "epoch 120; iter: 0; batch classifier loss: 0.061350; batch adversarial loss: 0.426065\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040547; batch adversarial loss: 0.388778\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043512; batch adversarial loss: 0.443065\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067051; batch adversarial loss: 0.469868\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054656; batch adversarial loss: 0.526157\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040697; batch adversarial loss: 0.580422\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021967; batch adversarial loss: 0.463787\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023312; batch adversarial loss: 0.452046\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016121; batch adversarial loss: 0.448726\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037778; batch adversarial loss: 0.483973\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047592; batch adversarial loss: 0.418849\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029186; batch adversarial loss: 0.532311\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039146; batch adversarial loss: 0.314531\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032084; batch adversarial loss: 0.479668\n",
      "epoch 134; iter: 0; batch classifier loss: 0.008505; batch adversarial loss: 0.435490\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036897; batch adversarial loss: 0.501978\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030531; batch adversarial loss: 0.424234\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036872; batch adversarial loss: 0.552756\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021083; batch adversarial loss: 0.377660\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036226; batch adversarial loss: 0.398106\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024612; batch adversarial loss: 0.390058\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021146; batch adversarial loss: 0.479869\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028528; batch adversarial loss: 0.475621\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023547; batch adversarial loss: 0.369540\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012170; batch adversarial loss: 0.517052\n",
      "epoch 145; iter: 0; batch classifier loss: 0.066353; batch adversarial loss: 0.377873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.047171; batch adversarial loss: 0.414630\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037251; batch adversarial loss: 0.398440\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022856; batch adversarial loss: 0.424292\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031840; batch adversarial loss: 0.444129\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036178; batch adversarial loss: 0.387562\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026830; batch adversarial loss: 0.473898\n",
      "epoch 152; iter: 0; batch classifier loss: 0.056607; batch adversarial loss: 0.460941\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020322; batch adversarial loss: 0.433512\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024407; batch adversarial loss: 0.383291\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010439; batch adversarial loss: 0.530700\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043194; batch adversarial loss: 0.395400\n",
      "epoch 157; iter: 0; batch classifier loss: 0.007631; batch adversarial loss: 0.467063\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014188; batch adversarial loss: 0.446946\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014308; batch adversarial loss: 0.450320\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014670; batch adversarial loss: 0.443393\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043508; batch adversarial loss: 0.408834\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009315; batch adversarial loss: 0.460836\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027037; batch adversarial loss: 0.507285\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036759; batch adversarial loss: 0.381234\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012693; batch adversarial loss: 0.465357\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027870; batch adversarial loss: 0.461286\n",
      "epoch 167; iter: 0; batch classifier loss: 0.050370; batch adversarial loss: 0.497641\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032426; batch adversarial loss: 0.428475\n",
      "epoch 169; iter: 0; batch classifier loss: 0.004783; batch adversarial loss: 0.500430\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021184; batch adversarial loss: 0.456777\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017461; batch adversarial loss: 0.540458\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027986; batch adversarial loss: 0.410679\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034987; batch adversarial loss: 0.471937\n",
      "epoch 174; iter: 0; batch classifier loss: 0.056874; batch adversarial loss: 0.393737\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040054; batch adversarial loss: 0.397135\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033086; batch adversarial loss: 0.399193\n",
      "epoch 177; iter: 0; batch classifier loss: 0.035795; batch adversarial loss: 0.466628\n",
      "epoch 178; iter: 0; batch classifier loss: 0.059068; batch adversarial loss: 0.441935\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017990; batch adversarial loss: 0.432222\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032003; batch adversarial loss: 0.530218\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021005; batch adversarial loss: 0.458219\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028006; batch adversarial loss: 0.489018\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006920; batch adversarial loss: 0.464026\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025007; batch adversarial loss: 0.434049\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013397; batch adversarial loss: 0.465171\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015777; batch adversarial loss: 0.423616\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008980; batch adversarial loss: 0.389073\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030489; batch adversarial loss: 0.471900\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017699; batch adversarial loss: 0.499708\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023374; batch adversarial loss: 0.419596\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020313; batch adversarial loss: 0.402036\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023509; batch adversarial loss: 0.561921\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013200; batch adversarial loss: 0.449569\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018190; batch adversarial loss: 0.499693\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029476; batch adversarial loss: 0.427936\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029578; batch adversarial loss: 0.526458\n",
      "epoch 197; iter: 0; batch classifier loss: 0.002510; batch adversarial loss: 0.547432\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013645; batch adversarial loss: 0.411051\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010931; batch adversarial loss: 0.505924\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680296; batch adversarial loss: 0.697998\n",
      "epoch 1; iter: 0; batch classifier loss: 0.445442; batch adversarial loss: 0.657563\n",
      "epoch 2; iter: 0; batch classifier loss: 0.425640; batch adversarial loss: 0.614617\n",
      "epoch 3; iter: 0; batch classifier loss: 0.418987; batch adversarial loss: 0.587144\n",
      "epoch 4; iter: 0; batch classifier loss: 0.363333; batch adversarial loss: 0.565563\n",
      "epoch 5; iter: 0; batch classifier loss: 0.345266; batch adversarial loss: 0.557901\n",
      "epoch 6; iter: 0; batch classifier loss: 0.357161; batch adversarial loss: 0.523136\n",
      "epoch 7; iter: 0; batch classifier loss: 0.295614; batch adversarial loss: 0.545356\n",
      "epoch 8; iter: 0; batch classifier loss: 0.238506; batch adversarial loss: 0.506955\n",
      "epoch 9; iter: 0; batch classifier loss: 0.294591; batch adversarial loss: 0.498952\n",
      "epoch 10; iter: 0; batch classifier loss: 0.214923; batch adversarial loss: 0.525970\n",
      "epoch 11; iter: 0; batch classifier loss: 0.229656; batch adversarial loss: 0.493989\n",
      "epoch 12; iter: 0; batch classifier loss: 0.263927; batch adversarial loss: 0.516808\n",
      "epoch 13; iter: 0; batch classifier loss: 0.210548; batch adversarial loss: 0.475808\n",
      "epoch 14; iter: 0; batch classifier loss: 0.175989; batch adversarial loss: 0.479221\n",
      "epoch 15; iter: 0; batch classifier loss: 0.201736; batch adversarial loss: 0.439391\n",
      "epoch 16; iter: 0; batch classifier loss: 0.148396; batch adversarial loss: 0.523706\n",
      "epoch 17; iter: 0; batch classifier loss: 0.223453; batch adversarial loss: 0.472222\n",
      "epoch 18; iter: 0; batch classifier loss: 0.138196; batch adversarial loss: 0.512207\n",
      "epoch 19; iter: 0; batch classifier loss: 0.137985; batch adversarial loss: 0.543545\n",
      "epoch 20; iter: 0; batch classifier loss: 0.180004; batch adversarial loss: 0.478016\n",
      "epoch 21; iter: 0; batch classifier loss: 0.176171; batch adversarial loss: 0.504362\n",
      "epoch 22; iter: 0; batch classifier loss: 0.157401; batch adversarial loss: 0.532979\n",
      "epoch 23; iter: 0; batch classifier loss: 0.205891; batch adversarial loss: 0.572373\n",
      "epoch 24; iter: 0; batch classifier loss: 0.211505; batch adversarial loss: 0.595757\n",
      "epoch 25; iter: 0; batch classifier loss: 0.214064; batch adversarial loss: 0.533755\n",
      "epoch 26; iter: 0; batch classifier loss: 0.195133; batch adversarial loss: 0.494183\n",
      "epoch 27; iter: 0; batch classifier loss: 0.219088; batch adversarial loss: 0.565701\n",
      "epoch 28; iter: 0; batch classifier loss: 0.182089; batch adversarial loss: 0.457088\n",
      "epoch 29; iter: 0; batch classifier loss: 0.226581; batch adversarial loss: 0.535477\n",
      "epoch 30; iter: 0; batch classifier loss: 0.209279; batch adversarial loss: 0.494655\n",
      "epoch 31; iter: 0; batch classifier loss: 0.200280; batch adversarial loss: 0.398991\n",
      "epoch 32; iter: 0; batch classifier loss: 0.354109; batch adversarial loss: 0.482136\n",
      "epoch 33; iter: 0; batch classifier loss: 0.334715; batch adversarial loss: 0.475856\n",
      "epoch 34; iter: 0; batch classifier loss: 0.218979; batch adversarial loss: 0.500549\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130565; batch adversarial loss: 0.389113\n",
      "epoch 36; iter: 0; batch classifier loss: 0.111354; batch adversarial loss: 0.468183\n",
      "epoch 37; iter: 0; batch classifier loss: 0.089936; batch adversarial loss: 0.450643\n",
      "epoch 38; iter: 0; batch classifier loss: 0.091947; batch adversarial loss: 0.470758\n",
      "epoch 39; iter: 0; batch classifier loss: 0.084814; batch adversarial loss: 0.411988\n",
      "epoch 40; iter: 0; batch classifier loss: 0.101020; batch adversarial loss: 0.519556\n",
      "epoch 41; iter: 0; batch classifier loss: 0.107310; batch adversarial loss: 0.405686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.081018; batch adversarial loss: 0.468905\n",
      "epoch 43; iter: 0; batch classifier loss: 0.126166; batch adversarial loss: 0.447489\n",
      "epoch 44; iter: 0; batch classifier loss: 0.067791; batch adversarial loss: 0.318836\n",
      "epoch 45; iter: 0; batch classifier loss: 0.079262; batch adversarial loss: 0.437686\n",
      "epoch 46; iter: 0; batch classifier loss: 0.059658; batch adversarial loss: 0.493059\n",
      "epoch 47; iter: 0; batch classifier loss: 0.098329; batch adversarial loss: 0.483238\n",
      "epoch 48; iter: 0; batch classifier loss: 0.120259; batch adversarial loss: 0.382543\n",
      "epoch 49; iter: 0; batch classifier loss: 0.111237; batch adversarial loss: 0.450025\n",
      "epoch 50; iter: 0; batch classifier loss: 0.112107; batch adversarial loss: 0.445737\n",
      "epoch 51; iter: 0; batch classifier loss: 0.132743; batch adversarial loss: 0.463815\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082091; batch adversarial loss: 0.429195\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088653; batch adversarial loss: 0.393581\n",
      "epoch 54; iter: 0; batch classifier loss: 0.087600; batch adversarial loss: 0.501532\n",
      "epoch 55; iter: 0; batch classifier loss: 0.064881; batch adversarial loss: 0.481195\n",
      "epoch 56; iter: 0; batch classifier loss: 0.063951; batch adversarial loss: 0.397997\n",
      "epoch 57; iter: 0; batch classifier loss: 0.114995; batch adversarial loss: 0.419715\n",
      "epoch 58; iter: 0; batch classifier loss: 0.089095; batch adversarial loss: 0.369208\n",
      "epoch 59; iter: 0; batch classifier loss: 0.118419; batch adversarial loss: 0.478221\n",
      "epoch 60; iter: 0; batch classifier loss: 0.074992; batch adversarial loss: 0.402341\n",
      "epoch 61; iter: 0; batch classifier loss: 0.061193; batch adversarial loss: 0.477071\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078767; batch adversarial loss: 0.394470\n",
      "epoch 63; iter: 0; batch classifier loss: 0.065987; batch adversarial loss: 0.509105\n",
      "epoch 64; iter: 0; batch classifier loss: 0.051138; batch adversarial loss: 0.410246\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110885; batch adversarial loss: 0.424475\n",
      "epoch 66; iter: 0; batch classifier loss: 0.061535; batch adversarial loss: 0.457932\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096332; batch adversarial loss: 0.431044\n",
      "epoch 68; iter: 0; batch classifier loss: 0.075746; batch adversarial loss: 0.425778\n",
      "epoch 69; iter: 0; batch classifier loss: 0.055674; batch adversarial loss: 0.451987\n",
      "epoch 70; iter: 0; batch classifier loss: 0.061396; batch adversarial loss: 0.401734\n",
      "epoch 71; iter: 0; batch classifier loss: 0.060933; batch adversarial loss: 0.504227\n",
      "epoch 72; iter: 0; batch classifier loss: 0.052922; batch adversarial loss: 0.497789\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075520; batch adversarial loss: 0.372408\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082464; batch adversarial loss: 0.446211\n",
      "epoch 75; iter: 0; batch classifier loss: 0.038502; batch adversarial loss: 0.509331\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086455; batch adversarial loss: 0.457164\n",
      "epoch 77; iter: 0; batch classifier loss: 0.048623; batch adversarial loss: 0.402411\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054089; batch adversarial loss: 0.539814\n",
      "epoch 79; iter: 0; batch classifier loss: 0.043133; batch adversarial loss: 0.401605\n",
      "epoch 80; iter: 0; batch classifier loss: 0.123271; batch adversarial loss: 0.369566\n",
      "epoch 81; iter: 0; batch classifier loss: 0.051545; batch adversarial loss: 0.414738\n",
      "epoch 82; iter: 0; batch classifier loss: 0.070992; batch adversarial loss: 0.434785\n",
      "epoch 83; iter: 0; batch classifier loss: 0.040568; batch adversarial loss: 0.429561\n",
      "epoch 84; iter: 0; batch classifier loss: 0.086220; batch adversarial loss: 0.469165\n",
      "epoch 85; iter: 0; batch classifier loss: 0.071913; batch adversarial loss: 0.464759\n",
      "epoch 86; iter: 0; batch classifier loss: 0.044613; batch adversarial loss: 0.498609\n",
      "epoch 87; iter: 0; batch classifier loss: 0.095013; batch adversarial loss: 0.341430\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075039; batch adversarial loss: 0.426259\n",
      "epoch 89; iter: 0; batch classifier loss: 0.072722; batch adversarial loss: 0.472190\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068781; batch adversarial loss: 0.493825\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077455; batch adversarial loss: 0.528401\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040948; batch adversarial loss: 0.411918\n",
      "epoch 93; iter: 0; batch classifier loss: 0.033795; batch adversarial loss: 0.468624\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047618; batch adversarial loss: 0.374904\n",
      "epoch 95; iter: 0; batch classifier loss: 0.089686; batch adversarial loss: 0.401774\n",
      "epoch 96; iter: 0; batch classifier loss: 0.031600; batch adversarial loss: 0.440842\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042048; batch adversarial loss: 0.501077\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044819; batch adversarial loss: 0.416701\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056399; batch adversarial loss: 0.480588\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064440; batch adversarial loss: 0.457440\n",
      "epoch 101; iter: 0; batch classifier loss: 0.028709; batch adversarial loss: 0.454169\n",
      "epoch 102; iter: 0; batch classifier loss: 0.040912; batch adversarial loss: 0.388116\n",
      "epoch 103; iter: 0; batch classifier loss: 0.034678; batch adversarial loss: 0.522908\n",
      "epoch 104; iter: 0; batch classifier loss: 0.023237; batch adversarial loss: 0.458085\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038807; batch adversarial loss: 0.429556\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064931; batch adversarial loss: 0.527309\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058300; batch adversarial loss: 0.462565\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039415; batch adversarial loss: 0.445861\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044154; batch adversarial loss: 0.520261\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042243; batch adversarial loss: 0.538219\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048813; batch adversarial loss: 0.481331\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043971; batch adversarial loss: 0.408381\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058593; batch adversarial loss: 0.324852\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072855; batch adversarial loss: 0.417600\n",
      "epoch 115; iter: 0; batch classifier loss: 0.077448; batch adversarial loss: 0.448654\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062723; batch adversarial loss: 0.490895\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038587; batch adversarial loss: 0.487535\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029611; batch adversarial loss: 0.376245\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019320; batch adversarial loss: 0.475318\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064047; batch adversarial loss: 0.441814\n",
      "epoch 121; iter: 0; batch classifier loss: 0.063194; batch adversarial loss: 0.435210\n",
      "epoch 122; iter: 0; batch classifier loss: 0.068933; batch adversarial loss: 0.384461\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031001; batch adversarial loss: 0.430259\n",
      "epoch 124; iter: 0; batch classifier loss: 0.056061; batch adversarial loss: 0.432305\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045264; batch adversarial loss: 0.455702\n",
      "epoch 126; iter: 0; batch classifier loss: 0.062117; batch adversarial loss: 0.417319\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023207; batch adversarial loss: 0.442359\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058395; batch adversarial loss: 0.472070\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019197; batch adversarial loss: 0.425504\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040749; batch adversarial loss: 0.393206\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032233; batch adversarial loss: 0.366832\n",
      "epoch 132; iter: 0; batch classifier loss: 0.054402; batch adversarial loss: 0.450953\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040618; batch adversarial loss: 0.384140\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023684; batch adversarial loss: 0.579493\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043406; batch adversarial loss: 0.460867\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043808; batch adversarial loss: 0.458548\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023751; batch adversarial loss: 0.424460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.064257; batch adversarial loss: 0.544427\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023880; batch adversarial loss: 0.520791\n",
      "epoch 140; iter: 0; batch classifier loss: 0.054322; batch adversarial loss: 0.516477\n",
      "epoch 141; iter: 0; batch classifier loss: 0.054534; batch adversarial loss: 0.538803\n",
      "epoch 142; iter: 0; batch classifier loss: 0.010220; batch adversarial loss: 0.489278\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011326; batch adversarial loss: 0.468435\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045680; batch adversarial loss: 0.392037\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023387; batch adversarial loss: 0.442976\n",
      "epoch 146; iter: 0; batch classifier loss: 0.063623; batch adversarial loss: 0.413642\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013931; batch adversarial loss: 0.467414\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032968; batch adversarial loss: 0.424300\n",
      "epoch 149; iter: 0; batch classifier loss: 0.048676; batch adversarial loss: 0.456172\n",
      "epoch 150; iter: 0; batch classifier loss: 0.059309; batch adversarial loss: 0.435775\n",
      "epoch 151; iter: 0; batch classifier loss: 0.053321; batch adversarial loss: 0.377880\n",
      "epoch 152; iter: 0; batch classifier loss: 0.053179; batch adversarial loss: 0.441899\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014677; batch adversarial loss: 0.528420\n",
      "epoch 154; iter: 0; batch classifier loss: 0.075357; batch adversarial loss: 0.422129\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038896; batch adversarial loss: 0.549624\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013312; batch adversarial loss: 0.437898\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029832; batch adversarial loss: 0.460163\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042105; batch adversarial loss: 0.437337\n",
      "epoch 159; iter: 0; batch classifier loss: 0.063789; batch adversarial loss: 0.446714\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028314; batch adversarial loss: 0.512653\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021001; batch adversarial loss: 0.380229\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033903; batch adversarial loss: 0.424695\n",
      "epoch 163; iter: 0; batch classifier loss: 0.046104; batch adversarial loss: 0.462785\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022344; batch adversarial loss: 0.423831\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007700; batch adversarial loss: 0.416343\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018440; batch adversarial loss: 0.426770\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018125; batch adversarial loss: 0.429981\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033010; batch adversarial loss: 0.427108\n",
      "epoch 169; iter: 0; batch classifier loss: 0.047103; batch adversarial loss: 0.472078\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011506; batch adversarial loss: 0.496743\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019530; batch adversarial loss: 0.449978\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020366; batch adversarial loss: 0.503662\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032204; batch adversarial loss: 0.412226\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037740; batch adversarial loss: 0.478796\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010113; batch adversarial loss: 0.361793\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026231; batch adversarial loss: 0.470677\n",
      "epoch 177; iter: 0; batch classifier loss: 0.005052; batch adversarial loss: 0.438188\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014775; batch adversarial loss: 0.489043\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034389; batch adversarial loss: 0.342015\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024829; batch adversarial loss: 0.318955\n",
      "epoch 181; iter: 0; batch classifier loss: 0.067495; batch adversarial loss: 0.465835\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032950; batch adversarial loss: 0.440490\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018703; batch adversarial loss: 0.452637\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022332; batch adversarial loss: 0.357139\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014154; batch adversarial loss: 0.527028\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025329; batch adversarial loss: 0.409336\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007752; batch adversarial loss: 0.440023\n",
      "epoch 188; iter: 0; batch classifier loss: 0.063759; batch adversarial loss: 0.441597\n",
      "epoch 189; iter: 0; batch classifier loss: 0.053984; batch adversarial loss: 0.429267\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011825; batch adversarial loss: 0.500282\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009925; batch adversarial loss: 0.471056\n",
      "epoch 192; iter: 0; batch classifier loss: 0.055077; batch adversarial loss: 0.644141\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027723; batch adversarial loss: 0.455408\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006198; batch adversarial loss: 0.482427\n",
      "epoch 195; iter: 0; batch classifier loss: 0.056744; batch adversarial loss: 0.455191\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009769; batch adversarial loss: 0.389936\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014699; batch adversarial loss: 0.523301\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041559; batch adversarial loss: 0.448318\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026621; batch adversarial loss: 0.390829\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683051; batch adversarial loss: 0.612192\n",
      "epoch 1; iter: 0; batch classifier loss: 0.414750; batch adversarial loss: 0.645901\n",
      "epoch 2; iter: 0; batch classifier loss: 0.407031; batch adversarial loss: 0.606270\n",
      "epoch 3; iter: 0; batch classifier loss: 0.422839; batch adversarial loss: 0.607906\n",
      "epoch 4; iter: 0; batch classifier loss: 0.454398; batch adversarial loss: 0.609492\n",
      "epoch 5; iter: 0; batch classifier loss: 0.512589; batch adversarial loss: 0.617944\n",
      "epoch 6; iter: 0; batch classifier loss: 0.534626; batch adversarial loss: 0.598032\n",
      "epoch 7; iter: 0; batch classifier loss: 0.570347; batch adversarial loss: 0.595241\n",
      "epoch 8; iter: 0; batch classifier loss: 0.636509; batch adversarial loss: 0.556754\n",
      "epoch 9; iter: 0; batch classifier loss: 0.390644; batch adversarial loss: 0.564175\n",
      "epoch 10; iter: 0; batch classifier loss: 0.391285; batch adversarial loss: 0.488189\n",
      "epoch 11; iter: 0; batch classifier loss: 0.412434; batch adversarial loss: 0.498174\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329088; batch adversarial loss: 0.539151\n",
      "epoch 13; iter: 0; batch classifier loss: 0.284844; batch adversarial loss: 0.472819\n",
      "epoch 14; iter: 0; batch classifier loss: 0.336320; batch adversarial loss: 0.542256\n",
      "epoch 15; iter: 0; batch classifier loss: 0.316235; batch adversarial loss: 0.548435\n",
      "epoch 16; iter: 0; batch classifier loss: 0.312549; batch adversarial loss: 0.499058\n",
      "epoch 17; iter: 0; batch classifier loss: 0.287444; batch adversarial loss: 0.572252\n",
      "epoch 18; iter: 0; batch classifier loss: 0.278793; batch adversarial loss: 0.439669\n",
      "epoch 19; iter: 0; batch classifier loss: 0.224576; batch adversarial loss: 0.536321\n",
      "epoch 20; iter: 0; batch classifier loss: 0.288981; batch adversarial loss: 0.517528\n",
      "epoch 21; iter: 0; batch classifier loss: 0.298325; batch adversarial loss: 0.431803\n",
      "epoch 22; iter: 0; batch classifier loss: 0.386377; batch adversarial loss: 0.493212\n",
      "epoch 23; iter: 0; batch classifier loss: 0.216734; batch adversarial loss: 0.496297\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214482; batch adversarial loss: 0.501252\n",
      "epoch 25; iter: 0; batch classifier loss: 0.252058; batch adversarial loss: 0.486189\n",
      "epoch 26; iter: 0; batch classifier loss: 0.311100; batch adversarial loss: 0.493766\n",
      "epoch 27; iter: 0; batch classifier loss: 0.207133; batch adversarial loss: 0.451414\n",
      "epoch 28; iter: 0; batch classifier loss: 0.281104; batch adversarial loss: 0.463480\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197960; batch adversarial loss: 0.510912\n",
      "epoch 30; iter: 0; batch classifier loss: 0.241419; batch adversarial loss: 0.480274\n",
      "epoch 31; iter: 0; batch classifier loss: 0.206330; batch adversarial loss: 0.504509\n",
      "epoch 32; iter: 0; batch classifier loss: 0.208538; batch adversarial loss: 0.426104\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188937; batch adversarial loss: 0.493282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.174197; batch adversarial loss: 0.450371\n",
      "epoch 35; iter: 0; batch classifier loss: 0.238560; batch adversarial loss: 0.487460\n",
      "epoch 36; iter: 0; batch classifier loss: 0.220886; batch adversarial loss: 0.433357\n",
      "epoch 37; iter: 0; batch classifier loss: 0.204395; batch adversarial loss: 0.506130\n",
      "epoch 38; iter: 0; batch classifier loss: 0.169115; batch adversarial loss: 0.453428\n",
      "epoch 39; iter: 0; batch classifier loss: 0.189412; batch adversarial loss: 0.586483\n",
      "epoch 40; iter: 0; batch classifier loss: 0.179480; batch adversarial loss: 0.516495\n",
      "epoch 41; iter: 0; batch classifier loss: 0.207772; batch adversarial loss: 0.491329\n",
      "epoch 42; iter: 0; batch classifier loss: 0.221738; batch adversarial loss: 0.454859\n",
      "epoch 43; iter: 0; batch classifier loss: 0.249149; batch adversarial loss: 0.506682\n",
      "epoch 44; iter: 0; batch classifier loss: 0.163754; batch adversarial loss: 0.520381\n",
      "epoch 45; iter: 0; batch classifier loss: 0.156241; batch adversarial loss: 0.411783\n",
      "epoch 46; iter: 0; batch classifier loss: 0.175881; batch adversarial loss: 0.493909\n",
      "epoch 47; iter: 0; batch classifier loss: 0.236563; batch adversarial loss: 0.455588\n",
      "epoch 48; iter: 0; batch classifier loss: 0.205700; batch adversarial loss: 0.422255\n",
      "epoch 49; iter: 0; batch classifier loss: 0.250114; batch adversarial loss: 0.452779\n",
      "epoch 50; iter: 0; batch classifier loss: 0.210829; batch adversarial loss: 0.527381\n",
      "epoch 51; iter: 0; batch classifier loss: 0.189760; batch adversarial loss: 0.494130\n",
      "epoch 52; iter: 0; batch classifier loss: 0.282082; batch adversarial loss: 0.447813\n",
      "epoch 53; iter: 0; batch classifier loss: 0.182085; batch adversarial loss: 0.392399\n",
      "epoch 54; iter: 0; batch classifier loss: 0.230150; batch adversarial loss: 0.541463\n",
      "epoch 55; iter: 0; batch classifier loss: 0.261991; batch adversarial loss: 0.438904\n",
      "epoch 56; iter: 0; batch classifier loss: 0.172879; batch adversarial loss: 0.551825\n",
      "epoch 57; iter: 0; batch classifier loss: 0.210560; batch adversarial loss: 0.518956\n",
      "epoch 58; iter: 0; batch classifier loss: 0.163619; batch adversarial loss: 0.588379\n",
      "epoch 59; iter: 0; batch classifier loss: 0.184117; batch adversarial loss: 0.491485\n",
      "epoch 60; iter: 0; batch classifier loss: 0.182773; batch adversarial loss: 0.469551\n",
      "epoch 61; iter: 0; batch classifier loss: 0.203946; batch adversarial loss: 0.423125\n",
      "epoch 62; iter: 0; batch classifier loss: 0.231090; batch adversarial loss: 0.318420\n",
      "epoch 63; iter: 0; batch classifier loss: 0.213178; batch adversarial loss: 0.401557\n",
      "epoch 64; iter: 0; batch classifier loss: 0.187846; batch adversarial loss: 0.482265\n",
      "epoch 65; iter: 0; batch classifier loss: 0.250275; batch adversarial loss: 0.458590\n",
      "epoch 66; iter: 0; batch classifier loss: 0.227435; batch adversarial loss: 0.470671\n",
      "epoch 67; iter: 0; batch classifier loss: 0.213864; batch adversarial loss: 0.470966\n",
      "epoch 68; iter: 0; batch classifier loss: 0.187507; batch adversarial loss: 0.555221\n",
      "epoch 69; iter: 0; batch classifier loss: 0.152524; batch adversarial loss: 0.471161\n",
      "epoch 70; iter: 0; batch classifier loss: 0.219000; batch adversarial loss: 0.387913\n",
      "epoch 71; iter: 0; batch classifier loss: 0.198770; batch adversarial loss: 0.434129\n",
      "epoch 72; iter: 0; batch classifier loss: 0.247572; batch adversarial loss: 0.456826\n",
      "epoch 73; iter: 0; batch classifier loss: 0.247376; batch adversarial loss: 0.470829\n",
      "epoch 74; iter: 0; batch classifier loss: 0.167768; batch adversarial loss: 0.495033\n",
      "epoch 75; iter: 0; batch classifier loss: 0.198276; batch adversarial loss: 0.494437\n",
      "epoch 76; iter: 0; batch classifier loss: 0.193634; batch adversarial loss: 0.458518\n",
      "epoch 77; iter: 0; batch classifier loss: 0.196753; batch adversarial loss: 0.518606\n",
      "epoch 78; iter: 0; batch classifier loss: 0.213671; batch adversarial loss: 0.399125\n",
      "epoch 79; iter: 0; batch classifier loss: 0.227635; batch adversarial loss: 0.459520\n",
      "epoch 80; iter: 0; batch classifier loss: 0.217463; batch adversarial loss: 0.423305\n",
      "epoch 81; iter: 0; batch classifier loss: 0.318336; batch adversarial loss: 0.399328\n",
      "epoch 82; iter: 0; batch classifier loss: 0.099155; batch adversarial loss: 0.397475\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072454; batch adversarial loss: 0.370558\n",
      "epoch 84; iter: 0; batch classifier loss: 0.092781; batch adversarial loss: 0.416648\n",
      "epoch 85; iter: 0; batch classifier loss: 0.069483; batch adversarial loss: 0.452786\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068709; batch adversarial loss: 0.547227\n",
      "epoch 87; iter: 0; batch classifier loss: 0.041996; batch adversarial loss: 0.478572\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059749; batch adversarial loss: 0.472608\n",
      "epoch 89; iter: 0; batch classifier loss: 0.123058; batch adversarial loss: 0.422465\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061832; batch adversarial loss: 0.549172\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050639; batch adversarial loss: 0.533021\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058356; batch adversarial loss: 0.472755\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036042; batch adversarial loss: 0.535575\n",
      "epoch 94; iter: 0; batch classifier loss: 0.078608; batch adversarial loss: 0.472259\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063515; batch adversarial loss: 0.493679\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081657; batch adversarial loss: 0.503542\n",
      "epoch 97; iter: 0; batch classifier loss: 0.082469; batch adversarial loss: 0.449110\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074958; batch adversarial loss: 0.421404\n",
      "epoch 99; iter: 0; batch classifier loss: 0.089455; batch adversarial loss: 0.458597\n",
      "epoch 100; iter: 0; batch classifier loss: 0.081531; batch adversarial loss: 0.487092\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071668; batch adversarial loss: 0.563986\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049867; batch adversarial loss: 0.408714\n",
      "epoch 103; iter: 0; batch classifier loss: 0.083005; batch adversarial loss: 0.439529\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037520; batch adversarial loss: 0.398174\n",
      "epoch 105; iter: 0; batch classifier loss: 0.083089; batch adversarial loss: 0.550273\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043206; batch adversarial loss: 0.504373\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053866; batch adversarial loss: 0.383217\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049085; batch adversarial loss: 0.501596\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046383; batch adversarial loss: 0.444073\n",
      "epoch 110; iter: 0; batch classifier loss: 0.097760; batch adversarial loss: 0.381882\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045761; batch adversarial loss: 0.445561\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056198; batch adversarial loss: 0.542081\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055425; batch adversarial loss: 0.409162\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056954; batch adversarial loss: 0.400122\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056443; batch adversarial loss: 0.347780\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057147; batch adversarial loss: 0.447119\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053978; batch adversarial loss: 0.509242\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050411; batch adversarial loss: 0.458593\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055384; batch adversarial loss: 0.443862\n",
      "epoch 120; iter: 0; batch classifier loss: 0.069301; batch adversarial loss: 0.403848\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035245; batch adversarial loss: 0.395582\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052737; batch adversarial loss: 0.420954\n",
      "epoch 123; iter: 0; batch classifier loss: 0.059435; batch adversarial loss: 0.488575\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043452; batch adversarial loss: 0.360137\n",
      "epoch 125; iter: 0; batch classifier loss: 0.073963; batch adversarial loss: 0.465762\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047675; batch adversarial loss: 0.370018\n",
      "epoch 127; iter: 0; batch classifier loss: 0.061132; batch adversarial loss: 0.439582\n",
      "epoch 128; iter: 0; batch classifier loss: 0.074561; batch adversarial loss: 0.449317\n",
      "epoch 129; iter: 0; batch classifier loss: 0.067986; batch adversarial loss: 0.438565\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043829; batch adversarial loss: 0.523289\n",
      "epoch 131; iter: 0; batch classifier loss: 0.068309; batch adversarial loss: 0.464907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.063157; batch adversarial loss: 0.440405\n",
      "epoch 133; iter: 0; batch classifier loss: 0.083933; batch adversarial loss: 0.382738\n",
      "epoch 134; iter: 0; batch classifier loss: 0.064800; batch adversarial loss: 0.347794\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051312; batch adversarial loss: 0.380473\n",
      "epoch 136; iter: 0; batch classifier loss: 0.069802; batch adversarial loss: 0.413108\n",
      "epoch 137; iter: 0; batch classifier loss: 0.064686; batch adversarial loss: 0.469218\n",
      "epoch 138; iter: 0; batch classifier loss: 0.067086; batch adversarial loss: 0.464168\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043546; batch adversarial loss: 0.420452\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045785; batch adversarial loss: 0.396431\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038849; batch adversarial loss: 0.430379\n",
      "epoch 142; iter: 0; batch classifier loss: 0.057925; batch adversarial loss: 0.440487\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029727; batch adversarial loss: 0.498772\n",
      "epoch 144; iter: 0; batch classifier loss: 0.062446; batch adversarial loss: 0.467226\n",
      "epoch 145; iter: 0; batch classifier loss: 0.054182; batch adversarial loss: 0.448526\n",
      "epoch 146; iter: 0; batch classifier loss: 0.078390; batch adversarial loss: 0.435975\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018496; batch adversarial loss: 0.447060\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028021; batch adversarial loss: 0.430281\n",
      "epoch 149; iter: 0; batch classifier loss: 0.079173; batch adversarial loss: 0.489903\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041262; batch adversarial loss: 0.378276\n",
      "epoch 151; iter: 0; batch classifier loss: 0.065780; batch adversarial loss: 0.490639\n",
      "epoch 152; iter: 0; batch classifier loss: 0.046597; batch adversarial loss: 0.440686\n",
      "epoch 153; iter: 0; batch classifier loss: 0.062642; batch adversarial loss: 0.466789\n",
      "epoch 154; iter: 0; batch classifier loss: 0.061059; batch adversarial loss: 0.468100\n",
      "epoch 155; iter: 0; batch classifier loss: 0.054933; batch adversarial loss: 0.454608\n",
      "epoch 156; iter: 0; batch classifier loss: 0.076196; batch adversarial loss: 0.447825\n",
      "epoch 157; iter: 0; batch classifier loss: 0.043437; batch adversarial loss: 0.482648\n",
      "epoch 158; iter: 0; batch classifier loss: 0.061304; batch adversarial loss: 0.392613\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040984; batch adversarial loss: 0.449926\n",
      "epoch 160; iter: 0; batch classifier loss: 0.052164; batch adversarial loss: 0.510667\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040716; batch adversarial loss: 0.467746\n",
      "epoch 162; iter: 0; batch classifier loss: 0.057425; batch adversarial loss: 0.446773\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035354; batch adversarial loss: 0.369243\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029649; batch adversarial loss: 0.434670\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042040; batch adversarial loss: 0.455768\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034459; batch adversarial loss: 0.411591\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032941; batch adversarial loss: 0.430359\n",
      "epoch 168; iter: 0; batch classifier loss: 0.066260; batch adversarial loss: 0.452167\n",
      "epoch 169; iter: 0; batch classifier loss: 0.077567; batch adversarial loss: 0.551799\n",
      "epoch 170; iter: 0; batch classifier loss: 0.056060; batch adversarial loss: 0.396480\n",
      "epoch 171; iter: 0; batch classifier loss: 0.037167; batch adversarial loss: 0.489141\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027323; batch adversarial loss: 0.394294\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031352; batch adversarial loss: 0.369023\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035917; batch adversarial loss: 0.521805\n",
      "epoch 175; iter: 0; batch classifier loss: 0.048385; batch adversarial loss: 0.419469\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029290; batch adversarial loss: 0.500891\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036551; batch adversarial loss: 0.543332\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029812; batch adversarial loss: 0.548607\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037959; batch adversarial loss: 0.525647\n",
      "epoch 180; iter: 0; batch classifier loss: 0.042797; batch adversarial loss: 0.480527\n",
      "epoch 181; iter: 0; batch classifier loss: 0.052963; batch adversarial loss: 0.399651\n",
      "epoch 182; iter: 0; batch classifier loss: 0.046102; batch adversarial loss: 0.467450\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042954; batch adversarial loss: 0.425227\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021886; batch adversarial loss: 0.366704\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018149; batch adversarial loss: 0.509165\n",
      "epoch 186; iter: 0; batch classifier loss: 0.057703; batch adversarial loss: 0.414947\n",
      "epoch 187; iter: 0; batch classifier loss: 0.050618; batch adversarial loss: 0.451937\n",
      "epoch 188; iter: 0; batch classifier loss: 0.056204; batch adversarial loss: 0.405681\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016671; batch adversarial loss: 0.442833\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032114; batch adversarial loss: 0.460641\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032311; batch adversarial loss: 0.532413\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030431; batch adversarial loss: 0.391147\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020247; batch adversarial loss: 0.446659\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015657; batch adversarial loss: 0.377802\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016033; batch adversarial loss: 0.425385\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021940; batch adversarial loss: 0.521305\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027708; batch adversarial loss: 0.464442\n",
      "epoch 198; iter: 0; batch classifier loss: 0.067179; batch adversarial loss: 0.379986\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014052; batch adversarial loss: 0.365115\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682620; batch adversarial loss: 0.611156\n",
      "epoch 1; iter: 0; batch classifier loss: 0.381977; batch adversarial loss: 0.608600\n",
      "epoch 2; iter: 0; batch classifier loss: 0.444906; batch adversarial loss: 0.584289\n",
      "epoch 3; iter: 0; batch classifier loss: 0.384370; batch adversarial loss: 0.608371\n",
      "epoch 4; iter: 0; batch classifier loss: 0.426780; batch adversarial loss: 0.585541\n",
      "epoch 5; iter: 0; batch classifier loss: 0.302908; batch adversarial loss: 0.595332\n",
      "epoch 6; iter: 0; batch classifier loss: 0.469580; batch adversarial loss: 0.638214\n",
      "epoch 7; iter: 0; batch classifier loss: 0.585001; batch adversarial loss: 0.599958\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525218; batch adversarial loss: 0.551839\n",
      "epoch 9; iter: 0; batch classifier loss: 0.428452; batch adversarial loss: 0.564769\n",
      "epoch 10; iter: 0; batch classifier loss: 0.343420; batch adversarial loss: 0.558141\n",
      "epoch 11; iter: 0; batch classifier loss: 0.334995; batch adversarial loss: 0.539383\n",
      "epoch 12; iter: 0; batch classifier loss: 0.298282; batch adversarial loss: 0.509642\n",
      "epoch 13; iter: 0; batch classifier loss: 0.284241; batch adversarial loss: 0.483705\n",
      "epoch 14; iter: 0; batch classifier loss: 0.258662; batch adversarial loss: 0.515428\n",
      "epoch 15; iter: 0; batch classifier loss: 0.263858; batch adversarial loss: 0.548297\n",
      "epoch 16; iter: 0; batch classifier loss: 0.348238; batch adversarial loss: 0.468852\n",
      "epoch 17; iter: 0; batch classifier loss: 0.236332; batch adversarial loss: 0.472195\n",
      "epoch 18; iter: 0; batch classifier loss: 0.299236; batch adversarial loss: 0.489682\n",
      "epoch 19; iter: 0; batch classifier loss: 0.265342; batch adversarial loss: 0.492888\n",
      "epoch 20; iter: 0; batch classifier loss: 0.244808; batch adversarial loss: 0.447753\n",
      "epoch 21; iter: 0; batch classifier loss: 0.239743; batch adversarial loss: 0.557801\n",
      "epoch 22; iter: 0; batch classifier loss: 0.211746; batch adversarial loss: 0.430547\n",
      "epoch 23; iter: 0; batch classifier loss: 0.228110; batch adversarial loss: 0.498646\n",
      "epoch 24; iter: 0; batch classifier loss: 0.244340; batch adversarial loss: 0.444325\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172381; batch adversarial loss: 0.550802\n",
      "epoch 26; iter: 0; batch classifier loss: 0.226202; batch adversarial loss: 0.427909\n",
      "epoch 27; iter: 0; batch classifier loss: 0.168612; batch adversarial loss: 0.507312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.202059; batch adversarial loss: 0.433884\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210960; batch adversarial loss: 0.453676\n",
      "epoch 30; iter: 0; batch classifier loss: 0.147676; batch adversarial loss: 0.487438\n",
      "epoch 31; iter: 0; batch classifier loss: 0.130080; batch adversarial loss: 0.438418\n",
      "epoch 32; iter: 0; batch classifier loss: 0.183307; batch adversarial loss: 0.453667\n",
      "epoch 33; iter: 0; batch classifier loss: 0.165581; batch adversarial loss: 0.537524\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122773; batch adversarial loss: 0.473083\n",
      "epoch 35; iter: 0; batch classifier loss: 0.184482; batch adversarial loss: 0.527012\n",
      "epoch 36; iter: 0; batch classifier loss: 0.182393; batch adversarial loss: 0.412984\n",
      "epoch 37; iter: 0; batch classifier loss: 0.151527; batch adversarial loss: 0.429228\n",
      "epoch 38; iter: 0; batch classifier loss: 0.135131; batch adversarial loss: 0.463098\n",
      "epoch 39; iter: 0; batch classifier loss: 0.147114; batch adversarial loss: 0.388613\n",
      "epoch 40; iter: 0; batch classifier loss: 0.108992; batch adversarial loss: 0.424665\n",
      "epoch 41; iter: 0; batch classifier loss: 0.143423; batch adversarial loss: 0.474798\n",
      "epoch 42; iter: 0; batch classifier loss: 0.109561; batch adversarial loss: 0.410636\n",
      "epoch 43; iter: 0; batch classifier loss: 0.173219; batch adversarial loss: 0.425214\n",
      "epoch 44; iter: 0; batch classifier loss: 0.178806; batch adversarial loss: 0.412217\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102961; batch adversarial loss: 0.513393\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102960; batch adversarial loss: 0.563535\n",
      "epoch 47; iter: 0; batch classifier loss: 0.151300; batch adversarial loss: 0.583609\n",
      "epoch 48; iter: 0; batch classifier loss: 0.091081; batch adversarial loss: 0.462928\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099087; batch adversarial loss: 0.394962\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091094; batch adversarial loss: 0.479549\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083157; batch adversarial loss: 0.572183\n",
      "epoch 52; iter: 0; batch classifier loss: 0.087520; batch adversarial loss: 0.483266\n",
      "epoch 53; iter: 0; batch classifier loss: 0.107643; batch adversarial loss: 0.419799\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122594; batch adversarial loss: 0.494149\n",
      "epoch 55; iter: 0; batch classifier loss: 0.097225; batch adversarial loss: 0.456277\n",
      "epoch 56; iter: 0; batch classifier loss: 0.068350; batch adversarial loss: 0.450193\n",
      "epoch 57; iter: 0; batch classifier loss: 0.097196; batch adversarial loss: 0.442663\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080435; batch adversarial loss: 0.428555\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099266; batch adversarial loss: 0.476159\n",
      "epoch 60; iter: 0; batch classifier loss: 0.068000; batch adversarial loss: 0.459649\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080390; batch adversarial loss: 0.464001\n",
      "epoch 62; iter: 0; batch classifier loss: 0.079230; batch adversarial loss: 0.476101\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091458; batch adversarial loss: 0.389406\n",
      "epoch 64; iter: 0; batch classifier loss: 0.121586; batch adversarial loss: 0.430373\n",
      "epoch 65; iter: 0; batch classifier loss: 0.103901; batch adversarial loss: 0.483557\n",
      "epoch 66; iter: 0; batch classifier loss: 0.077112; batch adversarial loss: 0.445036\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094528; batch adversarial loss: 0.458376\n",
      "epoch 68; iter: 0; batch classifier loss: 0.085922; batch adversarial loss: 0.430481\n",
      "epoch 69; iter: 0; batch classifier loss: 0.053971; batch adversarial loss: 0.477995\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078223; batch adversarial loss: 0.454668\n",
      "epoch 71; iter: 0; batch classifier loss: 0.093276; batch adversarial loss: 0.402638\n",
      "epoch 72; iter: 0; batch classifier loss: 0.067281; batch adversarial loss: 0.423888\n",
      "epoch 73; iter: 0; batch classifier loss: 0.056380; batch adversarial loss: 0.465757\n",
      "epoch 74; iter: 0; batch classifier loss: 0.083702; batch adversarial loss: 0.437183\n",
      "epoch 75; iter: 0; batch classifier loss: 0.052666; batch adversarial loss: 0.387466\n",
      "epoch 76; iter: 0; batch classifier loss: 0.114367; batch adversarial loss: 0.397381\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055532; batch adversarial loss: 0.461972\n",
      "epoch 78; iter: 0; batch classifier loss: 0.130266; batch adversarial loss: 0.415603\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075640; batch adversarial loss: 0.431747\n",
      "epoch 80; iter: 0; batch classifier loss: 0.059211; batch adversarial loss: 0.501306\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083212; batch adversarial loss: 0.507962\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062153; batch adversarial loss: 0.513268\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079469; batch adversarial loss: 0.467737\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064971; batch adversarial loss: 0.424310\n",
      "epoch 85; iter: 0; batch classifier loss: 0.063277; batch adversarial loss: 0.420010\n",
      "epoch 86; iter: 0; batch classifier loss: 0.029591; batch adversarial loss: 0.535286\n",
      "epoch 87; iter: 0; batch classifier loss: 0.032941; batch adversarial loss: 0.461276\n",
      "epoch 88; iter: 0; batch classifier loss: 0.101719; batch adversarial loss: 0.512069\n",
      "epoch 89; iter: 0; batch classifier loss: 0.036555; batch adversarial loss: 0.423368\n",
      "epoch 90; iter: 0; batch classifier loss: 0.076999; batch adversarial loss: 0.472341\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064877; batch adversarial loss: 0.459335\n",
      "epoch 92; iter: 0; batch classifier loss: 0.045703; batch adversarial loss: 0.423025\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036035; batch adversarial loss: 0.378759\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039911; batch adversarial loss: 0.468019\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065860; batch adversarial loss: 0.440615\n",
      "epoch 96; iter: 0; batch classifier loss: 0.031435; batch adversarial loss: 0.562783\n",
      "epoch 97; iter: 0; batch classifier loss: 0.092206; batch adversarial loss: 0.455667\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053590; batch adversarial loss: 0.426639\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038755; batch adversarial loss: 0.457165\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047919; batch adversarial loss: 0.504563\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057649; batch adversarial loss: 0.467876\n",
      "epoch 102; iter: 0; batch classifier loss: 0.084229; batch adversarial loss: 0.476988\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037324; batch adversarial loss: 0.510966\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034429; batch adversarial loss: 0.536041\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051657; batch adversarial loss: 0.497526\n",
      "epoch 106; iter: 0; batch classifier loss: 0.072869; batch adversarial loss: 0.430592\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066232; batch adversarial loss: 0.461306\n",
      "epoch 108; iter: 0; batch classifier loss: 0.047485; batch adversarial loss: 0.441999\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044390; batch adversarial loss: 0.442759\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043859; batch adversarial loss: 0.368567\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043421; batch adversarial loss: 0.389872\n",
      "epoch 112; iter: 0; batch classifier loss: 0.020370; batch adversarial loss: 0.386700\n",
      "epoch 113; iter: 0; batch classifier loss: 0.019004; batch adversarial loss: 0.429327\n",
      "epoch 114; iter: 0; batch classifier loss: 0.013616; batch adversarial loss: 0.541336\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028026; batch adversarial loss: 0.517252\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036829; batch adversarial loss: 0.450947\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026470; batch adversarial loss: 0.421949\n",
      "epoch 118; iter: 0; batch classifier loss: 0.058109; batch adversarial loss: 0.510760\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025228; batch adversarial loss: 0.449561\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040037; batch adversarial loss: 0.453708\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046766; batch adversarial loss: 0.532702\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043845; batch adversarial loss: 0.441505\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023681; batch adversarial loss: 0.438847\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041629; batch adversarial loss: 0.421846\n",
      "epoch 125; iter: 0; batch classifier loss: 0.019592; batch adversarial loss: 0.384286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.046548; batch adversarial loss: 0.616538\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027477; batch adversarial loss: 0.428670\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024352; batch adversarial loss: 0.439175\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027739; batch adversarial loss: 0.565245\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031995; batch adversarial loss: 0.370474\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035343; batch adversarial loss: 0.455562\n",
      "epoch 132; iter: 0; batch classifier loss: 0.074899; batch adversarial loss: 0.450504\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023176; batch adversarial loss: 0.468497\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028388; batch adversarial loss: 0.510823\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033745; batch adversarial loss: 0.463490\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025185; batch adversarial loss: 0.495825\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012004; batch adversarial loss: 0.385410\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045545; batch adversarial loss: 0.492365\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039945; batch adversarial loss: 0.481355\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033022; batch adversarial loss: 0.494302\n",
      "epoch 141; iter: 0; batch classifier loss: 0.047692; batch adversarial loss: 0.462747\n",
      "epoch 142; iter: 0; batch classifier loss: 0.054574; batch adversarial loss: 0.578190\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031523; batch adversarial loss: 0.541537\n",
      "epoch 144; iter: 0; batch classifier loss: 0.011738; batch adversarial loss: 0.481580\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036350; batch adversarial loss: 0.472380\n",
      "epoch 146; iter: 0; batch classifier loss: 0.008031; batch adversarial loss: 0.511017\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017768; batch adversarial loss: 0.512473\n",
      "epoch 148; iter: 0; batch classifier loss: 0.072441; batch adversarial loss: 0.515200\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031919; batch adversarial loss: 0.460240\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029467; batch adversarial loss: 0.321259\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012487; batch adversarial loss: 0.453574\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021094; batch adversarial loss: 0.412759\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038018; batch adversarial loss: 0.467578\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044055; batch adversarial loss: 0.359591\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021671; batch adversarial loss: 0.573188\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012320; batch adversarial loss: 0.454669\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019416; batch adversarial loss: 0.479449\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017954; batch adversarial loss: 0.400767\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042370; batch adversarial loss: 0.521519\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026697; batch adversarial loss: 0.463933\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037427; batch adversarial loss: 0.478484\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011290; batch adversarial loss: 0.519321\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027119; batch adversarial loss: 0.370759\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037357; batch adversarial loss: 0.360384\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014466; batch adversarial loss: 0.477180\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021904; batch adversarial loss: 0.542481\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032107; batch adversarial loss: 0.398269\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021499; batch adversarial loss: 0.396664\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026962; batch adversarial loss: 0.511087\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040140; batch adversarial loss: 0.436991\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020123; batch adversarial loss: 0.426110\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017480; batch adversarial loss: 0.396860\n",
      "epoch 173; iter: 0; batch classifier loss: 0.065815; batch adversarial loss: 0.460147\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021283; batch adversarial loss: 0.418702\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016916; batch adversarial loss: 0.560121\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016862; batch adversarial loss: 0.505728\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011348; batch adversarial loss: 0.485610\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018404; batch adversarial loss: 0.489132\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020200; batch adversarial loss: 0.472295\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027908; batch adversarial loss: 0.446934\n",
      "epoch 181; iter: 0; batch classifier loss: 0.004596; batch adversarial loss: 0.487194\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009978; batch adversarial loss: 0.457462\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013357; batch adversarial loss: 0.396337\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008027; batch adversarial loss: 0.502545\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040858; batch adversarial loss: 0.403015\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016275; batch adversarial loss: 0.438278\n",
      "epoch 187; iter: 0; batch classifier loss: 0.043509; batch adversarial loss: 0.545816\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011351; batch adversarial loss: 0.494746\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011459; batch adversarial loss: 0.444954\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023731; batch adversarial loss: 0.371296\n",
      "epoch 191; iter: 0; batch classifier loss: 0.059025; batch adversarial loss: 0.446987\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035022; batch adversarial loss: 0.443973\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014488; batch adversarial loss: 0.349748\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041506; batch adversarial loss: 0.356362\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017388; batch adversarial loss: 0.438137\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017647; batch adversarial loss: 0.395541\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009827; batch adversarial loss: 0.410828\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019423; batch adversarial loss: 0.458115\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011628; batch adversarial loss: 0.411118\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718989; batch adversarial loss: 0.606108\n",
      "epoch 1; iter: 0; batch classifier loss: 0.497064; batch adversarial loss: 0.611597\n",
      "epoch 2; iter: 0; batch classifier loss: 0.424702; batch adversarial loss: 0.569375\n",
      "epoch 3; iter: 0; batch classifier loss: 0.417654; batch adversarial loss: 0.601153\n",
      "epoch 4; iter: 0; batch classifier loss: 0.354392; batch adversarial loss: 0.604038\n",
      "epoch 5; iter: 0; batch classifier loss: 0.417149; batch adversarial loss: 0.561114\n",
      "epoch 6; iter: 0; batch classifier loss: 0.462864; batch adversarial loss: 0.513800\n",
      "epoch 7; iter: 0; batch classifier loss: 0.375899; batch adversarial loss: 0.573917\n",
      "epoch 8; iter: 0; batch classifier loss: 0.374741; batch adversarial loss: 0.600387\n",
      "epoch 9; iter: 0; batch classifier loss: 0.379748; batch adversarial loss: 0.583724\n",
      "epoch 10; iter: 0; batch classifier loss: 0.399022; batch adversarial loss: 0.544280\n",
      "epoch 11; iter: 0; batch classifier loss: 0.351898; batch adversarial loss: 0.560795\n",
      "epoch 12; iter: 0; batch classifier loss: 0.374928; batch adversarial loss: 0.544140\n",
      "epoch 13; iter: 0; batch classifier loss: 0.421450; batch adversarial loss: 0.533765\n",
      "epoch 14; iter: 0; batch classifier loss: 0.366320; batch adversarial loss: 0.437124\n",
      "epoch 15; iter: 0; batch classifier loss: 0.282753; batch adversarial loss: 0.494802\n",
      "epoch 16; iter: 0; batch classifier loss: 0.264680; batch adversarial loss: 0.545578\n",
      "epoch 17; iter: 0; batch classifier loss: 0.367446; batch adversarial loss: 0.442132\n",
      "epoch 18; iter: 0; batch classifier loss: 0.266858; batch adversarial loss: 0.443466\n",
      "epoch 19; iter: 0; batch classifier loss: 0.273826; batch adversarial loss: 0.497502\n",
      "epoch 20; iter: 0; batch classifier loss: 0.348915; batch adversarial loss: 0.480073\n",
      "epoch 21; iter: 0; batch classifier loss: 0.286067; batch adversarial loss: 0.520490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.255780; batch adversarial loss: 0.493086\n",
      "epoch 23; iter: 0; batch classifier loss: 0.327856; batch adversarial loss: 0.459657\n",
      "epoch 24; iter: 0; batch classifier loss: 0.295675; batch adversarial loss: 0.526391\n",
      "epoch 25; iter: 0; batch classifier loss: 0.275725; batch adversarial loss: 0.559088\n",
      "epoch 26; iter: 0; batch classifier loss: 0.272762; batch adversarial loss: 0.497940\n",
      "epoch 27; iter: 0; batch classifier loss: 0.208344; batch adversarial loss: 0.467950\n",
      "epoch 28; iter: 0; batch classifier loss: 0.171960; batch adversarial loss: 0.463530\n",
      "epoch 29; iter: 0; batch classifier loss: 0.212592; batch adversarial loss: 0.430347\n",
      "epoch 30; iter: 0; batch classifier loss: 0.242729; batch adversarial loss: 0.446178\n",
      "epoch 31; iter: 0; batch classifier loss: 0.269123; batch adversarial loss: 0.454680\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238139; batch adversarial loss: 0.377601\n",
      "epoch 33; iter: 0; batch classifier loss: 0.224291; batch adversarial loss: 0.476755\n",
      "epoch 34; iter: 0; batch classifier loss: 0.260580; batch adversarial loss: 0.383583\n",
      "epoch 35; iter: 0; batch classifier loss: 0.269271; batch adversarial loss: 0.383934\n",
      "epoch 36; iter: 0; batch classifier loss: 0.269391; batch adversarial loss: 0.450689\n",
      "epoch 37; iter: 0; batch classifier loss: 0.268740; batch adversarial loss: 0.471203\n",
      "epoch 38; iter: 0; batch classifier loss: 0.219857; batch adversarial loss: 0.495683\n",
      "epoch 39; iter: 0; batch classifier loss: 0.265146; batch adversarial loss: 0.483316\n",
      "epoch 40; iter: 0; batch classifier loss: 0.314929; batch adversarial loss: 0.436702\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142964; batch adversarial loss: 0.436276\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146261; batch adversarial loss: 0.411633\n",
      "epoch 43; iter: 0; batch classifier loss: 0.129829; batch adversarial loss: 0.423398\n",
      "epoch 44; iter: 0; batch classifier loss: 0.113122; batch adversarial loss: 0.447828\n",
      "epoch 45; iter: 0; batch classifier loss: 0.191233; batch adversarial loss: 0.437220\n",
      "epoch 46; iter: 0; batch classifier loss: 0.176754; batch adversarial loss: 0.469190\n",
      "epoch 47; iter: 0; batch classifier loss: 0.178579; batch adversarial loss: 0.486456\n",
      "epoch 48; iter: 0; batch classifier loss: 0.230550; batch adversarial loss: 0.495786\n",
      "epoch 49; iter: 0; batch classifier loss: 0.178213; batch adversarial loss: 0.449053\n",
      "epoch 50; iter: 0; batch classifier loss: 0.168360; batch adversarial loss: 0.569805\n",
      "epoch 51; iter: 0; batch classifier loss: 0.211632; batch adversarial loss: 0.496069\n",
      "epoch 52; iter: 0; batch classifier loss: 0.127135; batch adversarial loss: 0.567315\n",
      "epoch 53; iter: 0; batch classifier loss: 0.181238; batch adversarial loss: 0.555781\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116927; batch adversarial loss: 0.422523\n",
      "epoch 55; iter: 0; batch classifier loss: 0.061373; batch adversarial loss: 0.410588\n",
      "epoch 56; iter: 0; batch classifier loss: 0.079065; batch adversarial loss: 0.518324\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072415; batch adversarial loss: 0.365928\n",
      "epoch 58; iter: 0; batch classifier loss: 0.092679; batch adversarial loss: 0.533357\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092275; batch adversarial loss: 0.394728\n",
      "epoch 60; iter: 0; batch classifier loss: 0.232043; batch adversarial loss: 0.486054\n",
      "epoch 61; iter: 0; batch classifier loss: 0.100417; batch adversarial loss: 0.509640\n",
      "epoch 62; iter: 0; batch classifier loss: 0.086790; batch adversarial loss: 0.394234\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116371; batch adversarial loss: 0.456585\n",
      "epoch 64; iter: 0; batch classifier loss: 0.074657; batch adversarial loss: 0.345143\n",
      "epoch 65; iter: 0; batch classifier loss: 0.100002; batch adversarial loss: 0.535109\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091255; batch adversarial loss: 0.414341\n",
      "epoch 67; iter: 0; batch classifier loss: 0.166016; batch adversarial loss: 0.470368\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072645; batch adversarial loss: 0.369337\n",
      "epoch 69; iter: 0; batch classifier loss: 0.093589; batch adversarial loss: 0.386055\n",
      "epoch 70; iter: 0; batch classifier loss: 0.080338; batch adversarial loss: 0.421322\n",
      "epoch 71; iter: 0; batch classifier loss: 0.135728; batch adversarial loss: 0.385327\n",
      "epoch 72; iter: 0; batch classifier loss: 0.173170; batch adversarial loss: 0.396994\n",
      "epoch 73; iter: 0; batch classifier loss: 0.071238; batch adversarial loss: 0.457546\n",
      "epoch 74; iter: 0; batch classifier loss: 0.123284; batch adversarial loss: 0.384117\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079007; batch adversarial loss: 0.482758\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076646; batch adversarial loss: 0.394637\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087981; batch adversarial loss: 0.455286\n",
      "epoch 78; iter: 0; batch classifier loss: 0.165321; batch adversarial loss: 0.369568\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076391; batch adversarial loss: 0.459163\n",
      "epoch 80; iter: 0; batch classifier loss: 0.151562; batch adversarial loss: 0.447578\n",
      "epoch 81; iter: 0; batch classifier loss: 0.123920; batch adversarial loss: 0.532786\n",
      "epoch 82; iter: 0; batch classifier loss: 0.151619; batch adversarial loss: 0.447604\n",
      "epoch 83; iter: 0; batch classifier loss: 0.096628; batch adversarial loss: 0.408159\n",
      "epoch 84; iter: 0; batch classifier loss: 0.071377; batch adversarial loss: 0.483198\n",
      "epoch 85; iter: 0; batch classifier loss: 0.079394; batch adversarial loss: 0.447092\n",
      "epoch 86; iter: 0; batch classifier loss: 0.102347; batch adversarial loss: 0.457371\n",
      "epoch 87; iter: 0; batch classifier loss: 0.094597; batch adversarial loss: 0.396026\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078380; batch adversarial loss: 0.495472\n",
      "epoch 89; iter: 0; batch classifier loss: 0.129183; batch adversarial loss: 0.410776\n",
      "epoch 90; iter: 0; batch classifier loss: 0.097959; batch adversarial loss: 0.503379\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077034; batch adversarial loss: 0.555545\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062053; batch adversarial loss: 0.592861\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069946; batch adversarial loss: 0.450948\n",
      "epoch 94; iter: 0; batch classifier loss: 0.126030; batch adversarial loss: 0.408980\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079488; batch adversarial loss: 0.438413\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075483; batch adversarial loss: 0.493218\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064296; batch adversarial loss: 0.503991\n",
      "epoch 98; iter: 0; batch classifier loss: 0.084715; batch adversarial loss: 0.507662\n",
      "epoch 99; iter: 0; batch classifier loss: 0.111836; batch adversarial loss: 0.553705\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045385; batch adversarial loss: 0.567766\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040674; batch adversarial loss: 0.546367\n",
      "epoch 102; iter: 0; batch classifier loss: 0.072200; batch adversarial loss: 0.406674\n",
      "epoch 103; iter: 0; batch classifier loss: 0.104371; batch adversarial loss: 0.408346\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047880; batch adversarial loss: 0.446272\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061570; batch adversarial loss: 0.417494\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071306; batch adversarial loss: 0.490126\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049460; batch adversarial loss: 0.571051\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039698; batch adversarial loss: 0.412022\n",
      "epoch 109; iter: 0; batch classifier loss: 0.079537; batch adversarial loss: 0.484681\n",
      "epoch 110; iter: 0; batch classifier loss: 0.062254; batch adversarial loss: 0.495735\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057486; batch adversarial loss: 0.568249\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063853; batch adversarial loss: 0.434283\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055947; batch adversarial loss: 0.503099\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039004; batch adversarial loss: 0.461275\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043198; batch adversarial loss: 0.485572\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035826; batch adversarial loss: 0.493238\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047060; batch adversarial loss: 0.377828\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040288; batch adversarial loss: 0.495679\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022002; batch adversarial loss: 0.479825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.035889; batch adversarial loss: 0.506859\n",
      "epoch 121; iter: 0; batch classifier loss: 0.019249; batch adversarial loss: 0.543881\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044774; batch adversarial loss: 0.345998\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039862; batch adversarial loss: 0.461370\n",
      "epoch 124; iter: 0; batch classifier loss: 0.053410; batch adversarial loss: 0.475680\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044329; batch adversarial loss: 0.362997\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019473; batch adversarial loss: 0.399995\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028327; batch adversarial loss: 0.405238\n",
      "epoch 128; iter: 0; batch classifier loss: 0.014989; batch adversarial loss: 0.431834\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042589; batch adversarial loss: 0.436331\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035234; batch adversarial loss: 0.450435\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043345; batch adversarial loss: 0.438885\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025019; batch adversarial loss: 0.524624\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037769; batch adversarial loss: 0.470012\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017941; batch adversarial loss: 0.431898\n",
      "epoch 135; iter: 0; batch classifier loss: 0.048757; batch adversarial loss: 0.510535\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021341; batch adversarial loss: 0.465114\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035461; batch adversarial loss: 0.517637\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037262; batch adversarial loss: 0.480448\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036733; batch adversarial loss: 0.427758\n",
      "epoch 140; iter: 0; batch classifier loss: 0.063370; batch adversarial loss: 0.345497\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027559; batch adversarial loss: 0.447934\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019867; batch adversarial loss: 0.440559\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018046; batch adversarial loss: 0.362611\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021353; batch adversarial loss: 0.469250\n",
      "epoch 145; iter: 0; batch classifier loss: 0.010406; batch adversarial loss: 0.368825\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026507; batch adversarial loss: 0.459851\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017319; batch adversarial loss: 0.469526\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029173; batch adversarial loss: 0.437534\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030833; batch adversarial loss: 0.411651\n",
      "epoch 150; iter: 0; batch classifier loss: 0.008980; batch adversarial loss: 0.462559\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011229; batch adversarial loss: 0.379646\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034277; batch adversarial loss: 0.425708\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026614; batch adversarial loss: 0.534779\n",
      "epoch 154; iter: 0; batch classifier loss: 0.057417; batch adversarial loss: 0.493781\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019462; batch adversarial loss: 0.536035\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029258; batch adversarial loss: 0.363415\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018223; batch adversarial loss: 0.515760\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030683; batch adversarial loss: 0.422208\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012292; batch adversarial loss: 0.471497\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029732; batch adversarial loss: 0.491519\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013295; batch adversarial loss: 0.381364\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009490; batch adversarial loss: 0.449807\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023287; batch adversarial loss: 0.406434\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026031; batch adversarial loss: 0.445724\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022911; batch adversarial loss: 0.447974\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009453; batch adversarial loss: 0.417256\n",
      "epoch 167; iter: 0; batch classifier loss: 0.037493; batch adversarial loss: 0.423411\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018953; batch adversarial loss: 0.490945\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014307; batch adversarial loss: 0.434530\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022836; batch adversarial loss: 0.462102\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022900; batch adversarial loss: 0.494713\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013158; batch adversarial loss: 0.380001\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022924; batch adversarial loss: 0.574202\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026840; batch adversarial loss: 0.455846\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014940; batch adversarial loss: 0.411931\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018405; batch adversarial loss: 0.410404\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021667; batch adversarial loss: 0.467889\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012192; batch adversarial loss: 0.479480\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012919; batch adversarial loss: 0.409607\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034306; batch adversarial loss: 0.438248\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008197; batch adversarial loss: 0.401241\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015947; batch adversarial loss: 0.432642\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022704; batch adversarial loss: 0.536046\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038390; batch adversarial loss: 0.367501\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032477; batch adversarial loss: 0.592227\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026510; batch adversarial loss: 0.387033\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015765; batch adversarial loss: 0.426249\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014542; batch adversarial loss: 0.540490\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027555; batch adversarial loss: 0.505514\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032299; batch adversarial loss: 0.511248\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030311; batch adversarial loss: 0.446861\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021198; batch adversarial loss: 0.398851\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030487; batch adversarial loss: 0.397003\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020666; batch adversarial loss: 0.494336\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031518; batch adversarial loss: 0.456258\n",
      "epoch 196; iter: 0; batch classifier loss: 0.053680; batch adversarial loss: 0.429278\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009791; batch adversarial loss: 0.508851\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007200; batch adversarial loss: 0.514275\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014862; batch adversarial loss: 0.361645\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708741; batch adversarial loss: 0.519793\n",
      "epoch 1; iter: 0; batch classifier loss: 0.399628; batch adversarial loss: 0.620737\n",
      "epoch 2; iter: 0; batch classifier loss: 0.455515; batch adversarial loss: 0.583958\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339155; batch adversarial loss: 0.568766\n",
      "epoch 4; iter: 0; batch classifier loss: 0.440323; batch adversarial loss: 0.635812\n",
      "epoch 5; iter: 0; batch classifier loss: 0.375984; batch adversarial loss: 0.571526\n",
      "epoch 6; iter: 0; batch classifier loss: 0.290502; batch adversarial loss: 0.620576\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300415; batch adversarial loss: 0.586427\n",
      "epoch 8; iter: 0; batch classifier loss: 0.337631; batch adversarial loss: 0.513407\n",
      "epoch 9; iter: 0; batch classifier loss: 0.308299; batch adversarial loss: 0.562743\n",
      "epoch 10; iter: 0; batch classifier loss: 0.310871; batch adversarial loss: 0.539409\n",
      "epoch 11; iter: 0; batch classifier loss: 0.316265; batch adversarial loss: 0.557094\n",
      "epoch 12; iter: 0; batch classifier loss: 0.322010; batch adversarial loss: 0.596993\n",
      "epoch 13; iter: 0; batch classifier loss: 0.401781; batch adversarial loss: 0.504057\n",
      "epoch 14; iter: 0; batch classifier loss: 0.462588; batch adversarial loss: 0.569396\n",
      "epoch 15; iter: 0; batch classifier loss: 0.572445; batch adversarial loss: 0.525851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.522551; batch adversarial loss: 0.515640\n",
      "epoch 17; iter: 0; batch classifier loss: 0.361753; batch adversarial loss: 0.436148\n",
      "epoch 18; iter: 0; batch classifier loss: 0.326808; batch adversarial loss: 0.496847\n",
      "epoch 19; iter: 0; batch classifier loss: 0.244353; batch adversarial loss: 0.476591\n",
      "epoch 20; iter: 0; batch classifier loss: 0.224460; batch adversarial loss: 0.438854\n",
      "epoch 21; iter: 0; batch classifier loss: 0.180637; batch adversarial loss: 0.473283\n",
      "epoch 22; iter: 0; batch classifier loss: 0.252572; batch adversarial loss: 0.519473\n",
      "epoch 23; iter: 0; batch classifier loss: 0.210766; batch adversarial loss: 0.386878\n",
      "epoch 24; iter: 0; batch classifier loss: 0.157330; batch adversarial loss: 0.456268\n",
      "epoch 25; iter: 0; batch classifier loss: 0.157818; batch adversarial loss: 0.417841\n",
      "epoch 26; iter: 0; batch classifier loss: 0.135478; batch adversarial loss: 0.455065\n",
      "epoch 27; iter: 0; batch classifier loss: 0.111040; batch adversarial loss: 0.434451\n",
      "epoch 28; iter: 0; batch classifier loss: 0.202008; batch adversarial loss: 0.413423\n",
      "epoch 29; iter: 0; batch classifier loss: 0.105384; batch adversarial loss: 0.434708\n",
      "epoch 30; iter: 0; batch classifier loss: 0.115131; batch adversarial loss: 0.502780\n",
      "epoch 31; iter: 0; batch classifier loss: 0.168792; batch adversarial loss: 0.453681\n",
      "epoch 32; iter: 0; batch classifier loss: 0.151326; batch adversarial loss: 0.444490\n",
      "epoch 33; iter: 0; batch classifier loss: 0.228230; batch adversarial loss: 0.515842\n",
      "epoch 34; iter: 0; batch classifier loss: 0.110149; batch adversarial loss: 0.486210\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130017; batch adversarial loss: 0.448383\n",
      "epoch 36; iter: 0; batch classifier loss: 0.153004; batch adversarial loss: 0.495646\n",
      "epoch 37; iter: 0; batch classifier loss: 0.119278; batch adversarial loss: 0.521714\n",
      "epoch 38; iter: 0; batch classifier loss: 0.111139; batch adversarial loss: 0.546298\n",
      "epoch 39; iter: 0; batch classifier loss: 0.137241; batch adversarial loss: 0.413354\n",
      "epoch 40; iter: 0; batch classifier loss: 0.126300; batch adversarial loss: 0.345793\n",
      "epoch 41; iter: 0; batch classifier loss: 0.160948; batch adversarial loss: 0.428284\n",
      "epoch 42; iter: 0; batch classifier loss: 0.093153; batch adversarial loss: 0.438497\n",
      "epoch 43; iter: 0; batch classifier loss: 0.160334; batch adversarial loss: 0.449272\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127259; batch adversarial loss: 0.510817\n",
      "epoch 45; iter: 0; batch classifier loss: 0.123118; batch adversarial loss: 0.417209\n",
      "epoch 46; iter: 0; batch classifier loss: 0.098299; batch adversarial loss: 0.435291\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108660; batch adversarial loss: 0.437142\n",
      "epoch 48; iter: 0; batch classifier loss: 0.084964; batch adversarial loss: 0.404965\n",
      "epoch 49; iter: 0; batch classifier loss: 0.078879; batch adversarial loss: 0.507377\n",
      "epoch 50; iter: 0; batch classifier loss: 0.123601; batch adversarial loss: 0.477425\n",
      "epoch 51; iter: 0; batch classifier loss: 0.076919; batch adversarial loss: 0.445541\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112612; batch adversarial loss: 0.405007\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084210; batch adversarial loss: 0.561697\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096993; batch adversarial loss: 0.395131\n",
      "epoch 55; iter: 0; batch classifier loss: 0.080855; batch adversarial loss: 0.437736\n",
      "epoch 56; iter: 0; batch classifier loss: 0.182657; batch adversarial loss: 0.508942\n",
      "epoch 57; iter: 0; batch classifier loss: 0.172270; batch adversarial loss: 0.519908\n",
      "epoch 58; iter: 0; batch classifier loss: 0.140732; batch adversarial loss: 0.518369\n",
      "epoch 59; iter: 0; batch classifier loss: 0.101426; batch adversarial loss: 0.456614\n",
      "epoch 60; iter: 0; batch classifier loss: 0.078472; batch adversarial loss: 0.491896\n",
      "epoch 61; iter: 0; batch classifier loss: 0.153263; batch adversarial loss: 0.462752\n",
      "epoch 62; iter: 0; batch classifier loss: 0.115947; batch adversarial loss: 0.466816\n",
      "epoch 63; iter: 0; batch classifier loss: 0.138299; batch adversarial loss: 0.529837\n",
      "epoch 64; iter: 0; batch classifier loss: 0.128051; batch adversarial loss: 0.514782\n",
      "epoch 65; iter: 0; batch classifier loss: 0.130847; batch adversarial loss: 0.346378\n",
      "epoch 66; iter: 0; batch classifier loss: 0.123204; batch adversarial loss: 0.427168\n",
      "epoch 67; iter: 0; batch classifier loss: 0.145038; batch adversarial loss: 0.492873\n",
      "epoch 68; iter: 0; batch classifier loss: 0.167266; batch adversarial loss: 0.376315\n",
      "epoch 69; iter: 0; batch classifier loss: 0.092171; batch adversarial loss: 0.516313\n",
      "epoch 70; iter: 0; batch classifier loss: 0.149661; batch adversarial loss: 0.360424\n",
      "epoch 71; iter: 0; batch classifier loss: 0.159368; batch adversarial loss: 0.399477\n",
      "epoch 72; iter: 0; batch classifier loss: 0.150679; batch adversarial loss: 0.458073\n",
      "epoch 73; iter: 0; batch classifier loss: 0.091777; batch adversarial loss: 0.452981\n",
      "epoch 74; iter: 0; batch classifier loss: 0.086811; batch adversarial loss: 0.432373\n",
      "epoch 75; iter: 0; batch classifier loss: 0.119580; batch adversarial loss: 0.496189\n",
      "epoch 76; iter: 0; batch classifier loss: 0.122457; batch adversarial loss: 0.501935\n",
      "epoch 77; iter: 0; batch classifier loss: 0.092853; batch adversarial loss: 0.514288\n",
      "epoch 78; iter: 0; batch classifier loss: 0.137783; batch adversarial loss: 0.474878\n",
      "epoch 79; iter: 0; batch classifier loss: 0.136873; batch adversarial loss: 0.429063\n",
      "epoch 80; iter: 0; batch classifier loss: 0.093268; batch adversarial loss: 0.568925\n",
      "epoch 81; iter: 0; batch classifier loss: 0.113030; batch adversarial loss: 0.458090\n",
      "epoch 82; iter: 0; batch classifier loss: 0.137383; batch adversarial loss: 0.486713\n",
      "epoch 83; iter: 0; batch classifier loss: 0.097083; batch adversarial loss: 0.472830\n",
      "epoch 84; iter: 0; batch classifier loss: 0.072619; batch adversarial loss: 0.445624\n",
      "epoch 85; iter: 0; batch classifier loss: 0.142833; batch adversarial loss: 0.594635\n",
      "epoch 86; iter: 0; batch classifier loss: 0.114776; batch adversarial loss: 0.449627\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079150; batch adversarial loss: 0.421395\n",
      "epoch 88; iter: 0; batch classifier loss: 0.077179; batch adversarial loss: 0.485896\n",
      "epoch 89; iter: 0; batch classifier loss: 0.085652; batch adversarial loss: 0.533034\n",
      "epoch 90; iter: 0; batch classifier loss: 0.095351; batch adversarial loss: 0.480164\n",
      "epoch 91; iter: 0; batch classifier loss: 0.120917; batch adversarial loss: 0.348471\n",
      "epoch 92; iter: 0; batch classifier loss: 0.168703; batch adversarial loss: 0.361251\n",
      "epoch 93; iter: 0; batch classifier loss: 0.085969; batch adversarial loss: 0.476959\n",
      "epoch 94; iter: 0; batch classifier loss: 0.074384; batch adversarial loss: 0.525002\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083958; batch adversarial loss: 0.438643\n",
      "epoch 96; iter: 0; batch classifier loss: 0.100331; batch adversarial loss: 0.431628\n",
      "epoch 97; iter: 0; batch classifier loss: 0.082832; batch adversarial loss: 0.451595\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063229; batch adversarial loss: 0.490873\n",
      "epoch 99; iter: 0; batch classifier loss: 0.083015; batch adversarial loss: 0.397168\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053667; batch adversarial loss: 0.452313\n",
      "epoch 101; iter: 0; batch classifier loss: 0.064789; batch adversarial loss: 0.516715\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078283; batch adversarial loss: 0.438071\n",
      "epoch 103; iter: 0; batch classifier loss: 0.065865; batch adversarial loss: 0.446910\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083778; batch adversarial loss: 0.452636\n",
      "epoch 105; iter: 0; batch classifier loss: 0.100587; batch adversarial loss: 0.387610\n",
      "epoch 106; iter: 0; batch classifier loss: 0.082314; batch adversarial loss: 0.515910\n",
      "epoch 107; iter: 0; batch classifier loss: 0.102314; batch adversarial loss: 0.393909\n",
      "epoch 108; iter: 0; batch classifier loss: 0.092808; batch adversarial loss: 0.476147\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070682; batch adversarial loss: 0.404730\n",
      "epoch 110; iter: 0; batch classifier loss: 0.075168; batch adversarial loss: 0.413375\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052130; batch adversarial loss: 0.545333\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033501; batch adversarial loss: 0.382448\n",
      "epoch 113; iter: 0; batch classifier loss: 0.068995; batch adversarial loss: 0.435664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.026273; batch adversarial loss: 0.431649\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040761; batch adversarial loss: 0.446411\n",
      "epoch 116; iter: 0; batch classifier loss: 0.087433; batch adversarial loss: 0.433166\n",
      "epoch 117; iter: 0; batch classifier loss: 0.093498; batch adversarial loss: 0.371002\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030197; batch adversarial loss: 0.530108\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051190; batch adversarial loss: 0.467058\n",
      "epoch 120; iter: 0; batch classifier loss: 0.067024; batch adversarial loss: 0.369966\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029127; batch adversarial loss: 0.475000\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035280; batch adversarial loss: 0.446004\n",
      "epoch 123; iter: 0; batch classifier loss: 0.088260; batch adversarial loss: 0.500900\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021634; batch adversarial loss: 0.419211\n",
      "epoch 125; iter: 0; batch classifier loss: 0.016591; batch adversarial loss: 0.574080\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028407; batch adversarial loss: 0.504274\n",
      "epoch 127; iter: 0; batch classifier loss: 0.064142; batch adversarial loss: 0.425215\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049631; batch adversarial loss: 0.493620\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028549; batch adversarial loss: 0.443042\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034908; batch adversarial loss: 0.456974\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025135; batch adversarial loss: 0.389624\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041846; batch adversarial loss: 0.498421\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035527; batch adversarial loss: 0.336941\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057017; batch adversarial loss: 0.471121\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051052; batch adversarial loss: 0.506002\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022355; batch adversarial loss: 0.429214\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042272; batch adversarial loss: 0.505097\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018988; batch adversarial loss: 0.550949\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043378; batch adversarial loss: 0.452285\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046775; batch adversarial loss: 0.452746\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024383; batch adversarial loss: 0.530285\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041250; batch adversarial loss: 0.395321\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031492; batch adversarial loss: 0.520389\n",
      "epoch 144; iter: 0; batch classifier loss: 0.058777; batch adversarial loss: 0.433147\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038418; batch adversarial loss: 0.523074\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034655; batch adversarial loss: 0.434108\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024955; batch adversarial loss: 0.433420\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031621; batch adversarial loss: 0.462566\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040243; batch adversarial loss: 0.513242\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023882; batch adversarial loss: 0.499784\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021818; batch adversarial loss: 0.412549\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031459; batch adversarial loss: 0.558194\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026407; batch adversarial loss: 0.463714\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012684; batch adversarial loss: 0.419769\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035776; batch adversarial loss: 0.439003\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041363; batch adversarial loss: 0.474785\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029681; batch adversarial loss: 0.530541\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040040; batch adversarial loss: 0.396741\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014015; batch adversarial loss: 0.514666\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017803; batch adversarial loss: 0.446685\n",
      "epoch 161; iter: 0; batch classifier loss: 0.055769; batch adversarial loss: 0.457141\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020114; batch adversarial loss: 0.514587\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019529; batch adversarial loss: 0.371914\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018408; batch adversarial loss: 0.442976\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023289; batch adversarial loss: 0.444296\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026221; batch adversarial loss: 0.497657\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022067; batch adversarial loss: 0.483713\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019301; batch adversarial loss: 0.391923\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012609; batch adversarial loss: 0.485913\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026637; batch adversarial loss: 0.472686\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026827; batch adversarial loss: 0.374486\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024899; batch adversarial loss: 0.473106\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018657; batch adversarial loss: 0.513604\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031837; batch adversarial loss: 0.476677\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021158; batch adversarial loss: 0.436988\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018334; batch adversarial loss: 0.370124\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025918; batch adversarial loss: 0.430842\n",
      "epoch 178; iter: 0; batch classifier loss: 0.063749; batch adversarial loss: 0.474543\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008868; batch adversarial loss: 0.491509\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027474; batch adversarial loss: 0.470671\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023786; batch adversarial loss: 0.409481\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010569; batch adversarial loss: 0.453537\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017894; batch adversarial loss: 0.432011\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021911; batch adversarial loss: 0.393513\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026447; batch adversarial loss: 0.493655\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024640; batch adversarial loss: 0.467296\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034592; batch adversarial loss: 0.405469\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022631; batch adversarial loss: 0.398296\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030057; batch adversarial loss: 0.434674\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025139; batch adversarial loss: 0.460046\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034362; batch adversarial loss: 0.448533\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017968; batch adversarial loss: 0.482709\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014528; batch adversarial loss: 0.484299\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008712; batch adversarial loss: 0.544911\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026757; batch adversarial loss: 0.367254\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013068; batch adversarial loss: 0.398345\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029691; batch adversarial loss: 0.507869\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031635; batch adversarial loss: 0.472936\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015742; batch adversarial loss: 0.451155\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686971; batch adversarial loss: 0.953740\n",
      "epoch 1; iter: 0; batch classifier loss: 0.878841; batch adversarial loss: 1.203398\n",
      "epoch 2; iter: 0; batch classifier loss: 0.910270; batch adversarial loss: 1.094068\n",
      "epoch 3; iter: 0; batch classifier loss: 1.057616; batch adversarial loss: 1.079900\n",
      "epoch 4; iter: 0; batch classifier loss: 0.936018; batch adversarial loss: 0.902635\n",
      "epoch 5; iter: 0; batch classifier loss: 0.835316; batch adversarial loss: 0.791538\n",
      "epoch 6; iter: 0; batch classifier loss: 0.951002; batch adversarial loss: 0.805763\n",
      "epoch 7; iter: 0; batch classifier loss: 0.741367; batch adversarial loss: 0.695402\n",
      "epoch 8; iter: 0; batch classifier loss: 0.612754; batch adversarial loss: 0.632986\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563708; batch adversarial loss: 0.607559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.552863; batch adversarial loss: 0.584300\n",
      "epoch 11; iter: 0; batch classifier loss: 0.373735; batch adversarial loss: 0.566579\n",
      "epoch 12; iter: 0; batch classifier loss: 0.346762; batch adversarial loss: 0.473601\n",
      "epoch 13; iter: 0; batch classifier loss: 0.287692; batch adversarial loss: 0.477334\n",
      "epoch 14; iter: 0; batch classifier loss: 0.309708; batch adversarial loss: 0.515738\n",
      "epoch 15; iter: 0; batch classifier loss: 0.268349; batch adversarial loss: 0.416057\n",
      "epoch 16; iter: 0; batch classifier loss: 0.215077; batch adversarial loss: 0.503120\n",
      "epoch 17; iter: 0; batch classifier loss: 0.243786; batch adversarial loss: 0.494682\n",
      "epoch 18; iter: 0; batch classifier loss: 0.227452; batch adversarial loss: 0.479341\n",
      "epoch 19; iter: 0; batch classifier loss: 0.254664; batch adversarial loss: 0.485315\n",
      "epoch 20; iter: 0; batch classifier loss: 0.250900; batch adversarial loss: 0.544157\n",
      "epoch 21; iter: 0; batch classifier loss: 0.226682; batch adversarial loss: 0.523484\n",
      "epoch 22; iter: 0; batch classifier loss: 0.162358; batch adversarial loss: 0.490023\n",
      "epoch 23; iter: 0; batch classifier loss: 0.192009; batch adversarial loss: 0.523324\n",
      "epoch 24; iter: 0; batch classifier loss: 0.174002; batch adversarial loss: 0.468633\n",
      "epoch 25; iter: 0; batch classifier loss: 0.192172; batch adversarial loss: 0.453518\n",
      "epoch 26; iter: 0; batch classifier loss: 0.245177; batch adversarial loss: 0.431280\n",
      "epoch 27; iter: 0; batch classifier loss: 0.135058; batch adversarial loss: 0.438665\n",
      "epoch 28; iter: 0; batch classifier loss: 0.186108; batch adversarial loss: 0.450814\n",
      "epoch 29; iter: 0; batch classifier loss: 0.152135; batch adversarial loss: 0.490977\n",
      "epoch 30; iter: 0; batch classifier loss: 0.210673; batch adversarial loss: 0.412514\n",
      "epoch 31; iter: 0; batch classifier loss: 0.184035; batch adversarial loss: 0.418774\n",
      "epoch 32; iter: 0; batch classifier loss: 0.132625; batch adversarial loss: 0.503169\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123072; batch adversarial loss: 0.406910\n",
      "epoch 34; iter: 0; batch classifier loss: 0.134702; batch adversarial loss: 0.523737\n",
      "epoch 35; iter: 0; batch classifier loss: 0.155015; batch adversarial loss: 0.481529\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128135; batch adversarial loss: 0.456853\n",
      "epoch 37; iter: 0; batch classifier loss: 0.091409; batch adversarial loss: 0.499302\n",
      "epoch 38; iter: 0; batch classifier loss: 0.119217; batch adversarial loss: 0.449552\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126557; batch adversarial loss: 0.475491\n",
      "epoch 40; iter: 0; batch classifier loss: 0.111856; batch adversarial loss: 0.427391\n",
      "epoch 41; iter: 0; batch classifier loss: 0.148000; batch adversarial loss: 0.445140\n",
      "epoch 42; iter: 0; batch classifier loss: 0.144438; batch adversarial loss: 0.405892\n",
      "epoch 43; iter: 0; batch classifier loss: 0.145613; batch adversarial loss: 0.434101\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098691; batch adversarial loss: 0.470116\n",
      "epoch 45; iter: 0; batch classifier loss: 0.125296; batch adversarial loss: 0.522697\n",
      "epoch 46; iter: 0; batch classifier loss: 0.123694; batch adversarial loss: 0.524497\n",
      "epoch 47; iter: 0; batch classifier loss: 0.135791; batch adversarial loss: 0.472998\n",
      "epoch 48; iter: 0; batch classifier loss: 0.111123; batch adversarial loss: 0.498266\n",
      "epoch 49; iter: 0; batch classifier loss: 0.134776; batch adversarial loss: 0.382674\n",
      "epoch 50; iter: 0; batch classifier loss: 0.086560; batch adversarial loss: 0.519463\n",
      "epoch 51; iter: 0; batch classifier loss: 0.115911; batch adversarial loss: 0.455577\n",
      "epoch 52; iter: 0; batch classifier loss: 0.134175; batch adversarial loss: 0.480629\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084204; batch adversarial loss: 0.511220\n",
      "epoch 54; iter: 0; batch classifier loss: 0.120563; batch adversarial loss: 0.503756\n",
      "epoch 55; iter: 0; batch classifier loss: 0.128412; batch adversarial loss: 0.485449\n",
      "epoch 56; iter: 0; batch classifier loss: 0.108392; batch adversarial loss: 0.412133\n",
      "epoch 57; iter: 0; batch classifier loss: 0.114750; batch adversarial loss: 0.484775\n",
      "epoch 58; iter: 0; batch classifier loss: 0.100807; batch adversarial loss: 0.400306\n",
      "epoch 59; iter: 0; batch classifier loss: 0.118988; batch adversarial loss: 0.447507\n",
      "epoch 60; iter: 0; batch classifier loss: 0.064540; batch adversarial loss: 0.438337\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104308; batch adversarial loss: 0.424902\n",
      "epoch 62; iter: 0; batch classifier loss: 0.065072; batch adversarial loss: 0.465333\n",
      "epoch 63; iter: 0; batch classifier loss: 0.126161; batch adversarial loss: 0.464286\n",
      "epoch 64; iter: 0; batch classifier loss: 0.102421; batch adversarial loss: 0.435675\n",
      "epoch 65; iter: 0; batch classifier loss: 0.119245; batch adversarial loss: 0.485072\n",
      "epoch 66; iter: 0; batch classifier loss: 0.116340; batch adversarial loss: 0.418499\n",
      "epoch 67; iter: 0; batch classifier loss: 0.062122; batch adversarial loss: 0.480654\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096291; batch adversarial loss: 0.420798\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102288; batch adversarial loss: 0.453758\n",
      "epoch 70; iter: 0; batch classifier loss: 0.092590; batch adversarial loss: 0.516247\n",
      "epoch 71; iter: 0; batch classifier loss: 0.087447; batch adversarial loss: 0.442069\n",
      "epoch 72; iter: 0; batch classifier loss: 0.114966; batch adversarial loss: 0.390710\n",
      "epoch 73; iter: 0; batch classifier loss: 0.098152; batch adversarial loss: 0.380947\n",
      "epoch 74; iter: 0; batch classifier loss: 0.088054; batch adversarial loss: 0.427322\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110299; batch adversarial loss: 0.433799\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103225; batch adversarial loss: 0.469944\n",
      "epoch 77; iter: 0; batch classifier loss: 0.101295; batch adversarial loss: 0.492610\n",
      "epoch 78; iter: 0; batch classifier loss: 0.099057; batch adversarial loss: 0.372843\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067465; batch adversarial loss: 0.423437\n",
      "epoch 80; iter: 0; batch classifier loss: 0.094913; batch adversarial loss: 0.454144\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120134; batch adversarial loss: 0.520314\n",
      "epoch 82; iter: 0; batch classifier loss: 0.102154; batch adversarial loss: 0.386159\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067495; batch adversarial loss: 0.434162\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068276; batch adversarial loss: 0.529727\n",
      "epoch 85; iter: 0; batch classifier loss: 0.039875; batch adversarial loss: 0.453720\n",
      "epoch 86; iter: 0; batch classifier loss: 0.126618; batch adversarial loss: 0.405567\n",
      "epoch 87; iter: 0; batch classifier loss: 0.145732; batch adversarial loss: 0.423750\n",
      "epoch 88; iter: 0; batch classifier loss: 0.061070; batch adversarial loss: 0.382091\n",
      "epoch 89; iter: 0; batch classifier loss: 0.088004; batch adversarial loss: 0.456163\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075507; batch adversarial loss: 0.526775\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063134; batch adversarial loss: 0.418189\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077843; batch adversarial loss: 0.375844\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039411; batch adversarial loss: 0.506050\n",
      "epoch 94; iter: 0; batch classifier loss: 0.054820; batch adversarial loss: 0.478297\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073183; batch adversarial loss: 0.435969\n",
      "epoch 96; iter: 0; batch classifier loss: 0.165184; batch adversarial loss: 0.498630\n",
      "epoch 97; iter: 0; batch classifier loss: 0.149240; batch adversarial loss: 0.418652\n",
      "epoch 98; iter: 0; batch classifier loss: 0.077491; batch adversarial loss: 0.391328\n",
      "epoch 99; iter: 0; batch classifier loss: 0.091557; batch adversarial loss: 0.335983\n",
      "epoch 100; iter: 0; batch classifier loss: 0.101664; batch adversarial loss: 0.389343\n",
      "epoch 101; iter: 0; batch classifier loss: 0.089247; batch adversarial loss: 0.493242\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079837; batch adversarial loss: 0.451404\n",
      "epoch 103; iter: 0; batch classifier loss: 0.097019; batch adversarial loss: 0.348309\n",
      "epoch 104; iter: 0; batch classifier loss: 0.093401; batch adversarial loss: 0.436016\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045768; batch adversarial loss: 0.522800\n",
      "epoch 106; iter: 0; batch classifier loss: 0.078655; batch adversarial loss: 0.355122\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034111; batch adversarial loss: 0.576253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.090360; batch adversarial loss: 0.496416\n",
      "epoch 109; iter: 0; batch classifier loss: 0.087006; batch adversarial loss: 0.377642\n",
      "epoch 110; iter: 0; batch classifier loss: 0.111992; batch adversarial loss: 0.430359\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049363; batch adversarial loss: 0.437909\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060447; batch adversarial loss: 0.397969\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043566; batch adversarial loss: 0.472829\n",
      "epoch 114; iter: 0; batch classifier loss: 0.085095; batch adversarial loss: 0.453859\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042390; batch adversarial loss: 0.547086\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058550; batch adversarial loss: 0.376886\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060539; batch adversarial loss: 0.403884\n",
      "epoch 118; iter: 0; batch classifier loss: 0.087995; batch adversarial loss: 0.487712\n",
      "epoch 119; iter: 0; batch classifier loss: 0.113029; batch adversarial loss: 0.474662\n",
      "epoch 120; iter: 0; batch classifier loss: 0.077392; batch adversarial loss: 0.402945\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068462; batch adversarial loss: 0.521858\n",
      "epoch 122; iter: 0; batch classifier loss: 0.075478; batch adversarial loss: 0.471375\n",
      "epoch 123; iter: 0; batch classifier loss: 0.071384; batch adversarial loss: 0.471341\n",
      "epoch 124; iter: 0; batch classifier loss: 0.095688; batch adversarial loss: 0.433594\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051116; batch adversarial loss: 0.435072\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049909; batch adversarial loss: 0.384288\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035140; batch adversarial loss: 0.513601\n",
      "epoch 128; iter: 0; batch classifier loss: 0.071927; batch adversarial loss: 0.480319\n",
      "epoch 129; iter: 0; batch classifier loss: 0.071533; batch adversarial loss: 0.357406\n",
      "epoch 130; iter: 0; batch classifier loss: 0.071279; batch adversarial loss: 0.561860\n",
      "epoch 131; iter: 0; batch classifier loss: 0.104466; batch adversarial loss: 0.369813\n",
      "epoch 132; iter: 0; batch classifier loss: 0.124991; batch adversarial loss: 0.408955\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044463; batch adversarial loss: 0.417829\n",
      "epoch 134; iter: 0; batch classifier loss: 0.013113; batch adversarial loss: 0.459296\n",
      "epoch 135; iter: 0; batch classifier loss: 0.081214; batch adversarial loss: 0.469966\n",
      "epoch 136; iter: 0; batch classifier loss: 0.074241; batch adversarial loss: 0.449907\n",
      "epoch 137; iter: 0; batch classifier loss: 0.073828; batch adversarial loss: 0.481613\n",
      "epoch 138; iter: 0; batch classifier loss: 0.058364; batch adversarial loss: 0.364833\n",
      "epoch 139; iter: 0; batch classifier loss: 0.080759; batch adversarial loss: 0.492595\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041960; batch adversarial loss: 0.488494\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043681; batch adversarial loss: 0.437240\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026571; batch adversarial loss: 0.438796\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029396; batch adversarial loss: 0.439888\n",
      "epoch 144; iter: 0; batch classifier loss: 0.055638; batch adversarial loss: 0.410253\n",
      "epoch 145; iter: 0; batch classifier loss: 0.067592; batch adversarial loss: 0.361835\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030788; batch adversarial loss: 0.448886\n",
      "epoch 147; iter: 0; batch classifier loss: 0.081277; batch adversarial loss: 0.433076\n",
      "epoch 148; iter: 0; batch classifier loss: 0.059608; batch adversarial loss: 0.451137\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040448; batch adversarial loss: 0.421704\n",
      "epoch 150; iter: 0; batch classifier loss: 0.114382; batch adversarial loss: 0.429359\n",
      "epoch 151; iter: 0; batch classifier loss: 0.049161; batch adversarial loss: 0.532839\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022894; batch adversarial loss: 0.437505\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036498; batch adversarial loss: 0.486161\n",
      "epoch 154; iter: 0; batch classifier loss: 0.080593; batch adversarial loss: 0.373245\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042216; batch adversarial loss: 0.522274\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015650; batch adversarial loss: 0.429953\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042609; batch adversarial loss: 0.491926\n",
      "epoch 158; iter: 0; batch classifier loss: 0.058987; batch adversarial loss: 0.418306\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022355; batch adversarial loss: 0.502694\n",
      "epoch 160; iter: 0; batch classifier loss: 0.084259; batch adversarial loss: 0.434633\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038596; batch adversarial loss: 0.423088\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016439; batch adversarial loss: 0.485447\n",
      "epoch 163; iter: 0; batch classifier loss: 0.031923; batch adversarial loss: 0.522203\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033581; batch adversarial loss: 0.438722\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042513; batch adversarial loss: 0.446063\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017497; batch adversarial loss: 0.447789\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024713; batch adversarial loss: 0.636935\n",
      "epoch 168; iter: 0; batch classifier loss: 0.046545; batch adversarial loss: 0.409767\n",
      "epoch 169; iter: 0; batch classifier loss: 0.053768; batch adversarial loss: 0.353794\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030158; batch adversarial loss: 0.447683\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029532; batch adversarial loss: 0.380755\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031660; batch adversarial loss: 0.416222\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038752; batch adversarial loss: 0.365102\n",
      "epoch 174; iter: 0; batch classifier loss: 0.042646; batch adversarial loss: 0.429424\n",
      "epoch 175; iter: 0; batch classifier loss: 0.046912; batch adversarial loss: 0.411403\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021214; batch adversarial loss: 0.523606\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031360; batch adversarial loss: 0.436943\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006114; batch adversarial loss: 0.396559\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015855; batch adversarial loss: 0.338791\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029030; batch adversarial loss: 0.451908\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019557; batch adversarial loss: 0.535570\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015808; batch adversarial loss: 0.464981\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019017; batch adversarial loss: 0.477558\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017624; batch adversarial loss: 0.470327\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040360; batch adversarial loss: 0.485265\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021092; batch adversarial loss: 0.340901\n",
      "epoch 187; iter: 0; batch classifier loss: 0.038082; batch adversarial loss: 0.402678\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027255; batch adversarial loss: 0.491249\n",
      "epoch 189; iter: 0; batch classifier loss: 0.039723; batch adversarial loss: 0.491496\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022414; batch adversarial loss: 0.480423\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032506; batch adversarial loss: 0.459485\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008458; batch adversarial loss: 0.386115\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020936; batch adversarial loss: 0.499109\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017792; batch adversarial loss: 0.431050\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014997; batch adversarial loss: 0.436048\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022073; batch adversarial loss: 0.470523\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022715; batch adversarial loss: 0.456874\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022164; batch adversarial loss: 0.531303\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008035; batch adversarial loss: 0.445164\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677661; batch adversarial loss: 0.534657\n",
      "epoch 1; iter: 0; batch classifier loss: 0.375035; batch adversarial loss: 0.619127\n",
      "epoch 2; iter: 0; batch classifier loss: 0.433212; batch adversarial loss: 0.566727\n",
      "epoch 3; iter: 0; batch classifier loss: 0.321505; batch adversarial loss: 0.616160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.384505; batch adversarial loss: 0.507290\n",
      "epoch 5; iter: 0; batch classifier loss: 0.465705; batch adversarial loss: 0.661939\n",
      "epoch 6; iter: 0; batch classifier loss: 0.392525; batch adversarial loss: 0.539495\n",
      "epoch 7; iter: 0; batch classifier loss: 0.388769; batch adversarial loss: 0.573851\n",
      "epoch 8; iter: 0; batch classifier loss: 0.349620; batch adversarial loss: 0.507793\n",
      "epoch 9; iter: 0; batch classifier loss: 0.412207; batch adversarial loss: 0.634380\n",
      "epoch 10; iter: 0; batch classifier loss: 0.489513; batch adversarial loss: 0.569950\n",
      "epoch 11; iter: 0; batch classifier loss: 0.556068; batch adversarial loss: 0.587221\n",
      "epoch 12; iter: 0; batch classifier loss: 0.716897; batch adversarial loss: 0.495279\n",
      "epoch 13; iter: 0; batch classifier loss: 0.471346; batch adversarial loss: 0.568219\n",
      "epoch 14; iter: 0; batch classifier loss: 0.342464; batch adversarial loss: 0.490848\n",
      "epoch 15; iter: 0; batch classifier loss: 0.371659; batch adversarial loss: 0.454867\n",
      "epoch 16; iter: 0; batch classifier loss: 0.256727; batch adversarial loss: 0.534800\n",
      "epoch 17; iter: 0; batch classifier loss: 0.231326; batch adversarial loss: 0.424940\n",
      "epoch 18; iter: 0; batch classifier loss: 0.287773; batch adversarial loss: 0.446916\n",
      "epoch 19; iter: 0; batch classifier loss: 0.276661; batch adversarial loss: 0.473530\n",
      "epoch 20; iter: 0; batch classifier loss: 0.201766; batch adversarial loss: 0.497817\n",
      "epoch 21; iter: 0; batch classifier loss: 0.190908; batch adversarial loss: 0.430668\n",
      "epoch 22; iter: 0; batch classifier loss: 0.236572; batch adversarial loss: 0.452221\n",
      "epoch 23; iter: 0; batch classifier loss: 0.201795; batch adversarial loss: 0.470200\n",
      "epoch 24; iter: 0; batch classifier loss: 0.216700; batch adversarial loss: 0.440342\n",
      "epoch 25; iter: 0; batch classifier loss: 0.231289; batch adversarial loss: 0.514870\n",
      "epoch 26; iter: 0; batch classifier loss: 0.183252; batch adversarial loss: 0.494048\n",
      "epoch 27; iter: 0; batch classifier loss: 0.180922; batch adversarial loss: 0.449375\n",
      "epoch 28; iter: 0; batch classifier loss: 0.139873; batch adversarial loss: 0.474323\n",
      "epoch 29; iter: 0; batch classifier loss: 0.137712; batch adversarial loss: 0.417069\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172108; batch adversarial loss: 0.411651\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166782; batch adversarial loss: 0.499834\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172185; batch adversarial loss: 0.476242\n",
      "epoch 33; iter: 0; batch classifier loss: 0.181434; batch adversarial loss: 0.352617\n",
      "epoch 34; iter: 0; batch classifier loss: 0.166114; batch adversarial loss: 0.462264\n",
      "epoch 35; iter: 0; batch classifier loss: 0.165752; batch adversarial loss: 0.520357\n",
      "epoch 36; iter: 0; batch classifier loss: 0.235989; batch adversarial loss: 0.446527\n",
      "epoch 37; iter: 0; batch classifier loss: 0.127252; batch adversarial loss: 0.449980\n",
      "epoch 38; iter: 0; batch classifier loss: 0.134398; batch adversarial loss: 0.496787\n",
      "epoch 39; iter: 0; batch classifier loss: 0.174843; batch adversarial loss: 0.472192\n",
      "epoch 40; iter: 0; batch classifier loss: 0.164963; batch adversarial loss: 0.476929\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111026; batch adversarial loss: 0.509987\n",
      "epoch 42; iter: 0; batch classifier loss: 0.193712; batch adversarial loss: 0.475911\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150780; batch adversarial loss: 0.444125\n",
      "epoch 44; iter: 0; batch classifier loss: 0.148073; batch adversarial loss: 0.458072\n",
      "epoch 45; iter: 0; batch classifier loss: 0.191490; batch adversarial loss: 0.425171\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126542; batch adversarial loss: 0.475986\n",
      "epoch 47; iter: 0; batch classifier loss: 0.191455; batch adversarial loss: 0.480364\n",
      "epoch 48; iter: 0; batch classifier loss: 0.236753; batch adversarial loss: 0.407296\n",
      "epoch 49; iter: 0; batch classifier loss: 0.149808; batch adversarial loss: 0.474759\n",
      "epoch 50; iter: 0; batch classifier loss: 0.162844; batch adversarial loss: 0.428313\n",
      "epoch 51; iter: 0; batch classifier loss: 0.147537; batch adversarial loss: 0.468885\n",
      "epoch 52; iter: 0; batch classifier loss: 0.181348; batch adversarial loss: 0.443739\n",
      "epoch 53; iter: 0; batch classifier loss: 0.199733; batch adversarial loss: 0.460932\n",
      "epoch 54; iter: 0; batch classifier loss: 0.183314; batch adversarial loss: 0.447612\n",
      "epoch 55; iter: 0; batch classifier loss: 0.171925; batch adversarial loss: 0.443954\n",
      "epoch 56; iter: 0; batch classifier loss: 0.154895; batch adversarial loss: 0.447868\n",
      "epoch 57; iter: 0; batch classifier loss: 0.164040; batch adversarial loss: 0.360507\n",
      "epoch 58; iter: 0; batch classifier loss: 0.185440; batch adversarial loss: 0.470264\n",
      "epoch 59; iter: 0; batch classifier loss: 0.233450; batch adversarial loss: 0.485989\n",
      "epoch 60; iter: 0; batch classifier loss: 0.166206; batch adversarial loss: 0.399858\n",
      "epoch 61; iter: 0; batch classifier loss: 0.159001; batch adversarial loss: 0.460097\n",
      "epoch 62; iter: 0; batch classifier loss: 0.148727; batch adversarial loss: 0.461164\n",
      "epoch 63; iter: 0; batch classifier loss: 0.190500; batch adversarial loss: 0.433020\n",
      "epoch 64; iter: 0; batch classifier loss: 0.262294; batch adversarial loss: 0.407736\n",
      "epoch 65; iter: 0; batch classifier loss: 0.253447; batch adversarial loss: 0.395732\n",
      "epoch 66; iter: 0; batch classifier loss: 0.206147; batch adversarial loss: 0.423745\n",
      "epoch 67; iter: 0; batch classifier loss: 0.201999; batch adversarial loss: 0.394890\n",
      "epoch 68; iter: 0; batch classifier loss: 0.206658; batch adversarial loss: 0.408885\n",
      "epoch 69; iter: 0; batch classifier loss: 0.199740; batch adversarial loss: 0.447952\n",
      "epoch 70; iter: 0; batch classifier loss: 0.184985; batch adversarial loss: 0.421880\n",
      "epoch 71; iter: 0; batch classifier loss: 0.210102; batch adversarial loss: 0.521410\n",
      "epoch 72; iter: 0; batch classifier loss: 0.187416; batch adversarial loss: 0.421758\n",
      "epoch 73; iter: 0; batch classifier loss: 0.184358; batch adversarial loss: 0.534011\n",
      "epoch 74; iter: 0; batch classifier loss: 0.142023; batch adversarial loss: 0.433409\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110597; batch adversarial loss: 0.404350\n",
      "epoch 76; iter: 0; batch classifier loss: 0.091456; batch adversarial loss: 0.380874\n",
      "epoch 77; iter: 0; batch classifier loss: 0.178380; batch adversarial loss: 0.381705\n",
      "epoch 78; iter: 0; batch classifier loss: 0.222930; batch adversarial loss: 0.410468\n",
      "epoch 79; iter: 0; batch classifier loss: 0.202293; batch adversarial loss: 0.381609\n",
      "epoch 80; iter: 0; batch classifier loss: 0.185367; batch adversarial loss: 0.472215\n",
      "epoch 81; iter: 0; batch classifier loss: 0.173017; batch adversarial loss: 0.483442\n",
      "epoch 82; iter: 0; batch classifier loss: 0.170365; batch adversarial loss: 0.421159\n",
      "epoch 83; iter: 0; batch classifier loss: 0.185719; batch adversarial loss: 0.382609\n",
      "epoch 84; iter: 0; batch classifier loss: 0.182729; batch adversarial loss: 0.420813\n",
      "epoch 85; iter: 0; batch classifier loss: 0.150131; batch adversarial loss: 0.522728\n",
      "epoch 86; iter: 0; batch classifier loss: 0.125278; batch adversarial loss: 0.395829\n",
      "epoch 87; iter: 0; batch classifier loss: 0.206755; batch adversarial loss: 0.433430\n",
      "epoch 88; iter: 0; batch classifier loss: 0.207828; batch adversarial loss: 0.371706\n",
      "epoch 89; iter: 0; batch classifier loss: 0.129737; batch adversarial loss: 0.557960\n",
      "epoch 90; iter: 0; batch classifier loss: 0.178632; batch adversarial loss: 0.459528\n",
      "epoch 91; iter: 0; batch classifier loss: 0.194043; batch adversarial loss: 0.457770\n",
      "epoch 92; iter: 0; batch classifier loss: 0.121984; batch adversarial loss: 0.535158\n",
      "epoch 93; iter: 0; batch classifier loss: 0.183747; batch adversarial loss: 0.460637\n",
      "epoch 94; iter: 0; batch classifier loss: 0.188929; batch adversarial loss: 0.459318\n",
      "epoch 95; iter: 0; batch classifier loss: 0.163781; batch adversarial loss: 0.421398\n",
      "epoch 96; iter: 0; batch classifier loss: 0.218627; batch adversarial loss: 0.471945\n",
      "epoch 97; iter: 0; batch classifier loss: 0.173646; batch adversarial loss: 0.333507\n",
      "epoch 98; iter: 0; batch classifier loss: 0.196018; batch adversarial loss: 0.521830\n",
      "epoch 99; iter: 0; batch classifier loss: 0.162944; batch adversarial loss: 0.433589\n",
      "epoch 100; iter: 0; batch classifier loss: 0.147093; batch adversarial loss: 0.483776\n",
      "epoch 101; iter: 0; batch classifier loss: 0.151628; batch adversarial loss: 0.382925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.154343; batch adversarial loss: 0.459094\n",
      "epoch 103; iter: 0; batch classifier loss: 0.194177; batch adversarial loss: 0.433662\n",
      "epoch 104; iter: 0; batch classifier loss: 0.178353; batch adversarial loss: 0.445998\n",
      "epoch 105; iter: 0; batch classifier loss: 0.113885; batch adversarial loss: 0.421074\n",
      "epoch 106; iter: 0; batch classifier loss: 0.125958; batch adversarial loss: 0.432388\n",
      "epoch 107; iter: 0; batch classifier loss: 0.158919; batch adversarial loss: 0.484237\n",
      "epoch 108; iter: 0; batch classifier loss: 0.198038; batch adversarial loss: 0.358321\n",
      "epoch 109; iter: 0; batch classifier loss: 0.210030; batch adversarial loss: 0.432092\n",
      "epoch 110; iter: 0; batch classifier loss: 0.071506; batch adversarial loss: 0.535247\n",
      "epoch 111; iter: 0; batch classifier loss: 0.148820; batch adversarial loss: 0.434399\n",
      "epoch 112; iter: 0; batch classifier loss: 0.163546; batch adversarial loss: 0.522392\n",
      "epoch 113; iter: 0; batch classifier loss: 0.107826; batch adversarial loss: 0.444910\n",
      "epoch 114; iter: 0; batch classifier loss: 0.167433; batch adversarial loss: 0.385680\n",
      "epoch 115; iter: 0; batch classifier loss: 0.220328; batch adversarial loss: 0.408112\n",
      "epoch 116; iter: 0; batch classifier loss: 0.164316; batch adversarial loss: 0.458652\n",
      "epoch 117; iter: 0; batch classifier loss: 0.180675; batch adversarial loss: 0.433353\n",
      "epoch 118; iter: 0; batch classifier loss: 0.188131; batch adversarial loss: 0.396369\n",
      "epoch 119; iter: 0; batch classifier loss: 0.125426; batch adversarial loss: 0.424773\n",
      "epoch 120; iter: 0; batch classifier loss: 0.195334; batch adversarial loss: 0.357541\n",
      "epoch 121; iter: 0; batch classifier loss: 0.083660; batch adversarial loss: 0.523204\n",
      "epoch 122; iter: 0; batch classifier loss: 0.136593; batch adversarial loss: 0.445291\n",
      "epoch 123; iter: 0; batch classifier loss: 0.105716; batch adversarial loss: 0.433271\n",
      "epoch 124; iter: 0; batch classifier loss: 0.115024; batch adversarial loss: 0.432903\n",
      "epoch 125; iter: 0; batch classifier loss: 0.124778; batch adversarial loss: 0.409174\n",
      "epoch 126; iter: 0; batch classifier loss: 0.079044; batch adversarial loss: 0.375626\n",
      "epoch 127; iter: 0; batch classifier loss: 0.078391; batch adversarial loss: 0.549359\n",
      "epoch 128; iter: 0; batch classifier loss: 0.057928; batch adversarial loss: 0.538452\n",
      "epoch 129; iter: 0; batch classifier loss: 0.074564; batch adversarial loss: 0.444271\n",
      "epoch 130; iter: 0; batch classifier loss: 0.072417; batch adversarial loss: 0.383150\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041530; batch adversarial loss: 0.462148\n",
      "epoch 132; iter: 0; batch classifier loss: 0.076531; batch adversarial loss: 0.544466\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040074; batch adversarial loss: 0.364536\n",
      "epoch 134; iter: 0; batch classifier loss: 0.080104; batch adversarial loss: 0.449540\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041151; batch adversarial loss: 0.523305\n",
      "epoch 136; iter: 0; batch classifier loss: 0.072734; batch adversarial loss: 0.398169\n",
      "epoch 137; iter: 0; batch classifier loss: 0.071989; batch adversarial loss: 0.373584\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035854; batch adversarial loss: 0.442512\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024030; batch adversarial loss: 0.449099\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052996; batch adversarial loss: 0.445615\n",
      "epoch 141; iter: 0; batch classifier loss: 0.047063; batch adversarial loss: 0.459042\n",
      "epoch 142; iter: 0; batch classifier loss: 0.070456; batch adversarial loss: 0.384043\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046749; batch adversarial loss: 0.448395\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027532; batch adversarial loss: 0.463310\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033138; batch adversarial loss: 0.491644\n",
      "epoch 146; iter: 0; batch classifier loss: 0.050894; batch adversarial loss: 0.359583\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026775; batch adversarial loss: 0.445240\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017078; batch adversarial loss: 0.471089\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032165; batch adversarial loss: 0.401688\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012695; batch adversarial loss: 0.541097\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042021; batch adversarial loss: 0.484198\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032749; batch adversarial loss: 0.364875\n",
      "epoch 153; iter: 0; batch classifier loss: 0.062601; batch adversarial loss: 0.477583\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034705; batch adversarial loss: 0.390123\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019509; batch adversarial loss: 0.415460\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013143; batch adversarial loss: 0.426053\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022019; batch adversarial loss: 0.430020\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048117; batch adversarial loss: 0.446509\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049257; batch adversarial loss: 0.381009\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036493; batch adversarial loss: 0.441813\n",
      "epoch 161; iter: 0; batch classifier loss: 0.049231; batch adversarial loss: 0.469171\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028785; batch adversarial loss: 0.390070\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023349; batch adversarial loss: 0.384379\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029866; batch adversarial loss: 0.426899\n",
      "epoch 165; iter: 0; batch classifier loss: 0.052800; batch adversarial loss: 0.348712\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033020; batch adversarial loss: 0.406217\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025324; batch adversarial loss: 0.486760\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031612; batch adversarial loss: 0.455544\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036426; batch adversarial loss: 0.428214\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019698; batch adversarial loss: 0.468820\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014287; batch adversarial loss: 0.422268\n",
      "epoch 172; iter: 0; batch classifier loss: 0.037975; batch adversarial loss: 0.441587\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015197; batch adversarial loss: 0.394592\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026586; batch adversarial loss: 0.481101\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018338; batch adversarial loss: 0.371350\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010604; batch adversarial loss: 0.434103\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008047; batch adversarial loss: 0.403407\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010614; batch adversarial loss: 0.371713\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026152; batch adversarial loss: 0.476267\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023279; batch adversarial loss: 0.530571\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038621; batch adversarial loss: 0.359586\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006258; batch adversarial loss: 0.348828\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012910; batch adversarial loss: 0.364887\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015451; batch adversarial loss: 0.471974\n",
      "epoch 185; iter: 0; batch classifier loss: 0.043233; batch adversarial loss: 0.461975\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026455; batch adversarial loss: 0.423492\n",
      "epoch 187; iter: 0; batch classifier loss: 0.055073; batch adversarial loss: 0.451038\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006330; batch adversarial loss: 0.383864\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036685; batch adversarial loss: 0.589504\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024261; batch adversarial loss: 0.498948\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027725; batch adversarial loss: 0.380589\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018272; batch adversarial loss: 0.552593\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026457; batch adversarial loss: 0.414909\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021252; batch adversarial loss: 0.564261\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010101; batch adversarial loss: 0.483343\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026024; batch adversarial loss: 0.472145\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004996; batch adversarial loss: 0.387435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.012306; batch adversarial loss: 0.486565\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006487; batch adversarial loss: 0.505513\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706148; batch adversarial loss: 0.674466\n",
      "epoch 1; iter: 0; batch classifier loss: 0.528592; batch adversarial loss: 0.641128\n",
      "epoch 2; iter: 0; batch classifier loss: 0.412321; batch adversarial loss: 0.625191\n",
      "epoch 3; iter: 0; batch classifier loss: 0.422443; batch adversarial loss: 0.613424\n",
      "epoch 4; iter: 0; batch classifier loss: 0.432832; batch adversarial loss: 0.581224\n",
      "epoch 5; iter: 0; batch classifier loss: 0.449552; batch adversarial loss: 0.617549\n",
      "epoch 6; iter: 0; batch classifier loss: 0.506410; batch adversarial loss: 0.561518\n",
      "epoch 7; iter: 0; batch classifier loss: 0.433460; batch adversarial loss: 0.572298\n",
      "epoch 8; iter: 0; batch classifier loss: 0.460287; batch adversarial loss: 0.546710\n",
      "epoch 9; iter: 0; batch classifier loss: 0.489730; batch adversarial loss: 0.526062\n",
      "epoch 10; iter: 0; batch classifier loss: 0.461563; batch adversarial loss: 0.543884\n",
      "epoch 11; iter: 0; batch classifier loss: 0.312192; batch adversarial loss: 0.559213\n",
      "epoch 12; iter: 0; batch classifier loss: 0.439452; batch adversarial loss: 0.541093\n",
      "epoch 13; iter: 0; batch classifier loss: 0.377409; batch adversarial loss: 0.492429\n",
      "epoch 14; iter: 0; batch classifier loss: 0.349212; batch adversarial loss: 0.490614\n",
      "epoch 15; iter: 0; batch classifier loss: 0.318988; batch adversarial loss: 0.545120\n",
      "epoch 16; iter: 0; batch classifier loss: 0.440656; batch adversarial loss: 0.432221\n",
      "epoch 17; iter: 0; batch classifier loss: 0.358093; batch adversarial loss: 0.461951\n",
      "epoch 18; iter: 0; batch classifier loss: 0.329594; batch adversarial loss: 0.545875\n",
      "epoch 19; iter: 0; batch classifier loss: 0.343999; batch adversarial loss: 0.461907\n",
      "epoch 20; iter: 0; batch classifier loss: 0.329134; batch adversarial loss: 0.529042\n",
      "epoch 21; iter: 0; batch classifier loss: 0.447794; batch adversarial loss: 0.392604\n",
      "epoch 22; iter: 0; batch classifier loss: 0.345391; batch adversarial loss: 0.476277\n",
      "epoch 23; iter: 0; batch classifier loss: 0.373683; batch adversarial loss: 0.479677\n",
      "epoch 24; iter: 0; batch classifier loss: 0.351114; batch adversarial loss: 0.533600\n",
      "epoch 25; iter: 0; batch classifier loss: 0.302506; batch adversarial loss: 0.503350\n",
      "epoch 26; iter: 0; batch classifier loss: 0.369718; batch adversarial loss: 0.538667\n",
      "epoch 27; iter: 0; batch classifier loss: 0.353380; batch adversarial loss: 0.478968\n",
      "epoch 28; iter: 0; batch classifier loss: 0.333727; batch adversarial loss: 0.477917\n",
      "epoch 29; iter: 0; batch classifier loss: 0.335490; batch adversarial loss: 0.423315\n",
      "epoch 30; iter: 0; batch classifier loss: 0.271502; batch adversarial loss: 0.480125\n",
      "epoch 31; iter: 0; batch classifier loss: 0.307715; batch adversarial loss: 0.468158\n",
      "epoch 32; iter: 0; batch classifier loss: 0.256634; batch adversarial loss: 0.465415\n",
      "epoch 33; iter: 0; batch classifier loss: 0.295633; batch adversarial loss: 0.428429\n",
      "epoch 34; iter: 0; batch classifier loss: 0.232120; batch adversarial loss: 0.482191\n",
      "epoch 35; iter: 0; batch classifier loss: 0.339538; batch adversarial loss: 0.441813\n",
      "epoch 36; iter: 0; batch classifier loss: 0.296204; batch adversarial loss: 0.429696\n",
      "epoch 37; iter: 0; batch classifier loss: 0.234190; batch adversarial loss: 0.518653\n",
      "epoch 38; iter: 0; batch classifier loss: 0.247838; batch adversarial loss: 0.415821\n",
      "epoch 39; iter: 0; batch classifier loss: 0.236740; batch adversarial loss: 0.539737\n",
      "epoch 40; iter: 0; batch classifier loss: 0.179121; batch adversarial loss: 0.356268\n",
      "epoch 41; iter: 0; batch classifier loss: 0.130977; batch adversarial loss: 0.447040\n",
      "epoch 42; iter: 0; batch classifier loss: 0.109505; batch adversarial loss: 0.520421\n",
      "epoch 43; iter: 0; batch classifier loss: 0.239158; batch adversarial loss: 0.532877\n",
      "epoch 44; iter: 0; batch classifier loss: 0.176166; batch adversarial loss: 0.508147\n",
      "epoch 45; iter: 0; batch classifier loss: 0.221197; batch adversarial loss: 0.483661\n",
      "epoch 46; iter: 0; batch classifier loss: 0.283340; batch adversarial loss: 0.446478\n",
      "epoch 47; iter: 0; batch classifier loss: 0.195324; batch adversarial loss: 0.507213\n",
      "epoch 48; iter: 0; batch classifier loss: 0.214174; batch adversarial loss: 0.508569\n",
      "epoch 49; iter: 0; batch classifier loss: 0.268802; batch adversarial loss: 0.398873\n",
      "epoch 50; iter: 0; batch classifier loss: 0.240782; batch adversarial loss: 0.519788\n",
      "epoch 51; iter: 0; batch classifier loss: 0.201942; batch adversarial loss: 0.410723\n",
      "epoch 52; iter: 0; batch classifier loss: 0.194375; batch adversarial loss: 0.313480\n",
      "epoch 53; iter: 0; batch classifier loss: 0.142684; batch adversarial loss: 0.519311\n",
      "epoch 54; iter: 0; batch classifier loss: 0.139915; batch adversarial loss: 0.470479\n",
      "epoch 55; iter: 0; batch classifier loss: 0.233199; batch adversarial loss: 0.496314\n",
      "epoch 56; iter: 0; batch classifier loss: 0.142394; batch adversarial loss: 0.397274\n",
      "epoch 57; iter: 0; batch classifier loss: 0.150511; batch adversarial loss: 0.421591\n",
      "epoch 58; iter: 0; batch classifier loss: 0.233014; batch adversarial loss: 0.472082\n",
      "epoch 59; iter: 0; batch classifier loss: 0.158226; batch adversarial loss: 0.397755\n",
      "epoch 60; iter: 0; batch classifier loss: 0.195981; batch adversarial loss: 0.419962\n",
      "epoch 61; iter: 0; batch classifier loss: 0.228051; batch adversarial loss: 0.385389\n",
      "epoch 62; iter: 0; batch classifier loss: 0.166367; batch adversarial loss: 0.495807\n",
      "epoch 63; iter: 0; batch classifier loss: 0.208059; batch adversarial loss: 0.360353\n",
      "epoch 64; iter: 0; batch classifier loss: 0.172150; batch adversarial loss: 0.508286\n",
      "epoch 65; iter: 0; batch classifier loss: 0.207821; batch adversarial loss: 0.446874\n",
      "epoch 66; iter: 0; batch classifier loss: 0.099810; batch adversarial loss: 0.483123\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098557; batch adversarial loss: 0.419494\n",
      "epoch 68; iter: 0; batch classifier loss: 0.146713; batch adversarial loss: 0.444906\n",
      "epoch 69; iter: 0; batch classifier loss: 0.182159; batch adversarial loss: 0.499474\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103249; batch adversarial loss: 0.508204\n",
      "epoch 71; iter: 0; batch classifier loss: 0.138272; batch adversarial loss: 0.470015\n",
      "epoch 72; iter: 0; batch classifier loss: 0.180949; batch adversarial loss: 0.410531\n",
      "epoch 73; iter: 0; batch classifier loss: 0.231549; batch adversarial loss: 0.534404\n",
      "epoch 74; iter: 0; batch classifier loss: 0.156506; batch adversarial loss: 0.520286\n",
      "epoch 75; iter: 0; batch classifier loss: 0.186269; batch adversarial loss: 0.394756\n",
      "epoch 76; iter: 0; batch classifier loss: 0.254745; batch adversarial loss: 0.484498\n",
      "epoch 77; iter: 0; batch classifier loss: 0.239896; batch adversarial loss: 0.483983\n",
      "epoch 78; iter: 0; batch classifier loss: 0.121166; batch adversarial loss: 0.471105\n",
      "epoch 79; iter: 0; batch classifier loss: 0.159953; batch adversarial loss: 0.408848\n",
      "epoch 80; iter: 0; batch classifier loss: 0.228769; batch adversarial loss: 0.446420\n",
      "epoch 81; iter: 0; batch classifier loss: 0.185841; batch adversarial loss: 0.408427\n",
      "epoch 82; iter: 0; batch classifier loss: 0.167793; batch adversarial loss: 0.347861\n",
      "epoch 83; iter: 0; batch classifier loss: 0.174609; batch adversarial loss: 0.446638\n",
      "epoch 84; iter: 0; batch classifier loss: 0.198952; batch adversarial loss: 0.446344\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074338; batch adversarial loss: 0.471066\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081550; batch adversarial loss: 0.366404\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071095; batch adversarial loss: 0.450083\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075686; batch adversarial loss: 0.423874\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048420; batch adversarial loss: 0.426854\n",
      "epoch 90; iter: 0; batch classifier loss: 0.033249; batch adversarial loss: 0.501000\n",
      "epoch 91; iter: 0; batch classifier loss: 0.035098; batch adversarial loss: 0.420303\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074287; batch adversarial loss: 0.429037\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050828; batch adversarial loss: 0.455258\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079815; batch adversarial loss: 0.423416\n",
      "epoch 95; iter: 0; batch classifier loss: 0.072268; batch adversarial loss: 0.313317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.053382; batch adversarial loss: 0.417569\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055613; batch adversarial loss: 0.487285\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067666; batch adversarial loss: 0.363745\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074332; batch adversarial loss: 0.431653\n",
      "epoch 100; iter: 0; batch classifier loss: 0.058776; batch adversarial loss: 0.427868\n",
      "epoch 101; iter: 0; batch classifier loss: 0.101547; batch adversarial loss: 0.412191\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039179; batch adversarial loss: 0.462854\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055648; batch adversarial loss: 0.392868\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066800; batch adversarial loss: 0.408056\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045702; batch adversarial loss: 0.385348\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068064; batch adversarial loss: 0.447495\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047650; batch adversarial loss: 0.497776\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049090; batch adversarial loss: 0.543240\n",
      "epoch 109; iter: 0; batch classifier loss: 0.021765; batch adversarial loss: 0.527207\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048385; batch adversarial loss: 0.454742\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061223; batch adversarial loss: 0.494695\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033943; batch adversarial loss: 0.411134\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041441; batch adversarial loss: 0.383811\n",
      "epoch 114; iter: 0; batch classifier loss: 0.064361; batch adversarial loss: 0.380719\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051269; batch adversarial loss: 0.467272\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051328; batch adversarial loss: 0.458791\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026150; batch adversarial loss: 0.449693\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039550; batch adversarial loss: 0.440149\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046112; batch adversarial loss: 0.451040\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049831; batch adversarial loss: 0.379997\n",
      "epoch 121; iter: 0; batch classifier loss: 0.055844; batch adversarial loss: 0.394425\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026223; batch adversarial loss: 0.380900\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064422; batch adversarial loss: 0.550708\n",
      "epoch 124; iter: 0; batch classifier loss: 0.056928; batch adversarial loss: 0.384033\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028918; batch adversarial loss: 0.376639\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030313; batch adversarial loss: 0.439796\n",
      "epoch 127; iter: 0; batch classifier loss: 0.090027; batch adversarial loss: 0.389048\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041015; batch adversarial loss: 0.435011\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048905; batch adversarial loss: 0.456047\n",
      "epoch 130; iter: 0; batch classifier loss: 0.053350; batch adversarial loss: 0.365895\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047059; batch adversarial loss: 0.485198\n",
      "epoch 132; iter: 0; batch classifier loss: 0.054494; batch adversarial loss: 0.500559\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052875; batch adversarial loss: 0.579935\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042772; batch adversarial loss: 0.352439\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060976; batch adversarial loss: 0.374587\n",
      "epoch 136; iter: 0; batch classifier loss: 0.055659; batch adversarial loss: 0.417933\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043737; batch adversarial loss: 0.420721\n",
      "epoch 138; iter: 0; batch classifier loss: 0.052245; batch adversarial loss: 0.416778\n",
      "epoch 139; iter: 0; batch classifier loss: 0.097579; batch adversarial loss: 0.501254\n",
      "epoch 140; iter: 0; batch classifier loss: 0.059317; batch adversarial loss: 0.407028\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044711; batch adversarial loss: 0.466443\n",
      "epoch 142; iter: 0; batch classifier loss: 0.057734; batch adversarial loss: 0.417948\n",
      "epoch 143; iter: 0; batch classifier loss: 0.066590; batch adversarial loss: 0.463521\n",
      "epoch 144; iter: 0; batch classifier loss: 0.043115; batch adversarial loss: 0.409424\n",
      "epoch 145; iter: 0; batch classifier loss: 0.080205; batch adversarial loss: 0.445489\n",
      "epoch 146; iter: 0; batch classifier loss: 0.104695; batch adversarial loss: 0.387379\n",
      "epoch 147; iter: 0; batch classifier loss: 0.089623; batch adversarial loss: 0.429294\n",
      "epoch 148; iter: 0; batch classifier loss: 0.056431; batch adversarial loss: 0.354426\n",
      "epoch 149; iter: 0; batch classifier loss: 0.060988; batch adversarial loss: 0.448196\n",
      "epoch 150; iter: 0; batch classifier loss: 0.074331; batch adversarial loss: 0.508544\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044530; batch adversarial loss: 0.429888\n",
      "epoch 152; iter: 0; batch classifier loss: 0.053956; batch adversarial loss: 0.376504\n",
      "epoch 153; iter: 0; batch classifier loss: 0.050944; batch adversarial loss: 0.431541\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029328; batch adversarial loss: 0.396295\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045217; batch adversarial loss: 0.508264\n",
      "epoch 156; iter: 0; batch classifier loss: 0.055777; batch adversarial loss: 0.486214\n",
      "epoch 157; iter: 0; batch classifier loss: 0.080622; batch adversarial loss: 0.505498\n",
      "epoch 158; iter: 0; batch classifier loss: 0.061468; batch adversarial loss: 0.414536\n",
      "epoch 159; iter: 0; batch classifier loss: 0.078752; batch adversarial loss: 0.481317\n",
      "epoch 160; iter: 0; batch classifier loss: 0.058379; batch adversarial loss: 0.390234\n",
      "epoch 161; iter: 0; batch classifier loss: 0.064107; batch adversarial loss: 0.402881\n",
      "epoch 162; iter: 0; batch classifier loss: 0.047802; batch adversarial loss: 0.611910\n",
      "epoch 163; iter: 0; batch classifier loss: 0.048415; batch adversarial loss: 0.443159\n",
      "epoch 164; iter: 0; batch classifier loss: 0.066216; batch adversarial loss: 0.324788\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041362; batch adversarial loss: 0.448950\n",
      "epoch 166; iter: 0; batch classifier loss: 0.041539; batch adversarial loss: 0.382712\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042107; batch adversarial loss: 0.449998\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037728; batch adversarial loss: 0.394600\n",
      "epoch 169; iter: 0; batch classifier loss: 0.050011; batch adversarial loss: 0.460665\n",
      "epoch 170; iter: 0; batch classifier loss: 0.043294; batch adversarial loss: 0.451880\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047634; batch adversarial loss: 0.465197\n",
      "epoch 172; iter: 0; batch classifier loss: 0.058231; batch adversarial loss: 0.478604\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033025; batch adversarial loss: 0.544120\n",
      "epoch 174; iter: 0; batch classifier loss: 0.049888; batch adversarial loss: 0.507477\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038030; batch adversarial loss: 0.403476\n",
      "epoch 176; iter: 0; batch classifier loss: 0.052403; batch adversarial loss: 0.461913\n",
      "epoch 177; iter: 0; batch classifier loss: 0.058357; batch adversarial loss: 0.431478\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040526; batch adversarial loss: 0.386047\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029067; batch adversarial loss: 0.530625\n",
      "epoch 180; iter: 0; batch classifier loss: 0.048729; batch adversarial loss: 0.400344\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033801; batch adversarial loss: 0.470935\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036419; batch adversarial loss: 0.376662\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025152; batch adversarial loss: 0.526059\n",
      "epoch 184; iter: 0; batch classifier loss: 0.042320; batch adversarial loss: 0.456759\n",
      "epoch 185; iter: 0; batch classifier loss: 0.049040; batch adversarial loss: 0.432394\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040681; batch adversarial loss: 0.396514\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035811; batch adversarial loss: 0.422781\n",
      "epoch 188; iter: 0; batch classifier loss: 0.051604; batch adversarial loss: 0.425435\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028103; batch adversarial loss: 0.514014\n",
      "epoch 190; iter: 0; batch classifier loss: 0.056718; batch adversarial loss: 0.440963\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013326; batch adversarial loss: 0.483623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.028244; batch adversarial loss: 0.446010\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032098; batch adversarial loss: 0.402203\n",
      "epoch 194; iter: 0; batch classifier loss: 0.040288; batch adversarial loss: 0.351785\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027648; batch adversarial loss: 0.307442\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020670; batch adversarial loss: 0.456599\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023561; batch adversarial loss: 0.432075\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024889; batch adversarial loss: 0.410294\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019193; batch adversarial loss: 0.453035\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688461; batch adversarial loss: 0.788617\n",
      "epoch 1; iter: 0; batch classifier loss: 0.569631; batch adversarial loss: 0.754736\n",
      "epoch 2; iter: 0; batch classifier loss: 0.703041; batch adversarial loss: 0.749865\n",
      "epoch 3; iter: 0; batch classifier loss: 0.665886; batch adversarial loss: 0.695129\n",
      "epoch 4; iter: 0; batch classifier loss: 0.515492; batch adversarial loss: 0.633034\n",
      "epoch 5; iter: 0; batch classifier loss: 0.347703; batch adversarial loss: 0.567885\n",
      "epoch 6; iter: 0; batch classifier loss: 0.373597; batch adversarial loss: 0.599082\n",
      "epoch 7; iter: 0; batch classifier loss: 0.286378; batch adversarial loss: 0.571008\n",
      "epoch 8; iter: 0; batch classifier loss: 0.373591; batch adversarial loss: 0.523271\n",
      "epoch 9; iter: 0; batch classifier loss: 0.330508; batch adversarial loss: 0.522804\n",
      "epoch 10; iter: 0; batch classifier loss: 0.348050; batch adversarial loss: 0.534056\n",
      "epoch 11; iter: 0; batch classifier loss: 0.300696; batch adversarial loss: 0.515778\n",
      "epoch 12; iter: 0; batch classifier loss: 0.277836; batch adversarial loss: 0.524800\n",
      "epoch 13; iter: 0; batch classifier loss: 0.325948; batch adversarial loss: 0.550698\n",
      "epoch 14; iter: 0; batch classifier loss: 0.335139; batch adversarial loss: 0.471451\n",
      "epoch 15; iter: 0; batch classifier loss: 0.288538; batch adversarial loss: 0.451786\n",
      "epoch 16; iter: 0; batch classifier loss: 0.319126; batch adversarial loss: 0.519753\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241271; batch adversarial loss: 0.498640\n",
      "epoch 18; iter: 0; batch classifier loss: 0.303547; batch adversarial loss: 0.454694\n",
      "epoch 19; iter: 0; batch classifier loss: 0.286122; batch adversarial loss: 0.577737\n",
      "epoch 20; iter: 0; batch classifier loss: 0.212193; batch adversarial loss: 0.423198\n",
      "epoch 21; iter: 0; batch classifier loss: 0.262040; batch adversarial loss: 0.500707\n",
      "epoch 22; iter: 0; batch classifier loss: 0.223002; batch adversarial loss: 0.479631\n",
      "epoch 23; iter: 0; batch classifier loss: 0.264857; batch adversarial loss: 0.436889\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195542; batch adversarial loss: 0.421118\n",
      "epoch 25; iter: 0; batch classifier loss: 0.173988; batch adversarial loss: 0.503259\n",
      "epoch 26; iter: 0; batch classifier loss: 0.156604; batch adversarial loss: 0.485096\n",
      "epoch 27; iter: 0; batch classifier loss: 0.125960; batch adversarial loss: 0.534112\n",
      "epoch 28; iter: 0; batch classifier loss: 0.141840; batch adversarial loss: 0.454893\n",
      "epoch 29; iter: 0; batch classifier loss: 0.132172; batch adversarial loss: 0.448296\n",
      "epoch 30; iter: 0; batch classifier loss: 0.154835; batch adversarial loss: 0.458828\n",
      "epoch 31; iter: 0; batch classifier loss: 0.143078; batch adversarial loss: 0.468090\n",
      "epoch 32; iter: 0; batch classifier loss: 0.166049; batch adversarial loss: 0.394476\n",
      "epoch 33; iter: 0; batch classifier loss: 0.092065; batch adversarial loss: 0.443658\n",
      "epoch 34; iter: 0; batch classifier loss: 0.107889; batch adversarial loss: 0.499510\n",
      "epoch 35; iter: 0; batch classifier loss: 0.150479; batch adversarial loss: 0.400039\n",
      "epoch 36; iter: 0; batch classifier loss: 0.121787; batch adversarial loss: 0.430335\n",
      "epoch 37; iter: 0; batch classifier loss: 0.104552; batch adversarial loss: 0.504979\n",
      "epoch 38; iter: 0; batch classifier loss: 0.175621; batch adversarial loss: 0.459660\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125774; batch adversarial loss: 0.468659\n",
      "epoch 40; iter: 0; batch classifier loss: 0.084749; batch adversarial loss: 0.424627\n",
      "epoch 41; iter: 0; batch classifier loss: 0.051417; batch adversarial loss: 0.499315\n",
      "epoch 42; iter: 0; batch classifier loss: 0.083758; batch adversarial loss: 0.484616\n",
      "epoch 43; iter: 0; batch classifier loss: 0.116543; batch adversarial loss: 0.393401\n",
      "epoch 44; iter: 0; batch classifier loss: 0.109843; batch adversarial loss: 0.440212\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103189; batch adversarial loss: 0.473983\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116581; batch adversarial loss: 0.516690\n",
      "epoch 47; iter: 0; batch classifier loss: 0.075700; batch adversarial loss: 0.335630\n",
      "epoch 48; iter: 0; batch classifier loss: 0.048996; batch adversarial loss: 0.522761\n",
      "epoch 49; iter: 0; batch classifier loss: 0.078308; batch adversarial loss: 0.427478\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087170; batch adversarial loss: 0.441693\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073864; batch adversarial loss: 0.589249\n",
      "epoch 52; iter: 0; batch classifier loss: 0.133050; batch adversarial loss: 0.497743\n",
      "epoch 53; iter: 0; batch classifier loss: 0.068268; batch adversarial loss: 0.444125\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102725; batch adversarial loss: 0.493055\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086791; batch adversarial loss: 0.459899\n",
      "epoch 56; iter: 0; batch classifier loss: 0.057375; batch adversarial loss: 0.462630\n",
      "epoch 57; iter: 0; batch classifier loss: 0.085760; batch adversarial loss: 0.484277\n",
      "epoch 58; iter: 0; batch classifier loss: 0.102252; batch adversarial loss: 0.489382\n",
      "epoch 59; iter: 0; batch classifier loss: 0.058365; batch adversarial loss: 0.420339\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061759; batch adversarial loss: 0.476891\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090509; batch adversarial loss: 0.531031\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083471; batch adversarial loss: 0.467830\n",
      "epoch 63; iter: 0; batch classifier loss: 0.049537; batch adversarial loss: 0.552067\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057519; batch adversarial loss: 0.495211\n",
      "epoch 65; iter: 0; batch classifier loss: 0.076514; batch adversarial loss: 0.494617\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085496; batch adversarial loss: 0.478330\n",
      "epoch 67; iter: 0; batch classifier loss: 0.071711; batch adversarial loss: 0.428778\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059793; batch adversarial loss: 0.486105\n",
      "epoch 69; iter: 0; batch classifier loss: 0.056618; batch adversarial loss: 0.487906\n",
      "epoch 70; iter: 0; batch classifier loss: 0.087926; batch adversarial loss: 0.472780\n",
      "epoch 71; iter: 0; batch classifier loss: 0.088709; batch adversarial loss: 0.287971\n",
      "epoch 72; iter: 0; batch classifier loss: 0.086638; batch adversarial loss: 0.361030\n",
      "epoch 73; iter: 0; batch classifier loss: 0.072397; batch adversarial loss: 0.452220\n",
      "epoch 74; iter: 0; batch classifier loss: 0.029016; batch adversarial loss: 0.440561\n",
      "epoch 75; iter: 0; batch classifier loss: 0.046431; batch adversarial loss: 0.504106\n",
      "epoch 76; iter: 0; batch classifier loss: 0.045155; batch adversarial loss: 0.444110\n",
      "epoch 77; iter: 0; batch classifier loss: 0.031330; batch adversarial loss: 0.535331\n",
      "epoch 78; iter: 0; batch classifier loss: 0.051077; batch adversarial loss: 0.539145\n",
      "epoch 79; iter: 0; batch classifier loss: 0.042623; batch adversarial loss: 0.416517\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060350; batch adversarial loss: 0.500510\n",
      "epoch 81; iter: 0; batch classifier loss: 0.033658; batch adversarial loss: 0.509002\n",
      "epoch 82; iter: 0; batch classifier loss: 0.034815; batch adversarial loss: 0.406953\n",
      "epoch 83; iter: 0; batch classifier loss: 0.045154; batch adversarial loss: 0.465334\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045295; batch adversarial loss: 0.407133\n",
      "epoch 85; iter: 0; batch classifier loss: 0.012586; batch adversarial loss: 0.459722\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040559; batch adversarial loss: 0.405885\n",
      "epoch 87; iter: 0; batch classifier loss: 0.019577; batch adversarial loss: 0.464155\n",
      "epoch 88; iter: 0; batch classifier loss: 0.026019; batch adversarial loss: 0.493195\n",
      "epoch 89; iter: 0; batch classifier loss: 0.049766; batch adversarial loss: 0.456625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.024527; batch adversarial loss: 0.458120\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052443; batch adversarial loss: 0.417329\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044135; batch adversarial loss: 0.420329\n",
      "epoch 93; iter: 0; batch classifier loss: 0.025644; batch adversarial loss: 0.423226\n",
      "epoch 94; iter: 0; batch classifier loss: 0.055773; batch adversarial loss: 0.539573\n",
      "epoch 95; iter: 0; batch classifier loss: 0.022250; batch adversarial loss: 0.469303\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057083; batch adversarial loss: 0.398131\n",
      "epoch 97; iter: 0; batch classifier loss: 0.026694; batch adversarial loss: 0.447923\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062371; batch adversarial loss: 0.548517\n",
      "epoch 99; iter: 0; batch classifier loss: 0.017806; batch adversarial loss: 0.521292\n",
      "epoch 100; iter: 0; batch classifier loss: 0.041617; batch adversarial loss: 0.464062\n",
      "epoch 101; iter: 0; batch classifier loss: 0.052384; batch adversarial loss: 0.379313\n",
      "epoch 102; iter: 0; batch classifier loss: 0.015469; batch adversarial loss: 0.545366\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046179; batch adversarial loss: 0.522331\n",
      "epoch 104; iter: 0; batch classifier loss: 0.026410; batch adversarial loss: 0.479987\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040105; batch adversarial loss: 0.521588\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030740; batch adversarial loss: 0.435667\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036123; batch adversarial loss: 0.536044\n",
      "epoch 108; iter: 0; batch classifier loss: 0.050782; batch adversarial loss: 0.371628\n",
      "epoch 109; iter: 0; batch classifier loss: 0.018460; batch adversarial loss: 0.418138\n",
      "epoch 110; iter: 0; batch classifier loss: 0.012508; batch adversarial loss: 0.414506\n",
      "epoch 111; iter: 0; batch classifier loss: 0.018451; batch adversarial loss: 0.466205\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049887; batch adversarial loss: 0.364485\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027165; batch adversarial loss: 0.594398\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033089; batch adversarial loss: 0.429764\n",
      "epoch 115; iter: 0; batch classifier loss: 0.019619; batch adversarial loss: 0.521072\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030371; batch adversarial loss: 0.354732\n",
      "epoch 117; iter: 0; batch classifier loss: 0.018891; batch adversarial loss: 0.362551\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029869; batch adversarial loss: 0.497090\n",
      "epoch 119; iter: 0; batch classifier loss: 0.010419; batch adversarial loss: 0.483780\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042805; batch adversarial loss: 0.479879\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032074; batch adversarial loss: 0.370561\n",
      "epoch 122; iter: 0; batch classifier loss: 0.023187; batch adversarial loss: 0.457998\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037430; batch adversarial loss: 0.459177\n",
      "epoch 124; iter: 0; batch classifier loss: 0.015545; batch adversarial loss: 0.422805\n",
      "epoch 125; iter: 0; batch classifier loss: 0.006919; batch adversarial loss: 0.502499\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034175; batch adversarial loss: 0.523446\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027217; batch adversarial loss: 0.444099\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018383; batch adversarial loss: 0.551898\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021992; batch adversarial loss: 0.430936\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027754; batch adversarial loss: 0.444588\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030803; batch adversarial loss: 0.512885\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048682; batch adversarial loss: 0.447086\n",
      "epoch 133; iter: 0; batch classifier loss: 0.070566; batch adversarial loss: 0.498780\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015067; batch adversarial loss: 0.462927\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014542; batch adversarial loss: 0.465423\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023820; batch adversarial loss: 0.471572\n",
      "epoch 137; iter: 0; batch classifier loss: 0.016021; batch adversarial loss: 0.429957\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045671; batch adversarial loss: 0.399399\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032407; batch adversarial loss: 0.471532\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014011; batch adversarial loss: 0.546396\n",
      "epoch 141; iter: 0; batch classifier loss: 0.015038; batch adversarial loss: 0.472598\n",
      "epoch 142; iter: 0; batch classifier loss: 0.009792; batch adversarial loss: 0.426100\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028624; batch adversarial loss: 0.364599\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034013; batch adversarial loss: 0.485128\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012326; batch adversarial loss: 0.541069\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035667; batch adversarial loss: 0.419021\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020884; batch adversarial loss: 0.510683\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028881; batch adversarial loss: 0.554133\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026127; batch adversarial loss: 0.417880\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019231; batch adversarial loss: 0.417703\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028953; batch adversarial loss: 0.613973\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023161; batch adversarial loss: 0.510562\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018847; batch adversarial loss: 0.492998\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024706; batch adversarial loss: 0.465752\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035138; batch adversarial loss: 0.476233\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011987; batch adversarial loss: 0.494992\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018923; batch adversarial loss: 0.373057\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024741; batch adversarial loss: 0.389960\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019203; batch adversarial loss: 0.394556\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027067; batch adversarial loss: 0.516549\n",
      "epoch 161; iter: 0; batch classifier loss: 0.041244; batch adversarial loss: 0.497624\n",
      "epoch 162; iter: 0; batch classifier loss: 0.005038; batch adversarial loss: 0.490651\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024203; batch adversarial loss: 0.443397\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020752; batch adversarial loss: 0.415990\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024805; batch adversarial loss: 0.468042\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046240; batch adversarial loss: 0.407270\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011310; batch adversarial loss: 0.453961\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029433; batch adversarial loss: 0.444707\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032239; batch adversarial loss: 0.539751\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011816; batch adversarial loss: 0.469827\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018061; batch adversarial loss: 0.404510\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022059; batch adversarial loss: 0.414519\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024625; batch adversarial loss: 0.483917\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033881; batch adversarial loss: 0.411833\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018189; batch adversarial loss: 0.558882\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028875; batch adversarial loss: 0.475764\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029328; batch adversarial loss: 0.409465\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024484; batch adversarial loss: 0.512663\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011078; batch adversarial loss: 0.475723\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008679; batch adversarial loss: 0.413636\n",
      "epoch 181; iter: 0; batch classifier loss: 0.005446; batch adversarial loss: 0.503516\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009561; batch adversarial loss: 0.474317\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016546; batch adversarial loss: 0.444568\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019836; batch adversarial loss: 0.357511\n",
      "epoch 185; iter: 0; batch classifier loss: 0.043703; batch adversarial loss: 0.533287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.036686; batch adversarial loss: 0.420337\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016324; batch adversarial loss: 0.363731\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020494; batch adversarial loss: 0.539042\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004041; batch adversarial loss: 0.495641\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005484; batch adversarial loss: 0.473243\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008468; batch adversarial loss: 0.472424\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009328; batch adversarial loss: 0.542820\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028372; batch adversarial loss: 0.503013\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010438; batch adversarial loss: 0.444750\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014122; batch adversarial loss: 0.407997\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012357; batch adversarial loss: 0.417603\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021772; batch adversarial loss: 0.415996\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013640; batch adversarial loss: 0.528966\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026922; batch adversarial loss: 0.475423\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708442; batch adversarial loss: 0.712102\n",
      "epoch 1; iter: 0; batch classifier loss: 0.514988; batch adversarial loss: 0.702199\n",
      "epoch 2; iter: 0; batch classifier loss: 0.406092; batch adversarial loss: 0.692610\n",
      "epoch 3; iter: 0; batch classifier loss: 0.325199; batch adversarial loss: 0.676241\n",
      "epoch 4; iter: 0; batch classifier loss: 0.368821; batch adversarial loss: 0.628431\n",
      "epoch 5; iter: 0; batch classifier loss: 0.322946; batch adversarial loss: 0.580250\n",
      "epoch 6; iter: 0; batch classifier loss: 0.289451; batch adversarial loss: 0.586972\n",
      "epoch 7; iter: 0; batch classifier loss: 0.292413; batch adversarial loss: 0.547343\n",
      "epoch 8; iter: 0; batch classifier loss: 0.298924; batch adversarial loss: 0.510962\n",
      "epoch 9; iter: 0; batch classifier loss: 0.271443; batch adversarial loss: 0.517265\n",
      "epoch 10; iter: 0; batch classifier loss: 0.252790; batch adversarial loss: 0.475266\n",
      "epoch 11; iter: 0; batch classifier loss: 0.171582; batch adversarial loss: 0.515845\n",
      "epoch 12; iter: 0; batch classifier loss: 0.222439; batch adversarial loss: 0.436543\n",
      "epoch 13; iter: 0; batch classifier loss: 0.201283; batch adversarial loss: 0.480138\n",
      "epoch 14; iter: 0; batch classifier loss: 0.237021; batch adversarial loss: 0.449945\n",
      "epoch 15; iter: 0; batch classifier loss: 0.182491; batch adversarial loss: 0.448015\n",
      "epoch 16; iter: 0; batch classifier loss: 0.173582; batch adversarial loss: 0.469598\n",
      "epoch 17; iter: 0; batch classifier loss: 0.175989; batch adversarial loss: 0.416652\n",
      "epoch 18; iter: 0; batch classifier loss: 0.120920; batch adversarial loss: 0.373202\n",
      "epoch 19; iter: 0; batch classifier loss: 0.170996; batch adversarial loss: 0.359876\n",
      "epoch 20; iter: 0; batch classifier loss: 0.206855; batch adversarial loss: 0.472125\n",
      "epoch 21; iter: 0; batch classifier loss: 0.175127; batch adversarial loss: 0.470420\n",
      "epoch 22; iter: 0; batch classifier loss: 0.150196; batch adversarial loss: 0.373053\n",
      "epoch 23; iter: 0; batch classifier loss: 0.148270; batch adversarial loss: 0.411961\n",
      "epoch 24; iter: 0; batch classifier loss: 0.172569; batch adversarial loss: 0.434039\n",
      "epoch 25; iter: 0; batch classifier loss: 0.173698; batch adversarial loss: 0.418080\n",
      "epoch 26; iter: 0; batch classifier loss: 0.147070; batch adversarial loss: 0.420103\n",
      "epoch 27; iter: 0; batch classifier loss: 0.136567; batch adversarial loss: 0.393032\n",
      "epoch 28; iter: 0; batch classifier loss: 0.198893; batch adversarial loss: 0.481782\n",
      "epoch 29; iter: 0; batch classifier loss: 0.122910; batch adversarial loss: 0.315674\n",
      "epoch 30; iter: 0; batch classifier loss: 0.163873; batch adversarial loss: 0.417241\n",
      "epoch 31; iter: 0; batch classifier loss: 0.121047; batch adversarial loss: 0.399184\n",
      "epoch 32; iter: 0; batch classifier loss: 0.103796; batch adversarial loss: 0.368204\n",
      "epoch 33; iter: 0; batch classifier loss: 0.141684; batch adversarial loss: 0.370332\n",
      "epoch 34; iter: 0; batch classifier loss: 0.107298; batch adversarial loss: 0.406031\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129892; batch adversarial loss: 0.405371\n",
      "epoch 36; iter: 0; batch classifier loss: 0.104631; batch adversarial loss: 0.401628\n",
      "epoch 37; iter: 0; batch classifier loss: 0.077877; batch adversarial loss: 0.426387\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099161; batch adversarial loss: 0.402907\n",
      "epoch 39; iter: 0; batch classifier loss: 0.090346; batch adversarial loss: 0.379772\n",
      "epoch 40; iter: 0; batch classifier loss: 0.109237; batch adversarial loss: 0.323918\n",
      "epoch 41; iter: 0; batch classifier loss: 0.110109; batch adversarial loss: 0.425076\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106068; batch adversarial loss: 0.435537\n",
      "epoch 43; iter: 0; batch classifier loss: 0.090253; batch adversarial loss: 0.461787\n",
      "epoch 44; iter: 0; batch classifier loss: 0.084144; batch adversarial loss: 0.444835\n",
      "epoch 45; iter: 0; batch classifier loss: 0.120197; batch adversarial loss: 0.440559\n",
      "epoch 46; iter: 0; batch classifier loss: 0.096322; batch adversarial loss: 0.450138\n",
      "epoch 47; iter: 0; batch classifier loss: 0.083823; batch adversarial loss: 0.396108\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092091; batch adversarial loss: 0.371294\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101428; batch adversarial loss: 0.407798\n",
      "epoch 50; iter: 0; batch classifier loss: 0.076221; batch adversarial loss: 0.393426\n",
      "epoch 51; iter: 0; batch classifier loss: 0.074640; batch adversarial loss: 0.323095\n",
      "epoch 52; iter: 0; batch classifier loss: 0.110887; batch adversarial loss: 0.438331\n",
      "epoch 53; iter: 0; batch classifier loss: 0.073526; batch adversarial loss: 0.482820\n",
      "epoch 54; iter: 0; batch classifier loss: 0.092706; batch adversarial loss: 0.381105\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096071; batch adversarial loss: 0.395434\n",
      "epoch 56; iter: 0; batch classifier loss: 0.071946; batch adversarial loss: 0.424080\n",
      "epoch 57; iter: 0; batch classifier loss: 0.057989; batch adversarial loss: 0.398604\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080550; batch adversarial loss: 0.472605\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072626; batch adversarial loss: 0.371795\n",
      "epoch 60; iter: 0; batch classifier loss: 0.090168; batch adversarial loss: 0.439518\n",
      "epoch 61; iter: 0; batch classifier loss: 0.056149; batch adversarial loss: 0.332260\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083351; batch adversarial loss: 0.468338\n",
      "epoch 63; iter: 0; batch classifier loss: 0.068371; batch adversarial loss: 0.421408\n",
      "epoch 64; iter: 0; batch classifier loss: 0.054439; batch adversarial loss: 0.408935\n",
      "epoch 65; iter: 0; batch classifier loss: 0.069796; batch adversarial loss: 0.445610\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066425; batch adversarial loss: 0.403139\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061992; batch adversarial loss: 0.454162\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079286; batch adversarial loss: 0.346976\n",
      "epoch 69; iter: 0; batch classifier loss: 0.089302; batch adversarial loss: 0.521672\n",
      "epoch 70; iter: 0; batch classifier loss: 0.087765; batch adversarial loss: 0.438478\n",
      "epoch 71; iter: 0; batch classifier loss: 0.052222; batch adversarial loss: 0.346637\n",
      "epoch 72; iter: 0; batch classifier loss: 0.046639; batch adversarial loss: 0.397175\n",
      "epoch 73; iter: 0; batch classifier loss: 0.107564; batch adversarial loss: 0.372733\n",
      "epoch 74; iter: 0; batch classifier loss: 0.057654; batch adversarial loss: 0.482299\n",
      "epoch 75; iter: 0; batch classifier loss: 0.058134; batch adversarial loss: 0.461318\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069691; batch adversarial loss: 0.463417\n",
      "epoch 77; iter: 0; batch classifier loss: 0.030761; batch adversarial loss: 0.444988\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064594; batch adversarial loss: 0.434291\n",
      "epoch 79; iter: 0; batch classifier loss: 0.043959; batch adversarial loss: 0.456510\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061653; batch adversarial loss: 0.426387\n",
      "epoch 81; iter: 0; batch classifier loss: 0.063601; batch adversarial loss: 0.525542\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046463; batch adversarial loss: 0.433307\n",
      "epoch 83; iter: 0; batch classifier loss: 0.045771; batch adversarial loss: 0.398308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.058358; batch adversarial loss: 0.433180\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065367; batch adversarial loss: 0.458309\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083427; batch adversarial loss: 0.565865\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055631; batch adversarial loss: 0.421570\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057547; batch adversarial loss: 0.359397\n",
      "epoch 89; iter: 0; batch classifier loss: 0.082928; batch adversarial loss: 0.379787\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050270; batch adversarial loss: 0.360695\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046645; batch adversarial loss: 0.436440\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041498; batch adversarial loss: 0.471816\n",
      "epoch 93; iter: 0; batch classifier loss: 0.027043; batch adversarial loss: 0.467110\n",
      "epoch 94; iter: 0; batch classifier loss: 0.037062; batch adversarial loss: 0.450140\n",
      "epoch 95; iter: 0; batch classifier loss: 0.021121; batch adversarial loss: 0.507786\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035648; batch adversarial loss: 0.444230\n",
      "epoch 97; iter: 0; batch classifier loss: 0.023779; batch adversarial loss: 0.453196\n",
      "epoch 98; iter: 0; batch classifier loss: 0.028491; batch adversarial loss: 0.468206\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054976; batch adversarial loss: 0.489894\n",
      "epoch 100; iter: 0; batch classifier loss: 0.030111; batch adversarial loss: 0.452818\n",
      "epoch 101; iter: 0; batch classifier loss: 0.027261; batch adversarial loss: 0.464945\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027466; batch adversarial loss: 0.431060\n",
      "epoch 103; iter: 0; batch classifier loss: 0.016400; batch adversarial loss: 0.437357\n",
      "epoch 104; iter: 0; batch classifier loss: 0.020390; batch adversarial loss: 0.419684\n",
      "epoch 105; iter: 0; batch classifier loss: 0.015972; batch adversarial loss: 0.388640\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037223; batch adversarial loss: 0.536659\n",
      "epoch 107; iter: 0; batch classifier loss: 0.026118; batch adversarial loss: 0.531497\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044515; batch adversarial loss: 0.489329\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030820; batch adversarial loss: 0.426128\n",
      "epoch 110; iter: 0; batch classifier loss: 0.020173; batch adversarial loss: 0.521593\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035119; batch adversarial loss: 0.518109\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047385; batch adversarial loss: 0.495709\n",
      "epoch 113; iter: 0; batch classifier loss: 0.020145; batch adversarial loss: 0.396105\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037911; batch adversarial loss: 0.567774\n",
      "epoch 115; iter: 0; batch classifier loss: 0.010386; batch adversarial loss: 0.514110\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043249; batch adversarial loss: 0.535954\n",
      "epoch 117; iter: 0; batch classifier loss: 0.070576; batch adversarial loss: 0.574657\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056259; batch adversarial loss: 0.593597\n",
      "epoch 119; iter: 0; batch classifier loss: 0.080097; batch adversarial loss: 0.535545\n",
      "epoch 120; iter: 0; batch classifier loss: 0.090169; batch adversarial loss: 0.557381\n",
      "epoch 121; iter: 0; batch classifier loss: 0.094705; batch adversarial loss: 0.561977\n",
      "epoch 122; iter: 0; batch classifier loss: 0.181643; batch adversarial loss: 0.745532\n",
      "epoch 123; iter: 0; batch classifier loss: 0.116861; batch adversarial loss: 0.668986\n",
      "epoch 124; iter: 0; batch classifier loss: 0.103489; batch adversarial loss: 0.544683\n",
      "epoch 125; iter: 0; batch classifier loss: 0.129459; batch adversarial loss: 0.798366\n",
      "epoch 126; iter: 0; batch classifier loss: 0.126851; batch adversarial loss: 0.644718\n",
      "epoch 127; iter: 0; batch classifier loss: 0.133064; batch adversarial loss: 0.578799\n",
      "epoch 128; iter: 0; batch classifier loss: 0.144378; batch adversarial loss: 0.649322\n",
      "epoch 129; iter: 0; batch classifier loss: 0.122463; batch adversarial loss: 0.553722\n",
      "epoch 130; iter: 0; batch classifier loss: 0.155177; batch adversarial loss: 0.614445\n",
      "epoch 131; iter: 0; batch classifier loss: 0.177246; batch adversarial loss: 0.688314\n",
      "epoch 132; iter: 0; batch classifier loss: 0.149795; batch adversarial loss: 0.643435\n",
      "epoch 133; iter: 0; batch classifier loss: 0.231253; batch adversarial loss: 0.736832\n",
      "epoch 134; iter: 0; batch classifier loss: 0.168731; batch adversarial loss: 0.542154\n",
      "epoch 135; iter: 0; batch classifier loss: 0.200337; batch adversarial loss: 0.772026\n",
      "epoch 136; iter: 0; batch classifier loss: 0.153567; batch adversarial loss: 0.588864\n",
      "epoch 137; iter: 0; batch classifier loss: 0.076151; batch adversarial loss: 0.509741\n",
      "epoch 138; iter: 0; batch classifier loss: 0.126949; batch adversarial loss: 0.579487\n",
      "epoch 139; iter: 0; batch classifier loss: 0.191421; batch adversarial loss: 0.632669\n",
      "epoch 140; iter: 0; batch classifier loss: 0.121686; batch adversarial loss: 0.548068\n",
      "epoch 141; iter: 0; batch classifier loss: 0.123210; batch adversarial loss: 0.541355\n",
      "epoch 142; iter: 0; batch classifier loss: 0.185964; batch adversarial loss: 0.678845\n",
      "epoch 143; iter: 0; batch classifier loss: 0.081309; batch adversarial loss: 0.503736\n",
      "epoch 144; iter: 0; batch classifier loss: 0.132450; batch adversarial loss: 0.491515\n",
      "epoch 145; iter: 0; batch classifier loss: 0.157045; batch adversarial loss: 0.607174\n",
      "epoch 146; iter: 0; batch classifier loss: 0.105259; batch adversarial loss: 0.505410\n",
      "epoch 147; iter: 0; batch classifier loss: 0.195505; batch adversarial loss: 0.641120\n",
      "epoch 148; iter: 0; batch classifier loss: 0.140668; batch adversarial loss: 0.470200\n",
      "epoch 149; iter: 0; batch classifier loss: 0.131610; batch adversarial loss: 0.583840\n",
      "epoch 150; iter: 0; batch classifier loss: 0.197617; batch adversarial loss: 0.626663\n",
      "epoch 151; iter: 0; batch classifier loss: 0.149000; batch adversarial loss: 0.508980\n",
      "epoch 152; iter: 0; batch classifier loss: 0.123629; batch adversarial loss: 0.488145\n",
      "epoch 153; iter: 0; batch classifier loss: 0.112720; batch adversarial loss: 0.422815\n",
      "epoch 154; iter: 0; batch classifier loss: 0.164572; batch adversarial loss: 0.508505\n",
      "epoch 155; iter: 0; batch classifier loss: 0.185916; batch adversarial loss: 0.577222\n",
      "epoch 156; iter: 0; batch classifier loss: 0.095224; batch adversarial loss: 0.354336\n",
      "epoch 157; iter: 0; batch classifier loss: 0.075541; batch adversarial loss: 0.468404\n",
      "epoch 158; iter: 0; batch classifier loss: 0.077760; batch adversarial loss: 0.417483\n",
      "epoch 159; iter: 0; batch classifier loss: 0.090747; batch adversarial loss: 0.426267\n",
      "epoch 160; iter: 0; batch classifier loss: 0.077684; batch adversarial loss: 0.450614\n",
      "epoch 161; iter: 0; batch classifier loss: 0.155639; batch adversarial loss: 0.552963\n",
      "epoch 162; iter: 0; batch classifier loss: 0.118325; batch adversarial loss: 0.444768\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045202; batch adversarial loss: 0.493678\n",
      "epoch 164; iter: 0; batch classifier loss: 0.064999; batch adversarial loss: 0.454290\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028513; batch adversarial loss: 0.425155\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020764; batch adversarial loss: 0.451993\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019418; batch adversarial loss: 0.450573\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030477; batch adversarial loss: 0.457470\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032553; batch adversarial loss: 0.487417\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033641; batch adversarial loss: 0.437926\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029250; batch adversarial loss: 0.326854\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024895; batch adversarial loss: 0.402213\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032618; batch adversarial loss: 0.487482\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027364; batch adversarial loss: 0.472421\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034808; batch adversarial loss: 0.477535\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026473; batch adversarial loss: 0.485070\n",
      "epoch 177; iter: 0; batch classifier loss: 0.057880; batch adversarial loss: 0.530353\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025267; batch adversarial loss: 0.409669\n",
      "epoch 179; iter: 0; batch classifier loss: 0.046752; batch adversarial loss: 0.500964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.071501; batch adversarial loss: 0.442378\n",
      "epoch 181; iter: 0; batch classifier loss: 0.099273; batch adversarial loss: 0.404393\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016122; batch adversarial loss: 0.418821\n",
      "epoch 183; iter: 0; batch classifier loss: 0.090543; batch adversarial loss: 0.450747\n",
      "epoch 184; iter: 0; batch classifier loss: 0.089158; batch adversarial loss: 0.514023\n",
      "epoch 185; iter: 0; batch classifier loss: 0.030045; batch adversarial loss: 0.431807\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040151; batch adversarial loss: 0.406004\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035459; batch adversarial loss: 0.400235\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033577; batch adversarial loss: 0.386313\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033085; batch adversarial loss: 0.448623\n",
      "epoch 190; iter: 0; batch classifier loss: 0.066356; batch adversarial loss: 0.501219\n",
      "epoch 191; iter: 0; batch classifier loss: 0.048686; batch adversarial loss: 0.467673\n",
      "epoch 192; iter: 0; batch classifier loss: 0.056608; batch adversarial loss: 0.555855\n",
      "epoch 193; iter: 0; batch classifier loss: 0.056201; batch adversarial loss: 0.548909\n",
      "epoch 194; iter: 0; batch classifier loss: 0.049059; batch adversarial loss: 0.483997\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036224; batch adversarial loss: 0.364612\n",
      "epoch 196; iter: 0; batch classifier loss: 0.043733; batch adversarial loss: 0.430279\n",
      "epoch 197; iter: 0; batch classifier loss: 0.041611; batch adversarial loss: 0.509736\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041836; batch adversarial loss: 0.469831\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028639; batch adversarial loss: 0.448752\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668936; batch adversarial loss: 0.626450\n",
      "epoch 1; iter: 0; batch classifier loss: 0.538958; batch adversarial loss: 0.624694\n",
      "epoch 2; iter: 0; batch classifier loss: 0.355702; batch adversarial loss: 0.590652\n",
      "epoch 3; iter: 0; batch classifier loss: 0.331234; batch adversarial loss: 0.575629\n",
      "epoch 4; iter: 0; batch classifier loss: 0.359654; batch adversarial loss: 0.541106\n",
      "epoch 5; iter: 0; batch classifier loss: 0.255600; batch adversarial loss: 0.581141\n",
      "epoch 6; iter: 0; batch classifier loss: 0.391407; batch adversarial loss: 0.597445\n",
      "epoch 7; iter: 0; batch classifier loss: 0.284070; batch adversarial loss: 0.531419\n",
      "epoch 8; iter: 0; batch classifier loss: 0.281740; batch adversarial loss: 0.633603\n",
      "epoch 9; iter: 0; batch classifier loss: 0.314391; batch adversarial loss: 0.563652\n",
      "epoch 10; iter: 0; batch classifier loss: 0.302587; batch adversarial loss: 0.500815\n",
      "epoch 11; iter: 0; batch classifier loss: 0.313143; batch adversarial loss: 0.495557\n",
      "epoch 12; iter: 0; batch classifier loss: 0.286083; batch adversarial loss: 0.552933\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245187; batch adversarial loss: 0.437111\n",
      "epoch 14; iter: 0; batch classifier loss: 0.286254; batch adversarial loss: 0.531920\n",
      "epoch 15; iter: 0; batch classifier loss: 0.270557; batch adversarial loss: 0.458086\n",
      "epoch 16; iter: 0; batch classifier loss: 0.217627; batch adversarial loss: 0.453216\n",
      "epoch 17; iter: 0; batch classifier loss: 0.209203; batch adversarial loss: 0.511806\n",
      "epoch 18; iter: 0; batch classifier loss: 0.219585; batch adversarial loss: 0.557757\n",
      "epoch 19; iter: 0; batch classifier loss: 0.191479; batch adversarial loss: 0.510938\n",
      "epoch 20; iter: 0; batch classifier loss: 0.130831; batch adversarial loss: 0.467611\n",
      "epoch 21; iter: 0; batch classifier loss: 0.203806; batch adversarial loss: 0.498610\n",
      "epoch 22; iter: 0; batch classifier loss: 0.202565; batch adversarial loss: 0.491435\n",
      "epoch 23; iter: 0; batch classifier loss: 0.162277; batch adversarial loss: 0.579735\n",
      "epoch 24; iter: 0; batch classifier loss: 0.160746; batch adversarial loss: 0.467500\n",
      "epoch 25; iter: 0; batch classifier loss: 0.167110; batch adversarial loss: 0.505597\n",
      "epoch 26; iter: 0; batch classifier loss: 0.140046; batch adversarial loss: 0.501693\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162132; batch adversarial loss: 0.441694\n",
      "epoch 28; iter: 0; batch classifier loss: 0.175487; batch adversarial loss: 0.516498\n",
      "epoch 29; iter: 0; batch classifier loss: 0.139368; batch adversarial loss: 0.458696\n",
      "epoch 30; iter: 0; batch classifier loss: 0.147120; batch adversarial loss: 0.434150\n",
      "epoch 31; iter: 0; batch classifier loss: 0.187506; batch adversarial loss: 0.482204\n",
      "epoch 32; iter: 0; batch classifier loss: 0.104287; batch adversarial loss: 0.542451\n",
      "epoch 33; iter: 0; batch classifier loss: 0.147089; batch adversarial loss: 0.477326\n",
      "epoch 34; iter: 0; batch classifier loss: 0.111562; batch adversarial loss: 0.472348\n",
      "epoch 35; iter: 0; batch classifier loss: 0.104391; batch adversarial loss: 0.420129\n",
      "epoch 36; iter: 0; batch classifier loss: 0.127385; batch adversarial loss: 0.513165\n",
      "epoch 37; iter: 0; batch classifier loss: 0.174655; batch adversarial loss: 0.483601\n",
      "epoch 38; iter: 0; batch classifier loss: 0.165129; batch adversarial loss: 0.537730\n",
      "epoch 39; iter: 0; batch classifier loss: 0.115770; batch adversarial loss: 0.383450\n",
      "epoch 40; iter: 0; batch classifier loss: 0.174526; batch adversarial loss: 0.367681\n",
      "epoch 41; iter: 0; batch classifier loss: 0.124158; batch adversarial loss: 0.442298\n",
      "epoch 42; iter: 0; batch classifier loss: 0.150974; batch adversarial loss: 0.418350\n",
      "epoch 43; iter: 0; batch classifier loss: 0.165190; batch adversarial loss: 0.423759\n",
      "epoch 44; iter: 0; batch classifier loss: 0.139366; batch adversarial loss: 0.375947\n",
      "epoch 45; iter: 0; batch classifier loss: 0.162414; batch adversarial loss: 0.366935\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127822; batch adversarial loss: 0.497355\n",
      "epoch 47; iter: 0; batch classifier loss: 0.141346; batch adversarial loss: 0.486774\n",
      "epoch 48; iter: 0; batch classifier loss: 0.132074; batch adversarial loss: 0.447339\n",
      "epoch 49; iter: 0; batch classifier loss: 0.155979; batch adversarial loss: 0.342860\n",
      "epoch 50; iter: 0; batch classifier loss: 0.139275; batch adversarial loss: 0.517112\n",
      "epoch 51; iter: 0; batch classifier loss: 0.116437; batch adversarial loss: 0.533492\n",
      "epoch 52; iter: 0; batch classifier loss: 0.210736; batch adversarial loss: 0.455569\n",
      "epoch 53; iter: 0; batch classifier loss: 0.126843; batch adversarial loss: 0.480970\n",
      "epoch 54; iter: 0; batch classifier loss: 0.141245; batch adversarial loss: 0.459925\n",
      "epoch 55; iter: 0; batch classifier loss: 0.150353; batch adversarial loss: 0.390120\n",
      "epoch 56; iter: 0; batch classifier loss: 0.142034; batch adversarial loss: 0.420733\n",
      "epoch 57; iter: 0; batch classifier loss: 0.148792; batch adversarial loss: 0.373135\n",
      "epoch 58; iter: 0; batch classifier loss: 0.176826; batch adversarial loss: 0.421780\n",
      "epoch 59; iter: 0; batch classifier loss: 0.188938; batch adversarial loss: 0.409984\n",
      "epoch 60; iter: 0; batch classifier loss: 0.184710; batch adversarial loss: 0.375175\n",
      "epoch 61; iter: 0; batch classifier loss: 0.173166; batch adversarial loss: 0.450314\n",
      "epoch 62; iter: 0; batch classifier loss: 0.136153; batch adversarial loss: 0.454121\n",
      "epoch 63; iter: 0; batch classifier loss: 0.141139; batch adversarial loss: 0.436453\n",
      "epoch 64; iter: 0; batch classifier loss: 0.146601; batch adversarial loss: 0.407851\n",
      "epoch 65; iter: 0; batch classifier loss: 0.174528; batch adversarial loss: 0.490503\n",
      "epoch 66; iter: 0; batch classifier loss: 0.196936; batch adversarial loss: 0.469282\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171491; batch adversarial loss: 0.409481\n",
      "epoch 68; iter: 0; batch classifier loss: 0.215409; batch adversarial loss: 0.525596\n",
      "epoch 69; iter: 0; batch classifier loss: 0.258442; batch adversarial loss: 0.550151\n",
      "epoch 70; iter: 0; batch classifier loss: 0.183463; batch adversarial loss: 0.372211\n",
      "epoch 71; iter: 0; batch classifier loss: 0.250359; batch adversarial loss: 0.482613\n",
      "epoch 72; iter: 0; batch classifier loss: 0.220171; batch adversarial loss: 0.572224\n",
      "epoch 73; iter: 0; batch classifier loss: 0.160555; batch adversarial loss: 0.511027\n",
      "epoch 74; iter: 0; batch classifier loss: 0.115766; batch adversarial loss: 0.443452\n",
      "epoch 75; iter: 0; batch classifier loss: 0.129672; batch adversarial loss: 0.570010\n",
      "epoch 76; iter: 0; batch classifier loss: 0.225228; batch adversarial loss: 0.482828\n",
      "epoch 77; iter: 0; batch classifier loss: 0.253133; batch adversarial loss: 0.464236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.185887; batch adversarial loss: 0.455317\n",
      "epoch 79; iter: 0; batch classifier loss: 0.192686; batch adversarial loss: 0.364083\n",
      "epoch 80; iter: 0; batch classifier loss: 0.146371; batch adversarial loss: 0.406485\n",
      "epoch 81; iter: 0; batch classifier loss: 0.135543; batch adversarial loss: 0.436535\n",
      "epoch 82; iter: 0; batch classifier loss: 0.206859; batch adversarial loss: 0.461991\n",
      "epoch 83; iter: 0; batch classifier loss: 0.174551; batch adversarial loss: 0.569590\n",
      "epoch 84; iter: 0; batch classifier loss: 0.169834; batch adversarial loss: 0.397445\n",
      "epoch 85; iter: 0; batch classifier loss: 0.170516; batch adversarial loss: 0.481936\n",
      "epoch 86; iter: 0; batch classifier loss: 0.148933; batch adversarial loss: 0.531915\n",
      "epoch 87; iter: 0; batch classifier loss: 0.187012; batch adversarial loss: 0.458725\n",
      "epoch 88; iter: 0; batch classifier loss: 0.196326; batch adversarial loss: 0.396348\n",
      "epoch 89; iter: 0; batch classifier loss: 0.159147; batch adversarial loss: 0.509815\n",
      "epoch 90; iter: 0; batch classifier loss: 0.208968; batch adversarial loss: 0.409171\n",
      "epoch 91; iter: 0; batch classifier loss: 0.175992; batch adversarial loss: 0.422755\n",
      "epoch 92; iter: 0; batch classifier loss: 0.244397; batch adversarial loss: 0.346667\n",
      "epoch 93; iter: 0; batch classifier loss: 0.168941; batch adversarial loss: 0.421039\n",
      "epoch 94; iter: 0; batch classifier loss: 0.170540; batch adversarial loss: 0.458330\n",
      "epoch 95; iter: 0; batch classifier loss: 0.221445; batch adversarial loss: 0.358634\n",
      "epoch 96; iter: 0; batch classifier loss: 0.206863; batch adversarial loss: 0.447884\n",
      "epoch 97; iter: 0; batch classifier loss: 0.288487; batch adversarial loss: 0.297935\n",
      "epoch 98; iter: 0; batch classifier loss: 0.159542; batch adversarial loss: 0.466924\n",
      "epoch 99; iter: 0; batch classifier loss: 0.132804; batch adversarial loss: 0.356663\n",
      "epoch 100; iter: 0; batch classifier loss: 0.151513; batch adversarial loss: 0.471963\n",
      "epoch 101; iter: 0; batch classifier loss: 0.177924; batch adversarial loss: 0.443236\n",
      "epoch 102; iter: 0; batch classifier loss: 0.140673; batch adversarial loss: 0.419602\n",
      "epoch 103; iter: 0; batch classifier loss: 0.107015; batch adversarial loss: 0.444502\n",
      "epoch 104; iter: 0; batch classifier loss: 0.097180; batch adversarial loss: 0.507264\n",
      "epoch 105; iter: 0; batch classifier loss: 0.107559; batch adversarial loss: 0.459551\n",
      "epoch 106; iter: 0; batch classifier loss: 0.093213; batch adversarial loss: 0.470200\n",
      "epoch 107; iter: 0; batch classifier loss: 0.105932; batch adversarial loss: 0.415588\n",
      "epoch 108; iter: 0; batch classifier loss: 0.096370; batch adversarial loss: 0.461734\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055129; batch adversarial loss: 0.413805\n",
      "epoch 110; iter: 0; batch classifier loss: 0.084612; batch adversarial loss: 0.465866\n",
      "epoch 111; iter: 0; batch classifier loss: 0.127992; batch adversarial loss: 0.445084\n",
      "epoch 112; iter: 0; batch classifier loss: 0.077485; batch adversarial loss: 0.449962\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063028; batch adversarial loss: 0.358442\n",
      "epoch 114; iter: 0; batch classifier loss: 0.101817; batch adversarial loss: 0.500800\n",
      "epoch 115; iter: 0; batch classifier loss: 0.093451; batch adversarial loss: 0.402040\n",
      "epoch 116; iter: 0; batch classifier loss: 0.074452; batch adversarial loss: 0.410610\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046453; batch adversarial loss: 0.453499\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063645; batch adversarial loss: 0.402693\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041248; batch adversarial loss: 0.353522\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031436; batch adversarial loss: 0.416707\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027362; batch adversarial loss: 0.491542\n",
      "epoch 122; iter: 0; batch classifier loss: 0.072594; batch adversarial loss: 0.511608\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053548; batch adversarial loss: 0.520189\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022648; batch adversarial loss: 0.449770\n",
      "epoch 125; iter: 0; batch classifier loss: 0.082393; batch adversarial loss: 0.378557\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052129; batch adversarial loss: 0.537093\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041816; batch adversarial loss: 0.464591\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031035; batch adversarial loss: 0.391173\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056358; batch adversarial loss: 0.420775\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031807; batch adversarial loss: 0.571198\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040554; batch adversarial loss: 0.415128\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033928; batch adversarial loss: 0.431887\n",
      "epoch 133; iter: 0; batch classifier loss: 0.050877; batch adversarial loss: 0.398812\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038748; batch adversarial loss: 0.536602\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050535; batch adversarial loss: 0.473938\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028253; batch adversarial loss: 0.521168\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029101; batch adversarial loss: 0.487825\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040107; batch adversarial loss: 0.412635\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036573; batch adversarial loss: 0.428608\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036115; batch adversarial loss: 0.435827\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020828; batch adversarial loss: 0.540016\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036257; batch adversarial loss: 0.418119\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026276; batch adversarial loss: 0.419672\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052855; batch adversarial loss: 0.478661\n",
      "epoch 145; iter: 0; batch classifier loss: 0.049208; batch adversarial loss: 0.384824\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040573; batch adversarial loss: 0.462437\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034957; batch adversarial loss: 0.441867\n",
      "epoch 148; iter: 0; batch classifier loss: 0.051927; batch adversarial loss: 0.442737\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031670; batch adversarial loss: 0.424107\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043622; batch adversarial loss: 0.472286\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027293; batch adversarial loss: 0.464572\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025757; batch adversarial loss: 0.502520\n",
      "epoch 153; iter: 0; batch classifier loss: 0.052471; batch adversarial loss: 0.409350\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011545; batch adversarial loss: 0.418403\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010675; batch adversarial loss: 0.364076\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035358; batch adversarial loss: 0.491659\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033566; batch adversarial loss: 0.447555\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034228; batch adversarial loss: 0.432922\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036568; batch adversarial loss: 0.392007\n",
      "epoch 160; iter: 0; batch classifier loss: 0.049307; batch adversarial loss: 0.426409\n",
      "epoch 161; iter: 0; batch classifier loss: 0.044102; batch adversarial loss: 0.431328\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019136; batch adversarial loss: 0.412246\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029241; batch adversarial loss: 0.444046\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019851; batch adversarial loss: 0.494695\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013517; batch adversarial loss: 0.415554\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026250; batch adversarial loss: 0.449720\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013915; batch adversarial loss: 0.501446\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012423; batch adversarial loss: 0.356039\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024772; batch adversarial loss: 0.389357\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028273; batch adversarial loss: 0.462984\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024117; batch adversarial loss: 0.388702\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020712; batch adversarial loss: 0.430392\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031805; batch adversarial loss: 0.492605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.008742; batch adversarial loss: 0.367515\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039219; batch adversarial loss: 0.450254\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009374; batch adversarial loss: 0.455549\n",
      "epoch 177; iter: 0; batch classifier loss: 0.053057; batch adversarial loss: 0.376808\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015165; batch adversarial loss: 0.468539\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008599; batch adversarial loss: 0.479168\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022140; batch adversarial loss: 0.466919\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032504; batch adversarial loss: 0.468018\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013806; batch adversarial loss: 0.413262\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027970; batch adversarial loss: 0.420664\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006878; batch adversarial loss: 0.428678\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018184; batch adversarial loss: 0.452149\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021327; batch adversarial loss: 0.404103\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039192; batch adversarial loss: 0.458323\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023528; batch adversarial loss: 0.448805\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031995; batch adversarial loss: 0.561263\n",
      "epoch 190; iter: 0; batch classifier loss: 0.043289; batch adversarial loss: 0.425877\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019460; batch adversarial loss: 0.468012\n",
      "epoch 192; iter: 0; batch classifier loss: 0.054358; batch adversarial loss: 0.451059\n",
      "epoch 193; iter: 0; batch classifier loss: 0.041911; batch adversarial loss: 0.386906\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025371; batch adversarial loss: 0.373766\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006717; batch adversarial loss: 0.341876\n",
      "epoch 196; iter: 0; batch classifier loss: 0.043217; batch adversarial loss: 0.415736\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019980; batch adversarial loss: 0.462188\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020407; batch adversarial loss: 0.413826\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024466; batch adversarial loss: 0.379696\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704564; batch adversarial loss: 0.707532\n",
      "epoch 1; iter: 0; batch classifier loss: 0.474013; batch adversarial loss: 0.686839\n",
      "epoch 2; iter: 0; batch classifier loss: 0.409596; batch adversarial loss: 0.653319\n",
      "epoch 3; iter: 0; batch classifier loss: 0.455487; batch adversarial loss: 0.607731\n",
      "epoch 4; iter: 0; batch classifier loss: 0.409559; batch adversarial loss: 0.595353\n",
      "epoch 5; iter: 0; batch classifier loss: 0.369550; batch adversarial loss: 0.534246\n",
      "epoch 6; iter: 0; batch classifier loss: 0.318459; batch adversarial loss: 0.528387\n",
      "epoch 7; iter: 0; batch classifier loss: 0.285655; batch adversarial loss: 0.523625\n",
      "epoch 8; iter: 0; batch classifier loss: 0.355415; batch adversarial loss: 0.511468\n",
      "epoch 9; iter: 0; batch classifier loss: 0.229576; batch adversarial loss: 0.510381\n",
      "epoch 10; iter: 0; batch classifier loss: 0.200804; batch adversarial loss: 0.488501\n",
      "epoch 11; iter: 0; batch classifier loss: 0.242263; batch adversarial loss: 0.428199\n",
      "epoch 12; iter: 0; batch classifier loss: 0.258694; batch adversarial loss: 0.433675\n",
      "epoch 13; iter: 0; batch classifier loss: 0.212019; batch adversarial loss: 0.489140\n",
      "epoch 14; iter: 0; batch classifier loss: 0.216329; batch adversarial loss: 0.442408\n",
      "epoch 15; iter: 0; batch classifier loss: 0.234094; batch adversarial loss: 0.458444\n",
      "epoch 16; iter: 0; batch classifier loss: 0.131197; batch adversarial loss: 0.387969\n",
      "epoch 17; iter: 0; batch classifier loss: 0.144921; batch adversarial loss: 0.449490\n",
      "epoch 18; iter: 0; batch classifier loss: 0.200375; batch adversarial loss: 0.403246\n",
      "epoch 19; iter: 0; batch classifier loss: 0.186876; batch adversarial loss: 0.406154\n",
      "epoch 20; iter: 0; batch classifier loss: 0.121305; batch adversarial loss: 0.422499\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149074; batch adversarial loss: 0.374573\n",
      "epoch 22; iter: 0; batch classifier loss: 0.172550; batch adversarial loss: 0.416003\n",
      "epoch 23; iter: 0; batch classifier loss: 0.137239; batch adversarial loss: 0.396890\n",
      "epoch 24; iter: 0; batch classifier loss: 0.107837; batch adversarial loss: 0.426120\n",
      "epoch 25; iter: 0; batch classifier loss: 0.159142; batch adversarial loss: 0.423657\n",
      "epoch 26; iter: 0; batch classifier loss: 0.163650; batch adversarial loss: 0.455617\n",
      "epoch 27; iter: 0; batch classifier loss: 0.174226; batch adversarial loss: 0.356153\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185137; batch adversarial loss: 0.355895\n",
      "epoch 29; iter: 0; batch classifier loss: 0.133438; batch adversarial loss: 0.397033\n",
      "epoch 30; iter: 0; batch classifier loss: 0.126475; batch adversarial loss: 0.333663\n",
      "epoch 31; iter: 0; batch classifier loss: 0.108533; batch adversarial loss: 0.338312\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172612; batch adversarial loss: 0.463167\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145297; batch adversarial loss: 0.439107\n",
      "epoch 34; iter: 0; batch classifier loss: 0.130252; batch adversarial loss: 0.379472\n",
      "epoch 35; iter: 0; batch classifier loss: 0.127520; batch adversarial loss: 0.471301\n",
      "epoch 36; iter: 0; batch classifier loss: 0.080678; batch adversarial loss: 0.421070\n",
      "epoch 37; iter: 0; batch classifier loss: 0.128738; batch adversarial loss: 0.453449\n",
      "epoch 38; iter: 0; batch classifier loss: 0.100099; batch adversarial loss: 0.386876\n",
      "epoch 39; iter: 0; batch classifier loss: 0.115187; batch adversarial loss: 0.335835\n",
      "epoch 40; iter: 0; batch classifier loss: 0.125583; batch adversarial loss: 0.419050\n",
      "epoch 41; iter: 0; batch classifier loss: 0.079059; batch adversarial loss: 0.381228\n",
      "epoch 42; iter: 0; batch classifier loss: 0.076433; batch adversarial loss: 0.486483\n",
      "epoch 43; iter: 0; batch classifier loss: 0.087989; batch adversarial loss: 0.479770\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107296; batch adversarial loss: 0.395245\n",
      "epoch 45; iter: 0; batch classifier loss: 0.132978; batch adversarial loss: 0.398374\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113095; batch adversarial loss: 0.372373\n",
      "epoch 47; iter: 0; batch classifier loss: 0.127855; batch adversarial loss: 0.424666\n",
      "epoch 48; iter: 0; batch classifier loss: 0.064283; batch adversarial loss: 0.395590\n",
      "epoch 49; iter: 0; batch classifier loss: 0.091368; batch adversarial loss: 0.444318\n",
      "epoch 50; iter: 0; batch classifier loss: 0.103963; batch adversarial loss: 0.300031\n",
      "epoch 51; iter: 0; batch classifier loss: 0.091597; batch adversarial loss: 0.470524\n",
      "epoch 52; iter: 0; batch classifier loss: 0.069398; batch adversarial loss: 0.367500\n",
      "epoch 53; iter: 0; batch classifier loss: 0.113886; batch adversarial loss: 0.423517\n",
      "epoch 54; iter: 0; batch classifier loss: 0.073601; batch adversarial loss: 0.367251\n",
      "epoch 55; iter: 0; batch classifier loss: 0.070727; batch adversarial loss: 0.388876\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067078; batch adversarial loss: 0.370779\n",
      "epoch 57; iter: 0; batch classifier loss: 0.049159; batch adversarial loss: 0.392035\n",
      "epoch 58; iter: 0; batch classifier loss: 0.047327; batch adversarial loss: 0.353340\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082034; batch adversarial loss: 0.412431\n",
      "epoch 60; iter: 0; batch classifier loss: 0.083092; batch adversarial loss: 0.427219\n",
      "epoch 61; iter: 0; batch classifier loss: 0.121273; batch adversarial loss: 0.434618\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083160; batch adversarial loss: 0.372968\n",
      "epoch 63; iter: 0; batch classifier loss: 0.106369; batch adversarial loss: 0.413997\n",
      "epoch 64; iter: 0; batch classifier loss: 0.055988; batch adversarial loss: 0.392695\n",
      "epoch 65; iter: 0; batch classifier loss: 0.062009; batch adversarial loss: 0.488545\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062060; batch adversarial loss: 0.496766\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059107; batch adversarial loss: 0.408126\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054368; batch adversarial loss: 0.455916\n",
      "epoch 69; iter: 0; batch classifier loss: 0.097014; batch adversarial loss: 0.474974\n",
      "epoch 70; iter: 0; batch classifier loss: 0.077824; batch adversarial loss: 0.461913\n",
      "epoch 71; iter: 0; batch classifier loss: 0.074145; batch adversarial loss: 0.390777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.096063; batch adversarial loss: 0.500492\n",
      "epoch 73; iter: 0; batch classifier loss: 0.056945; batch adversarial loss: 0.466811\n",
      "epoch 74; iter: 0; batch classifier loss: 0.029717; batch adversarial loss: 0.349404\n",
      "epoch 75; iter: 0; batch classifier loss: 0.054261; batch adversarial loss: 0.316657\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049150; batch adversarial loss: 0.445634\n",
      "epoch 77; iter: 0; batch classifier loss: 0.088466; batch adversarial loss: 0.467803\n",
      "epoch 78; iter: 0; batch classifier loss: 0.093740; batch adversarial loss: 0.430585\n",
      "epoch 79; iter: 0; batch classifier loss: 0.049233; batch adversarial loss: 0.459676\n",
      "epoch 80; iter: 0; batch classifier loss: 0.042179; batch adversarial loss: 0.483169\n",
      "epoch 81; iter: 0; batch classifier loss: 0.060659; batch adversarial loss: 0.470192\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060450; batch adversarial loss: 0.408791\n",
      "epoch 83; iter: 0; batch classifier loss: 0.135315; batch adversarial loss: 0.363326\n",
      "epoch 84; iter: 0; batch classifier loss: 0.032899; batch adversarial loss: 0.483524\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051592; batch adversarial loss: 0.351268\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065473; batch adversarial loss: 0.408158\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054272; batch adversarial loss: 0.435857\n",
      "epoch 88; iter: 0; batch classifier loss: 0.086646; batch adversarial loss: 0.393936\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057742; batch adversarial loss: 0.507863\n",
      "epoch 90; iter: 0; batch classifier loss: 0.040213; batch adversarial loss: 0.372371\n",
      "epoch 91; iter: 0; batch classifier loss: 0.054738; batch adversarial loss: 0.451451\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047718; batch adversarial loss: 0.432429\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051781; batch adversarial loss: 0.441140\n",
      "epoch 94; iter: 0; batch classifier loss: 0.037313; batch adversarial loss: 0.409871\n",
      "epoch 95; iter: 0; batch classifier loss: 0.034533; batch adversarial loss: 0.477129\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045943; batch adversarial loss: 0.395975\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044538; batch adversarial loss: 0.470618\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062589; batch adversarial loss: 0.453996\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046447; batch adversarial loss: 0.347278\n",
      "epoch 100; iter: 0; batch classifier loss: 0.026181; batch adversarial loss: 0.384373\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049226; batch adversarial loss: 0.449726\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068970; batch adversarial loss: 0.394438\n",
      "epoch 103; iter: 0; batch classifier loss: 0.027032; batch adversarial loss: 0.429126\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044769; batch adversarial loss: 0.450919\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046982; batch adversarial loss: 0.415783\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031939; batch adversarial loss: 0.467039\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041452; batch adversarial loss: 0.398117\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036558; batch adversarial loss: 0.401466\n",
      "epoch 109; iter: 0; batch classifier loss: 0.024724; batch adversarial loss: 0.332251\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030008; batch adversarial loss: 0.442089\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029702; batch adversarial loss: 0.455384\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043717; batch adversarial loss: 0.418530\n",
      "epoch 113; iter: 0; batch classifier loss: 0.013856; batch adversarial loss: 0.409530\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029989; batch adversarial loss: 0.455324\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024237; batch adversarial loss: 0.441356\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052932; batch adversarial loss: 0.547647\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048569; batch adversarial loss: 0.379991\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031516; batch adversarial loss: 0.465255\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019028; batch adversarial loss: 0.556380\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036408; batch adversarial loss: 0.437574\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065464; batch adversarial loss: 0.480253\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026089; batch adversarial loss: 0.453157\n",
      "epoch 123; iter: 0; batch classifier loss: 0.097289; batch adversarial loss: 0.543587\n",
      "epoch 124; iter: 0; batch classifier loss: 0.075268; batch adversarial loss: 0.504701\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053815; batch adversarial loss: 0.579252\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025809; batch adversarial loss: 0.556453\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037130; batch adversarial loss: 0.470355\n",
      "epoch 128; iter: 0; batch classifier loss: 0.077998; batch adversarial loss: 0.500448\n",
      "epoch 129; iter: 0; batch classifier loss: 0.104179; batch adversarial loss: 0.627167\n",
      "epoch 130; iter: 0; batch classifier loss: 0.080673; batch adversarial loss: 0.656685\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024149; batch adversarial loss: 0.526752\n",
      "epoch 132; iter: 0; batch classifier loss: 0.073826; batch adversarial loss: 0.453350\n",
      "epoch 133; iter: 0; batch classifier loss: 0.074002; batch adversarial loss: 0.423493\n",
      "epoch 134; iter: 0; batch classifier loss: 0.087652; batch adversarial loss: 0.521297\n",
      "epoch 135; iter: 0; batch classifier loss: 0.079082; batch adversarial loss: 0.612322\n",
      "epoch 136; iter: 0; batch classifier loss: 0.174378; batch adversarial loss: 0.614291\n",
      "epoch 137; iter: 0; batch classifier loss: 0.087852; batch adversarial loss: 0.501532\n",
      "epoch 138; iter: 0; batch classifier loss: 0.200350; batch adversarial loss: 0.688353\n",
      "epoch 139; iter: 0; batch classifier loss: 0.144460; batch adversarial loss: 0.738358\n",
      "epoch 140; iter: 0; batch classifier loss: 0.167867; batch adversarial loss: 0.658236\n",
      "epoch 141; iter: 0; batch classifier loss: 0.058381; batch adversarial loss: 0.522785\n",
      "epoch 142; iter: 0; batch classifier loss: 0.109630; batch adversarial loss: 0.529609\n",
      "epoch 143; iter: 0; batch classifier loss: 0.132614; batch adversarial loss: 0.601732\n",
      "epoch 144; iter: 0; batch classifier loss: 0.160861; batch adversarial loss: 0.659237\n",
      "epoch 145; iter: 0; batch classifier loss: 0.191853; batch adversarial loss: 0.597440\n",
      "epoch 146; iter: 0; batch classifier loss: 0.129691; batch adversarial loss: 0.496590\n",
      "epoch 147; iter: 0; batch classifier loss: 0.120770; batch adversarial loss: 0.541371\n",
      "epoch 148; iter: 0; batch classifier loss: 0.072321; batch adversarial loss: 0.495867\n",
      "epoch 149; iter: 0; batch classifier loss: 0.156699; batch adversarial loss: 0.633407\n",
      "epoch 150; iter: 0; batch classifier loss: 0.132179; batch adversarial loss: 0.527545\n",
      "epoch 151; iter: 0; batch classifier loss: 0.106916; batch adversarial loss: 0.497546\n",
      "epoch 152; iter: 0; batch classifier loss: 0.142243; batch adversarial loss: 0.596213\n",
      "epoch 153; iter: 0; batch classifier loss: 0.151837; batch adversarial loss: 0.486879\n",
      "epoch 154; iter: 0; batch classifier loss: 0.204354; batch adversarial loss: 0.588614\n",
      "epoch 155; iter: 0; batch classifier loss: 0.108587; batch adversarial loss: 0.603394\n",
      "epoch 156; iter: 0; batch classifier loss: 0.112277; batch adversarial loss: 0.468389\n",
      "epoch 157; iter: 0; batch classifier loss: 0.065743; batch adversarial loss: 0.404453\n",
      "epoch 158; iter: 0; batch classifier loss: 0.089896; batch adversarial loss: 0.489078\n",
      "epoch 159; iter: 0; batch classifier loss: 0.164342; batch adversarial loss: 0.531047\n",
      "epoch 160; iter: 0; batch classifier loss: 0.135533; batch adversarial loss: 0.589667\n",
      "epoch 161; iter: 0; batch classifier loss: 0.116075; batch adversarial loss: 0.408294\n",
      "epoch 162; iter: 0; batch classifier loss: 0.104692; batch adversarial loss: 0.444206\n",
      "epoch 163; iter: 0; batch classifier loss: 0.198559; batch adversarial loss: 0.594833\n",
      "epoch 164; iter: 0; batch classifier loss: 0.076223; batch adversarial loss: 0.439554\n",
      "epoch 165; iter: 0; batch classifier loss: 0.141328; batch adversarial loss: 0.553132\n",
      "epoch 166; iter: 0; batch classifier loss: 0.084412; batch adversarial loss: 0.470596\n",
      "epoch 167; iter: 0; batch classifier loss: 0.168736; batch adversarial loss: 0.578093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.129821; batch adversarial loss: 0.521648\n",
      "epoch 169; iter: 0; batch classifier loss: 0.175304; batch adversarial loss: 0.621376\n",
      "epoch 170; iter: 0; batch classifier loss: 0.098888; batch adversarial loss: 0.493210\n",
      "epoch 171; iter: 0; batch classifier loss: 0.173888; batch adversarial loss: 0.509788\n",
      "epoch 172; iter: 0; batch classifier loss: 0.133919; batch adversarial loss: 0.445071\n",
      "epoch 173; iter: 0; batch classifier loss: 0.091166; batch adversarial loss: 0.507392\n",
      "epoch 174; iter: 0; batch classifier loss: 0.058290; batch adversarial loss: 0.416149\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030628; batch adversarial loss: 0.396552\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020129; batch adversarial loss: 0.469048\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049278; batch adversarial loss: 0.535756\n",
      "epoch 178; iter: 0; batch classifier loss: 0.044246; batch adversarial loss: 0.446239\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037425; batch adversarial loss: 0.441219\n",
      "epoch 180; iter: 0; batch classifier loss: 0.038301; batch adversarial loss: 0.365735\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027198; batch adversarial loss: 0.480336\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023714; batch adversarial loss: 0.409190\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026301; batch adversarial loss: 0.414605\n",
      "epoch 184; iter: 0; batch classifier loss: 0.082790; batch adversarial loss: 0.523494\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036515; batch adversarial loss: 0.350602\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027205; batch adversarial loss: 0.511646\n",
      "epoch 187; iter: 0; batch classifier loss: 0.047283; batch adversarial loss: 0.421665\n",
      "epoch 188; iter: 0; batch classifier loss: 0.036252; batch adversarial loss: 0.479993\n",
      "epoch 189; iter: 0; batch classifier loss: 0.063212; batch adversarial loss: 0.412082\n",
      "epoch 190; iter: 0; batch classifier loss: 0.052058; batch adversarial loss: 0.343639\n",
      "epoch 191; iter: 0; batch classifier loss: 0.042147; batch adversarial loss: 0.470108\n",
      "epoch 192; iter: 0; batch classifier loss: 0.052216; batch adversarial loss: 0.429480\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037592; batch adversarial loss: 0.340760\n",
      "epoch 194; iter: 0; batch classifier loss: 0.087099; batch adversarial loss: 0.488814\n",
      "epoch 195; iter: 0; batch classifier loss: 0.071290; batch adversarial loss: 0.448582\n",
      "epoch 196; iter: 0; batch classifier loss: 0.101859; batch adversarial loss: 0.515198\n",
      "epoch 197; iter: 0; batch classifier loss: 0.076887; batch adversarial loss: 0.510166\n",
      "epoch 198; iter: 0; batch classifier loss: 0.066358; batch adversarial loss: 0.411042\n",
      "epoch 199; iter: 0; batch classifier loss: 0.077399; batch adversarial loss: 0.532128\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701301; batch adversarial loss: 0.956836\n",
      "epoch 1; iter: 0; batch classifier loss: 0.642191; batch adversarial loss: 0.995723\n",
      "epoch 2; iter: 0; batch classifier loss: 0.867400; batch adversarial loss: 1.069413\n",
      "epoch 3; iter: 0; batch classifier loss: 0.897133; batch adversarial loss: 0.956921\n",
      "epoch 4; iter: 0; batch classifier loss: 0.933381; batch adversarial loss: 0.865400\n",
      "epoch 5; iter: 0; batch classifier loss: 0.976387; batch adversarial loss: 0.785624\n",
      "epoch 6; iter: 0; batch classifier loss: 1.007051; batch adversarial loss: 0.743645\n",
      "epoch 7; iter: 0; batch classifier loss: 0.919473; batch adversarial loss: 0.660640\n",
      "epoch 8; iter: 0; batch classifier loss: 0.944924; batch adversarial loss: 0.606972\n",
      "epoch 9; iter: 0; batch classifier loss: 0.649714; batch adversarial loss: 0.565752\n",
      "epoch 10; iter: 0; batch classifier loss: 0.403220; batch adversarial loss: 0.576990\n",
      "epoch 11; iter: 0; batch classifier loss: 0.335338; batch adversarial loss: 0.533278\n",
      "epoch 12; iter: 0; batch classifier loss: 0.275946; batch adversarial loss: 0.498222\n",
      "epoch 13; iter: 0; batch classifier loss: 0.264173; batch adversarial loss: 0.562797\n",
      "epoch 14; iter: 0; batch classifier loss: 0.315383; batch adversarial loss: 0.498087\n",
      "epoch 15; iter: 0; batch classifier loss: 0.277719; batch adversarial loss: 0.537390\n",
      "epoch 16; iter: 0; batch classifier loss: 0.284720; batch adversarial loss: 0.549640\n",
      "epoch 17; iter: 0; batch classifier loss: 0.298047; batch adversarial loss: 0.563386\n",
      "epoch 18; iter: 0; batch classifier loss: 0.290950; batch adversarial loss: 0.468875\n",
      "epoch 19; iter: 0; batch classifier loss: 0.293224; batch adversarial loss: 0.495630\n",
      "epoch 20; iter: 0; batch classifier loss: 0.316826; batch adversarial loss: 0.491839\n",
      "epoch 21; iter: 0; batch classifier loss: 0.264684; batch adversarial loss: 0.498216\n",
      "epoch 22; iter: 0; batch classifier loss: 0.282843; batch adversarial loss: 0.473964\n",
      "epoch 23; iter: 0; batch classifier loss: 0.261653; batch adversarial loss: 0.522442\n",
      "epoch 24; iter: 0; batch classifier loss: 0.288144; batch adversarial loss: 0.425217\n",
      "epoch 25; iter: 0; batch classifier loss: 0.222282; batch adversarial loss: 0.536400\n",
      "epoch 26; iter: 0; batch classifier loss: 0.298271; batch adversarial loss: 0.513013\n",
      "epoch 27; iter: 0; batch classifier loss: 0.291697; batch adversarial loss: 0.492935\n",
      "epoch 28; iter: 0; batch classifier loss: 0.342938; batch adversarial loss: 0.384643\n",
      "epoch 29; iter: 0; batch classifier loss: 0.213769; batch adversarial loss: 0.473259\n",
      "epoch 30; iter: 0; batch classifier loss: 0.280436; batch adversarial loss: 0.423647\n",
      "epoch 31; iter: 0; batch classifier loss: 0.288405; batch adversarial loss: 0.432841\n",
      "epoch 32; iter: 0; batch classifier loss: 0.325496; batch adversarial loss: 0.399458\n",
      "epoch 33; iter: 0; batch classifier loss: 0.222235; batch adversarial loss: 0.466099\n",
      "epoch 34; iter: 0; batch classifier loss: 0.232856; batch adversarial loss: 0.488409\n",
      "epoch 35; iter: 0; batch classifier loss: 0.275516; batch adversarial loss: 0.434081\n",
      "epoch 36; iter: 0; batch classifier loss: 0.283697; batch adversarial loss: 0.502730\n",
      "epoch 37; iter: 0; batch classifier loss: 0.318988; batch adversarial loss: 0.469318\n",
      "epoch 38; iter: 0; batch classifier loss: 0.282458; batch adversarial loss: 0.382330\n",
      "epoch 39; iter: 0; batch classifier loss: 0.241746; batch adversarial loss: 0.436296\n",
      "epoch 40; iter: 0; batch classifier loss: 0.220120; batch adversarial loss: 0.490234\n",
      "epoch 41; iter: 0; batch classifier loss: 0.188233; batch adversarial loss: 0.478007\n",
      "epoch 42; iter: 0; batch classifier loss: 0.184893; batch adversarial loss: 0.467829\n",
      "epoch 43; iter: 0; batch classifier loss: 0.200077; batch adversarial loss: 0.434880\n",
      "epoch 44; iter: 0; batch classifier loss: 0.247969; batch adversarial loss: 0.443405\n",
      "epoch 45; iter: 0; batch classifier loss: 0.255216; batch adversarial loss: 0.452389\n",
      "epoch 46; iter: 0; batch classifier loss: 0.256874; batch adversarial loss: 0.452516\n",
      "epoch 47; iter: 0; batch classifier loss: 0.211440; batch adversarial loss: 0.499603\n",
      "epoch 48; iter: 0; batch classifier loss: 0.219379; batch adversarial loss: 0.400875\n",
      "epoch 49; iter: 0; batch classifier loss: 0.221167; batch adversarial loss: 0.427912\n",
      "epoch 50; iter: 0; batch classifier loss: 0.231932; batch adversarial loss: 0.408481\n",
      "epoch 51; iter: 0; batch classifier loss: 0.258177; batch adversarial loss: 0.432832\n",
      "epoch 52; iter: 0; batch classifier loss: 0.236681; batch adversarial loss: 0.493561\n",
      "epoch 53; iter: 0; batch classifier loss: 0.252510; batch adversarial loss: 0.365124\n",
      "epoch 54; iter: 0; batch classifier loss: 0.211954; batch adversarial loss: 0.425128\n",
      "epoch 55; iter: 0; batch classifier loss: 0.200803; batch adversarial loss: 0.499170\n",
      "epoch 56; iter: 0; batch classifier loss: 0.201346; batch adversarial loss: 0.548731\n",
      "epoch 57; iter: 0; batch classifier loss: 0.218453; batch adversarial loss: 0.410825\n",
      "epoch 58; iter: 0; batch classifier loss: 0.188412; batch adversarial loss: 0.477973\n",
      "epoch 59; iter: 0; batch classifier loss: 0.199170; batch adversarial loss: 0.446277\n",
      "epoch 60; iter: 0; batch classifier loss: 0.199110; batch adversarial loss: 0.530664\n",
      "epoch 61; iter: 0; batch classifier loss: 0.170964; batch adversarial loss: 0.411955\n",
      "epoch 62; iter: 0; batch classifier loss: 0.168396; batch adversarial loss: 0.411852\n",
      "epoch 63; iter: 0; batch classifier loss: 0.200754; batch adversarial loss: 0.470992\n",
      "epoch 64; iter: 0; batch classifier loss: 0.211774; batch adversarial loss: 0.535826\n",
      "epoch 65; iter: 0; batch classifier loss: 0.192114; batch adversarial loss: 0.424221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.204287; batch adversarial loss: 0.423146\n",
      "epoch 67; iter: 0; batch classifier loss: 0.205822; batch adversarial loss: 0.336129\n",
      "epoch 68; iter: 0; batch classifier loss: 0.149120; batch adversarial loss: 0.471570\n",
      "epoch 69; iter: 0; batch classifier loss: 0.152970; batch adversarial loss: 0.508907\n",
      "epoch 70; iter: 0; batch classifier loss: 0.151017; batch adversarial loss: 0.434447\n",
      "epoch 71; iter: 0; batch classifier loss: 0.198613; batch adversarial loss: 0.482673\n",
      "epoch 72; iter: 0; batch classifier loss: 0.260396; batch adversarial loss: 0.495686\n",
      "epoch 73; iter: 0; batch classifier loss: 0.203777; batch adversarial loss: 0.458788\n",
      "epoch 74; iter: 0; batch classifier loss: 0.189457; batch adversarial loss: 0.445158\n",
      "epoch 75; iter: 0; batch classifier loss: 0.165337; batch adversarial loss: 0.533117\n",
      "epoch 76; iter: 0; batch classifier loss: 0.232247; batch adversarial loss: 0.485155\n",
      "epoch 77; iter: 0; batch classifier loss: 0.224140; batch adversarial loss: 0.447077\n",
      "epoch 78; iter: 0; batch classifier loss: 0.150010; batch adversarial loss: 0.434677\n",
      "epoch 79; iter: 0; batch classifier loss: 0.147683; batch adversarial loss: 0.397072\n",
      "epoch 80; iter: 0; batch classifier loss: 0.197327; batch adversarial loss: 0.459437\n",
      "epoch 81; iter: 0; batch classifier loss: 0.248188; batch adversarial loss: 0.396859\n",
      "epoch 82; iter: 0; batch classifier loss: 0.218783; batch adversarial loss: 0.409336\n",
      "epoch 83; iter: 0; batch classifier loss: 0.105046; batch adversarial loss: 0.458813\n",
      "epoch 84; iter: 0; batch classifier loss: 0.159795; batch adversarial loss: 0.408768\n",
      "epoch 85; iter: 0; batch classifier loss: 0.114583; batch adversarial loss: 0.496025\n",
      "epoch 86; iter: 0; batch classifier loss: 0.099807; batch adversarial loss: 0.458262\n",
      "epoch 87; iter: 0; batch classifier loss: 0.166537; batch adversarial loss: 0.395627\n",
      "epoch 88; iter: 0; batch classifier loss: 0.170044; batch adversarial loss: 0.471169\n",
      "epoch 89; iter: 0; batch classifier loss: 0.197654; batch adversarial loss: 0.445638\n",
      "epoch 90; iter: 0; batch classifier loss: 0.238685; batch adversarial loss: 0.409860\n",
      "epoch 91; iter: 0; batch classifier loss: 0.224941; batch adversarial loss: 0.446457\n",
      "epoch 92; iter: 0; batch classifier loss: 0.185745; batch adversarial loss: 0.421968\n",
      "epoch 93; iter: 0; batch classifier loss: 0.207558; batch adversarial loss: 0.421949\n",
      "epoch 94; iter: 0; batch classifier loss: 0.188559; batch adversarial loss: 0.471558\n",
      "epoch 95; iter: 0; batch classifier loss: 0.143201; batch adversarial loss: 0.521044\n",
      "epoch 96; iter: 0; batch classifier loss: 0.185385; batch adversarial loss: 0.359526\n",
      "epoch 97; iter: 0; batch classifier loss: 0.201609; batch adversarial loss: 0.409079\n",
      "epoch 98; iter: 0; batch classifier loss: 0.200288; batch adversarial loss: 0.396673\n",
      "epoch 99; iter: 0; batch classifier loss: 0.129964; batch adversarial loss: 0.408978\n",
      "epoch 100; iter: 0; batch classifier loss: 0.186127; batch adversarial loss: 0.422294\n",
      "epoch 101; iter: 0; batch classifier loss: 0.183956; batch adversarial loss: 0.371648\n",
      "epoch 102; iter: 0; batch classifier loss: 0.286371; batch adversarial loss: 0.434443\n",
      "epoch 103; iter: 0; batch classifier loss: 0.172425; batch adversarial loss: 0.496090\n",
      "epoch 104; iter: 0; batch classifier loss: 0.197409; batch adversarial loss: 0.482601\n",
      "epoch 105; iter: 0; batch classifier loss: 0.204506; batch adversarial loss: 0.483649\n",
      "epoch 106; iter: 0; batch classifier loss: 0.166031; batch adversarial loss: 0.521491\n",
      "epoch 107; iter: 0; batch classifier loss: 0.075511; batch adversarial loss: 0.471253\n",
      "epoch 108; iter: 0; batch classifier loss: 0.094907; batch adversarial loss: 0.408029\n",
      "epoch 109; iter: 0; batch classifier loss: 0.103314; batch adversarial loss: 0.417252\n",
      "epoch 110; iter: 0; batch classifier loss: 0.184482; batch adversarial loss: 0.511740\n",
      "epoch 111; iter: 0; batch classifier loss: 0.194519; batch adversarial loss: 0.410299\n",
      "epoch 112; iter: 0; batch classifier loss: 0.257965; batch adversarial loss: 0.508619\n",
      "epoch 113; iter: 0; batch classifier loss: 0.180031; batch adversarial loss: 0.470023\n",
      "epoch 114; iter: 0; batch classifier loss: 0.220534; batch adversarial loss: 0.474573\n",
      "epoch 115; iter: 0; batch classifier loss: 0.161175; batch adversarial loss: 0.433722\n",
      "epoch 116; iter: 0; batch classifier loss: 0.192470; batch adversarial loss: 0.523513\n",
      "epoch 117; iter: 0; batch classifier loss: 0.163930; batch adversarial loss: 0.496081\n",
      "epoch 118; iter: 0; batch classifier loss: 0.174511; batch adversarial loss: 0.484322\n",
      "epoch 119; iter: 0; batch classifier loss: 0.198146; batch adversarial loss: 0.435386\n",
      "epoch 120; iter: 0; batch classifier loss: 0.164610; batch adversarial loss: 0.396880\n",
      "epoch 121; iter: 0; batch classifier loss: 0.116599; batch adversarial loss: 0.508887\n",
      "epoch 122; iter: 0; batch classifier loss: 0.205645; batch adversarial loss: 0.433896\n",
      "epoch 123; iter: 0; batch classifier loss: 0.192244; batch adversarial loss: 0.546366\n",
      "epoch 124; iter: 0; batch classifier loss: 0.180879; batch adversarial loss: 0.433986\n",
      "epoch 125; iter: 0; batch classifier loss: 0.198606; batch adversarial loss: 0.433720\n",
      "epoch 126; iter: 0; batch classifier loss: 0.127519; batch adversarial loss: 0.471730\n",
      "epoch 127; iter: 0; batch classifier loss: 0.126682; batch adversarial loss: 0.396225\n",
      "epoch 128; iter: 0; batch classifier loss: 0.286098; batch adversarial loss: 0.470852\n",
      "epoch 129; iter: 0; batch classifier loss: 0.144511; batch adversarial loss: 0.509936\n",
      "epoch 130; iter: 0; batch classifier loss: 0.217322; batch adversarial loss: 0.508740\n",
      "epoch 131; iter: 0; batch classifier loss: 0.194148; batch adversarial loss: 0.422134\n",
      "epoch 132; iter: 0; batch classifier loss: 0.200144; batch adversarial loss: 0.446755\n",
      "epoch 133; iter: 0; batch classifier loss: 0.198445; batch adversarial loss: 0.484001\n",
      "epoch 134; iter: 0; batch classifier loss: 0.181382; batch adversarial loss: 0.471321\n",
      "epoch 135; iter: 0; batch classifier loss: 0.126813; batch adversarial loss: 0.471282\n",
      "epoch 136; iter: 0; batch classifier loss: 0.110041; batch adversarial loss: 0.408813\n",
      "epoch 137; iter: 0; batch classifier loss: 0.112696; batch adversarial loss: 0.485138\n",
      "epoch 138; iter: 0; batch classifier loss: 0.123555; batch adversarial loss: 0.532270\n",
      "epoch 139; iter: 0; batch classifier loss: 0.194812; batch adversarial loss: 0.407917\n",
      "epoch 140; iter: 0; batch classifier loss: 0.167008; batch adversarial loss: 0.521661\n",
      "epoch 141; iter: 0; batch classifier loss: 0.258473; batch adversarial loss: 0.408955\n",
      "epoch 142; iter: 0; batch classifier loss: 0.208069; batch adversarial loss: 0.483365\n",
      "epoch 143; iter: 0; batch classifier loss: 0.214494; batch adversarial loss: 0.445768\n",
      "epoch 144; iter: 0; batch classifier loss: 0.192235; batch adversarial loss: 0.397155\n",
      "epoch 145; iter: 0; batch classifier loss: 0.158586; batch adversarial loss: 0.409019\n",
      "epoch 146; iter: 0; batch classifier loss: 0.155497; batch adversarial loss: 0.595329\n",
      "epoch 147; iter: 0; batch classifier loss: 0.132914; batch adversarial loss: 0.508317\n",
      "epoch 148; iter: 0; batch classifier loss: 0.155181; batch adversarial loss: 0.433590\n",
      "epoch 149; iter: 0; batch classifier loss: 0.176536; batch adversarial loss: 0.459359\n",
      "epoch 150; iter: 0; batch classifier loss: 0.163051; batch adversarial loss: 0.546604\n",
      "epoch 151; iter: 0; batch classifier loss: 0.140414; batch adversarial loss: 0.521301\n",
      "epoch 152; iter: 0; batch classifier loss: 0.177852; batch adversarial loss: 0.359181\n",
      "epoch 153; iter: 0; batch classifier loss: 0.108384; batch adversarial loss: 0.346544\n",
      "epoch 154; iter: 0; batch classifier loss: 0.144949; batch adversarial loss: 0.382251\n",
      "epoch 155; iter: 0; batch classifier loss: 0.124548; batch adversarial loss: 0.395499\n",
      "epoch 156; iter: 0; batch classifier loss: 0.190820; batch adversarial loss: 0.382474\n",
      "epoch 157; iter: 0; batch classifier loss: 0.157215; batch adversarial loss: 0.410497\n",
      "epoch 158; iter: 0; batch classifier loss: 0.177568; batch adversarial loss: 0.495583\n",
      "epoch 159; iter: 0; batch classifier loss: 0.193661; batch adversarial loss: 0.372016\n",
      "epoch 160; iter: 0; batch classifier loss: 0.137664; batch adversarial loss: 0.510002\n",
      "epoch 161; iter: 0; batch classifier loss: 0.133319; batch adversarial loss: 0.469113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.156407; batch adversarial loss: 0.434592\n",
      "epoch 163; iter: 0; batch classifier loss: 0.154420; batch adversarial loss: 0.410165\n",
      "epoch 164; iter: 0; batch classifier loss: 0.101368; batch adversarial loss: 0.460822\n",
      "epoch 165; iter: 0; batch classifier loss: 0.077688; batch adversarial loss: 0.480786\n",
      "epoch 166; iter: 0; batch classifier loss: 0.095088; batch adversarial loss: 0.477651\n",
      "epoch 167; iter: 0; batch classifier loss: 0.094009; batch adversarial loss: 0.434347\n",
      "epoch 168; iter: 0; batch classifier loss: 0.080419; batch adversarial loss: 0.444552\n",
      "epoch 169; iter: 0; batch classifier loss: 0.058312; batch adversarial loss: 0.513971\n",
      "epoch 170; iter: 0; batch classifier loss: 0.054147; batch adversarial loss: 0.429594\n",
      "epoch 171; iter: 0; batch classifier loss: 0.053354; batch adversarial loss: 0.393160\n",
      "epoch 172; iter: 0; batch classifier loss: 0.048096; batch adversarial loss: 0.476615\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021745; batch adversarial loss: 0.460384\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035637; batch adversarial loss: 0.357907\n",
      "epoch 175; iter: 0; batch classifier loss: 0.070454; batch adversarial loss: 0.323980\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027982; batch adversarial loss: 0.453213\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024154; batch adversarial loss: 0.428042\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028351; batch adversarial loss: 0.481861\n",
      "epoch 179; iter: 0; batch classifier loss: 0.042658; batch adversarial loss: 0.417773\n",
      "epoch 180; iter: 0; batch classifier loss: 0.045784; batch adversarial loss: 0.444083\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039776; batch adversarial loss: 0.422131\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024940; batch adversarial loss: 0.421693\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031352; batch adversarial loss: 0.351166\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008753; batch adversarial loss: 0.363409\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018105; batch adversarial loss: 0.377669\n",
      "epoch 186; iter: 0; batch classifier loss: 0.042910; batch adversarial loss: 0.422822\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019555; batch adversarial loss: 0.421323\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015557; batch adversarial loss: 0.579842\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020860; batch adversarial loss: 0.458998\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012793; batch adversarial loss: 0.427309\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015245; batch adversarial loss: 0.460656\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030436; batch adversarial loss: 0.465619\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019899; batch adversarial loss: 0.493207\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013245; batch adversarial loss: 0.514407\n",
      "epoch 195; iter: 0; batch classifier loss: 0.041372; batch adversarial loss: 0.462992\n",
      "epoch 196; iter: 0; batch classifier loss: 0.042213; batch adversarial loss: 0.461428\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008277; batch adversarial loss: 0.392133\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026357; batch adversarial loss: 0.405361\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021511; batch adversarial loss: 0.443267\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711822; batch adversarial loss: 0.559364\n",
      "epoch 1; iter: 0; batch classifier loss: 0.370909; batch adversarial loss: 0.597670\n",
      "epoch 2; iter: 0; batch classifier loss: 0.412239; batch adversarial loss: 0.638425\n",
      "epoch 3; iter: 0; batch classifier loss: 0.427039; batch adversarial loss: 0.601252\n",
      "epoch 4; iter: 0; batch classifier loss: 0.452515; batch adversarial loss: 0.599313\n",
      "epoch 5; iter: 0; batch classifier loss: 0.509071; batch adversarial loss: 0.675536\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574190; batch adversarial loss: 0.628469\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604171; batch adversarial loss: 0.570402\n",
      "epoch 8; iter: 0; batch classifier loss: 0.457706; batch adversarial loss: 0.582232\n",
      "epoch 9; iter: 0; batch classifier loss: 0.618279; batch adversarial loss: 0.526170\n",
      "epoch 10; iter: 0; batch classifier loss: 0.469943; batch adversarial loss: 0.559405\n",
      "epoch 11; iter: 0; batch classifier loss: 0.316897; batch adversarial loss: 0.514523\n",
      "epoch 12; iter: 0; batch classifier loss: 0.335408; batch adversarial loss: 0.520952\n",
      "epoch 13; iter: 0; batch classifier loss: 0.321703; batch adversarial loss: 0.475174\n",
      "epoch 14; iter: 0; batch classifier loss: 0.387065; batch adversarial loss: 0.501222\n",
      "epoch 15; iter: 0; batch classifier loss: 0.276004; batch adversarial loss: 0.488241\n",
      "epoch 16; iter: 0; batch classifier loss: 0.216337; batch adversarial loss: 0.510755\n",
      "epoch 17; iter: 0; batch classifier loss: 0.270520; batch adversarial loss: 0.517992\n",
      "epoch 18; iter: 0; batch classifier loss: 0.196690; batch adversarial loss: 0.473826\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223547; batch adversarial loss: 0.517389\n",
      "epoch 20; iter: 0; batch classifier loss: 0.230140; batch adversarial loss: 0.472223\n",
      "epoch 21; iter: 0; batch classifier loss: 0.213912; batch adversarial loss: 0.496365\n",
      "epoch 22; iter: 0; batch classifier loss: 0.271606; batch adversarial loss: 0.486966\n",
      "epoch 23; iter: 0; batch classifier loss: 0.242062; batch adversarial loss: 0.405649\n",
      "epoch 24; iter: 0; batch classifier loss: 0.221981; batch adversarial loss: 0.453777\n",
      "epoch 25; iter: 0; batch classifier loss: 0.247779; batch adversarial loss: 0.546955\n",
      "epoch 26; iter: 0; batch classifier loss: 0.201455; batch adversarial loss: 0.416968\n",
      "epoch 27; iter: 0; batch classifier loss: 0.180112; batch adversarial loss: 0.465966\n",
      "epoch 28; iter: 0; batch classifier loss: 0.182935; batch adversarial loss: 0.529590\n",
      "epoch 29; iter: 0; batch classifier loss: 0.149306; batch adversarial loss: 0.609621\n",
      "epoch 30; iter: 0; batch classifier loss: 0.181155; batch adversarial loss: 0.525597\n",
      "epoch 31; iter: 0; batch classifier loss: 0.190315; batch adversarial loss: 0.510877\n",
      "epoch 32; iter: 0; batch classifier loss: 0.218971; batch adversarial loss: 0.473306\n",
      "epoch 33; iter: 0; batch classifier loss: 0.186713; batch adversarial loss: 0.460766\n",
      "epoch 34; iter: 0; batch classifier loss: 0.204260; batch adversarial loss: 0.513324\n",
      "epoch 35; iter: 0; batch classifier loss: 0.201353; batch adversarial loss: 0.439668\n",
      "epoch 36; iter: 0; batch classifier loss: 0.236062; batch adversarial loss: 0.482141\n",
      "epoch 37; iter: 0; batch classifier loss: 0.239532; batch adversarial loss: 0.436453\n",
      "epoch 38; iter: 0; batch classifier loss: 0.176760; batch adversarial loss: 0.417133\n",
      "epoch 39; iter: 0; batch classifier loss: 0.166772; batch adversarial loss: 0.492986\n",
      "epoch 40; iter: 0; batch classifier loss: 0.156917; batch adversarial loss: 0.434254\n",
      "epoch 41; iter: 0; batch classifier loss: 0.239462; batch adversarial loss: 0.413532\n",
      "epoch 42; iter: 0; batch classifier loss: 0.208343; batch adversarial loss: 0.464954\n",
      "epoch 43; iter: 0; batch classifier loss: 0.143102; batch adversarial loss: 0.487658\n",
      "epoch 44; iter: 0; batch classifier loss: 0.153607; batch adversarial loss: 0.462907\n",
      "epoch 45; iter: 0; batch classifier loss: 0.202178; batch adversarial loss: 0.472027\n",
      "epoch 46; iter: 0; batch classifier loss: 0.211262; batch adversarial loss: 0.468257\n",
      "epoch 47; iter: 0; batch classifier loss: 0.166290; batch adversarial loss: 0.472140\n",
      "epoch 48; iter: 0; batch classifier loss: 0.199751; batch adversarial loss: 0.493423\n",
      "epoch 49; iter: 0; batch classifier loss: 0.201806; batch adversarial loss: 0.474888\n",
      "epoch 50; iter: 0; batch classifier loss: 0.203270; batch adversarial loss: 0.470045\n",
      "epoch 51; iter: 0; batch classifier loss: 0.165920; batch adversarial loss: 0.449160\n",
      "epoch 52; iter: 0; batch classifier loss: 0.178543; batch adversarial loss: 0.483059\n",
      "epoch 53; iter: 0; batch classifier loss: 0.134760; batch adversarial loss: 0.459711\n",
      "epoch 54; iter: 0; batch classifier loss: 0.179588; batch adversarial loss: 0.401486\n",
      "epoch 55; iter: 0; batch classifier loss: 0.129986; batch adversarial loss: 0.458313\n",
      "epoch 56; iter: 0; batch classifier loss: 0.133265; batch adversarial loss: 0.493217\n",
      "epoch 57; iter: 0; batch classifier loss: 0.180312; batch adversarial loss: 0.530100\n",
      "epoch 58; iter: 0; batch classifier loss: 0.149202; batch adversarial loss: 0.495009\n",
      "epoch 59; iter: 0; batch classifier loss: 0.253479; batch adversarial loss: 0.469227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.220549; batch adversarial loss: 0.494133\n",
      "epoch 61; iter: 0; batch classifier loss: 0.130012; batch adversarial loss: 0.424008\n",
      "epoch 62; iter: 0; batch classifier loss: 0.149067; batch adversarial loss: 0.518563\n",
      "epoch 63; iter: 0; batch classifier loss: 0.239203; batch adversarial loss: 0.377195\n",
      "epoch 64; iter: 0; batch classifier loss: 0.121990; batch adversarial loss: 0.481917\n",
      "epoch 65; iter: 0; batch classifier loss: 0.133117; batch adversarial loss: 0.495886\n",
      "epoch 66; iter: 0; batch classifier loss: 0.206695; batch adversarial loss: 0.470951\n",
      "epoch 67; iter: 0; batch classifier loss: 0.152486; batch adversarial loss: 0.471067\n",
      "epoch 68; iter: 0; batch classifier loss: 0.143617; batch adversarial loss: 0.388015\n",
      "epoch 69; iter: 0; batch classifier loss: 0.164180; batch adversarial loss: 0.506454\n",
      "epoch 70; iter: 0; batch classifier loss: 0.238888; batch adversarial loss: 0.400910\n",
      "epoch 71; iter: 0; batch classifier loss: 0.141786; batch adversarial loss: 0.398702\n",
      "epoch 72; iter: 0; batch classifier loss: 0.084340; batch adversarial loss: 0.516694\n",
      "epoch 73; iter: 0; batch classifier loss: 0.109568; batch adversarial loss: 0.521117\n",
      "epoch 74; iter: 0; batch classifier loss: 0.094890; batch adversarial loss: 0.507484\n",
      "epoch 75; iter: 0; batch classifier loss: 0.165235; batch adversarial loss: 0.501613\n",
      "epoch 76; iter: 0; batch classifier loss: 0.108565; batch adversarial loss: 0.447053\n",
      "epoch 77; iter: 0; batch classifier loss: 0.111645; batch adversarial loss: 0.503851\n",
      "epoch 78; iter: 0; batch classifier loss: 0.121741; batch adversarial loss: 0.449925\n",
      "epoch 79; iter: 0; batch classifier loss: 0.152720; batch adversarial loss: 0.470990\n",
      "epoch 80; iter: 0; batch classifier loss: 0.110287; batch adversarial loss: 0.528865\n",
      "epoch 81; iter: 0; batch classifier loss: 0.139790; batch adversarial loss: 0.479351\n",
      "epoch 82; iter: 0; batch classifier loss: 0.108687; batch adversarial loss: 0.525392\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114606; batch adversarial loss: 0.516250\n",
      "epoch 84; iter: 0; batch classifier loss: 0.089667; batch adversarial loss: 0.462065\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083948; batch adversarial loss: 0.545233\n",
      "epoch 86; iter: 0; batch classifier loss: 0.080722; batch adversarial loss: 0.433793\n",
      "epoch 87; iter: 0; batch classifier loss: 0.155618; batch adversarial loss: 0.512575\n",
      "epoch 88; iter: 0; batch classifier loss: 0.103913; batch adversarial loss: 0.458393\n",
      "epoch 89; iter: 0; batch classifier loss: 0.090429; batch adversarial loss: 0.416207\n",
      "epoch 90; iter: 0; batch classifier loss: 0.086970; batch adversarial loss: 0.591687\n",
      "epoch 91; iter: 0; batch classifier loss: 0.080110; batch adversarial loss: 0.421530\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063248; batch adversarial loss: 0.540650\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059828; batch adversarial loss: 0.440052\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041884; batch adversarial loss: 0.480948\n",
      "epoch 95; iter: 0; batch classifier loss: 0.091723; batch adversarial loss: 0.447005\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046752; batch adversarial loss: 0.470328\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077925; batch adversarial loss: 0.469609\n",
      "epoch 98; iter: 0; batch classifier loss: 0.077871; batch adversarial loss: 0.498403\n",
      "epoch 99; iter: 0; batch classifier loss: 0.091958; batch adversarial loss: 0.473393\n",
      "epoch 100; iter: 0; batch classifier loss: 0.119757; batch adversarial loss: 0.458231\n",
      "epoch 101; iter: 0; batch classifier loss: 0.082771; batch adversarial loss: 0.546761\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044662; batch adversarial loss: 0.462925\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058118; batch adversarial loss: 0.458313\n",
      "epoch 104; iter: 0; batch classifier loss: 0.052321; batch adversarial loss: 0.549987\n",
      "epoch 105; iter: 0; batch classifier loss: 0.093134; batch adversarial loss: 0.425838\n",
      "epoch 106; iter: 0; batch classifier loss: 0.086554; batch adversarial loss: 0.503722\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069538; batch adversarial loss: 0.426174\n",
      "epoch 108; iter: 0; batch classifier loss: 0.061386; batch adversarial loss: 0.470333\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038858; batch adversarial loss: 0.444154\n",
      "epoch 110; iter: 0; batch classifier loss: 0.109643; batch adversarial loss: 0.428416\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058272; batch adversarial loss: 0.438546\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044299; batch adversarial loss: 0.410653\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029828; batch adversarial loss: 0.391946\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054623; batch adversarial loss: 0.514581\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054591; batch adversarial loss: 0.437010\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043221; batch adversarial loss: 0.451223\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048936; batch adversarial loss: 0.461522\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069294; batch adversarial loss: 0.453434\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031081; batch adversarial loss: 0.428751\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036003; batch adversarial loss: 0.416576\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051550; batch adversarial loss: 0.461342\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033769; batch adversarial loss: 0.400375\n",
      "epoch 123; iter: 0; batch classifier loss: 0.070014; batch adversarial loss: 0.498025\n",
      "epoch 124; iter: 0; batch classifier loss: 0.047503; batch adversarial loss: 0.524840\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031192; batch adversarial loss: 0.452432\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026031; batch adversarial loss: 0.561121\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051554; batch adversarial loss: 0.491758\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037608; batch adversarial loss: 0.465966\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041560; batch adversarial loss: 0.541542\n",
      "epoch 130; iter: 0; batch classifier loss: 0.049089; batch adversarial loss: 0.492482\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050986; batch adversarial loss: 0.378665\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028991; batch adversarial loss: 0.428412\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018149; batch adversarial loss: 0.478067\n",
      "epoch 134; iter: 0; batch classifier loss: 0.061769; batch adversarial loss: 0.405135\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038492; batch adversarial loss: 0.431967\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040708; batch adversarial loss: 0.559039\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026595; batch adversarial loss: 0.452179\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020479; batch adversarial loss: 0.544194\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022326; batch adversarial loss: 0.545501\n",
      "epoch 140; iter: 0; batch classifier loss: 0.064599; batch adversarial loss: 0.439735\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030977; batch adversarial loss: 0.438524\n",
      "epoch 142; iter: 0; batch classifier loss: 0.051316; batch adversarial loss: 0.480451\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021314; batch adversarial loss: 0.556375\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031247; batch adversarial loss: 0.489530\n",
      "epoch 145; iter: 0; batch classifier loss: 0.008561; batch adversarial loss: 0.515089\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041524; batch adversarial loss: 0.468359\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029581; batch adversarial loss: 0.417282\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029348; batch adversarial loss: 0.403677\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016272; batch adversarial loss: 0.589635\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012459; batch adversarial loss: 0.548342\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023047; batch adversarial loss: 0.469916\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030105; batch adversarial loss: 0.440060\n",
      "epoch 153; iter: 0; batch classifier loss: 0.055666; batch adversarial loss: 0.412568\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014654; batch adversarial loss: 0.554994\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020811; batch adversarial loss: 0.567066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.012823; batch adversarial loss: 0.460046\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028902; batch adversarial loss: 0.578586\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015386; batch adversarial loss: 0.350594\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014276; batch adversarial loss: 0.504484\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016418; batch adversarial loss: 0.469241\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013983; batch adversarial loss: 0.382824\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032154; batch adversarial loss: 0.453666\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032055; batch adversarial loss: 0.441355\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032436; batch adversarial loss: 0.483073\n",
      "epoch 165; iter: 0; batch classifier loss: 0.052956; batch adversarial loss: 0.398842\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020345; batch adversarial loss: 0.540072\n",
      "epoch 167; iter: 0; batch classifier loss: 0.043269; batch adversarial loss: 0.420051\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019468; batch adversarial loss: 0.455312\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017485; batch adversarial loss: 0.437011\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013603; batch adversarial loss: 0.426108\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011819; batch adversarial loss: 0.483710\n",
      "epoch 172; iter: 0; batch classifier loss: 0.042864; batch adversarial loss: 0.486341\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023180; batch adversarial loss: 0.452236\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026222; batch adversarial loss: 0.477625\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025475; batch adversarial loss: 0.468841\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032021; batch adversarial loss: 0.526651\n",
      "epoch 177; iter: 0; batch classifier loss: 0.047445; batch adversarial loss: 0.514275\n",
      "epoch 178; iter: 0; batch classifier loss: 0.051389; batch adversarial loss: 0.471904\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009747; batch adversarial loss: 0.549058\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035300; batch adversarial loss: 0.537673\n",
      "epoch 181; iter: 0; batch classifier loss: 0.043473; batch adversarial loss: 0.461018\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038605; batch adversarial loss: 0.483693\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016016; batch adversarial loss: 0.399158\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026747; batch adversarial loss: 0.455047\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011901; batch adversarial loss: 0.427097\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011021; batch adversarial loss: 0.408141\n",
      "epoch 187; iter: 0; batch classifier loss: 0.064296; batch adversarial loss: 0.506582\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025154; batch adversarial loss: 0.461579\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041473; batch adversarial loss: 0.451196\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025767; batch adversarial loss: 0.555673\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016231; batch adversarial loss: 0.466632\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018878; batch adversarial loss: 0.552838\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034558; batch adversarial loss: 0.431508\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016944; batch adversarial loss: 0.456759\n",
      "epoch 195; iter: 0; batch classifier loss: 0.032535; batch adversarial loss: 0.536196\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030000; batch adversarial loss: 0.415481\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016202; batch adversarial loss: 0.410237\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032124; batch adversarial loss: 0.483429\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024991; batch adversarial loss: 0.417736\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669275; batch adversarial loss: 0.884205\n",
      "epoch 1; iter: 0; batch classifier loss: 0.432381; batch adversarial loss: 0.998754\n",
      "epoch 2; iter: 0; batch classifier loss: 0.606259; batch adversarial loss: 0.902890\n",
      "epoch 3; iter: 0; batch classifier loss: 0.499662; batch adversarial loss: 0.915710\n",
      "epoch 4; iter: 0; batch classifier loss: 0.482784; batch adversarial loss: 0.847100\n",
      "epoch 5; iter: 0; batch classifier loss: 0.377294; batch adversarial loss: 0.753633\n",
      "epoch 6; iter: 0; batch classifier loss: 0.390898; batch adversarial loss: 0.677766\n",
      "epoch 7; iter: 0; batch classifier loss: 0.325109; batch adversarial loss: 0.642164\n",
      "epoch 8; iter: 0; batch classifier loss: 0.268156; batch adversarial loss: 0.607897\n",
      "epoch 9; iter: 0; batch classifier loss: 0.168940; batch adversarial loss: 0.571637\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258846; batch adversarial loss: 0.564950\n",
      "epoch 11; iter: 0; batch classifier loss: 0.245217; batch adversarial loss: 0.521116\n",
      "epoch 12; iter: 0; batch classifier loss: 0.318220; batch adversarial loss: 0.527629\n",
      "epoch 13; iter: 0; batch classifier loss: 0.290536; batch adversarial loss: 0.525016\n",
      "epoch 14; iter: 0; batch classifier loss: 0.234569; batch adversarial loss: 0.514385\n",
      "epoch 15; iter: 0; batch classifier loss: 0.295732; batch adversarial loss: 0.518670\n",
      "epoch 16; iter: 0; batch classifier loss: 0.262086; batch adversarial loss: 0.519087\n",
      "epoch 17; iter: 0; batch classifier loss: 0.218751; batch adversarial loss: 0.568696\n",
      "epoch 18; iter: 0; batch classifier loss: 0.236786; batch adversarial loss: 0.536444\n",
      "epoch 19; iter: 0; batch classifier loss: 0.169888; batch adversarial loss: 0.516554\n",
      "epoch 20; iter: 0; batch classifier loss: 0.296469; batch adversarial loss: 0.395572\n",
      "epoch 21; iter: 0; batch classifier loss: 0.205380; batch adversarial loss: 0.490606\n",
      "epoch 22; iter: 0; batch classifier loss: 0.196694; batch adversarial loss: 0.471221\n",
      "epoch 23; iter: 0; batch classifier loss: 0.173492; batch adversarial loss: 0.452037\n",
      "epoch 24; iter: 0; batch classifier loss: 0.200878; batch adversarial loss: 0.510254\n",
      "epoch 25; iter: 0; batch classifier loss: 0.191739; batch adversarial loss: 0.424452\n",
      "epoch 26; iter: 0; batch classifier loss: 0.160291; batch adversarial loss: 0.418575\n",
      "epoch 27; iter: 0; batch classifier loss: 0.145062; batch adversarial loss: 0.475821\n",
      "epoch 28; iter: 0; batch classifier loss: 0.123036; batch adversarial loss: 0.448756\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180634; batch adversarial loss: 0.457991\n",
      "epoch 30; iter: 0; batch classifier loss: 0.097340; batch adversarial loss: 0.375853\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170555; batch adversarial loss: 0.418808\n",
      "epoch 32; iter: 0; batch classifier loss: 0.142016; batch adversarial loss: 0.377549\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128829; batch adversarial loss: 0.503224\n",
      "epoch 34; iter: 0; batch classifier loss: 0.125395; batch adversarial loss: 0.381365\n",
      "epoch 35; iter: 0; batch classifier loss: 0.115816; batch adversarial loss: 0.305515\n",
      "epoch 36; iter: 0; batch classifier loss: 0.078990; batch adversarial loss: 0.426579\n",
      "epoch 37; iter: 0; batch classifier loss: 0.069128; batch adversarial loss: 0.452936\n",
      "epoch 38; iter: 0; batch classifier loss: 0.121437; batch adversarial loss: 0.385119\n",
      "epoch 39; iter: 0; batch classifier loss: 0.149418; batch adversarial loss: 0.473249\n",
      "epoch 40; iter: 0; batch classifier loss: 0.125251; batch adversarial loss: 0.404426\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104275; batch adversarial loss: 0.349300\n",
      "epoch 42; iter: 0; batch classifier loss: 0.094878; batch adversarial loss: 0.372988\n",
      "epoch 43; iter: 0; batch classifier loss: 0.106285; batch adversarial loss: 0.433904\n",
      "epoch 44; iter: 0; batch classifier loss: 0.104091; batch adversarial loss: 0.415808\n",
      "epoch 45; iter: 0; batch classifier loss: 0.107541; batch adversarial loss: 0.493208\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102035; batch adversarial loss: 0.520090\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100672; batch adversarial loss: 0.463527\n",
      "epoch 48; iter: 0; batch classifier loss: 0.071589; batch adversarial loss: 0.435406\n",
      "epoch 49; iter: 0; batch classifier loss: 0.073290; batch adversarial loss: 0.500854\n",
      "epoch 50; iter: 0; batch classifier loss: 0.081526; batch adversarial loss: 0.466702\n",
      "epoch 51; iter: 0; batch classifier loss: 0.114536; batch adversarial loss: 0.403872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.082086; batch adversarial loss: 0.359254\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076869; batch adversarial loss: 0.415962\n",
      "epoch 54; iter: 0; batch classifier loss: 0.107534; batch adversarial loss: 0.443083\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089593; batch adversarial loss: 0.398305\n",
      "epoch 56; iter: 0; batch classifier loss: 0.054961; batch adversarial loss: 0.391635\n",
      "epoch 57; iter: 0; batch classifier loss: 0.123681; batch adversarial loss: 0.428834\n",
      "epoch 58; iter: 0; batch classifier loss: 0.040574; batch adversarial loss: 0.456298\n",
      "epoch 59; iter: 0; batch classifier loss: 0.064918; batch adversarial loss: 0.391282\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118892; batch adversarial loss: 0.492439\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104868; batch adversarial loss: 0.452717\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082856; batch adversarial loss: 0.457001\n",
      "epoch 63; iter: 0; batch classifier loss: 0.108895; batch adversarial loss: 0.429386\n",
      "epoch 64; iter: 0; batch classifier loss: 0.056458; batch adversarial loss: 0.444935\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065782; batch adversarial loss: 0.454998\n",
      "epoch 66; iter: 0; batch classifier loss: 0.048337; batch adversarial loss: 0.366271\n",
      "epoch 67; iter: 0; batch classifier loss: 0.060865; batch adversarial loss: 0.399395\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071342; batch adversarial loss: 0.431320\n",
      "epoch 69; iter: 0; batch classifier loss: 0.098313; batch adversarial loss: 0.400385\n",
      "epoch 70; iter: 0; batch classifier loss: 0.050954; batch adversarial loss: 0.410581\n",
      "epoch 71; iter: 0; batch classifier loss: 0.053462; batch adversarial loss: 0.395566\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081243; batch adversarial loss: 0.420922\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077243; batch adversarial loss: 0.415240\n",
      "epoch 74; iter: 0; batch classifier loss: 0.083602; batch adversarial loss: 0.496219\n",
      "epoch 75; iter: 0; batch classifier loss: 0.087643; batch adversarial loss: 0.475050\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069709; batch adversarial loss: 0.467860\n",
      "epoch 77; iter: 0; batch classifier loss: 0.105990; batch adversarial loss: 0.492844\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077435; batch adversarial loss: 0.478410\n",
      "epoch 79; iter: 0; batch classifier loss: 0.079975; batch adversarial loss: 0.456605\n",
      "epoch 80; iter: 0; batch classifier loss: 0.051260; batch adversarial loss: 0.367922\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050506; batch adversarial loss: 0.396886\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053714; batch adversarial loss: 0.368209\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049281; batch adversarial loss: 0.421574\n",
      "epoch 84; iter: 0; batch classifier loss: 0.050138; batch adversarial loss: 0.367040\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075430; batch adversarial loss: 0.443865\n",
      "epoch 86; iter: 0; batch classifier loss: 0.060261; batch adversarial loss: 0.386129\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067109; batch adversarial loss: 0.508044\n",
      "epoch 88; iter: 0; batch classifier loss: 0.111522; batch adversarial loss: 0.419861\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042681; batch adversarial loss: 0.381655\n",
      "epoch 90; iter: 0; batch classifier loss: 0.070987; batch adversarial loss: 0.483945\n",
      "epoch 91; iter: 0; batch classifier loss: 0.094896; batch adversarial loss: 0.365901\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050175; batch adversarial loss: 0.394119\n",
      "epoch 93; iter: 0; batch classifier loss: 0.103969; batch adversarial loss: 0.412618\n",
      "epoch 94; iter: 0; batch classifier loss: 0.063525; batch adversarial loss: 0.484474\n",
      "epoch 95; iter: 0; batch classifier loss: 0.078075; batch adversarial loss: 0.316693\n",
      "epoch 96; iter: 0; batch classifier loss: 0.033665; batch adversarial loss: 0.362100\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052938; batch adversarial loss: 0.421910\n",
      "epoch 98; iter: 0; batch classifier loss: 0.084364; batch adversarial loss: 0.389221\n",
      "epoch 99; iter: 0; batch classifier loss: 0.111962; batch adversarial loss: 0.446576\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051142; batch adversarial loss: 0.462563\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070671; batch adversarial loss: 0.412352\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054541; batch adversarial loss: 0.378075\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060447; batch adversarial loss: 0.389083\n",
      "epoch 104; iter: 0; batch classifier loss: 0.024627; batch adversarial loss: 0.331910\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076585; batch adversarial loss: 0.474585\n",
      "epoch 106; iter: 0; batch classifier loss: 0.076021; batch adversarial loss: 0.469760\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056404; batch adversarial loss: 0.417353\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048329; batch adversarial loss: 0.307998\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064559; batch adversarial loss: 0.409660\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064374; batch adversarial loss: 0.424868\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039799; batch adversarial loss: 0.396494\n",
      "epoch 112; iter: 0; batch classifier loss: 0.058802; batch adversarial loss: 0.426230\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052998; batch adversarial loss: 0.452515\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045613; batch adversarial loss: 0.578337\n",
      "epoch 115; iter: 0; batch classifier loss: 0.069594; batch adversarial loss: 0.393983\n",
      "epoch 116; iter: 0; batch classifier loss: 0.099388; batch adversarial loss: 0.414966\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067222; batch adversarial loss: 0.465300\n",
      "epoch 118; iter: 0; batch classifier loss: 0.055785; batch adversarial loss: 0.457081\n",
      "epoch 119; iter: 0; batch classifier loss: 0.071681; batch adversarial loss: 0.462447\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043733; batch adversarial loss: 0.438765\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065633; batch adversarial loss: 0.507605\n",
      "epoch 122; iter: 0; batch classifier loss: 0.075111; batch adversarial loss: 0.452197\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043992; batch adversarial loss: 0.366813\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059318; batch adversarial loss: 0.383820\n",
      "epoch 125; iter: 0; batch classifier loss: 0.092130; batch adversarial loss: 0.407640\n",
      "epoch 126; iter: 0; batch classifier loss: 0.086144; batch adversarial loss: 0.417511\n",
      "epoch 127; iter: 0; batch classifier loss: 0.038790; batch adversarial loss: 0.383065\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043321; batch adversarial loss: 0.443064\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039137; batch adversarial loss: 0.380449\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050554; batch adversarial loss: 0.367301\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026119; batch adversarial loss: 0.449019\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024809; batch adversarial loss: 0.307039\n",
      "epoch 133; iter: 0; batch classifier loss: 0.078779; batch adversarial loss: 0.504332\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034299; batch adversarial loss: 0.476267\n",
      "epoch 135; iter: 0; batch classifier loss: 0.052619; batch adversarial loss: 0.510035\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044996; batch adversarial loss: 0.416615\n",
      "epoch 137; iter: 0; batch classifier loss: 0.081610; batch adversarial loss: 0.431907\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026269; batch adversarial loss: 0.417419\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050949; batch adversarial loss: 0.405934\n",
      "epoch 140; iter: 0; batch classifier loss: 0.103582; batch adversarial loss: 0.468367\n",
      "epoch 141; iter: 0; batch classifier loss: 0.080022; batch adversarial loss: 0.509836\n",
      "epoch 142; iter: 0; batch classifier loss: 0.059935; batch adversarial loss: 0.534540\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020879; batch adversarial loss: 0.376346\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036912; batch adversarial loss: 0.380553\n",
      "epoch 145; iter: 0; batch classifier loss: 0.076370; batch adversarial loss: 0.440210\n",
      "epoch 146; iter: 0; batch classifier loss: 0.058848; batch adversarial loss: 0.359080\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040499; batch adversarial loss: 0.400048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.048838; batch adversarial loss: 0.421712\n",
      "epoch 149; iter: 0; batch classifier loss: 0.062082; batch adversarial loss: 0.412100\n",
      "epoch 150; iter: 0; batch classifier loss: 0.077119; batch adversarial loss: 0.526610\n",
      "epoch 151; iter: 0; batch classifier loss: 0.078390; batch adversarial loss: 0.475781\n",
      "epoch 152; iter: 0; batch classifier loss: 0.063498; batch adversarial loss: 0.413503\n",
      "epoch 153; iter: 0; batch classifier loss: 0.057997; batch adversarial loss: 0.471078\n",
      "epoch 154; iter: 0; batch classifier loss: 0.059305; batch adversarial loss: 0.322189\n",
      "epoch 155; iter: 0; batch classifier loss: 0.051597; batch adversarial loss: 0.504266\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045657; batch adversarial loss: 0.406086\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024442; batch adversarial loss: 0.406458\n",
      "epoch 158; iter: 0; batch classifier loss: 0.088010; batch adversarial loss: 0.522124\n",
      "epoch 159; iter: 0; batch classifier loss: 0.071316; batch adversarial loss: 0.349890\n",
      "epoch 160; iter: 0; batch classifier loss: 0.055297; batch adversarial loss: 0.422591\n",
      "epoch 161; iter: 0; batch classifier loss: 0.101017; batch adversarial loss: 0.410810\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046555; batch adversarial loss: 0.423611\n",
      "epoch 163; iter: 0; batch classifier loss: 0.058441; batch adversarial loss: 0.426857\n",
      "epoch 164; iter: 0; batch classifier loss: 0.055937; batch adversarial loss: 0.425311\n",
      "epoch 165; iter: 0; batch classifier loss: 0.062910; batch adversarial loss: 0.446839\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045051; batch adversarial loss: 0.340733\n",
      "epoch 167; iter: 0; batch classifier loss: 0.044851; batch adversarial loss: 0.370036\n",
      "epoch 168; iter: 0; batch classifier loss: 0.047719; batch adversarial loss: 0.451191\n",
      "epoch 169; iter: 0; batch classifier loss: 0.082085; batch adversarial loss: 0.425099\n",
      "epoch 170; iter: 0; batch classifier loss: 0.059738; batch adversarial loss: 0.442951\n",
      "epoch 171; iter: 0; batch classifier loss: 0.065520; batch adversarial loss: 0.354388\n",
      "epoch 172; iter: 0; batch classifier loss: 0.054607; batch adversarial loss: 0.384605\n",
      "epoch 173; iter: 0; batch classifier loss: 0.055893; batch adversarial loss: 0.488256\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039994; batch adversarial loss: 0.444314\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036440; batch adversarial loss: 0.502339\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033975; batch adversarial loss: 0.425713\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037014; batch adversarial loss: 0.415740\n",
      "epoch 178; iter: 0; batch classifier loss: 0.046941; batch adversarial loss: 0.395547\n",
      "epoch 179; iter: 0; batch classifier loss: 0.061251; batch adversarial loss: 0.449110\n",
      "epoch 180; iter: 0; batch classifier loss: 0.065941; batch adversarial loss: 0.379488\n",
      "epoch 181; iter: 0; batch classifier loss: 0.048799; batch adversarial loss: 0.475620\n",
      "epoch 182; iter: 0; batch classifier loss: 0.054646; batch adversarial loss: 0.519714\n",
      "epoch 183; iter: 0; batch classifier loss: 0.066452; batch adversarial loss: 0.396356\n",
      "epoch 184; iter: 0; batch classifier loss: 0.056978; batch adversarial loss: 0.378708\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032947; batch adversarial loss: 0.450687\n",
      "epoch 186; iter: 0; batch classifier loss: 0.043028; batch adversarial loss: 0.371551\n",
      "epoch 187; iter: 0; batch classifier loss: 0.085408; batch adversarial loss: 0.331308\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027298; batch adversarial loss: 0.515152\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033930; batch adversarial loss: 0.411357\n",
      "epoch 190; iter: 0; batch classifier loss: 0.054299; batch adversarial loss: 0.470273\n",
      "epoch 191; iter: 0; batch classifier loss: 0.044104; batch adversarial loss: 0.467012\n",
      "epoch 192; iter: 0; batch classifier loss: 0.047538; batch adversarial loss: 0.480370\n",
      "epoch 193; iter: 0; batch classifier loss: 0.041132; batch adversarial loss: 0.525458\n",
      "epoch 194; iter: 0; batch classifier loss: 0.043216; batch adversarial loss: 0.384604\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025515; batch adversarial loss: 0.460387\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021077; batch adversarial loss: 0.444204\n",
      "epoch 197; iter: 0; batch classifier loss: 0.042660; batch adversarial loss: 0.394504\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024275; batch adversarial loss: 0.437035\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024881; batch adversarial loss: 0.436349\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693274; batch adversarial loss: 0.863715\n",
      "epoch 1; iter: 0; batch classifier loss: 0.410695; batch adversarial loss: 0.802302\n",
      "epoch 2; iter: 0; batch classifier loss: 0.376919; batch adversarial loss: 0.840969\n",
      "epoch 3; iter: 0; batch classifier loss: 0.347550; batch adversarial loss: 0.741988\n",
      "epoch 4; iter: 0; batch classifier loss: 0.416711; batch adversarial loss: 0.686565\n",
      "epoch 5; iter: 0; batch classifier loss: 0.341398; batch adversarial loss: 0.656873\n",
      "epoch 6; iter: 0; batch classifier loss: 0.423128; batch adversarial loss: 0.613334\n",
      "epoch 7; iter: 0; batch classifier loss: 0.276757; batch adversarial loss: 0.604300\n",
      "epoch 8; iter: 0; batch classifier loss: 0.353452; batch adversarial loss: 0.566656\n",
      "epoch 9; iter: 0; batch classifier loss: 0.243669; batch adversarial loss: 0.605040\n",
      "epoch 10; iter: 0; batch classifier loss: 0.246563; batch adversarial loss: 0.551237\n",
      "epoch 11; iter: 0; batch classifier loss: 0.309715; batch adversarial loss: 0.506092\n",
      "epoch 12; iter: 0; batch classifier loss: 0.321842; batch adversarial loss: 0.542129\n",
      "epoch 13; iter: 0; batch classifier loss: 0.237309; batch adversarial loss: 0.485232\n",
      "epoch 14; iter: 0; batch classifier loss: 0.298662; batch adversarial loss: 0.544366\n",
      "epoch 15; iter: 0; batch classifier loss: 0.336232; batch adversarial loss: 0.450360\n",
      "epoch 16; iter: 0; batch classifier loss: 0.236047; batch adversarial loss: 0.460262\n",
      "epoch 17; iter: 0; batch classifier loss: 0.255615; batch adversarial loss: 0.488392\n",
      "epoch 18; iter: 0; batch classifier loss: 0.319065; batch adversarial loss: 0.432682\n",
      "epoch 19; iter: 0; batch classifier loss: 0.324971; batch adversarial loss: 0.421716\n",
      "epoch 20; iter: 0; batch classifier loss: 0.303240; batch adversarial loss: 0.416033\n",
      "epoch 21; iter: 0; batch classifier loss: 0.292577; batch adversarial loss: 0.498045\n",
      "epoch 22; iter: 0; batch classifier loss: 0.258610; batch adversarial loss: 0.400620\n",
      "epoch 23; iter: 0; batch classifier loss: 0.210099; batch adversarial loss: 0.431070\n",
      "epoch 24; iter: 0; batch classifier loss: 0.242452; batch adversarial loss: 0.415665\n",
      "epoch 25; iter: 0; batch classifier loss: 0.276703; batch adversarial loss: 0.366187\n",
      "epoch 26; iter: 0; batch classifier loss: 0.186572; batch adversarial loss: 0.408691\n",
      "epoch 27; iter: 0; batch classifier loss: 0.203260; batch adversarial loss: 0.400343\n",
      "epoch 28; iter: 0; batch classifier loss: 0.199681; batch adversarial loss: 0.445091\n",
      "epoch 29; iter: 0; batch classifier loss: 0.242987; batch adversarial loss: 0.476228\n",
      "epoch 30; iter: 0; batch classifier loss: 0.159747; batch adversarial loss: 0.409876\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170108; batch adversarial loss: 0.367459\n",
      "epoch 32; iter: 0; batch classifier loss: 0.149218; batch adversarial loss: 0.406551\n",
      "epoch 33; iter: 0; batch classifier loss: 0.193403; batch adversarial loss: 0.354004\n",
      "epoch 34; iter: 0; batch classifier loss: 0.176049; batch adversarial loss: 0.426386\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142692; batch adversarial loss: 0.400549\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128342; batch adversarial loss: 0.397676\n",
      "epoch 37; iter: 0; batch classifier loss: 0.171307; batch adversarial loss: 0.502710\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122197; batch adversarial loss: 0.373277\n",
      "epoch 39; iter: 0; batch classifier loss: 0.196888; batch adversarial loss: 0.447396\n",
      "epoch 40; iter: 0; batch classifier loss: 0.182975; batch adversarial loss: 0.371609\n",
      "epoch 41; iter: 0; batch classifier loss: 0.121166; batch adversarial loss: 0.326020\n",
      "epoch 42; iter: 0; batch classifier loss: 0.135623; batch adversarial loss: 0.310690\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089717; batch adversarial loss: 0.375382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.124210; batch adversarial loss: 0.380709\n",
      "epoch 45; iter: 0; batch classifier loss: 0.110876; batch adversarial loss: 0.488960\n",
      "epoch 46; iter: 0; batch classifier loss: 0.124746; batch adversarial loss: 0.501459\n",
      "epoch 47; iter: 0; batch classifier loss: 0.118591; batch adversarial loss: 0.413876\n",
      "epoch 48; iter: 0; batch classifier loss: 0.145427; batch adversarial loss: 0.409452\n",
      "epoch 49; iter: 0; batch classifier loss: 0.130217; batch adversarial loss: 0.456142\n",
      "epoch 50; iter: 0; batch classifier loss: 0.180546; batch adversarial loss: 0.454696\n",
      "epoch 51; iter: 0; batch classifier loss: 0.120431; batch adversarial loss: 0.434766\n",
      "epoch 52; iter: 0; batch classifier loss: 0.127318; batch adversarial loss: 0.402301\n",
      "epoch 53; iter: 0; batch classifier loss: 0.101644; batch adversarial loss: 0.466385\n",
      "epoch 54; iter: 0; batch classifier loss: 0.150299; batch adversarial loss: 0.475705\n",
      "epoch 55; iter: 0; batch classifier loss: 0.094513; batch adversarial loss: 0.420859\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099473; batch adversarial loss: 0.405717\n",
      "epoch 57; iter: 0; batch classifier loss: 0.047001; batch adversarial loss: 0.468669\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078932; batch adversarial loss: 0.368855\n",
      "epoch 59; iter: 0; batch classifier loss: 0.060057; batch adversarial loss: 0.402005\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086922; batch adversarial loss: 0.426008\n",
      "epoch 61; iter: 0; batch classifier loss: 0.107216; batch adversarial loss: 0.448082\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120929; batch adversarial loss: 0.415491\n",
      "epoch 63; iter: 0; batch classifier loss: 0.082691; batch adversarial loss: 0.373001\n",
      "epoch 64; iter: 0; batch classifier loss: 0.075503; batch adversarial loss: 0.358343\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077240; batch adversarial loss: 0.404393\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087336; batch adversarial loss: 0.368045\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082523; batch adversarial loss: 0.414492\n",
      "epoch 68; iter: 0; batch classifier loss: 0.100992; batch adversarial loss: 0.465219\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087610; batch adversarial loss: 0.487079\n",
      "epoch 70; iter: 0; batch classifier loss: 0.107328; batch adversarial loss: 0.441772\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083744; batch adversarial loss: 0.381699\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100272; batch adversarial loss: 0.393689\n",
      "epoch 73; iter: 0; batch classifier loss: 0.105101; batch adversarial loss: 0.447124\n",
      "epoch 74; iter: 0; batch classifier loss: 0.091683; batch adversarial loss: 0.434483\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068575; batch adversarial loss: 0.416103\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072144; batch adversarial loss: 0.361992\n",
      "epoch 77; iter: 0; batch classifier loss: 0.070365; batch adversarial loss: 0.423734\n",
      "epoch 78; iter: 0; batch classifier loss: 0.078852; batch adversarial loss: 0.398970\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085580; batch adversarial loss: 0.396098\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083111; batch adversarial loss: 0.457707\n",
      "epoch 81; iter: 0; batch classifier loss: 0.135198; batch adversarial loss: 0.366926\n",
      "epoch 82; iter: 0; batch classifier loss: 0.100271; batch adversarial loss: 0.402646\n",
      "epoch 83; iter: 0; batch classifier loss: 0.055322; batch adversarial loss: 0.415938\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052999; batch adversarial loss: 0.391011\n",
      "epoch 85; iter: 0; batch classifier loss: 0.071373; batch adversarial loss: 0.453459\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054382; batch adversarial loss: 0.471069\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076552; batch adversarial loss: 0.436633\n",
      "epoch 88; iter: 0; batch classifier loss: 0.072814; batch adversarial loss: 0.336751\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042988; batch adversarial loss: 0.413465\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054577; batch adversarial loss: 0.441791\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052640; batch adversarial loss: 0.480367\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071862; batch adversarial loss: 0.374321\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055831; batch adversarial loss: 0.423517\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047557; batch adversarial loss: 0.462079\n",
      "epoch 95; iter: 0; batch classifier loss: 0.049253; batch adversarial loss: 0.401947\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082623; batch adversarial loss: 0.399477\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051409; batch adversarial loss: 0.390897\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054958; batch adversarial loss: 0.449233\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052850; batch adversarial loss: 0.363140\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055849; batch adversarial loss: 0.437568\n",
      "epoch 101; iter: 0; batch classifier loss: 0.033280; batch adversarial loss: 0.408583\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041539; batch adversarial loss: 0.498886\n",
      "epoch 103; iter: 0; batch classifier loss: 0.034674; batch adversarial loss: 0.431781\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062262; batch adversarial loss: 0.509520\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034411; batch adversarial loss: 0.484773\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047894; batch adversarial loss: 0.492318\n",
      "epoch 107; iter: 0; batch classifier loss: 0.030841; batch adversarial loss: 0.461080\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040423; batch adversarial loss: 0.489603\n",
      "epoch 109; iter: 0; batch classifier loss: 0.024504; batch adversarial loss: 0.526836\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023819; batch adversarial loss: 0.430413\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057510; batch adversarial loss: 0.425264\n",
      "epoch 112; iter: 0; batch classifier loss: 0.017547; batch adversarial loss: 0.461129\n",
      "epoch 113; iter: 0; batch classifier loss: 0.062252; batch adversarial loss: 0.457073\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056702; batch adversarial loss: 0.523090\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043401; batch adversarial loss: 0.568390\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034024; batch adversarial loss: 0.647772\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041574; batch adversarial loss: 0.442287\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039436; batch adversarial loss: 0.492357\n",
      "epoch 119; iter: 0; batch classifier loss: 0.016389; batch adversarial loss: 0.404106\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050052; batch adversarial loss: 0.455772\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043086; batch adversarial loss: 0.396012\n",
      "epoch 122; iter: 0; batch classifier loss: 0.096745; batch adversarial loss: 0.557756\n",
      "epoch 123; iter: 0; batch classifier loss: 0.102795; batch adversarial loss: 0.497557\n",
      "epoch 124; iter: 0; batch classifier loss: 0.080627; batch adversarial loss: 0.495087\n",
      "epoch 125; iter: 0; batch classifier loss: 0.117053; batch adversarial loss: 0.588109\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040943; batch adversarial loss: 0.608503\n",
      "epoch 127; iter: 0; batch classifier loss: 0.131600; batch adversarial loss: 0.666435\n",
      "epoch 128; iter: 0; batch classifier loss: 0.164743; batch adversarial loss: 0.640501\n",
      "epoch 129; iter: 0; batch classifier loss: 0.085045; batch adversarial loss: 0.549064\n",
      "epoch 130; iter: 0; batch classifier loss: 0.123792; batch adversarial loss: 0.659925\n",
      "epoch 131; iter: 0; batch classifier loss: 0.066385; batch adversarial loss: 0.477184\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053410; batch adversarial loss: 0.490483\n",
      "epoch 133; iter: 0; batch classifier loss: 0.109644; batch adversarial loss: 0.431575\n",
      "epoch 134; iter: 0; batch classifier loss: 0.088983; batch adversarial loss: 0.528639\n",
      "epoch 135; iter: 0; batch classifier loss: 0.079019; batch adversarial loss: 0.431506\n",
      "epoch 136; iter: 0; batch classifier loss: 0.098940; batch adversarial loss: 0.469519\n",
      "epoch 137; iter: 0; batch classifier loss: 0.162238; batch adversarial loss: 0.585838\n",
      "epoch 138; iter: 0; batch classifier loss: 0.165279; batch adversarial loss: 0.594380\n",
      "epoch 139; iter: 0; batch classifier loss: 0.156697; batch adversarial loss: 0.523066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.152132; batch adversarial loss: 0.623904\n",
      "epoch 141; iter: 0; batch classifier loss: 0.149007; batch adversarial loss: 0.587847\n",
      "epoch 142; iter: 0; batch classifier loss: 0.076482; batch adversarial loss: 0.502078\n",
      "epoch 143; iter: 0; batch classifier loss: 0.085938; batch adversarial loss: 0.396390\n",
      "epoch 144; iter: 0; batch classifier loss: 0.124702; batch adversarial loss: 0.528015\n",
      "epoch 145; iter: 0; batch classifier loss: 0.106420; batch adversarial loss: 0.488819\n",
      "epoch 146; iter: 0; batch classifier loss: 0.120334; batch adversarial loss: 0.513281\n",
      "epoch 147; iter: 0; batch classifier loss: 0.147948; batch adversarial loss: 0.590709\n",
      "epoch 148; iter: 0; batch classifier loss: 0.081032; batch adversarial loss: 0.530061\n",
      "epoch 149; iter: 0; batch classifier loss: 0.157488; batch adversarial loss: 0.693062\n",
      "epoch 150; iter: 0; batch classifier loss: 0.117185; batch adversarial loss: 0.548217\n",
      "epoch 151; iter: 0; batch classifier loss: 0.119361; batch adversarial loss: 0.545996\n",
      "epoch 152; iter: 0; batch classifier loss: 0.171788; batch adversarial loss: 0.493612\n",
      "epoch 153; iter: 0; batch classifier loss: 0.129895; batch adversarial loss: 0.481263\n",
      "epoch 154; iter: 0; batch classifier loss: 0.115953; batch adversarial loss: 0.486692\n",
      "epoch 155; iter: 0; batch classifier loss: 0.097784; batch adversarial loss: 0.457873\n",
      "epoch 156; iter: 0; batch classifier loss: 0.091796; batch adversarial loss: 0.505874\n",
      "epoch 157; iter: 0; batch classifier loss: 0.072980; batch adversarial loss: 0.404788\n",
      "epoch 158; iter: 0; batch classifier loss: 0.108624; batch adversarial loss: 0.526565\n",
      "epoch 159; iter: 0; batch classifier loss: 0.096320; batch adversarial loss: 0.536385\n",
      "epoch 160; iter: 0; batch classifier loss: 0.105009; batch adversarial loss: 0.458792\n",
      "epoch 161; iter: 0; batch classifier loss: 0.081679; batch adversarial loss: 0.396190\n",
      "epoch 162; iter: 0; batch classifier loss: 0.069380; batch adversarial loss: 0.427590\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042645; batch adversarial loss: 0.413105\n",
      "epoch 164; iter: 0; batch classifier loss: 0.052367; batch adversarial loss: 0.434700\n",
      "epoch 165; iter: 0; batch classifier loss: 0.095933; batch adversarial loss: 0.435460\n",
      "epoch 166; iter: 0; batch classifier loss: 0.074400; batch adversarial loss: 0.421444\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024499; batch adversarial loss: 0.420977\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040413; batch adversarial loss: 0.477814\n",
      "epoch 169; iter: 0; batch classifier loss: 0.039581; batch adversarial loss: 0.453642\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027600; batch adversarial loss: 0.426160\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047713; batch adversarial loss: 0.480596\n",
      "epoch 172; iter: 0; batch classifier loss: 0.037069; batch adversarial loss: 0.465019\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034437; batch adversarial loss: 0.427857\n",
      "epoch 174; iter: 0; batch classifier loss: 0.047896; batch adversarial loss: 0.463223\n",
      "epoch 175; iter: 0; batch classifier loss: 0.053954; batch adversarial loss: 0.460782\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031359; batch adversarial loss: 0.387612\n",
      "epoch 177; iter: 0; batch classifier loss: 0.089232; batch adversarial loss: 0.476210\n",
      "epoch 178; iter: 0; batch classifier loss: 0.044851; batch adversarial loss: 0.423948\n",
      "epoch 179; iter: 0; batch classifier loss: 0.060104; batch adversarial loss: 0.513151\n",
      "epoch 180; iter: 0; batch classifier loss: 0.058221; batch adversarial loss: 0.475515\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038372; batch adversarial loss: 0.524624\n",
      "epoch 182; iter: 0; batch classifier loss: 0.057307; batch adversarial loss: 0.441867\n",
      "epoch 183; iter: 0; batch classifier loss: 0.060344; batch adversarial loss: 0.483679\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024089; batch adversarial loss: 0.526457\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036575; batch adversarial loss: 0.427554\n",
      "epoch 186; iter: 0; batch classifier loss: 0.054297; batch adversarial loss: 0.506100\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036871; batch adversarial loss: 0.510929\n",
      "epoch 188; iter: 0; batch classifier loss: 0.062853; batch adversarial loss: 0.442531\n",
      "epoch 189; iter: 0; batch classifier loss: 0.047650; batch adversarial loss: 0.443291\n",
      "epoch 190; iter: 0; batch classifier loss: 0.068197; batch adversarial loss: 0.474063\n",
      "epoch 191; iter: 0; batch classifier loss: 0.040657; batch adversarial loss: 0.480591\n",
      "epoch 192; iter: 0; batch classifier loss: 0.051323; batch adversarial loss: 0.385357\n",
      "epoch 193; iter: 0; batch classifier loss: 0.118530; batch adversarial loss: 0.438535\n",
      "epoch 194; iter: 0; batch classifier loss: 0.078176; batch adversarial loss: 0.352393\n",
      "epoch 195; iter: 0; batch classifier loss: 0.053340; batch adversarial loss: 0.580518\n",
      "epoch 196; iter: 0; batch classifier loss: 0.053918; batch adversarial loss: 0.483512\n",
      "epoch 197; iter: 0; batch classifier loss: 0.093150; batch adversarial loss: 0.477053\n",
      "epoch 198; iter: 0; batch classifier loss: 0.094581; batch adversarial loss: 0.475278\n",
      "epoch 199; iter: 0; batch classifier loss: 0.080059; batch adversarial loss: 0.392413\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708177; batch adversarial loss: 0.732805\n",
      "epoch 1; iter: 0; batch classifier loss: 0.486082; batch adversarial loss: 0.692162\n",
      "epoch 2; iter: 0; batch classifier loss: 0.468327; batch adversarial loss: 0.654854\n",
      "epoch 3; iter: 0; batch classifier loss: 0.403777; batch adversarial loss: 0.632392\n",
      "epoch 4; iter: 0; batch classifier loss: 0.326449; batch adversarial loss: 0.588656\n",
      "epoch 5; iter: 0; batch classifier loss: 0.403128; batch adversarial loss: 0.533760\n",
      "epoch 6; iter: 0; batch classifier loss: 0.408553; batch adversarial loss: 0.516407\n",
      "epoch 7; iter: 0; batch classifier loss: 0.360910; batch adversarial loss: 0.532319\n",
      "epoch 8; iter: 0; batch classifier loss: 0.286915; batch adversarial loss: 0.480218\n",
      "epoch 9; iter: 0; batch classifier loss: 0.295446; batch adversarial loss: 0.512015\n",
      "epoch 10; iter: 0; batch classifier loss: 0.243387; batch adversarial loss: 0.409765\n",
      "epoch 11; iter: 0; batch classifier loss: 0.224415; batch adversarial loss: 0.442907\n",
      "epoch 12; iter: 0; batch classifier loss: 0.192823; batch adversarial loss: 0.472110\n",
      "epoch 13; iter: 0; batch classifier loss: 0.298470; batch adversarial loss: 0.502437\n",
      "epoch 14; iter: 0; batch classifier loss: 0.191282; batch adversarial loss: 0.454369\n",
      "epoch 15; iter: 0; batch classifier loss: 0.161636; batch adversarial loss: 0.479409\n",
      "epoch 16; iter: 0; batch classifier loss: 0.183714; batch adversarial loss: 0.415756\n",
      "epoch 17; iter: 0; batch classifier loss: 0.130958; batch adversarial loss: 0.354123\n",
      "epoch 18; iter: 0; batch classifier loss: 0.145467; batch adversarial loss: 0.426933\n",
      "epoch 19; iter: 0; batch classifier loss: 0.165342; batch adversarial loss: 0.371947\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220889; batch adversarial loss: 0.423153\n",
      "epoch 21; iter: 0; batch classifier loss: 0.270483; batch adversarial loss: 0.389226\n",
      "epoch 22; iter: 0; batch classifier loss: 0.187744; batch adversarial loss: 0.373778\n",
      "epoch 23; iter: 0; batch classifier loss: 0.187805; batch adversarial loss: 0.405333\n",
      "epoch 24; iter: 0; batch classifier loss: 0.177531; batch adversarial loss: 0.353687\n",
      "epoch 25; iter: 0; batch classifier loss: 0.173639; batch adversarial loss: 0.386252\n",
      "epoch 26; iter: 0; batch classifier loss: 0.168416; batch adversarial loss: 0.403837\n",
      "epoch 27; iter: 0; batch classifier loss: 0.158432; batch adversarial loss: 0.377343\n",
      "epoch 28; iter: 0; batch classifier loss: 0.163970; batch adversarial loss: 0.439560\n",
      "epoch 29; iter: 0; batch classifier loss: 0.198264; batch adversarial loss: 0.423518\n",
      "epoch 30; iter: 0; batch classifier loss: 0.164700; batch adversarial loss: 0.363554\n",
      "epoch 31; iter: 0; batch classifier loss: 0.161922; batch adversarial loss: 0.377342\n",
      "epoch 32; iter: 0; batch classifier loss: 0.142461; batch adversarial loss: 0.406399\n",
      "epoch 33; iter: 0; batch classifier loss: 0.208890; batch adversarial loss: 0.438415\n",
      "epoch 34; iter: 0; batch classifier loss: 0.126419; batch adversarial loss: 0.443036\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137673; batch adversarial loss: 0.403777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.119980; batch adversarial loss: 0.445613\n",
      "epoch 37; iter: 0; batch classifier loss: 0.106155; batch adversarial loss: 0.464494\n",
      "epoch 38; iter: 0; batch classifier loss: 0.138965; batch adversarial loss: 0.419319\n",
      "epoch 39; iter: 0; batch classifier loss: 0.120637; batch adversarial loss: 0.425267\n",
      "epoch 40; iter: 0; batch classifier loss: 0.137184; batch adversarial loss: 0.471239\n",
      "epoch 41; iter: 0; batch classifier loss: 0.141887; batch adversarial loss: 0.400731\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106647; batch adversarial loss: 0.487040\n",
      "epoch 43; iter: 0; batch classifier loss: 0.080271; batch adversarial loss: 0.463265\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119147; batch adversarial loss: 0.383986\n",
      "epoch 45; iter: 0; batch classifier loss: 0.084536; batch adversarial loss: 0.472982\n",
      "epoch 46; iter: 0; batch classifier loss: 0.141207; batch adversarial loss: 0.437683\n",
      "epoch 47; iter: 0; batch classifier loss: 0.084195; batch adversarial loss: 0.465361\n",
      "epoch 48; iter: 0; batch classifier loss: 0.119684; batch adversarial loss: 0.420248\n",
      "epoch 49; iter: 0; batch classifier loss: 0.095645; batch adversarial loss: 0.470234\n",
      "epoch 50; iter: 0; batch classifier loss: 0.133902; batch adversarial loss: 0.474220\n",
      "epoch 51; iter: 0; batch classifier loss: 0.052248; batch adversarial loss: 0.378024\n",
      "epoch 52; iter: 0; batch classifier loss: 0.074611; batch adversarial loss: 0.328992\n",
      "epoch 53; iter: 0; batch classifier loss: 0.093656; batch adversarial loss: 0.362237\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097415; batch adversarial loss: 0.443657\n",
      "epoch 55; iter: 0; batch classifier loss: 0.093821; batch adversarial loss: 0.386081\n",
      "epoch 56; iter: 0; batch classifier loss: 0.068129; batch adversarial loss: 0.352632\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110931; batch adversarial loss: 0.316776\n",
      "epoch 58; iter: 0; batch classifier loss: 0.099924; batch adversarial loss: 0.446654\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092427; batch adversarial loss: 0.428571\n",
      "epoch 60; iter: 0; batch classifier loss: 0.123199; batch adversarial loss: 0.474009\n",
      "epoch 61; iter: 0; batch classifier loss: 0.067204; batch adversarial loss: 0.392730\n",
      "epoch 62; iter: 0; batch classifier loss: 0.102387; batch adversarial loss: 0.507215\n",
      "epoch 63; iter: 0; batch classifier loss: 0.081589; batch adversarial loss: 0.386325\n",
      "epoch 64; iter: 0; batch classifier loss: 0.071492; batch adversarial loss: 0.394622\n",
      "epoch 65; iter: 0; batch classifier loss: 0.109137; batch adversarial loss: 0.423668\n",
      "epoch 66; iter: 0; batch classifier loss: 0.101103; batch adversarial loss: 0.355663\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130341; batch adversarial loss: 0.435303\n",
      "epoch 68; iter: 0; batch classifier loss: 0.101867; batch adversarial loss: 0.468194\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081141; batch adversarial loss: 0.453608\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095689; batch adversarial loss: 0.401119\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089946; batch adversarial loss: 0.406706\n",
      "epoch 72; iter: 0; batch classifier loss: 0.083353; batch adversarial loss: 0.421746\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079045; batch adversarial loss: 0.374342\n",
      "epoch 74; iter: 0; batch classifier loss: 0.072499; batch adversarial loss: 0.441033\n",
      "epoch 75; iter: 0; batch classifier loss: 0.119075; batch adversarial loss: 0.397303\n",
      "epoch 76; iter: 0; batch classifier loss: 0.074055; batch adversarial loss: 0.411340\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074083; batch adversarial loss: 0.448749\n",
      "epoch 78; iter: 0; batch classifier loss: 0.060927; batch adversarial loss: 0.371967\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065086; batch adversarial loss: 0.348577\n",
      "epoch 80; iter: 0; batch classifier loss: 0.066322; batch adversarial loss: 0.428953\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076061; batch adversarial loss: 0.423067\n",
      "epoch 82; iter: 0; batch classifier loss: 0.107719; batch adversarial loss: 0.444601\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059214; batch adversarial loss: 0.460892\n",
      "epoch 84; iter: 0; batch classifier loss: 0.053821; batch adversarial loss: 0.378588\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070140; batch adversarial loss: 0.478225\n",
      "epoch 86; iter: 0; batch classifier loss: 0.099823; batch adversarial loss: 0.459495\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082370; batch adversarial loss: 0.445685\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051439; batch adversarial loss: 0.451990\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087675; batch adversarial loss: 0.333487\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055137; batch adversarial loss: 0.461675\n",
      "epoch 91; iter: 0; batch classifier loss: 0.065828; batch adversarial loss: 0.446963\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071425; batch adversarial loss: 0.448098\n",
      "epoch 93; iter: 0; batch classifier loss: 0.057814; batch adversarial loss: 0.415232\n",
      "epoch 94; iter: 0; batch classifier loss: 0.105226; batch adversarial loss: 0.436367\n",
      "epoch 95; iter: 0; batch classifier loss: 0.036660; batch adversarial loss: 0.361891\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075448; batch adversarial loss: 0.457639\n",
      "epoch 97; iter: 0; batch classifier loss: 0.085098; batch adversarial loss: 0.446395\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052429; batch adversarial loss: 0.373629\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055459; batch adversarial loss: 0.389834\n",
      "epoch 100; iter: 0; batch classifier loss: 0.079457; batch adversarial loss: 0.489729\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061406; batch adversarial loss: 0.478213\n",
      "epoch 102; iter: 0; batch classifier loss: 0.103229; batch adversarial loss: 0.538746\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037944; batch adversarial loss: 0.399266\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062904; batch adversarial loss: 0.394820\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048567; batch adversarial loss: 0.381860\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052692; batch adversarial loss: 0.477369\n",
      "epoch 107; iter: 0; batch classifier loss: 0.064312; batch adversarial loss: 0.416188\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067637; batch adversarial loss: 0.420810\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048536; batch adversarial loss: 0.413980\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035133; batch adversarial loss: 0.447385\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033346; batch adversarial loss: 0.417333\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045396; batch adversarial loss: 0.508443\n",
      "epoch 113; iter: 0; batch classifier loss: 0.079319; batch adversarial loss: 0.409097\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041206; batch adversarial loss: 0.333620\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040730; batch adversarial loss: 0.466685\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040819; batch adversarial loss: 0.408221\n",
      "epoch 117; iter: 0; batch classifier loss: 0.024354; batch adversarial loss: 0.488217\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033383; batch adversarial loss: 0.399855\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026126; batch adversarial loss: 0.420798\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041267; batch adversarial loss: 0.447316\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025584; batch adversarial loss: 0.358706\n",
      "epoch 122; iter: 0; batch classifier loss: 0.047808; batch adversarial loss: 0.432548\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029579; batch adversarial loss: 0.408109\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035944; batch adversarial loss: 0.420665\n",
      "epoch 125; iter: 0; batch classifier loss: 0.069518; batch adversarial loss: 0.411890\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024326; batch adversarial loss: 0.472789\n",
      "epoch 127; iter: 0; batch classifier loss: 0.055524; batch adversarial loss: 0.426398\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049492; batch adversarial loss: 0.504282\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023184; batch adversarial loss: 0.434657\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029675; batch adversarial loss: 0.397840\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018181; batch adversarial loss: 0.440222\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016424; batch adversarial loss: 0.470595\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040393; batch adversarial loss: 0.523890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.047225; batch adversarial loss: 0.469901\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040780; batch adversarial loss: 0.433407\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043600; batch adversarial loss: 0.524336\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049666; batch adversarial loss: 0.522232\n",
      "epoch 138; iter: 0; batch classifier loss: 0.072072; batch adversarial loss: 0.527344\n",
      "epoch 139; iter: 0; batch classifier loss: 0.074523; batch adversarial loss: 0.594547\n",
      "epoch 140; iter: 0; batch classifier loss: 0.092626; batch adversarial loss: 0.568284\n",
      "epoch 141; iter: 0; batch classifier loss: 0.087131; batch adversarial loss: 0.513799\n",
      "epoch 142; iter: 0; batch classifier loss: 0.114158; batch adversarial loss: 0.564614\n",
      "epoch 143; iter: 0; batch classifier loss: 0.123236; batch adversarial loss: 0.516927\n",
      "epoch 144; iter: 0; batch classifier loss: 0.127958; batch adversarial loss: 0.604227\n",
      "epoch 145; iter: 0; batch classifier loss: 0.103976; batch adversarial loss: 0.528120\n",
      "epoch 146; iter: 0; batch classifier loss: 0.148721; batch adversarial loss: 0.739081\n",
      "epoch 147; iter: 0; batch classifier loss: 0.132767; batch adversarial loss: 0.707368\n",
      "epoch 148; iter: 0; batch classifier loss: 0.104985; batch adversarial loss: 0.581517\n",
      "epoch 149; iter: 0; batch classifier loss: 0.098570; batch adversarial loss: 0.476362\n",
      "epoch 150; iter: 0; batch classifier loss: 0.118776; batch adversarial loss: 0.558971\n",
      "epoch 151; iter: 0; batch classifier loss: 0.141909; batch adversarial loss: 0.621824\n",
      "epoch 152; iter: 0; batch classifier loss: 0.156329; batch adversarial loss: 0.664049\n",
      "epoch 153; iter: 0; batch classifier loss: 0.121760; batch adversarial loss: 0.571702\n",
      "epoch 154; iter: 0; batch classifier loss: 0.169236; batch adversarial loss: 0.669040\n",
      "epoch 155; iter: 0; batch classifier loss: 0.107204; batch adversarial loss: 0.517506\n",
      "epoch 156; iter: 0; batch classifier loss: 0.127948; batch adversarial loss: 0.596309\n",
      "epoch 157; iter: 0; batch classifier loss: 0.136506; batch adversarial loss: 0.667906\n",
      "epoch 158; iter: 0; batch classifier loss: 0.155612; batch adversarial loss: 0.652353\n",
      "epoch 159; iter: 0; batch classifier loss: 0.185472; batch adversarial loss: 0.625898\n",
      "epoch 160; iter: 0; batch classifier loss: 0.153212; batch adversarial loss: 0.637707\n",
      "epoch 161; iter: 0; batch classifier loss: 0.126504; batch adversarial loss: 0.576583\n",
      "epoch 162; iter: 0; batch classifier loss: 0.164136; batch adversarial loss: 0.661679\n",
      "epoch 163; iter: 0; batch classifier loss: 0.097839; batch adversarial loss: 0.506116\n",
      "epoch 164; iter: 0; batch classifier loss: 0.180961; batch adversarial loss: 0.647997\n",
      "epoch 165; iter: 0; batch classifier loss: 0.119269; batch adversarial loss: 0.591889\n",
      "epoch 166; iter: 0; batch classifier loss: 0.151576; batch adversarial loss: 0.645672\n",
      "epoch 167; iter: 0; batch classifier loss: 0.151784; batch adversarial loss: 0.557261\n",
      "epoch 168; iter: 0; batch classifier loss: 0.205599; batch adversarial loss: 0.660311\n",
      "epoch 169; iter: 0; batch classifier loss: 0.142425; batch adversarial loss: 0.501884\n",
      "epoch 170; iter: 0; batch classifier loss: 0.141243; batch adversarial loss: 0.531040\n",
      "epoch 171; iter: 0; batch classifier loss: 0.095327; batch adversarial loss: 0.422736\n",
      "epoch 172; iter: 0; batch classifier loss: 0.120958; batch adversarial loss: 0.519699\n",
      "epoch 173; iter: 0; batch classifier loss: 0.145801; batch adversarial loss: 0.562692\n",
      "epoch 174; iter: 0; batch classifier loss: 0.091784; batch adversarial loss: 0.518069\n",
      "epoch 175; iter: 0; batch classifier loss: 0.073414; batch adversarial loss: 0.362016\n",
      "epoch 176; iter: 0; batch classifier loss: 0.128063; batch adversarial loss: 0.589589\n",
      "epoch 177; iter: 0; batch classifier loss: 0.147158; batch adversarial loss: 0.560866\n",
      "epoch 178; iter: 0; batch classifier loss: 0.133541; batch adversarial loss: 0.485666\n",
      "epoch 179; iter: 0; batch classifier loss: 0.112397; batch adversarial loss: 0.634505\n",
      "epoch 180; iter: 0; batch classifier loss: 0.133510; batch adversarial loss: 0.498295\n",
      "epoch 181; iter: 0; batch classifier loss: 0.120885; batch adversarial loss: 0.509243\n",
      "epoch 182; iter: 0; batch classifier loss: 0.120449; batch adversarial loss: 0.507445\n",
      "epoch 183; iter: 0; batch classifier loss: 0.091979; batch adversarial loss: 0.455250\n",
      "epoch 184; iter: 0; batch classifier loss: 0.152542; batch adversarial loss: 0.629201\n",
      "epoch 185; iter: 0; batch classifier loss: 0.150798; batch adversarial loss: 0.546335\n",
      "epoch 186; iter: 0; batch classifier loss: 0.118870; batch adversarial loss: 0.612960\n",
      "epoch 187; iter: 0; batch classifier loss: 0.088306; batch adversarial loss: 0.486432\n",
      "epoch 188; iter: 0; batch classifier loss: 0.068081; batch adversarial loss: 0.418558\n",
      "epoch 189; iter: 0; batch classifier loss: 0.143278; batch adversarial loss: 0.518801\n",
      "epoch 190; iter: 0; batch classifier loss: 0.116446; batch adversarial loss: 0.404078\n",
      "epoch 191; iter: 0; batch classifier loss: 0.074999; batch adversarial loss: 0.361835\n",
      "epoch 192; iter: 0; batch classifier loss: 0.082753; batch adversarial loss: 0.436516\n",
      "epoch 193; iter: 0; batch classifier loss: 0.118168; batch adversarial loss: 0.395780\n",
      "epoch 194; iter: 0; batch classifier loss: 0.040712; batch adversarial loss: 0.383248\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033288; batch adversarial loss: 0.494121\n",
      "epoch 196; iter: 0; batch classifier loss: 0.047790; batch adversarial loss: 0.443021\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028266; batch adversarial loss: 0.617340\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025154; batch adversarial loss: 0.508827\n",
      "epoch 199; iter: 0; batch classifier loss: 0.045803; batch adversarial loss: 0.459577\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705984; batch adversarial loss: 0.771669\n",
      "epoch 1; iter: 0; batch classifier loss: 0.383460; batch adversarial loss: 0.719310\n",
      "epoch 2; iter: 0; batch classifier loss: 0.406525; batch adversarial loss: 0.691190\n",
      "epoch 3; iter: 0; batch classifier loss: 0.355164; batch adversarial loss: 0.654318\n",
      "epoch 4; iter: 0; batch classifier loss: 0.393034; batch adversarial loss: 0.623880\n",
      "epoch 5; iter: 0; batch classifier loss: 0.353436; batch adversarial loss: 0.596780\n",
      "epoch 6; iter: 0; batch classifier loss: 0.312328; batch adversarial loss: 0.555992\n",
      "epoch 7; iter: 0; batch classifier loss: 0.352440; batch adversarial loss: 0.544279\n",
      "epoch 8; iter: 0; batch classifier loss: 0.257629; batch adversarial loss: 0.531420\n",
      "epoch 9; iter: 0; batch classifier loss: 0.293694; batch adversarial loss: 0.495451\n",
      "epoch 10; iter: 0; batch classifier loss: 0.310291; batch adversarial loss: 0.471243\n",
      "epoch 11; iter: 0; batch classifier loss: 0.238042; batch adversarial loss: 0.443604\n",
      "epoch 12; iter: 0; batch classifier loss: 0.226265; batch adversarial loss: 0.467998\n",
      "epoch 13; iter: 0; batch classifier loss: 0.282513; batch adversarial loss: 0.473246\n",
      "epoch 14; iter: 0; batch classifier loss: 0.210021; batch adversarial loss: 0.414961\n",
      "epoch 15; iter: 0; batch classifier loss: 0.235924; batch adversarial loss: 0.454432\n",
      "epoch 16; iter: 0; batch classifier loss: 0.187766; batch adversarial loss: 0.459506\n",
      "epoch 17; iter: 0; batch classifier loss: 0.194641; batch adversarial loss: 0.415178\n",
      "epoch 18; iter: 0; batch classifier loss: 0.206741; batch adversarial loss: 0.470316\n",
      "epoch 19; iter: 0; batch classifier loss: 0.226702; batch adversarial loss: 0.438704\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204914; batch adversarial loss: 0.392529\n",
      "epoch 21; iter: 0; batch classifier loss: 0.214212; batch adversarial loss: 0.395304\n",
      "epoch 22; iter: 0; batch classifier loss: 0.243058; batch adversarial loss: 0.435686\n",
      "epoch 23; iter: 0; batch classifier loss: 0.215974; batch adversarial loss: 0.413835\n",
      "epoch 24; iter: 0; batch classifier loss: 0.200980; batch adversarial loss: 0.462193\n",
      "epoch 25; iter: 0; batch classifier loss: 0.205628; batch adversarial loss: 0.381588\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180175; batch adversarial loss: 0.482069\n",
      "epoch 27; iter: 0; batch classifier loss: 0.124851; batch adversarial loss: 0.400424\n",
      "epoch 28; iter: 0; batch classifier loss: 0.185936; batch adversarial loss: 0.530571\n",
      "epoch 29; iter: 0; batch classifier loss: 0.136379; batch adversarial loss: 0.381089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.169281; batch adversarial loss: 0.433904\n",
      "epoch 31; iter: 0; batch classifier loss: 0.139961; batch adversarial loss: 0.403933\n",
      "epoch 32; iter: 0; batch classifier loss: 0.197866; batch adversarial loss: 0.373153\n",
      "epoch 33; iter: 0; batch classifier loss: 0.102838; batch adversarial loss: 0.364167\n",
      "epoch 34; iter: 0; batch classifier loss: 0.196001; batch adversarial loss: 0.462475\n",
      "epoch 35; iter: 0; batch classifier loss: 0.111283; batch adversarial loss: 0.393628\n",
      "epoch 36; iter: 0; batch classifier loss: 0.175709; batch adversarial loss: 0.468748\n",
      "epoch 37; iter: 0; batch classifier loss: 0.114434; batch adversarial loss: 0.430097\n",
      "epoch 38; iter: 0; batch classifier loss: 0.090728; batch adversarial loss: 0.440344\n",
      "epoch 39; iter: 0; batch classifier loss: 0.101699; batch adversarial loss: 0.319769\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116445; batch adversarial loss: 0.388945\n",
      "epoch 41; iter: 0; batch classifier loss: 0.127008; batch adversarial loss: 0.376500\n",
      "epoch 42; iter: 0; batch classifier loss: 0.141075; batch adversarial loss: 0.420203\n",
      "epoch 43; iter: 0; batch classifier loss: 0.106648; batch adversarial loss: 0.427614\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112781; batch adversarial loss: 0.449773\n",
      "epoch 45; iter: 0; batch classifier loss: 0.114360; batch adversarial loss: 0.470606\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102555; batch adversarial loss: 0.383182\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095997; batch adversarial loss: 0.445833\n",
      "epoch 48; iter: 0; batch classifier loss: 0.088750; batch adversarial loss: 0.432613\n",
      "epoch 49; iter: 0; batch classifier loss: 0.075161; batch adversarial loss: 0.410443\n",
      "epoch 50; iter: 0; batch classifier loss: 0.092360; batch adversarial loss: 0.526551\n",
      "epoch 51; iter: 0; batch classifier loss: 0.119972; batch adversarial loss: 0.473039\n",
      "epoch 52; iter: 0; batch classifier loss: 0.088821; batch adversarial loss: 0.420544\n",
      "epoch 53; iter: 0; batch classifier loss: 0.118564; batch adversarial loss: 0.423600\n",
      "epoch 54; iter: 0; batch classifier loss: 0.089861; batch adversarial loss: 0.472335\n",
      "epoch 55; iter: 0; batch classifier loss: 0.104768; batch adversarial loss: 0.387316\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119901; batch adversarial loss: 0.442659\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106905; batch adversarial loss: 0.458311\n",
      "epoch 58; iter: 0; batch classifier loss: 0.092048; batch adversarial loss: 0.385877\n",
      "epoch 59; iter: 0; batch classifier loss: 0.117968; batch adversarial loss: 0.387330\n",
      "epoch 60; iter: 0; batch classifier loss: 0.074551; batch adversarial loss: 0.471079\n",
      "epoch 61; iter: 0; batch classifier loss: 0.072108; batch adversarial loss: 0.442023\n",
      "epoch 62; iter: 0; batch classifier loss: 0.077834; batch adversarial loss: 0.420758\n",
      "epoch 63; iter: 0; batch classifier loss: 0.080918; batch adversarial loss: 0.366462\n",
      "epoch 64; iter: 0; batch classifier loss: 0.138149; batch adversarial loss: 0.512687\n",
      "epoch 65; iter: 0; batch classifier loss: 0.071174; batch adversarial loss: 0.467248\n",
      "epoch 66; iter: 0; batch classifier loss: 0.137070; batch adversarial loss: 0.552734\n",
      "epoch 67; iter: 0; batch classifier loss: 0.075191; batch adversarial loss: 0.468629\n",
      "epoch 68; iter: 0; batch classifier loss: 0.097567; batch adversarial loss: 0.371276\n",
      "epoch 69; iter: 0; batch classifier loss: 0.077766; batch adversarial loss: 0.470590\n",
      "epoch 70; iter: 0; batch classifier loss: 0.121275; batch adversarial loss: 0.441961\n",
      "epoch 71; iter: 0; batch classifier loss: 0.087360; batch adversarial loss: 0.436789\n",
      "epoch 72; iter: 0; batch classifier loss: 0.113582; batch adversarial loss: 0.439760\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068983; batch adversarial loss: 0.364279\n",
      "epoch 74; iter: 0; batch classifier loss: 0.088753; batch adversarial loss: 0.477057\n",
      "epoch 75; iter: 0; batch classifier loss: 0.081643; batch adversarial loss: 0.494243\n",
      "epoch 76; iter: 0; batch classifier loss: 0.109473; batch adversarial loss: 0.442719\n",
      "epoch 77; iter: 0; batch classifier loss: 0.088416; batch adversarial loss: 0.439056\n",
      "epoch 78; iter: 0; batch classifier loss: 0.108887; batch adversarial loss: 0.468801\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061023; batch adversarial loss: 0.409307\n",
      "epoch 80; iter: 0; batch classifier loss: 0.114823; batch adversarial loss: 0.537716\n",
      "epoch 81; iter: 0; batch classifier loss: 0.059208; batch adversarial loss: 0.423567\n",
      "epoch 82; iter: 0; batch classifier loss: 0.080142; batch adversarial loss: 0.487543\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061126; batch adversarial loss: 0.409823\n",
      "epoch 84; iter: 0; batch classifier loss: 0.066122; batch adversarial loss: 0.385676\n",
      "epoch 85; iter: 0; batch classifier loss: 0.078849; batch adversarial loss: 0.315925\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068965; batch adversarial loss: 0.400399\n",
      "epoch 87; iter: 0; batch classifier loss: 0.111808; batch adversarial loss: 0.382771\n",
      "epoch 88; iter: 0; batch classifier loss: 0.052968; batch adversarial loss: 0.410640\n",
      "epoch 89; iter: 0; batch classifier loss: 0.079938; batch adversarial loss: 0.416601\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042930; batch adversarial loss: 0.469516\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048539; batch adversarial loss: 0.442831\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048200; batch adversarial loss: 0.417875\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053268; batch adversarial loss: 0.373599\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058702; batch adversarial loss: 0.447862\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052609; batch adversarial loss: 0.396127\n",
      "epoch 96; iter: 0; batch classifier loss: 0.074164; batch adversarial loss: 0.459579\n",
      "epoch 97; iter: 0; batch classifier loss: 0.030806; batch adversarial loss: 0.387412\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042909; batch adversarial loss: 0.386220\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071174; batch adversarial loss: 0.490086\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049979; batch adversarial loss: 0.428621\n",
      "epoch 101; iter: 0; batch classifier loss: 0.105889; batch adversarial loss: 0.485255\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048810; batch adversarial loss: 0.515077\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066176; batch adversarial loss: 0.470162\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050148; batch adversarial loss: 0.434431\n",
      "epoch 105; iter: 0; batch classifier loss: 0.071254; batch adversarial loss: 0.483876\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055034; batch adversarial loss: 0.394528\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040072; batch adversarial loss: 0.418598\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030947; batch adversarial loss: 0.431949\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051426; batch adversarial loss: 0.472121\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065048; batch adversarial loss: 0.384533\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034798; batch adversarial loss: 0.532331\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041825; batch adversarial loss: 0.499545\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053269; batch adversarial loss: 0.417791\n",
      "epoch 114; iter: 0; batch classifier loss: 0.064491; batch adversarial loss: 0.429073\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037920; batch adversarial loss: 0.591944\n",
      "epoch 116; iter: 0; batch classifier loss: 0.015279; batch adversarial loss: 0.420124\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026907; batch adversarial loss: 0.485797\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036120; batch adversarial loss: 0.426228\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020277; batch adversarial loss: 0.466731\n",
      "epoch 120; iter: 0; batch classifier loss: 0.056905; batch adversarial loss: 0.509453\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047630; batch adversarial loss: 0.351927\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037647; batch adversarial loss: 0.554813\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034039; batch adversarial loss: 0.447316\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032880; batch adversarial loss: 0.446444\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061932; batch adversarial loss: 0.491414\n",
      "epoch 126; iter: 0; batch classifier loss: 0.073903; batch adversarial loss: 0.477883\n",
      "epoch 127; iter: 0; batch classifier loss: 0.083872; batch adversarial loss: 0.475369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.085051; batch adversarial loss: 0.544790\n",
      "epoch 129; iter: 0; batch classifier loss: 0.060098; batch adversarial loss: 0.415998\n",
      "epoch 130; iter: 0; batch classifier loss: 0.116031; batch adversarial loss: 0.535891\n",
      "epoch 131; iter: 0; batch classifier loss: 0.124578; batch adversarial loss: 0.592252\n",
      "epoch 132; iter: 0; batch classifier loss: 0.190692; batch adversarial loss: 0.707770\n",
      "epoch 133; iter: 0; batch classifier loss: 0.111858; batch adversarial loss: 0.527328\n",
      "epoch 134; iter: 0; batch classifier loss: 0.215797; batch adversarial loss: 0.826398\n",
      "epoch 135; iter: 0; batch classifier loss: 0.165572; batch adversarial loss: 0.548101\n",
      "epoch 136; iter: 0; batch classifier loss: 0.144784; batch adversarial loss: 0.524633\n",
      "epoch 137; iter: 0; batch classifier loss: 0.112281; batch adversarial loss: 0.587544\n",
      "epoch 138; iter: 0; batch classifier loss: 0.119400; batch adversarial loss: 0.597830\n",
      "epoch 139; iter: 0; batch classifier loss: 0.181662; batch adversarial loss: 0.608287\n",
      "epoch 140; iter: 0; batch classifier loss: 0.116808; batch adversarial loss: 0.574399\n",
      "epoch 141; iter: 0; batch classifier loss: 0.201725; batch adversarial loss: 0.604967\n",
      "epoch 142; iter: 0; batch classifier loss: 0.231450; batch adversarial loss: 0.566971\n",
      "epoch 143; iter: 0; batch classifier loss: 0.172221; batch adversarial loss: 0.692548\n",
      "epoch 144; iter: 0; batch classifier loss: 0.137702; batch adversarial loss: 0.598473\n",
      "epoch 145; iter: 0; batch classifier loss: 0.107305; batch adversarial loss: 0.546508\n",
      "epoch 146; iter: 0; batch classifier loss: 0.108827; batch adversarial loss: 0.419083\n",
      "epoch 147; iter: 0; batch classifier loss: 0.171805; batch adversarial loss: 0.583930\n",
      "epoch 148; iter: 0; batch classifier loss: 0.198200; batch adversarial loss: 0.663207\n",
      "epoch 149; iter: 0; batch classifier loss: 0.150929; batch adversarial loss: 0.542518\n",
      "epoch 150; iter: 0; batch classifier loss: 0.138064; batch adversarial loss: 0.531158\n",
      "epoch 151; iter: 0; batch classifier loss: 0.108285; batch adversarial loss: 0.504046\n",
      "epoch 152; iter: 0; batch classifier loss: 0.124828; batch adversarial loss: 0.502534\n",
      "epoch 153; iter: 0; batch classifier loss: 0.183134; batch adversarial loss: 0.511891\n",
      "epoch 154; iter: 0; batch classifier loss: 0.179716; batch adversarial loss: 0.526402\n",
      "epoch 155; iter: 0; batch classifier loss: 0.181625; batch adversarial loss: 0.530826\n",
      "epoch 156; iter: 0; batch classifier loss: 0.140190; batch adversarial loss: 0.515820\n",
      "epoch 157; iter: 0; batch classifier loss: 0.202329; batch adversarial loss: 0.634894\n",
      "epoch 158; iter: 0; batch classifier loss: 0.135203; batch adversarial loss: 0.547836\n",
      "epoch 159; iter: 0; batch classifier loss: 0.107656; batch adversarial loss: 0.495136\n",
      "epoch 160; iter: 0; batch classifier loss: 0.078703; batch adversarial loss: 0.405421\n",
      "epoch 161; iter: 0; batch classifier loss: 0.077222; batch adversarial loss: 0.450899\n",
      "epoch 162; iter: 0; batch classifier loss: 0.089689; batch adversarial loss: 0.453626\n",
      "epoch 163; iter: 0; batch classifier loss: 0.145815; batch adversarial loss: 0.497447\n",
      "epoch 164; iter: 0; batch classifier loss: 0.094933; batch adversarial loss: 0.445504\n",
      "epoch 165; iter: 0; batch classifier loss: 0.133316; batch adversarial loss: 0.418808\n",
      "epoch 166; iter: 0; batch classifier loss: 0.149199; batch adversarial loss: 0.548950\n",
      "epoch 167; iter: 0; batch classifier loss: 0.142576; batch adversarial loss: 0.559216\n",
      "epoch 168; iter: 0; batch classifier loss: 0.095968; batch adversarial loss: 0.449796\n",
      "epoch 169; iter: 0; batch classifier loss: 0.095096; batch adversarial loss: 0.527835\n",
      "epoch 170; iter: 0; batch classifier loss: 0.055791; batch adversarial loss: 0.384484\n",
      "epoch 171; iter: 0; batch classifier loss: 0.067525; batch adversarial loss: 0.555339\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032327; batch adversarial loss: 0.386867\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031192; batch adversarial loss: 0.435342\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038307; batch adversarial loss: 0.525503\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039868; batch adversarial loss: 0.469664\n",
      "epoch 176; iter: 0; batch classifier loss: 0.061807; batch adversarial loss: 0.531369\n",
      "epoch 177; iter: 0; batch classifier loss: 0.069260; batch adversarial loss: 0.436255\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037040; batch adversarial loss: 0.408372\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032649; batch adversarial loss: 0.401044\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028285; batch adversarial loss: 0.426990\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032783; batch adversarial loss: 0.485088\n",
      "epoch 182; iter: 0; batch classifier loss: 0.044136; batch adversarial loss: 0.465323\n",
      "epoch 183; iter: 0; batch classifier loss: 0.055318; batch adversarial loss: 0.417293\n",
      "epoch 184; iter: 0; batch classifier loss: 0.041762; batch adversarial loss: 0.412129\n",
      "epoch 185; iter: 0; batch classifier loss: 0.055122; batch adversarial loss: 0.538774\n",
      "epoch 186; iter: 0; batch classifier loss: 0.039775; batch adversarial loss: 0.549958\n",
      "epoch 187; iter: 0; batch classifier loss: 0.052122; batch adversarial loss: 0.420282\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035044; batch adversarial loss: 0.422613\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013648; batch adversarial loss: 0.397727\n",
      "epoch 190; iter: 0; batch classifier loss: 0.091732; batch adversarial loss: 0.405690\n",
      "epoch 191; iter: 0; batch classifier loss: 0.041642; batch adversarial loss: 0.454568\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032907; batch adversarial loss: 0.407674\n",
      "epoch 193; iter: 0; batch classifier loss: 0.045580; batch adversarial loss: 0.494672\n",
      "epoch 194; iter: 0; batch classifier loss: 0.076019; batch adversarial loss: 0.470311\n",
      "epoch 195; iter: 0; batch classifier loss: 0.049937; batch adversarial loss: 0.426100\n",
      "epoch 196; iter: 0; batch classifier loss: 0.079515; batch adversarial loss: 0.461919\n",
      "epoch 197; iter: 0; batch classifier loss: 0.061698; batch adversarial loss: 0.466213\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041905; batch adversarial loss: 0.393641\n",
      "epoch 199; iter: 0; batch classifier loss: 0.090126; batch adversarial loss: 0.475937\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696089; batch adversarial loss: 0.759909\n",
      "epoch 1; iter: 0; batch classifier loss: 0.520068; batch adversarial loss: 0.677966\n",
      "epoch 2; iter: 0; batch classifier loss: 0.392093; batch adversarial loss: 0.638275\n",
      "epoch 3; iter: 0; batch classifier loss: 0.358007; batch adversarial loss: 0.621434\n",
      "epoch 4; iter: 0; batch classifier loss: 0.353689; batch adversarial loss: 0.603407\n",
      "epoch 5; iter: 0; batch classifier loss: 0.374360; batch adversarial loss: 0.578311\n",
      "epoch 6; iter: 0; batch classifier loss: 0.382210; batch adversarial loss: 0.549399\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306800; batch adversarial loss: 0.536190\n",
      "epoch 8; iter: 0; batch classifier loss: 0.313466; batch adversarial loss: 0.520653\n",
      "epoch 9; iter: 0; batch classifier loss: 0.325555; batch adversarial loss: 0.537225\n",
      "epoch 10; iter: 0; batch classifier loss: 0.280679; batch adversarial loss: 0.492303\n",
      "epoch 11; iter: 0; batch classifier loss: 0.221779; batch adversarial loss: 0.483067\n",
      "epoch 12; iter: 0; batch classifier loss: 0.279799; batch adversarial loss: 0.518280\n",
      "epoch 13; iter: 0; batch classifier loss: 0.228141; batch adversarial loss: 0.485721\n",
      "epoch 14; iter: 0; batch classifier loss: 0.175979; batch adversarial loss: 0.505024\n",
      "epoch 15; iter: 0; batch classifier loss: 0.226093; batch adversarial loss: 0.492134\n",
      "epoch 16; iter: 0; batch classifier loss: 0.231924; batch adversarial loss: 0.449729\n",
      "epoch 17; iter: 0; batch classifier loss: 0.287034; batch adversarial loss: 0.470643\n",
      "epoch 18; iter: 0; batch classifier loss: 0.210061; batch adversarial loss: 0.529251\n",
      "epoch 19; iter: 0; batch classifier loss: 0.181699; batch adversarial loss: 0.537046\n",
      "epoch 20; iter: 0; batch classifier loss: 0.246231; batch adversarial loss: 0.509723\n",
      "epoch 21; iter: 0; batch classifier loss: 0.167986; batch adversarial loss: 0.491810\n",
      "epoch 22; iter: 0; batch classifier loss: 0.252827; batch adversarial loss: 0.469000\n",
      "epoch 23; iter: 0; batch classifier loss: 0.238860; batch adversarial loss: 0.421118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.188332; batch adversarial loss: 0.496290\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180381; batch adversarial loss: 0.513454\n",
      "epoch 26; iter: 0; batch classifier loss: 0.159095; batch adversarial loss: 0.432141\n",
      "epoch 27; iter: 0; batch classifier loss: 0.131788; batch adversarial loss: 0.586174\n",
      "epoch 28; iter: 0; batch classifier loss: 0.158826; batch adversarial loss: 0.350882\n",
      "epoch 29; iter: 0; batch classifier loss: 0.185753; batch adversarial loss: 0.465180\n",
      "epoch 30; iter: 0; batch classifier loss: 0.142819; batch adversarial loss: 0.467996\n",
      "epoch 31; iter: 0; batch classifier loss: 0.127462; batch adversarial loss: 0.399033\n",
      "epoch 32; iter: 0; batch classifier loss: 0.184287; batch adversarial loss: 0.384242\n",
      "epoch 33; iter: 0; batch classifier loss: 0.212375; batch adversarial loss: 0.456266\n",
      "epoch 34; iter: 0; batch classifier loss: 0.145528; batch adversarial loss: 0.403417\n",
      "epoch 35; iter: 0; batch classifier loss: 0.189484; batch adversarial loss: 0.392606\n",
      "epoch 36; iter: 0; batch classifier loss: 0.255517; batch adversarial loss: 0.415783\n",
      "epoch 37; iter: 0; batch classifier loss: 0.198173; batch adversarial loss: 0.353401\n",
      "epoch 38; iter: 0; batch classifier loss: 0.134446; batch adversarial loss: 0.463245\n",
      "epoch 39; iter: 0; batch classifier loss: 0.146925; batch adversarial loss: 0.409129\n",
      "epoch 40; iter: 0; batch classifier loss: 0.153893; batch adversarial loss: 0.531113\n",
      "epoch 41; iter: 0; batch classifier loss: 0.136769; batch adversarial loss: 0.461937\n",
      "epoch 42; iter: 0; batch classifier loss: 0.160111; batch adversarial loss: 0.388976\n",
      "epoch 43; iter: 0; batch classifier loss: 0.100032; batch adversarial loss: 0.557030\n",
      "epoch 44; iter: 0; batch classifier loss: 0.178287; batch adversarial loss: 0.452028\n",
      "epoch 45; iter: 0; batch classifier loss: 0.153848; batch adversarial loss: 0.445943\n",
      "epoch 46; iter: 0; batch classifier loss: 0.180126; batch adversarial loss: 0.523745\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108248; batch adversarial loss: 0.389859\n",
      "epoch 48; iter: 0; batch classifier loss: 0.168683; batch adversarial loss: 0.390881\n",
      "epoch 49; iter: 0; batch classifier loss: 0.221775; batch adversarial loss: 0.436883\n",
      "epoch 50; iter: 0; batch classifier loss: 0.178102; batch adversarial loss: 0.405867\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092175; batch adversarial loss: 0.424693\n",
      "epoch 52; iter: 0; batch classifier loss: 0.143109; batch adversarial loss: 0.548901\n",
      "epoch 53; iter: 0; batch classifier loss: 0.154739; batch adversarial loss: 0.525704\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114240; batch adversarial loss: 0.445529\n",
      "epoch 55; iter: 0; batch classifier loss: 0.138700; batch adversarial loss: 0.475631\n",
      "epoch 56; iter: 0; batch classifier loss: 0.148504; batch adversarial loss: 0.436298\n",
      "epoch 57; iter: 0; batch classifier loss: 0.133612; batch adversarial loss: 0.400329\n",
      "epoch 58; iter: 0; batch classifier loss: 0.139156; batch adversarial loss: 0.500663\n",
      "epoch 59; iter: 0; batch classifier loss: 0.078994; batch adversarial loss: 0.459058\n",
      "epoch 60; iter: 0; batch classifier loss: 0.133292; batch adversarial loss: 0.375162\n",
      "epoch 61; iter: 0; batch classifier loss: 0.100438; batch adversarial loss: 0.494044\n",
      "epoch 62; iter: 0; batch classifier loss: 0.153300; batch adversarial loss: 0.462910\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098825; batch adversarial loss: 0.398235\n",
      "epoch 64; iter: 0; batch classifier loss: 0.136502; batch adversarial loss: 0.466455\n",
      "epoch 65; iter: 0; batch classifier loss: 0.080713; batch adversarial loss: 0.501223\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085623; batch adversarial loss: 0.464959\n",
      "epoch 67; iter: 0; batch classifier loss: 0.103901; batch adversarial loss: 0.549293\n",
      "epoch 68; iter: 0; batch classifier loss: 0.148193; batch adversarial loss: 0.485138\n",
      "epoch 69; iter: 0; batch classifier loss: 0.091902; batch adversarial loss: 0.477421\n",
      "epoch 70; iter: 0; batch classifier loss: 0.122296; batch adversarial loss: 0.490502\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058324; batch adversarial loss: 0.506361\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072169; batch adversarial loss: 0.524483\n",
      "epoch 73; iter: 0; batch classifier loss: 0.080795; batch adversarial loss: 0.452866\n",
      "epoch 74; iter: 0; batch classifier loss: 0.113307; batch adversarial loss: 0.365971\n",
      "epoch 75; iter: 0; batch classifier loss: 0.098774; batch adversarial loss: 0.524068\n",
      "epoch 76; iter: 0; batch classifier loss: 0.120369; batch adversarial loss: 0.418437\n",
      "epoch 77; iter: 0; batch classifier loss: 0.115351; batch adversarial loss: 0.382108\n",
      "epoch 78; iter: 0; batch classifier loss: 0.063850; batch adversarial loss: 0.449823\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070488; batch adversarial loss: 0.341472\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084827; batch adversarial loss: 0.467794\n",
      "epoch 81; iter: 0; batch classifier loss: 0.092322; batch adversarial loss: 0.411393\n",
      "epoch 82; iter: 0; batch classifier loss: 0.082653; batch adversarial loss: 0.470320\n",
      "epoch 83; iter: 0; batch classifier loss: 0.095696; batch adversarial loss: 0.399050\n",
      "epoch 84; iter: 0; batch classifier loss: 0.116711; batch adversarial loss: 0.517297\n",
      "epoch 85; iter: 0; batch classifier loss: 0.078972; batch adversarial loss: 0.612499\n",
      "epoch 86; iter: 0; batch classifier loss: 0.056890; batch adversarial loss: 0.476256\n",
      "epoch 87; iter: 0; batch classifier loss: 0.116018; batch adversarial loss: 0.369999\n",
      "epoch 88; iter: 0; batch classifier loss: 0.091793; batch adversarial loss: 0.478431\n",
      "epoch 89; iter: 0; batch classifier loss: 0.115922; batch adversarial loss: 0.486911\n",
      "epoch 90; iter: 0; batch classifier loss: 0.086884; batch adversarial loss: 0.525562\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060539; batch adversarial loss: 0.511085\n",
      "epoch 92; iter: 0; batch classifier loss: 0.087037; batch adversarial loss: 0.452489\n",
      "epoch 93; iter: 0; batch classifier loss: 0.068167; batch adversarial loss: 0.417622\n",
      "epoch 94; iter: 0; batch classifier loss: 0.054047; batch adversarial loss: 0.396575\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080775; batch adversarial loss: 0.507532\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045754; batch adversarial loss: 0.447025\n",
      "epoch 97; iter: 0; batch classifier loss: 0.067264; batch adversarial loss: 0.569833\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049567; batch adversarial loss: 0.377468\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049126; batch adversarial loss: 0.557740\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051782; batch adversarial loss: 0.413476\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039981; batch adversarial loss: 0.446308\n",
      "epoch 102; iter: 0; batch classifier loss: 0.045541; batch adversarial loss: 0.445577\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039602; batch adversarial loss: 0.450176\n",
      "epoch 104; iter: 0; batch classifier loss: 0.087743; batch adversarial loss: 0.545500\n",
      "epoch 105; iter: 0; batch classifier loss: 0.021730; batch adversarial loss: 0.507014\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025132; batch adversarial loss: 0.456187\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053907; batch adversarial loss: 0.500952\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040010; batch adversarial loss: 0.434938\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047920; batch adversarial loss: 0.452898\n",
      "epoch 110; iter: 0; batch classifier loss: 0.080880; batch adversarial loss: 0.462460\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034938; batch adversarial loss: 0.403470\n",
      "epoch 112; iter: 0; batch classifier loss: 0.061414; batch adversarial loss: 0.453472\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058723; batch adversarial loss: 0.463668\n",
      "epoch 114; iter: 0; batch classifier loss: 0.017026; batch adversarial loss: 0.411402\n",
      "epoch 115; iter: 0; batch classifier loss: 0.091916; batch adversarial loss: 0.398792\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024133; batch adversarial loss: 0.433749\n",
      "epoch 117; iter: 0; batch classifier loss: 0.057343; batch adversarial loss: 0.344491\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032327; batch adversarial loss: 0.511722\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055618; batch adversarial loss: 0.418477\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040793; batch adversarial loss: 0.384185\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032684; batch adversarial loss: 0.419930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.031879; batch adversarial loss: 0.417920\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014776; batch adversarial loss: 0.515399\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027131; batch adversarial loss: 0.487066\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040431; batch adversarial loss: 0.438120\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038365; batch adversarial loss: 0.558667\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060508; batch adversarial loss: 0.467140\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018122; batch adversarial loss: 0.449225\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034899; batch adversarial loss: 0.429961\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032564; batch adversarial loss: 0.567604\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041972; batch adversarial loss: 0.460236\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027593; batch adversarial loss: 0.498416\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032175; batch adversarial loss: 0.485340\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030889; batch adversarial loss: 0.436033\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060301; batch adversarial loss: 0.465673\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042190; batch adversarial loss: 0.438928\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041077; batch adversarial loss: 0.457037\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028010; batch adversarial loss: 0.427181\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022302; batch adversarial loss: 0.530001\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031834; batch adversarial loss: 0.550672\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020755; batch adversarial loss: 0.438906\n",
      "epoch 142; iter: 0; batch classifier loss: 0.060323; batch adversarial loss: 0.478871\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035590; batch adversarial loss: 0.435829\n",
      "epoch 144; iter: 0; batch classifier loss: 0.054696; batch adversarial loss: 0.536339\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044915; batch adversarial loss: 0.484638\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029939; batch adversarial loss: 0.452376\n",
      "epoch 147; iter: 0; batch classifier loss: 0.063508; batch adversarial loss: 0.497150\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015751; batch adversarial loss: 0.419444\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030276; batch adversarial loss: 0.526061\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022417; batch adversarial loss: 0.459003\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015656; batch adversarial loss: 0.384380\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041979; batch adversarial loss: 0.389356\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029636; batch adversarial loss: 0.412958\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015851; batch adversarial loss: 0.452264\n",
      "epoch 155; iter: 0; batch classifier loss: 0.003617; batch adversarial loss: 0.453662\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016175; batch adversarial loss: 0.434473\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022017; batch adversarial loss: 0.433306\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025923; batch adversarial loss: 0.433384\n",
      "epoch 159; iter: 0; batch classifier loss: 0.008943; batch adversarial loss: 0.520317\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023889; batch adversarial loss: 0.461706\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020665; batch adversarial loss: 0.437844\n",
      "epoch 162; iter: 0; batch classifier loss: 0.035529; batch adversarial loss: 0.329369\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042137; batch adversarial loss: 0.487203\n",
      "epoch 164; iter: 0; batch classifier loss: 0.006616; batch adversarial loss: 0.506740\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023746; batch adversarial loss: 0.454308\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038125; batch adversarial loss: 0.598218\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015702; batch adversarial loss: 0.462367\n",
      "epoch 168; iter: 0; batch classifier loss: 0.050335; batch adversarial loss: 0.495447\n",
      "epoch 169; iter: 0; batch classifier loss: 0.056997; batch adversarial loss: 0.425138\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027499; batch adversarial loss: 0.379750\n",
      "epoch 171; iter: 0; batch classifier loss: 0.041000; batch adversarial loss: 0.476927\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031996; batch adversarial loss: 0.472591\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008623; batch adversarial loss: 0.411000\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019876; batch adversarial loss: 0.380685\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033238; batch adversarial loss: 0.422481\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010543; batch adversarial loss: 0.484744\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025527; batch adversarial loss: 0.521156\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028531; batch adversarial loss: 0.460968\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011084; batch adversarial loss: 0.482374\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019444; batch adversarial loss: 0.448861\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006892; batch adversarial loss: 0.479846\n",
      "epoch 182; iter: 0; batch classifier loss: 0.001954; batch adversarial loss: 0.531215\n",
      "epoch 183; iter: 0; batch classifier loss: 0.035684; batch adversarial loss: 0.415379\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020791; batch adversarial loss: 0.389197\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036854; batch adversarial loss: 0.465086\n",
      "epoch 186; iter: 0; batch classifier loss: 0.004464; batch adversarial loss: 0.416754\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034837; batch adversarial loss: 0.494695\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016138; batch adversarial loss: 0.403718\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033787; batch adversarial loss: 0.423134\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024034; batch adversarial loss: 0.465232\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011833; batch adversarial loss: 0.538148\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005480; batch adversarial loss: 0.410770\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028040; batch adversarial loss: 0.455341\n",
      "epoch 194; iter: 0; batch classifier loss: 0.038668; batch adversarial loss: 0.431070\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011194; batch adversarial loss: 0.441309\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037154; batch adversarial loss: 0.519526\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039356; batch adversarial loss: 0.397839\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016423; batch adversarial loss: 0.452502\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009240; batch adversarial loss: 0.502948\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689543; batch adversarial loss: 0.733068\n",
      "epoch 1; iter: 0; batch classifier loss: 0.493938; batch adversarial loss: 0.673285\n",
      "epoch 2; iter: 0; batch classifier loss: 0.505569; batch adversarial loss: 0.638120\n",
      "epoch 3; iter: 0; batch classifier loss: 0.319739; batch adversarial loss: 0.611261\n",
      "epoch 4; iter: 0; batch classifier loss: 0.360137; batch adversarial loss: 0.599543\n",
      "epoch 5; iter: 0; batch classifier loss: 0.368928; batch adversarial loss: 0.621941\n",
      "epoch 6; iter: 0; batch classifier loss: 0.359539; batch adversarial loss: 0.594448\n",
      "epoch 7; iter: 0; batch classifier loss: 0.324818; batch adversarial loss: 0.551225\n",
      "epoch 8; iter: 0; batch classifier loss: 0.327035; batch adversarial loss: 0.473288\n",
      "epoch 9; iter: 0; batch classifier loss: 0.324072; batch adversarial loss: 0.558068\n",
      "epoch 10; iter: 0; batch classifier loss: 0.281839; batch adversarial loss: 0.515707\n",
      "epoch 11; iter: 0; batch classifier loss: 0.283732; batch adversarial loss: 0.546836\n",
      "epoch 12; iter: 0; batch classifier loss: 0.428953; batch adversarial loss: 0.507043\n",
      "epoch 13; iter: 0; batch classifier loss: 0.306336; batch adversarial loss: 0.542111\n",
      "epoch 14; iter: 0; batch classifier loss: 0.289209; batch adversarial loss: 0.563223\n",
      "epoch 15; iter: 0; batch classifier loss: 0.311804; batch adversarial loss: 0.517803\n",
      "epoch 16; iter: 0; batch classifier loss: 0.351092; batch adversarial loss: 0.486125\n",
      "epoch 17; iter: 0; batch classifier loss: 0.285896; batch adversarial loss: 0.495952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.346652; batch adversarial loss: 0.484365\n",
      "epoch 19; iter: 0; batch classifier loss: 0.286609; batch adversarial loss: 0.494630\n",
      "epoch 20; iter: 0; batch classifier loss: 0.293100; batch adversarial loss: 0.525270\n",
      "epoch 21; iter: 0; batch classifier loss: 0.358062; batch adversarial loss: 0.453058\n",
      "epoch 22; iter: 0; batch classifier loss: 0.209142; batch adversarial loss: 0.461746\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285996; batch adversarial loss: 0.499580\n",
      "epoch 24; iter: 0; batch classifier loss: 0.272184; batch adversarial loss: 0.442270\n",
      "epoch 25; iter: 0; batch classifier loss: 0.250678; batch adversarial loss: 0.446861\n",
      "epoch 26; iter: 0; batch classifier loss: 0.340693; batch adversarial loss: 0.469463\n",
      "epoch 27; iter: 0; batch classifier loss: 0.272798; batch adversarial loss: 0.448661\n",
      "epoch 28; iter: 0; batch classifier loss: 0.266184; batch adversarial loss: 0.476676\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180835; batch adversarial loss: 0.488932\n",
      "epoch 30; iter: 0; batch classifier loss: 0.201120; batch adversarial loss: 0.457867\n",
      "epoch 31; iter: 0; batch classifier loss: 0.216601; batch adversarial loss: 0.459892\n",
      "epoch 32; iter: 0; batch classifier loss: 0.213122; batch adversarial loss: 0.461568\n",
      "epoch 33; iter: 0; batch classifier loss: 0.211069; batch adversarial loss: 0.488950\n",
      "epoch 34; iter: 0; batch classifier loss: 0.266315; batch adversarial loss: 0.465058\n",
      "epoch 35; iter: 0; batch classifier loss: 0.196928; batch adversarial loss: 0.461288\n",
      "epoch 36; iter: 0; batch classifier loss: 0.220788; batch adversarial loss: 0.457525\n",
      "epoch 37; iter: 0; batch classifier loss: 0.205177; batch adversarial loss: 0.454872\n",
      "epoch 38; iter: 0; batch classifier loss: 0.191574; batch adversarial loss: 0.531046\n",
      "epoch 39; iter: 0; batch classifier loss: 0.189508; batch adversarial loss: 0.439281\n",
      "epoch 40; iter: 0; batch classifier loss: 0.242033; batch adversarial loss: 0.456197\n",
      "epoch 41; iter: 0; batch classifier loss: 0.185781; batch adversarial loss: 0.570912\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200100; batch adversarial loss: 0.529566\n",
      "epoch 43; iter: 0; batch classifier loss: 0.201927; batch adversarial loss: 0.465867\n",
      "epoch 44; iter: 0; batch classifier loss: 0.220111; batch adversarial loss: 0.382126\n",
      "epoch 45; iter: 0; batch classifier loss: 0.211014; batch adversarial loss: 0.504253\n",
      "epoch 46; iter: 0; batch classifier loss: 0.169242; batch adversarial loss: 0.460148\n",
      "epoch 47; iter: 0; batch classifier loss: 0.208957; batch adversarial loss: 0.437122\n",
      "epoch 48; iter: 0; batch classifier loss: 0.178885; batch adversarial loss: 0.437083\n",
      "epoch 49; iter: 0; batch classifier loss: 0.178114; batch adversarial loss: 0.425638\n",
      "epoch 50; iter: 0; batch classifier loss: 0.118017; batch adversarial loss: 0.482575\n",
      "epoch 51; iter: 0; batch classifier loss: 0.110796; batch adversarial loss: 0.457611\n",
      "epoch 52; iter: 0; batch classifier loss: 0.078278; batch adversarial loss: 0.395593\n",
      "epoch 53; iter: 0; batch classifier loss: 0.085856; batch adversarial loss: 0.456333\n",
      "epoch 54; iter: 0; batch classifier loss: 0.171759; batch adversarial loss: 0.566375\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086297; batch adversarial loss: 0.541235\n",
      "epoch 56; iter: 0; batch classifier loss: 0.164251; batch adversarial loss: 0.484076\n",
      "epoch 57; iter: 0; batch classifier loss: 0.282717; batch adversarial loss: 0.478752\n",
      "epoch 58; iter: 0; batch classifier loss: 0.112601; batch adversarial loss: 0.482410\n",
      "epoch 59; iter: 0; batch classifier loss: 0.157846; batch adversarial loss: 0.504514\n",
      "epoch 60; iter: 0; batch classifier loss: 0.145803; batch adversarial loss: 0.495098\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104810; batch adversarial loss: 0.422339\n",
      "epoch 62; iter: 0; batch classifier loss: 0.141269; batch adversarial loss: 0.412626\n",
      "epoch 63; iter: 0; batch classifier loss: 0.177908; batch adversarial loss: 0.450117\n",
      "epoch 64; iter: 0; batch classifier loss: 0.177524; batch adversarial loss: 0.564328\n",
      "epoch 65; iter: 0; batch classifier loss: 0.252148; batch adversarial loss: 0.435163\n",
      "epoch 66; iter: 0; batch classifier loss: 0.154635; batch adversarial loss: 0.423198\n",
      "epoch 67; iter: 0; batch classifier loss: 0.153204; batch adversarial loss: 0.563988\n",
      "epoch 68; iter: 0; batch classifier loss: 0.186716; batch adversarial loss: 0.352096\n",
      "epoch 69; iter: 0; batch classifier loss: 0.181909; batch adversarial loss: 0.519989\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144196; batch adversarial loss: 0.434919\n",
      "epoch 71; iter: 0; batch classifier loss: 0.141937; batch adversarial loss: 0.424154\n",
      "epoch 72; iter: 0; batch classifier loss: 0.176940; batch adversarial loss: 0.363552\n",
      "epoch 73; iter: 0; batch classifier loss: 0.200636; batch adversarial loss: 0.387452\n",
      "epoch 74; iter: 0; batch classifier loss: 0.200567; batch adversarial loss: 0.434516\n",
      "epoch 75; iter: 0; batch classifier loss: 0.242736; batch adversarial loss: 0.435395\n",
      "epoch 76; iter: 0; batch classifier loss: 0.204850; batch adversarial loss: 0.423934\n",
      "epoch 77; iter: 0; batch classifier loss: 0.203070; batch adversarial loss: 0.433774\n",
      "epoch 78; iter: 0; batch classifier loss: 0.194930; batch adversarial loss: 0.436486\n",
      "epoch 79; iter: 0; batch classifier loss: 0.169837; batch adversarial loss: 0.448053\n",
      "epoch 80; iter: 0; batch classifier loss: 0.157135; batch adversarial loss: 0.515523\n",
      "epoch 81; iter: 0; batch classifier loss: 0.183055; batch adversarial loss: 0.471768\n",
      "epoch 82; iter: 0; batch classifier loss: 0.178421; batch adversarial loss: 0.435684\n",
      "epoch 83; iter: 0; batch classifier loss: 0.162581; batch adversarial loss: 0.433648\n",
      "epoch 84; iter: 0; batch classifier loss: 0.116512; batch adversarial loss: 0.483215\n",
      "epoch 85; iter: 0; batch classifier loss: 0.135875; batch adversarial loss: 0.529091\n",
      "epoch 86; iter: 0; batch classifier loss: 0.173773; batch adversarial loss: 0.409873\n",
      "epoch 87; iter: 0; batch classifier loss: 0.129333; batch adversarial loss: 0.408375\n",
      "epoch 88; iter: 0; batch classifier loss: 0.130579; batch adversarial loss: 0.437464\n",
      "epoch 89; iter: 0; batch classifier loss: 0.101225; batch adversarial loss: 0.517061\n",
      "epoch 90; iter: 0; batch classifier loss: 0.155116; batch adversarial loss: 0.528539\n",
      "epoch 91; iter: 0; batch classifier loss: 0.097696; batch adversarial loss: 0.503728\n",
      "epoch 92; iter: 0; batch classifier loss: 0.194208; batch adversarial loss: 0.489809\n",
      "epoch 93; iter: 0; batch classifier loss: 0.119666; batch adversarial loss: 0.507173\n",
      "epoch 94; iter: 0; batch classifier loss: 0.074568; batch adversarial loss: 0.508817\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081485; batch adversarial loss: 0.398123\n",
      "epoch 96; iter: 0; batch classifier loss: 0.090046; batch adversarial loss: 0.464717\n",
      "epoch 97; iter: 0; batch classifier loss: 0.095973; batch adversarial loss: 0.463152\n",
      "epoch 98; iter: 0; batch classifier loss: 0.043058; batch adversarial loss: 0.612819\n",
      "epoch 99; iter: 0; batch classifier loss: 0.120358; batch adversarial loss: 0.438894\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061403; batch adversarial loss: 0.497292\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083739; batch adversarial loss: 0.385014\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058633; batch adversarial loss: 0.483371\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063688; batch adversarial loss: 0.453568\n",
      "epoch 104; iter: 0; batch classifier loss: 0.098358; batch adversarial loss: 0.537516\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041903; batch adversarial loss: 0.478404\n",
      "epoch 106; iter: 0; batch classifier loss: 0.066243; batch adversarial loss: 0.446866\n",
      "epoch 107; iter: 0; batch classifier loss: 0.067847; batch adversarial loss: 0.487650\n",
      "epoch 108; iter: 0; batch classifier loss: 0.050939; batch adversarial loss: 0.473399\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064072; batch adversarial loss: 0.483101\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052189; batch adversarial loss: 0.514615\n",
      "epoch 111; iter: 0; batch classifier loss: 0.080761; batch adversarial loss: 0.441262\n",
      "epoch 112; iter: 0; batch classifier loss: 0.072494; batch adversarial loss: 0.442539\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044164; batch adversarial loss: 0.421714\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033246; batch adversarial loss: 0.501574\n",
      "epoch 115; iter: 0; batch classifier loss: 0.081271; batch adversarial loss: 0.387975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.056069; batch adversarial loss: 0.443645\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049769; batch adversarial loss: 0.425646\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050292; batch adversarial loss: 0.526513\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037968; batch adversarial loss: 0.462413\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057821; batch adversarial loss: 0.533586\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039098; batch adversarial loss: 0.411912\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015823; batch adversarial loss: 0.436861\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044244; batch adversarial loss: 0.525775\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027241; batch adversarial loss: 0.471850\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043754; batch adversarial loss: 0.468390\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039660; batch adversarial loss: 0.379513\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044359; batch adversarial loss: 0.436087\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036425; batch adversarial loss: 0.439622\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029535; batch adversarial loss: 0.472264\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033773; batch adversarial loss: 0.509817\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027552; batch adversarial loss: 0.440617\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058315; batch adversarial loss: 0.541763\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030645; batch adversarial loss: 0.493211\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062995; batch adversarial loss: 0.391615\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019344; batch adversarial loss: 0.573696\n",
      "epoch 136; iter: 0; batch classifier loss: 0.014562; batch adversarial loss: 0.538590\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020399; batch adversarial loss: 0.425765\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030586; batch adversarial loss: 0.457161\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045011; batch adversarial loss: 0.516782\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018705; batch adversarial loss: 0.425381\n",
      "epoch 141; iter: 0; batch classifier loss: 0.080828; batch adversarial loss: 0.392655\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026499; batch adversarial loss: 0.430689\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020513; batch adversarial loss: 0.427944\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020412; batch adversarial loss: 0.470494\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018662; batch adversarial loss: 0.378207\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031605; batch adversarial loss: 0.445621\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027365; batch adversarial loss: 0.416483\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026054; batch adversarial loss: 0.558379\n",
      "epoch 149; iter: 0; batch classifier loss: 0.054796; batch adversarial loss: 0.485475\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032809; batch adversarial loss: 0.467774\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015336; batch adversarial loss: 0.556652\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018799; batch adversarial loss: 0.527002\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036716; batch adversarial loss: 0.474968\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031984; batch adversarial loss: 0.538611\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010388; batch adversarial loss: 0.516915\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018161; batch adversarial loss: 0.444139\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012338; batch adversarial loss: 0.446771\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007620; batch adversarial loss: 0.475910\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043978; batch adversarial loss: 0.464109\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014184; batch adversarial loss: 0.449353\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014534; batch adversarial loss: 0.533790\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026422; batch adversarial loss: 0.455516\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024787; batch adversarial loss: 0.445317\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032119; batch adversarial loss: 0.428583\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029860; batch adversarial loss: 0.543379\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013560; batch adversarial loss: 0.462306\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006745; batch adversarial loss: 0.374385\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023032; batch adversarial loss: 0.431525\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040209; batch adversarial loss: 0.523539\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015060; batch adversarial loss: 0.619064\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020299; batch adversarial loss: 0.439007\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018716; batch adversarial loss: 0.395298\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012277; batch adversarial loss: 0.487096\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008432; batch adversarial loss: 0.465242\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022407; batch adversarial loss: 0.564601\n",
      "epoch 176; iter: 0; batch classifier loss: 0.042908; batch adversarial loss: 0.473621\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021748; batch adversarial loss: 0.441240\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027319; batch adversarial loss: 0.552605\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009065; batch adversarial loss: 0.501298\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018671; batch adversarial loss: 0.453291\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032035; batch adversarial loss: 0.395049\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014764; batch adversarial loss: 0.463099\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016331; batch adversarial loss: 0.456110\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017161; batch adversarial loss: 0.477015\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011572; batch adversarial loss: 0.506952\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013427; batch adversarial loss: 0.521108\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017920; batch adversarial loss: 0.598371\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032150; batch adversarial loss: 0.437184\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032451; batch adversarial loss: 0.482342\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004111; batch adversarial loss: 0.496641\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028124; batch adversarial loss: 0.425108\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021465; batch adversarial loss: 0.478888\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022100; batch adversarial loss: 0.426960\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016192; batch adversarial loss: 0.449239\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011576; batch adversarial loss: 0.426999\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027664; batch adversarial loss: 0.556394\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025843; batch adversarial loss: 0.438538\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024226; batch adversarial loss: 0.558405\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016387; batch adversarial loss: 0.484523\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722279; batch adversarial loss: 0.720954\n",
      "epoch 1; iter: 0; batch classifier loss: 0.528783; batch adversarial loss: 0.678884\n",
      "epoch 2; iter: 0; batch classifier loss: 0.449801; batch adversarial loss: 0.648482\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339003; batch adversarial loss: 0.619383\n",
      "epoch 4; iter: 0; batch classifier loss: 0.318454; batch adversarial loss: 0.576303\n",
      "epoch 5; iter: 0; batch classifier loss: 0.271244; batch adversarial loss: 0.552859\n",
      "epoch 6; iter: 0; batch classifier loss: 0.273334; batch adversarial loss: 0.525283\n",
      "epoch 7; iter: 0; batch classifier loss: 0.271453; batch adversarial loss: 0.535555\n",
      "epoch 8; iter: 0; batch classifier loss: 0.263525; batch adversarial loss: 0.540691\n",
      "epoch 9; iter: 0; batch classifier loss: 0.265493; batch adversarial loss: 0.542530\n",
      "epoch 10; iter: 0; batch classifier loss: 0.250244; batch adversarial loss: 0.553091\n",
      "epoch 11; iter: 0; batch classifier loss: 0.286363; batch adversarial loss: 0.498113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.344184; batch adversarial loss: 0.565919\n",
      "epoch 13; iter: 0; batch classifier loss: 0.299769; batch adversarial loss: 0.513248\n",
      "epoch 14; iter: 0; batch classifier loss: 0.187393; batch adversarial loss: 0.473280\n",
      "epoch 15; iter: 0; batch classifier loss: 0.198445; batch adversarial loss: 0.497410\n",
      "epoch 16; iter: 0; batch classifier loss: 0.247729; batch adversarial loss: 0.530251\n",
      "epoch 17; iter: 0; batch classifier loss: 0.302675; batch adversarial loss: 0.556575\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359291; batch adversarial loss: 0.448492\n",
      "epoch 19; iter: 0; batch classifier loss: 0.447547; batch adversarial loss: 0.528074\n",
      "epoch 20; iter: 0; batch classifier loss: 0.505861; batch adversarial loss: 0.489594\n",
      "epoch 21; iter: 0; batch classifier loss: 0.361662; batch adversarial loss: 0.529288\n",
      "epoch 22; iter: 0; batch classifier loss: 0.365843; batch adversarial loss: 0.436903\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203203; batch adversarial loss: 0.505399\n",
      "epoch 24; iter: 0; batch classifier loss: 0.200461; batch adversarial loss: 0.450117\n",
      "epoch 25; iter: 0; batch classifier loss: 0.204992; batch adversarial loss: 0.459133\n",
      "epoch 26; iter: 0; batch classifier loss: 0.191761; batch adversarial loss: 0.491959\n",
      "epoch 27; iter: 0; batch classifier loss: 0.131051; batch adversarial loss: 0.489196\n",
      "epoch 28; iter: 0; batch classifier loss: 0.157675; batch adversarial loss: 0.480622\n",
      "epoch 29; iter: 0; batch classifier loss: 0.130179; batch adversarial loss: 0.384360\n",
      "epoch 30; iter: 0; batch classifier loss: 0.123144; batch adversarial loss: 0.420993\n",
      "epoch 31; iter: 0; batch classifier loss: 0.116209; batch adversarial loss: 0.461130\n",
      "epoch 32; iter: 0; batch classifier loss: 0.171395; batch adversarial loss: 0.457590\n",
      "epoch 33; iter: 0; batch classifier loss: 0.157732; batch adversarial loss: 0.470001\n",
      "epoch 34; iter: 0; batch classifier loss: 0.112948; batch adversarial loss: 0.479489\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125528; batch adversarial loss: 0.467496\n",
      "epoch 36; iter: 0; batch classifier loss: 0.160003; batch adversarial loss: 0.458533\n",
      "epoch 37; iter: 0; batch classifier loss: 0.121519; batch adversarial loss: 0.427484\n",
      "epoch 38; iter: 0; batch classifier loss: 0.103755; batch adversarial loss: 0.530405\n",
      "epoch 39; iter: 0; batch classifier loss: 0.128350; batch adversarial loss: 0.440300\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091393; batch adversarial loss: 0.395800\n",
      "epoch 41; iter: 0; batch classifier loss: 0.144968; batch adversarial loss: 0.472843\n",
      "epoch 42; iter: 0; batch classifier loss: 0.138267; batch adversarial loss: 0.393495\n",
      "epoch 43; iter: 0; batch classifier loss: 0.130174; batch adversarial loss: 0.437194\n",
      "epoch 44; iter: 0; batch classifier loss: 0.087837; batch adversarial loss: 0.404854\n",
      "epoch 45; iter: 0; batch classifier loss: 0.088624; batch adversarial loss: 0.447603\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114689; batch adversarial loss: 0.448551\n",
      "epoch 47; iter: 0; batch classifier loss: 0.127594; batch adversarial loss: 0.489438\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081226; batch adversarial loss: 0.437280\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096264; batch adversarial loss: 0.489765\n",
      "epoch 50; iter: 0; batch classifier loss: 0.102934; batch adversarial loss: 0.504457\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092505; batch adversarial loss: 0.411212\n",
      "epoch 52; iter: 0; batch classifier loss: 0.097740; batch adversarial loss: 0.478108\n",
      "epoch 53; iter: 0; batch classifier loss: 0.118788; batch adversarial loss: 0.428666\n",
      "epoch 54; iter: 0; batch classifier loss: 0.105817; batch adversarial loss: 0.535366\n",
      "epoch 55; iter: 0; batch classifier loss: 0.111793; batch adversarial loss: 0.444750\n",
      "epoch 56; iter: 0; batch classifier loss: 0.140458; batch adversarial loss: 0.416348\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106883; batch adversarial loss: 0.423112\n",
      "epoch 58; iter: 0; batch classifier loss: 0.081937; batch adversarial loss: 0.591225\n",
      "epoch 59; iter: 0; batch classifier loss: 0.096543; batch adversarial loss: 0.481452\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095023; batch adversarial loss: 0.504233\n",
      "epoch 61; iter: 0; batch classifier loss: 0.163186; batch adversarial loss: 0.496936\n",
      "epoch 62; iter: 0; batch classifier loss: 0.118381; batch adversarial loss: 0.464817\n",
      "epoch 63; iter: 0; batch classifier loss: 0.112742; batch adversarial loss: 0.391073\n",
      "epoch 64; iter: 0; batch classifier loss: 0.102826; batch adversarial loss: 0.495913\n",
      "epoch 65; iter: 0; batch classifier loss: 0.094365; batch adversarial loss: 0.517934\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075604; batch adversarial loss: 0.405972\n",
      "epoch 67; iter: 0; batch classifier loss: 0.123385; batch adversarial loss: 0.491823\n",
      "epoch 68; iter: 0; batch classifier loss: 0.090878; batch adversarial loss: 0.395356\n",
      "epoch 69; iter: 0; batch classifier loss: 0.060549; batch adversarial loss: 0.437405\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073828; batch adversarial loss: 0.504103\n",
      "epoch 71; iter: 0; batch classifier loss: 0.118903; batch adversarial loss: 0.484740\n",
      "epoch 72; iter: 0; batch classifier loss: 0.067407; batch adversarial loss: 0.409752\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074774; batch adversarial loss: 0.390503\n",
      "epoch 74; iter: 0; batch classifier loss: 0.065673; batch adversarial loss: 0.551930\n",
      "epoch 75; iter: 0; batch classifier loss: 0.128730; batch adversarial loss: 0.521865\n",
      "epoch 76; iter: 0; batch classifier loss: 0.120484; batch adversarial loss: 0.404002\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094617; batch adversarial loss: 0.426295\n",
      "epoch 78; iter: 0; batch classifier loss: 0.111236; batch adversarial loss: 0.535810\n",
      "epoch 79; iter: 0; batch classifier loss: 0.066771; batch adversarial loss: 0.500080\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076167; batch adversarial loss: 0.485337\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081680; batch adversarial loss: 0.457508\n",
      "epoch 82; iter: 0; batch classifier loss: 0.109471; batch adversarial loss: 0.419935\n",
      "epoch 83; iter: 0; batch classifier loss: 0.140717; batch adversarial loss: 0.494076\n",
      "epoch 84; iter: 0; batch classifier loss: 0.141658; batch adversarial loss: 0.391042\n",
      "epoch 85; iter: 0; batch classifier loss: 0.079246; batch adversarial loss: 0.418530\n",
      "epoch 86; iter: 0; batch classifier loss: 0.093383; batch adversarial loss: 0.427558\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047084; batch adversarial loss: 0.518095\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076882; batch adversarial loss: 0.403221\n",
      "epoch 89; iter: 0; batch classifier loss: 0.038373; batch adversarial loss: 0.438073\n",
      "epoch 90; iter: 0; batch classifier loss: 0.093733; batch adversarial loss: 0.430161\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059770; batch adversarial loss: 0.441313\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071127; batch adversarial loss: 0.494022\n",
      "epoch 93; iter: 0; batch classifier loss: 0.113862; batch adversarial loss: 0.434191\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070607; batch adversarial loss: 0.389714\n",
      "epoch 95; iter: 0; batch classifier loss: 0.114796; batch adversarial loss: 0.430616\n",
      "epoch 96; iter: 0; batch classifier loss: 0.138746; batch adversarial loss: 0.406930\n",
      "epoch 97; iter: 0; batch classifier loss: 0.120304; batch adversarial loss: 0.570234\n",
      "epoch 98; iter: 0; batch classifier loss: 0.082633; batch adversarial loss: 0.447461\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061716; batch adversarial loss: 0.502778\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051747; batch adversarial loss: 0.471697\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039033; batch adversarial loss: 0.463391\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068210; batch adversarial loss: 0.410152\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050436; batch adversarial loss: 0.500512\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063891; batch adversarial loss: 0.432072\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049558; batch adversarial loss: 0.510920\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052719; batch adversarial loss: 0.482379\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038003; batch adversarial loss: 0.406438\n",
      "epoch 108; iter: 0; batch classifier loss: 0.071580; batch adversarial loss: 0.396690\n",
      "epoch 109; iter: 0; batch classifier loss: 0.080593; batch adversarial loss: 0.435407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.077757; batch adversarial loss: 0.449832\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042658; batch adversarial loss: 0.377164\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048608; batch adversarial loss: 0.487036\n",
      "epoch 113; iter: 0; batch classifier loss: 0.012870; batch adversarial loss: 0.382836\n",
      "epoch 114; iter: 0; batch classifier loss: 0.067598; batch adversarial loss: 0.495580\n",
      "epoch 115; iter: 0; batch classifier loss: 0.067419; batch adversarial loss: 0.444722\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050946; batch adversarial loss: 0.440380\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055012; batch adversarial loss: 0.439139\n",
      "epoch 118; iter: 0; batch classifier loss: 0.062941; batch adversarial loss: 0.496276\n",
      "epoch 119; iter: 0; batch classifier loss: 0.075854; batch adversarial loss: 0.457183\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046602; batch adversarial loss: 0.412403\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052440; batch adversarial loss: 0.541784\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045479; batch adversarial loss: 0.422774\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027533; batch adversarial loss: 0.523358\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030023; batch adversarial loss: 0.452586\n",
      "epoch 125; iter: 0; batch classifier loss: 0.072509; batch adversarial loss: 0.396720\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040133; batch adversarial loss: 0.512901\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033203; batch adversarial loss: 0.482704\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055884; batch adversarial loss: 0.438348\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047704; batch adversarial loss: 0.408636\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026334; batch adversarial loss: 0.454780\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052804; batch adversarial loss: 0.545116\n",
      "epoch 132; iter: 0; batch classifier loss: 0.070565; batch adversarial loss: 0.534739\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033593; batch adversarial loss: 0.455435\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020300; batch adversarial loss: 0.512738\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032462; batch adversarial loss: 0.378461\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038824; batch adversarial loss: 0.455913\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045130; batch adversarial loss: 0.529823\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041869; batch adversarial loss: 0.389139\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032505; batch adversarial loss: 0.454339\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041995; batch adversarial loss: 0.452136\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023459; batch adversarial loss: 0.437570\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030218; batch adversarial loss: 0.384742\n",
      "epoch 143; iter: 0; batch classifier loss: 0.062253; batch adversarial loss: 0.448846\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049803; batch adversarial loss: 0.407735\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029983; batch adversarial loss: 0.557253\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028890; batch adversarial loss: 0.446850\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023421; batch adversarial loss: 0.548405\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025245; batch adversarial loss: 0.407803\n",
      "epoch 149; iter: 0; batch classifier loss: 0.058384; batch adversarial loss: 0.438132\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038979; batch adversarial loss: 0.568867\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018692; batch adversarial loss: 0.419951\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042004; batch adversarial loss: 0.466859\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039990; batch adversarial loss: 0.466795\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046122; batch adversarial loss: 0.444716\n",
      "epoch 155; iter: 0; batch classifier loss: 0.053948; batch adversarial loss: 0.451444\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028359; batch adversarial loss: 0.374539\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022331; batch adversarial loss: 0.517426\n",
      "epoch 158; iter: 0; batch classifier loss: 0.046630; batch adversarial loss: 0.515677\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027414; batch adversarial loss: 0.400052\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046821; batch adversarial loss: 0.390738\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031441; batch adversarial loss: 0.514302\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014730; batch adversarial loss: 0.543223\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026062; batch adversarial loss: 0.482353\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037791; batch adversarial loss: 0.500429\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026167; batch adversarial loss: 0.415944\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019030; batch adversarial loss: 0.445312\n",
      "epoch 167; iter: 0; batch classifier loss: 0.066355; batch adversarial loss: 0.596477\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018353; batch adversarial loss: 0.428932\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012187; batch adversarial loss: 0.412800\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032849; batch adversarial loss: 0.397972\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018393; batch adversarial loss: 0.541710\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024915; batch adversarial loss: 0.351489\n",
      "epoch 173; iter: 0; batch classifier loss: 0.041699; batch adversarial loss: 0.383204\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025022; batch adversarial loss: 0.454945\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021934; batch adversarial loss: 0.437005\n",
      "epoch 176; iter: 0; batch classifier loss: 0.055614; batch adversarial loss: 0.462544\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022834; batch adversarial loss: 0.454055\n",
      "epoch 178; iter: 0; batch classifier loss: 0.053642; batch adversarial loss: 0.552255\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024418; batch adversarial loss: 0.448347\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008427; batch adversarial loss: 0.451122\n",
      "epoch 181; iter: 0; batch classifier loss: 0.047827; batch adversarial loss: 0.432823\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034705; batch adversarial loss: 0.390101\n",
      "epoch 183; iter: 0; batch classifier loss: 0.041268; batch adversarial loss: 0.465905\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033558; batch adversarial loss: 0.467260\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017569; batch adversarial loss: 0.477772\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025307; batch adversarial loss: 0.410090\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020193; batch adversarial loss: 0.503325\n",
      "epoch 188; iter: 0; batch classifier loss: 0.050285; batch adversarial loss: 0.518202\n",
      "epoch 189; iter: 0; batch classifier loss: 0.043036; batch adversarial loss: 0.505402\n",
      "epoch 190; iter: 0; batch classifier loss: 0.045569; batch adversarial loss: 0.469440\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034787; batch adversarial loss: 0.526185\n",
      "epoch 192; iter: 0; batch classifier loss: 0.081497; batch adversarial loss: 0.442386\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022922; batch adversarial loss: 0.410491\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010285; batch adversarial loss: 0.518569\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027235; batch adversarial loss: 0.430833\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006557; batch adversarial loss: 0.458166\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026379; batch adversarial loss: 0.444129\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030177; batch adversarial loss: 0.424220\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032986; batch adversarial loss: 0.415960\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685211; batch adversarial loss: 0.565131\n",
      "epoch 1; iter: 0; batch classifier loss: 0.393117; batch adversarial loss: 0.579920\n",
      "epoch 2; iter: 0; batch classifier loss: 0.447953; batch adversarial loss: 0.577318\n",
      "epoch 3; iter: 0; batch classifier loss: 0.338261; batch adversarial loss: 0.586035\n",
      "epoch 4; iter: 0; batch classifier loss: 0.394345; batch adversarial loss: 0.585052\n",
      "epoch 5; iter: 0; batch classifier loss: 0.401097; batch adversarial loss: 0.594008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.339613; batch adversarial loss: 0.597694\n",
      "epoch 7; iter: 0; batch classifier loss: 0.472540; batch adversarial loss: 0.585339\n",
      "epoch 8; iter: 0; batch classifier loss: 0.577115; batch adversarial loss: 0.585577\n",
      "epoch 9; iter: 0; batch classifier loss: 0.562146; batch adversarial loss: 0.556276\n",
      "epoch 10; iter: 0; batch classifier loss: 0.596667; batch adversarial loss: 0.536704\n",
      "epoch 11; iter: 0; batch classifier loss: 0.390273; batch adversarial loss: 0.572631\n",
      "epoch 12; iter: 0; batch classifier loss: 0.373749; batch adversarial loss: 0.484080\n",
      "epoch 13; iter: 0; batch classifier loss: 0.330166; batch adversarial loss: 0.479045\n",
      "epoch 14; iter: 0; batch classifier loss: 0.353720; batch adversarial loss: 0.509348\n",
      "epoch 15; iter: 0; batch classifier loss: 0.264717; batch adversarial loss: 0.513007\n",
      "epoch 16; iter: 0; batch classifier loss: 0.376320; batch adversarial loss: 0.437716\n",
      "epoch 17; iter: 0; batch classifier loss: 0.289259; batch adversarial loss: 0.476201\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320224; batch adversarial loss: 0.540810\n",
      "epoch 19; iter: 0; batch classifier loss: 0.234873; batch adversarial loss: 0.473212\n",
      "epoch 20; iter: 0; batch classifier loss: 0.289121; batch adversarial loss: 0.505726\n",
      "epoch 21; iter: 0; batch classifier loss: 0.261400; batch adversarial loss: 0.488702\n",
      "epoch 22; iter: 0; batch classifier loss: 0.310983; batch adversarial loss: 0.509207\n",
      "epoch 23; iter: 0; batch classifier loss: 0.241838; batch adversarial loss: 0.441362\n",
      "epoch 24; iter: 0; batch classifier loss: 0.282740; batch adversarial loss: 0.521033\n",
      "epoch 25; iter: 0; batch classifier loss: 0.234149; batch adversarial loss: 0.528535\n",
      "epoch 26; iter: 0; batch classifier loss: 0.229630; batch adversarial loss: 0.481648\n",
      "epoch 27; iter: 0; batch classifier loss: 0.302108; batch adversarial loss: 0.505042\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217826; batch adversarial loss: 0.454139\n",
      "epoch 29; iter: 0; batch classifier loss: 0.212243; batch adversarial loss: 0.500249\n",
      "epoch 30; iter: 0; batch classifier loss: 0.170773; batch adversarial loss: 0.557536\n",
      "epoch 31; iter: 0; batch classifier loss: 0.211489; batch adversarial loss: 0.514129\n",
      "epoch 32; iter: 0; batch classifier loss: 0.208753; batch adversarial loss: 0.509034\n",
      "epoch 33; iter: 0; batch classifier loss: 0.271847; batch adversarial loss: 0.362841\n",
      "epoch 34; iter: 0; batch classifier loss: 0.220861; batch adversarial loss: 0.448011\n",
      "epoch 35; iter: 0; batch classifier loss: 0.287402; batch adversarial loss: 0.479842\n",
      "epoch 36; iter: 0; batch classifier loss: 0.226474; batch adversarial loss: 0.396277\n",
      "epoch 37; iter: 0; batch classifier loss: 0.206349; batch adversarial loss: 0.487212\n",
      "epoch 38; iter: 0; batch classifier loss: 0.249007; batch adversarial loss: 0.431999\n",
      "epoch 39; iter: 0; batch classifier loss: 0.170073; batch adversarial loss: 0.491260\n",
      "epoch 40; iter: 0; batch classifier loss: 0.178129; batch adversarial loss: 0.476071\n",
      "epoch 41; iter: 0; batch classifier loss: 0.206714; batch adversarial loss: 0.438261\n",
      "epoch 42; iter: 0; batch classifier loss: 0.217504; batch adversarial loss: 0.434217\n",
      "epoch 43; iter: 0; batch classifier loss: 0.264919; batch adversarial loss: 0.548585\n",
      "epoch 44; iter: 0; batch classifier loss: 0.214264; batch adversarial loss: 0.473877\n",
      "epoch 45; iter: 0; batch classifier loss: 0.178772; batch adversarial loss: 0.437041\n",
      "epoch 46; iter: 0; batch classifier loss: 0.217516; batch adversarial loss: 0.471802\n",
      "epoch 47; iter: 0; batch classifier loss: 0.243637; batch adversarial loss: 0.459200\n",
      "epoch 48; iter: 0; batch classifier loss: 0.168442; batch adversarial loss: 0.482613\n",
      "epoch 49; iter: 0; batch classifier loss: 0.276887; batch adversarial loss: 0.482442\n",
      "epoch 50; iter: 0; batch classifier loss: 0.211361; batch adversarial loss: 0.458551\n",
      "epoch 51; iter: 0; batch classifier loss: 0.132321; batch adversarial loss: 0.412954\n",
      "epoch 52; iter: 0; batch classifier loss: 0.261426; batch adversarial loss: 0.509738\n",
      "epoch 53; iter: 0; batch classifier loss: 0.152275; batch adversarial loss: 0.469802\n",
      "epoch 54; iter: 0; batch classifier loss: 0.172850; batch adversarial loss: 0.483237\n",
      "epoch 55; iter: 0; batch classifier loss: 0.269266; batch adversarial loss: 0.425813\n",
      "epoch 56; iter: 0; batch classifier loss: 0.153565; batch adversarial loss: 0.435685\n",
      "epoch 57; iter: 0; batch classifier loss: 0.205838; batch adversarial loss: 0.458796\n",
      "epoch 58; iter: 0; batch classifier loss: 0.269426; batch adversarial loss: 0.413211\n",
      "epoch 59; iter: 0; batch classifier loss: 0.143470; batch adversarial loss: 0.398396\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104829; batch adversarial loss: 0.531252\n",
      "epoch 61; iter: 0; batch classifier loss: 0.164559; batch adversarial loss: 0.433781\n",
      "epoch 62; iter: 0; batch classifier loss: 0.199570; batch adversarial loss: 0.460427\n",
      "epoch 63; iter: 0; batch classifier loss: 0.156390; batch adversarial loss: 0.422916\n",
      "epoch 64; iter: 0; batch classifier loss: 0.189984; batch adversarial loss: 0.434511\n",
      "epoch 65; iter: 0; batch classifier loss: 0.250218; batch adversarial loss: 0.483308\n",
      "epoch 66; iter: 0; batch classifier loss: 0.252753; batch adversarial loss: 0.424927\n",
      "epoch 67; iter: 0; batch classifier loss: 0.217853; batch adversarial loss: 0.387206\n",
      "epoch 68; iter: 0; batch classifier loss: 0.216627; batch adversarial loss: 0.435477\n",
      "epoch 69; iter: 0; batch classifier loss: 0.122493; batch adversarial loss: 0.481326\n",
      "epoch 70; iter: 0; batch classifier loss: 0.060289; batch adversarial loss: 0.445227\n",
      "epoch 71; iter: 0; batch classifier loss: 0.103907; batch adversarial loss: 0.483461\n",
      "epoch 72; iter: 0; batch classifier loss: 0.112349; batch adversarial loss: 0.527317\n",
      "epoch 73; iter: 0; batch classifier loss: 0.063810; batch adversarial loss: 0.452091\n",
      "epoch 74; iter: 0; batch classifier loss: 0.052743; batch adversarial loss: 0.421882\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066956; batch adversarial loss: 0.495993\n",
      "epoch 76; iter: 0; batch classifier loss: 0.098247; batch adversarial loss: 0.360621\n",
      "epoch 77; iter: 0; batch classifier loss: 0.115955; batch adversarial loss: 0.444124\n",
      "epoch 78; iter: 0; batch classifier loss: 0.116263; batch adversarial loss: 0.397720\n",
      "epoch 79; iter: 0; batch classifier loss: 0.103287; batch adversarial loss: 0.510056\n",
      "epoch 80; iter: 0; batch classifier loss: 0.092069; batch adversarial loss: 0.432989\n",
      "epoch 81; iter: 0; batch classifier loss: 0.115940; batch adversarial loss: 0.395091\n",
      "epoch 82; iter: 0; batch classifier loss: 0.098516; batch adversarial loss: 0.438329\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081860; batch adversarial loss: 0.464766\n",
      "epoch 84; iter: 0; batch classifier loss: 0.072733; batch adversarial loss: 0.493262\n",
      "epoch 85; iter: 0; batch classifier loss: 0.103214; batch adversarial loss: 0.485535\n",
      "epoch 86; iter: 0; batch classifier loss: 0.110571; batch adversarial loss: 0.498954\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071158; batch adversarial loss: 0.508189\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069190; batch adversarial loss: 0.485300\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065170; batch adversarial loss: 0.474709\n",
      "epoch 90; iter: 0; batch classifier loss: 0.135781; batch adversarial loss: 0.403156\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062557; batch adversarial loss: 0.483494\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064963; batch adversarial loss: 0.411979\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067531; batch adversarial loss: 0.424786\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053684; batch adversarial loss: 0.531101\n",
      "epoch 95; iter: 0; batch classifier loss: 0.108461; batch adversarial loss: 0.453574\n",
      "epoch 96; iter: 0; batch classifier loss: 0.038710; batch adversarial loss: 0.495552\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066397; batch adversarial loss: 0.514340\n",
      "epoch 98; iter: 0; batch classifier loss: 0.092414; batch adversarial loss: 0.438236\n",
      "epoch 99; iter: 0; batch classifier loss: 0.109629; batch adversarial loss: 0.451148\n",
      "epoch 100; iter: 0; batch classifier loss: 0.063423; batch adversarial loss: 0.547289\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043444; batch adversarial loss: 0.467041\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033113; batch adversarial loss: 0.607043\n",
      "epoch 103; iter: 0; batch classifier loss: 0.065246; batch adversarial loss: 0.425520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.074423; batch adversarial loss: 0.498200\n",
      "epoch 105; iter: 0; batch classifier loss: 0.101435; batch adversarial loss: 0.428343\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056437; batch adversarial loss: 0.470422\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059807; batch adversarial loss: 0.459027\n",
      "epoch 108; iter: 0; batch classifier loss: 0.047699; batch adversarial loss: 0.383796\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043140; batch adversarial loss: 0.445261\n",
      "epoch 110; iter: 0; batch classifier loss: 0.083880; batch adversarial loss: 0.462102\n",
      "epoch 111; iter: 0; batch classifier loss: 0.067437; batch adversarial loss: 0.482925\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047304; batch adversarial loss: 0.493181\n",
      "epoch 113; iter: 0; batch classifier loss: 0.111507; batch adversarial loss: 0.509722\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050738; batch adversarial loss: 0.418328\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053948; batch adversarial loss: 0.486783\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022730; batch adversarial loss: 0.459766\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037496; batch adversarial loss: 0.545706\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028048; batch adversarial loss: 0.398948\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021746; batch adversarial loss: 0.455416\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045732; batch adversarial loss: 0.451137\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047005; batch adversarial loss: 0.447764\n",
      "epoch 122; iter: 0; batch classifier loss: 0.064465; batch adversarial loss: 0.394603\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045353; batch adversarial loss: 0.471880\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043827; batch adversarial loss: 0.491535\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052076; batch adversarial loss: 0.475358\n",
      "epoch 126; iter: 0; batch classifier loss: 0.067009; batch adversarial loss: 0.486950\n",
      "epoch 127; iter: 0; batch classifier loss: 0.065480; batch adversarial loss: 0.471473\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053740; batch adversarial loss: 0.463026\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016908; batch adversarial loss: 0.392261\n",
      "epoch 130; iter: 0; batch classifier loss: 0.063150; batch adversarial loss: 0.430769\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030119; batch adversarial loss: 0.446420\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045452; batch adversarial loss: 0.590646\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018803; batch adversarial loss: 0.384508\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027863; batch adversarial loss: 0.519080\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024642; batch adversarial loss: 0.468283\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021952; batch adversarial loss: 0.461977\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030501; batch adversarial loss: 0.397292\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040979; batch adversarial loss: 0.388989\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049595; batch adversarial loss: 0.465945\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023251; batch adversarial loss: 0.412584\n",
      "epoch 141; iter: 0; batch classifier loss: 0.013243; batch adversarial loss: 0.530998\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021765; batch adversarial loss: 0.400509\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014407; batch adversarial loss: 0.491238\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045741; batch adversarial loss: 0.539872\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017794; batch adversarial loss: 0.445684\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039162; batch adversarial loss: 0.383534\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041332; batch adversarial loss: 0.379218\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054395; batch adversarial loss: 0.430382\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028936; batch adversarial loss: 0.474417\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025441; batch adversarial loss: 0.469027\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030353; batch adversarial loss: 0.422845\n",
      "epoch 152; iter: 0; batch classifier loss: 0.009494; batch adversarial loss: 0.458814\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036599; batch adversarial loss: 0.467938\n",
      "epoch 154; iter: 0; batch classifier loss: 0.051866; batch adversarial loss: 0.435427\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017911; batch adversarial loss: 0.570305\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043171; batch adversarial loss: 0.398433\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026218; batch adversarial loss: 0.468416\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012624; batch adversarial loss: 0.569863\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020377; batch adversarial loss: 0.391156\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032125; batch adversarial loss: 0.443692\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028897; batch adversarial loss: 0.450329\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021204; batch adversarial loss: 0.400725\n",
      "epoch 163; iter: 0; batch classifier loss: 0.046895; batch adversarial loss: 0.469603\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013209; batch adversarial loss: 0.522557\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015163; batch adversarial loss: 0.636167\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023204; batch adversarial loss: 0.574999\n",
      "epoch 167; iter: 0; batch classifier loss: 0.004664; batch adversarial loss: 0.462045\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028471; batch adversarial loss: 0.520591\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009432; batch adversarial loss: 0.377282\n",
      "epoch 170; iter: 0; batch classifier loss: 0.043187; batch adversarial loss: 0.467499\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009528; batch adversarial loss: 0.444600\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011713; batch adversarial loss: 0.480467\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018385; batch adversarial loss: 0.470040\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019074; batch adversarial loss: 0.429667\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039136; batch adversarial loss: 0.591727\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023822; batch adversarial loss: 0.523470\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020975; batch adversarial loss: 0.452445\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007202; batch adversarial loss: 0.456510\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017380; batch adversarial loss: 0.474435\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033336; batch adversarial loss: 0.514715\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020203; batch adversarial loss: 0.408952\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013743; batch adversarial loss: 0.458681\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010754; batch adversarial loss: 0.494259\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029364; batch adversarial loss: 0.495093\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020219; batch adversarial loss: 0.442859\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035325; batch adversarial loss: 0.389578\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029526; batch adversarial loss: 0.493361\n",
      "epoch 188; iter: 0; batch classifier loss: 0.051462; batch adversarial loss: 0.489332\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012825; batch adversarial loss: 0.489181\n",
      "epoch 190; iter: 0; batch classifier loss: 0.044648; batch adversarial loss: 0.440528\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021738; batch adversarial loss: 0.589237\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009284; batch adversarial loss: 0.482695\n",
      "epoch 193; iter: 0; batch classifier loss: 0.038581; batch adversarial loss: 0.414773\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031653; batch adversarial loss: 0.421607\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016276; batch adversarial loss: 0.468945\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009275; batch adversarial loss: 0.550609\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037191; batch adversarial loss: 0.399670\n",
      "epoch 198; iter: 0; batch classifier loss: 0.036763; batch adversarial loss: 0.440415\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005478; batch adversarial loss: 0.517261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.722977; batch adversarial loss: 0.796720\n",
      "epoch 1; iter: 0; batch classifier loss: 0.388267; batch adversarial loss: 0.740537\n",
      "epoch 2; iter: 0; batch classifier loss: 0.398293; batch adversarial loss: 0.771186\n",
      "epoch 3; iter: 0; batch classifier loss: 0.349134; batch adversarial loss: 0.719816\n",
      "epoch 4; iter: 0; batch classifier loss: 0.274974; batch adversarial loss: 0.651787\n",
      "epoch 5; iter: 0; batch classifier loss: 0.278896; batch adversarial loss: 0.645633\n",
      "epoch 6; iter: 0; batch classifier loss: 0.304322; batch adversarial loss: 0.613434\n",
      "epoch 7; iter: 0; batch classifier loss: 0.307690; batch adversarial loss: 0.601453\n",
      "epoch 8; iter: 0; batch classifier loss: 0.301677; batch adversarial loss: 0.565274\n",
      "epoch 9; iter: 0; batch classifier loss: 0.324191; batch adversarial loss: 0.552175\n",
      "epoch 10; iter: 0; batch classifier loss: 0.266064; batch adversarial loss: 0.497691\n",
      "epoch 11; iter: 0; batch classifier loss: 0.252389; batch adversarial loss: 0.531631\n",
      "epoch 12; iter: 0; batch classifier loss: 0.270774; batch adversarial loss: 0.441290\n",
      "epoch 13; iter: 0; batch classifier loss: 0.277034; batch adversarial loss: 0.446884\n",
      "epoch 14; iter: 0; batch classifier loss: 0.240181; batch adversarial loss: 0.443050\n",
      "epoch 15; iter: 0; batch classifier loss: 0.233165; batch adversarial loss: 0.493865\n",
      "epoch 16; iter: 0; batch classifier loss: 0.208469; batch adversarial loss: 0.387497\n",
      "epoch 17; iter: 0; batch classifier loss: 0.232595; batch adversarial loss: 0.518002\n",
      "epoch 18; iter: 0; batch classifier loss: 0.217030; batch adversarial loss: 0.419494\n",
      "epoch 19; iter: 0; batch classifier loss: 0.212069; batch adversarial loss: 0.442828\n",
      "epoch 20; iter: 0; batch classifier loss: 0.214421; batch adversarial loss: 0.409588\n",
      "epoch 21; iter: 0; batch classifier loss: 0.213042; batch adversarial loss: 0.404202\n",
      "epoch 22; iter: 0; batch classifier loss: 0.190862; batch adversarial loss: 0.417150\n",
      "epoch 23; iter: 0; batch classifier loss: 0.170549; batch adversarial loss: 0.399642\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214703; batch adversarial loss: 0.406026\n",
      "epoch 25; iter: 0; batch classifier loss: 0.234155; batch adversarial loss: 0.321030\n",
      "epoch 26; iter: 0; batch classifier loss: 0.136990; batch adversarial loss: 0.427123\n",
      "epoch 27; iter: 0; batch classifier loss: 0.146660; batch adversarial loss: 0.372693\n",
      "epoch 28; iter: 0; batch classifier loss: 0.156365; batch adversarial loss: 0.482152\n",
      "epoch 29; iter: 0; batch classifier loss: 0.200747; batch adversarial loss: 0.499452\n",
      "epoch 30; iter: 0; batch classifier loss: 0.139974; batch adversarial loss: 0.379853\n",
      "epoch 31; iter: 0; batch classifier loss: 0.129507; batch adversarial loss: 0.393944\n",
      "epoch 32; iter: 0; batch classifier loss: 0.129204; batch adversarial loss: 0.333758\n",
      "epoch 33; iter: 0; batch classifier loss: 0.187562; batch adversarial loss: 0.458360\n",
      "epoch 34; iter: 0; batch classifier loss: 0.150246; batch adversarial loss: 0.378821\n",
      "epoch 35; iter: 0; batch classifier loss: 0.157531; batch adversarial loss: 0.410853\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128959; batch adversarial loss: 0.436670\n",
      "epoch 37; iter: 0; batch classifier loss: 0.130508; batch adversarial loss: 0.382061\n",
      "epoch 38; iter: 0; batch classifier loss: 0.123496; batch adversarial loss: 0.416228\n",
      "epoch 39; iter: 0; batch classifier loss: 0.163245; batch adversarial loss: 0.398126\n",
      "epoch 40; iter: 0; batch classifier loss: 0.132569; batch adversarial loss: 0.423258\n",
      "epoch 41; iter: 0; batch classifier loss: 0.150225; batch adversarial loss: 0.439029\n",
      "epoch 42; iter: 0; batch classifier loss: 0.094717; batch adversarial loss: 0.401620\n",
      "epoch 43; iter: 0; batch classifier loss: 0.186242; batch adversarial loss: 0.328145\n",
      "epoch 44; iter: 0; batch classifier loss: 0.109453; batch adversarial loss: 0.415352\n",
      "epoch 45; iter: 0; batch classifier loss: 0.106815; batch adversarial loss: 0.406451\n",
      "epoch 46; iter: 0; batch classifier loss: 0.152066; batch adversarial loss: 0.449711\n",
      "epoch 47; iter: 0; batch classifier loss: 0.102852; batch adversarial loss: 0.452450\n",
      "epoch 48; iter: 0; batch classifier loss: 0.087022; batch adversarial loss: 0.433668\n",
      "epoch 49; iter: 0; batch classifier loss: 0.128618; batch adversarial loss: 0.444335\n",
      "epoch 50; iter: 0; batch classifier loss: 0.086370; batch adversarial loss: 0.398375\n",
      "epoch 51; iter: 0; batch classifier loss: 0.131165; batch adversarial loss: 0.412406\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089401; batch adversarial loss: 0.379704\n",
      "epoch 53; iter: 0; batch classifier loss: 0.118897; batch adversarial loss: 0.403650\n",
      "epoch 54; iter: 0; batch classifier loss: 0.098837; batch adversarial loss: 0.401017\n",
      "epoch 55; iter: 0; batch classifier loss: 0.069859; batch adversarial loss: 0.402603\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103950; batch adversarial loss: 0.432817\n",
      "epoch 57; iter: 0; batch classifier loss: 0.070642; batch adversarial loss: 0.398750\n",
      "epoch 58; iter: 0; batch classifier loss: 0.076117; batch adversarial loss: 0.431678\n",
      "epoch 59; iter: 0; batch classifier loss: 0.114510; batch adversarial loss: 0.451259\n",
      "epoch 60; iter: 0; batch classifier loss: 0.085720; batch adversarial loss: 0.354157\n",
      "epoch 61; iter: 0; batch classifier loss: 0.085677; batch adversarial loss: 0.362997\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080997; batch adversarial loss: 0.436609\n",
      "epoch 63; iter: 0; batch classifier loss: 0.101910; batch adversarial loss: 0.493931\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083454; batch adversarial loss: 0.382111\n",
      "epoch 65; iter: 0; batch classifier loss: 0.112260; batch adversarial loss: 0.378317\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078912; batch adversarial loss: 0.351504\n",
      "epoch 67; iter: 0; batch classifier loss: 0.064721; batch adversarial loss: 0.385673\n",
      "epoch 68; iter: 0; batch classifier loss: 0.060186; batch adversarial loss: 0.422342\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103338; batch adversarial loss: 0.462223\n",
      "epoch 70; iter: 0; batch classifier loss: 0.107716; batch adversarial loss: 0.475306\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089277; batch adversarial loss: 0.451841\n",
      "epoch 72; iter: 0; batch classifier loss: 0.037760; batch adversarial loss: 0.399820\n",
      "epoch 73; iter: 0; batch classifier loss: 0.052766; batch adversarial loss: 0.389937\n",
      "epoch 74; iter: 0; batch classifier loss: 0.045592; batch adversarial loss: 0.383851\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069553; batch adversarial loss: 0.370187\n",
      "epoch 76; iter: 0; batch classifier loss: 0.041851; batch adversarial loss: 0.469806\n",
      "epoch 77; iter: 0; batch classifier loss: 0.077190; batch adversarial loss: 0.365015\n",
      "epoch 78; iter: 0; batch classifier loss: 0.055049; batch adversarial loss: 0.359396\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076971; batch adversarial loss: 0.442816\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043998; batch adversarial loss: 0.512291\n",
      "epoch 81; iter: 0; batch classifier loss: 0.051488; batch adversarial loss: 0.374057\n",
      "epoch 82; iter: 0; batch classifier loss: 0.043770; batch adversarial loss: 0.503250\n",
      "epoch 83; iter: 0; batch classifier loss: 0.039447; batch adversarial loss: 0.417431\n",
      "epoch 84; iter: 0; batch classifier loss: 0.050394; batch adversarial loss: 0.389395\n",
      "epoch 85; iter: 0; batch classifier loss: 0.048409; batch adversarial loss: 0.488228\n",
      "epoch 86; iter: 0; batch classifier loss: 0.026376; batch adversarial loss: 0.467886\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046414; batch adversarial loss: 0.447064\n",
      "epoch 88; iter: 0; batch classifier loss: 0.034349; batch adversarial loss: 0.572724\n",
      "epoch 89; iter: 0; batch classifier loss: 0.040461; batch adversarial loss: 0.372295\n",
      "epoch 90; iter: 0; batch classifier loss: 0.033981; batch adversarial loss: 0.504130\n",
      "epoch 91; iter: 0; batch classifier loss: 0.032263; batch adversarial loss: 0.438935\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041761; batch adversarial loss: 0.494006\n",
      "epoch 93; iter: 0; batch classifier loss: 0.032462; batch adversarial loss: 0.415509\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044291; batch adversarial loss: 0.433953\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060751; batch adversarial loss: 0.446940\n",
      "epoch 96; iter: 0; batch classifier loss: 0.015631; batch adversarial loss: 0.447581\n",
      "epoch 97; iter: 0; batch classifier loss: 0.029095; batch adversarial loss: 0.388180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.040512; batch adversarial loss: 0.513228\n",
      "epoch 99; iter: 0; batch classifier loss: 0.027060; batch adversarial loss: 0.520266\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034714; batch adversarial loss: 0.453300\n",
      "epoch 101; iter: 0; batch classifier loss: 0.091269; batch adversarial loss: 0.511117\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039242; batch adversarial loss: 0.498844\n",
      "epoch 103; iter: 0; batch classifier loss: 0.051518; batch adversarial loss: 0.453697\n",
      "epoch 104; iter: 0; batch classifier loss: 0.074893; batch adversarial loss: 0.511319\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035753; batch adversarial loss: 0.432215\n",
      "epoch 106; iter: 0; batch classifier loss: 0.090208; batch adversarial loss: 0.494017\n",
      "epoch 107; iter: 0; batch classifier loss: 0.114104; batch adversarial loss: 0.738282\n",
      "epoch 108; iter: 0; batch classifier loss: 0.109491; batch adversarial loss: 0.562605\n",
      "epoch 109; iter: 0; batch classifier loss: 0.131515; batch adversarial loss: 0.424278\n",
      "epoch 110; iter: 0; batch classifier loss: 0.101887; batch adversarial loss: 0.475966\n",
      "epoch 111; iter: 0; batch classifier loss: 0.138717; batch adversarial loss: 0.697754\n",
      "epoch 112; iter: 0; batch classifier loss: 0.061639; batch adversarial loss: 0.461223\n",
      "epoch 113; iter: 0; batch classifier loss: 0.095995; batch adversarial loss: 0.551339\n",
      "epoch 114; iter: 0; batch classifier loss: 0.098475; batch adversarial loss: 0.688437\n",
      "epoch 115; iter: 0; batch classifier loss: 0.094014; batch adversarial loss: 0.553203\n",
      "epoch 116; iter: 0; batch classifier loss: 0.141368; batch adversarial loss: 0.568171\n",
      "epoch 117; iter: 0; batch classifier loss: 0.112596; batch adversarial loss: 0.591630\n",
      "epoch 118; iter: 0; batch classifier loss: 0.126861; batch adversarial loss: 0.462065\n",
      "epoch 119; iter: 0; batch classifier loss: 0.143144; batch adversarial loss: 0.613315\n",
      "epoch 120; iter: 0; batch classifier loss: 0.113792; batch adversarial loss: 0.481574\n",
      "epoch 121; iter: 0; batch classifier loss: 0.146067; batch adversarial loss: 0.556699\n",
      "epoch 122; iter: 0; batch classifier loss: 0.108562; batch adversarial loss: 0.440798\n",
      "epoch 123; iter: 0; batch classifier loss: 0.153448; batch adversarial loss: 0.486023\n",
      "epoch 124; iter: 0; batch classifier loss: 0.114680; batch adversarial loss: 0.520357\n",
      "epoch 125; iter: 0; batch classifier loss: 0.103216; batch adversarial loss: 0.530532\n",
      "epoch 126; iter: 0; batch classifier loss: 0.175316; batch adversarial loss: 0.676345\n",
      "epoch 127; iter: 0; batch classifier loss: 0.095819; batch adversarial loss: 0.498452\n",
      "epoch 128; iter: 0; batch classifier loss: 0.067633; batch adversarial loss: 0.424213\n",
      "epoch 129; iter: 0; batch classifier loss: 0.120089; batch adversarial loss: 0.502326\n",
      "epoch 130; iter: 0; batch classifier loss: 0.088208; batch adversarial loss: 0.480304\n",
      "epoch 131; iter: 0; batch classifier loss: 0.128546; batch adversarial loss: 0.533352\n",
      "epoch 132; iter: 0; batch classifier loss: 0.112027; batch adversarial loss: 0.531684\n",
      "epoch 133; iter: 0; batch classifier loss: 0.112703; batch adversarial loss: 0.562009\n",
      "epoch 134; iter: 0; batch classifier loss: 0.183133; batch adversarial loss: 0.576073\n",
      "epoch 135; iter: 0; batch classifier loss: 0.081743; batch adversarial loss: 0.492256\n",
      "epoch 136; iter: 0; batch classifier loss: 0.153866; batch adversarial loss: 0.515414\n",
      "epoch 137; iter: 0; batch classifier loss: 0.109822; batch adversarial loss: 0.570217\n",
      "epoch 138; iter: 0; batch classifier loss: 0.096754; batch adversarial loss: 0.456786\n",
      "epoch 139; iter: 0; batch classifier loss: 0.109422; batch adversarial loss: 0.439705\n",
      "epoch 140; iter: 0; batch classifier loss: 0.088363; batch adversarial loss: 0.559117\n",
      "epoch 141; iter: 0; batch classifier loss: 0.090216; batch adversarial loss: 0.457938\n",
      "epoch 142; iter: 0; batch classifier loss: 0.055967; batch adversarial loss: 0.455529\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030594; batch adversarial loss: 0.471873\n",
      "epoch 144; iter: 0; batch classifier loss: 0.060663; batch adversarial loss: 0.464308\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016113; batch adversarial loss: 0.483725\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028506; batch adversarial loss: 0.463313\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027626; batch adversarial loss: 0.464748\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029791; batch adversarial loss: 0.510818\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056471; batch adversarial loss: 0.454348\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029839; batch adversarial loss: 0.469616\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039279; batch adversarial loss: 0.449651\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036826; batch adversarial loss: 0.449825\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024285; batch adversarial loss: 0.338377\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024501; batch adversarial loss: 0.524133\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036301; batch adversarial loss: 0.509523\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045960; batch adversarial loss: 0.517152\n",
      "epoch 157; iter: 0; batch classifier loss: 0.060138; batch adversarial loss: 0.451248\n",
      "epoch 158; iter: 0; batch classifier loss: 0.039674; batch adversarial loss: 0.395974\n",
      "epoch 159; iter: 0; batch classifier loss: 0.053975; batch adversarial loss: 0.485086\n",
      "epoch 160; iter: 0; batch classifier loss: 0.063071; batch adversarial loss: 0.399268\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027062; batch adversarial loss: 0.467149\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038912; batch adversarial loss: 0.427831\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042090; batch adversarial loss: 0.457504\n",
      "epoch 164; iter: 0; batch classifier loss: 0.056486; batch adversarial loss: 0.467083\n",
      "epoch 165; iter: 0; batch classifier loss: 0.052337; batch adversarial loss: 0.384376\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040633; batch adversarial loss: 0.447653\n",
      "epoch 167; iter: 0; batch classifier loss: 0.054411; batch adversarial loss: 0.416430\n",
      "epoch 168; iter: 0; batch classifier loss: 0.057556; batch adversarial loss: 0.521415\n",
      "epoch 169; iter: 0; batch classifier loss: 0.093583; batch adversarial loss: 0.363242\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040572; batch adversarial loss: 0.483596\n",
      "epoch 171; iter: 0; batch classifier loss: 0.070162; batch adversarial loss: 0.445271\n",
      "epoch 172; iter: 0; batch classifier loss: 0.081861; batch adversarial loss: 0.506493\n",
      "epoch 173; iter: 0; batch classifier loss: 0.061928; batch adversarial loss: 0.457824\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040530; batch adversarial loss: 0.410905\n",
      "epoch 175; iter: 0; batch classifier loss: 0.070100; batch adversarial loss: 0.449892\n",
      "epoch 176; iter: 0; batch classifier loss: 0.126609; batch adversarial loss: 0.378195\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027728; batch adversarial loss: 0.437005\n",
      "epoch 178; iter: 0; batch classifier loss: 0.054315; batch adversarial loss: 0.419596\n",
      "epoch 179; iter: 0; batch classifier loss: 0.081575; batch adversarial loss: 0.435927\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040471; batch adversarial loss: 0.385108\n",
      "epoch 181; iter: 0; batch classifier loss: 0.058511; batch adversarial loss: 0.509979\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037388; batch adversarial loss: 0.495230\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027407; batch adversarial loss: 0.406588\n",
      "epoch 184; iter: 0; batch classifier loss: 0.057453; batch adversarial loss: 0.438359\n",
      "epoch 185; iter: 0; batch classifier loss: 0.067668; batch adversarial loss: 0.434420\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029766; batch adversarial loss: 0.459748\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021412; batch adversarial loss: 0.451359\n",
      "epoch 188; iter: 0; batch classifier loss: 0.055556; batch adversarial loss: 0.495996\n",
      "epoch 189; iter: 0; batch classifier loss: 0.053728; batch adversarial loss: 0.517025\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036308; batch adversarial loss: 0.450732\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028282; batch adversarial loss: 0.499707\n",
      "epoch 192; iter: 0; batch classifier loss: 0.061267; batch adversarial loss: 0.493024\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030966; batch adversarial loss: 0.466559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.025513; batch adversarial loss: 0.532638\n",
      "epoch 195; iter: 0; batch classifier loss: 0.041494; batch adversarial loss: 0.579308\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032961; batch adversarial loss: 0.481477\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031673; batch adversarial loss: 0.477209\n",
      "epoch 198; iter: 0; batch classifier loss: 0.057332; batch adversarial loss: 0.385048\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023805; batch adversarial loss: 0.458976\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708444; batch adversarial loss: 0.819245\n",
      "epoch 1; iter: 0; batch classifier loss: 0.469623; batch adversarial loss: 0.773216\n",
      "epoch 2; iter: 0; batch classifier loss: 0.470006; batch adversarial loss: 0.731908\n",
      "epoch 3; iter: 0; batch classifier loss: 0.508965; batch adversarial loss: 0.688212\n",
      "epoch 4; iter: 0; batch classifier loss: 0.547518; batch adversarial loss: 0.635814\n",
      "epoch 5; iter: 0; batch classifier loss: 0.431196; batch adversarial loss: 0.602386\n",
      "epoch 6; iter: 0; batch classifier loss: 0.426157; batch adversarial loss: 0.584764\n",
      "epoch 7; iter: 0; batch classifier loss: 0.307013; batch adversarial loss: 0.574674\n",
      "epoch 8; iter: 0; batch classifier loss: 0.304575; batch adversarial loss: 0.534840\n",
      "epoch 9; iter: 0; batch classifier loss: 0.332234; batch adversarial loss: 0.544918\n",
      "epoch 10; iter: 0; batch classifier loss: 0.319309; batch adversarial loss: 0.492810\n",
      "epoch 11; iter: 0; batch classifier loss: 0.350474; batch adversarial loss: 0.587804\n",
      "epoch 12; iter: 0; batch classifier loss: 0.375172; batch adversarial loss: 0.556741\n",
      "epoch 13; iter: 0; batch classifier loss: 0.411752; batch adversarial loss: 0.531690\n",
      "epoch 14; iter: 0; batch classifier loss: 0.416557; batch adversarial loss: 0.507515\n",
      "epoch 15; iter: 0; batch classifier loss: 0.398752; batch adversarial loss: 0.534849\n",
      "epoch 16; iter: 0; batch classifier loss: 0.423973; batch adversarial loss: 0.490095\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310407; batch adversarial loss: 0.519594\n",
      "epoch 18; iter: 0; batch classifier loss: 0.316782; batch adversarial loss: 0.504592\n",
      "epoch 19; iter: 0; batch classifier loss: 0.319401; batch adversarial loss: 0.449779\n",
      "epoch 20; iter: 0; batch classifier loss: 0.365709; batch adversarial loss: 0.473912\n",
      "epoch 21; iter: 0; batch classifier loss: 0.290040; batch adversarial loss: 0.454851\n",
      "epoch 22; iter: 0; batch classifier loss: 0.225256; batch adversarial loss: 0.490631\n",
      "epoch 23; iter: 0; batch classifier loss: 0.256250; batch adversarial loss: 0.476962\n",
      "epoch 24; iter: 0; batch classifier loss: 0.227554; batch adversarial loss: 0.437236\n",
      "epoch 25; iter: 0; batch classifier loss: 0.229929; batch adversarial loss: 0.485776\n",
      "epoch 26; iter: 0; batch classifier loss: 0.195755; batch adversarial loss: 0.453234\n",
      "epoch 27; iter: 0; batch classifier loss: 0.252361; batch adversarial loss: 0.539831\n",
      "epoch 28; iter: 0; batch classifier loss: 0.286077; batch adversarial loss: 0.469816\n",
      "epoch 29; iter: 0; batch classifier loss: 0.271373; batch adversarial loss: 0.464950\n",
      "epoch 30; iter: 0; batch classifier loss: 0.236353; batch adversarial loss: 0.395798\n",
      "epoch 31; iter: 0; batch classifier loss: 0.232419; batch adversarial loss: 0.452550\n",
      "epoch 32; iter: 0; batch classifier loss: 0.233005; batch adversarial loss: 0.396811\n",
      "epoch 33; iter: 0; batch classifier loss: 0.238939; batch adversarial loss: 0.412834\n",
      "epoch 34; iter: 0; batch classifier loss: 0.225304; batch adversarial loss: 0.389784\n",
      "epoch 35; iter: 0; batch classifier loss: 0.189783; batch adversarial loss: 0.471449\n",
      "epoch 36; iter: 0; batch classifier loss: 0.247806; batch adversarial loss: 0.402514\n",
      "epoch 37; iter: 0; batch classifier loss: 0.230696; batch adversarial loss: 0.402234\n",
      "epoch 38; iter: 0; batch classifier loss: 0.200115; batch adversarial loss: 0.419822\n",
      "epoch 39; iter: 0; batch classifier loss: 0.176948; batch adversarial loss: 0.496669\n",
      "epoch 40; iter: 0; batch classifier loss: 0.231777; batch adversarial loss: 0.449377\n",
      "epoch 41; iter: 0; batch classifier loss: 0.183541; batch adversarial loss: 0.452177\n",
      "epoch 42; iter: 0; batch classifier loss: 0.184093; batch adversarial loss: 0.424220\n",
      "epoch 43; iter: 0; batch classifier loss: 0.184517; batch adversarial loss: 0.576334\n",
      "epoch 44; iter: 0; batch classifier loss: 0.190427; batch adversarial loss: 0.403933\n",
      "epoch 45; iter: 0; batch classifier loss: 0.183016; batch adversarial loss: 0.379856\n",
      "epoch 46; iter: 0; batch classifier loss: 0.185147; batch adversarial loss: 0.496206\n",
      "epoch 47; iter: 0; batch classifier loss: 0.149310; batch adversarial loss: 0.418467\n",
      "epoch 48; iter: 0; batch classifier loss: 0.140821; batch adversarial loss: 0.544961\n",
      "epoch 49; iter: 0; batch classifier loss: 0.222707; batch adversarial loss: 0.488880\n",
      "epoch 50; iter: 0; batch classifier loss: 0.192705; batch adversarial loss: 0.470767\n",
      "epoch 51; iter: 0; batch classifier loss: 0.232455; batch adversarial loss: 0.396635\n",
      "epoch 52; iter: 0; batch classifier loss: 0.171774; batch adversarial loss: 0.505830\n",
      "epoch 53; iter: 0; batch classifier loss: 0.134598; batch adversarial loss: 0.548229\n",
      "epoch 54; iter: 0; batch classifier loss: 0.161990; batch adversarial loss: 0.531687\n",
      "epoch 55; iter: 0; batch classifier loss: 0.242131; batch adversarial loss: 0.376474\n",
      "epoch 56; iter: 0; batch classifier loss: 0.198153; batch adversarial loss: 0.361436\n",
      "epoch 57; iter: 0; batch classifier loss: 0.200858; batch adversarial loss: 0.448084\n",
      "epoch 58; iter: 0; batch classifier loss: 0.166770; batch adversarial loss: 0.552438\n",
      "epoch 59; iter: 0; batch classifier loss: 0.178472; batch adversarial loss: 0.516614\n",
      "epoch 60; iter: 0; batch classifier loss: 0.153340; batch adversarial loss: 0.455742\n",
      "epoch 61; iter: 0; batch classifier loss: 0.135933; batch adversarial loss: 0.399321\n",
      "epoch 62; iter: 0; batch classifier loss: 0.096761; batch adversarial loss: 0.421559\n",
      "epoch 63; iter: 0; batch classifier loss: 0.112275; batch adversarial loss: 0.464164\n",
      "epoch 64; iter: 0; batch classifier loss: 0.128770; batch adversarial loss: 0.435946\n",
      "epoch 65; iter: 0; batch classifier loss: 0.096386; batch adversarial loss: 0.410739\n",
      "epoch 66; iter: 0; batch classifier loss: 0.110384; batch adversarial loss: 0.475506\n",
      "epoch 67; iter: 0; batch classifier loss: 0.066141; batch adversarial loss: 0.548109\n",
      "epoch 68; iter: 0; batch classifier loss: 0.111339; batch adversarial loss: 0.493718\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082340; batch adversarial loss: 0.431000\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067211; batch adversarial loss: 0.440572\n",
      "epoch 71; iter: 0; batch classifier loss: 0.068020; batch adversarial loss: 0.495934\n",
      "epoch 72; iter: 0; batch classifier loss: 0.094946; batch adversarial loss: 0.438524\n",
      "epoch 73; iter: 0; batch classifier loss: 0.099046; batch adversarial loss: 0.606474\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089282; batch adversarial loss: 0.451587\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075139; batch adversarial loss: 0.449757\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060476; batch adversarial loss: 0.526333\n",
      "epoch 77; iter: 0; batch classifier loss: 0.072528; batch adversarial loss: 0.502703\n",
      "epoch 78; iter: 0; batch classifier loss: 0.045318; batch adversarial loss: 0.443459\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057095; batch adversarial loss: 0.384505\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061339; batch adversarial loss: 0.383254\n",
      "epoch 81; iter: 0; batch classifier loss: 0.043334; batch adversarial loss: 0.474414\n",
      "epoch 82; iter: 0; batch classifier loss: 0.105823; batch adversarial loss: 0.405853\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066116; batch adversarial loss: 0.409508\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064722; batch adversarial loss: 0.410075\n",
      "epoch 85; iter: 0; batch classifier loss: 0.057814; batch adversarial loss: 0.484706\n",
      "epoch 86; iter: 0; batch classifier loss: 0.108488; batch adversarial loss: 0.407228\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068437; batch adversarial loss: 0.467913\n",
      "epoch 88; iter: 0; batch classifier loss: 0.111973; batch adversarial loss: 0.458934\n",
      "epoch 89; iter: 0; batch classifier loss: 0.049818; batch adversarial loss: 0.513368\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057286; batch adversarial loss: 0.517312\n",
      "epoch 91; iter: 0; batch classifier loss: 0.054044; batch adversarial loss: 0.466595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.043438; batch adversarial loss: 0.557418\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055824; batch adversarial loss: 0.464583\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068660; batch adversarial loss: 0.365317\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056665; batch adversarial loss: 0.447605\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057531; batch adversarial loss: 0.453121\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042029; batch adversarial loss: 0.636244\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062988; batch adversarial loss: 0.476568\n",
      "epoch 99; iter: 0; batch classifier loss: 0.036325; batch adversarial loss: 0.504591\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061231; batch adversarial loss: 0.517528\n",
      "epoch 101; iter: 0; batch classifier loss: 0.036562; batch adversarial loss: 0.387905\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033332; batch adversarial loss: 0.490391\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041688; batch adversarial loss: 0.522506\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038407; batch adversarial loss: 0.388141\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060245; batch adversarial loss: 0.489777\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047538; batch adversarial loss: 0.409727\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069517; batch adversarial loss: 0.377465\n",
      "epoch 108; iter: 0; batch classifier loss: 0.029692; batch adversarial loss: 0.478541\n",
      "epoch 109; iter: 0; batch classifier loss: 0.016449; batch adversarial loss: 0.562505\n",
      "epoch 110; iter: 0; batch classifier loss: 0.081927; batch adversarial loss: 0.474454\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050170; batch adversarial loss: 0.494666\n",
      "epoch 112; iter: 0; batch classifier loss: 0.029432; batch adversarial loss: 0.418369\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025769; batch adversarial loss: 0.448521\n",
      "epoch 114; iter: 0; batch classifier loss: 0.012121; batch adversarial loss: 0.401854\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022345; batch adversarial loss: 0.478991\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037979; batch adversarial loss: 0.509402\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025053; batch adversarial loss: 0.475592\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036280; batch adversarial loss: 0.483215\n",
      "epoch 119; iter: 0; batch classifier loss: 0.028132; batch adversarial loss: 0.545502\n",
      "epoch 120; iter: 0; batch classifier loss: 0.023800; batch adversarial loss: 0.463711\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038258; batch adversarial loss: 0.523840\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030093; batch adversarial loss: 0.481386\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052082; batch adversarial loss: 0.399593\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042984; batch adversarial loss: 0.394107\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037642; batch adversarial loss: 0.439551\n",
      "epoch 126; iter: 0; batch classifier loss: 0.011002; batch adversarial loss: 0.420919\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029253; batch adversarial loss: 0.489373\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028703; batch adversarial loss: 0.355984\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043535; batch adversarial loss: 0.436148\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033208; batch adversarial loss: 0.406740\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034259; batch adversarial loss: 0.435572\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047380; batch adversarial loss: 0.453087\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039323; batch adversarial loss: 0.406727\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049918; batch adversarial loss: 0.481972\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036211; batch adversarial loss: 0.502666\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016164; batch adversarial loss: 0.425390\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028898; batch adversarial loss: 0.430085\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034082; batch adversarial loss: 0.526741\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013317; batch adversarial loss: 0.398615\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028707; batch adversarial loss: 0.434834\n",
      "epoch 141; iter: 0; batch classifier loss: 0.008753; batch adversarial loss: 0.535656\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013447; batch adversarial loss: 0.421943\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028257; batch adversarial loss: 0.504854\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032632; batch adversarial loss: 0.477383\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016003; batch adversarial loss: 0.446033\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013285; batch adversarial loss: 0.492729\n",
      "epoch 147; iter: 0; batch classifier loss: 0.059516; batch adversarial loss: 0.418805\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024707; batch adversarial loss: 0.412524\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012703; batch adversarial loss: 0.427290\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024054; batch adversarial loss: 0.485794\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021481; batch adversarial loss: 0.396956\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017423; batch adversarial loss: 0.514680\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015780; batch adversarial loss: 0.464238\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017014; batch adversarial loss: 0.395606\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019055; batch adversarial loss: 0.388923\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018884; batch adversarial loss: 0.529064\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009250; batch adversarial loss: 0.493372\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021722; batch adversarial loss: 0.531175\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030436; batch adversarial loss: 0.456760\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019119; batch adversarial loss: 0.394251\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011858; batch adversarial loss: 0.469184\n",
      "epoch 162; iter: 0; batch classifier loss: 0.045891; batch adversarial loss: 0.421266\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017490; batch adversarial loss: 0.411940\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010628; batch adversarial loss: 0.453788\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042052; batch adversarial loss: 0.452719\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007045; batch adversarial loss: 0.413720\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012957; batch adversarial loss: 0.475762\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014534; batch adversarial loss: 0.485441\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014377; batch adversarial loss: 0.489959\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007972; batch adversarial loss: 0.459345\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019763; batch adversarial loss: 0.472951\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020114; batch adversarial loss: 0.421420\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011018; batch adversarial loss: 0.369293\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010614; batch adversarial loss: 0.494707\n",
      "epoch 175; iter: 0; batch classifier loss: 0.005052; batch adversarial loss: 0.451427\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022253; batch adversarial loss: 0.477682\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010761; batch adversarial loss: 0.389462\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034349; batch adversarial loss: 0.477029\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022982; batch adversarial loss: 0.368538\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025771; batch adversarial loss: 0.415060\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025560; batch adversarial loss: 0.565214\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016907; batch adversarial loss: 0.453104\n",
      "epoch 183; iter: 0; batch classifier loss: 0.037382; batch adversarial loss: 0.514384\n",
      "epoch 184; iter: 0; batch classifier loss: 0.051746; batch adversarial loss: 0.427561\n",
      "epoch 185; iter: 0; batch classifier loss: 0.044562; batch adversarial loss: 0.469541\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007456; batch adversarial loss: 0.424249\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012117; batch adversarial loss: 0.533597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.025698; batch adversarial loss: 0.394724\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006859; batch adversarial loss: 0.502086\n",
      "epoch 190; iter: 0; batch classifier loss: 0.003359; batch adversarial loss: 0.530560\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012047; batch adversarial loss: 0.523351\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032191; batch adversarial loss: 0.367230\n",
      "epoch 193; iter: 0; batch classifier loss: 0.044301; batch adversarial loss: 0.413103\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012442; batch adversarial loss: 0.372326\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014296; batch adversarial loss: 0.409842\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007373; batch adversarial loss: 0.443786\n",
      "epoch 197; iter: 0; batch classifier loss: 0.003433; batch adversarial loss: 0.546152\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007542; batch adversarial loss: 0.402481\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009449; batch adversarial loss: 0.511827\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710067; batch adversarial loss: 0.783359\n",
      "epoch 1; iter: 0; batch classifier loss: 0.462612; batch adversarial loss: 0.721253\n",
      "epoch 2; iter: 0; batch classifier loss: 0.478367; batch adversarial loss: 0.678408\n",
      "epoch 3; iter: 0; batch classifier loss: 0.497154; batch adversarial loss: 0.621425\n",
      "epoch 4; iter: 0; batch classifier loss: 0.430850; batch adversarial loss: 0.612383\n",
      "epoch 5; iter: 0; batch classifier loss: 0.402132; batch adversarial loss: 0.600370\n",
      "epoch 6; iter: 0; batch classifier loss: 0.338655; batch adversarial loss: 0.594528\n",
      "epoch 7; iter: 0; batch classifier loss: 0.407280; batch adversarial loss: 0.575911\n",
      "epoch 8; iter: 0; batch classifier loss: 0.316561; batch adversarial loss: 0.545877\n",
      "epoch 9; iter: 0; batch classifier loss: 0.437225; batch adversarial loss: 0.551040\n",
      "epoch 10; iter: 0; batch classifier loss: 0.424859; batch adversarial loss: 0.540166\n",
      "epoch 11; iter: 0; batch classifier loss: 0.419653; batch adversarial loss: 0.513263\n",
      "epoch 12; iter: 0; batch classifier loss: 0.398588; batch adversarial loss: 0.562003\n",
      "epoch 13; iter: 0; batch classifier loss: 0.398708; batch adversarial loss: 0.526495\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500039; batch adversarial loss: 0.518834\n",
      "epoch 15; iter: 0; batch classifier loss: 0.422805; batch adversarial loss: 0.464410\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387268; batch adversarial loss: 0.497935\n",
      "epoch 17; iter: 0; batch classifier loss: 0.299108; batch adversarial loss: 0.503176\n",
      "epoch 18; iter: 0; batch classifier loss: 0.348033; batch adversarial loss: 0.482648\n",
      "epoch 19; iter: 0; batch classifier loss: 0.302983; batch adversarial loss: 0.491968\n",
      "epoch 20; iter: 0; batch classifier loss: 0.300048; batch adversarial loss: 0.522913\n",
      "epoch 21; iter: 0; batch classifier loss: 0.281734; batch adversarial loss: 0.445362\n",
      "epoch 22; iter: 0; batch classifier loss: 0.268948; batch adversarial loss: 0.484755\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285023; batch adversarial loss: 0.403524\n",
      "epoch 24; iter: 0; batch classifier loss: 0.234575; batch adversarial loss: 0.545440\n",
      "epoch 25; iter: 0; batch classifier loss: 0.221533; batch adversarial loss: 0.484863\n",
      "epoch 26; iter: 0; batch classifier loss: 0.236695; batch adversarial loss: 0.441157\n",
      "epoch 27; iter: 0; batch classifier loss: 0.315026; batch adversarial loss: 0.448763\n",
      "epoch 28; iter: 0; batch classifier loss: 0.298340; batch adversarial loss: 0.571132\n",
      "epoch 29; iter: 0; batch classifier loss: 0.349929; batch adversarial loss: 0.486210\n",
      "epoch 30; iter: 0; batch classifier loss: 0.245267; batch adversarial loss: 0.449418\n",
      "epoch 31; iter: 0; batch classifier loss: 0.218574; batch adversarial loss: 0.505430\n",
      "epoch 32; iter: 0; batch classifier loss: 0.228419; batch adversarial loss: 0.524907\n",
      "epoch 33; iter: 0; batch classifier loss: 0.231611; batch adversarial loss: 0.472395\n",
      "epoch 34; iter: 0; batch classifier loss: 0.208459; batch adversarial loss: 0.449972\n",
      "epoch 35; iter: 0; batch classifier loss: 0.313689; batch adversarial loss: 0.507596\n",
      "epoch 36; iter: 0; batch classifier loss: 0.205435; batch adversarial loss: 0.472668\n",
      "epoch 37; iter: 0; batch classifier loss: 0.188498; batch adversarial loss: 0.463842\n",
      "epoch 38; iter: 0; batch classifier loss: 0.261055; batch adversarial loss: 0.422815\n",
      "epoch 39; iter: 0; batch classifier loss: 0.187967; batch adversarial loss: 0.449777\n",
      "epoch 40; iter: 0; batch classifier loss: 0.191799; batch adversarial loss: 0.458499\n",
      "epoch 41; iter: 0; batch classifier loss: 0.242551; batch adversarial loss: 0.379651\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200314; batch adversarial loss: 0.455385\n",
      "epoch 43; iter: 0; batch classifier loss: 0.155770; batch adversarial loss: 0.367854\n",
      "epoch 44; iter: 0; batch classifier loss: 0.149012; batch adversarial loss: 0.430340\n",
      "epoch 45; iter: 0; batch classifier loss: 0.205243; batch adversarial loss: 0.447701\n",
      "epoch 46; iter: 0; batch classifier loss: 0.169381; batch adversarial loss: 0.378200\n",
      "epoch 47; iter: 0; batch classifier loss: 0.129087; batch adversarial loss: 0.636860\n",
      "epoch 48; iter: 0; batch classifier loss: 0.226896; batch adversarial loss: 0.458907\n",
      "epoch 49; iter: 0; batch classifier loss: 0.158429; batch adversarial loss: 0.449329\n",
      "epoch 50; iter: 0; batch classifier loss: 0.120553; batch adversarial loss: 0.482385\n",
      "epoch 51; iter: 0; batch classifier loss: 0.139241; batch adversarial loss: 0.500935\n",
      "epoch 52; iter: 0; batch classifier loss: 0.182036; batch adversarial loss: 0.493850\n",
      "epoch 53; iter: 0; batch classifier loss: 0.108584; batch adversarial loss: 0.446222\n",
      "epoch 54; iter: 0; batch classifier loss: 0.115664; batch adversarial loss: 0.527305\n",
      "epoch 55; iter: 0; batch classifier loss: 0.163214; batch adversarial loss: 0.401972\n",
      "epoch 56; iter: 0; batch classifier loss: 0.093738; batch adversarial loss: 0.470853\n",
      "epoch 57; iter: 0; batch classifier loss: 0.124547; batch adversarial loss: 0.457900\n",
      "epoch 58; iter: 0; batch classifier loss: 0.058812; batch adversarial loss: 0.406150\n",
      "epoch 59; iter: 0; batch classifier loss: 0.160729; batch adversarial loss: 0.395260\n",
      "epoch 60; iter: 0; batch classifier loss: 0.084417; batch adversarial loss: 0.451526\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093115; batch adversarial loss: 0.454890\n",
      "epoch 62; iter: 0; batch classifier loss: 0.130967; batch adversarial loss: 0.445051\n",
      "epoch 63; iter: 0; batch classifier loss: 0.080060; batch adversarial loss: 0.526740\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073076; batch adversarial loss: 0.509753\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073655; batch adversarial loss: 0.482765\n",
      "epoch 66; iter: 0; batch classifier loss: 0.065872; batch adversarial loss: 0.472205\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096553; batch adversarial loss: 0.457594\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078208; batch adversarial loss: 0.374760\n",
      "epoch 69; iter: 0; batch classifier loss: 0.060781; batch adversarial loss: 0.420049\n",
      "epoch 70; iter: 0; batch classifier loss: 0.133134; batch adversarial loss: 0.500025\n",
      "epoch 71; iter: 0; batch classifier loss: 0.139049; batch adversarial loss: 0.459343\n",
      "epoch 72; iter: 0; batch classifier loss: 0.049366; batch adversarial loss: 0.482023\n",
      "epoch 73; iter: 0; batch classifier loss: 0.108583; batch adversarial loss: 0.510864\n",
      "epoch 74; iter: 0; batch classifier loss: 0.085599; batch adversarial loss: 0.422905\n",
      "epoch 75; iter: 0; batch classifier loss: 0.060084; batch adversarial loss: 0.412193\n",
      "epoch 76; iter: 0; batch classifier loss: 0.036547; batch adversarial loss: 0.365466\n",
      "epoch 77; iter: 0; batch classifier loss: 0.126597; batch adversarial loss: 0.404440\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076307; batch adversarial loss: 0.519301\n",
      "epoch 79; iter: 0; batch classifier loss: 0.052409; batch adversarial loss: 0.458979\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043215; batch adversarial loss: 0.553424\n",
      "epoch 81; iter: 0; batch classifier loss: 0.085372; batch adversarial loss: 0.544105\n",
      "epoch 82; iter: 0; batch classifier loss: 0.034193; batch adversarial loss: 0.406918\n",
      "epoch 83; iter: 0; batch classifier loss: 0.047153; batch adversarial loss: 0.509954\n",
      "epoch 84; iter: 0; batch classifier loss: 0.034588; batch adversarial loss: 0.442915\n",
      "epoch 85; iter: 0; batch classifier loss: 0.062789; batch adversarial loss: 0.382612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.057496; batch adversarial loss: 0.436402\n",
      "epoch 87; iter: 0; batch classifier loss: 0.033391; batch adversarial loss: 0.506729\n",
      "epoch 88; iter: 0; batch classifier loss: 0.032388; batch adversarial loss: 0.461007\n",
      "epoch 89; iter: 0; batch classifier loss: 0.099379; batch adversarial loss: 0.379657\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062365; batch adversarial loss: 0.543494\n",
      "epoch 91; iter: 0; batch classifier loss: 0.058508; batch adversarial loss: 0.524496\n",
      "epoch 92; iter: 0; batch classifier loss: 0.095221; batch adversarial loss: 0.488560\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051468; batch adversarial loss: 0.481246\n",
      "epoch 94; iter: 0; batch classifier loss: 0.078368; batch adversarial loss: 0.497450\n",
      "epoch 95; iter: 0; batch classifier loss: 0.023447; batch adversarial loss: 0.466111\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042270; batch adversarial loss: 0.453788\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039121; batch adversarial loss: 0.454941\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044157; batch adversarial loss: 0.450575\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051322; batch adversarial loss: 0.472198\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046441; batch adversarial loss: 0.321384\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057180; batch adversarial loss: 0.503359\n",
      "epoch 102; iter: 0; batch classifier loss: 0.024945; batch adversarial loss: 0.546255\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052964; batch adversarial loss: 0.519365\n",
      "epoch 104; iter: 0; batch classifier loss: 0.042111; batch adversarial loss: 0.507088\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047213; batch adversarial loss: 0.477263\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039392; batch adversarial loss: 0.507819\n",
      "epoch 107; iter: 0; batch classifier loss: 0.108931; batch adversarial loss: 0.383508\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030743; batch adversarial loss: 0.427904\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057221; batch adversarial loss: 0.403762\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060603; batch adversarial loss: 0.434147\n",
      "epoch 111; iter: 0; batch classifier loss: 0.017323; batch adversarial loss: 0.416891\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025046; batch adversarial loss: 0.359887\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033241; batch adversarial loss: 0.449882\n",
      "epoch 114; iter: 0; batch classifier loss: 0.019113; batch adversarial loss: 0.606846\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047961; batch adversarial loss: 0.417981\n",
      "epoch 116; iter: 0; batch classifier loss: 0.066075; batch adversarial loss: 0.370490\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031924; batch adversarial loss: 0.449398\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042378; batch adversarial loss: 0.349993\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033527; batch adversarial loss: 0.422100\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043693; batch adversarial loss: 0.462324\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054122; batch adversarial loss: 0.444629\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051447; batch adversarial loss: 0.467132\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025466; batch adversarial loss: 0.542516\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037228; batch adversarial loss: 0.449875\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038653; batch adversarial loss: 0.528595\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036608; batch adversarial loss: 0.474553\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032732; batch adversarial loss: 0.455919\n",
      "epoch 128; iter: 0; batch classifier loss: 0.057949; batch adversarial loss: 0.458821\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037739; batch adversarial loss: 0.442290\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030207; batch adversarial loss: 0.497743\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039078; batch adversarial loss: 0.382254\n",
      "epoch 132; iter: 0; batch classifier loss: 0.075226; batch adversarial loss: 0.454993\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043052; batch adversarial loss: 0.453227\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020681; batch adversarial loss: 0.393318\n",
      "epoch 135; iter: 0; batch classifier loss: 0.056709; batch adversarial loss: 0.479093\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031015; batch adversarial loss: 0.441480\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042819; batch adversarial loss: 0.377715\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016898; batch adversarial loss: 0.407313\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028501; batch adversarial loss: 0.384418\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031528; batch adversarial loss: 0.406715\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035270; batch adversarial loss: 0.433863\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044701; batch adversarial loss: 0.417752\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020080; batch adversarial loss: 0.441734\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045506; batch adversarial loss: 0.474330\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042017; batch adversarial loss: 0.376254\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018146; batch adversarial loss: 0.378967\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029040; batch adversarial loss: 0.446908\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028038; batch adversarial loss: 0.428797\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027150; batch adversarial loss: 0.453048\n",
      "epoch 150; iter: 0; batch classifier loss: 0.008233; batch adversarial loss: 0.582853\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021525; batch adversarial loss: 0.424532\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022252; batch adversarial loss: 0.528020\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035274; batch adversarial loss: 0.480995\n",
      "epoch 154; iter: 0; batch classifier loss: 0.056168; batch adversarial loss: 0.493818\n",
      "epoch 155; iter: 0; batch classifier loss: 0.053093; batch adversarial loss: 0.437452\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011596; batch adversarial loss: 0.487045\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026667; batch adversarial loss: 0.571108\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018823; batch adversarial loss: 0.521821\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025762; batch adversarial loss: 0.385248\n",
      "epoch 160; iter: 0; batch classifier loss: 0.003454; batch adversarial loss: 0.414740\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024756; batch adversarial loss: 0.564898\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021213; batch adversarial loss: 0.463562\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026701; batch adversarial loss: 0.475944\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017280; batch adversarial loss: 0.429347\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039486; batch adversarial loss: 0.542511\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018990; batch adversarial loss: 0.499317\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012987; batch adversarial loss: 0.484913\n",
      "epoch 168; iter: 0; batch classifier loss: 0.006819; batch adversarial loss: 0.410745\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016675; batch adversarial loss: 0.346530\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039044; batch adversarial loss: 0.450250\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017966; batch adversarial loss: 0.525372\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016314; batch adversarial loss: 0.433327\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031949; batch adversarial loss: 0.428646\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027859; batch adversarial loss: 0.536119\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012221; batch adversarial loss: 0.422913\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015266; batch adversarial loss: 0.439156\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022027; batch adversarial loss: 0.430704\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031175; batch adversarial loss: 0.488731\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011800; batch adversarial loss: 0.471759\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039077; batch adversarial loss: 0.385120\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025068; batch adversarial loss: 0.501146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.050284; batch adversarial loss: 0.378909\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030202; batch adversarial loss: 0.537989\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031574; batch adversarial loss: 0.494112\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022802; batch adversarial loss: 0.553223\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024294; batch adversarial loss: 0.565777\n",
      "epoch 187; iter: 0; batch classifier loss: 0.057657; batch adversarial loss: 0.505140\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006167; batch adversarial loss: 0.455861\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004393; batch adversarial loss: 0.396888\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011818; batch adversarial loss: 0.407205\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019126; batch adversarial loss: 0.600261\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007317; batch adversarial loss: 0.492208\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016884; batch adversarial loss: 0.459014\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024672; batch adversarial loss: 0.466338\n",
      "epoch 195; iter: 0; batch classifier loss: 0.065838; batch adversarial loss: 0.378740\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027887; batch adversarial loss: 0.439139\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021921; batch adversarial loss: 0.472198\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009816; batch adversarial loss: 0.459129\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019880; batch adversarial loss: 0.522498\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719660; batch adversarial loss: 0.723132\n",
      "epoch 1; iter: 0; batch classifier loss: 0.389503; batch adversarial loss: 0.677127\n",
      "epoch 2; iter: 0; batch classifier loss: 0.290998; batch adversarial loss: 0.643974\n",
      "epoch 3; iter: 0; batch classifier loss: 0.348821; batch adversarial loss: 0.618967\n",
      "epoch 4; iter: 0; batch classifier loss: 0.345582; batch adversarial loss: 0.584019\n",
      "epoch 5; iter: 0; batch classifier loss: 0.314706; batch adversarial loss: 0.578035\n",
      "epoch 6; iter: 0; batch classifier loss: 0.376677; batch adversarial loss: 0.535793\n",
      "epoch 7; iter: 0; batch classifier loss: 0.288249; batch adversarial loss: 0.600467\n",
      "epoch 8; iter: 0; batch classifier loss: 0.340928; batch adversarial loss: 0.530201\n",
      "epoch 9; iter: 0; batch classifier loss: 0.323003; batch adversarial loss: 0.490238\n",
      "epoch 10; iter: 0; batch classifier loss: 0.430811; batch adversarial loss: 0.531525\n",
      "epoch 11; iter: 0; batch classifier loss: 0.432183; batch adversarial loss: 0.535962\n",
      "epoch 12; iter: 0; batch classifier loss: 0.417909; batch adversarial loss: 0.504391\n",
      "epoch 13; iter: 0; batch classifier loss: 0.543276; batch adversarial loss: 0.541838\n",
      "epoch 14; iter: 0; batch classifier loss: 0.400294; batch adversarial loss: 0.530342\n",
      "epoch 15; iter: 0; batch classifier loss: 0.327670; batch adversarial loss: 0.510672\n",
      "epoch 16; iter: 0; batch classifier loss: 0.314460; batch adversarial loss: 0.503506\n",
      "epoch 17; iter: 0; batch classifier loss: 0.372166; batch adversarial loss: 0.524326\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269619; batch adversarial loss: 0.520491\n",
      "epoch 19; iter: 0; batch classifier loss: 0.300759; batch adversarial loss: 0.489925\n",
      "epoch 20; iter: 0; batch classifier loss: 0.272627; batch adversarial loss: 0.477905\n",
      "epoch 21; iter: 0; batch classifier loss: 0.285753; batch adversarial loss: 0.469712\n",
      "epoch 22; iter: 0; batch classifier loss: 0.217628; batch adversarial loss: 0.518499\n",
      "epoch 23; iter: 0; batch classifier loss: 0.260233; batch adversarial loss: 0.487167\n",
      "epoch 24; iter: 0; batch classifier loss: 0.310211; batch adversarial loss: 0.534547\n",
      "epoch 25; iter: 0; batch classifier loss: 0.339200; batch adversarial loss: 0.500146\n",
      "epoch 26; iter: 0; batch classifier loss: 0.266618; batch adversarial loss: 0.392500\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241161; batch adversarial loss: 0.430753\n",
      "epoch 28; iter: 0; batch classifier loss: 0.221605; batch adversarial loss: 0.585698\n",
      "epoch 29; iter: 0; batch classifier loss: 0.223725; batch adversarial loss: 0.380050\n",
      "epoch 30; iter: 0; batch classifier loss: 0.223843; batch adversarial loss: 0.466315\n",
      "epoch 31; iter: 0; batch classifier loss: 0.143564; batch adversarial loss: 0.385785\n",
      "epoch 32; iter: 0; batch classifier loss: 0.152490; batch adversarial loss: 0.441459\n",
      "epoch 33; iter: 0; batch classifier loss: 0.193433; batch adversarial loss: 0.438576\n",
      "epoch 34; iter: 0; batch classifier loss: 0.227964; batch adversarial loss: 0.430106\n",
      "epoch 35; iter: 0; batch classifier loss: 0.192815; batch adversarial loss: 0.440896\n",
      "epoch 36; iter: 0; batch classifier loss: 0.161461; batch adversarial loss: 0.527526\n",
      "epoch 37; iter: 0; batch classifier loss: 0.178278; batch adversarial loss: 0.453741\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115348; batch adversarial loss: 0.479875\n",
      "epoch 39; iter: 0; batch classifier loss: 0.158043; batch adversarial loss: 0.496164\n",
      "epoch 40; iter: 0; batch classifier loss: 0.122875; batch adversarial loss: 0.409813\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146252; batch adversarial loss: 0.443452\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146627; batch adversarial loss: 0.394252\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150431; batch adversarial loss: 0.405293\n",
      "epoch 44; iter: 0; batch classifier loss: 0.155037; batch adversarial loss: 0.485538\n",
      "epoch 45; iter: 0; batch classifier loss: 0.111620; batch adversarial loss: 0.442635\n",
      "epoch 46; iter: 0; batch classifier loss: 0.172022; batch adversarial loss: 0.429627\n",
      "epoch 47; iter: 0; batch classifier loss: 0.105900; batch adversarial loss: 0.433977\n",
      "epoch 48; iter: 0; batch classifier loss: 0.143555; batch adversarial loss: 0.426133\n",
      "epoch 49; iter: 0; batch classifier loss: 0.116190; batch adversarial loss: 0.502490\n",
      "epoch 50; iter: 0; batch classifier loss: 0.150500; batch adversarial loss: 0.400520\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109378; batch adversarial loss: 0.442309\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082652; batch adversarial loss: 0.503921\n",
      "epoch 53; iter: 0; batch classifier loss: 0.127482; batch adversarial loss: 0.477369\n",
      "epoch 54; iter: 0; batch classifier loss: 0.088184; batch adversarial loss: 0.445399\n",
      "epoch 55; iter: 0; batch classifier loss: 0.128806; batch adversarial loss: 0.425297\n",
      "epoch 56; iter: 0; batch classifier loss: 0.133454; batch adversarial loss: 0.555467\n",
      "epoch 57; iter: 0; batch classifier loss: 0.167239; batch adversarial loss: 0.364303\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103812; batch adversarial loss: 0.325570\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099245; batch adversarial loss: 0.395134\n",
      "epoch 60; iter: 0; batch classifier loss: 0.138883; batch adversarial loss: 0.437343\n",
      "epoch 61; iter: 0; batch classifier loss: 0.095279; batch adversarial loss: 0.406695\n",
      "epoch 62; iter: 0; batch classifier loss: 0.152827; batch adversarial loss: 0.448344\n",
      "epoch 63; iter: 0; batch classifier loss: 0.152888; batch adversarial loss: 0.477196\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106933; batch adversarial loss: 0.499546\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088401; batch adversarial loss: 0.474564\n",
      "epoch 66; iter: 0; batch classifier loss: 0.118504; batch adversarial loss: 0.348124\n",
      "epoch 67; iter: 0; batch classifier loss: 0.154009; batch adversarial loss: 0.527659\n",
      "epoch 68; iter: 0; batch classifier loss: 0.126638; batch adversarial loss: 0.467783\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070369; batch adversarial loss: 0.330746\n",
      "epoch 70; iter: 0; batch classifier loss: 0.106578; batch adversarial loss: 0.426742\n",
      "epoch 71; iter: 0; batch classifier loss: 0.116211; batch adversarial loss: 0.368301\n",
      "epoch 72; iter: 0; batch classifier loss: 0.078633; batch adversarial loss: 0.409084\n",
      "epoch 73; iter: 0; batch classifier loss: 0.121950; batch adversarial loss: 0.465736\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073177; batch adversarial loss: 0.441377\n",
      "epoch 75; iter: 0; batch classifier loss: 0.108659; batch adversarial loss: 0.413883\n",
      "epoch 76; iter: 0; batch classifier loss: 0.115053; batch adversarial loss: 0.525307\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074364; batch adversarial loss: 0.536846\n",
      "epoch 78; iter: 0; batch classifier loss: 0.051736; batch adversarial loss: 0.377375\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080666; batch adversarial loss: 0.499533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.076371; batch adversarial loss: 0.596342\n",
      "epoch 81; iter: 0; batch classifier loss: 0.038582; batch adversarial loss: 0.485878\n",
      "epoch 82; iter: 0; batch classifier loss: 0.064565; batch adversarial loss: 0.445602\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085333; batch adversarial loss: 0.498523\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068561; batch adversarial loss: 0.401432\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080409; batch adversarial loss: 0.485108\n",
      "epoch 86; iter: 0; batch classifier loss: 0.039609; batch adversarial loss: 0.377979\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072780; batch adversarial loss: 0.488468\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064181; batch adversarial loss: 0.441415\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060754; batch adversarial loss: 0.545099\n",
      "epoch 90; iter: 0; batch classifier loss: 0.105533; batch adversarial loss: 0.460538\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057733; batch adversarial loss: 0.495248\n",
      "epoch 92; iter: 0; batch classifier loss: 0.028755; batch adversarial loss: 0.446390\n",
      "epoch 93; iter: 0; batch classifier loss: 0.115074; batch adversarial loss: 0.380039\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041709; batch adversarial loss: 0.417494\n",
      "epoch 95; iter: 0; batch classifier loss: 0.061987; batch adversarial loss: 0.355015\n",
      "epoch 96; iter: 0; batch classifier loss: 0.040979; batch adversarial loss: 0.366824\n",
      "epoch 97; iter: 0; batch classifier loss: 0.086731; batch adversarial loss: 0.400400\n",
      "epoch 98; iter: 0; batch classifier loss: 0.065007; batch adversarial loss: 0.390406\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058063; batch adversarial loss: 0.498917\n",
      "epoch 100; iter: 0; batch classifier loss: 0.029563; batch adversarial loss: 0.434381\n",
      "epoch 101; iter: 0; batch classifier loss: 0.084088; batch adversarial loss: 0.526223\n",
      "epoch 102; iter: 0; batch classifier loss: 0.040290; batch adversarial loss: 0.399669\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055015; batch adversarial loss: 0.455902\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055640; batch adversarial loss: 0.447085\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057555; batch adversarial loss: 0.433815\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031482; batch adversarial loss: 0.360106\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052736; batch adversarial loss: 0.367553\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052608; batch adversarial loss: 0.496420\n",
      "epoch 109; iter: 0; batch classifier loss: 0.104477; batch adversarial loss: 0.474422\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023246; batch adversarial loss: 0.502077\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047555; batch adversarial loss: 0.434561\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054488; batch adversarial loss: 0.401366\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050364; batch adversarial loss: 0.406851\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052253; batch adversarial loss: 0.344486\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044467; batch adversarial loss: 0.429783\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030448; batch adversarial loss: 0.447166\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044347; batch adversarial loss: 0.395752\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063519; batch adversarial loss: 0.467699\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050375; batch adversarial loss: 0.523054\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033451; batch adversarial loss: 0.436483\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035886; batch adversarial loss: 0.438101\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044404; batch adversarial loss: 0.421971\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038722; batch adversarial loss: 0.499781\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022819; batch adversarial loss: 0.411300\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029822; batch adversarial loss: 0.477431\n",
      "epoch 126; iter: 0; batch classifier loss: 0.070790; batch adversarial loss: 0.407322\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040627; batch adversarial loss: 0.326586\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058057; batch adversarial loss: 0.393483\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056911; batch adversarial loss: 0.472610\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019410; batch adversarial loss: 0.327041\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036295; batch adversarial loss: 0.426704\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015361; batch adversarial loss: 0.552635\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043148; batch adversarial loss: 0.421462\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030776; batch adversarial loss: 0.576061\n",
      "epoch 135; iter: 0; batch classifier loss: 0.056058; batch adversarial loss: 0.449425\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033774; batch adversarial loss: 0.445956\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017748; batch adversarial loss: 0.462152\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020348; batch adversarial loss: 0.376950\n",
      "epoch 139; iter: 0; batch classifier loss: 0.064891; batch adversarial loss: 0.480480\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019290; batch adversarial loss: 0.495802\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046745; batch adversarial loss: 0.455663\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032213; batch adversarial loss: 0.435094\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025767; batch adversarial loss: 0.450380\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027382; batch adversarial loss: 0.454062\n",
      "epoch 145; iter: 0; batch classifier loss: 0.059797; batch adversarial loss: 0.541661\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029029; batch adversarial loss: 0.446519\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035849; batch adversarial loss: 0.386865\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019039; batch adversarial loss: 0.405334\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023213; batch adversarial loss: 0.397260\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014948; batch adversarial loss: 0.429340\n",
      "epoch 151; iter: 0; batch classifier loss: 0.046560; batch adversarial loss: 0.442761\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029248; batch adversarial loss: 0.434747\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015371; batch adversarial loss: 0.382209\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016556; batch adversarial loss: 0.394746\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038787; batch adversarial loss: 0.446043\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018714; batch adversarial loss: 0.494490\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034657; batch adversarial loss: 0.473947\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030145; batch adversarial loss: 0.474291\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021541; batch adversarial loss: 0.425972\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041442; batch adversarial loss: 0.401533\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017861; batch adversarial loss: 0.440257\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039254; batch adversarial loss: 0.488310\n",
      "epoch 163; iter: 0; batch classifier loss: 0.051255; batch adversarial loss: 0.456557\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015006; batch adversarial loss: 0.443143\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018759; batch adversarial loss: 0.363362\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024615; batch adversarial loss: 0.380035\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039673; batch adversarial loss: 0.397381\n",
      "epoch 168; iter: 0; batch classifier loss: 0.075222; batch adversarial loss: 0.390982\n",
      "epoch 169; iter: 0; batch classifier loss: 0.049606; batch adversarial loss: 0.377673\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037208; batch adversarial loss: 0.424380\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017273; batch adversarial loss: 0.413134\n",
      "epoch 172; iter: 0; batch classifier loss: 0.046437; batch adversarial loss: 0.559940\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040345; batch adversarial loss: 0.380650\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014871; batch adversarial loss: 0.469794\n",
      "epoch 175; iter: 0; batch classifier loss: 0.056884; batch adversarial loss: 0.508715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.024665; batch adversarial loss: 0.426062\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017049; batch adversarial loss: 0.492787\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018711; batch adversarial loss: 0.400427\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019587; batch adversarial loss: 0.444721\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015044; batch adversarial loss: 0.343583\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032131; batch adversarial loss: 0.419947\n",
      "epoch 182; iter: 0; batch classifier loss: 0.043614; batch adversarial loss: 0.543895\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010806; batch adversarial loss: 0.463167\n",
      "epoch 184; iter: 0; batch classifier loss: 0.043284; batch adversarial loss: 0.476126\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023301; batch adversarial loss: 0.416932\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023202; batch adversarial loss: 0.478858\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027571; batch adversarial loss: 0.600226\n",
      "epoch 188; iter: 0; batch classifier loss: 0.039888; batch adversarial loss: 0.528181\n",
      "epoch 189; iter: 0; batch classifier loss: 0.005152; batch adversarial loss: 0.507482\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024445; batch adversarial loss: 0.461586\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018130; batch adversarial loss: 0.410245\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013989; batch adversarial loss: 0.476820\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013971; batch adversarial loss: 0.506615\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014528; batch adversarial loss: 0.344182\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013916; batch adversarial loss: 0.466332\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032434; batch adversarial loss: 0.474212\n",
      "epoch 197; iter: 0; batch classifier loss: 0.068409; batch adversarial loss: 0.365817\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022861; batch adversarial loss: 0.455532\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009836; batch adversarial loss: 0.553370\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723224; batch adversarial loss: 0.935414\n",
      "epoch 1; iter: 0; batch classifier loss: 0.563152; batch adversarial loss: 0.935095\n",
      "epoch 2; iter: 0; batch classifier loss: 0.814946; batch adversarial loss: 0.944417\n",
      "epoch 3; iter: 0; batch classifier loss: 0.951334; batch adversarial loss: 0.903121\n",
      "epoch 4; iter: 0; batch classifier loss: 0.872569; batch adversarial loss: 0.804696\n",
      "epoch 5; iter: 0; batch classifier loss: 0.974824; batch adversarial loss: 0.730129\n",
      "epoch 6; iter: 0; batch classifier loss: 0.968877; batch adversarial loss: 0.650315\n",
      "epoch 7; iter: 0; batch classifier loss: 0.976712; batch adversarial loss: 0.594038\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571472; batch adversarial loss: 0.583498\n",
      "epoch 9; iter: 0; batch classifier loss: 0.342518; batch adversarial loss: 0.592177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.343622; batch adversarial loss: 0.569064\n",
      "epoch 11; iter: 0; batch classifier loss: 0.368399; batch adversarial loss: 0.527226\n",
      "epoch 12; iter: 0; batch classifier loss: 0.348063; batch adversarial loss: 0.527339\n",
      "epoch 13; iter: 0; batch classifier loss: 0.324395; batch adversarial loss: 0.571587\n",
      "epoch 14; iter: 0; batch classifier loss: 0.360038; batch adversarial loss: 0.519343\n",
      "epoch 15; iter: 0; batch classifier loss: 0.339711; batch adversarial loss: 0.531501\n",
      "epoch 16; iter: 0; batch classifier loss: 0.310336; batch adversarial loss: 0.536306\n",
      "epoch 17; iter: 0; batch classifier loss: 0.320764; batch adversarial loss: 0.536487\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359026; batch adversarial loss: 0.441752\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338930; batch adversarial loss: 0.509160\n",
      "epoch 20; iter: 0; batch classifier loss: 0.289781; batch adversarial loss: 0.501790\n",
      "epoch 21; iter: 0; batch classifier loss: 0.279993; batch adversarial loss: 0.502820\n",
      "epoch 22; iter: 0; batch classifier loss: 0.374898; batch adversarial loss: 0.474008\n",
      "epoch 23; iter: 0; batch classifier loss: 0.336498; batch adversarial loss: 0.427010\n",
      "epoch 24; iter: 0; batch classifier loss: 0.250041; batch adversarial loss: 0.458365\n",
      "epoch 25; iter: 0; batch classifier loss: 0.278054; batch adversarial loss: 0.402996\n",
      "epoch 26; iter: 0; batch classifier loss: 0.296367; batch adversarial loss: 0.490597\n",
      "epoch 27; iter: 0; batch classifier loss: 0.283983; batch adversarial loss: 0.445246\n",
      "epoch 28; iter: 0; batch classifier loss: 0.257521; batch adversarial loss: 0.505599\n",
      "epoch 29; iter: 0; batch classifier loss: 0.219812; batch adversarial loss: 0.487562\n",
      "epoch 30; iter: 0; batch classifier loss: 0.252534; batch adversarial loss: 0.479913\n",
      "epoch 31; iter: 0; batch classifier loss: 0.327258; batch adversarial loss: 0.461104\n",
      "epoch 32; iter: 0; batch classifier loss: 0.312466; batch adversarial loss: 0.469433\n",
      "epoch 33; iter: 0; batch classifier loss: 0.288440; batch adversarial loss: 0.475637\n",
      "epoch 34; iter: 0; batch classifier loss: 0.204367; batch adversarial loss: 0.535556\n",
      "epoch 35; iter: 0; batch classifier loss: 0.248618; batch adversarial loss: 0.456319\n",
      "epoch 36; iter: 0; batch classifier loss: 0.258499; batch adversarial loss: 0.521634\n",
      "epoch 37; iter: 0; batch classifier loss: 0.273158; batch adversarial loss: 0.488396\n",
      "epoch 38; iter: 0; batch classifier loss: 0.207159; batch adversarial loss: 0.477645\n",
      "epoch 39; iter: 0; batch classifier loss: 0.226564; batch adversarial loss: 0.423948\n",
      "epoch 40; iter: 0; batch classifier loss: 0.208896; batch adversarial loss: 0.457754\n",
      "epoch 41; iter: 0; batch classifier loss: 0.215701; batch adversarial loss: 0.473546\n",
      "epoch 42; iter: 0; batch classifier loss: 0.205519; batch adversarial loss: 0.392420\n",
      "epoch 43; iter: 0; batch classifier loss: 0.218371; batch adversarial loss: 0.531213\n",
      "epoch 44; iter: 0; batch classifier loss: 0.205837; batch adversarial loss: 0.407081\n",
      "epoch 45; iter: 0; batch classifier loss: 0.189074; batch adversarial loss: 0.478120\n",
      "epoch 46; iter: 0; batch classifier loss: 0.181919; batch adversarial loss: 0.367843\n",
      "epoch 47; iter: 0; batch classifier loss: 0.201716; batch adversarial loss: 0.420817\n",
      "epoch 48; iter: 0; batch classifier loss: 0.223580; batch adversarial loss: 0.501414\n",
      "epoch 49; iter: 0; batch classifier loss: 0.175478; batch adversarial loss: 0.458392\n",
      "epoch 50; iter: 0; batch classifier loss: 0.179666; batch adversarial loss: 0.479084\n",
      "epoch 51; iter: 0; batch classifier loss: 0.158903; batch adversarial loss: 0.435089\n",
      "epoch 52; iter: 0; batch classifier loss: 0.158336; batch adversarial loss: 0.477516\n",
      "epoch 53; iter: 0; batch classifier loss: 0.181668; batch adversarial loss: 0.503209\n",
      "epoch 54; iter: 0; batch classifier loss: 0.142737; batch adversarial loss: 0.469582\n",
      "epoch 55; iter: 0; batch classifier loss: 0.158188; batch adversarial loss: 0.506661\n",
      "epoch 56; iter: 0; batch classifier loss: 0.220561; batch adversarial loss: 0.431158\n",
      "epoch 57; iter: 0; batch classifier loss: 0.240174; batch adversarial loss: 0.569468\n",
      "epoch 58; iter: 0; batch classifier loss: 0.190343; batch adversarial loss: 0.444523\n",
      "epoch 59; iter: 0; batch classifier loss: 0.196220; batch adversarial loss: 0.435059\n",
      "epoch 60; iter: 0; batch classifier loss: 0.183232; batch adversarial loss: 0.431246\n",
      "epoch 61; iter: 0; batch classifier loss: 0.140489; batch adversarial loss: 0.418082\n",
      "epoch 62; iter: 0; batch classifier loss: 0.186564; batch adversarial loss: 0.444817\n",
      "epoch 63; iter: 0; batch classifier loss: 0.153047; batch adversarial loss: 0.495842\n",
      "epoch 64; iter: 0; batch classifier loss: 0.144344; batch adversarial loss: 0.479724\n",
      "epoch 65; iter: 0; batch classifier loss: 0.187112; batch adversarial loss: 0.419965\n",
      "epoch 66; iter: 0; batch classifier loss: 0.150476; batch adversarial loss: 0.428154\n",
      "epoch 67; iter: 0; batch classifier loss: 0.195223; batch adversarial loss: 0.404124\n",
      "epoch 68; iter: 0; batch classifier loss: 0.162804; batch adversarial loss: 0.469224\n",
      "epoch 69; iter: 0; batch classifier loss: 0.165643; batch adversarial loss: 0.505751\n",
      "epoch 70; iter: 0; batch classifier loss: 0.181151; batch adversarial loss: 0.445972\n",
      "epoch 71; iter: 0; batch classifier loss: 0.203950; batch adversarial loss: 0.491734\n",
      "epoch 72; iter: 0; batch classifier loss: 0.184538; batch adversarial loss: 0.527906\n",
      "epoch 73; iter: 0; batch classifier loss: 0.107389; batch adversarial loss: 0.455893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.102146; batch adversarial loss: 0.420357\n",
      "epoch 75; iter: 0; batch classifier loss: 0.129397; batch adversarial loss: 0.454703\n",
      "epoch 76; iter: 0; batch classifier loss: 0.172159; batch adversarial loss: 0.564711\n",
      "epoch 77; iter: 0; batch classifier loss: 0.123752; batch adversarial loss: 0.445391\n",
      "epoch 78; iter: 0; batch classifier loss: 0.134056; batch adversarial loss: 0.403300\n",
      "epoch 79; iter: 0; batch classifier loss: 0.119970; batch adversarial loss: 0.510633\n",
      "epoch 80; iter: 0; batch classifier loss: 0.149031; batch adversarial loss: 0.538486\n",
      "epoch 81; iter: 0; batch classifier loss: 0.126791; batch adversarial loss: 0.414903\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091294; batch adversarial loss: 0.512949\n",
      "epoch 83; iter: 0; batch classifier loss: 0.107172; batch adversarial loss: 0.603523\n",
      "epoch 84; iter: 0; batch classifier loss: 0.141675; batch adversarial loss: 0.482032\n",
      "epoch 85; iter: 0; batch classifier loss: 0.099232; batch adversarial loss: 0.462960\n",
      "epoch 86; iter: 0; batch classifier loss: 0.088205; batch adversarial loss: 0.427988\n",
      "epoch 87; iter: 0; batch classifier loss: 0.122604; batch adversarial loss: 0.452058\n",
      "epoch 88; iter: 0; batch classifier loss: 0.113599; batch adversarial loss: 0.463308\n",
      "epoch 89; iter: 0; batch classifier loss: 0.145746; batch adversarial loss: 0.526628\n",
      "epoch 90; iter: 0; batch classifier loss: 0.153080; batch adversarial loss: 0.437378\n",
      "epoch 91; iter: 0; batch classifier loss: 0.113124; batch adversarial loss: 0.502947\n",
      "epoch 92; iter: 0; batch classifier loss: 0.081391; batch adversarial loss: 0.499916\n",
      "epoch 93; iter: 0; batch classifier loss: 0.117763; batch adversarial loss: 0.433530\n",
      "epoch 94; iter: 0; batch classifier loss: 0.088299; batch adversarial loss: 0.515898\n",
      "epoch 95; iter: 0; batch classifier loss: 0.110632; batch adversarial loss: 0.417329\n",
      "epoch 96; iter: 0; batch classifier loss: 0.109254; batch adversarial loss: 0.531340\n",
      "epoch 97; iter: 0; batch classifier loss: 0.090928; batch adversarial loss: 0.419715\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063642; batch adversarial loss: 0.381411\n",
      "epoch 99; iter: 0; batch classifier loss: 0.082488; batch adversarial loss: 0.477291\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046259; batch adversarial loss: 0.452700\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063715; batch adversarial loss: 0.418076\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079463; batch adversarial loss: 0.480027\n",
      "epoch 103; iter: 0; batch classifier loss: 0.084596; batch adversarial loss: 0.479287\n",
      "epoch 104; iter: 0; batch classifier loss: 0.095020; batch adversarial loss: 0.506881\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056379; batch adversarial loss: 0.507209\n",
      "epoch 106; iter: 0; batch classifier loss: 0.094532; batch adversarial loss: 0.480558\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062125; batch adversarial loss: 0.426966\n",
      "epoch 108; iter: 0; batch classifier loss: 0.047837; batch adversarial loss: 0.407385\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064494; batch adversarial loss: 0.423356\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053610; batch adversarial loss: 0.516245\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043680; batch adversarial loss: 0.418685\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042133; batch adversarial loss: 0.436637\n",
      "epoch 113; iter: 0; batch classifier loss: 0.073026; batch adversarial loss: 0.378955\n",
      "epoch 114; iter: 0; batch classifier loss: 0.055394; batch adversarial loss: 0.481813\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057615; batch adversarial loss: 0.481580\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057362; batch adversarial loss: 0.451575\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045563; batch adversarial loss: 0.532923\n",
      "epoch 118; iter: 0; batch classifier loss: 0.067655; batch adversarial loss: 0.412948\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027238; batch adversarial loss: 0.481286\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039693; batch adversarial loss: 0.456901\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024264; batch adversarial loss: 0.424470\n",
      "epoch 122; iter: 0; batch classifier loss: 0.055336; batch adversarial loss: 0.364789\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026369; batch adversarial loss: 0.514731\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037076; batch adversarial loss: 0.442199\n",
      "epoch 125; iter: 0; batch classifier loss: 0.067298; batch adversarial loss: 0.503210\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042815; batch adversarial loss: 0.413534\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027904; batch adversarial loss: 0.467083\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031923; batch adversarial loss: 0.527981\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024074; batch adversarial loss: 0.428749\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031541; batch adversarial loss: 0.414346\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037073; batch adversarial loss: 0.383334\n",
      "epoch 132; iter: 0; batch classifier loss: 0.006486; batch adversarial loss: 0.363432\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034157; batch adversarial loss: 0.470112\n",
      "epoch 134; iter: 0; batch classifier loss: 0.041109; batch adversarial loss: 0.547682\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037040; batch adversarial loss: 0.403402\n",
      "epoch 136; iter: 0; batch classifier loss: 0.062858; batch adversarial loss: 0.496346\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024521; batch adversarial loss: 0.372167\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022771; batch adversarial loss: 0.482331\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029220; batch adversarial loss: 0.479743\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040346; batch adversarial loss: 0.455703\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022277; batch adversarial loss: 0.507968\n",
      "epoch 142; iter: 0; batch classifier loss: 0.055744; batch adversarial loss: 0.440227\n",
      "epoch 143; iter: 0; batch classifier loss: 0.103147; batch adversarial loss: 0.403687\n",
      "epoch 144; iter: 0; batch classifier loss: 0.035622; batch adversarial loss: 0.407553\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023116; batch adversarial loss: 0.408892\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026165; batch adversarial loss: 0.404029\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019735; batch adversarial loss: 0.438934\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019602; batch adversarial loss: 0.492145\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012347; batch adversarial loss: 0.429026\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034612; batch adversarial loss: 0.386267\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035731; batch adversarial loss: 0.371959\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031205; batch adversarial loss: 0.481947\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027344; batch adversarial loss: 0.346400\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052224; batch adversarial loss: 0.467269\n",
      "epoch 155; iter: 0; batch classifier loss: 0.051691; batch adversarial loss: 0.440578\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024153; batch adversarial loss: 0.333088\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010703; batch adversarial loss: 0.470367\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018358; batch adversarial loss: 0.379203\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040646; batch adversarial loss: 0.481031\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025827; batch adversarial loss: 0.436969\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017500; batch adversarial loss: 0.389329\n",
      "epoch 162; iter: 0; batch classifier loss: 0.055603; batch adversarial loss: 0.444536\n",
      "epoch 163; iter: 0; batch classifier loss: 0.051616; batch adversarial loss: 0.497060\n",
      "epoch 164; iter: 0; batch classifier loss: 0.046095; batch adversarial loss: 0.495473\n",
      "epoch 165; iter: 0; batch classifier loss: 0.003837; batch adversarial loss: 0.350895\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033323; batch adversarial loss: 0.440305\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017375; batch adversarial loss: 0.505263\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020314; batch adversarial loss: 0.448309\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035412; batch adversarial loss: 0.412611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.016245; batch adversarial loss: 0.389628\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016680; batch adversarial loss: 0.373824\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027774; batch adversarial loss: 0.512884\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013661; batch adversarial loss: 0.410024\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033692; batch adversarial loss: 0.436778\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007148; batch adversarial loss: 0.491325\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026191; batch adversarial loss: 0.429578\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015788; batch adversarial loss: 0.500458\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017808; batch adversarial loss: 0.441601\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021631; batch adversarial loss: 0.400235\n",
      "epoch 180; iter: 0; batch classifier loss: 0.003439; batch adversarial loss: 0.503439\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033147; batch adversarial loss: 0.465784\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015365; batch adversarial loss: 0.373104\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018005; batch adversarial loss: 0.410073\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011541; batch adversarial loss: 0.475051\n",
      "epoch 185; iter: 0; batch classifier loss: 0.034202; batch adversarial loss: 0.489074\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026727; batch adversarial loss: 0.442674\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017703; batch adversarial loss: 0.454257\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027558; batch adversarial loss: 0.486927\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030791; batch adversarial loss: 0.506427\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020702; batch adversarial loss: 0.533777\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015696; batch adversarial loss: 0.513858\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016059; batch adversarial loss: 0.391058\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037018; batch adversarial loss: 0.380880\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005203; batch adversarial loss: 0.430348\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004468; batch adversarial loss: 0.432393\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026795; batch adversarial loss: 0.415337\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005793; batch adversarial loss: 0.358382\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027487; batch adversarial loss: 0.484719\n",
      "epoch 199; iter: 0; batch classifier loss: 0.003957; batch adversarial loss: 0.357681\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681010; batch adversarial loss: 0.729331\n",
      "epoch 1; iter: 0; batch classifier loss: 0.565626; batch adversarial loss: 0.682043\n",
      "epoch 2; iter: 0; batch classifier loss: 0.368288; batch adversarial loss: 0.624979\n",
      "epoch 3; iter: 0; batch classifier loss: 0.289658; batch adversarial loss: 0.579784\n",
      "epoch 4; iter: 0; batch classifier loss: 0.407810; batch adversarial loss: 0.624335\n",
      "epoch 5; iter: 0; batch classifier loss: 0.338931; batch adversarial loss: 0.599947\n",
      "epoch 6; iter: 0; batch classifier loss: 0.369366; batch adversarial loss: 0.582069\n",
      "epoch 7; iter: 0; batch classifier loss: 0.323169; batch adversarial loss: 0.521844\n",
      "epoch 8; iter: 0; batch classifier loss: 0.261080; batch adversarial loss: 0.526575\n",
      "epoch 9; iter: 0; batch classifier loss: 0.261567; batch adversarial loss: 0.499343\n",
      "epoch 10; iter: 0; batch classifier loss: 0.279575; batch adversarial loss: 0.550786\n",
      "epoch 11; iter: 0; batch classifier loss: 0.216109; batch adversarial loss: 0.520294\n",
      "epoch 12; iter: 0; batch classifier loss: 0.264245; batch adversarial loss: 0.531506\n",
      "epoch 13; iter: 0; batch classifier loss: 0.219201; batch adversarial loss: 0.543561\n",
      "epoch 14; iter: 0; batch classifier loss: 0.230483; batch adversarial loss: 0.514153\n",
      "epoch 15; iter: 0; batch classifier loss: 0.272243; batch adversarial loss: 0.483526\n",
      "epoch 16; iter: 0; batch classifier loss: 0.352328; batch adversarial loss: 0.545517\n",
      "epoch 17; iter: 0; batch classifier loss: 0.247496; batch adversarial loss: 0.501759\n",
      "epoch 18; iter: 0; batch classifier loss: 0.265340; batch adversarial loss: 0.477259\n",
      "epoch 19; iter: 0; batch classifier loss: 0.180697; batch adversarial loss: 0.525610\n",
      "epoch 20; iter: 0; batch classifier loss: 0.210272; batch adversarial loss: 0.506369\n",
      "epoch 21; iter: 0; batch classifier loss: 0.226188; batch adversarial loss: 0.458282\n",
      "epoch 22; iter: 0; batch classifier loss: 0.219076; batch adversarial loss: 0.511889\n",
      "epoch 23; iter: 0; batch classifier loss: 0.226732; batch adversarial loss: 0.410095\n",
      "epoch 24; iter: 0; batch classifier loss: 0.211614; batch adversarial loss: 0.417311\n",
      "epoch 25; iter: 0; batch classifier loss: 0.197698; batch adversarial loss: 0.567869\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189229; batch adversarial loss: 0.442152\n",
      "epoch 27; iter: 0; batch classifier loss: 0.138951; batch adversarial loss: 0.483477\n",
      "epoch 28; iter: 0; batch classifier loss: 0.114670; batch adversarial loss: 0.469794\n",
      "epoch 29; iter: 0; batch classifier loss: 0.126498; batch adversarial loss: 0.463624\n",
      "epoch 30; iter: 0; batch classifier loss: 0.234327; batch adversarial loss: 0.500517\n",
      "epoch 31; iter: 0; batch classifier loss: 0.205474; batch adversarial loss: 0.430122\n",
      "epoch 32; iter: 0; batch classifier loss: 0.106773; batch adversarial loss: 0.475638\n",
      "epoch 33; iter: 0; batch classifier loss: 0.196361; batch adversarial loss: 0.468139\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122455; batch adversarial loss: 0.524411\n",
      "epoch 35; iter: 0; batch classifier loss: 0.131534; batch adversarial loss: 0.477514\n",
      "epoch 36; iter: 0; batch classifier loss: 0.106107; batch adversarial loss: 0.526354\n",
      "epoch 37; iter: 0; batch classifier loss: 0.160066; batch adversarial loss: 0.444656\n",
      "epoch 38; iter: 0; batch classifier loss: 0.134270; batch adversarial loss: 0.536669\n",
      "epoch 39; iter: 0; batch classifier loss: 0.141362; batch adversarial loss: 0.423673\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116295; batch adversarial loss: 0.414864\n",
      "epoch 41; iter: 0; batch classifier loss: 0.151455; batch adversarial loss: 0.415625\n",
      "epoch 42; iter: 0; batch classifier loss: 0.104213; batch adversarial loss: 0.479855\n",
      "epoch 43; iter: 0; batch classifier loss: 0.146676; batch adversarial loss: 0.452417\n",
      "epoch 44; iter: 0; batch classifier loss: 0.102701; batch adversarial loss: 0.429930\n",
      "epoch 45; iter: 0; batch classifier loss: 0.121391; batch adversarial loss: 0.416775\n",
      "epoch 46; iter: 0; batch classifier loss: 0.133986; batch adversarial loss: 0.562505\n",
      "epoch 47; iter: 0; batch classifier loss: 0.093452; batch adversarial loss: 0.546722\n",
      "epoch 48; iter: 0; batch classifier loss: 0.103244; batch adversarial loss: 0.423972\n",
      "epoch 49; iter: 0; batch classifier loss: 0.123003; batch adversarial loss: 0.449909\n",
      "epoch 50; iter: 0; batch classifier loss: 0.170412; batch adversarial loss: 0.448291\n",
      "epoch 51; iter: 0; batch classifier loss: 0.169467; batch adversarial loss: 0.493897\n",
      "epoch 52; iter: 0; batch classifier loss: 0.141973; batch adversarial loss: 0.409024\n",
      "epoch 53; iter: 0; batch classifier loss: 0.106038; batch adversarial loss: 0.461422\n",
      "epoch 54; iter: 0; batch classifier loss: 0.136351; batch adversarial loss: 0.465205\n",
      "epoch 55; iter: 0; batch classifier loss: 0.167259; batch adversarial loss: 0.469020\n",
      "epoch 56; iter: 0; batch classifier loss: 0.113152; batch adversarial loss: 0.455901\n",
      "epoch 57; iter: 0; batch classifier loss: 0.084949; batch adversarial loss: 0.455539\n",
      "epoch 58; iter: 0; batch classifier loss: 0.054078; batch adversarial loss: 0.386113\n",
      "epoch 59; iter: 0; batch classifier loss: 0.106974; batch adversarial loss: 0.410829\n",
      "epoch 60; iter: 0; batch classifier loss: 0.063096; batch adversarial loss: 0.470627\n",
      "epoch 61; iter: 0; batch classifier loss: 0.092948; batch adversarial loss: 0.507220\n",
      "epoch 62; iter: 0; batch classifier loss: 0.106920; batch adversarial loss: 0.459178\n",
      "epoch 63; iter: 0; batch classifier loss: 0.087884; batch adversarial loss: 0.489393\n",
      "epoch 64; iter: 0; batch classifier loss: 0.062476; batch adversarial loss: 0.431604\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087607; batch adversarial loss: 0.581144\n",
      "epoch 66; iter: 0; batch classifier loss: 0.074386; batch adversarial loss: 0.440805\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096314; batch adversarial loss: 0.431140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.037594; batch adversarial loss: 0.541091\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073166; batch adversarial loss: 0.520530\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086666; batch adversarial loss: 0.441260\n",
      "epoch 71; iter: 0; batch classifier loss: 0.106061; batch adversarial loss: 0.457173\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097474; batch adversarial loss: 0.448770\n",
      "epoch 73; iter: 0; batch classifier loss: 0.086404; batch adversarial loss: 0.400967\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067764; batch adversarial loss: 0.427756\n",
      "epoch 75; iter: 0; batch classifier loss: 0.060249; batch adversarial loss: 0.463855\n",
      "epoch 76; iter: 0; batch classifier loss: 0.108864; batch adversarial loss: 0.448431\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067074; batch adversarial loss: 0.481069\n",
      "epoch 78; iter: 0; batch classifier loss: 0.097686; batch adversarial loss: 0.471503\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075506; batch adversarial loss: 0.491620\n",
      "epoch 80; iter: 0; batch classifier loss: 0.063569; batch adversarial loss: 0.496745\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061797; batch adversarial loss: 0.576836\n",
      "epoch 82; iter: 0; batch classifier loss: 0.057833; batch adversarial loss: 0.438701\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035881; batch adversarial loss: 0.417320\n",
      "epoch 84; iter: 0; batch classifier loss: 0.054945; batch adversarial loss: 0.434726\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070465; batch adversarial loss: 0.519586\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073564; batch adversarial loss: 0.425961\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071272; batch adversarial loss: 0.521355\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076156; batch adversarial loss: 0.368775\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068424; batch adversarial loss: 0.452344\n",
      "epoch 90; iter: 0; batch classifier loss: 0.049636; batch adversarial loss: 0.374559\n",
      "epoch 91; iter: 0; batch classifier loss: 0.032462; batch adversarial loss: 0.403133\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044925; batch adversarial loss: 0.453174\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079880; batch adversarial loss: 0.348836\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050978; batch adversarial loss: 0.451952\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070208; batch adversarial loss: 0.536660\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066308; batch adversarial loss: 0.449488\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050289; batch adversarial loss: 0.507706\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052346; batch adversarial loss: 0.496876\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069574; batch adversarial loss: 0.518275\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036730; batch adversarial loss: 0.415243\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055739; batch adversarial loss: 0.540310\n",
      "epoch 102; iter: 0; batch classifier loss: 0.070253; batch adversarial loss: 0.464938\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033699; batch adversarial loss: 0.507681\n",
      "epoch 104; iter: 0; batch classifier loss: 0.020720; batch adversarial loss: 0.468414\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030967; batch adversarial loss: 0.375648\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025553; batch adversarial loss: 0.473506\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055541; batch adversarial loss: 0.539266\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054229; batch adversarial loss: 0.424486\n",
      "epoch 109; iter: 0; batch classifier loss: 0.069739; batch adversarial loss: 0.554066\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047037; batch adversarial loss: 0.438326\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055012; batch adversarial loss: 0.464474\n",
      "epoch 112; iter: 0; batch classifier loss: 0.073740; batch adversarial loss: 0.403927\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044550; batch adversarial loss: 0.500937\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054430; batch adversarial loss: 0.551972\n",
      "epoch 115; iter: 0; batch classifier loss: 0.078231; batch adversarial loss: 0.469217\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045142; batch adversarial loss: 0.373594\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034182; batch adversarial loss: 0.427787\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035218; batch adversarial loss: 0.482639\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035842; batch adversarial loss: 0.594263\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024834; batch adversarial loss: 0.522799\n",
      "epoch 121; iter: 0; batch classifier loss: 0.023071; batch adversarial loss: 0.464706\n",
      "epoch 122; iter: 0; batch classifier loss: 0.082758; batch adversarial loss: 0.352534\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027520; batch adversarial loss: 0.436485\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024802; batch adversarial loss: 0.421575\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018103; batch adversarial loss: 0.463111\n",
      "epoch 126; iter: 0; batch classifier loss: 0.013361; batch adversarial loss: 0.393807\n",
      "epoch 127; iter: 0; batch classifier loss: 0.054914; batch adversarial loss: 0.387095\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024378; batch adversarial loss: 0.452678\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035349; batch adversarial loss: 0.398635\n",
      "epoch 130; iter: 0; batch classifier loss: 0.009798; batch adversarial loss: 0.468535\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015540; batch adversarial loss: 0.470769\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025556; batch adversarial loss: 0.523650\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023258; batch adversarial loss: 0.495364\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018578; batch adversarial loss: 0.445586\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012372; batch adversarial loss: 0.522126\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013384; batch adversarial loss: 0.463179\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036254; batch adversarial loss: 0.531324\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013353; batch adversarial loss: 0.461309\n",
      "epoch 139; iter: 0; batch classifier loss: 0.012030; batch adversarial loss: 0.536496\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028277; batch adversarial loss: 0.489955\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032249; batch adversarial loss: 0.465422\n",
      "epoch 142; iter: 0; batch classifier loss: 0.071728; batch adversarial loss: 0.429977\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018164; batch adversarial loss: 0.395208\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026836; batch adversarial loss: 0.423645\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012724; batch adversarial loss: 0.474530\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039480; batch adversarial loss: 0.503162\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035670; batch adversarial loss: 0.457745\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019487; batch adversarial loss: 0.532979\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026054; batch adversarial loss: 0.484174\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011909; batch adversarial loss: 0.471007\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048639; batch adversarial loss: 0.515650\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027805; batch adversarial loss: 0.428104\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029756; batch adversarial loss: 0.465023\n",
      "epoch 154; iter: 0; batch classifier loss: 0.045251; batch adversarial loss: 0.432970\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034545; batch adversarial loss: 0.503540\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018803; batch adversarial loss: 0.458377\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031799; batch adversarial loss: 0.460382\n",
      "epoch 158; iter: 0; batch classifier loss: 0.061011; batch adversarial loss: 0.486704\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015541; batch adversarial loss: 0.406512\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016400; batch adversarial loss: 0.386578\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031624; batch adversarial loss: 0.466654\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014823; batch adversarial loss: 0.528301\n",
      "epoch 163; iter: 0; batch classifier loss: 0.041036; batch adversarial loss: 0.402369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.010723; batch adversarial loss: 0.319152\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009615; batch adversarial loss: 0.419812\n",
      "epoch 166; iter: 0; batch classifier loss: 0.055118; batch adversarial loss: 0.442310\n",
      "epoch 167; iter: 0; batch classifier loss: 0.003653; batch adversarial loss: 0.448289\n",
      "epoch 168; iter: 0; batch classifier loss: 0.047490; batch adversarial loss: 0.411592\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028157; batch adversarial loss: 0.346150\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012041; batch adversarial loss: 0.389813\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019802; batch adversarial loss: 0.432344\n",
      "epoch 172; iter: 0; batch classifier loss: 0.052590; batch adversarial loss: 0.359140\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028391; batch adversarial loss: 0.398996\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011283; batch adversarial loss: 0.366959\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020596; batch adversarial loss: 0.433139\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008101; batch adversarial loss: 0.532752\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023433; batch adversarial loss: 0.426208\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020442; batch adversarial loss: 0.487069\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021848; batch adversarial loss: 0.436011\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021448; batch adversarial loss: 0.353454\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033895; batch adversarial loss: 0.469543\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036453; batch adversarial loss: 0.472110\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015913; batch adversarial loss: 0.488489\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018782; batch adversarial loss: 0.449907\n",
      "epoch 185; iter: 0; batch classifier loss: 0.086834; batch adversarial loss: 0.467990\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012991; batch adversarial loss: 0.450320\n",
      "epoch 187; iter: 0; batch classifier loss: 0.047158; batch adversarial loss: 0.493850\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040405; batch adversarial loss: 0.499677\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035533; batch adversarial loss: 0.417567\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016943; batch adversarial loss: 0.454018\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024513; batch adversarial loss: 0.399585\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005973; batch adversarial loss: 0.394703\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030188; batch adversarial loss: 0.448360\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027203; batch adversarial loss: 0.472143\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031001; batch adversarial loss: 0.517145\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013441; batch adversarial loss: 0.427700\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026199; batch adversarial loss: 0.489750\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010625; batch adversarial loss: 0.340290\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017930; batch adversarial loss: 0.451147\n",
      "epoch 0; iter: 0; batch classifier loss: 0.665009; batch adversarial loss: 0.725938\n",
      "epoch 1; iter: 0; batch classifier loss: 0.459846; batch adversarial loss: 0.700688\n",
      "epoch 2; iter: 0; batch classifier loss: 0.445217; batch adversarial loss: 0.680973\n",
      "epoch 3; iter: 0; batch classifier loss: 0.340723; batch adversarial loss: 0.656289\n",
      "epoch 4; iter: 0; batch classifier loss: 0.278655; batch adversarial loss: 0.620255\n",
      "epoch 5; iter: 0; batch classifier loss: 0.335803; batch adversarial loss: 0.577050\n",
      "epoch 6; iter: 0; batch classifier loss: 0.298285; batch adversarial loss: 0.570566\n",
      "epoch 7; iter: 0; batch classifier loss: 0.297789; batch adversarial loss: 0.517102\n",
      "epoch 8; iter: 0; batch classifier loss: 0.345895; batch adversarial loss: 0.490813\n",
      "epoch 9; iter: 0; batch classifier loss: 0.205287; batch adversarial loss: 0.458972\n",
      "epoch 10; iter: 0; batch classifier loss: 0.226836; batch adversarial loss: 0.476329\n",
      "epoch 11; iter: 0; batch classifier loss: 0.247708; batch adversarial loss: 0.455208\n",
      "epoch 12; iter: 0; batch classifier loss: 0.228768; batch adversarial loss: 0.433478\n",
      "epoch 13; iter: 0; batch classifier loss: 0.194762; batch adversarial loss: 0.471343\n",
      "epoch 14; iter: 0; batch classifier loss: 0.220471; batch adversarial loss: 0.437484\n",
      "epoch 15; iter: 0; batch classifier loss: 0.173375; batch adversarial loss: 0.491154\n",
      "epoch 16; iter: 0; batch classifier loss: 0.172052; batch adversarial loss: 0.477304\n",
      "epoch 17; iter: 0; batch classifier loss: 0.227827; batch adversarial loss: 0.514777\n",
      "epoch 18; iter: 0; batch classifier loss: 0.176394; batch adversarial loss: 0.550719\n",
      "epoch 19; iter: 0; batch classifier loss: 0.132046; batch adversarial loss: 0.431347\n",
      "epoch 20; iter: 0; batch classifier loss: 0.154175; batch adversarial loss: 0.437879\n",
      "epoch 21; iter: 0; batch classifier loss: 0.123927; batch adversarial loss: 0.458151\n",
      "epoch 22; iter: 0; batch classifier loss: 0.138644; batch adversarial loss: 0.460514\n",
      "epoch 23; iter: 0; batch classifier loss: 0.174324; batch adversarial loss: 0.437914\n",
      "epoch 24; iter: 0; batch classifier loss: 0.136980; batch adversarial loss: 0.421692\n",
      "epoch 25; iter: 0; batch classifier loss: 0.157189; batch adversarial loss: 0.403251\n",
      "epoch 26; iter: 0; batch classifier loss: 0.148818; batch adversarial loss: 0.429457\n",
      "epoch 27; iter: 0; batch classifier loss: 0.124790; batch adversarial loss: 0.431644\n",
      "epoch 28; iter: 0; batch classifier loss: 0.149640; batch adversarial loss: 0.396820\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210532; batch adversarial loss: 0.395387\n",
      "epoch 30; iter: 0; batch classifier loss: 0.124189; batch adversarial loss: 0.405347\n",
      "epoch 31; iter: 0; batch classifier loss: 0.165229; batch adversarial loss: 0.374412\n",
      "epoch 32; iter: 0; batch classifier loss: 0.111421; batch adversarial loss: 0.344507\n",
      "epoch 33; iter: 0; batch classifier loss: 0.191989; batch adversarial loss: 0.445737\n",
      "epoch 34; iter: 0; batch classifier loss: 0.127585; batch adversarial loss: 0.363833\n",
      "epoch 35; iter: 0; batch classifier loss: 0.162663; batch adversarial loss: 0.436459\n",
      "epoch 36; iter: 0; batch classifier loss: 0.177107; batch adversarial loss: 0.408853\n",
      "epoch 37; iter: 0; batch classifier loss: 0.086631; batch adversarial loss: 0.385503\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115594; batch adversarial loss: 0.414132\n",
      "epoch 39; iter: 0; batch classifier loss: 0.110101; batch adversarial loss: 0.503547\n",
      "epoch 40; iter: 0; batch classifier loss: 0.122312; batch adversarial loss: 0.413200\n",
      "epoch 41; iter: 0; batch classifier loss: 0.132563; batch adversarial loss: 0.436429\n",
      "epoch 42; iter: 0; batch classifier loss: 0.124003; batch adversarial loss: 0.406695\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150337; batch adversarial loss: 0.471029\n",
      "epoch 44; iter: 0; batch classifier loss: 0.132918; batch adversarial loss: 0.326756\n",
      "epoch 45; iter: 0; batch classifier loss: 0.151451; batch adversarial loss: 0.379456\n",
      "epoch 46; iter: 0; batch classifier loss: 0.100668; batch adversarial loss: 0.416821\n",
      "epoch 47; iter: 0; batch classifier loss: 0.075058; batch adversarial loss: 0.381687\n",
      "epoch 48; iter: 0; batch classifier loss: 0.118442; batch adversarial loss: 0.427870\n",
      "epoch 49; iter: 0; batch classifier loss: 0.123507; batch adversarial loss: 0.491324\n",
      "epoch 50; iter: 0; batch classifier loss: 0.078563; batch adversarial loss: 0.419157\n",
      "epoch 51; iter: 0; batch classifier loss: 0.085208; batch adversarial loss: 0.418066\n",
      "epoch 52; iter: 0; batch classifier loss: 0.119221; batch adversarial loss: 0.397752\n",
      "epoch 53; iter: 0; batch classifier loss: 0.103085; batch adversarial loss: 0.363290\n",
      "epoch 54; iter: 0; batch classifier loss: 0.078903; batch adversarial loss: 0.387919\n",
      "epoch 55; iter: 0; batch classifier loss: 0.073645; batch adversarial loss: 0.410539\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119480; batch adversarial loss: 0.487742\n",
      "epoch 57; iter: 0; batch classifier loss: 0.119106; batch adversarial loss: 0.410407\n",
      "epoch 58; iter: 0; batch classifier loss: 0.088910; batch adversarial loss: 0.421146\n",
      "epoch 59; iter: 0; batch classifier loss: 0.075167; batch adversarial loss: 0.428159\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097854; batch adversarial loss: 0.432978\n",
      "epoch 61; iter: 0; batch classifier loss: 0.097887; batch adversarial loss: 0.471007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.090256; batch adversarial loss: 0.380961\n",
      "epoch 63; iter: 0; batch classifier loss: 0.055449; batch adversarial loss: 0.348620\n",
      "epoch 64; iter: 0; batch classifier loss: 0.064327; batch adversarial loss: 0.531410\n",
      "epoch 65; iter: 0; batch classifier loss: 0.048428; batch adversarial loss: 0.424564\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086110; batch adversarial loss: 0.439506\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106621; batch adversarial loss: 0.415078\n",
      "epoch 68; iter: 0; batch classifier loss: 0.083003; batch adversarial loss: 0.366314\n",
      "epoch 69; iter: 0; batch classifier loss: 0.111580; batch adversarial loss: 0.432242\n",
      "epoch 70; iter: 0; batch classifier loss: 0.084141; batch adversarial loss: 0.435789\n",
      "epoch 71; iter: 0; batch classifier loss: 0.077668; batch adversarial loss: 0.448583\n",
      "epoch 72; iter: 0; batch classifier loss: 0.069833; batch adversarial loss: 0.437376\n",
      "epoch 73; iter: 0; batch classifier loss: 0.078074; batch adversarial loss: 0.385723\n",
      "epoch 74; iter: 0; batch classifier loss: 0.083322; batch adversarial loss: 0.336650\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075312; batch adversarial loss: 0.416836\n",
      "epoch 76; iter: 0; batch classifier loss: 0.047143; batch adversarial loss: 0.443101\n",
      "epoch 77; iter: 0; batch classifier loss: 0.082184; batch adversarial loss: 0.352560\n",
      "epoch 78; iter: 0; batch classifier loss: 0.087298; batch adversarial loss: 0.445812\n",
      "epoch 79; iter: 0; batch classifier loss: 0.078098; batch adversarial loss: 0.471946\n",
      "epoch 80; iter: 0; batch classifier loss: 0.081061; batch adversarial loss: 0.376233\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066421; batch adversarial loss: 0.407915\n",
      "epoch 82; iter: 0; batch classifier loss: 0.093701; batch adversarial loss: 0.450992\n",
      "epoch 83; iter: 0; batch classifier loss: 0.101386; batch adversarial loss: 0.453719\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065063; batch adversarial loss: 0.522662\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074784; batch adversarial loss: 0.431859\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065412; batch adversarial loss: 0.488116\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083264; batch adversarial loss: 0.409365\n",
      "epoch 88; iter: 0; batch classifier loss: 0.081923; batch adversarial loss: 0.369970\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060292; batch adversarial loss: 0.397095\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051740; batch adversarial loss: 0.487612\n",
      "epoch 91; iter: 0; batch classifier loss: 0.054942; batch adversarial loss: 0.414241\n",
      "epoch 92; iter: 0; batch classifier loss: 0.107055; batch adversarial loss: 0.433596\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047161; batch adversarial loss: 0.498629\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038820; batch adversarial loss: 0.389350\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064632; batch adversarial loss: 0.494300\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059362; batch adversarial loss: 0.427535\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065043; batch adversarial loss: 0.518130\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061700; batch adversarial loss: 0.379117\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047809; batch adversarial loss: 0.475858\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048135; batch adversarial loss: 0.397011\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044711; batch adversarial loss: 0.378540\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059097; batch adversarial loss: 0.429962\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033805; batch adversarial loss: 0.467799\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045788; batch adversarial loss: 0.391278\n",
      "epoch 105; iter: 0; batch classifier loss: 0.025015; batch adversarial loss: 0.536861\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035086; batch adversarial loss: 0.380942\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035181; batch adversarial loss: 0.488029\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064542; batch adversarial loss: 0.458579\n",
      "epoch 109; iter: 0; batch classifier loss: 0.052852; batch adversarial loss: 0.449770\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046265; batch adversarial loss: 0.532930\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053878; batch adversarial loss: 0.371549\n",
      "epoch 112; iter: 0; batch classifier loss: 0.023000; batch adversarial loss: 0.461126\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027921; batch adversarial loss: 0.499125\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047581; batch adversarial loss: 0.388960\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048538; batch adversarial loss: 0.414931\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022211; batch adversarial loss: 0.539423\n",
      "epoch 117; iter: 0; batch classifier loss: 0.011977; batch adversarial loss: 0.414226\n",
      "epoch 118; iter: 0; batch classifier loss: 0.027155; batch adversarial loss: 0.525517\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045702; batch adversarial loss: 0.493960\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062122; batch adversarial loss: 0.593120\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060181; batch adversarial loss: 0.538188\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067210; batch adversarial loss: 0.483888\n",
      "epoch 123; iter: 0; batch classifier loss: 0.078605; batch adversarial loss: 0.594433\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067700; batch adversarial loss: 0.510885\n",
      "epoch 125; iter: 0; batch classifier loss: 0.115506; batch adversarial loss: 0.525004\n",
      "epoch 126; iter: 0; batch classifier loss: 0.165921; batch adversarial loss: 0.616593\n",
      "epoch 127; iter: 0; batch classifier loss: 0.134319; batch adversarial loss: 0.669120\n",
      "epoch 128; iter: 0; batch classifier loss: 0.104662; batch adversarial loss: 0.557428\n",
      "epoch 129; iter: 0; batch classifier loss: 0.105803; batch adversarial loss: 0.569464\n",
      "epoch 130; iter: 0; batch classifier loss: 0.149750; batch adversarial loss: 0.576813\n",
      "epoch 131; iter: 0; batch classifier loss: 0.190852; batch adversarial loss: 0.707720\n",
      "epoch 132; iter: 0; batch classifier loss: 0.185243; batch adversarial loss: 0.701190\n",
      "epoch 133; iter: 0; batch classifier loss: 0.138038; batch adversarial loss: 0.513574\n",
      "epoch 134; iter: 0; batch classifier loss: 0.105728; batch adversarial loss: 0.597645\n",
      "epoch 135; iter: 0; batch classifier loss: 0.088696; batch adversarial loss: 0.470505\n",
      "epoch 136; iter: 0; batch classifier loss: 0.071746; batch adversarial loss: 0.463889\n",
      "epoch 137; iter: 0; batch classifier loss: 0.118735; batch adversarial loss: 0.567560\n",
      "epoch 138; iter: 0; batch classifier loss: 0.100354; batch adversarial loss: 0.477867\n",
      "epoch 139; iter: 0; batch classifier loss: 0.215561; batch adversarial loss: 0.729956\n",
      "epoch 140; iter: 0; batch classifier loss: 0.102310; batch adversarial loss: 0.520086\n",
      "epoch 141; iter: 0; batch classifier loss: 0.123018; batch adversarial loss: 0.483349\n",
      "epoch 142; iter: 0; batch classifier loss: 0.144820; batch adversarial loss: 0.586171\n",
      "epoch 143; iter: 0; batch classifier loss: 0.166593; batch adversarial loss: 0.520148\n",
      "epoch 144; iter: 0; batch classifier loss: 0.145638; batch adversarial loss: 0.494153\n",
      "epoch 145; iter: 0; batch classifier loss: 0.180450; batch adversarial loss: 0.652766\n",
      "epoch 146; iter: 0; batch classifier loss: 0.136729; batch adversarial loss: 0.532334\n",
      "epoch 147; iter: 0; batch classifier loss: 0.146462; batch adversarial loss: 0.440595\n",
      "epoch 148; iter: 0; batch classifier loss: 0.118809; batch adversarial loss: 0.504100\n",
      "epoch 149; iter: 0; batch classifier loss: 0.226266; batch adversarial loss: 0.661963\n",
      "epoch 150; iter: 0; batch classifier loss: 0.086158; batch adversarial loss: 0.475646\n",
      "epoch 151; iter: 0; batch classifier loss: 0.101172; batch adversarial loss: 0.466966\n",
      "epoch 152; iter: 0; batch classifier loss: 0.136316; batch adversarial loss: 0.535658\n",
      "epoch 153; iter: 0; batch classifier loss: 0.115654; batch adversarial loss: 0.430288\n",
      "epoch 154; iter: 0; batch classifier loss: 0.155750; batch adversarial loss: 0.553244\n",
      "epoch 155; iter: 0; batch classifier loss: 0.120003; batch adversarial loss: 0.452560\n",
      "epoch 156; iter: 0; batch classifier loss: 0.142348; batch adversarial loss: 0.500862\n",
      "epoch 157; iter: 0; batch classifier loss: 0.164445; batch adversarial loss: 0.502513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.092634; batch adversarial loss: 0.419023\n",
      "epoch 159; iter: 0; batch classifier loss: 0.081231; batch adversarial loss: 0.439968\n",
      "epoch 160; iter: 0; batch classifier loss: 0.125462; batch adversarial loss: 0.500533\n",
      "epoch 161; iter: 0; batch classifier loss: 0.066962; batch adversarial loss: 0.417352\n",
      "epoch 162; iter: 0; batch classifier loss: 0.190548; batch adversarial loss: 0.554959\n",
      "epoch 163; iter: 0; batch classifier loss: 0.099692; batch adversarial loss: 0.390251\n",
      "epoch 164; iter: 0; batch classifier loss: 0.154791; batch adversarial loss: 0.453263\n",
      "epoch 165; iter: 0; batch classifier loss: 0.151765; batch adversarial loss: 0.518652\n",
      "epoch 166; iter: 0; batch classifier loss: 0.103926; batch adversarial loss: 0.420431\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036641; batch adversarial loss: 0.419012\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027464; batch adversarial loss: 0.528658\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040113; batch adversarial loss: 0.558857\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033441; batch adversarial loss: 0.565080\n",
      "epoch 171; iter: 0; batch classifier loss: 0.039049; batch adversarial loss: 0.456087\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012538; batch adversarial loss: 0.462104\n",
      "epoch 173; iter: 0; batch classifier loss: 0.068220; batch adversarial loss: 0.451045\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029419; batch adversarial loss: 0.499874\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041811; batch adversarial loss: 0.482054\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041492; batch adversarial loss: 0.361185\n",
      "epoch 177; iter: 0; batch classifier loss: 0.045880; batch adversarial loss: 0.369535\n",
      "epoch 178; iter: 0; batch classifier loss: 0.053010; batch adversarial loss: 0.445525\n",
      "epoch 179; iter: 0; batch classifier loss: 0.071572; batch adversarial loss: 0.455053\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027741; batch adversarial loss: 0.551331\n",
      "epoch 181; iter: 0; batch classifier loss: 0.075124; batch adversarial loss: 0.536903\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038630; batch adversarial loss: 0.449256\n",
      "epoch 183; iter: 0; batch classifier loss: 0.043932; batch adversarial loss: 0.486418\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037284; batch adversarial loss: 0.435911\n",
      "epoch 185; iter: 0; batch classifier loss: 0.052727; batch adversarial loss: 0.438781\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025123; batch adversarial loss: 0.424450\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031447; batch adversarial loss: 0.420897\n",
      "epoch 188; iter: 0; batch classifier loss: 0.098001; batch adversarial loss: 0.410729\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030999; batch adversarial loss: 0.423591\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035782; batch adversarial loss: 0.458637\n",
      "epoch 191; iter: 0; batch classifier loss: 0.052654; batch adversarial loss: 0.435100\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025869; batch adversarial loss: 0.485404\n",
      "epoch 193; iter: 0; batch classifier loss: 0.061466; batch adversarial loss: 0.532090\n",
      "epoch 194; iter: 0; batch classifier loss: 0.064192; batch adversarial loss: 0.432424\n",
      "epoch 195; iter: 0; batch classifier loss: 0.089398; batch adversarial loss: 0.343879\n",
      "epoch 196; iter: 0; batch classifier loss: 0.068106; batch adversarial loss: 0.449208\n",
      "epoch 197; iter: 0; batch classifier loss: 0.044338; batch adversarial loss: 0.447965\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031421; batch adversarial loss: 0.426364\n",
      "epoch 199; iter: 0; batch classifier loss: 0.061133; batch adversarial loss: 0.491999\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685369; batch adversarial loss: 0.622700\n",
      "epoch 1; iter: 0; batch classifier loss: 0.421644; batch adversarial loss: 0.634823\n",
      "epoch 2; iter: 0; batch classifier loss: 0.317976; batch adversarial loss: 0.607231\n",
      "epoch 3; iter: 0; batch classifier loss: 0.320394; batch adversarial loss: 0.588382\n",
      "epoch 4; iter: 0; batch classifier loss: 0.278078; batch adversarial loss: 0.536768\n",
      "epoch 5; iter: 0; batch classifier loss: 0.346353; batch adversarial loss: 0.540850\n",
      "epoch 6; iter: 0; batch classifier loss: 0.303204; batch adversarial loss: 0.530829\n",
      "epoch 7; iter: 0; batch classifier loss: 0.293984; batch adversarial loss: 0.559648\n",
      "epoch 8; iter: 0; batch classifier loss: 0.328149; batch adversarial loss: 0.518466\n",
      "epoch 9; iter: 0; batch classifier loss: 0.276854; batch adversarial loss: 0.553727\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269944; batch adversarial loss: 0.551273\n",
      "epoch 11; iter: 0; batch classifier loss: 0.293070; batch adversarial loss: 0.393513\n",
      "epoch 12; iter: 0; batch classifier loss: 0.267716; batch adversarial loss: 0.592494\n",
      "epoch 13; iter: 0; batch classifier loss: 0.320875; batch adversarial loss: 0.553095\n",
      "epoch 14; iter: 0; batch classifier loss: 0.305687; batch adversarial loss: 0.460656\n",
      "epoch 15; iter: 0; batch classifier loss: 0.309854; batch adversarial loss: 0.579167\n",
      "epoch 16; iter: 0; batch classifier loss: 0.380255; batch adversarial loss: 0.535717\n",
      "epoch 17; iter: 0; batch classifier loss: 0.367905; batch adversarial loss: 0.525892\n",
      "epoch 18; iter: 0; batch classifier loss: 0.487778; batch adversarial loss: 0.503586\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523523; batch adversarial loss: 0.531434\n",
      "epoch 20; iter: 0; batch classifier loss: 0.384632; batch adversarial loss: 0.503172\n",
      "epoch 21; iter: 0; batch classifier loss: 0.262034; batch adversarial loss: 0.492101\n",
      "epoch 22; iter: 0; batch classifier loss: 0.199833; batch adversarial loss: 0.460688\n",
      "epoch 23; iter: 0; batch classifier loss: 0.240926; batch adversarial loss: 0.499518\n",
      "epoch 24; iter: 0; batch classifier loss: 0.128182; batch adversarial loss: 0.526841\n",
      "epoch 25; iter: 0; batch classifier loss: 0.156845; batch adversarial loss: 0.473647\n",
      "epoch 26; iter: 0; batch classifier loss: 0.190429; batch adversarial loss: 0.479071\n",
      "epoch 27; iter: 0; batch classifier loss: 0.147658; batch adversarial loss: 0.370636\n",
      "epoch 28; iter: 0; batch classifier loss: 0.183541; batch adversarial loss: 0.421551\n",
      "epoch 29; iter: 0; batch classifier loss: 0.161993; batch adversarial loss: 0.387581\n",
      "epoch 30; iter: 0; batch classifier loss: 0.216825; batch adversarial loss: 0.424321\n",
      "epoch 31; iter: 0; batch classifier loss: 0.152518; batch adversarial loss: 0.427798\n",
      "epoch 32; iter: 0; batch classifier loss: 0.092312; batch adversarial loss: 0.382428\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144227; batch adversarial loss: 0.517060\n",
      "epoch 34; iter: 0; batch classifier loss: 0.174361; batch adversarial loss: 0.379574\n",
      "epoch 35; iter: 0; batch classifier loss: 0.119113; batch adversarial loss: 0.499398\n",
      "epoch 36; iter: 0; batch classifier loss: 0.108915; batch adversarial loss: 0.453094\n",
      "epoch 37; iter: 0; batch classifier loss: 0.162738; batch adversarial loss: 0.430543\n",
      "epoch 38; iter: 0; batch classifier loss: 0.156356; batch adversarial loss: 0.401680\n",
      "epoch 39; iter: 0; batch classifier loss: 0.075616; batch adversarial loss: 0.529492\n",
      "epoch 40; iter: 0; batch classifier loss: 0.114971; batch adversarial loss: 0.451215\n",
      "epoch 41; iter: 0; batch classifier loss: 0.202208; batch adversarial loss: 0.476118\n",
      "epoch 42; iter: 0; batch classifier loss: 0.132186; batch adversarial loss: 0.392647\n",
      "epoch 43; iter: 0; batch classifier loss: 0.146262; batch adversarial loss: 0.386085\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136630; batch adversarial loss: 0.427834\n",
      "epoch 45; iter: 0; batch classifier loss: 0.145456; batch adversarial loss: 0.470547\n",
      "epoch 46; iter: 0; batch classifier loss: 0.093393; batch adversarial loss: 0.438717\n",
      "epoch 47; iter: 0; batch classifier loss: 0.144708; batch adversarial loss: 0.519286\n",
      "epoch 48; iter: 0; batch classifier loss: 0.088692; batch adversarial loss: 0.485378\n",
      "epoch 49; iter: 0; batch classifier loss: 0.106797; batch adversarial loss: 0.336321\n",
      "epoch 50; iter: 0; batch classifier loss: 0.146999; batch adversarial loss: 0.474272\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100077; batch adversarial loss: 0.473234\n",
      "epoch 52; iter: 0; batch classifier loss: 0.122306; batch adversarial loss: 0.450771\n",
      "epoch 53; iter: 0; batch classifier loss: 0.205771; batch adversarial loss: 0.463334\n",
      "epoch 54; iter: 0; batch classifier loss: 0.143455; batch adversarial loss: 0.487116\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096375; batch adversarial loss: 0.468419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.109138; batch adversarial loss: 0.436377\n",
      "epoch 57; iter: 0; batch classifier loss: 0.124922; batch adversarial loss: 0.443552\n",
      "epoch 58; iter: 0; batch classifier loss: 0.125153; batch adversarial loss: 0.459043\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099540; batch adversarial loss: 0.407498\n",
      "epoch 60; iter: 0; batch classifier loss: 0.140345; batch adversarial loss: 0.397145\n",
      "epoch 61; iter: 0; batch classifier loss: 0.116374; batch adversarial loss: 0.453270\n",
      "epoch 62; iter: 0; batch classifier loss: 0.070669; batch adversarial loss: 0.574621\n",
      "epoch 63; iter: 0; batch classifier loss: 0.090653; batch adversarial loss: 0.385422\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098249; batch adversarial loss: 0.530164\n",
      "epoch 65; iter: 0; batch classifier loss: 0.124710; batch adversarial loss: 0.346223\n",
      "epoch 66; iter: 0; batch classifier loss: 0.158489; batch adversarial loss: 0.427488\n",
      "epoch 67; iter: 0; batch classifier loss: 0.093282; batch adversarial loss: 0.430387\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078509; batch adversarial loss: 0.446123\n",
      "epoch 69; iter: 0; batch classifier loss: 0.101839; batch adversarial loss: 0.348047\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110807; batch adversarial loss: 0.425002\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099784; batch adversarial loss: 0.530639\n",
      "epoch 72; iter: 0; batch classifier loss: 0.094502; batch adversarial loss: 0.421447\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101482; batch adversarial loss: 0.382456\n",
      "epoch 74; iter: 0; batch classifier loss: 0.068656; batch adversarial loss: 0.490505\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068812; batch adversarial loss: 0.512946\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077512; batch adversarial loss: 0.448008\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094571; batch adversarial loss: 0.565812\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085448; batch adversarial loss: 0.459864\n",
      "epoch 79; iter: 0; batch classifier loss: 0.091538; batch adversarial loss: 0.451988\n",
      "epoch 80; iter: 0; batch classifier loss: 0.085155; batch adversarial loss: 0.447252\n",
      "epoch 81; iter: 0; batch classifier loss: 0.038798; batch adversarial loss: 0.379075\n",
      "epoch 82; iter: 0; batch classifier loss: 0.121755; batch adversarial loss: 0.396341\n",
      "epoch 83; iter: 0; batch classifier loss: 0.038089; batch adversarial loss: 0.542026\n",
      "epoch 84; iter: 0; batch classifier loss: 0.084726; batch adversarial loss: 0.539409\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052840; batch adversarial loss: 0.531814\n",
      "epoch 86; iter: 0; batch classifier loss: 0.100741; batch adversarial loss: 0.388689\n",
      "epoch 87; iter: 0; batch classifier loss: 0.097490; batch adversarial loss: 0.449238\n",
      "epoch 88; iter: 0; batch classifier loss: 0.060563; batch adversarial loss: 0.428752\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053033; batch adversarial loss: 0.387437\n",
      "epoch 90; iter: 0; batch classifier loss: 0.102412; batch adversarial loss: 0.477919\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075204; batch adversarial loss: 0.550038\n",
      "epoch 92; iter: 0; batch classifier loss: 0.099264; batch adversarial loss: 0.481788\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058749; batch adversarial loss: 0.433431\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068403; batch adversarial loss: 0.435994\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068534; batch adversarial loss: 0.546199\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057461; batch adversarial loss: 0.471082\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081325; batch adversarial loss: 0.440904\n",
      "epoch 98; iter: 0; batch classifier loss: 0.073326; batch adversarial loss: 0.451234\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049084; batch adversarial loss: 0.507374\n",
      "epoch 100; iter: 0; batch classifier loss: 0.071221; batch adversarial loss: 0.475004\n",
      "epoch 101; iter: 0; batch classifier loss: 0.060574; batch adversarial loss: 0.539461\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029980; batch adversarial loss: 0.457197\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055927; batch adversarial loss: 0.460321\n",
      "epoch 104; iter: 0; batch classifier loss: 0.082894; batch adversarial loss: 0.358954\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043371; batch adversarial loss: 0.436925\n",
      "epoch 106; iter: 0; batch classifier loss: 0.074028; batch adversarial loss: 0.522576\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038818; batch adversarial loss: 0.498415\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049885; batch adversarial loss: 0.475677\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066640; batch adversarial loss: 0.395000\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069418; batch adversarial loss: 0.525796\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051368; batch adversarial loss: 0.468432\n",
      "epoch 112; iter: 0; batch classifier loss: 0.050983; batch adversarial loss: 0.397450\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040579; batch adversarial loss: 0.486332\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052071; batch adversarial loss: 0.336831\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046567; batch adversarial loss: 0.464843\n",
      "epoch 116; iter: 0; batch classifier loss: 0.075989; batch adversarial loss: 0.465606\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047063; batch adversarial loss: 0.415030\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041892; batch adversarial loss: 0.456952\n",
      "epoch 119; iter: 0; batch classifier loss: 0.024212; batch adversarial loss: 0.468709\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043096; batch adversarial loss: 0.535599\n",
      "epoch 121; iter: 0; batch classifier loss: 0.022225; batch adversarial loss: 0.383063\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038218; batch adversarial loss: 0.461189\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050529; batch adversarial loss: 0.563419\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036285; batch adversarial loss: 0.418957\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035285; batch adversarial loss: 0.429941\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032979; batch adversarial loss: 0.386138\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028824; batch adversarial loss: 0.481857\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039803; batch adversarial loss: 0.489360\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028638; batch adversarial loss: 0.491416\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032746; batch adversarial loss: 0.507587\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023346; batch adversarial loss: 0.544725\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025561; batch adversarial loss: 0.539569\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030116; batch adversarial loss: 0.605109\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034552; batch adversarial loss: 0.442819\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027036; batch adversarial loss: 0.414090\n",
      "epoch 136; iter: 0; batch classifier loss: 0.068817; batch adversarial loss: 0.415287\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044869; batch adversarial loss: 0.420827\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025892; batch adversarial loss: 0.430682\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020632; batch adversarial loss: 0.443975\n",
      "epoch 140; iter: 0; batch classifier loss: 0.012279; batch adversarial loss: 0.507689\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044190; batch adversarial loss: 0.424990\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021008; batch adversarial loss: 0.473710\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037840; batch adversarial loss: 0.465951\n",
      "epoch 144; iter: 0; batch classifier loss: 0.055067; batch adversarial loss: 0.439362\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015565; batch adversarial loss: 0.471872\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016987; batch adversarial loss: 0.512301\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031320; batch adversarial loss: 0.476206\n",
      "epoch 148; iter: 0; batch classifier loss: 0.053122; batch adversarial loss: 0.597176\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020929; batch adversarial loss: 0.431187\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015288; batch adversarial loss: 0.524293\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022895; batch adversarial loss: 0.504421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.023285; batch adversarial loss: 0.479718\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027258; batch adversarial loss: 0.469159\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020875; batch adversarial loss: 0.448528\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027896; batch adversarial loss: 0.515132\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029907; batch adversarial loss: 0.526703\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029007; batch adversarial loss: 0.447604\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015605; batch adversarial loss: 0.448250\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028336; batch adversarial loss: 0.427185\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015703; batch adversarial loss: 0.436818\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024451; batch adversarial loss: 0.439449\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037167; batch adversarial loss: 0.524580\n",
      "epoch 163; iter: 0; batch classifier loss: 0.043791; batch adversarial loss: 0.488216\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018834; batch adversarial loss: 0.460695\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022158; batch adversarial loss: 0.515006\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010627; batch adversarial loss: 0.554913\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021210; batch adversarial loss: 0.383167\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035013; batch adversarial loss: 0.454730\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020794; batch adversarial loss: 0.385436\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039185; batch adversarial loss: 0.469630\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018995; batch adversarial loss: 0.439715\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014572; batch adversarial loss: 0.526234\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036389; batch adversarial loss: 0.544760\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012181; batch adversarial loss: 0.531696\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026720; batch adversarial loss: 0.462644\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031432; batch adversarial loss: 0.493827\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029320; batch adversarial loss: 0.499827\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020474; batch adversarial loss: 0.421560\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014492; batch adversarial loss: 0.405968\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016809; batch adversarial loss: 0.385068\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023942; batch adversarial loss: 0.544725\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014429; batch adversarial loss: 0.533511\n",
      "epoch 183; iter: 0; batch classifier loss: 0.050227; batch adversarial loss: 0.439285\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007164; batch adversarial loss: 0.545195\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021812; batch adversarial loss: 0.453840\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041626; batch adversarial loss: 0.427558\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006847; batch adversarial loss: 0.499270\n",
      "epoch 188; iter: 0; batch classifier loss: 0.065896; batch adversarial loss: 0.453732\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010495; batch adversarial loss: 0.436638\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014451; batch adversarial loss: 0.475884\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037005; batch adversarial loss: 0.493313\n",
      "epoch 192; iter: 0; batch classifier loss: 0.054078; batch adversarial loss: 0.451714\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008961; batch adversarial loss: 0.446094\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032978; batch adversarial loss: 0.414168\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027518; batch adversarial loss: 0.408657\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018414; batch adversarial loss: 0.520416\n",
      "epoch 197; iter: 0; batch classifier loss: 0.050289; batch adversarial loss: 0.481720\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039692; batch adversarial loss: 0.471599\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019044; batch adversarial loss: 0.467647\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686019; batch adversarial loss: 0.869552\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583518; batch adversarial loss: 0.892807\n",
      "epoch 2; iter: 0; batch classifier loss: 0.811741; batch adversarial loss: 0.898628\n",
      "epoch 3; iter: 0; batch classifier loss: 0.779790; batch adversarial loss: 0.808998\n",
      "epoch 4; iter: 0; batch classifier loss: 0.982084; batch adversarial loss: 0.740501\n",
      "epoch 5; iter: 0; batch classifier loss: 1.068519; batch adversarial loss: 0.679569\n",
      "epoch 6; iter: 0; batch classifier loss: 0.796374; batch adversarial loss: 0.603949\n",
      "epoch 7; iter: 0; batch classifier loss: 0.509669; batch adversarial loss: 0.567351\n",
      "epoch 8; iter: 0; batch classifier loss: 0.441964; batch adversarial loss: 0.543283\n",
      "epoch 9; iter: 0; batch classifier loss: 0.369756; batch adversarial loss: 0.540197\n",
      "epoch 10; iter: 0; batch classifier loss: 0.393649; batch adversarial loss: 0.540127\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362211; batch adversarial loss: 0.551772\n",
      "epoch 12; iter: 0; batch classifier loss: 0.318997; batch adversarial loss: 0.535300\n",
      "epoch 13; iter: 0; batch classifier loss: 0.358165; batch adversarial loss: 0.512530\n",
      "epoch 14; iter: 0; batch classifier loss: 0.363992; batch adversarial loss: 0.547281\n",
      "epoch 15; iter: 0; batch classifier loss: 0.368441; batch adversarial loss: 0.532173\n",
      "epoch 16; iter: 0; batch classifier loss: 0.306332; batch adversarial loss: 0.512785\n",
      "epoch 17; iter: 0; batch classifier loss: 0.300771; batch adversarial loss: 0.508893\n",
      "epoch 18; iter: 0; batch classifier loss: 0.333744; batch adversarial loss: 0.551397\n",
      "epoch 19; iter: 0; batch classifier loss: 0.347519; batch adversarial loss: 0.454298\n",
      "epoch 20; iter: 0; batch classifier loss: 0.352059; batch adversarial loss: 0.497270\n",
      "epoch 21; iter: 0; batch classifier loss: 0.363589; batch adversarial loss: 0.467078\n",
      "epoch 22; iter: 0; batch classifier loss: 0.301405; batch adversarial loss: 0.534262\n",
      "epoch 23; iter: 0; batch classifier loss: 0.278049; batch adversarial loss: 0.447164\n",
      "epoch 24; iter: 0; batch classifier loss: 0.258485; batch adversarial loss: 0.484742\n",
      "epoch 25; iter: 0; batch classifier loss: 0.283840; batch adversarial loss: 0.468660\n",
      "epoch 26; iter: 0; batch classifier loss: 0.345190; batch adversarial loss: 0.485390\n",
      "epoch 27; iter: 0; batch classifier loss: 0.282625; batch adversarial loss: 0.451054\n",
      "epoch 28; iter: 0; batch classifier loss: 0.225934; batch adversarial loss: 0.440585\n",
      "epoch 29; iter: 0; batch classifier loss: 0.257085; batch adversarial loss: 0.389593\n",
      "epoch 30; iter: 0; batch classifier loss: 0.326358; batch adversarial loss: 0.473465\n",
      "epoch 31; iter: 0; batch classifier loss: 0.233448; batch adversarial loss: 0.523969\n",
      "epoch 32; iter: 0; batch classifier loss: 0.208722; batch adversarial loss: 0.463395\n",
      "epoch 33; iter: 0; batch classifier loss: 0.252439; batch adversarial loss: 0.426279\n",
      "epoch 34; iter: 0; batch classifier loss: 0.188554; batch adversarial loss: 0.528057\n",
      "epoch 35; iter: 0; batch classifier loss: 0.295098; batch adversarial loss: 0.416539\n",
      "epoch 36; iter: 0; batch classifier loss: 0.186613; batch adversarial loss: 0.494371\n",
      "epoch 37; iter: 0; batch classifier loss: 0.260172; batch adversarial loss: 0.387218\n",
      "epoch 38; iter: 0; batch classifier loss: 0.284827; batch adversarial loss: 0.478862\n",
      "epoch 39; iter: 0; batch classifier loss: 0.206272; batch adversarial loss: 0.464442\n",
      "epoch 40; iter: 0; batch classifier loss: 0.251866; batch adversarial loss: 0.459454\n",
      "epoch 41; iter: 0; batch classifier loss: 0.215933; batch adversarial loss: 0.521121\n",
      "epoch 42; iter: 0; batch classifier loss: 0.221602; batch adversarial loss: 0.460757\n",
      "epoch 43; iter: 0; batch classifier loss: 0.225040; batch adversarial loss: 0.399969\n",
      "epoch 44; iter: 0; batch classifier loss: 0.164214; batch adversarial loss: 0.429734\n",
      "epoch 45; iter: 0; batch classifier loss: 0.200969; batch adversarial loss: 0.491411\n",
      "epoch 46; iter: 0; batch classifier loss: 0.215826; batch adversarial loss: 0.411234\n",
      "epoch 47; iter: 0; batch classifier loss: 0.236004; batch adversarial loss: 0.499982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.216636; batch adversarial loss: 0.529937\n",
      "epoch 49; iter: 0; batch classifier loss: 0.153793; batch adversarial loss: 0.453102\n",
      "epoch 50; iter: 0; batch classifier loss: 0.178407; batch adversarial loss: 0.421430\n",
      "epoch 51; iter: 0; batch classifier loss: 0.125390; batch adversarial loss: 0.423748\n",
      "epoch 52; iter: 0; batch classifier loss: 0.241217; batch adversarial loss: 0.528837\n",
      "epoch 53; iter: 0; batch classifier loss: 0.172125; batch adversarial loss: 0.549745\n",
      "epoch 54; iter: 0; batch classifier loss: 0.213274; batch adversarial loss: 0.484746\n",
      "epoch 55; iter: 0; batch classifier loss: 0.157793; batch adversarial loss: 0.413565\n",
      "epoch 56; iter: 0; batch classifier loss: 0.157552; batch adversarial loss: 0.487379\n",
      "epoch 57; iter: 0; batch classifier loss: 0.168779; batch adversarial loss: 0.399113\n",
      "epoch 58; iter: 0; batch classifier loss: 0.209245; batch adversarial loss: 0.455405\n",
      "epoch 59; iter: 0; batch classifier loss: 0.228565; batch adversarial loss: 0.466794\n",
      "epoch 60; iter: 0; batch classifier loss: 0.182379; batch adversarial loss: 0.431755\n",
      "epoch 61; iter: 0; batch classifier loss: 0.252667; batch adversarial loss: 0.448106\n",
      "epoch 62; iter: 0; batch classifier loss: 0.215707; batch adversarial loss: 0.536565\n",
      "epoch 63; iter: 0; batch classifier loss: 0.123516; batch adversarial loss: 0.487211\n",
      "epoch 64; iter: 0; batch classifier loss: 0.174457; batch adversarial loss: 0.477961\n",
      "epoch 65; iter: 0; batch classifier loss: 0.207294; batch adversarial loss: 0.444020\n",
      "epoch 66; iter: 0; batch classifier loss: 0.194591; batch adversarial loss: 0.448995\n",
      "epoch 67; iter: 0; batch classifier loss: 0.227643; batch adversarial loss: 0.548542\n",
      "epoch 68; iter: 0; batch classifier loss: 0.210054; batch adversarial loss: 0.445234\n",
      "epoch 69; iter: 0; batch classifier loss: 0.236123; batch adversarial loss: 0.437325\n",
      "epoch 70; iter: 0; batch classifier loss: 0.175665; batch adversarial loss: 0.458561\n",
      "epoch 71; iter: 0; batch classifier loss: 0.200991; batch adversarial loss: 0.482620\n",
      "epoch 72; iter: 0; batch classifier loss: 0.218982; batch adversarial loss: 0.425799\n",
      "epoch 73; iter: 0; batch classifier loss: 0.156322; batch adversarial loss: 0.514688\n",
      "epoch 74; iter: 0; batch classifier loss: 0.150976; batch adversarial loss: 0.488569\n",
      "epoch 75; iter: 0; batch classifier loss: 0.158915; batch adversarial loss: 0.448867\n",
      "epoch 76; iter: 0; batch classifier loss: 0.158416; batch adversarial loss: 0.384407\n",
      "epoch 77; iter: 0; batch classifier loss: 0.202264; batch adversarial loss: 0.437622\n",
      "epoch 78; iter: 0; batch classifier loss: 0.126084; batch adversarial loss: 0.439085\n",
      "epoch 79; iter: 0; batch classifier loss: 0.137538; batch adversarial loss: 0.564710\n",
      "epoch 80; iter: 0; batch classifier loss: 0.129602; batch adversarial loss: 0.456226\n",
      "epoch 81; iter: 0; batch classifier loss: 0.164595; batch adversarial loss: 0.456360\n",
      "epoch 82; iter: 0; batch classifier loss: 0.125981; batch adversarial loss: 0.414795\n",
      "epoch 83; iter: 0; batch classifier loss: 0.166102; batch adversarial loss: 0.399812\n",
      "epoch 84; iter: 0; batch classifier loss: 0.116720; batch adversarial loss: 0.515521\n",
      "epoch 85; iter: 0; batch classifier loss: 0.181616; batch adversarial loss: 0.381965\n",
      "epoch 86; iter: 0; batch classifier loss: 0.128485; batch adversarial loss: 0.426715\n",
      "epoch 87; iter: 0; batch classifier loss: 0.142752; batch adversarial loss: 0.426086\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088980; batch adversarial loss: 0.582704\n",
      "epoch 89; iter: 0; batch classifier loss: 0.102777; batch adversarial loss: 0.524855\n",
      "epoch 90; iter: 0; batch classifier loss: 0.133623; batch adversarial loss: 0.528944\n",
      "epoch 91; iter: 0; batch classifier loss: 0.162639; batch adversarial loss: 0.560048\n",
      "epoch 92; iter: 0; batch classifier loss: 0.143881; batch adversarial loss: 0.395460\n",
      "epoch 93; iter: 0; batch classifier loss: 0.166470; batch adversarial loss: 0.405992\n",
      "epoch 94; iter: 0; batch classifier loss: 0.148688; batch adversarial loss: 0.424009\n",
      "epoch 95; iter: 0; batch classifier loss: 0.123275; batch adversarial loss: 0.490016\n",
      "epoch 96; iter: 0; batch classifier loss: 0.072280; batch adversarial loss: 0.498323\n",
      "epoch 97; iter: 0; batch classifier loss: 0.097035; batch adversarial loss: 0.468463\n",
      "epoch 98; iter: 0; batch classifier loss: 0.090787; batch adversarial loss: 0.496743\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058375; batch adversarial loss: 0.443946\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048880; batch adversarial loss: 0.545687\n",
      "epoch 101; iter: 0; batch classifier loss: 0.067700; batch adversarial loss: 0.468733\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067815; batch adversarial loss: 0.522121\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063269; batch adversarial loss: 0.518164\n",
      "epoch 104; iter: 0; batch classifier loss: 0.081218; batch adversarial loss: 0.428831\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053419; batch adversarial loss: 0.489014\n",
      "epoch 106; iter: 0; batch classifier loss: 0.026872; batch adversarial loss: 0.480763\n",
      "epoch 107; iter: 0; batch classifier loss: 0.102636; batch adversarial loss: 0.399175\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067778; batch adversarial loss: 0.553314\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039213; batch adversarial loss: 0.460243\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056178; batch adversarial loss: 0.476532\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039571; batch adversarial loss: 0.543803\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035738; batch adversarial loss: 0.499904\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056269; batch adversarial loss: 0.355533\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036091; batch adversarial loss: 0.539208\n",
      "epoch 115; iter: 0; batch classifier loss: 0.026563; batch adversarial loss: 0.453398\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033510; batch adversarial loss: 0.469780\n",
      "epoch 117; iter: 0; batch classifier loss: 0.069186; batch adversarial loss: 0.386266\n",
      "epoch 118; iter: 0; batch classifier loss: 0.034980; batch adversarial loss: 0.527359\n",
      "epoch 119; iter: 0; batch classifier loss: 0.058547; batch adversarial loss: 0.436338\n",
      "epoch 120; iter: 0; batch classifier loss: 0.065506; batch adversarial loss: 0.495108\n",
      "epoch 121; iter: 0; batch classifier loss: 0.016279; batch adversarial loss: 0.413346\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037894; batch adversarial loss: 0.460254\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014329; batch adversarial loss: 0.416860\n",
      "epoch 124; iter: 0; batch classifier loss: 0.016264; batch adversarial loss: 0.442180\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018667; batch adversarial loss: 0.439609\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049924; batch adversarial loss: 0.527102\n",
      "epoch 127; iter: 0; batch classifier loss: 0.011986; batch adversarial loss: 0.422852\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054392; batch adversarial loss: 0.422283\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030048; batch adversarial loss: 0.479207\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016546; batch adversarial loss: 0.443823\n",
      "epoch 131; iter: 0; batch classifier loss: 0.008482; batch adversarial loss: 0.413035\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019635; batch adversarial loss: 0.316631\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028497; batch adversarial loss: 0.403319\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028092; batch adversarial loss: 0.494070\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041240; batch adversarial loss: 0.436227\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043640; batch adversarial loss: 0.521533\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018260; batch adversarial loss: 0.481434\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030075; batch adversarial loss: 0.416517\n",
      "epoch 139; iter: 0; batch classifier loss: 0.011332; batch adversarial loss: 0.537897\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020495; batch adversarial loss: 0.477762\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021919; batch adversarial loss: 0.457157\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023471; batch adversarial loss: 0.524451\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010768; batch adversarial loss: 0.446744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.031123; batch adversarial loss: 0.532414\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013529; batch adversarial loss: 0.406004\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011321; batch adversarial loss: 0.384588\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025996; batch adversarial loss: 0.552190\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021934; batch adversarial loss: 0.431288\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019197; batch adversarial loss: 0.424731\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013256; batch adversarial loss: 0.467940\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010341; batch adversarial loss: 0.459375\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011276; batch adversarial loss: 0.498431\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021091; batch adversarial loss: 0.552030\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020082; batch adversarial loss: 0.373650\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013492; batch adversarial loss: 0.462429\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034293; batch adversarial loss: 0.466485\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017517; batch adversarial loss: 0.399723\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018461; batch adversarial loss: 0.440893\n",
      "epoch 159; iter: 0; batch classifier loss: 0.006636; batch adversarial loss: 0.494599\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013214; batch adversarial loss: 0.451737\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014157; batch adversarial loss: 0.343323\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029868; batch adversarial loss: 0.419233\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007391; batch adversarial loss: 0.427413\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027727; batch adversarial loss: 0.520143\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019256; batch adversarial loss: 0.495213\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012185; batch adversarial loss: 0.443257\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014974; batch adversarial loss: 0.349817\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013800; batch adversarial loss: 0.419191\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010629; batch adversarial loss: 0.456710\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014808; batch adversarial loss: 0.426369\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017566; batch adversarial loss: 0.395975\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015876; batch adversarial loss: 0.422000\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018980; batch adversarial loss: 0.422591\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010022; batch adversarial loss: 0.393535\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012505; batch adversarial loss: 0.498928\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013528; batch adversarial loss: 0.541660\n",
      "epoch 177; iter: 0; batch classifier loss: 0.004514; batch adversarial loss: 0.419437\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015589; batch adversarial loss: 0.493902\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017099; batch adversarial loss: 0.404351\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009032; batch adversarial loss: 0.400673\n",
      "epoch 181; iter: 0; batch classifier loss: 0.059756; batch adversarial loss: 0.444370\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038603; batch adversarial loss: 0.487114\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014844; batch adversarial loss: 0.507443\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009284; batch adversarial loss: 0.460161\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021516; batch adversarial loss: 0.422425\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022869; batch adversarial loss: 0.462250\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013805; batch adversarial loss: 0.445010\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006028; batch adversarial loss: 0.509442\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004280; batch adversarial loss: 0.401065\n",
      "epoch 190; iter: 0; batch classifier loss: 0.003231; batch adversarial loss: 0.474423\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009817; batch adversarial loss: 0.368827\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024093; batch adversarial loss: 0.379202\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010765; batch adversarial loss: 0.418719\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004346; batch adversarial loss: 0.545569\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015425; batch adversarial loss: 0.374560\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011419; batch adversarial loss: 0.401352\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010683; batch adversarial loss: 0.509212\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012338; batch adversarial loss: 0.535548\n",
      "epoch 199; iter: 0; batch classifier loss: 0.003654; batch adversarial loss: 0.431475\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701932; batch adversarial loss: 0.655957\n",
      "epoch 1; iter: 0; batch classifier loss: 0.473145; batch adversarial loss: 0.678993\n",
      "epoch 2; iter: 0; batch classifier loss: 0.370892; batch adversarial loss: 0.606195\n",
      "epoch 3; iter: 0; batch classifier loss: 0.388716; batch adversarial loss: 0.606697\n",
      "epoch 4; iter: 0; batch classifier loss: 0.359164; batch adversarial loss: 0.570515\n",
      "epoch 5; iter: 0; batch classifier loss: 0.322663; batch adversarial loss: 0.526188\n",
      "epoch 6; iter: 0; batch classifier loss: 0.351897; batch adversarial loss: 0.534564\n",
      "epoch 7; iter: 0; batch classifier loss: 0.242876; batch adversarial loss: 0.489568\n",
      "epoch 8; iter: 0; batch classifier loss: 0.266984; batch adversarial loss: 0.524709\n",
      "epoch 9; iter: 0; batch classifier loss: 0.247115; batch adversarial loss: 0.471346\n",
      "epoch 10; iter: 0; batch classifier loss: 0.274112; batch adversarial loss: 0.468993\n",
      "epoch 11; iter: 0; batch classifier loss: 0.231060; batch adversarial loss: 0.439552\n",
      "epoch 12; iter: 0; batch classifier loss: 0.268578; batch adversarial loss: 0.459746\n",
      "epoch 13; iter: 0; batch classifier loss: 0.225964; batch adversarial loss: 0.457650\n",
      "epoch 14; iter: 0; batch classifier loss: 0.195609; batch adversarial loss: 0.452709\n",
      "epoch 15; iter: 0; batch classifier loss: 0.183885; batch adversarial loss: 0.421653\n",
      "epoch 16; iter: 0; batch classifier loss: 0.192406; batch adversarial loss: 0.422512\n",
      "epoch 17; iter: 0; batch classifier loss: 0.184464; batch adversarial loss: 0.428437\n",
      "epoch 18; iter: 0; batch classifier loss: 0.156257; batch adversarial loss: 0.517943\n",
      "epoch 19; iter: 0; batch classifier loss: 0.184097; batch adversarial loss: 0.408384\n",
      "epoch 20; iter: 0; batch classifier loss: 0.133955; batch adversarial loss: 0.457053\n",
      "epoch 21; iter: 0; batch classifier loss: 0.114183; batch adversarial loss: 0.478297\n",
      "epoch 22; iter: 0; batch classifier loss: 0.199215; batch adversarial loss: 0.596151\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168448; batch adversarial loss: 0.388898\n",
      "epoch 24; iter: 0; batch classifier loss: 0.141644; batch adversarial loss: 0.522931\n",
      "epoch 25; iter: 0; batch classifier loss: 0.162126; batch adversarial loss: 0.543820\n",
      "epoch 26; iter: 0; batch classifier loss: 0.226620; batch adversarial loss: 0.562168\n",
      "epoch 27; iter: 0; batch classifier loss: 0.132982; batch adversarial loss: 0.487029\n",
      "epoch 28; iter: 0; batch classifier loss: 0.208062; batch adversarial loss: 0.490090\n",
      "epoch 29; iter: 0; batch classifier loss: 0.146848; batch adversarial loss: 0.445926\n",
      "epoch 30; iter: 0; batch classifier loss: 0.165863; batch adversarial loss: 0.397414\n",
      "epoch 31; iter: 0; batch classifier loss: 0.219556; batch adversarial loss: 0.514656\n",
      "epoch 32; iter: 0; batch classifier loss: 0.145057; batch adversarial loss: 0.397426\n",
      "epoch 33; iter: 0; batch classifier loss: 0.233120; batch adversarial loss: 0.461468\n",
      "epoch 34; iter: 0; batch classifier loss: 0.198360; batch adversarial loss: 0.449958\n",
      "epoch 35; iter: 0; batch classifier loss: 0.223648; batch adversarial loss: 0.493559\n",
      "epoch 36; iter: 0; batch classifier loss: 0.214113; batch adversarial loss: 0.476546\n",
      "epoch 37; iter: 0; batch classifier loss: 0.215672; batch adversarial loss: 0.360493\n",
      "epoch 38; iter: 0; batch classifier loss: 0.182202; batch adversarial loss: 0.488470\n",
      "epoch 39; iter: 0; batch classifier loss: 0.163354; batch adversarial loss: 0.562249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.137729; batch adversarial loss: 0.391979\n",
      "epoch 41; iter: 0; batch classifier loss: 0.103640; batch adversarial loss: 0.416579\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096553; batch adversarial loss: 0.402541\n",
      "epoch 43; iter: 0; batch classifier loss: 0.113968; batch adversarial loss: 0.448414\n",
      "epoch 44; iter: 0; batch classifier loss: 0.070142; batch adversarial loss: 0.493691\n",
      "epoch 45; iter: 0; batch classifier loss: 0.067627; batch adversarial loss: 0.474016\n",
      "epoch 46; iter: 0; batch classifier loss: 0.067033; batch adversarial loss: 0.549376\n",
      "epoch 47; iter: 0; batch classifier loss: 0.089546; batch adversarial loss: 0.423108\n",
      "epoch 48; iter: 0; batch classifier loss: 0.063120; batch adversarial loss: 0.575052\n",
      "epoch 49; iter: 0; batch classifier loss: 0.066995; batch adversarial loss: 0.531773\n",
      "epoch 50; iter: 0; batch classifier loss: 0.067462; batch adversarial loss: 0.535769\n",
      "epoch 51; iter: 0; batch classifier loss: 0.068749; batch adversarial loss: 0.441196\n",
      "epoch 52; iter: 0; batch classifier loss: 0.134149; batch adversarial loss: 0.381690\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084588; batch adversarial loss: 0.410540\n",
      "epoch 54; iter: 0; batch classifier loss: 0.070789; batch adversarial loss: 0.477643\n",
      "epoch 55; iter: 0; batch classifier loss: 0.093306; batch adversarial loss: 0.398290\n",
      "epoch 56; iter: 0; batch classifier loss: 0.059053; batch adversarial loss: 0.395375\n",
      "epoch 57; iter: 0; batch classifier loss: 0.031327; batch adversarial loss: 0.411363\n",
      "epoch 58; iter: 0; batch classifier loss: 0.089306; batch adversarial loss: 0.496035\n",
      "epoch 59; iter: 0; batch classifier loss: 0.094030; batch adversarial loss: 0.346073\n",
      "epoch 60; iter: 0; batch classifier loss: 0.050916; batch adversarial loss: 0.427465\n",
      "epoch 61; iter: 0; batch classifier loss: 0.070195; batch adversarial loss: 0.389416\n",
      "epoch 62; iter: 0; batch classifier loss: 0.061195; batch adversarial loss: 0.481892\n",
      "epoch 63; iter: 0; batch classifier loss: 0.052612; batch adversarial loss: 0.390882\n",
      "epoch 64; iter: 0; batch classifier loss: 0.096969; batch adversarial loss: 0.483061\n",
      "epoch 65; iter: 0; batch classifier loss: 0.051227; batch adversarial loss: 0.486098\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096848; batch adversarial loss: 0.455050\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082012; batch adversarial loss: 0.369908\n",
      "epoch 68; iter: 0; batch classifier loss: 0.040194; batch adversarial loss: 0.431894\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065120; batch adversarial loss: 0.472169\n",
      "epoch 70; iter: 0; batch classifier loss: 0.087823; batch adversarial loss: 0.367762\n",
      "epoch 71; iter: 0; batch classifier loss: 0.052963; batch adversarial loss: 0.519490\n",
      "epoch 72; iter: 0; batch classifier loss: 0.056538; batch adversarial loss: 0.377999\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076488; batch adversarial loss: 0.527507\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053232; batch adversarial loss: 0.502788\n",
      "epoch 75; iter: 0; batch classifier loss: 0.057974; batch adversarial loss: 0.443100\n",
      "epoch 76; iter: 0; batch classifier loss: 0.062492; batch adversarial loss: 0.481799\n",
      "epoch 77; iter: 0; batch classifier loss: 0.058325; batch adversarial loss: 0.426845\n",
      "epoch 78; iter: 0; batch classifier loss: 0.095464; batch adversarial loss: 0.400126\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060129; batch adversarial loss: 0.461211\n",
      "epoch 80; iter: 0; batch classifier loss: 0.059168; batch adversarial loss: 0.399286\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050687; batch adversarial loss: 0.499129\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046717; batch adversarial loss: 0.453012\n",
      "epoch 83; iter: 0; batch classifier loss: 0.069009; batch adversarial loss: 0.347195\n",
      "epoch 84; iter: 0; batch classifier loss: 0.044058; batch adversarial loss: 0.424479\n",
      "epoch 85; iter: 0; batch classifier loss: 0.091043; batch adversarial loss: 0.430912\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046038; batch adversarial loss: 0.477369\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062081; batch adversarial loss: 0.454666\n",
      "epoch 88; iter: 0; batch classifier loss: 0.044655; batch adversarial loss: 0.450323\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060456; batch adversarial loss: 0.469533\n",
      "epoch 90; iter: 0; batch classifier loss: 0.037693; batch adversarial loss: 0.513116\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068707; batch adversarial loss: 0.443620\n",
      "epoch 92; iter: 0; batch classifier loss: 0.035261; batch adversarial loss: 0.497931\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046728; batch adversarial loss: 0.458913\n",
      "epoch 94; iter: 0; batch classifier loss: 0.105790; batch adversarial loss: 0.478973\n",
      "epoch 95; iter: 0; batch classifier loss: 0.028230; batch adversarial loss: 0.422828\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049609; batch adversarial loss: 0.456341\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054330; batch adversarial loss: 0.432171\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046521; batch adversarial loss: 0.363090\n",
      "epoch 99; iter: 0; batch classifier loss: 0.031189; batch adversarial loss: 0.417952\n",
      "epoch 100; iter: 0; batch classifier loss: 0.020992; batch adversarial loss: 0.448505\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062287; batch adversarial loss: 0.533368\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048537; batch adversarial loss: 0.437621\n",
      "epoch 103; iter: 0; batch classifier loss: 0.075740; batch adversarial loss: 0.532315\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073568; batch adversarial loss: 0.470837\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041309; batch adversarial loss: 0.532713\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042851; batch adversarial loss: 0.463542\n",
      "epoch 107; iter: 0; batch classifier loss: 0.073383; batch adversarial loss: 0.369219\n",
      "epoch 108; iter: 0; batch classifier loss: 0.072268; batch adversarial loss: 0.396573\n",
      "epoch 109; iter: 0; batch classifier loss: 0.080925; batch adversarial loss: 0.401267\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037019; batch adversarial loss: 0.446170\n",
      "epoch 111; iter: 0; batch classifier loss: 0.018042; batch adversarial loss: 0.419989\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044505; batch adversarial loss: 0.445529\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044820; batch adversarial loss: 0.447041\n",
      "epoch 114; iter: 0; batch classifier loss: 0.023423; batch adversarial loss: 0.481350\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021680; batch adversarial loss: 0.465618\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040649; batch adversarial loss: 0.439384\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028961; batch adversarial loss: 0.346565\n",
      "epoch 118; iter: 0; batch classifier loss: 0.071624; batch adversarial loss: 0.540947\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033946; batch adversarial loss: 0.346573\n",
      "epoch 120; iter: 0; batch classifier loss: 0.018987; batch adversarial loss: 0.448524\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034606; batch adversarial loss: 0.502795\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040988; batch adversarial loss: 0.425183\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033368; batch adversarial loss: 0.462430\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032856; batch adversarial loss: 0.444243\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039697; batch adversarial loss: 0.468566\n",
      "epoch 126; iter: 0; batch classifier loss: 0.065851; batch adversarial loss: 0.415366\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036555; batch adversarial loss: 0.382668\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038235; batch adversarial loss: 0.354307\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036026; batch adversarial loss: 0.517043\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043018; batch adversarial loss: 0.540811\n",
      "epoch 131; iter: 0; batch classifier loss: 0.056009; batch adversarial loss: 0.472602\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015140; batch adversarial loss: 0.515584\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028749; batch adversarial loss: 0.404492\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035771; batch adversarial loss: 0.526047\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046287; batch adversarial loss: 0.488953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.046478; batch adversarial loss: 0.415700\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026322; batch adversarial loss: 0.421737\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024595; batch adversarial loss: 0.383192\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018771; batch adversarial loss: 0.447199\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021934; batch adversarial loss: 0.486595\n",
      "epoch 141; iter: 0; batch classifier loss: 0.054598; batch adversarial loss: 0.402248\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033009; batch adversarial loss: 0.464800\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027934; batch adversarial loss: 0.412005\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017520; batch adversarial loss: 0.380982\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029695; batch adversarial loss: 0.485329\n",
      "epoch 146; iter: 0; batch classifier loss: 0.058821; batch adversarial loss: 0.376233\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044121; batch adversarial loss: 0.439349\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040161; batch adversarial loss: 0.491594\n",
      "epoch 149; iter: 0; batch classifier loss: 0.041982; batch adversarial loss: 0.442759\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023723; batch adversarial loss: 0.429898\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021283; batch adversarial loss: 0.430314\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043458; batch adversarial loss: 0.452393\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018254; batch adversarial loss: 0.415170\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038782; batch adversarial loss: 0.387765\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028193; batch adversarial loss: 0.431234\n",
      "epoch 156; iter: 0; batch classifier loss: 0.009893; batch adversarial loss: 0.416488\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032429; batch adversarial loss: 0.425486\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016624; batch adversarial loss: 0.379913\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038055; batch adversarial loss: 0.455462\n",
      "epoch 160; iter: 0; batch classifier loss: 0.011246; batch adversarial loss: 0.491706\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042541; batch adversarial loss: 0.518640\n",
      "epoch 162; iter: 0; batch classifier loss: 0.044425; batch adversarial loss: 0.411929\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021347; batch adversarial loss: 0.400427\n",
      "epoch 164; iter: 0; batch classifier loss: 0.008802; batch adversarial loss: 0.484483\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031787; batch adversarial loss: 0.492474\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020695; batch adversarial loss: 0.363621\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042009; batch adversarial loss: 0.490582\n",
      "epoch 168; iter: 0; batch classifier loss: 0.053961; batch adversarial loss: 0.495324\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031217; batch adversarial loss: 0.470451\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027594; batch adversarial loss: 0.452792\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021337; batch adversarial loss: 0.379647\n",
      "epoch 172; iter: 0; batch classifier loss: 0.042114; batch adversarial loss: 0.388425\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014204; batch adversarial loss: 0.468095\n",
      "epoch 174; iter: 0; batch classifier loss: 0.034130; batch adversarial loss: 0.408158\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033025; batch adversarial loss: 0.492140\n",
      "epoch 176; iter: 0; batch classifier loss: 0.042955; batch adversarial loss: 0.370688\n",
      "epoch 177; iter: 0; batch classifier loss: 0.035724; batch adversarial loss: 0.469030\n",
      "epoch 178; iter: 0; batch classifier loss: 0.049341; batch adversarial loss: 0.397012\n",
      "epoch 179; iter: 0; batch classifier loss: 0.048834; batch adversarial loss: 0.426777\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017015; batch adversarial loss: 0.398847\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038191; batch adversarial loss: 0.504982\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022467; batch adversarial loss: 0.420740\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025191; batch adversarial loss: 0.407128\n",
      "epoch 184; iter: 0; batch classifier loss: 0.064414; batch adversarial loss: 0.460481\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035751; batch adversarial loss: 0.417898\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007545; batch adversarial loss: 0.434822\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021288; batch adversarial loss: 0.371925\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007214; batch adversarial loss: 0.453211\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031347; batch adversarial loss: 0.569377\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024926; batch adversarial loss: 0.469732\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009282; batch adversarial loss: 0.441357\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019103; batch adversarial loss: 0.507478\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023369; batch adversarial loss: 0.387506\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009092; batch adversarial loss: 0.440900\n",
      "epoch 195; iter: 0; batch classifier loss: 0.047181; batch adversarial loss: 0.441878\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009770; batch adversarial loss: 0.426388\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012254; batch adversarial loss: 0.410044\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008243; batch adversarial loss: 0.440564\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024024; batch adversarial loss: 0.434939\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709550; batch adversarial loss: 0.647378\n",
      "epoch 1; iter: 0; batch classifier loss: 0.463253; batch adversarial loss: 0.618597\n",
      "epoch 2; iter: 0; batch classifier loss: 0.341253; batch adversarial loss: 0.624301\n",
      "epoch 3; iter: 0; batch classifier loss: 0.384337; batch adversarial loss: 0.579095\n",
      "epoch 4; iter: 0; batch classifier loss: 0.324090; batch adversarial loss: 0.549265\n",
      "epoch 5; iter: 0; batch classifier loss: 0.273970; batch adversarial loss: 0.532767\n",
      "epoch 6; iter: 0; batch classifier loss: 0.330522; batch adversarial loss: 0.523432\n",
      "epoch 7; iter: 0; batch classifier loss: 0.265143; batch adversarial loss: 0.522209\n",
      "epoch 8; iter: 0; batch classifier loss: 0.251817; batch adversarial loss: 0.508870\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273739; batch adversarial loss: 0.488598\n",
      "epoch 10; iter: 0; batch classifier loss: 0.244661; batch adversarial loss: 0.498120\n",
      "epoch 11; iter: 0; batch classifier loss: 0.228154; batch adversarial loss: 0.505277\n",
      "epoch 12; iter: 0; batch classifier loss: 0.164010; batch adversarial loss: 0.497602\n",
      "epoch 13; iter: 0; batch classifier loss: 0.212834; batch adversarial loss: 0.503253\n",
      "epoch 14; iter: 0; batch classifier loss: 0.187713; batch adversarial loss: 0.474427\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260405; batch adversarial loss: 0.477776\n",
      "epoch 16; iter: 0; batch classifier loss: 0.187653; batch adversarial loss: 0.540303\n",
      "epoch 17; iter: 0; batch classifier loss: 0.220300; batch adversarial loss: 0.529890\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268289; batch adversarial loss: 0.531796\n",
      "epoch 19; iter: 0; batch classifier loss: 0.231329; batch adversarial loss: 0.459257\n",
      "epoch 20; iter: 0; batch classifier loss: 0.211303; batch adversarial loss: 0.564798\n",
      "epoch 21; iter: 0; batch classifier loss: 0.188825; batch adversarial loss: 0.446512\n",
      "epoch 22; iter: 0; batch classifier loss: 0.222540; batch adversarial loss: 0.450438\n",
      "epoch 23; iter: 0; batch classifier loss: 0.218021; batch adversarial loss: 0.543521\n",
      "epoch 24; iter: 0; batch classifier loss: 0.242368; batch adversarial loss: 0.515068\n",
      "epoch 25; iter: 0; batch classifier loss: 0.255264; batch adversarial loss: 0.571891\n",
      "epoch 26; iter: 0; batch classifier loss: 0.190976; batch adversarial loss: 0.439752\n",
      "epoch 27; iter: 0; batch classifier loss: 0.238280; batch adversarial loss: 0.518847\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212956; batch adversarial loss: 0.469200\n",
      "epoch 29; iter: 0; batch classifier loss: 0.264602; batch adversarial loss: 0.509189\n",
      "epoch 30; iter: 0; batch classifier loss: 0.180908; batch adversarial loss: 0.491836\n",
      "epoch 31; iter: 0; batch classifier loss: 0.290515; batch adversarial loss: 0.413495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.393712; batch adversarial loss: 0.515771\n",
      "epoch 33; iter: 0; batch classifier loss: 0.137951; batch adversarial loss: 0.432400\n",
      "epoch 34; iter: 0; batch classifier loss: 0.135318; batch adversarial loss: 0.471262\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113046; batch adversarial loss: 0.451338\n",
      "epoch 36; iter: 0; batch classifier loss: 0.146679; batch adversarial loss: 0.399604\n",
      "epoch 37; iter: 0; batch classifier loss: 0.176489; batch adversarial loss: 0.373568\n",
      "epoch 38; iter: 0; batch classifier loss: 0.133876; batch adversarial loss: 0.462316\n",
      "epoch 39; iter: 0; batch classifier loss: 0.080411; batch adversarial loss: 0.438542\n",
      "epoch 40; iter: 0; batch classifier loss: 0.089103; batch adversarial loss: 0.527494\n",
      "epoch 41; iter: 0; batch classifier loss: 0.071835; batch adversarial loss: 0.424323\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111714; batch adversarial loss: 0.475981\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117723; batch adversarial loss: 0.462983\n",
      "epoch 44; iter: 0; batch classifier loss: 0.077249; batch adversarial loss: 0.394067\n",
      "epoch 45; iter: 0; batch classifier loss: 0.147155; batch adversarial loss: 0.513974\n",
      "epoch 46; iter: 0; batch classifier loss: 0.110093; batch adversarial loss: 0.502842\n",
      "epoch 47; iter: 0; batch classifier loss: 0.085869; batch adversarial loss: 0.420961\n",
      "epoch 48; iter: 0; batch classifier loss: 0.103551; batch adversarial loss: 0.648365\n",
      "epoch 49; iter: 0; batch classifier loss: 0.124065; batch adversarial loss: 0.437906\n",
      "epoch 50; iter: 0; batch classifier loss: 0.077313; batch adversarial loss: 0.404789\n",
      "epoch 51; iter: 0; batch classifier loss: 0.079959; batch adversarial loss: 0.446313\n",
      "epoch 52; iter: 0; batch classifier loss: 0.123915; batch adversarial loss: 0.372260\n",
      "epoch 53; iter: 0; batch classifier loss: 0.103522; batch adversarial loss: 0.406154\n",
      "epoch 54; iter: 0; batch classifier loss: 0.135168; batch adversarial loss: 0.440851\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096882; batch adversarial loss: 0.512271\n",
      "epoch 56; iter: 0; batch classifier loss: 0.109234; batch adversarial loss: 0.489743\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072332; batch adversarial loss: 0.424574\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078774; batch adversarial loss: 0.514693\n",
      "epoch 59; iter: 0; batch classifier loss: 0.101724; batch adversarial loss: 0.460051\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097542; batch adversarial loss: 0.323484\n",
      "epoch 61; iter: 0; batch classifier loss: 0.132664; batch adversarial loss: 0.506504\n",
      "epoch 62; iter: 0; batch classifier loss: 0.042495; batch adversarial loss: 0.524789\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116123; batch adversarial loss: 0.477551\n",
      "epoch 64; iter: 0; batch classifier loss: 0.093381; batch adversarial loss: 0.435181\n",
      "epoch 65; iter: 0; batch classifier loss: 0.102574; batch adversarial loss: 0.515784\n",
      "epoch 66; iter: 0; batch classifier loss: 0.100811; batch adversarial loss: 0.381180\n",
      "epoch 67; iter: 0; batch classifier loss: 0.124944; batch adversarial loss: 0.432029\n",
      "epoch 68; iter: 0; batch classifier loss: 0.122022; batch adversarial loss: 0.465588\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102285; batch adversarial loss: 0.569111\n",
      "epoch 70; iter: 0; batch classifier loss: 0.126615; batch adversarial loss: 0.467634\n",
      "epoch 71; iter: 0; batch classifier loss: 0.087861; batch adversarial loss: 0.450614\n",
      "epoch 72; iter: 0; batch classifier loss: 0.171182; batch adversarial loss: 0.476149\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089338; batch adversarial loss: 0.536958\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063416; batch adversarial loss: 0.629054\n",
      "epoch 75; iter: 0; batch classifier loss: 0.092417; batch adversarial loss: 0.566738\n",
      "epoch 76; iter: 0; batch classifier loss: 0.094402; batch adversarial loss: 0.473268\n",
      "epoch 77; iter: 0; batch classifier loss: 0.106337; batch adversarial loss: 0.415444\n",
      "epoch 78; iter: 0; batch classifier loss: 0.173593; batch adversarial loss: 0.517257\n",
      "epoch 79; iter: 0; batch classifier loss: 0.100028; batch adversarial loss: 0.473845\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078899; batch adversarial loss: 0.469176\n",
      "epoch 81; iter: 0; batch classifier loss: 0.165017; batch adversarial loss: 0.432952\n",
      "epoch 82; iter: 0; batch classifier loss: 0.100544; batch adversarial loss: 0.433288\n",
      "epoch 83; iter: 0; batch classifier loss: 0.125003; batch adversarial loss: 0.377811\n",
      "epoch 84; iter: 0; batch classifier loss: 0.094325; batch adversarial loss: 0.470656\n",
      "epoch 85; iter: 0; batch classifier loss: 0.081285; batch adversarial loss: 0.473082\n",
      "epoch 86; iter: 0; batch classifier loss: 0.125423; batch adversarial loss: 0.396119\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073256; batch adversarial loss: 0.431537\n",
      "epoch 88; iter: 0; batch classifier loss: 0.117301; batch adversarial loss: 0.441976\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069837; batch adversarial loss: 0.447908\n",
      "epoch 90; iter: 0; batch classifier loss: 0.072886; batch adversarial loss: 0.441945\n",
      "epoch 91; iter: 0; batch classifier loss: 0.089678; batch adversarial loss: 0.366480\n",
      "epoch 92; iter: 0; batch classifier loss: 0.101650; batch adversarial loss: 0.380640\n",
      "epoch 93; iter: 0; batch classifier loss: 0.164876; batch adversarial loss: 0.416838\n",
      "epoch 94; iter: 0; batch classifier loss: 0.097048; batch adversarial loss: 0.390573\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065101; batch adversarial loss: 0.458741\n",
      "epoch 96; iter: 0; batch classifier loss: 0.076604; batch adversarial loss: 0.467288\n",
      "epoch 97; iter: 0; batch classifier loss: 0.153061; batch adversarial loss: 0.453423\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046553; batch adversarial loss: 0.476106\n",
      "epoch 99; iter: 0; batch classifier loss: 0.087559; batch adversarial loss: 0.376264\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050603; batch adversarial loss: 0.475296\n",
      "epoch 101; iter: 0; batch classifier loss: 0.163159; batch adversarial loss: 0.390123\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050079; batch adversarial loss: 0.546670\n",
      "epoch 103; iter: 0; batch classifier loss: 0.094014; batch adversarial loss: 0.406974\n",
      "epoch 104; iter: 0; batch classifier loss: 0.094510; batch adversarial loss: 0.448455\n",
      "epoch 105; iter: 0; batch classifier loss: 0.077759; batch adversarial loss: 0.526059\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060665; batch adversarial loss: 0.403099\n",
      "epoch 107; iter: 0; batch classifier loss: 0.120076; batch adversarial loss: 0.445020\n",
      "epoch 108; iter: 0; batch classifier loss: 0.071300; batch adversarial loss: 0.405701\n",
      "epoch 109; iter: 0; batch classifier loss: 0.065606; batch adversarial loss: 0.408210\n",
      "epoch 110; iter: 0; batch classifier loss: 0.079899; batch adversarial loss: 0.360390\n",
      "epoch 111; iter: 0; batch classifier loss: 0.082051; batch adversarial loss: 0.466357\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039580; batch adversarial loss: 0.477505\n",
      "epoch 113; iter: 0; batch classifier loss: 0.101006; batch adversarial loss: 0.477301\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044140; batch adversarial loss: 0.519664\n",
      "epoch 115; iter: 0; batch classifier loss: 0.072775; batch adversarial loss: 0.423767\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028409; batch adversarial loss: 0.586120\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061793; batch adversarial loss: 0.393525\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050853; batch adversarial loss: 0.434516\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035373; batch adversarial loss: 0.455794\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046495; batch adversarial loss: 0.459325\n",
      "epoch 121; iter: 0; batch classifier loss: 0.061306; batch adversarial loss: 0.502626\n",
      "epoch 122; iter: 0; batch classifier loss: 0.069318; batch adversarial loss: 0.406297\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037405; batch adversarial loss: 0.442102\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040938; batch adversarial loss: 0.384678\n",
      "epoch 125; iter: 0; batch classifier loss: 0.086290; batch adversarial loss: 0.450187\n",
      "epoch 126; iter: 0; batch classifier loss: 0.073467; batch adversarial loss: 0.468762\n",
      "epoch 127; iter: 0; batch classifier loss: 0.049471; batch adversarial loss: 0.463691\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030629; batch adversarial loss: 0.523219\n",
      "epoch 129; iter: 0; batch classifier loss: 0.054239; batch adversarial loss: 0.455654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.040284; batch adversarial loss: 0.466383\n",
      "epoch 131; iter: 0; batch classifier loss: 0.087053; batch adversarial loss: 0.405590\n",
      "epoch 132; iter: 0; batch classifier loss: 0.076763; batch adversarial loss: 0.460985\n",
      "epoch 133; iter: 0; batch classifier loss: 0.062076; batch adversarial loss: 0.399657\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038715; batch adversarial loss: 0.399022\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030444; batch adversarial loss: 0.478578\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031638; batch adversarial loss: 0.509504\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023535; batch adversarial loss: 0.462845\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046752; batch adversarial loss: 0.423531\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043831; batch adversarial loss: 0.454474\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025869; batch adversarial loss: 0.520139\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017926; batch adversarial loss: 0.373649\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048585; batch adversarial loss: 0.440750\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033348; batch adversarial loss: 0.436375\n",
      "epoch 144; iter: 0; batch classifier loss: 0.071094; batch adversarial loss: 0.581513\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020428; batch adversarial loss: 0.430356\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027072; batch adversarial loss: 0.550957\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022014; batch adversarial loss: 0.409004\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031013; batch adversarial loss: 0.451456\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027863; batch adversarial loss: 0.389430\n",
      "epoch 150; iter: 0; batch classifier loss: 0.062558; batch adversarial loss: 0.435453\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025233; batch adversarial loss: 0.531354\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022560; batch adversarial loss: 0.448855\n",
      "epoch 153; iter: 0; batch classifier loss: 0.043603; batch adversarial loss: 0.534927\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024672; batch adversarial loss: 0.444891\n",
      "epoch 155; iter: 0; batch classifier loss: 0.039672; batch adversarial loss: 0.435638\n",
      "epoch 156; iter: 0; batch classifier loss: 0.061305; batch adversarial loss: 0.412141\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047923; batch adversarial loss: 0.528749\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026863; batch adversarial loss: 0.435516\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027755; batch adversarial loss: 0.491840\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021910; batch adversarial loss: 0.401031\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032663; batch adversarial loss: 0.461881\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027411; batch adversarial loss: 0.413859\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016032; batch adversarial loss: 0.455981\n",
      "epoch 164; iter: 0; batch classifier loss: 0.041769; batch adversarial loss: 0.439822\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029696; batch adversarial loss: 0.399792\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024179; batch adversarial loss: 0.400919\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034822; batch adversarial loss: 0.450142\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027660; batch adversarial loss: 0.462741\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035609; batch adversarial loss: 0.422799\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029901; batch adversarial loss: 0.427253\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027560; batch adversarial loss: 0.416839\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010515; batch adversarial loss: 0.452040\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028388; batch adversarial loss: 0.429365\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026089; batch adversarial loss: 0.402130\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026428; batch adversarial loss: 0.419017\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040825; batch adversarial loss: 0.466217\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014778; batch adversarial loss: 0.414107\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027406; batch adversarial loss: 0.504189\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032230; batch adversarial loss: 0.474582\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025953; batch adversarial loss: 0.588994\n",
      "epoch 181; iter: 0; batch classifier loss: 0.031616; batch adversarial loss: 0.436983\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015296; batch adversarial loss: 0.467890\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039331; batch adversarial loss: 0.450500\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014966; batch adversarial loss: 0.419835\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022036; batch adversarial loss: 0.435763\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021752; batch adversarial loss: 0.537093\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027604; batch adversarial loss: 0.495179\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021847; batch adversarial loss: 0.410515\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022864; batch adversarial loss: 0.500232\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035343; batch adversarial loss: 0.527211\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020639; batch adversarial loss: 0.343044\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005750; batch adversarial loss: 0.452099\n",
      "epoch 193; iter: 0; batch classifier loss: 0.033767; batch adversarial loss: 0.407971\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035092; batch adversarial loss: 0.568465\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011039; batch adversarial loss: 0.478301\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009381; batch adversarial loss: 0.496391\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015829; batch adversarial loss: 0.503914\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024997; batch adversarial loss: 0.419703\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010167; batch adversarial loss: 0.506104\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693408; batch adversarial loss: 0.618046\n",
      "epoch 1; iter: 0; batch classifier loss: 0.417271; batch adversarial loss: 0.625299\n",
      "epoch 2; iter: 0; batch classifier loss: 0.426135; batch adversarial loss: 0.615444\n",
      "epoch 3; iter: 0; batch classifier loss: 0.396019; batch adversarial loss: 0.608026\n",
      "epoch 4; iter: 0; batch classifier loss: 0.352166; batch adversarial loss: 0.541830\n",
      "epoch 5; iter: 0; batch classifier loss: 0.445868; batch adversarial loss: 0.566783\n",
      "epoch 6; iter: 0; batch classifier loss: 0.332558; batch adversarial loss: 0.578196\n",
      "epoch 7; iter: 0; batch classifier loss: 0.240506; batch adversarial loss: 0.530313\n",
      "epoch 8; iter: 0; batch classifier loss: 0.387634; batch adversarial loss: 0.526511\n",
      "epoch 9; iter: 0; batch classifier loss: 0.401353; batch adversarial loss: 0.513443\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464785; batch adversarial loss: 0.575019\n",
      "epoch 11; iter: 0; batch classifier loss: 0.544878; batch adversarial loss: 0.552555\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556693; batch adversarial loss: 0.560494\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528004; batch adversarial loss: 0.476388\n",
      "epoch 14; iter: 0; batch classifier loss: 0.409394; batch adversarial loss: 0.436039\n",
      "epoch 15; iter: 0; batch classifier loss: 0.360528; batch adversarial loss: 0.477639\n",
      "epoch 16; iter: 0; batch classifier loss: 0.262463; batch adversarial loss: 0.514259\n",
      "epoch 17; iter: 0; batch classifier loss: 0.229986; batch adversarial loss: 0.511547\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237955; batch adversarial loss: 0.521933\n",
      "epoch 19; iter: 0; batch classifier loss: 0.219063; batch adversarial loss: 0.547111\n",
      "epoch 20; iter: 0; batch classifier loss: 0.207225; batch adversarial loss: 0.465489\n",
      "epoch 21; iter: 0; batch classifier loss: 0.207347; batch adversarial loss: 0.462428\n",
      "epoch 22; iter: 0; batch classifier loss: 0.195518; batch adversarial loss: 0.444534\n",
      "epoch 23; iter: 0; batch classifier loss: 0.150357; batch adversarial loss: 0.414433\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182976; batch adversarial loss: 0.466680\n",
      "epoch 25; iter: 0; batch classifier loss: 0.134488; batch adversarial loss: 0.472745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.173101; batch adversarial loss: 0.449968\n",
      "epoch 27; iter: 0; batch classifier loss: 0.173340; batch adversarial loss: 0.496920\n",
      "epoch 28; iter: 0; batch classifier loss: 0.142774; batch adversarial loss: 0.443994\n",
      "epoch 29; iter: 0; batch classifier loss: 0.255575; batch adversarial loss: 0.437062\n",
      "epoch 30; iter: 0; batch classifier loss: 0.137918; batch adversarial loss: 0.471356\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134952; batch adversarial loss: 0.501727\n",
      "epoch 32; iter: 0; batch classifier loss: 0.119286; batch adversarial loss: 0.561805\n",
      "epoch 33; iter: 0; batch classifier loss: 0.133700; batch adversarial loss: 0.498713\n",
      "epoch 34; iter: 0; batch classifier loss: 0.146724; batch adversarial loss: 0.507209\n",
      "epoch 35; iter: 0; batch classifier loss: 0.203871; batch adversarial loss: 0.453105\n",
      "epoch 36; iter: 0; batch classifier loss: 0.143736; batch adversarial loss: 0.430668\n",
      "epoch 37; iter: 0; batch classifier loss: 0.140202; batch adversarial loss: 0.485645\n",
      "epoch 38; iter: 0; batch classifier loss: 0.174969; batch adversarial loss: 0.476438\n",
      "epoch 39; iter: 0; batch classifier loss: 0.123298; batch adversarial loss: 0.447009\n",
      "epoch 40; iter: 0; batch classifier loss: 0.152494; batch adversarial loss: 0.457978\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111229; batch adversarial loss: 0.381451\n",
      "epoch 42; iter: 0; batch classifier loss: 0.129046; batch adversarial loss: 0.375744\n",
      "epoch 43; iter: 0; batch classifier loss: 0.138499; batch adversarial loss: 0.458601\n",
      "epoch 44; iter: 0; batch classifier loss: 0.145540; batch adversarial loss: 0.377385\n",
      "epoch 45; iter: 0; batch classifier loss: 0.159148; batch adversarial loss: 0.479941\n",
      "epoch 46; iter: 0; batch classifier loss: 0.187207; batch adversarial loss: 0.432194\n",
      "epoch 47; iter: 0; batch classifier loss: 0.190403; batch adversarial loss: 0.438253\n",
      "epoch 48; iter: 0; batch classifier loss: 0.195142; batch adversarial loss: 0.508463\n",
      "epoch 49; iter: 0; batch classifier loss: 0.152821; batch adversarial loss: 0.482767\n",
      "epoch 50; iter: 0; batch classifier loss: 0.118619; batch adversarial loss: 0.573418\n",
      "epoch 51; iter: 0; batch classifier loss: 0.158747; batch adversarial loss: 0.437228\n",
      "epoch 52; iter: 0; batch classifier loss: 0.119318; batch adversarial loss: 0.483510\n",
      "epoch 53; iter: 0; batch classifier loss: 0.168499; batch adversarial loss: 0.471435\n",
      "epoch 54; iter: 0; batch classifier loss: 0.132259; batch adversarial loss: 0.485608\n",
      "epoch 55; iter: 0; batch classifier loss: 0.133560; batch adversarial loss: 0.490383\n",
      "epoch 56; iter: 0; batch classifier loss: 0.145536; batch adversarial loss: 0.413456\n",
      "epoch 57; iter: 0; batch classifier loss: 0.267517; batch adversarial loss: 0.393579\n",
      "epoch 58; iter: 0; batch classifier loss: 0.193038; batch adversarial loss: 0.411294\n",
      "epoch 59; iter: 0; batch classifier loss: 0.173336; batch adversarial loss: 0.466250\n",
      "epoch 60; iter: 0; batch classifier loss: 0.134843; batch adversarial loss: 0.405843\n",
      "epoch 61; iter: 0; batch classifier loss: 0.250497; batch adversarial loss: 0.452591\n",
      "epoch 62; iter: 0; batch classifier loss: 0.143753; batch adversarial loss: 0.461321\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099963; batch adversarial loss: 0.457171\n",
      "epoch 64; iter: 0; batch classifier loss: 0.198167; batch adversarial loss: 0.507948\n",
      "epoch 65; iter: 0; batch classifier loss: 0.205716; batch adversarial loss: 0.442493\n",
      "epoch 66; iter: 0; batch classifier loss: 0.138256; batch adversarial loss: 0.320186\n",
      "epoch 67; iter: 0; batch classifier loss: 0.211661; batch adversarial loss: 0.390140\n",
      "epoch 68; iter: 0; batch classifier loss: 0.196713; batch adversarial loss: 0.500637\n",
      "epoch 69; iter: 0; batch classifier loss: 0.200308; batch adversarial loss: 0.444508\n",
      "epoch 70; iter: 0; batch classifier loss: 0.259404; batch adversarial loss: 0.470281\n",
      "epoch 71; iter: 0; batch classifier loss: 0.188037; batch adversarial loss: 0.416614\n",
      "epoch 72; iter: 0; batch classifier loss: 0.213997; batch adversarial loss: 0.568576\n",
      "epoch 73; iter: 0; batch classifier loss: 0.164493; batch adversarial loss: 0.422113\n",
      "epoch 74; iter: 0; batch classifier loss: 0.233668; batch adversarial loss: 0.384563\n",
      "epoch 75; iter: 0; batch classifier loss: 0.175956; batch adversarial loss: 0.431183\n",
      "epoch 76; iter: 0; batch classifier loss: 0.166719; batch adversarial loss: 0.472578\n",
      "epoch 77; iter: 0; batch classifier loss: 0.221967; batch adversarial loss: 0.424032\n",
      "epoch 78; iter: 0; batch classifier loss: 0.180548; batch adversarial loss: 0.471587\n",
      "epoch 79; iter: 0; batch classifier loss: 0.188551; batch adversarial loss: 0.462625\n",
      "epoch 80; iter: 0; batch classifier loss: 0.157772; batch adversarial loss: 0.456888\n",
      "epoch 81; iter: 0; batch classifier loss: 0.206179; batch adversarial loss: 0.506968\n",
      "epoch 82; iter: 0; batch classifier loss: 0.211219; batch adversarial loss: 0.460284\n",
      "epoch 83; iter: 0; batch classifier loss: 0.142542; batch adversarial loss: 0.479502\n",
      "epoch 84; iter: 0; batch classifier loss: 0.170892; batch adversarial loss: 0.340972\n",
      "epoch 85; iter: 0; batch classifier loss: 0.231628; batch adversarial loss: 0.349976\n",
      "epoch 86; iter: 0; batch classifier loss: 0.229213; batch adversarial loss: 0.469962\n",
      "epoch 87; iter: 0; batch classifier loss: 0.245938; batch adversarial loss: 0.480389\n",
      "epoch 88; iter: 0; batch classifier loss: 0.307381; batch adversarial loss: 0.424827\n",
      "epoch 89; iter: 0; batch classifier loss: 0.216764; batch adversarial loss: 0.394485\n",
      "epoch 90; iter: 0; batch classifier loss: 0.177578; batch adversarial loss: 0.495079\n",
      "epoch 91; iter: 0; batch classifier loss: 0.196488; batch adversarial loss: 0.555006\n",
      "epoch 92; iter: 0; batch classifier loss: 0.208425; batch adversarial loss: 0.519197\n",
      "epoch 93; iter: 0; batch classifier loss: 0.226169; batch adversarial loss: 0.447160\n",
      "epoch 94; iter: 0; batch classifier loss: 0.205710; batch adversarial loss: 0.506416\n",
      "epoch 95; iter: 0; batch classifier loss: 0.162578; batch adversarial loss: 0.434087\n",
      "epoch 96; iter: 0; batch classifier loss: 0.225885; batch adversarial loss: 0.434410\n",
      "epoch 97; iter: 0; batch classifier loss: 0.202312; batch adversarial loss: 0.398131\n",
      "epoch 98; iter: 0; batch classifier loss: 0.162643; batch adversarial loss: 0.472172\n",
      "epoch 99; iter: 0; batch classifier loss: 0.207342; batch adversarial loss: 0.470996\n",
      "epoch 100; iter: 0; batch classifier loss: 0.185178; batch adversarial loss: 0.458051\n",
      "epoch 101; iter: 0; batch classifier loss: 0.209607; batch adversarial loss: 0.495266\n",
      "epoch 102; iter: 0; batch classifier loss: 0.151525; batch adversarial loss: 0.433787\n",
      "epoch 103; iter: 0; batch classifier loss: 0.182942; batch adversarial loss: 0.520878\n",
      "epoch 104; iter: 0; batch classifier loss: 0.265162; batch adversarial loss: 0.447018\n",
      "epoch 105; iter: 0; batch classifier loss: 0.165044; batch adversarial loss: 0.459246\n",
      "epoch 106; iter: 0; batch classifier loss: 0.104025; batch adversarial loss: 0.458184\n",
      "epoch 107; iter: 0; batch classifier loss: 0.196397; batch adversarial loss: 0.458815\n",
      "epoch 108; iter: 0; batch classifier loss: 0.191671; batch adversarial loss: 0.457895\n",
      "epoch 109; iter: 0; batch classifier loss: 0.173216; batch adversarial loss: 0.410962\n",
      "epoch 110; iter: 0; batch classifier loss: 0.176132; batch adversarial loss: 0.433686\n",
      "epoch 111; iter: 0; batch classifier loss: 0.182317; batch adversarial loss: 0.532075\n",
      "epoch 112; iter: 0; batch classifier loss: 0.194707; batch adversarial loss: 0.471273\n",
      "epoch 113; iter: 0; batch classifier loss: 0.182902; batch adversarial loss: 0.422802\n",
      "epoch 114; iter: 0; batch classifier loss: 0.226734; batch adversarial loss: 0.508331\n",
      "epoch 115; iter: 0; batch classifier loss: 0.159071; batch adversarial loss: 0.531670\n",
      "epoch 116; iter: 0; batch classifier loss: 0.159490; batch adversarial loss: 0.385881\n",
      "epoch 117; iter: 0; batch classifier loss: 0.186010; batch adversarial loss: 0.483226\n",
      "epoch 118; iter: 0; batch classifier loss: 0.157266; batch adversarial loss: 0.494089\n",
      "epoch 119; iter: 0; batch classifier loss: 0.181714; batch adversarial loss: 0.372944\n",
      "epoch 120; iter: 0; batch classifier loss: 0.141415; batch adversarial loss: 0.508958\n",
      "epoch 121; iter: 0; batch classifier loss: 0.189440; batch adversarial loss: 0.410028\n",
      "epoch 122; iter: 0; batch classifier loss: 0.149669; batch adversarial loss: 0.421986\n",
      "epoch 123; iter: 0; batch classifier loss: 0.183637; batch adversarial loss: 0.458785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.189234; batch adversarial loss: 0.618225\n",
      "epoch 125; iter: 0; batch classifier loss: 0.166409; batch adversarial loss: 0.544168\n",
      "epoch 126; iter: 0; batch classifier loss: 0.254363; batch adversarial loss: 0.446633\n",
      "epoch 127; iter: 0; batch classifier loss: 0.162004; batch adversarial loss: 0.483293\n",
      "epoch 128; iter: 0; batch classifier loss: 0.183262; batch adversarial loss: 0.386392\n",
      "epoch 129; iter: 0; batch classifier loss: 0.234388; batch adversarial loss: 0.435541\n",
      "epoch 130; iter: 0; batch classifier loss: 0.185469; batch adversarial loss: 0.495746\n",
      "epoch 131; iter: 0; batch classifier loss: 0.195520; batch adversarial loss: 0.446660\n",
      "epoch 132; iter: 0; batch classifier loss: 0.206305; batch adversarial loss: 0.568473\n",
      "epoch 133; iter: 0; batch classifier loss: 0.173486; batch adversarial loss: 0.458306\n",
      "epoch 134; iter: 0; batch classifier loss: 0.173225; batch adversarial loss: 0.410379\n",
      "epoch 135; iter: 0; batch classifier loss: 0.165534; batch adversarial loss: 0.446872\n",
      "epoch 136; iter: 0; batch classifier loss: 0.246126; batch adversarial loss: 0.459245\n",
      "epoch 137; iter: 0; batch classifier loss: 0.201410; batch adversarial loss: 0.519836\n",
      "epoch 138; iter: 0; batch classifier loss: 0.190846; batch adversarial loss: 0.470485\n",
      "epoch 139; iter: 0; batch classifier loss: 0.176763; batch adversarial loss: 0.482970\n",
      "epoch 140; iter: 0; batch classifier loss: 0.172748; batch adversarial loss: 0.581566\n",
      "epoch 141; iter: 0; batch classifier loss: 0.202339; batch adversarial loss: 0.470804\n",
      "epoch 142; iter: 0; batch classifier loss: 0.189572; batch adversarial loss: 0.495120\n",
      "epoch 143; iter: 0; batch classifier loss: 0.169093; batch adversarial loss: 0.422660\n",
      "epoch 144; iter: 0; batch classifier loss: 0.211617; batch adversarial loss: 0.458884\n",
      "epoch 145; iter: 0; batch classifier loss: 0.130109; batch adversarial loss: 0.458355\n",
      "epoch 146; iter: 0; batch classifier loss: 0.226267; batch adversarial loss: 0.372886\n",
      "epoch 147; iter: 0; batch classifier loss: 0.217919; batch adversarial loss: 0.459054\n",
      "epoch 148; iter: 0; batch classifier loss: 0.142107; batch adversarial loss: 0.459481\n",
      "epoch 149; iter: 0; batch classifier loss: 0.179139; batch adversarial loss: 0.445736\n",
      "epoch 150; iter: 0; batch classifier loss: 0.177180; batch adversarial loss: 0.336648\n",
      "epoch 151; iter: 0; batch classifier loss: 0.177572; batch adversarial loss: 0.471417\n",
      "epoch 152; iter: 0; batch classifier loss: 0.185831; batch adversarial loss: 0.348759\n",
      "epoch 153; iter: 0; batch classifier loss: 0.177531; batch adversarial loss: 0.433734\n",
      "epoch 154; iter: 0; batch classifier loss: 0.151459; batch adversarial loss: 0.508005\n",
      "epoch 155; iter: 0; batch classifier loss: 0.105938; batch adversarial loss: 0.483113\n",
      "epoch 156; iter: 0; batch classifier loss: 0.158416; batch adversarial loss: 0.446545\n",
      "epoch 157; iter: 0; batch classifier loss: 0.150939; batch adversarial loss: 0.458897\n",
      "epoch 158; iter: 0; batch classifier loss: 0.201879; batch adversarial loss: 0.422002\n",
      "epoch 159; iter: 0; batch classifier loss: 0.172400; batch adversarial loss: 0.422377\n",
      "epoch 160; iter: 0; batch classifier loss: 0.170494; batch adversarial loss: 0.532527\n",
      "epoch 161; iter: 0; batch classifier loss: 0.164807; batch adversarial loss: 0.398578\n",
      "epoch 162; iter: 0; batch classifier loss: 0.199854; batch adversarial loss: 0.506362\n",
      "epoch 163; iter: 0; batch classifier loss: 0.164379; batch adversarial loss: 0.496895\n",
      "epoch 164; iter: 0; batch classifier loss: 0.175366; batch adversarial loss: 0.518692\n",
      "epoch 165; iter: 0; batch classifier loss: 0.156325; batch adversarial loss: 0.410608\n",
      "epoch 166; iter: 0; batch classifier loss: 0.160849; batch adversarial loss: 0.421613\n",
      "epoch 167; iter: 0; batch classifier loss: 0.156939; batch adversarial loss: 0.435028\n",
      "epoch 168; iter: 0; batch classifier loss: 0.133431; batch adversarial loss: 0.406815\n",
      "epoch 169; iter: 0; batch classifier loss: 0.129058; batch adversarial loss: 0.466011\n",
      "epoch 170; iter: 0; batch classifier loss: 0.078892; batch adversarial loss: 0.481930\n",
      "epoch 171; iter: 0; batch classifier loss: 0.072140; batch adversarial loss: 0.495308\n",
      "epoch 172; iter: 0; batch classifier loss: 0.061661; batch adversarial loss: 0.414130\n",
      "epoch 173; iter: 0; batch classifier loss: 0.090497; batch adversarial loss: 0.433448\n",
      "epoch 174; iter: 0; batch classifier loss: 0.066932; batch adversarial loss: 0.484647\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033630; batch adversarial loss: 0.484193\n",
      "epoch 176; iter: 0; batch classifier loss: 0.050034; batch adversarial loss: 0.499964\n",
      "epoch 177; iter: 0; batch classifier loss: 0.055964; batch adversarial loss: 0.446802\n",
      "epoch 178; iter: 0; batch classifier loss: 0.074644; batch adversarial loss: 0.458300\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038325; batch adversarial loss: 0.437836\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032409; batch adversarial loss: 0.419845\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039959; batch adversarial loss: 0.429620\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023395; batch adversarial loss: 0.491400\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013206; batch adversarial loss: 0.418114\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033456; batch adversarial loss: 0.444924\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032084; batch adversarial loss: 0.484481\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029497; batch adversarial loss: 0.448528\n",
      "epoch 187; iter: 0; batch classifier loss: 0.041499; batch adversarial loss: 0.420616\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031584; batch adversarial loss: 0.409342\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037212; batch adversarial loss: 0.415054\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025163; batch adversarial loss: 0.543149\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014792; batch adversarial loss: 0.409682\n",
      "epoch 192; iter: 0; batch classifier loss: 0.044331; batch adversarial loss: 0.455517\n",
      "epoch 193; iter: 0; batch classifier loss: 0.036024; batch adversarial loss: 0.488556\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019077; batch adversarial loss: 0.431340\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018718; batch adversarial loss: 0.400354\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021815; batch adversarial loss: 0.439358\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017684; batch adversarial loss: 0.456426\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018968; batch adversarial loss: 0.439034\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010207; batch adversarial loss: 0.429647\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701765; batch adversarial loss: 0.575708\n",
      "epoch 1; iter: 0; batch classifier loss: 0.386570; batch adversarial loss: 0.590123\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396865; batch adversarial loss: 0.585704\n",
      "epoch 3; iter: 0; batch classifier loss: 0.311686; batch adversarial loss: 0.567418\n",
      "epoch 4; iter: 0; batch classifier loss: 0.323917; batch adversarial loss: 0.564346\n",
      "epoch 5; iter: 0; batch classifier loss: 0.353229; batch adversarial loss: 0.539456\n",
      "epoch 6; iter: 0; batch classifier loss: 0.325977; batch adversarial loss: 0.594174\n",
      "epoch 7; iter: 0; batch classifier loss: 0.267099; batch adversarial loss: 0.567207\n",
      "epoch 8; iter: 0; batch classifier loss: 0.371365; batch adversarial loss: 0.533895\n",
      "epoch 9; iter: 0; batch classifier loss: 0.321404; batch adversarial loss: 0.598520\n",
      "epoch 10; iter: 0; batch classifier loss: 0.385278; batch adversarial loss: 0.521870\n",
      "epoch 11; iter: 0; batch classifier loss: 0.356089; batch adversarial loss: 0.491944\n",
      "epoch 12; iter: 0; batch classifier loss: 0.496471; batch adversarial loss: 0.608763\n",
      "epoch 13; iter: 0; batch classifier loss: 0.604017; batch adversarial loss: 0.546470\n",
      "epoch 14; iter: 0; batch classifier loss: 0.491794; batch adversarial loss: 0.547978\n",
      "epoch 15; iter: 0; batch classifier loss: 0.273857; batch adversarial loss: 0.470865\n",
      "epoch 16; iter: 0; batch classifier loss: 0.240258; batch adversarial loss: 0.504660\n",
      "epoch 17; iter: 0; batch classifier loss: 0.275436; batch adversarial loss: 0.490970\n",
      "epoch 18; iter: 0; batch classifier loss: 0.164793; batch adversarial loss: 0.532750\n",
      "epoch 19; iter: 0; batch classifier loss: 0.212131; batch adversarial loss: 0.420277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.216588; batch adversarial loss: 0.468019\n",
      "epoch 21; iter: 0; batch classifier loss: 0.224321; batch adversarial loss: 0.461871\n",
      "epoch 22; iter: 0; batch classifier loss: 0.253287; batch adversarial loss: 0.422532\n",
      "epoch 23; iter: 0; batch classifier loss: 0.183145; batch adversarial loss: 0.496094\n",
      "epoch 24; iter: 0; batch classifier loss: 0.178515; batch adversarial loss: 0.497890\n",
      "epoch 25; iter: 0; batch classifier loss: 0.207998; batch adversarial loss: 0.484817\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188037; batch adversarial loss: 0.360840\n",
      "epoch 27; iter: 0; batch classifier loss: 0.134381; batch adversarial loss: 0.470002\n",
      "epoch 28; iter: 0; batch classifier loss: 0.206479; batch adversarial loss: 0.419952\n",
      "epoch 29; iter: 0; batch classifier loss: 0.141976; batch adversarial loss: 0.426349\n",
      "epoch 30; iter: 0; batch classifier loss: 0.170202; batch adversarial loss: 0.455389\n",
      "epoch 31; iter: 0; batch classifier loss: 0.200374; batch adversarial loss: 0.464293\n",
      "epoch 32; iter: 0; batch classifier loss: 0.222487; batch adversarial loss: 0.465925\n",
      "epoch 33; iter: 0; batch classifier loss: 0.157941; batch adversarial loss: 0.401065\n",
      "epoch 34; iter: 0; batch classifier loss: 0.115655; batch adversarial loss: 0.431752\n",
      "epoch 35; iter: 0; batch classifier loss: 0.162042; batch adversarial loss: 0.501234\n",
      "epoch 36; iter: 0; batch classifier loss: 0.172937; batch adversarial loss: 0.442014\n",
      "epoch 37; iter: 0; batch classifier loss: 0.172227; batch adversarial loss: 0.402017\n",
      "epoch 38; iter: 0; batch classifier loss: 0.179335; batch adversarial loss: 0.423854\n",
      "epoch 39; iter: 0; batch classifier loss: 0.128641; batch adversarial loss: 0.425573\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135014; batch adversarial loss: 0.617845\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135652; batch adversarial loss: 0.483241\n",
      "epoch 42; iter: 0; batch classifier loss: 0.161504; batch adversarial loss: 0.454184\n",
      "epoch 43; iter: 0; batch classifier loss: 0.168311; batch adversarial loss: 0.394406\n",
      "epoch 44; iter: 0; batch classifier loss: 0.196479; batch adversarial loss: 0.473676\n",
      "epoch 45; iter: 0; batch classifier loss: 0.155690; batch adversarial loss: 0.406202\n",
      "epoch 46; iter: 0; batch classifier loss: 0.203450; batch adversarial loss: 0.454432\n",
      "epoch 47; iter: 0; batch classifier loss: 0.145888; batch adversarial loss: 0.437025\n",
      "epoch 48; iter: 0; batch classifier loss: 0.127398; batch adversarial loss: 0.422975\n",
      "epoch 49; iter: 0; batch classifier loss: 0.153682; batch adversarial loss: 0.469601\n",
      "epoch 50; iter: 0; batch classifier loss: 0.170414; batch adversarial loss: 0.426773\n",
      "epoch 51; iter: 0; batch classifier loss: 0.156947; batch adversarial loss: 0.432607\n",
      "epoch 52; iter: 0; batch classifier loss: 0.168983; batch adversarial loss: 0.426697\n",
      "epoch 53; iter: 0; batch classifier loss: 0.186856; batch adversarial loss: 0.360100\n",
      "epoch 54; iter: 0; batch classifier loss: 0.182175; batch adversarial loss: 0.462587\n",
      "epoch 55; iter: 0; batch classifier loss: 0.173107; batch adversarial loss: 0.388001\n",
      "epoch 56; iter: 0; batch classifier loss: 0.118476; batch adversarial loss: 0.431013\n",
      "epoch 57; iter: 0; batch classifier loss: 0.236408; batch adversarial loss: 0.522799\n",
      "epoch 58; iter: 0; batch classifier loss: 0.280794; batch adversarial loss: 0.451485\n",
      "epoch 59; iter: 0; batch classifier loss: 0.144672; batch adversarial loss: 0.471407\n",
      "epoch 60; iter: 0; batch classifier loss: 0.171174; batch adversarial loss: 0.444404\n",
      "epoch 61; iter: 0; batch classifier loss: 0.222636; batch adversarial loss: 0.448128\n",
      "epoch 62; iter: 0; batch classifier loss: 0.201720; batch adversarial loss: 0.385270\n",
      "epoch 63; iter: 0; batch classifier loss: 0.257567; batch adversarial loss: 0.503419\n",
      "epoch 64; iter: 0; batch classifier loss: 0.161591; batch adversarial loss: 0.532641\n",
      "epoch 65; iter: 0; batch classifier loss: 0.212783; batch adversarial loss: 0.470476\n",
      "epoch 66; iter: 0; batch classifier loss: 0.214935; batch adversarial loss: 0.494733\n",
      "epoch 67; iter: 0; batch classifier loss: 0.165164; batch adversarial loss: 0.483230\n",
      "epoch 68; iter: 0; batch classifier loss: 0.182095; batch adversarial loss: 0.449166\n",
      "epoch 69; iter: 0; batch classifier loss: 0.205613; batch adversarial loss: 0.506640\n",
      "epoch 70; iter: 0; batch classifier loss: 0.237554; batch adversarial loss: 0.470441\n",
      "epoch 71; iter: 0; batch classifier loss: 0.247306; batch adversarial loss: 0.494017\n",
      "epoch 72; iter: 0; batch classifier loss: 0.208116; batch adversarial loss: 0.557170\n",
      "epoch 73; iter: 0; batch classifier loss: 0.198881; batch adversarial loss: 0.435298\n",
      "epoch 74; iter: 0; batch classifier loss: 0.196182; batch adversarial loss: 0.507404\n",
      "epoch 75; iter: 0; batch classifier loss: 0.239296; batch adversarial loss: 0.506712\n",
      "epoch 76; iter: 0; batch classifier loss: 0.169902; batch adversarial loss: 0.519334\n",
      "epoch 77; iter: 0; batch classifier loss: 0.177079; batch adversarial loss: 0.493943\n",
      "epoch 78; iter: 0; batch classifier loss: 0.259099; batch adversarial loss: 0.398127\n",
      "epoch 79; iter: 0; batch classifier loss: 0.243743; batch adversarial loss: 0.385998\n",
      "epoch 80; iter: 0; batch classifier loss: 0.198196; batch adversarial loss: 0.531607\n",
      "epoch 81; iter: 0; batch classifier loss: 0.257300; batch adversarial loss: 0.373444\n",
      "epoch 82; iter: 0; batch classifier loss: 0.258951; batch adversarial loss: 0.361582\n",
      "epoch 83; iter: 0; batch classifier loss: 0.148260; batch adversarial loss: 0.434441\n",
      "epoch 84; iter: 0; batch classifier loss: 0.236977; batch adversarial loss: 0.458979\n",
      "epoch 85; iter: 0; batch classifier loss: 0.109620; batch adversarial loss: 0.482046\n",
      "epoch 86; iter: 0; batch classifier loss: 0.097736; batch adversarial loss: 0.445295\n",
      "epoch 87; iter: 0; batch classifier loss: 0.077369; batch adversarial loss: 0.524459\n",
      "epoch 88; iter: 0; batch classifier loss: 0.100203; batch adversarial loss: 0.493708\n",
      "epoch 89; iter: 0; batch classifier loss: 0.108981; batch adversarial loss: 0.438497\n",
      "epoch 90; iter: 0; batch classifier loss: 0.171173; batch adversarial loss: 0.455063\n",
      "epoch 91; iter: 0; batch classifier loss: 0.193976; batch adversarial loss: 0.438018\n",
      "epoch 92; iter: 0; batch classifier loss: 0.139826; batch adversarial loss: 0.353862\n",
      "epoch 93; iter: 0; batch classifier loss: 0.124514; batch adversarial loss: 0.375883\n",
      "epoch 94; iter: 0; batch classifier loss: 0.109326; batch adversarial loss: 0.483547\n",
      "epoch 95; iter: 0; batch classifier loss: 0.184549; batch adversarial loss: 0.386659\n",
      "epoch 96; iter: 0; batch classifier loss: 0.207871; batch adversarial loss: 0.459096\n",
      "epoch 97; iter: 0; batch classifier loss: 0.185041; batch adversarial loss: 0.447550\n",
      "epoch 98; iter: 0; batch classifier loss: 0.157969; batch adversarial loss: 0.455007\n",
      "epoch 99; iter: 0; batch classifier loss: 0.190385; batch adversarial loss: 0.533609\n",
      "epoch 100; iter: 0; batch classifier loss: 0.143581; batch adversarial loss: 0.444896\n",
      "epoch 101; iter: 0; batch classifier loss: 0.258865; batch adversarial loss: 0.530722\n",
      "epoch 102; iter: 0; batch classifier loss: 0.294352; batch adversarial loss: 0.446840\n",
      "epoch 103; iter: 0; batch classifier loss: 0.239120; batch adversarial loss: 0.472751\n",
      "epoch 104; iter: 0; batch classifier loss: 0.194250; batch adversarial loss: 0.494082\n",
      "epoch 105; iter: 0; batch classifier loss: 0.223679; batch adversarial loss: 0.408577\n",
      "epoch 106; iter: 0; batch classifier loss: 0.195916; batch adversarial loss: 0.506695\n",
      "epoch 107; iter: 0; batch classifier loss: 0.178539; batch adversarial loss: 0.437800\n",
      "epoch 108; iter: 0; batch classifier loss: 0.176786; batch adversarial loss: 0.471075\n",
      "epoch 109; iter: 0; batch classifier loss: 0.191447; batch adversarial loss: 0.420439\n",
      "epoch 110; iter: 0; batch classifier loss: 0.188276; batch adversarial loss: 0.507830\n",
      "epoch 111; iter: 0; batch classifier loss: 0.160111; batch adversarial loss: 0.447572\n",
      "epoch 112; iter: 0; batch classifier loss: 0.213215; batch adversarial loss: 0.412112\n",
      "epoch 113; iter: 0; batch classifier loss: 0.163920; batch adversarial loss: 0.454484\n",
      "epoch 114; iter: 0; batch classifier loss: 0.194097; batch adversarial loss: 0.613164\n",
      "epoch 115; iter: 0; batch classifier loss: 0.146621; batch adversarial loss: 0.541753\n",
      "epoch 116; iter: 0; batch classifier loss: 0.153564; batch adversarial loss: 0.396157\n",
      "epoch 117; iter: 0; batch classifier loss: 0.152223; batch adversarial loss: 0.458955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.198924; batch adversarial loss: 0.346139\n",
      "epoch 119; iter: 0; batch classifier loss: 0.121387; batch adversarial loss: 0.444279\n",
      "epoch 120; iter: 0; batch classifier loss: 0.156691; batch adversarial loss: 0.407283\n",
      "epoch 121; iter: 0; batch classifier loss: 0.193175; batch adversarial loss: 0.445699\n",
      "epoch 122; iter: 0; batch classifier loss: 0.133346; batch adversarial loss: 0.422779\n",
      "epoch 123; iter: 0; batch classifier loss: 0.144635; batch adversarial loss: 0.444995\n",
      "epoch 124; iter: 0; batch classifier loss: 0.144281; batch adversarial loss: 0.418917\n",
      "epoch 125; iter: 0; batch classifier loss: 0.100647; batch adversarial loss: 0.551434\n",
      "epoch 126; iter: 0; batch classifier loss: 0.098673; batch adversarial loss: 0.455413\n",
      "epoch 127; iter: 0; batch classifier loss: 0.067011; batch adversarial loss: 0.458914\n",
      "epoch 128; iter: 0; batch classifier loss: 0.071016; batch adversarial loss: 0.527651\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052619; batch adversarial loss: 0.585257\n",
      "epoch 130; iter: 0; batch classifier loss: 0.088998; batch adversarial loss: 0.444272\n",
      "epoch 131; iter: 0; batch classifier loss: 0.061768; batch adversarial loss: 0.470792\n",
      "epoch 132; iter: 0; batch classifier loss: 0.076319; batch adversarial loss: 0.494770\n",
      "epoch 133; iter: 0; batch classifier loss: 0.050518; batch adversarial loss: 0.453823\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053022; batch adversarial loss: 0.424516\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040969; batch adversarial loss: 0.398423\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047526; batch adversarial loss: 0.426941\n",
      "epoch 137; iter: 0; batch classifier loss: 0.078326; batch adversarial loss: 0.403339\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028892; batch adversarial loss: 0.527766\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044275; batch adversarial loss: 0.489822\n",
      "epoch 140; iter: 0; batch classifier loss: 0.057966; batch adversarial loss: 0.428144\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037204; batch adversarial loss: 0.508043\n",
      "epoch 142; iter: 0; batch classifier loss: 0.054851; batch adversarial loss: 0.398569\n",
      "epoch 143; iter: 0; batch classifier loss: 0.072471; batch adversarial loss: 0.494361\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049903; batch adversarial loss: 0.464357\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044756; batch adversarial loss: 0.424426\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028944; batch adversarial loss: 0.477224\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016974; batch adversarial loss: 0.442313\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042702; batch adversarial loss: 0.414940\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025034; batch adversarial loss: 0.389961\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033140; batch adversarial loss: 0.487159\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042911; batch adversarial loss: 0.438898\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019152; batch adversarial loss: 0.433858\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031239; batch adversarial loss: 0.510445\n",
      "epoch 154; iter: 0; batch classifier loss: 0.056653; batch adversarial loss: 0.516556\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042158; batch adversarial loss: 0.524516\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032271; batch adversarial loss: 0.527518\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032031; batch adversarial loss: 0.559955\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035659; batch adversarial loss: 0.426801\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013839; batch adversarial loss: 0.520117\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023005; batch adversarial loss: 0.378981\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038453; batch adversarial loss: 0.478123\n",
      "epoch 162; iter: 0; batch classifier loss: 0.044799; batch adversarial loss: 0.409707\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029040; batch adversarial loss: 0.410172\n",
      "epoch 164; iter: 0; batch classifier loss: 0.044784; batch adversarial loss: 0.434822\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025253; batch adversarial loss: 0.499835\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034541; batch adversarial loss: 0.433584\n",
      "epoch 167; iter: 0; batch classifier loss: 0.068115; batch adversarial loss: 0.479547\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028630; batch adversarial loss: 0.334480\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017654; batch adversarial loss: 0.413743\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016410; batch adversarial loss: 0.520878\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010870; batch adversarial loss: 0.473678\n",
      "epoch 172; iter: 0; batch classifier loss: 0.048156; batch adversarial loss: 0.501334\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040728; batch adversarial loss: 0.334631\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028781; batch adversarial loss: 0.484152\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019232; batch adversarial loss: 0.481011\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039351; batch adversarial loss: 0.536594\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013339; batch adversarial loss: 0.455467\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029988; batch adversarial loss: 0.536355\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044000; batch adversarial loss: 0.385242\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023180; batch adversarial loss: 0.558582\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023313; batch adversarial loss: 0.327121\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017457; batch adversarial loss: 0.419497\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039063; batch adversarial loss: 0.412722\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040569; batch adversarial loss: 0.382000\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031061; batch adversarial loss: 0.425549\n",
      "epoch 186; iter: 0; batch classifier loss: 0.054797; batch adversarial loss: 0.391381\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017865; batch adversarial loss: 0.471310\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013152; batch adversarial loss: 0.457931\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017185; batch adversarial loss: 0.433598\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011103; batch adversarial loss: 0.529985\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016116; batch adversarial loss: 0.362327\n",
      "epoch 192; iter: 0; batch classifier loss: 0.041071; batch adversarial loss: 0.356323\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022841; batch adversarial loss: 0.402917\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024989; batch adversarial loss: 0.403521\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020121; batch adversarial loss: 0.477101\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011372; batch adversarial loss: 0.423212\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017453; batch adversarial loss: 0.425840\n",
      "epoch 198; iter: 0; batch classifier loss: 0.045037; batch adversarial loss: 0.462049\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009048; batch adversarial loss: 0.549588\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680762; batch adversarial loss: 0.510704\n",
      "epoch 1; iter: 0; batch classifier loss: 0.453814; batch adversarial loss: 0.603356\n",
      "epoch 2; iter: 0; batch classifier loss: 0.405257; batch adversarial loss: 0.582080\n",
      "epoch 3; iter: 0; batch classifier loss: 0.388977; batch adversarial loss: 0.567209\n",
      "epoch 4; iter: 0; batch classifier loss: 0.393031; batch adversarial loss: 0.588153\n",
      "epoch 5; iter: 0; batch classifier loss: 0.341045; batch adversarial loss: 0.561135\n",
      "epoch 6; iter: 0; batch classifier loss: 0.357739; batch adversarial loss: 0.615348\n",
      "epoch 7; iter: 0; batch classifier loss: 0.350961; batch adversarial loss: 0.544182\n",
      "epoch 8; iter: 0; batch classifier loss: 0.390570; batch adversarial loss: 0.458060\n",
      "epoch 9; iter: 0; batch classifier loss: 0.387149; batch adversarial loss: 0.534232\n",
      "epoch 10; iter: 0; batch classifier loss: 0.443688; batch adversarial loss: 0.656152\n",
      "epoch 11; iter: 0; batch classifier loss: 0.384762; batch adversarial loss: 0.525828\n",
      "epoch 12; iter: 0; batch classifier loss: 0.475949; batch adversarial loss: 0.523974\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520961; batch adversarial loss: 0.515837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.334941; batch adversarial loss: 0.473912\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310919; batch adversarial loss: 0.518663\n",
      "epoch 16; iter: 0; batch classifier loss: 0.257170; batch adversarial loss: 0.500998\n",
      "epoch 17; iter: 0; batch classifier loss: 0.233783; batch adversarial loss: 0.509872\n",
      "epoch 18; iter: 0; batch classifier loss: 0.282597; batch adversarial loss: 0.457872\n",
      "epoch 19; iter: 0; batch classifier loss: 0.215120; batch adversarial loss: 0.441243\n",
      "epoch 20; iter: 0; batch classifier loss: 0.156822; batch adversarial loss: 0.502701\n",
      "epoch 21; iter: 0; batch classifier loss: 0.168749; batch adversarial loss: 0.479731\n",
      "epoch 22; iter: 0; batch classifier loss: 0.202101; batch adversarial loss: 0.516508\n",
      "epoch 23; iter: 0; batch classifier loss: 0.212024; batch adversarial loss: 0.474046\n",
      "epoch 24; iter: 0; batch classifier loss: 0.197942; batch adversarial loss: 0.479524\n",
      "epoch 25; iter: 0; batch classifier loss: 0.151676; batch adversarial loss: 0.490111\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188437; batch adversarial loss: 0.501262\n",
      "epoch 27; iter: 0; batch classifier loss: 0.199245; batch adversarial loss: 0.464027\n",
      "epoch 28; iter: 0; batch classifier loss: 0.189626; batch adversarial loss: 0.448242\n",
      "epoch 29; iter: 0; batch classifier loss: 0.150535; batch adversarial loss: 0.427921\n",
      "epoch 30; iter: 0; batch classifier loss: 0.119831; batch adversarial loss: 0.502793\n",
      "epoch 31; iter: 0; batch classifier loss: 0.101345; batch adversarial loss: 0.472962\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140793; batch adversarial loss: 0.475454\n",
      "epoch 33; iter: 0; batch classifier loss: 0.179532; batch adversarial loss: 0.479830\n",
      "epoch 34; iter: 0; batch classifier loss: 0.090827; batch adversarial loss: 0.456465\n",
      "epoch 35; iter: 0; batch classifier loss: 0.120704; batch adversarial loss: 0.470810\n",
      "epoch 36; iter: 0; batch classifier loss: 0.122338; batch adversarial loss: 0.507405\n",
      "epoch 37; iter: 0; batch classifier loss: 0.160770; batch adversarial loss: 0.416145\n",
      "epoch 38; iter: 0; batch classifier loss: 0.112396; batch adversarial loss: 0.434555\n",
      "epoch 39; iter: 0; batch classifier loss: 0.105175; batch adversarial loss: 0.481490\n",
      "epoch 40; iter: 0; batch classifier loss: 0.097760; batch adversarial loss: 0.519901\n",
      "epoch 41; iter: 0; batch classifier loss: 0.121823; batch adversarial loss: 0.430434\n",
      "epoch 42; iter: 0; batch classifier loss: 0.082803; batch adversarial loss: 0.476673\n",
      "epoch 43; iter: 0; batch classifier loss: 0.101924; batch adversarial loss: 0.549463\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106155; batch adversarial loss: 0.422579\n",
      "epoch 45; iter: 0; batch classifier loss: 0.133818; batch adversarial loss: 0.470377\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114756; batch adversarial loss: 0.481578\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096433; batch adversarial loss: 0.434499\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092802; batch adversarial loss: 0.420555\n",
      "epoch 49; iter: 0; batch classifier loss: 0.090689; batch adversarial loss: 0.368970\n",
      "epoch 50; iter: 0; batch classifier loss: 0.061345; batch adversarial loss: 0.396440\n",
      "epoch 51; iter: 0; batch classifier loss: 0.111151; batch adversarial loss: 0.452267\n",
      "epoch 52; iter: 0; batch classifier loss: 0.092163; batch adversarial loss: 0.470416\n",
      "epoch 53; iter: 0; batch classifier loss: 0.069458; batch adversarial loss: 0.366601\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116211; batch adversarial loss: 0.454333\n",
      "epoch 55; iter: 0; batch classifier loss: 0.110571; batch adversarial loss: 0.401144\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067645; batch adversarial loss: 0.520267\n",
      "epoch 57; iter: 0; batch classifier loss: 0.109343; batch adversarial loss: 0.417835\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103075; batch adversarial loss: 0.481399\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081861; batch adversarial loss: 0.468605\n",
      "epoch 60; iter: 0; batch classifier loss: 0.067027; batch adversarial loss: 0.563480\n",
      "epoch 61; iter: 0; batch classifier loss: 0.069030; batch adversarial loss: 0.553021\n",
      "epoch 62; iter: 0; batch classifier loss: 0.071061; batch adversarial loss: 0.479181\n",
      "epoch 63; iter: 0; batch classifier loss: 0.060820; batch adversarial loss: 0.447986\n",
      "epoch 64; iter: 0; batch classifier loss: 0.088463; batch adversarial loss: 0.446896\n",
      "epoch 65; iter: 0; batch classifier loss: 0.090403; batch adversarial loss: 0.418253\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072917; batch adversarial loss: 0.515968\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130505; batch adversarial loss: 0.418901\n",
      "epoch 68; iter: 0; batch classifier loss: 0.088001; batch adversarial loss: 0.397616\n",
      "epoch 69; iter: 0; batch classifier loss: 0.068823; batch adversarial loss: 0.432002\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082367; batch adversarial loss: 0.433111\n",
      "epoch 71; iter: 0; batch classifier loss: 0.085366; batch adversarial loss: 0.442608\n",
      "epoch 72; iter: 0; batch classifier loss: 0.091347; batch adversarial loss: 0.545658\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090964; batch adversarial loss: 0.405738\n",
      "epoch 74; iter: 0; batch classifier loss: 0.068775; batch adversarial loss: 0.522328\n",
      "epoch 75; iter: 0; batch classifier loss: 0.131737; batch adversarial loss: 0.396083\n",
      "epoch 76; iter: 0; batch classifier loss: 0.113560; batch adversarial loss: 0.520055\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102609; batch adversarial loss: 0.433002\n",
      "epoch 78; iter: 0; batch classifier loss: 0.093199; batch adversarial loss: 0.436023\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093161; batch adversarial loss: 0.386811\n",
      "epoch 80; iter: 0; batch classifier loss: 0.150889; batch adversarial loss: 0.433153\n",
      "epoch 81; iter: 0; batch classifier loss: 0.094915; batch adversarial loss: 0.510950\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074370; batch adversarial loss: 0.502330\n",
      "epoch 83; iter: 0; batch classifier loss: 0.113308; batch adversarial loss: 0.451526\n",
      "epoch 84; iter: 0; batch classifier loss: 0.076231; batch adversarial loss: 0.471065\n",
      "epoch 85; iter: 0; batch classifier loss: 0.094730; batch adversarial loss: 0.539167\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068208; batch adversarial loss: 0.400022\n",
      "epoch 87; iter: 0; batch classifier loss: 0.105327; batch adversarial loss: 0.424844\n",
      "epoch 88; iter: 0; batch classifier loss: 0.048585; batch adversarial loss: 0.508364\n",
      "epoch 89; iter: 0; batch classifier loss: 0.084602; batch adversarial loss: 0.487136\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066362; batch adversarial loss: 0.463056\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052365; batch adversarial loss: 0.441653\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052063; batch adversarial loss: 0.485481\n",
      "epoch 93; iter: 0; batch classifier loss: 0.116126; batch adversarial loss: 0.534876\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072000; batch adversarial loss: 0.432706\n",
      "epoch 95; iter: 0; batch classifier loss: 0.105481; batch adversarial loss: 0.371331\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096752; batch adversarial loss: 0.445009\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066604; batch adversarial loss: 0.499372\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061984; batch adversarial loss: 0.437742\n",
      "epoch 99; iter: 0; batch classifier loss: 0.075508; batch adversarial loss: 0.463612\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047985; batch adversarial loss: 0.428319\n",
      "epoch 101; iter: 0; batch classifier loss: 0.104045; batch adversarial loss: 0.535438\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056463; batch adversarial loss: 0.551186\n",
      "epoch 103; iter: 0; batch classifier loss: 0.088220; batch adversarial loss: 0.488378\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050332; batch adversarial loss: 0.429002\n",
      "epoch 105; iter: 0; batch classifier loss: 0.063429; batch adversarial loss: 0.459620\n",
      "epoch 106; iter: 0; batch classifier loss: 0.089910; batch adversarial loss: 0.409948\n",
      "epoch 107; iter: 0; batch classifier loss: 0.083206; batch adversarial loss: 0.497065\n",
      "epoch 108; iter: 0; batch classifier loss: 0.093570; batch adversarial loss: 0.422805\n",
      "epoch 109; iter: 0; batch classifier loss: 0.052247; batch adversarial loss: 0.448228\n",
      "epoch 110; iter: 0; batch classifier loss: 0.063710; batch adversarial loss: 0.428348\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062127; batch adversarial loss: 0.427746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.030214; batch adversarial loss: 0.577067\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044423; batch adversarial loss: 0.510059\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061557; batch adversarial loss: 0.507404\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070710; batch adversarial loss: 0.403988\n",
      "epoch 116; iter: 0; batch classifier loss: 0.087485; batch adversarial loss: 0.438475\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027754; batch adversarial loss: 0.521535\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044856; batch adversarial loss: 0.448774\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049611; batch adversarial loss: 0.493181\n",
      "epoch 120; iter: 0; batch classifier loss: 0.087107; batch adversarial loss: 0.488207\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046079; batch adversarial loss: 0.519983\n",
      "epoch 122; iter: 0; batch classifier loss: 0.011775; batch adversarial loss: 0.498895\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040469; batch adversarial loss: 0.510980\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032902; batch adversarial loss: 0.468935\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037464; batch adversarial loss: 0.516601\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026040; batch adversarial loss: 0.433638\n",
      "epoch 127; iter: 0; batch classifier loss: 0.063042; batch adversarial loss: 0.443683\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030640; batch adversarial loss: 0.422312\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037740; batch adversarial loss: 0.552713\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028627; batch adversarial loss: 0.442633\n",
      "epoch 131; iter: 0; batch classifier loss: 0.075404; batch adversarial loss: 0.585334\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051964; batch adversarial loss: 0.468045\n",
      "epoch 133; iter: 0; batch classifier loss: 0.063536; batch adversarial loss: 0.499874\n",
      "epoch 134; iter: 0; batch classifier loss: 0.086907; batch adversarial loss: 0.463524\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045553; batch adversarial loss: 0.455095\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025811; batch adversarial loss: 0.387227\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045047; batch adversarial loss: 0.449270\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011720; batch adversarial loss: 0.507151\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025101; batch adversarial loss: 0.486953\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045051; batch adversarial loss: 0.471598\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046662; batch adversarial loss: 0.485588\n",
      "epoch 142; iter: 0; batch classifier loss: 0.053011; batch adversarial loss: 0.409349\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043582; batch adversarial loss: 0.533524\n",
      "epoch 144; iter: 0; batch classifier loss: 0.073515; batch adversarial loss: 0.397624\n",
      "epoch 145; iter: 0; batch classifier loss: 0.091181; batch adversarial loss: 0.386287\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030995; batch adversarial loss: 0.413007\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018469; batch adversarial loss: 0.440535\n",
      "epoch 148; iter: 0; batch classifier loss: 0.066226; batch adversarial loss: 0.483017\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033020; batch adversarial loss: 0.427059\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030978; batch adversarial loss: 0.412640\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034114; batch adversarial loss: 0.449058\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024485; batch adversarial loss: 0.494947\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022292; batch adversarial loss: 0.497323\n",
      "epoch 154; iter: 0; batch classifier loss: 0.053562; batch adversarial loss: 0.536500\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019436; batch adversarial loss: 0.500398\n",
      "epoch 156; iter: 0; batch classifier loss: 0.052631; batch adversarial loss: 0.422446\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042753; batch adversarial loss: 0.495400\n",
      "epoch 158; iter: 0; batch classifier loss: 0.043615; batch adversarial loss: 0.494872\n",
      "epoch 159; iter: 0; batch classifier loss: 0.061249; batch adversarial loss: 0.446006\n",
      "epoch 160; iter: 0; batch classifier loss: 0.048790; batch adversarial loss: 0.536180\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031366; batch adversarial loss: 0.535973\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052583; batch adversarial loss: 0.477446\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023834; batch adversarial loss: 0.484643\n",
      "epoch 164; iter: 0; batch classifier loss: 0.042975; batch adversarial loss: 0.468828\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020505; batch adversarial loss: 0.432586\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011844; batch adversarial loss: 0.486670\n",
      "epoch 167; iter: 0; batch classifier loss: 0.044394; batch adversarial loss: 0.368995\n",
      "epoch 168; iter: 0; batch classifier loss: 0.050062; batch adversarial loss: 0.481025\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019172; batch adversarial loss: 0.499066\n",
      "epoch 170; iter: 0; batch classifier loss: 0.054924; batch adversarial loss: 0.391910\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036712; batch adversarial loss: 0.531883\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040611; batch adversarial loss: 0.514077\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019721; batch adversarial loss: 0.500317\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038242; batch adversarial loss: 0.494374\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019569; batch adversarial loss: 0.484600\n",
      "epoch 176; iter: 0; batch classifier loss: 0.059398; batch adversarial loss: 0.495821\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020032; batch adversarial loss: 0.425356\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009165; batch adversarial loss: 0.399689\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025576; batch adversarial loss: 0.434160\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013347; batch adversarial loss: 0.426601\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027230; batch adversarial loss: 0.378076\n",
      "epoch 182; iter: 0; batch classifier loss: 0.072230; batch adversarial loss: 0.391876\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019615; batch adversarial loss: 0.567431\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026373; batch adversarial loss: 0.464209\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031116; batch adversarial loss: 0.408214\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025529; batch adversarial loss: 0.455132\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022087; batch adversarial loss: 0.457811\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026177; batch adversarial loss: 0.587697\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021383; batch adversarial loss: 0.480464\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033150; batch adversarial loss: 0.448015\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023868; batch adversarial loss: 0.510996\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023369; batch adversarial loss: 0.416078\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008594; batch adversarial loss: 0.467830\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007494; batch adversarial loss: 0.523282\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028860; batch adversarial loss: 0.459778\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023558; batch adversarial loss: 0.535841\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039965; batch adversarial loss: 0.512276\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016596; batch adversarial loss: 0.538588\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019354; batch adversarial loss: 0.463532\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718315; batch adversarial loss: 0.528216\n",
      "epoch 1; iter: 0; batch classifier loss: 0.482107; batch adversarial loss: 0.594171\n",
      "epoch 2; iter: 0; batch classifier loss: 0.411530; batch adversarial loss: 0.597915\n",
      "epoch 3; iter: 0; batch classifier loss: 0.356839; batch adversarial loss: 0.570832\n",
      "epoch 4; iter: 0; batch classifier loss: 0.346435; batch adversarial loss: 0.535193\n",
      "epoch 5; iter: 0; batch classifier loss: 0.368795; batch adversarial loss: 0.535077\n",
      "epoch 6; iter: 0; batch classifier loss: 0.297195; batch adversarial loss: 0.574063\n",
      "epoch 7; iter: 0; batch classifier loss: 0.295469; batch adversarial loss: 0.547506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.288192; batch adversarial loss: 0.491641\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416887; batch adversarial loss: 0.534538\n",
      "epoch 10; iter: 0; batch classifier loss: 0.369441; batch adversarial loss: 0.573167\n",
      "epoch 11; iter: 0; batch classifier loss: 0.347166; batch adversarial loss: 0.500521\n",
      "epoch 12; iter: 0; batch classifier loss: 0.430900; batch adversarial loss: 0.519117\n",
      "epoch 13; iter: 0; batch classifier loss: 0.298991; batch adversarial loss: 0.453508\n",
      "epoch 14; iter: 0; batch classifier loss: 0.307730; batch adversarial loss: 0.534329\n",
      "epoch 15; iter: 0; batch classifier loss: 0.241895; batch adversarial loss: 0.515851\n",
      "epoch 16; iter: 0; batch classifier loss: 0.284543; batch adversarial loss: 0.498345\n",
      "epoch 17; iter: 0; batch classifier loss: 0.291667; batch adversarial loss: 0.432300\n",
      "epoch 18; iter: 0; batch classifier loss: 0.266134; batch adversarial loss: 0.479627\n",
      "epoch 19; iter: 0; batch classifier loss: 0.305534; batch adversarial loss: 0.604171\n",
      "epoch 20; iter: 0; batch classifier loss: 0.174315; batch adversarial loss: 0.467156\n",
      "epoch 21; iter: 0; batch classifier loss: 0.198310; batch adversarial loss: 0.502697\n",
      "epoch 22; iter: 0; batch classifier loss: 0.229782; batch adversarial loss: 0.430272\n",
      "epoch 23; iter: 0; batch classifier loss: 0.209531; batch adversarial loss: 0.494857\n",
      "epoch 24; iter: 0; batch classifier loss: 0.244983; batch adversarial loss: 0.416796\n",
      "epoch 25; iter: 0; batch classifier loss: 0.216990; batch adversarial loss: 0.429040\n",
      "epoch 26; iter: 0; batch classifier loss: 0.174456; batch adversarial loss: 0.514711\n",
      "epoch 27; iter: 0; batch classifier loss: 0.215010; batch adversarial loss: 0.541484\n",
      "epoch 28; iter: 0; batch classifier loss: 0.214334; batch adversarial loss: 0.425929\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180976; batch adversarial loss: 0.515465\n",
      "epoch 30; iter: 0; batch classifier loss: 0.230654; batch adversarial loss: 0.394009\n",
      "epoch 31; iter: 0; batch classifier loss: 0.276551; batch adversarial loss: 0.433362\n",
      "epoch 32; iter: 0; batch classifier loss: 0.217348; batch adversarial loss: 0.458358\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188348; batch adversarial loss: 0.504646\n",
      "epoch 34; iter: 0; batch classifier loss: 0.258059; batch adversarial loss: 0.495748\n",
      "epoch 35; iter: 0; batch classifier loss: 0.229128; batch adversarial loss: 0.471719\n",
      "epoch 36; iter: 0; batch classifier loss: 0.204214; batch adversarial loss: 0.436521\n",
      "epoch 37; iter: 0; batch classifier loss: 0.233182; batch adversarial loss: 0.500959\n",
      "epoch 38; iter: 0; batch classifier loss: 0.231738; batch adversarial loss: 0.467809\n",
      "epoch 39; iter: 0; batch classifier loss: 0.171302; batch adversarial loss: 0.458520\n",
      "epoch 40; iter: 0; batch classifier loss: 0.180794; batch adversarial loss: 0.536003\n",
      "epoch 41; iter: 0; batch classifier loss: 0.185592; batch adversarial loss: 0.415307\n",
      "epoch 42; iter: 0; batch classifier loss: 0.221941; batch adversarial loss: 0.497640\n",
      "epoch 43; iter: 0; batch classifier loss: 0.217217; batch adversarial loss: 0.480606\n",
      "epoch 44; iter: 0; batch classifier loss: 0.211812; batch adversarial loss: 0.489272\n",
      "epoch 45; iter: 0; batch classifier loss: 0.227147; batch adversarial loss: 0.554748\n",
      "epoch 46; iter: 0; batch classifier loss: 0.223087; batch adversarial loss: 0.467099\n",
      "epoch 47; iter: 0; batch classifier loss: 0.234654; batch adversarial loss: 0.445411\n",
      "epoch 48; iter: 0; batch classifier loss: 0.236002; batch adversarial loss: 0.494526\n",
      "epoch 49; iter: 0; batch classifier loss: 0.244014; batch adversarial loss: 0.459667\n",
      "epoch 50; iter: 0; batch classifier loss: 0.236633; batch adversarial loss: 0.470977\n",
      "epoch 51; iter: 0; batch classifier loss: 0.202535; batch adversarial loss: 0.422538\n",
      "epoch 52; iter: 0; batch classifier loss: 0.272436; batch adversarial loss: 0.411407\n",
      "epoch 53; iter: 0; batch classifier loss: 0.105396; batch adversarial loss: 0.445940\n",
      "epoch 54; iter: 0; batch classifier loss: 0.069677; batch adversarial loss: 0.374467\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083595; batch adversarial loss: 0.468998\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103622; batch adversarial loss: 0.481375\n",
      "epoch 57; iter: 0; batch classifier loss: 0.070226; batch adversarial loss: 0.645991\n",
      "epoch 58; iter: 0; batch classifier loss: 0.068539; batch adversarial loss: 0.507980\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083624; batch adversarial loss: 0.408962\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105872; batch adversarial loss: 0.549641\n",
      "epoch 61; iter: 0; batch classifier loss: 0.153012; batch adversarial loss: 0.433893\n",
      "epoch 62; iter: 0; batch classifier loss: 0.107318; batch adversarial loss: 0.463015\n",
      "epoch 63; iter: 0; batch classifier loss: 0.102358; batch adversarial loss: 0.416318\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084371; batch adversarial loss: 0.455675\n",
      "epoch 65; iter: 0; batch classifier loss: 0.090021; batch adversarial loss: 0.490614\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089360; batch adversarial loss: 0.407533\n",
      "epoch 67; iter: 0; batch classifier loss: 0.177878; batch adversarial loss: 0.482906\n",
      "epoch 68; iter: 0; batch classifier loss: 0.111793; batch adversarial loss: 0.482593\n",
      "epoch 69; iter: 0; batch classifier loss: 0.097418; batch adversarial loss: 0.483201\n",
      "epoch 70; iter: 0; batch classifier loss: 0.130111; batch adversarial loss: 0.484360\n",
      "epoch 71; iter: 0; batch classifier loss: 0.122701; batch adversarial loss: 0.485599\n",
      "epoch 72; iter: 0; batch classifier loss: 0.042557; batch adversarial loss: 0.461332\n",
      "epoch 73; iter: 0; batch classifier loss: 0.072912; batch adversarial loss: 0.468271\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067928; batch adversarial loss: 0.486418\n",
      "epoch 75; iter: 0; batch classifier loss: 0.086811; batch adversarial loss: 0.471053\n",
      "epoch 76; iter: 0; batch classifier loss: 0.134578; batch adversarial loss: 0.381466\n",
      "epoch 77; iter: 0; batch classifier loss: 0.133439; batch adversarial loss: 0.467837\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085015; batch adversarial loss: 0.566956\n",
      "epoch 79; iter: 0; batch classifier loss: 0.108446; batch adversarial loss: 0.398197\n",
      "epoch 80; iter: 0; batch classifier loss: 0.100384; batch adversarial loss: 0.389799\n",
      "epoch 81; iter: 0; batch classifier loss: 0.100820; batch adversarial loss: 0.516289\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072501; batch adversarial loss: 0.464431\n",
      "epoch 83; iter: 0; batch classifier loss: 0.096728; batch adversarial loss: 0.533049\n",
      "epoch 84; iter: 0; batch classifier loss: 0.102110; batch adversarial loss: 0.442362\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088790; batch adversarial loss: 0.520702\n",
      "epoch 86; iter: 0; batch classifier loss: 0.101687; batch adversarial loss: 0.583939\n",
      "epoch 87; iter: 0; batch classifier loss: 0.124461; batch adversarial loss: 0.392888\n",
      "epoch 88; iter: 0; batch classifier loss: 0.086968; batch adversarial loss: 0.397367\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059330; batch adversarial loss: 0.588637\n",
      "epoch 90; iter: 0; batch classifier loss: 0.099494; batch adversarial loss: 0.481395\n",
      "epoch 91; iter: 0; batch classifier loss: 0.085154; batch adversarial loss: 0.479858\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077377; batch adversarial loss: 0.513945\n",
      "epoch 93; iter: 0; batch classifier loss: 0.134786; batch adversarial loss: 0.397575\n",
      "epoch 94; iter: 0; batch classifier loss: 0.093731; batch adversarial loss: 0.447107\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087578; batch adversarial loss: 0.444145\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062913; batch adversarial loss: 0.511298\n",
      "epoch 97; iter: 0; batch classifier loss: 0.096065; batch adversarial loss: 0.397852\n",
      "epoch 98; iter: 0; batch classifier loss: 0.140961; batch adversarial loss: 0.508529\n",
      "epoch 99; iter: 0; batch classifier loss: 0.102071; batch adversarial loss: 0.480805\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076259; batch adversarial loss: 0.461438\n",
      "epoch 101; iter: 0; batch classifier loss: 0.101000; batch adversarial loss: 0.409343\n",
      "epoch 102; iter: 0; batch classifier loss: 0.082549; batch adversarial loss: 0.430703\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058915; batch adversarial loss: 0.476122\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069479; batch adversarial loss: 0.428059\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061217; batch adversarial loss: 0.385461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.054197; batch adversarial loss: 0.542566\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049098; batch adversarial loss: 0.429912\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045164; batch adversarial loss: 0.465383\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070090; batch adversarial loss: 0.498740\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069216; batch adversarial loss: 0.461232\n",
      "epoch 111; iter: 0; batch classifier loss: 0.067753; batch adversarial loss: 0.487719\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042957; batch adversarial loss: 0.447836\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056678; batch adversarial loss: 0.478456\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042027; batch adversarial loss: 0.419631\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062946; batch adversarial loss: 0.496873\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035769; batch adversarial loss: 0.436637\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035292; batch adversarial loss: 0.480662\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053580; batch adversarial loss: 0.463500\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057929; batch adversarial loss: 0.411158\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037190; batch adversarial loss: 0.386049\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046589; batch adversarial loss: 0.431651\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039102; batch adversarial loss: 0.500577\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031182; batch adversarial loss: 0.396485\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026238; batch adversarial loss: 0.453275\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038520; batch adversarial loss: 0.506188\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017767; batch adversarial loss: 0.449412\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029412; batch adversarial loss: 0.570900\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042390; batch adversarial loss: 0.428978\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017095; batch adversarial loss: 0.415193\n",
      "epoch 130; iter: 0; batch classifier loss: 0.058874; batch adversarial loss: 0.433278\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043512; batch adversarial loss: 0.416969\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033377; batch adversarial loss: 0.373888\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030531; batch adversarial loss: 0.484100\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042943; batch adversarial loss: 0.478277\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060263; batch adversarial loss: 0.441824\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046738; batch adversarial loss: 0.392099\n",
      "epoch 137; iter: 0; batch classifier loss: 0.014607; batch adversarial loss: 0.517696\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029959; batch adversarial loss: 0.486281\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044036; batch adversarial loss: 0.443058\n",
      "epoch 140; iter: 0; batch classifier loss: 0.012121; batch adversarial loss: 0.471323\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039196; batch adversarial loss: 0.401667\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018780; batch adversarial loss: 0.394016\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032584; batch adversarial loss: 0.456929\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022628; batch adversarial loss: 0.481432\n",
      "epoch 145; iter: 0; batch classifier loss: 0.069830; batch adversarial loss: 0.407174\n",
      "epoch 146; iter: 0; batch classifier loss: 0.008062; batch adversarial loss: 0.438658\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035722; batch adversarial loss: 0.570475\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040815; batch adversarial loss: 0.520835\n",
      "epoch 149; iter: 0; batch classifier loss: 0.009131; batch adversarial loss: 0.446614\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034214; batch adversarial loss: 0.406293\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040492; batch adversarial loss: 0.398717\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018107; batch adversarial loss: 0.397748\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023208; batch adversarial loss: 0.416956\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033441; batch adversarial loss: 0.423632\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019002; batch adversarial loss: 0.385589\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013211; batch adversarial loss: 0.454944\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027433; batch adversarial loss: 0.474770\n",
      "epoch 158; iter: 0; batch classifier loss: 0.053136; batch adversarial loss: 0.499846\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027850; batch adversarial loss: 0.454342\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026758; batch adversarial loss: 0.494853\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017993; batch adversarial loss: 0.434363\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039097; batch adversarial loss: 0.463862\n",
      "epoch 163; iter: 0; batch classifier loss: 0.057172; batch adversarial loss: 0.477756\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015808; batch adversarial loss: 0.463961\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048877; batch adversarial loss: 0.492127\n",
      "epoch 166; iter: 0; batch classifier loss: 0.039047; batch adversarial loss: 0.346470\n",
      "epoch 167; iter: 0; batch classifier loss: 0.043654; batch adversarial loss: 0.328761\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033847; batch adversarial loss: 0.375719\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033066; batch adversarial loss: 0.499270\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014524; batch adversarial loss: 0.437138\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028354; batch adversarial loss: 0.461912\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005798; batch adversarial loss: 0.477100\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020823; batch adversarial loss: 0.362001\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011290; batch adversarial loss: 0.447775\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008463; batch adversarial loss: 0.419029\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016219; batch adversarial loss: 0.343266\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029433; batch adversarial loss: 0.424703\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019142; batch adversarial loss: 0.432579\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016855; batch adversarial loss: 0.491107\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030686; batch adversarial loss: 0.459336\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013968; batch adversarial loss: 0.493953\n",
      "epoch 182; iter: 0; batch classifier loss: 0.005157; batch adversarial loss: 0.407752\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015554; batch adversarial loss: 0.475364\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018571; batch adversarial loss: 0.443861\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016416; batch adversarial loss: 0.541400\n",
      "epoch 186; iter: 0; batch classifier loss: 0.004467; batch adversarial loss: 0.442258\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013666; batch adversarial loss: 0.468095\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029766; batch adversarial loss: 0.429602\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009672; batch adversarial loss: 0.443220\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020319; batch adversarial loss: 0.493662\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010903; batch adversarial loss: 0.496328\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012490; batch adversarial loss: 0.427094\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025756; batch adversarial loss: 0.365023\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007257; batch adversarial loss: 0.591599\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018074; batch adversarial loss: 0.398170\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012239; batch adversarial loss: 0.375524\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005881; batch adversarial loss: 0.374755\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025124; batch adversarial loss: 0.482286\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008289; batch adversarial loss: 0.367130\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698888; batch adversarial loss: 0.518609\n",
      "epoch 1; iter: 0; batch classifier loss: 0.321431; batch adversarial loss: 0.599809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.406942; batch adversarial loss: 0.605585\n",
      "epoch 3; iter: 0; batch classifier loss: 0.400515; batch adversarial loss: 0.594556\n",
      "epoch 4; iter: 0; batch classifier loss: 0.344712; batch adversarial loss: 0.557282\n",
      "epoch 5; iter: 0; batch classifier loss: 0.268894; batch adversarial loss: 0.653566\n",
      "epoch 6; iter: 0; batch classifier loss: 0.310641; batch adversarial loss: 0.561379\n",
      "epoch 7; iter: 0; batch classifier loss: 0.331696; batch adversarial loss: 0.594814\n",
      "epoch 8; iter: 0; batch classifier loss: 0.346761; batch adversarial loss: 0.551032\n",
      "epoch 9; iter: 0; batch classifier loss: 0.247054; batch adversarial loss: 0.501543\n",
      "epoch 10; iter: 0; batch classifier loss: 0.267545; batch adversarial loss: 0.579997\n",
      "epoch 11; iter: 0; batch classifier loss: 0.296869; batch adversarial loss: 0.437726\n",
      "epoch 12; iter: 0; batch classifier loss: 0.393162; batch adversarial loss: 0.521147\n",
      "epoch 13; iter: 0; batch classifier loss: 0.409655; batch adversarial loss: 0.576874\n",
      "epoch 14; iter: 0; batch classifier loss: 0.579527; batch adversarial loss: 0.610819\n",
      "epoch 15; iter: 0; batch classifier loss: 0.445384; batch adversarial loss: 0.529638\n",
      "epoch 16; iter: 0; batch classifier loss: 0.437634; batch adversarial loss: 0.499813\n",
      "epoch 17; iter: 0; batch classifier loss: 0.338585; batch adversarial loss: 0.459255\n",
      "epoch 18; iter: 0; batch classifier loss: 0.217871; batch adversarial loss: 0.488787\n",
      "epoch 19; iter: 0; batch classifier loss: 0.215293; batch adversarial loss: 0.527466\n",
      "epoch 20; iter: 0; batch classifier loss: 0.191129; batch adversarial loss: 0.457321\n",
      "epoch 21; iter: 0; batch classifier loss: 0.233455; batch adversarial loss: 0.416689\n",
      "epoch 22; iter: 0; batch classifier loss: 0.167503; batch adversarial loss: 0.459743\n",
      "epoch 23; iter: 0; batch classifier loss: 0.194068; batch adversarial loss: 0.421110\n",
      "epoch 24; iter: 0; batch classifier loss: 0.136592; batch adversarial loss: 0.394954\n",
      "epoch 25; iter: 0; batch classifier loss: 0.233793; batch adversarial loss: 0.441966\n",
      "epoch 26; iter: 0; batch classifier loss: 0.126212; batch adversarial loss: 0.362492\n",
      "epoch 27; iter: 0; batch classifier loss: 0.156959; batch adversarial loss: 0.448012\n",
      "epoch 28; iter: 0; batch classifier loss: 0.153322; batch adversarial loss: 0.470724\n",
      "epoch 29; iter: 0; batch classifier loss: 0.162645; batch adversarial loss: 0.412205\n",
      "epoch 30; iter: 0; batch classifier loss: 0.114685; batch adversarial loss: 0.418078\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141684; batch adversarial loss: 0.476128\n",
      "epoch 32; iter: 0; batch classifier loss: 0.132343; batch adversarial loss: 0.417025\n",
      "epoch 33; iter: 0; batch classifier loss: 0.121183; batch adversarial loss: 0.445652\n",
      "epoch 34; iter: 0; batch classifier loss: 0.131796; batch adversarial loss: 0.486155\n",
      "epoch 35; iter: 0; batch classifier loss: 0.135750; batch adversarial loss: 0.486696\n",
      "epoch 36; iter: 0; batch classifier loss: 0.143159; batch adversarial loss: 0.483473\n",
      "epoch 37; iter: 0; batch classifier loss: 0.162623; batch adversarial loss: 0.378599\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126396; batch adversarial loss: 0.542704\n",
      "epoch 39; iter: 0; batch classifier loss: 0.217695; batch adversarial loss: 0.464227\n",
      "epoch 40; iter: 0; batch classifier loss: 0.085128; batch adversarial loss: 0.521456\n",
      "epoch 41; iter: 0; batch classifier loss: 0.144011; batch adversarial loss: 0.473293\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146726; batch adversarial loss: 0.517421\n",
      "epoch 43; iter: 0; batch classifier loss: 0.088178; batch adversarial loss: 0.383789\n",
      "epoch 44; iter: 0; batch classifier loss: 0.172495; batch adversarial loss: 0.463894\n",
      "epoch 45; iter: 0; batch classifier loss: 0.114411; batch adversarial loss: 0.449695\n",
      "epoch 46; iter: 0; batch classifier loss: 0.132018; batch adversarial loss: 0.425883\n",
      "epoch 47; iter: 0; batch classifier loss: 0.162720; batch adversarial loss: 0.418988\n",
      "epoch 48; iter: 0; batch classifier loss: 0.085424; batch adversarial loss: 0.393765\n",
      "epoch 49; iter: 0; batch classifier loss: 0.104033; batch adversarial loss: 0.459863\n",
      "epoch 50; iter: 0; batch classifier loss: 0.127127; batch adversarial loss: 0.470539\n",
      "epoch 51; iter: 0; batch classifier loss: 0.104795; batch adversarial loss: 0.323498\n",
      "epoch 52; iter: 0; batch classifier loss: 0.148038; batch adversarial loss: 0.450821\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098868; batch adversarial loss: 0.492630\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127831; batch adversarial loss: 0.462408\n",
      "epoch 55; iter: 0; batch classifier loss: 0.070127; batch adversarial loss: 0.415501\n",
      "epoch 56; iter: 0; batch classifier loss: 0.111031; batch adversarial loss: 0.411267\n",
      "epoch 57; iter: 0; batch classifier loss: 0.117782; batch adversarial loss: 0.420418\n",
      "epoch 58; iter: 0; batch classifier loss: 0.128874; batch adversarial loss: 0.492912\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092488; batch adversarial loss: 0.463607\n",
      "epoch 60; iter: 0; batch classifier loss: 0.112625; batch adversarial loss: 0.391916\n",
      "epoch 61; iter: 0; batch classifier loss: 0.097203; batch adversarial loss: 0.435211\n",
      "epoch 62; iter: 0; batch classifier loss: 0.138511; batch adversarial loss: 0.433621\n",
      "epoch 63; iter: 0; batch classifier loss: 0.159101; batch adversarial loss: 0.454747\n",
      "epoch 64; iter: 0; batch classifier loss: 0.192046; batch adversarial loss: 0.406648\n",
      "epoch 65; iter: 0; batch classifier loss: 0.130267; batch adversarial loss: 0.436389\n",
      "epoch 66; iter: 0; batch classifier loss: 0.141701; batch adversarial loss: 0.556330\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080604; batch adversarial loss: 0.490108\n",
      "epoch 68; iter: 0; batch classifier loss: 0.093442; batch adversarial loss: 0.443909\n",
      "epoch 69; iter: 0; batch classifier loss: 0.166876; batch adversarial loss: 0.470532\n",
      "epoch 70; iter: 0; batch classifier loss: 0.117851; batch adversarial loss: 0.383361\n",
      "epoch 71; iter: 0; batch classifier loss: 0.107848; batch adversarial loss: 0.426651\n",
      "epoch 72; iter: 0; batch classifier loss: 0.168193; batch adversarial loss: 0.524432\n",
      "epoch 73; iter: 0; batch classifier loss: 0.143647; batch adversarial loss: 0.511336\n",
      "epoch 74; iter: 0; batch classifier loss: 0.158661; batch adversarial loss: 0.498759\n",
      "epoch 75; iter: 0; batch classifier loss: 0.115247; batch adversarial loss: 0.542489\n",
      "epoch 76; iter: 0; batch classifier loss: 0.175829; batch adversarial loss: 0.433079\n",
      "epoch 77; iter: 0; batch classifier loss: 0.096191; batch adversarial loss: 0.440580\n",
      "epoch 78; iter: 0; batch classifier loss: 0.125421; batch adversarial loss: 0.381054\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074429; batch adversarial loss: 0.499608\n",
      "epoch 80; iter: 0; batch classifier loss: 0.101390; batch adversarial loss: 0.482854\n",
      "epoch 81; iter: 0; batch classifier loss: 0.097026; batch adversarial loss: 0.359208\n",
      "epoch 82; iter: 0; batch classifier loss: 0.089955; batch adversarial loss: 0.410658\n",
      "epoch 83; iter: 0; batch classifier loss: 0.131144; batch adversarial loss: 0.390267\n",
      "epoch 84; iter: 0; batch classifier loss: 0.104911; batch adversarial loss: 0.415994\n",
      "epoch 85; iter: 0; batch classifier loss: 0.166707; batch adversarial loss: 0.388902\n",
      "epoch 86; iter: 0; batch classifier loss: 0.112387; batch adversarial loss: 0.496593\n",
      "epoch 87; iter: 0; batch classifier loss: 0.135858; batch adversarial loss: 0.441598\n",
      "epoch 88; iter: 0; batch classifier loss: 0.144792; batch adversarial loss: 0.471680\n",
      "epoch 89; iter: 0; batch classifier loss: 0.134162; batch adversarial loss: 0.423427\n",
      "epoch 90; iter: 0; batch classifier loss: 0.137417; batch adversarial loss: 0.368549\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059763; batch adversarial loss: 0.449391\n",
      "epoch 92; iter: 0; batch classifier loss: 0.098743; batch adversarial loss: 0.393349\n",
      "epoch 93; iter: 0; batch classifier loss: 0.145438; batch adversarial loss: 0.449487\n",
      "epoch 94; iter: 0; batch classifier loss: 0.086359; batch adversarial loss: 0.558758\n",
      "epoch 95; iter: 0; batch classifier loss: 0.078687; batch adversarial loss: 0.424596\n",
      "epoch 96; iter: 0; batch classifier loss: 0.080654; batch adversarial loss: 0.542969\n",
      "epoch 97; iter: 0; batch classifier loss: 0.084655; batch adversarial loss: 0.478706\n",
      "epoch 98; iter: 0; batch classifier loss: 0.137632; batch adversarial loss: 0.446822\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074369; batch adversarial loss: 0.442444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.141714; batch adversarial loss: 0.496192\n",
      "epoch 101; iter: 0; batch classifier loss: 0.109480; batch adversarial loss: 0.487394\n",
      "epoch 102; iter: 0; batch classifier loss: 0.095750; batch adversarial loss: 0.387283\n",
      "epoch 103; iter: 0; batch classifier loss: 0.112127; batch adversarial loss: 0.420760\n",
      "epoch 104; iter: 0; batch classifier loss: 0.132387; batch adversarial loss: 0.468906\n",
      "epoch 105; iter: 0; batch classifier loss: 0.093530; batch adversarial loss: 0.368141\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035765; batch adversarial loss: 0.521495\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066843; batch adversarial loss: 0.430946\n",
      "epoch 108; iter: 0; batch classifier loss: 0.076579; batch adversarial loss: 0.476571\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070052; batch adversarial loss: 0.452301\n",
      "epoch 110; iter: 0; batch classifier loss: 0.084654; batch adversarial loss: 0.498434\n",
      "epoch 111; iter: 0; batch classifier loss: 0.106451; batch adversarial loss: 0.385105\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049210; batch adversarial loss: 0.344686\n",
      "epoch 113; iter: 0; batch classifier loss: 0.070444; batch adversarial loss: 0.445615\n",
      "epoch 114; iter: 0; batch classifier loss: 0.076068; batch adversarial loss: 0.399517\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056313; batch adversarial loss: 0.448735\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050292; batch adversarial loss: 0.470584\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038372; batch adversarial loss: 0.426085\n",
      "epoch 118; iter: 0; batch classifier loss: 0.074804; batch adversarial loss: 0.471983\n",
      "epoch 119; iter: 0; batch classifier loss: 0.061965; batch adversarial loss: 0.376222\n",
      "epoch 120; iter: 0; batch classifier loss: 0.084821; batch adversarial loss: 0.474162\n",
      "epoch 121; iter: 0; batch classifier loss: 0.086582; batch adversarial loss: 0.381541\n",
      "epoch 122; iter: 0; batch classifier loss: 0.060111; batch adversarial loss: 0.339446\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038366; batch adversarial loss: 0.447395\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042108; batch adversarial loss: 0.361372\n",
      "epoch 125; iter: 0; batch classifier loss: 0.063485; batch adversarial loss: 0.431578\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045237; batch adversarial loss: 0.523362\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053016; batch adversarial loss: 0.427392\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040458; batch adversarial loss: 0.396091\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051347; batch adversarial loss: 0.425206\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018984; batch adversarial loss: 0.339183\n",
      "epoch 131; iter: 0; batch classifier loss: 0.062704; batch adversarial loss: 0.466163\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042513; batch adversarial loss: 0.420919\n",
      "epoch 133; iter: 0; batch classifier loss: 0.061484; batch adversarial loss: 0.418162\n",
      "epoch 134; iter: 0; batch classifier loss: 0.075641; batch adversarial loss: 0.535206\n",
      "epoch 135; iter: 0; batch classifier loss: 0.054004; batch adversarial loss: 0.372429\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041061; batch adversarial loss: 0.507594\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039421; batch adversarial loss: 0.549224\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022966; batch adversarial loss: 0.451706\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039361; batch adversarial loss: 0.371257\n",
      "epoch 140; iter: 0; batch classifier loss: 0.070363; batch adversarial loss: 0.461372\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034059; batch adversarial loss: 0.393228\n",
      "epoch 142; iter: 0; batch classifier loss: 0.052004; batch adversarial loss: 0.521323\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017047; batch adversarial loss: 0.391766\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019528; batch adversarial loss: 0.417956\n",
      "epoch 145; iter: 0; batch classifier loss: 0.092593; batch adversarial loss: 0.395014\n",
      "epoch 146; iter: 0; batch classifier loss: 0.068085; batch adversarial loss: 0.441710\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028827; batch adversarial loss: 0.485225\n",
      "epoch 148; iter: 0; batch classifier loss: 0.060130; batch adversarial loss: 0.373709\n",
      "epoch 149; iter: 0; batch classifier loss: 0.047493; batch adversarial loss: 0.422088\n",
      "epoch 150; iter: 0; batch classifier loss: 0.065073; batch adversarial loss: 0.391447\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044094; batch adversarial loss: 0.389063\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026423; batch adversarial loss: 0.367570\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028576; batch adversarial loss: 0.367828\n",
      "epoch 154; iter: 0; batch classifier loss: 0.063004; batch adversarial loss: 0.572938\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028983; batch adversarial loss: 0.486324\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016798; batch adversarial loss: 0.396904\n",
      "epoch 157; iter: 0; batch classifier loss: 0.048310; batch adversarial loss: 0.439653\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021646; batch adversarial loss: 0.502731\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041149; batch adversarial loss: 0.375585\n",
      "epoch 160; iter: 0; batch classifier loss: 0.039583; batch adversarial loss: 0.387016\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020644; batch adversarial loss: 0.489793\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025831; batch adversarial loss: 0.356351\n",
      "epoch 163; iter: 0; batch classifier loss: 0.031599; batch adversarial loss: 0.378802\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021518; batch adversarial loss: 0.476029\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024244; batch adversarial loss: 0.424623\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010204; batch adversarial loss: 0.393772\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027010; batch adversarial loss: 0.497151\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040934; batch adversarial loss: 0.450744\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044707; batch adversarial loss: 0.451404\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019594; batch adversarial loss: 0.465115\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028897; batch adversarial loss: 0.399965\n",
      "epoch 172; iter: 0; batch classifier loss: 0.041377; batch adversarial loss: 0.420445\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008548; batch adversarial loss: 0.545961\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040247; batch adversarial loss: 0.420307\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025930; batch adversarial loss: 0.477113\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022932; batch adversarial loss: 0.499373\n",
      "epoch 177; iter: 0; batch classifier loss: 0.059354; batch adversarial loss: 0.436530\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029645; batch adversarial loss: 0.497580\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013345; batch adversarial loss: 0.440719\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017915; batch adversarial loss: 0.428487\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018254; batch adversarial loss: 0.452847\n",
      "epoch 182; iter: 0; batch classifier loss: 0.035277; batch adversarial loss: 0.544120\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024126; batch adversarial loss: 0.465745\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025909; batch adversarial loss: 0.457179\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021801; batch adversarial loss: 0.444283\n",
      "epoch 186; iter: 0; batch classifier loss: 0.044811; batch adversarial loss: 0.417158\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021359; batch adversarial loss: 0.509918\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035757; batch adversarial loss: 0.371742\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026909; batch adversarial loss: 0.476294\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020497; batch adversarial loss: 0.502919\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027969; batch adversarial loss: 0.504955\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028630; batch adversarial loss: 0.556666\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021628; batch adversarial loss: 0.399047\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039835; batch adversarial loss: 0.481157\n",
      "epoch 195; iter: 0; batch classifier loss: 0.047504; batch adversarial loss: 0.468966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.020533; batch adversarial loss: 0.449206\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013709; batch adversarial loss: 0.544789\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013887; batch adversarial loss: 0.446660\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013348; batch adversarial loss: 0.437112\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea2ab3",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ff3788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47ba6360",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:46.750905Z",
     "start_time": "2024-01-04T20:53:46.744795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 300,\n",
      " 'experiment_iteration': 'Exp_iter_3',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 300,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b0aa26f024ad1b1089190e134193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 300, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddcae8f6fc4651885a3144088ae9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43ba8d965cc436a91f10cc39b3d5e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94495e7bec64c9ebf4c05cdd52e605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f7167dd20740a68f8f90158ec19560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b1273f",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36315bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7566409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:37.675129Z",
     "start_time": "2024-01-04T20:53:37.670178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 400,\n",
      " 'experiment_iteration': 'Exp_iter_4',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 400,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5b534568b14897b8686d22a9c79d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 400, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42164aebf0d74a5992f0ca8075639200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a128a0a62f40fb9bd0b88e41d55103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6300cf6db9cc4bcf95389b1f6e9b8108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e75feb8b5c4e00a1fc551544462dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140fe99a",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ecedfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39b844ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:27.080554Z",
     "start_time": "2024-01-04T20:53:27.072313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 500,\n",
      " 'experiment_iteration': 'Exp_iter_5',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 500,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8257cfd4f743e8887bbc74613694af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 500, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2d40e5f54c4d67bf9f1e66289ae23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63535df3c576469e9e855b70194bc572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15688b8597f74cdaadb60cc93599720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165f4884fae4f29829de3acc475dac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58191eee",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0072e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86e7ed46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:16.632770Z",
     "start_time": "2024-01-04T20:53:16.629083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 600,\n",
      " 'experiment_iteration': 'Exp_iter_6',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 600,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2670abffe30e4a388a7a09306feb6673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 600, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f28080438649c0aa4a0f71f4b322c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511b20dacfe5420981d3cf173f60fc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a989d937f483784b5138783479302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c5fe28a14a47118da3a7d485a77e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9483247c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
